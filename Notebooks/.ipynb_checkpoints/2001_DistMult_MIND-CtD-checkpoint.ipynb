{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d6bf3a-b341-4282-9470-beaa8f275cf3",
   "metadata": {},
   "source": [
    "# Run DistMult algorithm on MIND-CtD dataset\n",
    "## Parameters:\n",
    "* batch_size: 200\n",
    "* hidden_dimension_size: 225\n",
    "* learning_rate: 0.001\n",
    "* negative_sample_size: 100\n",
    "* `double_entity_embedding`: True for ComplEx\n",
    "* `double_relation_embedding`: True for ComplEx and RotatE\n",
    "\n",
    "\n",
    "## Code for Hyperparameter Optimization\n",
    "```python\n",
    "# Code for Generating MCtD best trials\n",
    "storage = optuna.storages.RDBStorage(\n",
    "    url=\"postgresql+psycopg2://rogertu:admin@localhost/optuna_test\",\n",
    ")\n",
    "mctd_dist = optuna.load_study(study_name = 'DistMult_MIND_CtD', storage = storage)\n",
    "mctd_dist.best_trial\n",
    "```\n",
    "\n",
    "## Results\n",
    "```\n",
    "FrozenTrial(number=58, values=[0.07018471468688428], datetime_start=datetime.datetime(2022, 10, 24, 16, 22, 20, 767474), datetime_complete=datetime.datetime(2022, 10, 24, 17, 17, 57, 506841), params={'batch_size': 200, 'negative_sample_size': 100, 'hidden_dimension_size': 225, 'learning_rate': 0.009380369158284479, 'max_steps': 70000}, distributions={'batch_size': IntDistribution(high=256, log=False, low=64, step=4), 'negative_sample_size': IntDistribution(high=128, log=False, low=64, step=4), 'hidden_dimension_size': IntDistribution(high=300, log=False, low=100, step=25), 'learning_rate': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'max_steps': IntDistribution(high=100000, log=False, low=50000, step=10000)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1058, state=TrialState.COMPLETE, value=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757f0b5c-43a4-434b-8dcf-e4128bd9b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e04cec2-4efe-4ff5-9186-8d3ae66aaaaf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu117\n",
      "Start Training......\n",
      "2022-11-02 12:18:06,457 INFO     Model: DistMult\n",
      "2022-11-02 12:18:06,458 INFO     Data Path: data/MIND_CtD\n",
      "2022-11-02 12:18:06,458 INFO     #entity: 249605\n",
      "2022-11-02 12:18:06,458 INFO     #relation: 83\n",
      "2022-11-02 12:18:11,372 INFO     #train: 9657134\n",
      "2022-11-02 12:18:11,372 INFO     #valid: 473\n",
      "2022-11-02 12:18:11,372 INFO     #test: 511\n",
      "2022-11-02 12:18:11,819 INFO     Model Parameter Configuration:\n",
      "2022-11-02 12:18:11,820 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2022-11-02 12:18:11,820 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2022-11-02 12:18:11,820 INFO     Parameter entity_embedding: torch.Size([249605, 225]), require_grad = True\n",
      "2022-11-02 12:18:11,820 INFO     Parameter relation_embedding: torch.Size([83, 225]), require_grad = True\n",
      "2022-11-02 12:18:55,519 INFO     Ramdomly Initializing DistMult Model...\n",
      "2022-11-02 12:18:55,519 INFO     Start Training...\n",
      "2022-11-02 12:18:55,519 INFO     init_step = 0\n",
      "2022-11-02 12:18:55,519 INFO     batch_size = 200\n",
      "2022-11-02 12:18:55,519 INFO     negative_adversarial_sampling = 1\n",
      "2022-11-02 12:18:55,519 INFO     hidden_dim = 225\n",
      "2022-11-02 12:18:55,519 INFO     gamma = 48.000000\n",
      "2022-11-02 12:18:55,519 INFO     negative_adversarial_sampling = True\n",
      "2022-11-02 12:18:55,519 INFO     adversarial_temperature = 1.000000\n",
      "2022-11-02 12:18:55,519 INFO     learning_rate = 0\n",
      "2022-11-02 12:18:56,969 INFO     Training average positive_sample_loss at step 0: 0.688967\n",
      "2022-11-02 12:18:56,969 INFO     Training average negative_sample_loss at step 0: 0.693888\n",
      "2022-11-02 12:18:56,969 INFO     Training average loss at step 0: 0.691427\n",
      "2022-11-02 12:19:00,156 INFO     Training average positive_sample_loss at step 100: 0.693413\n",
      "2022-11-02 12:19:00,156 INFO     Training average negative_sample_loss at step 100: 0.693792\n",
      "2022-11-02 12:19:00,156 INFO     Training average loss at step 100: 0.693602\n",
      "2022-11-02 12:19:02,737 INFO     Training average positive_sample_loss at step 200: 0.693186\n",
      "2022-11-02 12:19:02,737 INFO     Training average negative_sample_loss at step 200: 0.693767\n",
      "2022-11-02 12:19:02,737 INFO     Training average loss at step 200: 0.693476\n",
      "2022-11-02 12:19:05,318 INFO     Training average positive_sample_loss at step 300: 0.693426\n",
      "2022-11-02 12:19:05,318 INFO     Training average negative_sample_loss at step 300: 0.693806\n",
      "2022-11-02 12:19:05,318 INFO     Training average loss at step 300: 0.693616\n",
      "2022-11-02 12:19:07,914 INFO     Training average positive_sample_loss at step 400: 0.693096\n",
      "2022-11-02 12:19:07,914 INFO     Training average negative_sample_loss at step 400: 0.693760\n",
      "2022-11-02 12:19:07,914 INFO     Training average loss at step 400: 0.693428\n",
      "2022-11-02 12:19:10,498 INFO     Training average positive_sample_loss at step 500: 0.693339\n",
      "2022-11-02 12:19:10,498 INFO     Training average negative_sample_loss at step 500: 0.693770\n",
      "2022-11-02 12:19:10,498 INFO     Training average loss at step 500: 0.693554\n",
      "2022-11-02 12:19:13,062 INFO     Training average positive_sample_loss at step 600: 0.692714\n",
      "2022-11-02 12:19:13,062 INFO     Training average negative_sample_loss at step 600: 0.693797\n",
      "2022-11-02 12:19:13,062 INFO     Training average loss at step 600: 0.693256\n",
      "2022-11-02 12:19:15,644 INFO     Training average positive_sample_loss at step 700: 0.693096\n",
      "2022-11-02 12:19:15,644 INFO     Training average negative_sample_loss at step 700: 0.693731\n",
      "2022-11-02 12:19:15,644 INFO     Training average loss at step 700: 0.693414\n",
      "2022-11-02 12:19:18,206 INFO     Training average positive_sample_loss at step 800: 0.693562\n",
      "2022-11-02 12:19:18,207 INFO     Training average negative_sample_loss at step 800: 0.693777\n",
      "2022-11-02 12:19:18,207 INFO     Training average loss at step 800: 0.693670\n",
      "2022-11-02 12:19:20,776 INFO     Training average positive_sample_loss at step 900: 0.692897\n",
      "2022-11-02 12:19:20,776 INFO     Training average negative_sample_loss at step 900: 0.693758\n",
      "2022-11-02 12:19:20,776 INFO     Training average loss at step 900: 0.693328\n",
      "2022-11-02 12:19:23,354 INFO     Training average positive_sample_loss at step 1000: 0.693037\n",
      "2022-11-02 12:19:23,354 INFO     Training average negative_sample_loss at step 1000: 0.693749\n",
      "2022-11-02 12:19:23,354 INFO     Training average loss at step 1000: 0.693393\n",
      "2022-11-02 12:19:25,960 INFO     Training average positive_sample_loss at step 1100: 0.693034\n",
      "2022-11-02 12:19:25,960 INFO     Training average negative_sample_loss at step 1100: 0.693747\n",
      "2022-11-02 12:19:25,961 INFO     Training average loss at step 1100: 0.693390\n",
      "2022-11-02 12:19:28,538 INFO     Training average positive_sample_loss at step 1200: 0.693063\n",
      "2022-11-02 12:19:28,538 INFO     Training average negative_sample_loss at step 1200: 0.693783\n",
      "2022-11-02 12:19:28,538 INFO     Training average loss at step 1200: 0.693423\n",
      "2022-11-02 12:19:30,938 INFO     Training average positive_sample_loss at step 1300: 0.692806\n",
      "2022-11-02 12:19:30,938 INFO     Training average negative_sample_loss at step 1300: 0.693801\n",
      "2022-11-02 12:19:30,938 INFO     Training average loss at step 1300: 0.693303\n",
      "2022-11-02 12:19:32,727 INFO     Training average positive_sample_loss at step 1400: 0.692716\n",
      "2022-11-02 12:19:32,727 INFO     Training average negative_sample_loss at step 1400: 0.693762\n",
      "2022-11-02 12:19:32,727 INFO     Training average loss at step 1400: 0.693239\n",
      "2022-11-02 12:19:35,305 INFO     Training average positive_sample_loss at step 1500: 0.692804\n",
      "2022-11-02 12:19:35,305 INFO     Training average negative_sample_loss at step 1500: 0.693776\n",
      "2022-11-02 12:19:35,305 INFO     Training average loss at step 1500: 0.693290\n",
      "2022-11-02 12:19:37,170 INFO     Training average positive_sample_loss at step 1600: 0.692740\n",
      "2022-11-02 12:19:37,170 INFO     Training average negative_sample_loss at step 1600: 0.693783\n",
      "2022-11-02 12:19:37,170 INFO     Training average loss at step 1600: 0.693261\n",
      "2022-11-02 12:19:38,900 INFO     Training average positive_sample_loss at step 1700: 0.692603\n",
      "2022-11-02 12:19:38,900 INFO     Training average negative_sample_loss at step 1700: 0.693812\n",
      "2022-11-02 12:19:38,900 INFO     Training average loss at step 1700: 0.693207\n",
      "2022-11-02 12:19:41,099 INFO     Training average positive_sample_loss at step 1800: 0.692577\n",
      "2022-11-02 12:19:41,100 INFO     Training average negative_sample_loss at step 1800: 0.693769\n",
      "2022-11-02 12:19:41,100 INFO     Training average loss at step 1800: 0.693173\n",
      "2022-11-02 12:19:43,695 INFO     Training average positive_sample_loss at step 1900: 0.692471\n",
      "2022-11-02 12:19:43,696 INFO     Training average negative_sample_loss at step 1900: 0.693802\n",
      "2022-11-02 12:19:43,696 INFO     Training average loss at step 1900: 0.693137\n",
      "2022-11-02 12:19:46,282 INFO     Training average positive_sample_loss at step 2000: 0.692560\n",
      "2022-11-02 12:19:46,282 INFO     Training average negative_sample_loss at step 2000: 0.693788\n",
      "2022-11-02 12:19:46,282 INFO     Training average loss at step 2000: 0.693174\n",
      "2022-11-02 12:19:48,859 INFO     Training average positive_sample_loss at step 2100: 0.692134\n",
      "2022-11-02 12:19:48,859 INFO     Training average negative_sample_loss at step 2100: 0.693787\n",
      "2022-11-02 12:19:48,859 INFO     Training average loss at step 2100: 0.692961\n",
      "2022-11-02 12:19:51,425 INFO     Training average positive_sample_loss at step 2200: 0.692299\n",
      "2022-11-02 12:19:51,425 INFO     Training average negative_sample_loss at step 2200: 0.693801\n",
      "2022-11-02 12:19:51,425 INFO     Training average loss at step 2200: 0.693050\n",
      "2022-11-02 12:19:53,993 INFO     Training average positive_sample_loss at step 2300: 0.692256\n",
      "2022-11-02 12:19:53,993 INFO     Training average negative_sample_loss at step 2300: 0.693796\n",
      "2022-11-02 12:19:53,993 INFO     Training average loss at step 2300: 0.693026\n",
      "2022-11-02 12:19:56,567 INFO     Training average positive_sample_loss at step 2400: 0.692197\n",
      "2022-11-02 12:19:56,567 INFO     Training average negative_sample_loss at step 2400: 0.693819\n",
      "2022-11-02 12:19:56,568 INFO     Training average loss at step 2400: 0.693008\n",
      "2022-11-02 12:19:59,145 INFO     Training average positive_sample_loss at step 2500: 0.691931\n",
      "2022-11-02 12:19:59,145 INFO     Training average negative_sample_loss at step 2500: 0.693822\n",
      "2022-11-02 12:19:59,145 INFO     Training average loss at step 2500: 0.692877\n",
      "2022-11-02 12:20:01,717 INFO     Training average positive_sample_loss at step 2600: 0.691141\n",
      "2022-11-02 12:20:01,717 INFO     Training average negative_sample_loss at step 2600: 0.693838\n",
      "2022-11-02 12:20:01,717 INFO     Training average loss at step 2600: 0.692490\n",
      "2022-11-02 12:20:04,285 INFO     Training average positive_sample_loss at step 2700: 0.690967\n",
      "2022-11-02 12:20:04,285 INFO     Training average negative_sample_loss at step 2700: 0.693829\n",
      "2022-11-02 12:20:04,285 INFO     Training average loss at step 2700: 0.692398\n",
      "2022-11-02 12:20:06,859 INFO     Training average positive_sample_loss at step 2800: 0.690653\n",
      "2022-11-02 12:20:06,860 INFO     Training average negative_sample_loss at step 2800: 0.693840\n",
      "2022-11-02 12:20:06,860 INFO     Training average loss at step 2800: 0.692246\n",
      "2022-11-02 12:20:09,427 INFO     Training average positive_sample_loss at step 2900: 0.690144\n",
      "2022-11-02 12:20:09,427 INFO     Training average negative_sample_loss at step 2900: 0.693844\n",
      "2022-11-02 12:20:09,427 INFO     Training average loss at step 2900: 0.691994\n",
      "2022-11-02 12:20:11,984 INFO     Training average positive_sample_loss at step 3000: 0.689604\n",
      "2022-11-02 12:20:11,984 INFO     Training average negative_sample_loss at step 3000: 0.693847\n",
      "2022-11-02 12:20:11,984 INFO     Training average loss at step 3000: 0.691725\n",
      "2022-11-02 12:20:14,562 INFO     Training average positive_sample_loss at step 3100: 0.688567\n",
      "2022-11-02 12:20:14,562 INFO     Training average negative_sample_loss at step 3100: 0.693814\n",
      "2022-11-02 12:20:14,562 INFO     Training average loss at step 3100: 0.691190\n",
      "2022-11-02 12:20:17,117 INFO     Training average positive_sample_loss at step 3200: 0.687974\n",
      "2022-11-02 12:20:17,117 INFO     Training average negative_sample_loss at step 3200: 0.693752\n",
      "2022-11-02 12:20:17,117 INFO     Training average loss at step 3200: 0.690863\n",
      "2022-11-02 12:20:19,669 INFO     Training average positive_sample_loss at step 3300: 0.686155\n",
      "2022-11-02 12:20:19,669 INFO     Training average negative_sample_loss at step 3300: 0.693684\n",
      "2022-11-02 12:20:19,669 INFO     Training average loss at step 3300: 0.689920\n",
      "2022-11-02 12:20:22,233 INFO     Training average positive_sample_loss at step 3400: 0.684462\n",
      "2022-11-02 12:20:22,233 INFO     Training average negative_sample_loss at step 3400: 0.693459\n",
      "2022-11-02 12:20:22,233 INFO     Training average loss at step 3400: 0.688961\n",
      "2022-11-02 12:20:24,822 INFO     Training average positive_sample_loss at step 3500: 0.681718\n",
      "2022-11-02 12:20:24,822 INFO     Training average negative_sample_loss at step 3500: 0.693288\n",
      "2022-11-02 12:20:24,822 INFO     Training average loss at step 3500: 0.687503\n",
      "2022-11-02 12:20:27,378 INFO     Training average positive_sample_loss at step 3600: 0.678735\n",
      "2022-11-02 12:20:27,378 INFO     Training average negative_sample_loss at step 3600: 0.692848\n",
      "2022-11-02 12:20:27,378 INFO     Training average loss at step 3600: 0.685791\n",
      "2022-11-02 12:20:29,963 INFO     Training average positive_sample_loss at step 3700: 0.673953\n",
      "2022-11-02 12:20:29,963 INFO     Training average negative_sample_loss at step 3700: 0.692123\n",
      "2022-11-02 12:20:29,963 INFO     Training average loss at step 3700: 0.683038\n",
      "2022-11-02 12:20:32,514 INFO     Training average positive_sample_loss at step 3800: 0.669500\n",
      "2022-11-02 12:20:32,514 INFO     Training average negative_sample_loss at step 3800: 0.691279\n",
      "2022-11-02 12:20:32,514 INFO     Training average loss at step 3800: 0.680389\n",
      "2022-11-02 12:20:35,065 INFO     Training average positive_sample_loss at step 3900: 0.662623\n",
      "2022-11-02 12:20:35,066 INFO     Training average negative_sample_loss at step 3900: 0.689952\n",
      "2022-11-02 12:20:35,066 INFO     Training average loss at step 3900: 0.676288\n",
      "2022-11-02 12:20:37,617 INFO     Training average positive_sample_loss at step 4000: 0.654687\n",
      "2022-11-02 12:20:37,617 INFO     Training average negative_sample_loss at step 4000: 0.688672\n",
      "2022-11-02 12:20:37,617 INFO     Training average loss at step 4000: 0.671680\n",
      "2022-11-02 12:20:40,163 INFO     Training average positive_sample_loss at step 4100: 0.645698\n",
      "2022-11-02 12:20:40,163 INFO     Training average negative_sample_loss at step 4100: 0.686698\n",
      "2022-11-02 12:20:40,163 INFO     Training average loss at step 4100: 0.666198\n",
      "2022-11-02 12:20:42,734 INFO     Training average positive_sample_loss at step 4200: 0.636759\n",
      "2022-11-02 12:20:42,734 INFO     Training average negative_sample_loss at step 4200: 0.684727\n",
      "2022-11-02 12:20:42,734 INFO     Training average loss at step 4200: 0.660743\n",
      "2022-11-02 12:20:45,324 INFO     Training average positive_sample_loss at step 4300: 0.625632\n",
      "2022-11-02 12:20:45,324 INFO     Training average negative_sample_loss at step 4300: 0.682111\n",
      "2022-11-02 12:20:45,324 INFO     Training average loss at step 4300: 0.653872\n",
      "2022-11-02 12:20:47,952 INFO     Training average positive_sample_loss at step 4400: 0.616682\n",
      "2022-11-02 12:20:47,952 INFO     Training average negative_sample_loss at step 4400: 0.679603\n",
      "2022-11-02 12:20:47,952 INFO     Training average loss at step 4400: 0.648142\n",
      "2022-11-02 12:20:50,555 INFO     Training average positive_sample_loss at step 4500: 0.603962\n",
      "2022-11-02 12:20:50,555 INFO     Training average negative_sample_loss at step 4500: 0.676896\n",
      "2022-11-02 12:20:50,555 INFO     Training average loss at step 4500: 0.640429\n",
      "2022-11-02 12:20:53,171 INFO     Training average positive_sample_loss at step 4600: 0.591997\n",
      "2022-11-02 12:20:53,171 INFO     Training average negative_sample_loss at step 4600: 0.674394\n",
      "2022-11-02 12:20:53,171 INFO     Training average loss at step 4600: 0.633196\n",
      "2022-11-02 12:20:55,789 INFO     Training average positive_sample_loss at step 4700: 0.582557\n",
      "2022-11-02 12:20:55,789 INFO     Training average negative_sample_loss at step 4700: 0.672466\n",
      "2022-11-02 12:20:55,789 INFO     Training average loss at step 4700: 0.627511\n",
      "2022-11-02 12:20:58,370 INFO     Training average positive_sample_loss at step 4800: 0.574994\n",
      "2022-11-02 12:20:58,370 INFO     Training average negative_sample_loss at step 4800: 0.670785\n",
      "2022-11-02 12:20:58,370 INFO     Training average loss at step 4800: 0.622890\n",
      "2022-11-02 12:21:00,952 INFO     Training average positive_sample_loss at step 4900: 0.565470\n",
      "2022-11-02 12:21:00,952 INFO     Training average negative_sample_loss at step 4900: 0.669887\n",
      "2022-11-02 12:21:00,952 INFO     Training average loss at step 4900: 0.617678\n",
      "2022-11-02 12:21:03,503 INFO     Training average positive_sample_loss at step 5000: 0.553927\n",
      "2022-11-02 12:21:03,504 INFO     Training average negative_sample_loss at step 5000: 0.667516\n",
      "2022-11-02 12:21:03,504 INFO     Training average loss at step 5000: 0.610721\n",
      "2022-11-02 12:21:06,070 INFO     Training average positive_sample_loss at step 5100: 0.541221\n",
      "2022-11-02 12:21:06,070 INFO     Training average negative_sample_loss at step 5100: 0.667071\n",
      "2022-11-02 12:21:06,070 INFO     Training average loss at step 5100: 0.604146\n",
      "2022-11-02 12:21:08,604 INFO     Training average positive_sample_loss at step 5200: 0.536965\n",
      "2022-11-02 12:21:08,604 INFO     Training average negative_sample_loss at step 5200: 0.666996\n",
      "2022-11-02 12:21:08,604 INFO     Training average loss at step 5200: 0.601981\n",
      "2022-11-02 12:21:11,199 INFO     Training average positive_sample_loss at step 5300: 0.527370\n",
      "2022-11-02 12:21:11,199 INFO     Training average negative_sample_loss at step 5300: 0.666573\n",
      "2022-11-02 12:21:11,199 INFO     Training average loss at step 5300: 0.596971\n",
      "2022-11-02 12:21:13,813 INFO     Training average positive_sample_loss at step 5400: 0.522622\n",
      "2022-11-02 12:21:13,813 INFO     Training average negative_sample_loss at step 5400: 0.666980\n",
      "2022-11-02 12:21:13,813 INFO     Training average loss at step 5400: 0.594801\n",
      "2022-11-02 12:21:16,416 INFO     Training average positive_sample_loss at step 5500: 0.513770\n",
      "2022-11-02 12:21:16,416 INFO     Training average negative_sample_loss at step 5500: 0.666224\n",
      "2022-11-02 12:21:16,416 INFO     Training average loss at step 5500: 0.589997\n",
      "2022-11-02 12:21:18,977 INFO     Training average positive_sample_loss at step 5600: 0.505310\n",
      "2022-11-02 12:21:18,977 INFO     Training average negative_sample_loss at step 5600: 0.663348\n",
      "2022-11-02 12:21:18,977 INFO     Training average loss at step 5600: 0.584329\n",
      "2022-11-02 12:21:21,555 INFO     Training average positive_sample_loss at step 5700: 0.505440\n",
      "2022-11-02 12:21:21,555 INFO     Training average negative_sample_loss at step 5700: 0.662064\n",
      "2022-11-02 12:21:21,555 INFO     Training average loss at step 5700: 0.583752\n",
      "2022-11-02 12:21:24,135 INFO     Training average positive_sample_loss at step 5800: 0.493733\n",
      "2022-11-02 12:21:24,135 INFO     Training average negative_sample_loss at step 5800: 0.659450\n",
      "2022-11-02 12:21:24,135 INFO     Training average loss at step 5800: 0.576591\n",
      "2022-11-02 12:21:26,698 INFO     Training average positive_sample_loss at step 5900: 0.490432\n",
      "2022-11-02 12:21:26,698 INFO     Training average negative_sample_loss at step 5900: 0.657772\n",
      "2022-11-02 12:21:26,698 INFO     Training average loss at step 5900: 0.574102\n",
      "2022-11-02 12:21:29,265 INFO     Training average positive_sample_loss at step 6000: 0.487598\n",
      "2022-11-02 12:21:29,265 INFO     Training average negative_sample_loss at step 6000: 0.657830\n",
      "2022-11-02 12:21:29,265 INFO     Training average loss at step 6000: 0.572714\n",
      "2022-11-02 12:21:31,809 INFO     Training average positive_sample_loss at step 6100: 0.488396\n",
      "2022-11-02 12:21:31,809 INFO     Training average negative_sample_loss at step 6100: 0.650502\n",
      "2022-11-02 12:21:31,809 INFO     Training average loss at step 6100: 0.569449\n",
      "2022-11-02 12:21:34,334 INFO     Training average positive_sample_loss at step 6200: 0.487705\n",
      "2022-11-02 12:21:34,334 INFO     Training average negative_sample_loss at step 6200: 0.650449\n",
      "2022-11-02 12:21:34,334 INFO     Training average loss at step 6200: 0.569077\n",
      "2022-11-02 12:21:36,862 INFO     Training average positive_sample_loss at step 6300: 0.482477\n",
      "2022-11-02 12:21:36,862 INFO     Training average negative_sample_loss at step 6300: 0.649877\n",
      "2022-11-02 12:21:36,862 INFO     Training average loss at step 6300: 0.566177\n",
      "2022-11-02 12:21:39,395 INFO     Training average positive_sample_loss at step 6400: 0.480619\n",
      "2022-11-02 12:21:39,395 INFO     Training average negative_sample_loss at step 6400: 0.644364\n",
      "2022-11-02 12:21:39,395 INFO     Training average loss at step 6400: 0.562491\n",
      "2022-11-02 12:21:41,922 INFO     Training average positive_sample_loss at step 6500: 0.477838\n",
      "2022-11-02 12:21:41,922 INFO     Training average negative_sample_loss at step 6500: 0.641629\n",
      "2022-11-02 12:21:41,922 INFO     Training average loss at step 6500: 0.559734\n",
      "2022-11-02 12:21:44,440 INFO     Training average positive_sample_loss at step 6600: 0.474021\n",
      "2022-11-02 12:21:44,441 INFO     Training average negative_sample_loss at step 6600: 0.637432\n",
      "2022-11-02 12:21:44,441 INFO     Training average loss at step 6600: 0.555726\n",
      "2022-11-02 12:21:46,984 INFO     Training average positive_sample_loss at step 6700: 0.477077\n",
      "2022-11-02 12:21:46,985 INFO     Training average negative_sample_loss at step 6700: 0.631436\n",
      "2022-11-02 12:21:46,985 INFO     Training average loss at step 6700: 0.554257\n",
      "2022-11-02 12:21:49,510 INFO     Training average positive_sample_loss at step 6800: 0.471479\n",
      "2022-11-02 12:21:49,511 INFO     Training average negative_sample_loss at step 6800: 0.630495\n",
      "2022-11-02 12:21:49,511 INFO     Training average loss at step 6800: 0.550987\n",
      "2022-11-02 12:21:52,026 INFO     Training average positive_sample_loss at step 6900: 0.475822\n",
      "2022-11-02 12:21:52,026 INFO     Training average negative_sample_loss at step 6900: 0.625286\n",
      "2022-11-02 12:21:52,027 INFO     Training average loss at step 6900: 0.550554\n",
      "2022-11-02 12:21:54,599 INFO     Training average positive_sample_loss at step 7000: 0.480735\n",
      "2022-11-02 12:21:54,599 INFO     Training average negative_sample_loss at step 7000: 0.620689\n",
      "2022-11-02 12:21:54,599 INFO     Training average loss at step 7000: 0.550712\n",
      "2022-11-02 12:21:57,267 INFO     Training average positive_sample_loss at step 7100: 0.476663\n",
      "2022-11-02 12:21:57,267 INFO     Training average negative_sample_loss at step 7100: 0.616077\n",
      "2022-11-02 12:21:57,267 INFO     Training average loss at step 7100: 0.546370\n",
      "2022-11-02 12:21:59,876 INFO     Training average positive_sample_loss at step 7200: 0.476780\n",
      "2022-11-02 12:21:59,876 INFO     Training average negative_sample_loss at step 7200: 0.612035\n",
      "2022-11-02 12:21:59,876 INFO     Training average loss at step 7200: 0.544408\n",
      "2022-11-02 12:22:02,406 INFO     Training average positive_sample_loss at step 7300: 0.478469\n",
      "2022-11-02 12:22:02,406 INFO     Training average negative_sample_loss at step 7300: 0.604181\n",
      "2022-11-02 12:22:02,406 INFO     Training average loss at step 7300: 0.541325\n",
      "2022-11-02 12:22:04,955 INFO     Training average positive_sample_loss at step 7400: 0.480206\n",
      "2022-11-02 12:22:04,955 INFO     Training average negative_sample_loss at step 7400: 0.603429\n",
      "2022-11-02 12:22:04,955 INFO     Training average loss at step 7400: 0.541818\n",
      "2022-11-02 12:22:07,628 INFO     Training average positive_sample_loss at step 7500: 0.477868\n",
      "2022-11-02 12:22:07,628 INFO     Training average negative_sample_loss at step 7500: 0.594267\n",
      "2022-11-02 12:22:07,628 INFO     Training average loss at step 7500: 0.536068\n",
      "2022-11-02 12:22:10,298 INFO     Training average positive_sample_loss at step 7600: 0.481173\n",
      "2022-11-02 12:22:10,298 INFO     Training average negative_sample_loss at step 7600: 0.593699\n",
      "2022-11-02 12:22:10,298 INFO     Training average loss at step 7600: 0.537436\n",
      "2022-11-02 12:22:12,858 INFO     Training average positive_sample_loss at step 7700: 0.476253\n",
      "2022-11-02 12:22:12,858 INFO     Training average negative_sample_loss at step 7700: 0.590610\n",
      "2022-11-02 12:22:12,858 INFO     Training average loss at step 7700: 0.533431\n",
      "2022-11-02 12:22:15,403 INFO     Training average positive_sample_loss at step 7800: 0.481466\n",
      "2022-11-02 12:22:15,403 INFO     Training average negative_sample_loss at step 7800: 0.584094\n",
      "2022-11-02 12:22:15,403 INFO     Training average loss at step 7800: 0.532780\n",
      "2022-11-02 12:22:17,965 INFO     Training average positive_sample_loss at step 7900: 0.481889\n",
      "2022-11-02 12:22:17,965 INFO     Training average negative_sample_loss at step 7900: 0.580759\n",
      "2022-11-02 12:22:17,965 INFO     Training average loss at step 7900: 0.531324\n",
      "2022-11-02 12:22:20,514 INFO     Training average positive_sample_loss at step 8000: 0.476262\n",
      "2022-11-02 12:22:20,514 INFO     Training average negative_sample_loss at step 8000: 0.577607\n",
      "2022-11-02 12:22:20,514 INFO     Training average loss at step 8000: 0.526934\n",
      "2022-11-02 12:22:23,047 INFO     Training average positive_sample_loss at step 8100: 0.481670\n",
      "2022-11-02 12:22:23,047 INFO     Training average negative_sample_loss at step 8100: 0.573990\n",
      "2022-11-02 12:22:23,047 INFO     Training average loss at step 8100: 0.527830\n",
      "2022-11-02 12:22:25,622 INFO     Training average positive_sample_loss at step 8200: 0.492127\n",
      "2022-11-02 12:22:25,622 INFO     Training average negative_sample_loss at step 8200: 0.571064\n",
      "2022-11-02 12:22:25,622 INFO     Training average loss at step 8200: 0.531595\n",
      "2022-11-02 12:22:28,024 INFO     Training average positive_sample_loss at step 8300: 0.482121\n",
      "2022-11-02 12:22:28,024 INFO     Training average negative_sample_loss at step 8300: 0.565738\n",
      "2022-11-02 12:22:28,024 INFO     Training average loss at step 8300: 0.523930\n",
      "2022-11-02 12:22:29,831 INFO     Training average positive_sample_loss at step 8400: 0.480156\n",
      "2022-11-02 12:22:29,831 INFO     Training average negative_sample_loss at step 8400: 0.564804\n",
      "2022-11-02 12:22:29,831 INFO     Training average loss at step 8400: 0.522480\n",
      "2022-11-02 12:22:32,381 INFO     Training average positive_sample_loss at step 8500: 0.481533\n",
      "2022-11-02 12:22:32,381 INFO     Training average negative_sample_loss at step 8500: 0.560813\n",
      "2022-11-02 12:22:32,381 INFO     Training average loss at step 8500: 0.521173\n",
      "2022-11-02 12:22:34,435 INFO     Training average positive_sample_loss at step 8600: 0.482854\n",
      "2022-11-02 12:22:34,435 INFO     Training average negative_sample_loss at step 8600: 0.559203\n",
      "2022-11-02 12:22:34,435 INFO     Training average loss at step 8600: 0.521029\n",
      "2022-11-02 12:22:36,707 INFO     Training average positive_sample_loss at step 8700: 0.479182\n",
      "2022-11-02 12:22:36,707 INFO     Training average negative_sample_loss at step 8700: 0.558100\n",
      "2022-11-02 12:22:36,707 INFO     Training average loss at step 8700: 0.518641\n",
      "2022-11-02 12:22:39,069 INFO     Training average positive_sample_loss at step 8800: 0.482523\n",
      "2022-11-02 12:22:39,069 INFO     Training average negative_sample_loss at step 8800: 0.558756\n",
      "2022-11-02 12:22:39,069 INFO     Training average loss at step 8800: 0.520639\n",
      "2022-11-02 12:22:40,645 INFO     Training average positive_sample_loss at step 8900: 0.494461\n",
      "2022-11-02 12:22:40,645 INFO     Training average negative_sample_loss at step 8900: 0.552685\n",
      "2022-11-02 12:22:40,645 INFO     Training average loss at step 8900: 0.523573\n",
      "2022-11-02 12:22:43,239 INFO     Training average positive_sample_loss at step 9000: 0.484958\n",
      "2022-11-02 12:22:43,239 INFO     Training average negative_sample_loss at step 9000: 0.550184\n",
      "2022-11-02 12:22:43,239 INFO     Training average loss at step 9000: 0.517571\n",
      "2022-11-02 12:22:45,816 INFO     Training average positive_sample_loss at step 9100: 0.469923\n",
      "2022-11-02 12:22:45,817 INFO     Training average negative_sample_loss at step 9100: 0.546176\n",
      "2022-11-02 12:22:45,817 INFO     Training average loss at step 9100: 0.508050\n",
      "2022-11-02 12:22:48,368 INFO     Training average positive_sample_loss at step 9200: 0.492912\n",
      "2022-11-02 12:22:48,368 INFO     Training average negative_sample_loss at step 9200: 0.545704\n",
      "2022-11-02 12:22:48,369 INFO     Training average loss at step 9200: 0.519308\n",
      "2022-11-02 12:22:50,915 INFO     Training average positive_sample_loss at step 9300: 0.481865\n",
      "2022-11-02 12:22:50,915 INFO     Training average negative_sample_loss at step 9300: 0.543657\n",
      "2022-11-02 12:22:50,915 INFO     Training average loss at step 9300: 0.512761\n",
      "2022-11-02 12:22:53,497 INFO     Training average positive_sample_loss at step 9400: 0.476060\n",
      "2022-11-02 12:22:53,497 INFO     Training average negative_sample_loss at step 9400: 0.546786\n",
      "2022-11-02 12:22:53,497 INFO     Training average loss at step 9400: 0.511423\n",
      "2022-11-02 12:22:56,054 INFO     Training average positive_sample_loss at step 9500: 0.468737\n",
      "2022-11-02 12:22:56,054 INFO     Training average negative_sample_loss at step 9500: 0.545922\n",
      "2022-11-02 12:22:56,054 INFO     Training average loss at step 9500: 0.507329\n",
      "2022-11-02 12:22:58,636 INFO     Training average positive_sample_loss at step 9600: 0.476046\n",
      "2022-11-02 12:22:58,636 INFO     Training average negative_sample_loss at step 9600: 0.541221\n",
      "2022-11-02 12:22:58,636 INFO     Training average loss at step 9600: 0.508633\n",
      "2022-11-02 12:23:01,267 INFO     Training average positive_sample_loss at step 9700: 0.480505\n",
      "2022-11-02 12:23:01,267 INFO     Training average negative_sample_loss at step 9700: 0.535519\n",
      "2022-11-02 12:23:01,267 INFO     Training average loss at step 9700: 0.508012\n",
      "2022-11-02 12:23:03,880 INFO     Training average positive_sample_loss at step 9800: 0.470571\n",
      "2022-11-02 12:23:03,880 INFO     Training average negative_sample_loss at step 9800: 0.540639\n",
      "2022-11-02 12:23:03,880 INFO     Training average loss at step 9800: 0.505605\n",
      "2022-11-02 12:23:06,449 INFO     Training average positive_sample_loss at step 9900: 0.475198\n",
      "2022-11-02 12:23:06,449 INFO     Training average negative_sample_loss at step 9900: 0.539402\n",
      "2022-11-02 12:23:06,449 INFO     Training average loss at step 9900: 0.507300\n",
      "2022-11-02 12:23:10,330 INFO     Training average positive_sample_loss at step 10000: 0.480101\n",
      "2022-11-02 12:23:10,330 INFO     Training average negative_sample_loss at step 10000: 0.533889\n",
      "2022-11-02 12:23:10,330 INFO     Training average loss at step 10000: 0.506995\n",
      "2022-11-02 12:23:12,871 INFO     Training average positive_sample_loss at step 10100: 0.473784\n",
      "2022-11-02 12:23:12,871 INFO     Training average negative_sample_loss at step 10100: 0.537657\n",
      "2022-11-02 12:23:12,871 INFO     Training average loss at step 10100: 0.505720\n",
      "2022-11-02 12:23:15,401 INFO     Training average positive_sample_loss at step 10200: 0.470673\n",
      "2022-11-02 12:23:15,401 INFO     Training average negative_sample_loss at step 10200: 0.533435\n",
      "2022-11-02 12:23:15,401 INFO     Training average loss at step 10200: 0.502054\n",
      "2022-11-02 12:23:17,940 INFO     Training average positive_sample_loss at step 10300: 0.474062\n",
      "2022-11-02 12:23:17,940 INFO     Training average negative_sample_loss at step 10300: 0.533135\n",
      "2022-11-02 12:23:17,940 INFO     Training average loss at step 10300: 0.503599\n",
      "2022-11-02 12:23:20,536 INFO     Training average positive_sample_loss at step 10400: 0.478140\n",
      "2022-11-02 12:23:20,536 INFO     Training average negative_sample_loss at step 10400: 0.533775\n",
      "2022-11-02 12:23:20,536 INFO     Training average loss at step 10400: 0.505958\n",
      "2022-11-02 12:23:23,096 INFO     Training average positive_sample_loss at step 10500: 0.478980\n",
      "2022-11-02 12:23:23,096 INFO     Training average negative_sample_loss at step 10500: 0.529005\n",
      "2022-11-02 12:23:23,096 INFO     Training average loss at step 10500: 0.503993\n",
      "2022-11-02 12:23:25,706 INFO     Training average positive_sample_loss at step 10600: 0.466872\n",
      "2022-11-02 12:23:25,706 INFO     Training average negative_sample_loss at step 10600: 0.533781\n",
      "2022-11-02 12:23:25,706 INFO     Training average loss at step 10600: 0.500327\n",
      "2022-11-02 12:23:28,303 INFO     Training average positive_sample_loss at step 10700: 0.465571\n",
      "2022-11-02 12:23:28,303 INFO     Training average negative_sample_loss at step 10700: 0.533888\n",
      "2022-11-02 12:23:28,303 INFO     Training average loss at step 10700: 0.499729\n",
      "2022-11-02 12:23:30,878 INFO     Training average positive_sample_loss at step 10800: 0.471019\n",
      "2022-11-02 12:23:30,878 INFO     Training average negative_sample_loss at step 10800: 0.531084\n",
      "2022-11-02 12:23:30,879 INFO     Training average loss at step 10800: 0.501051\n",
      "2022-11-02 12:23:33,465 INFO     Training average positive_sample_loss at step 10900: 0.464569\n",
      "2022-11-02 12:23:33,465 INFO     Training average negative_sample_loss at step 10900: 0.532123\n",
      "2022-11-02 12:23:33,465 INFO     Training average loss at step 10900: 0.498346\n",
      "2022-11-02 12:23:36,051 INFO     Training average positive_sample_loss at step 11000: 0.465018\n",
      "2022-11-02 12:23:36,051 INFO     Training average negative_sample_loss at step 11000: 0.526923\n",
      "2022-11-02 12:23:36,051 INFO     Training average loss at step 11000: 0.495971\n",
      "2022-11-02 12:23:38,636 INFO     Training average positive_sample_loss at step 11100: 0.460393\n",
      "2022-11-02 12:23:38,637 INFO     Training average negative_sample_loss at step 11100: 0.529737\n",
      "2022-11-02 12:23:38,637 INFO     Training average loss at step 11100: 0.495065\n",
      "2022-11-02 12:23:41,188 INFO     Training average positive_sample_loss at step 11200: 0.465917\n",
      "2022-11-02 12:23:41,188 INFO     Training average negative_sample_loss at step 11200: 0.525714\n",
      "2022-11-02 12:23:41,188 INFO     Training average loss at step 11200: 0.495815\n",
      "2022-11-02 12:23:43,749 INFO     Training average positive_sample_loss at step 11300: 0.466898\n",
      "2022-11-02 12:23:43,749 INFO     Training average negative_sample_loss at step 11300: 0.530777\n",
      "2022-11-02 12:23:43,749 INFO     Training average loss at step 11300: 0.498838\n",
      "2022-11-02 12:23:46,349 INFO     Training average positive_sample_loss at step 11400: 0.474425\n",
      "2022-11-02 12:23:46,349 INFO     Training average negative_sample_loss at step 11400: 0.523440\n",
      "2022-11-02 12:23:46,349 INFO     Training average loss at step 11400: 0.498933\n",
      "2022-11-02 12:23:48,951 INFO     Training average positive_sample_loss at step 11500: 0.469711\n",
      "2022-11-02 12:23:48,952 INFO     Training average negative_sample_loss at step 11500: 0.524119\n",
      "2022-11-02 12:23:48,952 INFO     Training average loss at step 11500: 0.496915\n",
      "2022-11-02 12:23:50,506 INFO     Training average positive_sample_loss at step 11600: 0.469419\n",
      "2022-11-02 12:23:50,506 INFO     Training average negative_sample_loss at step 11600: 0.523316\n",
      "2022-11-02 12:23:50,506 INFO     Training average loss at step 11600: 0.496368\n",
      "2022-11-02 12:23:52,887 INFO     Training average positive_sample_loss at step 11700: 0.461153\n",
      "2022-11-02 12:23:52,887 INFO     Training average negative_sample_loss at step 11700: 0.525251\n",
      "2022-11-02 12:23:52,887 INFO     Training average loss at step 11700: 0.493202\n",
      "2022-11-02 12:23:55,452 INFO     Training average positive_sample_loss at step 11800: 0.467085\n",
      "2022-11-02 12:23:55,452 INFO     Training average negative_sample_loss at step 11800: 0.521582\n",
      "2022-11-02 12:23:55,452 INFO     Training average loss at step 11800: 0.494333\n",
      "2022-11-02 12:23:58,009 INFO     Training average positive_sample_loss at step 11900: 0.459425\n",
      "2022-11-02 12:23:58,009 INFO     Training average negative_sample_loss at step 11900: 0.526292\n",
      "2022-11-02 12:23:58,009 INFO     Training average loss at step 11900: 0.492858\n",
      "2022-11-02 12:24:00,587 INFO     Training average positive_sample_loss at step 12000: 0.454786\n",
      "2022-11-02 12:24:00,587 INFO     Training average negative_sample_loss at step 12000: 0.528920\n",
      "2022-11-02 12:24:00,587 INFO     Training average loss at step 12000: 0.491853\n",
      "2022-11-02 12:24:03,106 INFO     Training average positive_sample_loss at step 12100: 0.460449\n",
      "2022-11-02 12:24:03,107 INFO     Training average negative_sample_loss at step 12100: 0.523234\n",
      "2022-11-02 12:24:03,107 INFO     Training average loss at step 12100: 0.491842\n",
      "2022-11-02 12:24:05,662 INFO     Training average positive_sample_loss at step 12200: 0.450689\n",
      "2022-11-02 12:24:05,662 INFO     Training average negative_sample_loss at step 12200: 0.526613\n",
      "2022-11-02 12:24:05,662 INFO     Training average loss at step 12200: 0.488651\n",
      "2022-11-02 12:24:08,257 INFO     Training average positive_sample_loss at step 12300: 0.466409\n",
      "2022-11-02 12:24:08,257 INFO     Training average negative_sample_loss at step 12300: 0.521646\n",
      "2022-11-02 12:24:08,257 INFO     Training average loss at step 12300: 0.494028\n",
      "2022-11-02 12:24:10,876 INFO     Training average positive_sample_loss at step 12400: 0.444161\n",
      "2022-11-02 12:24:10,876 INFO     Training average negative_sample_loss at step 12400: 0.527709\n",
      "2022-11-02 12:24:10,876 INFO     Training average loss at step 12400: 0.485935\n",
      "2022-11-02 12:24:13,468 INFO     Training average positive_sample_loss at step 12500: 0.456393\n",
      "2022-11-02 12:24:13,468 INFO     Training average negative_sample_loss at step 12500: 0.520543\n",
      "2022-11-02 12:24:13,468 INFO     Training average loss at step 12500: 0.488468\n",
      "2022-11-02 12:24:16,062 INFO     Training average positive_sample_loss at step 12600: 0.446213\n",
      "2022-11-02 12:24:16,062 INFO     Training average negative_sample_loss at step 12600: 0.525610\n",
      "2022-11-02 12:24:16,062 INFO     Training average loss at step 12600: 0.485911\n",
      "2022-11-02 12:24:18,625 INFO     Training average positive_sample_loss at step 12700: 0.460906\n",
      "2022-11-02 12:24:18,625 INFO     Training average negative_sample_loss at step 12700: 0.520420\n",
      "2022-11-02 12:24:18,625 INFO     Training average loss at step 12700: 0.490663\n",
      "2022-11-02 12:24:21,212 INFO     Training average positive_sample_loss at step 12800: 0.457848\n",
      "2022-11-02 12:24:21,213 INFO     Training average negative_sample_loss at step 12800: 0.517889\n",
      "2022-11-02 12:24:21,213 INFO     Training average loss at step 12800: 0.487868\n",
      "2022-11-02 12:24:23,780 INFO     Training average positive_sample_loss at step 12900: 0.451680\n",
      "2022-11-02 12:24:23,780 INFO     Training average negative_sample_loss at step 12900: 0.519045\n",
      "2022-11-02 12:24:23,781 INFO     Training average loss at step 12900: 0.485362\n",
      "2022-11-02 12:24:26,359 INFO     Training average positive_sample_loss at step 13000: 0.449977\n",
      "2022-11-02 12:24:26,359 INFO     Training average negative_sample_loss at step 13000: 0.518825\n",
      "2022-11-02 12:24:26,359 INFO     Training average loss at step 13000: 0.484401\n",
      "2022-11-02 12:24:28,951 INFO     Training average positive_sample_loss at step 13100: 0.438469\n",
      "2022-11-02 12:24:28,951 INFO     Training average negative_sample_loss at step 13100: 0.519675\n",
      "2022-11-02 12:24:28,951 INFO     Training average loss at step 13100: 0.479072\n",
      "2022-11-02 12:24:31,580 INFO     Training average positive_sample_loss at step 13200: 0.442525\n",
      "2022-11-02 12:24:31,580 INFO     Training average negative_sample_loss at step 13200: 0.519667\n",
      "2022-11-02 12:24:31,580 INFO     Training average loss at step 13200: 0.481096\n",
      "2022-11-02 12:24:34,143 INFO     Training average positive_sample_loss at step 13300: 0.443081\n",
      "2022-11-02 12:24:34,143 INFO     Training average negative_sample_loss at step 13300: 0.521590\n",
      "2022-11-02 12:24:34,143 INFO     Training average loss at step 13300: 0.482335\n",
      "2022-11-02 12:24:36,713 INFO     Training average positive_sample_loss at step 13400: 0.453304\n",
      "2022-11-02 12:24:36,713 INFO     Training average negative_sample_loss at step 13400: 0.509597\n",
      "2022-11-02 12:24:36,713 INFO     Training average loss at step 13400: 0.481451\n",
      "2022-11-02 12:24:39,304 INFO     Training average positive_sample_loss at step 13500: 0.447287\n",
      "2022-11-02 12:24:39,304 INFO     Training average negative_sample_loss at step 13500: 0.514186\n",
      "2022-11-02 12:24:39,305 INFO     Training average loss at step 13500: 0.480736\n",
      "2022-11-02 12:24:41,863 INFO     Training average positive_sample_loss at step 13600: 0.437603\n",
      "2022-11-02 12:24:41,863 INFO     Training average negative_sample_loss at step 13600: 0.518731\n",
      "2022-11-02 12:24:41,863 INFO     Training average loss at step 13600: 0.478167\n",
      "2022-11-02 12:24:44,424 INFO     Training average positive_sample_loss at step 13700: 0.443164\n",
      "2022-11-02 12:24:44,424 INFO     Training average negative_sample_loss at step 13700: 0.517796\n",
      "2022-11-02 12:24:44,424 INFO     Training average loss at step 13700: 0.480480\n",
      "2022-11-02 12:24:47,026 INFO     Training average positive_sample_loss at step 13800: 0.447847\n",
      "2022-11-02 12:24:47,026 INFO     Training average negative_sample_loss at step 13800: 0.513375\n",
      "2022-11-02 12:24:47,026 INFO     Training average loss at step 13800: 0.480611\n",
      "2022-11-02 12:24:49,632 INFO     Training average positive_sample_loss at step 13900: 0.448221\n",
      "2022-11-02 12:24:49,632 INFO     Training average negative_sample_loss at step 13900: 0.515977\n",
      "2022-11-02 12:24:49,632 INFO     Training average loss at step 13900: 0.482099\n",
      "2022-11-02 12:24:52,216 INFO     Training average positive_sample_loss at step 14000: 0.440440\n",
      "2022-11-02 12:24:52,216 INFO     Training average negative_sample_loss at step 14000: 0.515268\n",
      "2022-11-02 12:24:52,217 INFO     Training average loss at step 14000: 0.477854\n",
      "2022-11-02 12:24:54,785 INFO     Training average positive_sample_loss at step 14100: 0.432380\n",
      "2022-11-02 12:24:54,785 INFO     Training average negative_sample_loss at step 14100: 0.516675\n",
      "2022-11-02 12:24:54,785 INFO     Training average loss at step 14100: 0.474527\n",
      "2022-11-02 12:24:57,369 INFO     Training average positive_sample_loss at step 14200: 0.455995\n",
      "2022-11-02 12:24:57,370 INFO     Training average negative_sample_loss at step 14200: 0.513212\n",
      "2022-11-02 12:24:57,370 INFO     Training average loss at step 14200: 0.484604\n",
      "2022-11-02 12:24:59,947 INFO     Training average positive_sample_loss at step 14300: 0.434270\n",
      "2022-11-02 12:24:59,947 INFO     Training average negative_sample_loss at step 14300: 0.510744\n",
      "2022-11-02 12:24:59,947 INFO     Training average loss at step 14300: 0.472507\n",
      "2022-11-02 12:25:02,538 INFO     Training average positive_sample_loss at step 14400: 0.440533\n",
      "2022-11-02 12:25:02,539 INFO     Training average negative_sample_loss at step 14400: 0.509191\n",
      "2022-11-02 12:25:02,539 INFO     Training average loss at step 14400: 0.474862\n",
      "2022-11-02 12:25:05,138 INFO     Training average positive_sample_loss at step 14500: 0.442841\n",
      "2022-11-02 12:25:05,138 INFO     Training average negative_sample_loss at step 14500: 0.511961\n",
      "2022-11-02 12:25:05,138 INFO     Training average loss at step 14500: 0.477401\n",
      "2022-11-02 12:25:07,709 INFO     Training average positive_sample_loss at step 14600: 0.444202\n",
      "2022-11-02 12:25:07,709 INFO     Training average negative_sample_loss at step 14600: 0.510600\n",
      "2022-11-02 12:25:07,709 INFO     Training average loss at step 14600: 0.477401\n",
      "2022-11-02 12:25:10,266 INFO     Training average positive_sample_loss at step 14700: 0.447172\n",
      "2022-11-02 12:25:10,266 INFO     Training average negative_sample_loss at step 14700: 0.513795\n",
      "2022-11-02 12:25:10,266 INFO     Training average loss at step 14700: 0.480484\n",
      "2022-11-02 12:25:12,858 INFO     Training average positive_sample_loss at step 14800: 0.438781\n",
      "2022-11-02 12:25:12,858 INFO     Training average negative_sample_loss at step 14800: 0.513233\n",
      "2022-11-02 12:25:12,858 INFO     Training average loss at step 14800: 0.476007\n",
      "2022-11-02 12:25:15,471 INFO     Training average positive_sample_loss at step 14900: 0.432549\n",
      "2022-11-02 12:25:15,471 INFO     Training average negative_sample_loss at step 14900: 0.508922\n",
      "2022-11-02 12:25:15,471 INFO     Training average loss at step 14900: 0.470735\n",
      "2022-11-02 12:25:18,060 INFO     Training average positive_sample_loss at step 15000: 0.436288\n",
      "2022-11-02 12:25:18,060 INFO     Training average negative_sample_loss at step 15000: 0.504021\n",
      "2022-11-02 12:25:18,060 INFO     Training average loss at step 15000: 0.470155\n",
      "2022-11-02 12:25:20,659 INFO     Training average positive_sample_loss at step 15100: 0.438004\n",
      "2022-11-02 12:25:20,659 INFO     Training average negative_sample_loss at step 15100: 0.506894\n",
      "2022-11-02 12:25:20,659 INFO     Training average loss at step 15100: 0.472449\n",
      "2022-11-02 12:25:23,238 INFO     Training average positive_sample_loss at step 15200: 0.438421\n",
      "2022-11-02 12:25:23,238 INFO     Training average negative_sample_loss at step 15200: 0.507135\n",
      "2022-11-02 12:25:23,238 INFO     Training average loss at step 15200: 0.472778\n",
      "2022-11-02 12:25:25,285 INFO     Training average positive_sample_loss at step 15300: 0.441488\n",
      "2022-11-02 12:25:25,285 INFO     Training average negative_sample_loss at step 15300: 0.504939\n",
      "2022-11-02 12:25:25,285 INFO     Training average loss at step 15300: 0.473213\n",
      "2022-11-02 12:25:27,482 INFO     Training average positive_sample_loss at step 15400: 0.435169\n",
      "2022-11-02 12:25:27,483 INFO     Training average negative_sample_loss at step 15400: 0.510283\n",
      "2022-11-02 12:25:27,483 INFO     Training average loss at step 15400: 0.472726\n",
      "2022-11-02 12:25:30,061 INFO     Training average positive_sample_loss at step 15500: 0.437320\n",
      "2022-11-02 12:25:30,061 INFO     Training average negative_sample_loss at step 15500: 0.509732\n",
      "2022-11-02 12:25:30,061 INFO     Training average loss at step 15500: 0.473526\n",
      "2022-11-02 12:25:31,925 INFO     Training average positive_sample_loss at step 15600: 0.442066\n",
      "2022-11-02 12:25:31,925 INFO     Training average negative_sample_loss at step 15600: 0.504184\n",
      "2022-11-02 12:25:31,925 INFO     Training average loss at step 15600: 0.473125\n",
      "2022-11-02 12:25:34,463 INFO     Training average positive_sample_loss at step 15700: 0.431337\n",
      "2022-11-02 12:25:34,463 INFO     Training average negative_sample_loss at step 15700: 0.507981\n",
      "2022-11-02 12:25:34,463 INFO     Training average loss at step 15700: 0.469659\n",
      "2022-11-02 12:25:36,360 INFO     Training average positive_sample_loss at step 15800: 0.443330\n",
      "2022-11-02 12:25:36,361 INFO     Training average negative_sample_loss at step 15800: 0.506273\n",
      "2022-11-02 12:25:36,361 INFO     Training average loss at step 15800: 0.474802\n",
      "2022-11-02 12:25:38,662 INFO     Training average positive_sample_loss at step 15900: 0.437947\n",
      "2022-11-02 12:25:38,662 INFO     Training average negative_sample_loss at step 15900: 0.503229\n",
      "2022-11-02 12:25:38,663 INFO     Training average loss at step 15900: 0.470588\n",
      "2022-11-02 12:25:41,234 INFO     Training average positive_sample_loss at step 16000: 0.431388\n",
      "2022-11-02 12:25:41,234 INFO     Training average negative_sample_loss at step 16000: 0.507683\n",
      "2022-11-02 12:25:41,234 INFO     Training average loss at step 16000: 0.469536\n",
      "2022-11-02 12:25:42,993 INFO     Training average positive_sample_loss at step 16100: 0.437695\n",
      "2022-11-02 12:25:42,993 INFO     Training average negative_sample_loss at step 16100: 0.503748\n",
      "2022-11-02 12:25:42,993 INFO     Training average loss at step 16100: 0.470722\n",
      "2022-11-02 12:25:45,544 INFO     Training average positive_sample_loss at step 16200: 0.438602\n",
      "2022-11-02 12:25:45,544 INFO     Training average negative_sample_loss at step 16200: 0.505020\n",
      "2022-11-02 12:25:45,544 INFO     Training average loss at step 16200: 0.471811\n",
      "2022-11-02 12:25:48,108 INFO     Training average positive_sample_loss at step 16300: 0.422770\n",
      "2022-11-02 12:25:48,108 INFO     Training average negative_sample_loss at step 16300: 0.507274\n",
      "2022-11-02 12:25:48,108 INFO     Training average loss at step 16300: 0.465022\n",
      "2022-11-02 12:25:50,687 INFO     Training average positive_sample_loss at step 16400: 0.436798\n",
      "2022-11-02 12:25:50,688 INFO     Training average negative_sample_loss at step 16400: 0.499333\n",
      "2022-11-02 12:25:50,688 INFO     Training average loss at step 16400: 0.468066\n",
      "2022-11-02 12:25:53,268 INFO     Training average positive_sample_loss at step 16500: 0.433031\n",
      "2022-11-02 12:25:53,268 INFO     Training average negative_sample_loss at step 16500: 0.500739\n",
      "2022-11-02 12:25:53,268 INFO     Training average loss at step 16500: 0.466885\n",
      "2022-11-02 12:25:55,807 INFO     Training average positive_sample_loss at step 16600: 0.436866\n",
      "2022-11-02 12:25:55,807 INFO     Training average negative_sample_loss at step 16600: 0.498122\n",
      "2022-11-02 12:25:55,807 INFO     Training average loss at step 16600: 0.467494\n",
      "2022-11-02 12:25:58,351 INFO     Training average positive_sample_loss at step 16700: 0.439423\n",
      "2022-11-02 12:25:58,351 INFO     Training average negative_sample_loss at step 16700: 0.501174\n",
      "2022-11-02 12:25:58,351 INFO     Training average loss at step 16700: 0.470298\n",
      "2022-11-02 12:26:00,882 INFO     Training average positive_sample_loss at step 16800: 0.420076\n",
      "2022-11-02 12:26:00,882 INFO     Training average negative_sample_loss at step 16800: 0.498639\n",
      "2022-11-02 12:26:00,882 INFO     Training average loss at step 16800: 0.459357\n",
      "2022-11-02 12:26:03,429 INFO     Training average positive_sample_loss at step 16900: 0.424770\n",
      "2022-11-02 12:26:03,430 INFO     Training average negative_sample_loss at step 16900: 0.496825\n",
      "2022-11-02 12:26:03,430 INFO     Training average loss at step 16900: 0.460798\n",
      "2022-11-02 12:26:05,960 INFO     Training average positive_sample_loss at step 17000: 0.424998\n",
      "2022-11-02 12:26:05,960 INFO     Training average negative_sample_loss at step 17000: 0.494816\n",
      "2022-11-02 12:26:05,960 INFO     Training average loss at step 17000: 0.459907\n",
      "2022-11-02 12:26:08,510 INFO     Training average positive_sample_loss at step 17100: 0.433062\n",
      "2022-11-02 12:26:08,510 INFO     Training average negative_sample_loss at step 17100: 0.495756\n",
      "2022-11-02 12:26:08,510 INFO     Training average loss at step 17100: 0.464409\n",
      "2022-11-02 12:26:11,039 INFO     Training average positive_sample_loss at step 17200: 0.415760\n",
      "2022-11-02 12:26:11,039 INFO     Training average negative_sample_loss at step 17200: 0.500548\n",
      "2022-11-02 12:26:11,039 INFO     Training average loss at step 17200: 0.458154\n",
      "2022-11-02 12:26:13,583 INFO     Training average positive_sample_loss at step 17300: 0.426547\n",
      "2022-11-02 12:26:13,583 INFO     Training average negative_sample_loss at step 17300: 0.498957\n",
      "2022-11-02 12:26:13,583 INFO     Training average loss at step 17300: 0.462752\n",
      "2022-11-02 12:26:16,121 INFO     Training average positive_sample_loss at step 17400: 0.422650\n",
      "2022-11-02 12:26:16,121 INFO     Training average negative_sample_loss at step 17400: 0.497760\n",
      "2022-11-02 12:26:16,121 INFO     Training average loss at step 17400: 0.460205\n",
      "2022-11-02 12:26:18,663 INFO     Training average positive_sample_loss at step 17500: 0.433475\n",
      "2022-11-02 12:26:18,663 INFO     Training average negative_sample_loss at step 17500: 0.497839\n",
      "2022-11-02 12:26:18,663 INFO     Training average loss at step 17500: 0.465657\n",
      "2022-11-02 12:26:21,196 INFO     Training average positive_sample_loss at step 17600: 0.423642\n",
      "2022-11-02 12:26:21,196 INFO     Training average negative_sample_loss at step 17600: 0.495290\n",
      "2022-11-02 12:26:21,196 INFO     Training average loss at step 17600: 0.459466\n",
      "2022-11-02 12:26:23,738 INFO     Training average positive_sample_loss at step 17700: 0.425589\n",
      "2022-11-02 12:26:23,738 INFO     Training average negative_sample_loss at step 17700: 0.493801\n",
      "2022-11-02 12:26:23,739 INFO     Training average loss at step 17700: 0.459695\n",
      "2022-11-02 12:26:26,266 INFO     Training average positive_sample_loss at step 17800: 0.420814\n",
      "2022-11-02 12:26:26,266 INFO     Training average negative_sample_loss at step 17800: 0.497308\n",
      "2022-11-02 12:26:26,266 INFO     Training average loss at step 17800: 0.459061\n",
      "2022-11-02 12:26:28,803 INFO     Training average positive_sample_loss at step 17900: 0.433825\n",
      "2022-11-02 12:26:28,803 INFO     Training average negative_sample_loss at step 17900: 0.494122\n",
      "2022-11-02 12:26:28,804 INFO     Training average loss at step 17900: 0.463973\n",
      "2022-11-02 12:26:31,344 INFO     Training average positive_sample_loss at step 18000: 0.420001\n",
      "2022-11-02 12:26:31,344 INFO     Training average negative_sample_loss at step 18000: 0.493518\n",
      "2022-11-02 12:26:31,344 INFO     Training average loss at step 18000: 0.456759\n",
      "2022-11-02 12:26:33,876 INFO     Training average positive_sample_loss at step 18100: 0.434367\n",
      "2022-11-02 12:26:33,876 INFO     Training average negative_sample_loss at step 18100: 0.495904\n",
      "2022-11-02 12:26:33,877 INFO     Training average loss at step 18100: 0.465136\n",
      "2022-11-02 12:26:36,425 INFO     Training average positive_sample_loss at step 18200: 0.422300\n",
      "2022-11-02 12:26:36,425 INFO     Training average negative_sample_loss at step 18200: 0.493423\n",
      "2022-11-02 12:26:36,425 INFO     Training average loss at step 18200: 0.457861\n",
      "2022-11-02 12:26:38,974 INFO     Training average positive_sample_loss at step 18300: 0.419876\n",
      "2022-11-02 12:26:38,974 INFO     Training average negative_sample_loss at step 18300: 0.495535\n",
      "2022-11-02 12:26:38,975 INFO     Training average loss at step 18300: 0.457705\n",
      "2022-11-02 12:26:41,522 INFO     Training average positive_sample_loss at step 18400: 0.422955\n",
      "2022-11-02 12:26:41,522 INFO     Training average negative_sample_loss at step 18400: 0.495306\n",
      "2022-11-02 12:26:41,522 INFO     Training average loss at step 18400: 0.459131\n",
      "2022-11-02 12:26:44,053 INFO     Training average positive_sample_loss at step 18500: 0.426422\n",
      "2022-11-02 12:26:44,054 INFO     Training average negative_sample_loss at step 18500: 0.490034\n",
      "2022-11-02 12:26:44,054 INFO     Training average loss at step 18500: 0.458228\n",
      "2022-11-02 12:26:46,617 INFO     Training average positive_sample_loss at step 18600: 0.414247\n",
      "2022-11-02 12:26:46,617 INFO     Training average negative_sample_loss at step 18600: 0.494698\n",
      "2022-11-02 12:26:46,617 INFO     Training average loss at step 18600: 0.454472\n",
      "2022-11-02 12:26:49,152 INFO     Training average positive_sample_loss at step 18700: 0.418576\n",
      "2022-11-02 12:26:49,152 INFO     Training average negative_sample_loss at step 18700: 0.493477\n",
      "2022-11-02 12:26:49,152 INFO     Training average loss at step 18700: 0.456026\n",
      "2022-11-02 12:26:51,684 INFO     Training average positive_sample_loss at step 18800: 0.419929\n",
      "2022-11-02 12:26:51,684 INFO     Training average negative_sample_loss at step 18800: 0.491568\n",
      "2022-11-02 12:26:51,684 INFO     Training average loss at step 18800: 0.455748\n",
      "2022-11-02 12:26:54,217 INFO     Training average positive_sample_loss at step 18900: 0.430422\n",
      "2022-11-02 12:26:54,217 INFO     Training average negative_sample_loss at step 18900: 0.486909\n",
      "2022-11-02 12:26:54,218 INFO     Training average loss at step 18900: 0.458666\n",
      "2022-11-02 12:26:56,757 INFO     Training average positive_sample_loss at step 19000: 0.422395\n",
      "2022-11-02 12:26:56,757 INFO     Training average negative_sample_loss at step 19000: 0.481035\n",
      "2022-11-02 12:26:56,757 INFO     Training average loss at step 19000: 0.451715\n",
      "2022-11-02 12:26:59,304 INFO     Training average positive_sample_loss at step 19100: 0.416142\n",
      "2022-11-02 12:26:59,304 INFO     Training average negative_sample_loss at step 19100: 0.489668\n",
      "2022-11-02 12:26:59,304 INFO     Training average loss at step 19100: 0.452905\n",
      "2022-11-02 12:27:01,838 INFO     Training average positive_sample_loss at step 19200: 0.418479\n",
      "2022-11-02 12:27:01,838 INFO     Training average negative_sample_loss at step 19200: 0.491074\n",
      "2022-11-02 12:27:01,838 INFO     Training average loss at step 19200: 0.454776\n",
      "2022-11-02 12:27:04,381 INFO     Training average positive_sample_loss at step 19300: 0.403991\n",
      "2022-11-02 12:27:04,381 INFO     Training average negative_sample_loss at step 19300: 0.487413\n",
      "2022-11-02 12:27:04,381 INFO     Training average loss at step 19300: 0.445702\n",
      "2022-11-02 12:27:06,912 INFO     Training average positive_sample_loss at step 19400: 0.425303\n",
      "2022-11-02 12:27:06,912 INFO     Training average negative_sample_loss at step 19400: 0.483808\n",
      "2022-11-02 12:27:06,912 INFO     Training average loss at step 19400: 0.454556\n",
      "2022-11-02 12:27:09,442 INFO     Training average positive_sample_loss at step 19500: 0.414523\n",
      "2022-11-02 12:27:09,443 INFO     Training average negative_sample_loss at step 19500: 0.482669\n",
      "2022-11-02 12:27:09,443 INFO     Training average loss at step 19500: 0.448596\n",
      "2022-11-02 12:27:11,960 INFO     Training average positive_sample_loss at step 19600: 0.411511\n",
      "2022-11-02 12:27:11,961 INFO     Training average negative_sample_loss at step 19600: 0.487999\n",
      "2022-11-02 12:27:11,961 INFO     Training average loss at step 19600: 0.449755\n",
      "2022-11-02 12:27:14,486 INFO     Training average positive_sample_loss at step 19700: 0.412740\n",
      "2022-11-02 12:27:14,486 INFO     Training average negative_sample_loss at step 19700: 0.482934\n",
      "2022-11-02 12:27:14,486 INFO     Training average loss at step 19700: 0.447837\n",
      "2022-11-02 12:27:17,016 INFO     Training average positive_sample_loss at step 19800: 0.417066\n",
      "2022-11-02 12:27:17,016 INFO     Training average negative_sample_loss at step 19800: 0.486618\n",
      "2022-11-02 12:27:17,016 INFO     Training average loss at step 19800: 0.451842\n",
      "2022-11-02 12:27:19,542 INFO     Training average positive_sample_loss at step 19900: 0.423618\n",
      "2022-11-02 12:27:19,542 INFO     Training average negative_sample_loss at step 19900: 0.477571\n",
      "2022-11-02 12:27:19,542 INFO     Training average loss at step 19900: 0.450594\n",
      "2022-11-02 12:27:23,318 INFO     Training average positive_sample_loss at step 20000: 0.422182\n",
      "2022-11-02 12:27:23,318 INFO     Training average negative_sample_loss at step 20000: 0.482948\n",
      "2022-11-02 12:27:23,318 INFO     Training average loss at step 20000: 0.452565\n",
      "2022-11-02 12:27:25,874 INFO     Training average positive_sample_loss at step 20100: 0.422652\n",
      "2022-11-02 12:27:25,874 INFO     Training average negative_sample_loss at step 20100: 0.479991\n",
      "2022-11-02 12:27:25,874 INFO     Training average loss at step 20100: 0.451321\n",
      "2022-11-02 12:27:28,423 INFO     Training average positive_sample_loss at step 20200: 0.429709\n",
      "2022-11-02 12:27:28,423 INFO     Training average negative_sample_loss at step 20200: 0.483805\n",
      "2022-11-02 12:27:28,423 INFO     Training average loss at step 20200: 0.456757\n",
      "2022-11-02 12:27:30,956 INFO     Training average positive_sample_loss at step 20300: 0.418123\n",
      "2022-11-02 12:27:30,956 INFO     Training average negative_sample_loss at step 20300: 0.483494\n",
      "2022-11-02 12:27:30,956 INFO     Training average loss at step 20300: 0.450809\n",
      "2022-11-02 12:27:33,504 INFO     Training average positive_sample_loss at step 20400: 0.409129\n",
      "2022-11-02 12:27:33,504 INFO     Training average negative_sample_loss at step 20400: 0.482188\n",
      "2022-11-02 12:27:33,504 INFO     Training average loss at step 20400: 0.445659\n",
      "2022-11-02 12:27:36,034 INFO     Training average positive_sample_loss at step 20500: 0.419263\n",
      "2022-11-02 12:27:36,034 INFO     Training average negative_sample_loss at step 20500: 0.483834\n",
      "2022-11-02 12:27:36,034 INFO     Training average loss at step 20500: 0.451549\n",
      "2022-11-02 12:27:38,570 INFO     Training average positive_sample_loss at step 20600: 0.403461\n",
      "2022-11-02 12:27:38,570 INFO     Training average negative_sample_loss at step 20600: 0.482748\n",
      "2022-11-02 12:27:38,570 INFO     Training average loss at step 20600: 0.443105\n",
      "2022-11-02 12:27:41,111 INFO     Training average positive_sample_loss at step 20700: 0.413071\n",
      "2022-11-02 12:27:41,111 INFO     Training average negative_sample_loss at step 20700: 0.478894\n",
      "2022-11-02 12:27:41,111 INFO     Training average loss at step 20700: 0.445983\n",
      "2022-11-02 12:27:43,642 INFO     Training average positive_sample_loss at step 20800: 0.413610\n",
      "2022-11-02 12:27:43,642 INFO     Training average negative_sample_loss at step 20800: 0.482396\n",
      "2022-11-02 12:27:43,642 INFO     Training average loss at step 20800: 0.448003\n",
      "2022-11-02 12:27:46,183 INFO     Training average positive_sample_loss at step 20900: 0.401731\n",
      "2022-11-02 12:27:46,183 INFO     Training average negative_sample_loss at step 20900: 0.475175\n",
      "2022-11-02 12:27:46,183 INFO     Training average loss at step 20900: 0.438453\n",
      "2022-11-02 12:27:48,723 INFO     Training average positive_sample_loss at step 21000: 0.421629\n",
      "2022-11-02 12:27:48,724 INFO     Training average negative_sample_loss at step 21000: 0.478260\n",
      "2022-11-02 12:27:48,724 INFO     Training average loss at step 21000: 0.449945\n",
      "2022-11-02 12:27:51,273 INFO     Training average positive_sample_loss at step 21100: 0.420982\n",
      "2022-11-02 12:27:51,273 INFO     Training average negative_sample_loss at step 21100: 0.476141\n",
      "2022-11-02 12:27:51,273 INFO     Training average loss at step 21100: 0.448562\n",
      "2022-11-02 12:27:53,820 INFO     Training average positive_sample_loss at step 21200: 0.412240\n",
      "2022-11-02 12:27:53,820 INFO     Training average negative_sample_loss at step 21200: 0.479933\n",
      "2022-11-02 12:27:53,821 INFO     Training average loss at step 21200: 0.446087\n",
      "2022-11-02 12:27:56,384 INFO     Training average positive_sample_loss at step 21300: 0.408483\n",
      "2022-11-02 12:27:56,384 INFO     Training average negative_sample_loss at step 21300: 0.480004\n",
      "2022-11-02 12:27:56,384 INFO     Training average loss at step 21300: 0.444244\n",
      "2022-11-02 12:27:58,949 INFO     Training average positive_sample_loss at step 21400: 0.406799\n",
      "2022-11-02 12:27:58,949 INFO     Training average negative_sample_loss at step 21400: 0.480281\n",
      "2022-11-02 12:27:58,949 INFO     Training average loss at step 21400: 0.443540\n",
      "2022-11-02 12:28:01,486 INFO     Training average positive_sample_loss at step 21500: 0.406100\n",
      "2022-11-02 12:28:01,486 INFO     Training average negative_sample_loss at step 21500: 0.467667\n",
      "2022-11-02 12:28:01,486 INFO     Training average loss at step 21500: 0.436884\n",
      "2022-11-02 12:28:04,020 INFO     Training average positive_sample_loss at step 21600: 0.408581\n",
      "2022-11-02 12:28:04,020 INFO     Training average negative_sample_loss at step 21600: 0.476915\n",
      "2022-11-02 12:28:04,020 INFO     Training average loss at step 21600: 0.442748\n",
      "2022-11-02 12:28:06,560 INFO     Training average positive_sample_loss at step 21700: 0.420534\n",
      "2022-11-02 12:28:06,560 INFO     Training average negative_sample_loss at step 21700: 0.479959\n",
      "2022-11-02 12:28:06,560 INFO     Training average loss at step 21700: 0.450246\n",
      "2022-11-02 12:28:09,096 INFO     Training average positive_sample_loss at step 21800: 0.407274\n",
      "2022-11-02 12:28:09,096 INFO     Training average negative_sample_loss at step 21800: 0.472860\n",
      "2022-11-02 12:28:09,096 INFO     Training average loss at step 21800: 0.440067\n",
      "2022-11-02 12:28:11,624 INFO     Training average positive_sample_loss at step 21900: 0.418205\n",
      "2022-11-02 12:28:11,625 INFO     Training average negative_sample_loss at step 21900: 0.474198\n",
      "2022-11-02 12:28:11,625 INFO     Training average loss at step 21900: 0.446202\n",
      "2022-11-02 12:28:14,163 INFO     Training average positive_sample_loss at step 22000: 0.406159\n",
      "2022-11-02 12:28:14,163 INFO     Training average negative_sample_loss at step 22000: 0.477047\n",
      "2022-11-02 12:28:14,163 INFO     Training average loss at step 22000: 0.441603\n",
      "2022-11-02 12:28:16,697 INFO     Training average positive_sample_loss at step 22100: 0.406006\n",
      "2022-11-02 12:28:16,697 INFO     Training average negative_sample_loss at step 22100: 0.474286\n",
      "2022-11-02 12:28:16,698 INFO     Training average loss at step 22100: 0.440146\n",
      "2022-11-02 12:28:19,232 INFO     Training average positive_sample_loss at step 22200: 0.397938\n",
      "2022-11-02 12:28:19,232 INFO     Training average negative_sample_loss at step 22200: 0.474985\n",
      "2022-11-02 12:28:19,232 INFO     Training average loss at step 22200: 0.436462\n",
      "2022-11-02 12:28:21,772 INFO     Training average positive_sample_loss at step 22300: 0.410614\n",
      "2022-11-02 12:28:21,773 INFO     Training average negative_sample_loss at step 22300: 0.466621\n",
      "2022-11-02 12:28:21,773 INFO     Training average loss at step 22300: 0.438618\n",
      "2022-11-02 12:28:24,240 INFO     Training average positive_sample_loss at step 22400: 0.408579\n",
      "2022-11-02 12:28:24,241 INFO     Training average negative_sample_loss at step 22400: 0.469108\n",
      "2022-11-02 12:28:24,241 INFO     Training average loss at step 22400: 0.438843\n",
      "2022-11-02 12:28:25,932 INFO     Training average positive_sample_loss at step 22500: 0.397111\n",
      "2022-11-02 12:28:25,932 INFO     Training average negative_sample_loss at step 22500: 0.472993\n",
      "2022-11-02 12:28:25,932 INFO     Training average loss at step 22500: 0.435052\n",
      "2022-11-02 12:28:28,466 INFO     Training average positive_sample_loss at step 22600: 0.413192\n",
      "2022-11-02 12:28:28,466 INFO     Training average negative_sample_loss at step 22600: 0.466008\n",
      "2022-11-02 12:28:28,466 INFO     Training average loss at step 22600: 0.439600\n",
      "2022-11-02 12:28:30,359 INFO     Training average positive_sample_loss at step 22700: 0.402823\n",
      "2022-11-02 12:28:30,359 INFO     Training average negative_sample_loss at step 22700: 0.469309\n",
      "2022-11-02 12:28:30,359 INFO     Training average loss at step 22700: 0.436066\n",
      "2022-11-02 12:28:32,048 INFO     Training average positive_sample_loss at step 22800: 0.402690\n",
      "2022-11-02 12:28:32,048 INFO     Training average negative_sample_loss at step 22800: 0.470108\n",
      "2022-11-02 12:28:32,048 INFO     Training average loss at step 22800: 0.436399\n",
      "2022-11-02 12:28:34,443 INFO     Training average positive_sample_loss at step 22900: 0.405375\n",
      "2022-11-02 12:28:34,443 INFO     Training average negative_sample_loss at step 22900: 0.469750\n",
      "2022-11-02 12:28:34,443 INFO     Training average loss at step 22900: 0.437563\n",
      "2022-11-02 12:28:36,733 INFO     Training average positive_sample_loss at step 23000: 0.404818\n",
      "2022-11-02 12:28:36,733 INFO     Training average negative_sample_loss at step 23000: 0.464010\n",
      "2022-11-02 12:28:36,733 INFO     Training average loss at step 23000: 0.434414\n",
      "2022-11-02 12:28:38,743 INFO     Training average positive_sample_loss at step 23100: 0.398788\n",
      "2022-11-02 12:28:38,743 INFO     Training average negative_sample_loss at step 23100: 0.466640\n",
      "2022-11-02 12:28:38,743 INFO     Training average loss at step 23100: 0.432714\n",
      "2022-11-02 12:28:41,272 INFO     Training average positive_sample_loss at step 23200: 0.400040\n",
      "2022-11-02 12:28:41,272 INFO     Training average negative_sample_loss at step 23200: 0.472653\n",
      "2022-11-02 12:28:41,272 INFO     Training average loss at step 23200: 0.436346\n",
      "2022-11-02 12:28:43,801 INFO     Training average positive_sample_loss at step 23300: 0.401069\n",
      "2022-11-02 12:28:43,801 INFO     Training average negative_sample_loss at step 23300: 0.471795\n",
      "2022-11-02 12:28:43,801 INFO     Training average loss at step 23300: 0.436432\n",
      "2022-11-02 12:28:46,350 INFO     Training average positive_sample_loss at step 23400: 0.408545\n",
      "2022-11-02 12:28:46,350 INFO     Training average negative_sample_loss at step 23400: 0.464067\n",
      "2022-11-02 12:28:46,350 INFO     Training average loss at step 23400: 0.436306\n",
      "2022-11-02 12:28:48,901 INFO     Training average positive_sample_loss at step 23500: 0.401498\n",
      "2022-11-02 12:28:48,901 INFO     Training average negative_sample_loss at step 23500: 0.467307\n",
      "2022-11-02 12:28:48,901 INFO     Training average loss at step 23500: 0.434403\n",
      "2022-11-02 12:28:51,447 INFO     Training average positive_sample_loss at step 23600: 0.404083\n",
      "2022-11-02 12:28:51,447 INFO     Training average negative_sample_loss at step 23600: 0.466275\n",
      "2022-11-02 12:28:51,447 INFO     Training average loss at step 23600: 0.435179\n",
      "2022-11-02 12:28:53,992 INFO     Training average positive_sample_loss at step 23700: 0.410717\n",
      "2022-11-02 12:28:53,992 INFO     Training average negative_sample_loss at step 23700: 0.460544\n",
      "2022-11-02 12:28:53,992 INFO     Training average loss at step 23700: 0.435630\n",
      "2022-11-02 12:28:56,533 INFO     Training average positive_sample_loss at step 23800: 0.390011\n",
      "2022-11-02 12:28:56,533 INFO     Training average negative_sample_loss at step 23800: 0.464822\n",
      "2022-11-02 12:28:56,533 INFO     Training average loss at step 23800: 0.427416\n",
      "2022-11-02 12:28:59,065 INFO     Training average positive_sample_loss at step 23900: 0.400325\n",
      "2022-11-02 12:28:59,065 INFO     Training average negative_sample_loss at step 23900: 0.460498\n",
      "2022-11-02 12:28:59,065 INFO     Training average loss at step 23900: 0.430411\n",
      "2022-11-02 12:29:01,627 INFO     Training average positive_sample_loss at step 24000: 0.402171\n",
      "2022-11-02 12:29:01,627 INFO     Training average negative_sample_loss at step 24000: 0.457731\n",
      "2022-11-02 12:29:01,627 INFO     Training average loss at step 24000: 0.429951\n",
      "2022-11-02 12:29:04,171 INFO     Training average positive_sample_loss at step 24100: 0.412513\n",
      "2022-11-02 12:29:04,171 INFO     Training average negative_sample_loss at step 24100: 0.455170\n",
      "2022-11-02 12:29:04,171 INFO     Training average loss at step 24100: 0.433841\n",
      "2022-11-02 12:29:06,716 INFO     Training average positive_sample_loss at step 24200: 0.405020\n",
      "2022-11-02 12:29:06,716 INFO     Training average negative_sample_loss at step 24200: 0.460817\n",
      "2022-11-02 12:29:06,716 INFO     Training average loss at step 24200: 0.432918\n",
      "2022-11-02 12:29:09,276 INFO     Training average positive_sample_loss at step 24300: 0.394606\n",
      "2022-11-02 12:29:09,276 INFO     Training average negative_sample_loss at step 24300: 0.465197\n",
      "2022-11-02 12:29:09,276 INFO     Training average loss at step 24300: 0.429902\n",
      "2022-11-02 12:29:11,812 INFO     Training average positive_sample_loss at step 24400: 0.392139\n",
      "2022-11-02 12:29:11,812 INFO     Training average negative_sample_loss at step 24400: 0.464721\n",
      "2022-11-02 12:29:11,812 INFO     Training average loss at step 24400: 0.428430\n",
      "2022-11-02 12:29:14,342 INFO     Training average positive_sample_loss at step 24500: 0.396735\n",
      "2022-11-02 12:29:14,342 INFO     Training average negative_sample_loss at step 24500: 0.462851\n",
      "2022-11-02 12:29:14,342 INFO     Training average loss at step 24500: 0.429793\n",
      "2022-11-02 12:29:16,894 INFO     Training average positive_sample_loss at step 24600: 0.392108\n",
      "2022-11-02 12:29:16,895 INFO     Training average negative_sample_loss at step 24600: 0.454586\n",
      "2022-11-02 12:29:16,895 INFO     Training average loss at step 24600: 0.423347\n",
      "2022-11-02 12:29:19,454 INFO     Training average positive_sample_loss at step 24700: 0.417610\n",
      "2022-11-02 12:29:19,454 INFO     Training average negative_sample_loss at step 24700: 0.458286\n",
      "2022-11-02 12:29:19,455 INFO     Training average loss at step 24700: 0.437948\n",
      "2022-11-02 12:29:21,990 INFO     Training average positive_sample_loss at step 24800: 0.403133\n",
      "2022-11-02 12:29:21,990 INFO     Training average negative_sample_loss at step 24800: 0.465233\n",
      "2022-11-02 12:29:21,990 INFO     Training average loss at step 24800: 0.434183\n",
      "2022-11-02 12:29:24,545 INFO     Training average positive_sample_loss at step 24900: 0.393599\n",
      "2022-11-02 12:29:24,545 INFO     Training average negative_sample_loss at step 24900: 0.460003\n",
      "2022-11-02 12:29:24,545 INFO     Training average loss at step 24900: 0.426801\n",
      "2022-11-02 12:29:27,121 INFO     Training average positive_sample_loss at step 25000: 0.391097\n",
      "2022-11-02 12:29:27,121 INFO     Training average negative_sample_loss at step 25000: 0.459142\n",
      "2022-11-02 12:29:27,121 INFO     Training average loss at step 25000: 0.425119\n",
      "2022-11-02 12:29:29,653 INFO     Training average positive_sample_loss at step 25100: 0.394675\n",
      "2022-11-02 12:29:29,654 INFO     Training average negative_sample_loss at step 25100: 0.455013\n",
      "2022-11-02 12:29:29,654 INFO     Training average loss at step 25100: 0.424844\n",
      "2022-11-02 12:29:32,183 INFO     Training average positive_sample_loss at step 25200: 0.395559\n",
      "2022-11-02 12:29:32,184 INFO     Training average negative_sample_loss at step 25200: 0.456872\n",
      "2022-11-02 12:29:32,184 INFO     Training average loss at step 25200: 0.426215\n",
      "2022-11-02 12:29:34,714 INFO     Training average positive_sample_loss at step 25300: 0.408337\n",
      "2022-11-02 12:29:34,714 INFO     Training average negative_sample_loss at step 25300: 0.456426\n",
      "2022-11-02 12:29:34,714 INFO     Training average loss at step 25300: 0.432381\n",
      "2022-11-02 12:29:37,244 INFO     Training average positive_sample_loss at step 25400: 0.384077\n",
      "2022-11-02 12:29:37,244 INFO     Training average negative_sample_loss at step 25400: 0.458971\n",
      "2022-11-02 12:29:37,244 INFO     Training average loss at step 25400: 0.421524\n",
      "2022-11-02 12:29:39,807 INFO     Training average positive_sample_loss at step 25500: 0.388169\n",
      "2022-11-02 12:29:39,807 INFO     Training average negative_sample_loss at step 25500: 0.459347\n",
      "2022-11-02 12:29:39,807 INFO     Training average loss at step 25500: 0.423758\n",
      "2022-11-02 12:29:42,329 INFO     Training average positive_sample_loss at step 25600: 0.391426\n",
      "2022-11-02 12:29:42,329 INFO     Training average negative_sample_loss at step 25600: 0.456164\n",
      "2022-11-02 12:29:42,329 INFO     Training average loss at step 25600: 0.423795\n",
      "2022-11-02 12:29:44,866 INFO     Training average positive_sample_loss at step 25700: 0.393285\n",
      "2022-11-02 12:29:44,866 INFO     Training average negative_sample_loss at step 25700: 0.452225\n",
      "2022-11-02 12:29:44,866 INFO     Training average loss at step 25700: 0.422755\n",
      "2022-11-02 12:29:47,407 INFO     Training average positive_sample_loss at step 25800: 0.395550\n",
      "2022-11-02 12:29:47,407 INFO     Training average negative_sample_loss at step 25800: 0.456997\n",
      "2022-11-02 12:29:47,407 INFO     Training average loss at step 25800: 0.426274\n",
      "2022-11-02 12:29:49,962 INFO     Training average positive_sample_loss at step 25900: 0.388798\n",
      "2022-11-02 12:29:49,963 INFO     Training average negative_sample_loss at step 25900: 0.450216\n",
      "2022-11-02 12:29:49,963 INFO     Training average loss at step 25900: 0.419507\n",
      "2022-11-02 12:29:52,512 INFO     Training average positive_sample_loss at step 26000: 0.395093\n",
      "2022-11-02 12:29:52,512 INFO     Training average negative_sample_loss at step 26000: 0.449477\n",
      "2022-11-02 12:29:52,513 INFO     Training average loss at step 26000: 0.422285\n",
      "2022-11-02 12:29:55,059 INFO     Training average positive_sample_loss at step 26100: 0.398343\n",
      "2022-11-02 12:29:55,059 INFO     Training average negative_sample_loss at step 26100: 0.459075\n",
      "2022-11-02 12:29:55,059 INFO     Training average loss at step 26100: 0.428709\n",
      "2022-11-02 12:29:57,609 INFO     Training average positive_sample_loss at step 26200: 0.388037\n",
      "2022-11-02 12:29:57,609 INFO     Training average negative_sample_loss at step 26200: 0.454013\n",
      "2022-11-02 12:29:57,609 INFO     Training average loss at step 26200: 0.421025\n",
      "2022-11-02 12:30:00,247 INFO     Training average positive_sample_loss at step 26300: 0.385971\n",
      "2022-11-02 12:30:00,248 INFO     Training average negative_sample_loss at step 26300: 0.454815\n",
      "2022-11-02 12:30:00,248 INFO     Training average loss at step 26300: 0.420393\n",
      "2022-11-02 12:30:02,908 INFO     Training average positive_sample_loss at step 26400: 0.389325\n",
      "2022-11-02 12:30:02,908 INFO     Training average negative_sample_loss at step 26400: 0.453782\n",
      "2022-11-02 12:30:02,908 INFO     Training average loss at step 26400: 0.421553\n",
      "2022-11-02 12:30:05,538 INFO     Training average positive_sample_loss at step 26500: 0.386359\n",
      "2022-11-02 12:30:05,538 INFO     Training average negative_sample_loss at step 26500: 0.456236\n",
      "2022-11-02 12:30:05,538 INFO     Training average loss at step 26500: 0.421298\n",
      "2022-11-02 12:30:08,091 INFO     Training average positive_sample_loss at step 26600: 0.395402\n",
      "2022-11-02 12:30:08,091 INFO     Training average negative_sample_loss at step 26600: 0.448885\n",
      "2022-11-02 12:30:08,091 INFO     Training average loss at step 26600: 0.422143\n",
      "2022-11-02 12:30:10,652 INFO     Training average positive_sample_loss at step 26700: 0.391451\n",
      "2022-11-02 12:30:10,652 INFO     Training average negative_sample_loss at step 26700: 0.451095\n",
      "2022-11-02 12:30:10,652 INFO     Training average loss at step 26700: 0.421273\n",
      "2022-11-02 12:30:13,215 INFO     Training average positive_sample_loss at step 26800: 0.399849\n",
      "2022-11-02 12:30:13,215 INFO     Training average negative_sample_loss at step 26800: 0.447866\n",
      "2022-11-02 12:30:13,215 INFO     Training average loss at step 26800: 0.423857\n",
      "2022-11-02 12:30:15,401 INFO     Training average positive_sample_loss at step 26900: 0.391546\n",
      "2022-11-02 12:30:15,401 INFO     Training average negative_sample_loss at step 26900: 0.453195\n",
      "2022-11-02 12:30:15,401 INFO     Training average loss at step 26900: 0.422370\n",
      "2022-11-02 12:30:17,044 INFO     Training average positive_sample_loss at step 27000: 0.383201\n",
      "2022-11-02 12:30:17,044 INFO     Training average negative_sample_loss at step 27000: 0.446781\n",
      "2022-11-02 12:30:17,044 INFO     Training average loss at step 27000: 0.414991\n",
      "2022-11-02 12:30:19,656 INFO     Training average positive_sample_loss at step 27100: 0.378428\n",
      "2022-11-02 12:30:19,656 INFO     Training average negative_sample_loss at step 27100: 0.452130\n",
      "2022-11-02 12:30:19,656 INFO     Training average loss at step 27100: 0.415279\n",
      "2022-11-02 12:30:22,210 INFO     Training average positive_sample_loss at step 27200: 0.390246\n",
      "2022-11-02 12:30:22,210 INFO     Training average negative_sample_loss at step 27200: 0.445989\n",
      "2022-11-02 12:30:22,210 INFO     Training average loss at step 27200: 0.418118\n",
      "2022-11-02 12:30:24,787 INFO     Training average positive_sample_loss at step 27300: 0.400797\n",
      "2022-11-02 12:30:24,787 INFO     Training average negative_sample_loss at step 27300: 0.452646\n",
      "2022-11-02 12:30:24,787 INFO     Training average loss at step 27300: 0.426722\n",
      "2022-11-02 12:30:27,359 INFO     Training average positive_sample_loss at step 27400: 0.394722\n",
      "2022-11-02 12:30:27,359 INFO     Training average negative_sample_loss at step 27400: 0.449478\n",
      "2022-11-02 12:30:27,359 INFO     Training average loss at step 27400: 0.422100\n",
      "2022-11-02 12:30:29,904 INFO     Training average positive_sample_loss at step 27500: 0.390989\n",
      "2022-11-02 12:30:29,905 INFO     Training average negative_sample_loss at step 27500: 0.439182\n",
      "2022-11-02 12:30:29,905 INFO     Training average loss at step 27500: 0.415085\n",
      "2022-11-02 12:30:32,469 INFO     Training average positive_sample_loss at step 27600: 0.387235\n",
      "2022-11-02 12:30:32,469 INFO     Training average negative_sample_loss at step 27600: 0.446953\n",
      "2022-11-02 12:30:32,469 INFO     Training average loss at step 27600: 0.417094\n",
      "2022-11-02 12:30:35,040 INFO     Training average positive_sample_loss at step 27700: 0.380286\n",
      "2022-11-02 12:30:35,040 INFO     Training average negative_sample_loss at step 27700: 0.450271\n",
      "2022-11-02 12:30:35,040 INFO     Training average loss at step 27700: 0.415279\n",
      "2022-11-02 12:30:37,604 INFO     Training average positive_sample_loss at step 27800: 0.389389\n",
      "2022-11-02 12:30:37,605 INFO     Training average negative_sample_loss at step 27800: 0.444769\n",
      "2022-11-02 12:30:37,605 INFO     Training average loss at step 27800: 0.417079\n",
      "2022-11-02 12:30:40,153 INFO     Training average positive_sample_loss at step 27900: 0.392273\n",
      "2022-11-02 12:30:40,153 INFO     Training average negative_sample_loss at step 27900: 0.447000\n",
      "2022-11-02 12:30:40,153 INFO     Training average loss at step 27900: 0.419637\n",
      "2022-11-02 12:30:42,714 INFO     Training average positive_sample_loss at step 28000: 0.379728\n",
      "2022-11-02 12:30:42,714 INFO     Training average negative_sample_loss at step 28000: 0.447448\n",
      "2022-11-02 12:30:42,714 INFO     Training average loss at step 28000: 0.413588\n",
      "2022-11-02 12:30:45,260 INFO     Training average positive_sample_loss at step 28100: 0.387883\n",
      "2022-11-02 12:30:45,261 INFO     Training average negative_sample_loss at step 28100: 0.440084\n",
      "2022-11-02 12:30:45,261 INFO     Training average loss at step 28100: 0.413984\n",
      "2022-11-02 12:30:47,813 INFO     Training average positive_sample_loss at step 28200: 0.384704\n",
      "2022-11-02 12:30:47,813 INFO     Training average negative_sample_loss at step 28200: 0.447133\n",
      "2022-11-02 12:30:47,813 INFO     Training average loss at step 28200: 0.415919\n",
      "2022-11-02 12:30:50,467 INFO     Training average positive_sample_loss at step 28300: 0.397886\n",
      "2022-11-02 12:30:50,467 INFO     Training average negative_sample_loss at step 28300: 0.444409\n",
      "2022-11-02 12:30:50,467 INFO     Training average loss at step 28300: 0.421147\n",
      "2022-11-02 12:30:53,135 INFO     Training average positive_sample_loss at step 28400: 0.380816\n",
      "2022-11-02 12:30:53,135 INFO     Training average negative_sample_loss at step 28400: 0.447301\n",
      "2022-11-02 12:30:53,135 INFO     Training average loss at step 28400: 0.414059\n",
      "2022-11-02 12:30:55,800 INFO     Training average positive_sample_loss at step 28500: 0.389606\n",
      "2022-11-02 12:30:55,800 INFO     Training average negative_sample_loss at step 28500: 0.441282\n",
      "2022-11-02 12:30:55,800 INFO     Training average loss at step 28500: 0.415444\n",
      "2022-11-02 12:30:58,409 INFO     Training average positive_sample_loss at step 28600: 0.387995\n",
      "2022-11-02 12:30:58,409 INFO     Training average negative_sample_loss at step 28600: 0.441087\n",
      "2022-11-02 12:30:58,409 INFO     Training average loss at step 28600: 0.414541\n",
      "2022-11-02 12:31:00,977 INFO     Training average positive_sample_loss at step 28700: 0.381291\n",
      "2022-11-02 12:31:00,977 INFO     Training average negative_sample_loss at step 28700: 0.441464\n",
      "2022-11-02 12:31:00,977 INFO     Training average loss at step 28700: 0.411378\n",
      "2022-11-02 12:31:03,510 INFO     Training average positive_sample_loss at step 28800: 0.386042\n",
      "2022-11-02 12:31:03,511 INFO     Training average negative_sample_loss at step 28800: 0.441804\n",
      "2022-11-02 12:31:03,511 INFO     Training average loss at step 28800: 0.413923\n",
      "2022-11-02 12:31:06,056 INFO     Training average positive_sample_loss at step 28900: 0.393836\n",
      "2022-11-02 12:31:06,057 INFO     Training average negative_sample_loss at step 28900: 0.447209\n",
      "2022-11-02 12:31:06,057 INFO     Training average loss at step 28900: 0.420523\n",
      "2022-11-02 12:31:08,627 INFO     Training average positive_sample_loss at step 29000: 0.392595\n",
      "2022-11-02 12:31:08,627 INFO     Training average negative_sample_loss at step 29000: 0.441875\n",
      "2022-11-02 12:31:08,627 INFO     Training average loss at step 29000: 0.417235\n",
      "2022-11-02 12:31:11,172 INFO     Training average positive_sample_loss at step 29100: 0.377200\n",
      "2022-11-02 12:31:11,172 INFO     Training average negative_sample_loss at step 29100: 0.438480\n",
      "2022-11-02 12:31:11,172 INFO     Training average loss at step 29100: 0.407840\n",
      "2022-11-02 12:31:13,703 INFO     Training average positive_sample_loss at step 29200: 0.392887\n",
      "2022-11-02 12:31:13,704 INFO     Training average negative_sample_loss at step 29200: 0.442159\n",
      "2022-11-02 12:31:13,704 INFO     Training average loss at step 29200: 0.417523\n",
      "2022-11-02 12:31:16,229 INFO     Training average positive_sample_loss at step 29300: 0.381334\n",
      "2022-11-02 12:31:16,229 INFO     Training average negative_sample_loss at step 29300: 0.436943\n",
      "2022-11-02 12:31:16,229 INFO     Training average loss at step 29300: 0.409138\n",
      "2022-11-02 12:31:18,753 INFO     Training average positive_sample_loss at step 29400: 0.380162\n",
      "2022-11-02 12:31:18,754 INFO     Training average negative_sample_loss at step 29400: 0.440644\n",
      "2022-11-02 12:31:18,754 INFO     Training average loss at step 29400: 0.410403\n",
      "2022-11-02 12:31:21,307 INFO     Training average positive_sample_loss at step 29500: 0.382244\n",
      "2022-11-02 12:31:21,307 INFO     Training average negative_sample_loss at step 29500: 0.437815\n",
      "2022-11-02 12:31:21,307 INFO     Training average loss at step 29500: 0.410030\n",
      "2022-11-02 12:31:23,857 INFO     Training average positive_sample_loss at step 29600: 0.378042\n",
      "2022-11-02 12:31:23,857 INFO     Training average negative_sample_loss at step 29600: 0.437581\n",
      "2022-11-02 12:31:23,857 INFO     Training average loss at step 29600: 0.407811\n",
      "2022-11-02 12:31:26,426 INFO     Training average positive_sample_loss at step 29700: 0.387108\n",
      "2022-11-02 12:31:26,426 INFO     Training average negative_sample_loss at step 29700: 0.437573\n",
      "2022-11-02 12:31:26,426 INFO     Training average loss at step 29700: 0.412341\n",
      "2022-11-02 12:31:28,286 INFO     Training average positive_sample_loss at step 29800: 0.382651\n",
      "2022-11-02 12:31:28,286 INFO     Training average negative_sample_loss at step 29800: 0.440657\n",
      "2022-11-02 12:31:28,286 INFO     Training average loss at step 29800: 0.411654\n",
      "2022-11-02 12:31:30,695 INFO     Training average positive_sample_loss at step 29900: 0.376253\n",
      "2022-11-02 12:31:30,695 INFO     Training average negative_sample_loss at step 29900: 0.428394\n",
      "2022-11-02 12:31:30,695 INFO     Training average loss at step 29900: 0.402324\n",
      "2022-11-02 12:31:34,429 INFO     Training average positive_sample_loss at step 30000: 0.382359\n",
      "2022-11-02 12:31:34,429 INFO     Training average negative_sample_loss at step 30000: 0.440731\n",
      "2022-11-02 12:31:34,429 INFO     Training average loss at step 30000: 0.411545\n",
      "2022-11-02 12:31:36,149 INFO     Training average positive_sample_loss at step 30100: 0.379378\n",
      "2022-11-02 12:31:36,149 INFO     Training average negative_sample_loss at step 30100: 0.440879\n",
      "2022-11-02 12:31:36,149 INFO     Training average loss at step 30100: 0.410128\n",
      "2022-11-02 12:31:38,705 INFO     Training average positive_sample_loss at step 30200: 0.381263\n",
      "2022-11-02 12:31:38,705 INFO     Training average negative_sample_loss at step 30200: 0.433235\n",
      "2022-11-02 12:31:38,705 INFO     Training average loss at step 30200: 0.407249\n",
      "2022-11-02 12:31:40,668 INFO     Training average positive_sample_loss at step 30300: 0.377662\n",
      "2022-11-02 12:31:40,668 INFO     Training average negative_sample_loss at step 30300: 0.432806\n",
      "2022-11-02 12:31:40,668 INFO     Training average loss at step 30300: 0.405234\n",
      "2022-11-02 12:31:42,989 INFO     Training average positive_sample_loss at step 30400: 0.380874\n",
      "2022-11-02 12:31:42,990 INFO     Training average negative_sample_loss at step 30400: 0.437897\n",
      "2022-11-02 12:31:42,990 INFO     Training average loss at step 30400: 0.409386\n",
      "2022-11-02 12:31:45,550 INFO     Training average positive_sample_loss at step 30500: 0.375104\n",
      "2022-11-02 12:31:45,550 INFO     Training average negative_sample_loss at step 30500: 0.438069\n",
      "2022-11-02 12:31:45,550 INFO     Training average loss at step 30500: 0.406586\n",
      "2022-11-02 12:31:48,114 INFO     Training average positive_sample_loss at step 30600: 0.384979\n",
      "2022-11-02 12:31:48,114 INFO     Training average negative_sample_loss at step 30600: 0.433673\n",
      "2022-11-02 12:31:48,114 INFO     Training average loss at step 30600: 0.409326\n",
      "2022-11-02 12:31:50,739 INFO     Training average positive_sample_loss at step 30700: 0.391209\n",
      "2022-11-02 12:31:50,739 INFO     Training average negative_sample_loss at step 30700: 0.437085\n",
      "2022-11-02 12:31:50,739 INFO     Training average loss at step 30700: 0.414147\n",
      "2022-11-02 12:31:53,331 INFO     Training average positive_sample_loss at step 30800: 0.376760\n",
      "2022-11-02 12:31:53,331 INFO     Training average negative_sample_loss at step 30800: 0.440266\n",
      "2022-11-02 12:31:53,331 INFO     Training average loss at step 30800: 0.408513\n",
      "2022-11-02 12:31:55,903 INFO     Training average positive_sample_loss at step 30900: 0.391708\n",
      "2022-11-02 12:31:55,903 INFO     Training average negative_sample_loss at step 30900: 0.436209\n",
      "2022-11-02 12:31:55,903 INFO     Training average loss at step 30900: 0.413959\n",
      "2022-11-02 12:31:58,467 INFO     Training average positive_sample_loss at step 31000: 0.384985\n",
      "2022-11-02 12:31:58,467 INFO     Training average negative_sample_loss at step 31000: 0.431281\n",
      "2022-11-02 12:31:58,467 INFO     Training average loss at step 31000: 0.408133\n",
      "2022-11-02 12:32:01,046 INFO     Training average positive_sample_loss at step 31100: 0.370992\n",
      "2022-11-02 12:32:01,046 INFO     Training average negative_sample_loss at step 31100: 0.437616\n",
      "2022-11-02 12:32:01,046 INFO     Training average loss at step 31100: 0.404304\n",
      "2022-11-02 12:32:03,601 INFO     Training average positive_sample_loss at step 31200: 0.374188\n",
      "2022-11-02 12:32:03,601 INFO     Training average negative_sample_loss at step 31200: 0.437877\n",
      "2022-11-02 12:32:03,601 INFO     Training average loss at step 31200: 0.406032\n",
      "2022-11-02 12:32:06,175 INFO     Training average positive_sample_loss at step 31300: 0.379202\n",
      "2022-11-02 12:32:06,175 INFO     Training average negative_sample_loss at step 31300: 0.428199\n",
      "2022-11-02 12:32:06,175 INFO     Training average loss at step 31300: 0.403700\n",
      "2022-11-02 12:32:08,815 INFO     Training average positive_sample_loss at step 31400: 0.387345\n",
      "2022-11-02 12:32:08,816 INFO     Training average negative_sample_loss at step 31400: 0.424148\n",
      "2022-11-02 12:32:08,816 INFO     Training average loss at step 31400: 0.405746\n",
      "2022-11-02 12:32:11,434 INFO     Training average positive_sample_loss at step 31500: 0.387455\n",
      "2022-11-02 12:32:11,434 INFO     Training average negative_sample_loss at step 31500: 0.430088\n",
      "2022-11-02 12:32:11,434 INFO     Training average loss at step 31500: 0.408772\n",
      "2022-11-02 12:32:14,020 INFO     Training average positive_sample_loss at step 31600: 0.385457\n",
      "2022-11-02 12:32:14,020 INFO     Training average negative_sample_loss at step 31600: 0.436212\n",
      "2022-11-02 12:32:14,020 INFO     Training average loss at step 31600: 0.410834\n",
      "2022-11-02 12:32:16,604 INFO     Training average positive_sample_loss at step 31700: 0.365745\n",
      "2022-11-02 12:32:16,604 INFO     Training average negative_sample_loss at step 31700: 0.428934\n",
      "2022-11-02 12:32:16,604 INFO     Training average loss at step 31700: 0.397339\n",
      "2022-11-02 12:32:19,197 INFO     Training average positive_sample_loss at step 31800: 0.380166\n",
      "2022-11-02 12:32:19,197 INFO     Training average negative_sample_loss at step 31800: 0.430928\n",
      "2022-11-02 12:32:19,197 INFO     Training average loss at step 31800: 0.405547\n",
      "2022-11-02 12:32:21,744 INFO     Training average positive_sample_loss at step 31900: 0.388340\n",
      "2022-11-02 12:32:21,744 INFO     Training average negative_sample_loss at step 31900: 0.433817\n",
      "2022-11-02 12:32:21,744 INFO     Training average loss at step 31900: 0.411079\n",
      "2022-11-02 12:32:24,354 INFO     Training average positive_sample_loss at step 32000: 0.371742\n",
      "2022-11-02 12:32:24,354 INFO     Training average negative_sample_loss at step 32000: 0.427372\n",
      "2022-11-02 12:32:24,355 INFO     Training average loss at step 32000: 0.399557\n",
      "2022-11-02 12:32:26,954 INFO     Training average positive_sample_loss at step 32100: 0.370344\n",
      "2022-11-02 12:32:26,954 INFO     Training average negative_sample_loss at step 32100: 0.429101\n",
      "2022-11-02 12:32:26,954 INFO     Training average loss at step 32100: 0.399723\n",
      "2022-11-02 12:32:29,529 INFO     Training average positive_sample_loss at step 32200: 0.368195\n",
      "2022-11-02 12:32:29,529 INFO     Training average negative_sample_loss at step 32200: 0.429597\n",
      "2022-11-02 12:32:29,529 INFO     Training average loss at step 32200: 0.398896\n",
      "2022-11-02 12:32:32,094 INFO     Training average positive_sample_loss at step 32300: 0.371578\n",
      "2022-11-02 12:32:32,094 INFO     Training average negative_sample_loss at step 32300: 0.434208\n",
      "2022-11-02 12:32:32,094 INFO     Training average loss at step 32300: 0.402893\n",
      "2022-11-02 12:32:34,658 INFO     Training average positive_sample_loss at step 32400: 0.369305\n",
      "2022-11-02 12:32:34,658 INFO     Training average negative_sample_loss at step 32400: 0.424751\n",
      "2022-11-02 12:32:34,658 INFO     Training average loss at step 32400: 0.397028\n",
      "2022-11-02 12:32:37,239 INFO     Training average positive_sample_loss at step 32500: 0.374906\n",
      "2022-11-02 12:32:37,239 INFO     Training average negative_sample_loss at step 32500: 0.433004\n",
      "2022-11-02 12:32:37,239 INFO     Training average loss at step 32500: 0.403955\n",
      "2022-11-02 12:32:39,807 INFO     Training average positive_sample_loss at step 32600: 0.370686\n",
      "2022-11-02 12:32:39,807 INFO     Training average negative_sample_loss at step 32600: 0.428018\n",
      "2022-11-02 12:32:39,808 INFO     Training average loss at step 32600: 0.399352\n",
      "2022-11-02 12:32:42,358 INFO     Training average positive_sample_loss at step 32700: 0.377391\n",
      "2022-11-02 12:32:42,358 INFO     Training average negative_sample_loss at step 32700: 0.425256\n",
      "2022-11-02 12:32:42,358 INFO     Training average loss at step 32700: 0.401324\n",
      "2022-11-02 12:32:44,909 INFO     Training average positive_sample_loss at step 32800: 0.371870\n",
      "2022-11-02 12:32:44,909 INFO     Training average negative_sample_loss at step 32800: 0.427841\n",
      "2022-11-02 12:32:44,909 INFO     Training average loss at step 32800: 0.399855\n",
      "2022-11-02 12:32:47,470 INFO     Training average positive_sample_loss at step 32900: 0.363815\n",
      "2022-11-02 12:32:47,470 INFO     Training average negative_sample_loss at step 32900: 0.427436\n",
      "2022-11-02 12:32:47,470 INFO     Training average loss at step 32900: 0.395625\n",
      "2022-11-02 12:32:50,002 INFO     Training average positive_sample_loss at step 33000: 0.360638\n",
      "2022-11-02 12:32:50,002 INFO     Training average negative_sample_loss at step 33000: 0.425893\n",
      "2022-11-02 12:32:50,002 INFO     Training average loss at step 33000: 0.393266\n",
      "2022-11-02 12:32:52,567 INFO     Training average positive_sample_loss at step 33100: 0.373073\n",
      "2022-11-02 12:32:52,568 INFO     Training average negative_sample_loss at step 33100: 0.410879\n",
      "2022-11-02 12:32:52,568 INFO     Training average loss at step 33100: 0.391976\n",
      "2022-11-02 12:32:55,153 INFO     Training average positive_sample_loss at step 33200: 0.380519\n",
      "2022-11-02 12:32:55,153 INFO     Training average negative_sample_loss at step 33200: 0.428322\n",
      "2022-11-02 12:32:55,153 INFO     Training average loss at step 33200: 0.404421\n",
      "2022-11-02 12:32:57,711 INFO     Training average positive_sample_loss at step 33300: 0.366324\n",
      "2022-11-02 12:32:57,711 INFO     Training average negative_sample_loss at step 33300: 0.426015\n",
      "2022-11-02 12:32:57,711 INFO     Training average loss at step 33300: 0.396170\n",
      "2022-11-02 12:33:00,275 INFO     Training average positive_sample_loss at step 33400: 0.386799\n",
      "2022-11-02 12:33:00,275 INFO     Training average negative_sample_loss at step 33400: 0.424622\n",
      "2022-11-02 12:33:00,275 INFO     Training average loss at step 33400: 0.405711\n",
      "2022-11-02 12:33:02,852 INFO     Training average positive_sample_loss at step 33500: 0.381373\n",
      "2022-11-02 12:33:02,852 INFO     Training average negative_sample_loss at step 33500: 0.422321\n",
      "2022-11-02 12:33:02,852 INFO     Training average loss at step 33500: 0.401847\n",
      "2022-11-02 12:33:05,396 INFO     Training average positive_sample_loss at step 33600: 0.377080\n",
      "2022-11-02 12:33:05,396 INFO     Training average negative_sample_loss at step 33600: 0.428024\n",
      "2022-11-02 12:33:05,396 INFO     Training average loss at step 33600: 0.402552\n",
      "2022-11-02 12:33:07,970 INFO     Training average positive_sample_loss at step 33700: 0.369541\n",
      "2022-11-02 12:33:07,971 INFO     Training average negative_sample_loss at step 33700: 0.423458\n",
      "2022-11-02 12:33:07,971 INFO     Training average loss at step 33700: 0.396499\n",
      "2022-11-02 12:33:10,562 INFO     Training average positive_sample_loss at step 33800: 0.368658\n",
      "2022-11-02 12:33:10,562 INFO     Training average negative_sample_loss at step 33800: 0.420104\n",
      "2022-11-02 12:33:10,562 INFO     Training average loss at step 33800: 0.394381\n",
      "2022-11-02 12:33:13,127 INFO     Training average positive_sample_loss at step 33900: 0.376591\n",
      "2022-11-02 12:33:13,128 INFO     Training average negative_sample_loss at step 33900: 0.424272\n",
      "2022-11-02 12:33:13,128 INFO     Training average loss at step 33900: 0.400431\n",
      "2022-11-02 12:33:15,687 INFO     Training average positive_sample_loss at step 34000: 0.371382\n",
      "2022-11-02 12:33:15,687 INFO     Training average negative_sample_loss at step 34000: 0.425191\n",
      "2022-11-02 12:33:15,687 INFO     Training average loss at step 34000: 0.398286\n",
      "2022-11-02 12:33:18,255 INFO     Training average positive_sample_loss at step 34100: 0.374391\n",
      "2022-11-02 12:33:18,255 INFO     Training average negative_sample_loss at step 34100: 0.431285\n",
      "2022-11-02 12:33:18,255 INFO     Training average loss at step 34100: 0.402838\n",
      "2022-11-02 12:33:20,815 INFO     Training average positive_sample_loss at step 34200: 0.370969\n",
      "2022-11-02 12:33:20,815 INFO     Training average negative_sample_loss at step 34200: 0.421920\n",
      "2022-11-02 12:33:20,815 INFO     Training average loss at step 34200: 0.396444\n",
      "2022-11-02 12:33:23,412 INFO     Training average positive_sample_loss at step 34300: 0.359672\n",
      "2022-11-02 12:33:23,412 INFO     Training average negative_sample_loss at step 34300: 0.419567\n",
      "2022-11-02 12:33:23,412 INFO     Training average loss at step 34300: 0.389619\n",
      "2022-11-02 12:33:26,014 INFO     Training average positive_sample_loss at step 34400: 0.362060\n",
      "2022-11-02 12:33:26,015 INFO     Training average negative_sample_loss at step 34400: 0.422060\n",
      "2022-11-02 12:33:26,015 INFO     Training average loss at step 34400: 0.392060\n",
      "2022-11-02 12:33:28,596 INFO     Training average positive_sample_loss at step 34500: 0.369845\n",
      "2022-11-02 12:33:28,596 INFO     Training average negative_sample_loss at step 34500: 0.416588\n",
      "2022-11-02 12:33:28,596 INFO     Training average loss at step 34500: 0.393216\n",
      "2022-11-02 12:33:31,185 INFO     Training average positive_sample_loss at step 34600: 0.368852\n",
      "2022-11-02 12:33:31,185 INFO     Training average negative_sample_loss at step 34600: 0.420458\n",
      "2022-11-02 12:33:31,185 INFO     Training average loss at step 34600: 0.394655\n",
      "2022-11-02 12:33:33,789 INFO     Training average positive_sample_loss at step 34700: 0.375738\n",
      "2022-11-02 12:33:33,789 INFO     Training average negative_sample_loss at step 34700: 0.421589\n",
      "2022-11-02 12:33:33,789 INFO     Training average loss at step 34700: 0.398664\n",
      "2022-11-02 12:33:36,363 INFO     Training average positive_sample_loss at step 34800: 0.368551\n",
      "2022-11-02 12:33:36,363 INFO     Training average negative_sample_loss at step 34800: 0.417550\n",
      "2022-11-02 12:33:36,363 INFO     Training average loss at step 34800: 0.393050\n",
      "2022-11-02 12:33:38,956 INFO     Training average positive_sample_loss at step 34900: 0.370572\n",
      "2022-11-02 12:33:38,957 INFO     Training average negative_sample_loss at step 34900: 0.425772\n",
      "2022-11-02 12:33:38,957 INFO     Training average loss at step 34900: 0.398172\n",
      "2022-11-02 12:33:41,523 INFO     Training average positive_sample_loss at step 35000: 0.370852\n",
      "2022-11-02 12:33:41,523 INFO     Training average negative_sample_loss at step 35000: 0.415686\n",
      "2022-11-02 12:33:41,523 INFO     Training average loss at step 35000: 0.393269\n",
      "2022-11-02 12:33:44,141 INFO     Training average positive_sample_loss at step 35100: 0.369942\n",
      "2022-11-02 12:33:44,141 INFO     Training average negative_sample_loss at step 35100: 0.422244\n",
      "2022-11-02 12:33:44,141 INFO     Training average loss at step 35100: 0.396093\n",
      "2022-11-02 12:33:46,718 INFO     Training average positive_sample_loss at step 35200: 0.369843\n",
      "2022-11-02 12:33:46,718 INFO     Training average negative_sample_loss at step 35200: 0.422584\n",
      "2022-11-02 12:33:46,718 INFO     Training average loss at step 35200: 0.396214\n",
      "2022-11-02 12:33:49,273 INFO     Training average positive_sample_loss at step 35300: 0.371837\n",
      "2022-11-02 12:33:49,273 INFO     Training average negative_sample_loss at step 35300: 0.421373\n",
      "2022-11-02 12:33:49,273 INFO     Training average loss at step 35300: 0.396605\n",
      "2022-11-02 12:33:51,869 INFO     Training average positive_sample_loss at step 35400: 0.368387\n",
      "2022-11-02 12:33:51,870 INFO     Training average negative_sample_loss at step 35400: 0.418999\n",
      "2022-11-02 12:33:51,870 INFO     Training average loss at step 35400: 0.393693\n",
      "2022-11-02 12:33:54,483 INFO     Training average positive_sample_loss at step 35500: 0.365679\n",
      "2022-11-02 12:33:54,483 INFO     Training average negative_sample_loss at step 35500: 0.420988\n",
      "2022-11-02 12:33:54,483 INFO     Training average loss at step 35500: 0.393334\n",
      "2022-11-02 12:33:57,105 INFO     Training average positive_sample_loss at step 35600: 0.348940\n",
      "2022-11-02 12:33:57,105 INFO     Training average negative_sample_loss at step 35600: 0.421726\n",
      "2022-11-02 12:33:57,105 INFO     Training average loss at step 35600: 0.385333\n",
      "2022-11-02 12:33:59,704 INFO     Training average positive_sample_loss at step 35700: 0.367445\n",
      "2022-11-02 12:33:59,704 INFO     Training average negative_sample_loss at step 35700: 0.413027\n",
      "2022-11-02 12:33:59,704 INFO     Training average loss at step 35700: 0.390236\n",
      "2022-11-02 12:34:02,282 INFO     Training average positive_sample_loss at step 35800: 0.365323\n",
      "2022-11-02 12:34:02,282 INFO     Training average negative_sample_loss at step 35800: 0.418445\n",
      "2022-11-02 12:34:02,282 INFO     Training average loss at step 35800: 0.391884\n",
      "2022-11-02 12:34:04,840 INFO     Training average positive_sample_loss at step 35900: 0.364066\n",
      "2022-11-02 12:34:04,840 INFO     Training average negative_sample_loss at step 35900: 0.418020\n",
      "2022-11-02 12:34:04,840 INFO     Training average loss at step 35900: 0.391043\n",
      "2022-11-02 12:34:07,399 INFO     Training average positive_sample_loss at step 36000: 0.363818\n",
      "2022-11-02 12:34:07,399 INFO     Training average negative_sample_loss at step 36000: 0.412534\n",
      "2022-11-02 12:34:07,399 INFO     Training average loss at step 36000: 0.388176\n",
      "2022-11-02 12:34:09,949 INFO     Training average positive_sample_loss at step 36100: 0.371604\n",
      "2022-11-02 12:34:09,949 INFO     Training average negative_sample_loss at step 36100: 0.413829\n",
      "2022-11-02 12:34:09,949 INFO     Training average loss at step 36100: 0.392716\n",
      "2022-11-02 12:34:12,502 INFO     Training average positive_sample_loss at step 36200: 0.377514\n",
      "2022-11-02 12:34:12,502 INFO     Training average negative_sample_loss at step 36200: 0.410247\n",
      "2022-11-02 12:34:12,502 INFO     Training average loss at step 36200: 0.393880\n",
      "2022-11-02 12:34:15,064 INFO     Training average positive_sample_loss at step 36300: 0.359066\n",
      "2022-11-02 12:34:15,064 INFO     Training average negative_sample_loss at step 36300: 0.415856\n",
      "2022-11-02 12:34:15,064 INFO     Training average loss at step 36300: 0.387461\n",
      "2022-11-02 12:34:17,680 INFO     Training average positive_sample_loss at step 36400: 0.360819\n",
      "2022-11-02 12:34:17,680 INFO     Training average negative_sample_loss at step 36400: 0.423742\n",
      "2022-11-02 12:34:17,680 INFO     Training average loss at step 36400: 0.392281\n",
      "2022-11-02 12:34:20,235 INFO     Training average positive_sample_loss at step 36500: 0.369318\n",
      "2022-11-02 12:34:20,235 INFO     Training average negative_sample_loss at step 36500: 0.412702\n",
      "2022-11-02 12:34:20,235 INFO     Training average loss at step 36500: 0.391010\n",
      "2022-11-02 12:34:22,828 INFO     Training average positive_sample_loss at step 36600: 0.368530\n",
      "2022-11-02 12:34:22,829 INFO     Training average negative_sample_loss at step 36600: 0.417377\n",
      "2022-11-02 12:34:22,829 INFO     Training average loss at step 36600: 0.392953\n",
      "2022-11-02 12:34:25,389 INFO     Training average positive_sample_loss at step 36700: 0.348635\n",
      "2022-11-02 12:34:25,389 INFO     Training average negative_sample_loss at step 36700: 0.412714\n",
      "2022-11-02 12:34:25,389 INFO     Training average loss at step 36700: 0.380675\n",
      "2022-11-02 12:34:27,931 INFO     Training average positive_sample_loss at step 36800: 0.376729\n",
      "2022-11-02 12:34:27,931 INFO     Training average negative_sample_loss at step 36800: 0.410574\n",
      "2022-11-02 12:34:27,931 INFO     Training average loss at step 36800: 0.393651\n",
      "2022-11-02 12:34:30,202 INFO     Training average positive_sample_loss at step 36900: 0.354853\n",
      "2022-11-02 12:34:30,202 INFO     Training average negative_sample_loss at step 36900: 0.408656\n",
      "2022-11-02 12:34:30,202 INFO     Training average loss at step 36900: 0.381755\n",
      "2022-11-02 12:34:32,127 INFO     Training average positive_sample_loss at step 37000: 0.353748\n",
      "2022-11-02 12:34:32,127 INFO     Training average negative_sample_loss at step 37000: 0.420880\n",
      "2022-11-02 12:34:32,127 INFO     Training average loss at step 37000: 0.387314\n",
      "2022-11-02 12:34:34,681 INFO     Training average positive_sample_loss at step 37100: 0.363385\n",
      "2022-11-02 12:34:34,681 INFO     Training average negative_sample_loss at step 37100: 0.413942\n",
      "2022-11-02 12:34:34,681 INFO     Training average loss at step 37100: 0.388664\n",
      "2022-11-02 12:34:36,373 INFO     Training average positive_sample_loss at step 37200: 0.372201\n",
      "2022-11-02 12:34:36,373 INFO     Training average negative_sample_loss at step 37200: 0.418730\n",
      "2022-11-02 12:34:36,373 INFO     Training average loss at step 37200: 0.395466\n",
      "2022-11-02 12:34:38,124 INFO     Training average positive_sample_loss at step 37300: 0.361647\n",
      "2022-11-02 12:34:38,124 INFO     Training average negative_sample_loss at step 37300: 0.414053\n",
      "2022-11-02 12:34:38,124 INFO     Training average loss at step 37300: 0.387850\n",
      "2022-11-02 12:34:40,652 INFO     Training average positive_sample_loss at step 37400: 0.371192\n",
      "2022-11-02 12:34:40,652 INFO     Training average negative_sample_loss at step 37400: 0.410376\n",
      "2022-11-02 12:34:40,652 INFO     Training average loss at step 37400: 0.390784\n",
      "2022-11-02 12:34:42,747 INFO     Training average positive_sample_loss at step 37500: 0.364729\n",
      "2022-11-02 12:34:42,747 INFO     Training average negative_sample_loss at step 37500: 0.411581\n",
      "2022-11-02 12:34:42,747 INFO     Training average loss at step 37500: 0.388155\n",
      "2022-11-02 12:34:44,986 INFO     Training average positive_sample_loss at step 37600: 0.365439\n",
      "2022-11-02 12:34:44,986 INFO     Training average negative_sample_loss at step 37600: 0.404522\n",
      "2022-11-02 12:34:44,986 INFO     Training average loss at step 37600: 0.384981\n",
      "2022-11-02 12:34:47,549 INFO     Training average positive_sample_loss at step 37700: 0.373419\n",
      "2022-11-02 12:34:47,549 INFO     Training average negative_sample_loss at step 37700: 0.410478\n",
      "2022-11-02 12:34:47,549 INFO     Training average loss at step 37700: 0.391949\n",
      "2022-11-02 12:34:50,102 INFO     Training average positive_sample_loss at step 37800: 0.356993\n",
      "2022-11-02 12:34:50,102 INFO     Training average negative_sample_loss at step 37800: 0.408047\n",
      "2022-11-02 12:34:50,102 INFO     Training average loss at step 37800: 0.382520\n",
      "2022-11-02 12:34:52,652 INFO     Training average positive_sample_loss at step 37900: 0.352910\n",
      "2022-11-02 12:34:52,652 INFO     Training average negative_sample_loss at step 37900: 0.409241\n",
      "2022-11-02 12:34:52,653 INFO     Training average loss at step 37900: 0.381075\n",
      "2022-11-02 12:34:55,194 INFO     Training average positive_sample_loss at step 38000: 0.353960\n",
      "2022-11-02 12:34:55,194 INFO     Training average negative_sample_loss at step 38000: 0.405119\n",
      "2022-11-02 12:34:55,194 INFO     Training average loss at step 38000: 0.379539\n",
      "2022-11-02 12:34:57,776 INFO     Training average positive_sample_loss at step 38100: 0.362848\n",
      "2022-11-02 12:34:57,776 INFO     Training average negative_sample_loss at step 38100: 0.412579\n",
      "2022-11-02 12:34:57,776 INFO     Training average loss at step 38100: 0.387713\n",
      "2022-11-02 12:35:00,302 INFO     Training average positive_sample_loss at step 38200: 0.357671\n",
      "2022-11-02 12:35:00,302 INFO     Training average negative_sample_loss at step 38200: 0.409203\n",
      "2022-11-02 12:35:00,302 INFO     Training average loss at step 38200: 0.383437\n",
      "2022-11-02 12:35:02,851 INFO     Training average positive_sample_loss at step 38300: 0.364714\n",
      "2022-11-02 12:35:02,851 INFO     Training average negative_sample_loss at step 38300: 0.411772\n",
      "2022-11-02 12:35:02,851 INFO     Training average loss at step 38300: 0.388243\n",
      "2022-11-02 12:35:05,407 INFO     Training average positive_sample_loss at step 38400: 0.356083\n",
      "2022-11-02 12:35:05,408 INFO     Training average negative_sample_loss at step 38400: 0.414272\n",
      "2022-11-02 12:35:05,408 INFO     Training average loss at step 38400: 0.385177\n",
      "2022-11-02 12:35:07,948 INFO     Training average positive_sample_loss at step 38500: 0.357080\n",
      "2022-11-02 12:35:07,948 INFO     Training average negative_sample_loss at step 38500: 0.403345\n",
      "2022-11-02 12:35:07,948 INFO     Training average loss at step 38500: 0.380212\n",
      "2022-11-02 12:35:10,495 INFO     Training average positive_sample_loss at step 38600: 0.359809\n",
      "2022-11-02 12:35:10,496 INFO     Training average negative_sample_loss at step 38600: 0.399146\n",
      "2022-11-02 12:35:10,496 INFO     Training average loss at step 38600: 0.379478\n",
      "2022-11-02 12:35:13,053 INFO     Training average positive_sample_loss at step 38700: 0.367555\n",
      "2022-11-02 12:35:13,053 INFO     Training average negative_sample_loss at step 38700: 0.411275\n",
      "2022-11-02 12:35:13,053 INFO     Training average loss at step 38700: 0.389415\n",
      "2022-11-02 12:35:15,604 INFO     Training average positive_sample_loss at step 38800: 0.353834\n",
      "2022-11-02 12:35:15,604 INFO     Training average negative_sample_loss at step 38800: 0.403523\n",
      "2022-11-02 12:35:15,604 INFO     Training average loss at step 38800: 0.378679\n",
      "2022-11-02 12:35:18,178 INFO     Training average positive_sample_loss at step 38900: 0.366166\n",
      "2022-11-02 12:35:18,178 INFO     Training average negative_sample_loss at step 38900: 0.404975\n",
      "2022-11-02 12:35:18,178 INFO     Training average loss at step 38900: 0.385570\n",
      "2022-11-02 12:35:20,718 INFO     Training average positive_sample_loss at step 39000: 0.358747\n",
      "2022-11-02 12:35:20,718 INFO     Training average negative_sample_loss at step 39000: 0.402424\n",
      "2022-11-02 12:35:20,718 INFO     Training average loss at step 39000: 0.380586\n",
      "2022-11-02 12:35:23,283 INFO     Training average positive_sample_loss at step 39100: 0.363294\n",
      "2022-11-02 12:35:23,283 INFO     Training average negative_sample_loss at step 39100: 0.400752\n",
      "2022-11-02 12:35:23,283 INFO     Training average loss at step 39100: 0.382023\n",
      "2022-11-02 12:35:25,856 INFO     Training average positive_sample_loss at step 39200: 0.358943\n",
      "2022-11-02 12:35:25,856 INFO     Training average negative_sample_loss at step 39200: 0.408141\n",
      "2022-11-02 12:35:25,856 INFO     Training average loss at step 39200: 0.383542\n",
      "2022-11-02 12:35:28,384 INFO     Training average positive_sample_loss at step 39300: 0.362117\n",
      "2022-11-02 12:35:28,384 INFO     Training average negative_sample_loss at step 39300: 0.403871\n",
      "2022-11-02 12:35:28,384 INFO     Training average loss at step 39300: 0.382994\n",
      "2022-11-02 12:35:30,945 INFO     Training average positive_sample_loss at step 39400: 0.348468\n",
      "2022-11-02 12:35:30,945 INFO     Training average negative_sample_loss at step 39400: 0.404115\n",
      "2022-11-02 12:35:30,945 INFO     Training average loss at step 39400: 0.376292\n",
      "2022-11-02 12:35:33,534 INFO     Training average positive_sample_loss at step 39500: 0.362097\n",
      "2022-11-02 12:35:33,534 INFO     Training average negative_sample_loss at step 39500: 0.407074\n",
      "2022-11-02 12:35:33,534 INFO     Training average loss at step 39500: 0.384586\n",
      "2022-11-02 12:35:36,100 INFO     Training average positive_sample_loss at step 39600: 0.352223\n",
      "2022-11-02 12:35:36,101 INFO     Training average negative_sample_loss at step 39600: 0.407253\n",
      "2022-11-02 12:35:36,101 INFO     Training average loss at step 39600: 0.379738\n",
      "2022-11-02 12:35:38,639 INFO     Training average positive_sample_loss at step 39700: 0.357018\n",
      "2022-11-02 12:35:38,639 INFO     Training average negative_sample_loss at step 39700: 0.400593\n",
      "2022-11-02 12:35:38,639 INFO     Training average loss at step 39700: 0.378806\n",
      "2022-11-02 12:35:41,219 INFO     Training average positive_sample_loss at step 39800: 0.360152\n",
      "2022-11-02 12:35:41,219 INFO     Training average negative_sample_loss at step 39800: 0.407843\n",
      "2022-11-02 12:35:41,219 INFO     Training average loss at step 39800: 0.383997\n",
      "2022-11-02 12:35:43,762 INFO     Training average positive_sample_loss at step 39900: 0.346193\n",
      "2022-11-02 12:35:43,762 INFO     Training average negative_sample_loss at step 39900: 0.404196\n",
      "2022-11-02 12:35:43,762 INFO     Training average loss at step 39900: 0.375194\n",
      "2022-11-02 12:35:47,524 INFO     Training average positive_sample_loss at step 40000: 0.354604\n",
      "2022-11-02 12:35:47,524 INFO     Training average negative_sample_loss at step 40000: 0.405972\n",
      "2022-11-02 12:35:47,525 INFO     Training average loss at step 40000: 0.380288\n",
      "2022-11-02 12:35:50,085 INFO     Training average positive_sample_loss at step 40100: 0.354877\n",
      "2022-11-02 12:35:50,085 INFO     Training average negative_sample_loss at step 40100: 0.400061\n",
      "2022-11-02 12:35:50,085 INFO     Training average loss at step 40100: 0.377469\n",
      "2022-11-02 12:35:52,671 INFO     Training average positive_sample_loss at step 40200: 0.350389\n",
      "2022-11-02 12:35:52,671 INFO     Training average negative_sample_loss at step 40200: 0.403377\n",
      "2022-11-02 12:35:52,671 INFO     Training average loss at step 40200: 0.376883\n",
      "2022-11-02 12:35:55,231 INFO     Training average positive_sample_loss at step 40300: 0.353591\n",
      "2022-11-02 12:35:55,231 INFO     Training average negative_sample_loss at step 40300: 0.401992\n",
      "2022-11-02 12:35:55,231 INFO     Training average loss at step 40300: 0.377792\n",
      "2022-11-02 12:35:57,777 INFO     Training average positive_sample_loss at step 40400: 0.354697\n",
      "2022-11-02 12:35:57,777 INFO     Training average negative_sample_loss at step 40400: 0.405202\n",
      "2022-11-02 12:35:57,777 INFO     Training average loss at step 40400: 0.379950\n",
      "2022-11-02 12:36:00,339 INFO     Training average positive_sample_loss at step 40500: 0.366980\n",
      "2022-11-02 12:36:00,339 INFO     Training average negative_sample_loss at step 40500: 0.403164\n",
      "2022-11-02 12:36:00,339 INFO     Training average loss at step 40500: 0.385072\n",
      "2022-11-02 12:36:02,918 INFO     Training average positive_sample_loss at step 40600: 0.356402\n",
      "2022-11-02 12:36:02,918 INFO     Training average negative_sample_loss at step 40600: 0.409236\n",
      "2022-11-02 12:36:02,918 INFO     Training average loss at step 40600: 0.382819\n",
      "2022-11-02 12:36:05,509 INFO     Training average positive_sample_loss at step 40700: 0.357256\n",
      "2022-11-02 12:36:05,509 INFO     Training average negative_sample_loss at step 40700: 0.409445\n",
      "2022-11-02 12:36:05,509 INFO     Training average loss at step 40700: 0.383350\n",
      "2022-11-02 12:36:08,079 INFO     Training average positive_sample_loss at step 40800: 0.350037\n",
      "2022-11-02 12:36:08,080 INFO     Training average negative_sample_loss at step 40800: 0.398065\n",
      "2022-11-02 12:36:08,080 INFO     Training average loss at step 40800: 0.374051\n",
      "2022-11-02 12:36:10,666 INFO     Training average positive_sample_loss at step 40900: 0.344679\n",
      "2022-11-02 12:36:10,666 INFO     Training average negative_sample_loss at step 40900: 0.404846\n",
      "2022-11-02 12:36:10,666 INFO     Training average loss at step 40900: 0.374763\n",
      "2022-11-02 12:36:13,218 INFO     Training average positive_sample_loss at step 41000: 0.363391\n",
      "2022-11-02 12:36:13,219 INFO     Training average negative_sample_loss at step 41000: 0.402719\n",
      "2022-11-02 12:36:13,219 INFO     Training average loss at step 41000: 0.383055\n",
      "2022-11-02 12:36:15,773 INFO     Training average positive_sample_loss at step 41100: 0.340608\n",
      "2022-11-02 12:36:15,774 INFO     Training average negative_sample_loss at step 41100: 0.404267\n",
      "2022-11-02 12:36:15,774 INFO     Training average loss at step 41100: 0.372437\n",
      "2022-11-02 12:36:18,359 INFO     Training average positive_sample_loss at step 41200: 0.362242\n",
      "2022-11-02 12:36:18,359 INFO     Training average negative_sample_loss at step 41200: 0.393602\n",
      "2022-11-02 12:36:18,359 INFO     Training average loss at step 41200: 0.377922\n",
      "2022-11-02 12:36:20,928 INFO     Training average positive_sample_loss at step 41300: 0.351780\n",
      "2022-11-02 12:36:20,928 INFO     Training average negative_sample_loss at step 41300: 0.400316\n",
      "2022-11-02 12:36:20,928 INFO     Training average loss at step 41300: 0.376048\n",
      "2022-11-02 12:36:23,571 INFO     Training average positive_sample_loss at step 41400: 0.338604\n",
      "2022-11-02 12:36:23,572 INFO     Training average negative_sample_loss at step 41400: 0.404467\n",
      "2022-11-02 12:36:23,572 INFO     Training average loss at step 41400: 0.371536\n",
      "2022-11-02 12:36:26,177 INFO     Training average positive_sample_loss at step 41500: 0.355817\n",
      "2022-11-02 12:36:26,177 INFO     Training average negative_sample_loss at step 41500: 0.388992\n",
      "2022-11-02 12:36:26,177 INFO     Training average loss at step 41500: 0.372405\n",
      "2022-11-02 12:36:28,759 INFO     Training average positive_sample_loss at step 41600: 0.355166\n",
      "2022-11-02 12:36:28,759 INFO     Training average negative_sample_loss at step 41600: 0.407209\n",
      "2022-11-02 12:36:28,759 INFO     Training average loss at step 41600: 0.381187\n",
      "2022-11-02 12:36:31,344 INFO     Training average positive_sample_loss at step 41700: 0.347368\n",
      "2022-11-02 12:36:31,344 INFO     Training average negative_sample_loss at step 41700: 0.397849\n",
      "2022-11-02 12:36:31,344 INFO     Training average loss at step 41700: 0.372608\n",
      "2022-11-02 12:36:33,928 INFO     Training average positive_sample_loss at step 41800: 0.343728\n",
      "2022-11-02 12:36:33,928 INFO     Training average negative_sample_loss at step 41800: 0.400502\n",
      "2022-11-02 12:36:33,928 INFO     Training average loss at step 41800: 0.372115\n",
      "2022-11-02 12:36:36,515 INFO     Training average positive_sample_loss at step 41900: 0.353454\n",
      "2022-11-02 12:36:36,515 INFO     Training average negative_sample_loss at step 41900: 0.389801\n",
      "2022-11-02 12:36:36,515 INFO     Training average loss at step 41900: 0.371627\n",
      "2022-11-02 12:36:39,069 INFO     Training average positive_sample_loss at step 42000: 0.344392\n",
      "2022-11-02 12:36:39,069 INFO     Training average negative_sample_loss at step 42000: 0.399419\n",
      "2022-11-02 12:36:39,069 INFO     Training average loss at step 42000: 0.371906\n",
      "2022-11-02 12:36:41,628 INFO     Training average positive_sample_loss at step 42100: 0.362898\n",
      "2022-11-02 12:36:41,628 INFO     Training average negative_sample_loss at step 42100: 0.395376\n",
      "2022-11-02 12:36:41,628 INFO     Training average loss at step 42100: 0.379137\n",
      "2022-11-02 12:36:43,783 INFO     Training average positive_sample_loss at step 42200: 0.341040\n",
      "2022-11-02 12:36:43,783 INFO     Training average negative_sample_loss at step 42200: 0.398499\n",
      "2022-11-02 12:36:43,783 INFO     Training average loss at step 42200: 0.369770\n",
      "2022-11-02 12:36:45,558 INFO     Training average positive_sample_loss at step 42300: 0.346524\n",
      "2022-11-02 12:36:45,558 INFO     Training average negative_sample_loss at step 42300: 0.396617\n",
      "2022-11-02 12:36:45,558 INFO     Training average loss at step 42300: 0.371571\n",
      "2022-11-02 12:36:48,093 INFO     Training average positive_sample_loss at step 42400: 0.355852\n",
      "2022-11-02 12:36:48,093 INFO     Training average negative_sample_loss at step 42400: 0.389853\n",
      "2022-11-02 12:36:48,093 INFO     Training average loss at step 42400: 0.372852\n",
      "2022-11-02 12:36:50,663 INFO     Training average positive_sample_loss at step 42500: 0.348973\n",
      "2022-11-02 12:36:50,663 INFO     Training average negative_sample_loss at step 42500: 0.402575\n",
      "2022-11-02 12:36:50,663 INFO     Training average loss at step 42500: 0.375774\n",
      "2022-11-02 12:36:53,227 INFO     Training average positive_sample_loss at step 42600: 0.361665\n",
      "2022-11-02 12:36:53,227 INFO     Training average negative_sample_loss at step 42600: 0.400161\n",
      "2022-11-02 12:36:53,227 INFO     Training average loss at step 42600: 0.380913\n",
      "2022-11-02 12:36:55,800 INFO     Training average positive_sample_loss at step 42700: 0.338049\n",
      "2022-11-02 12:36:55,800 INFO     Training average negative_sample_loss at step 42700: 0.394630\n",
      "2022-11-02 12:36:55,800 INFO     Training average loss at step 42700: 0.366339\n",
      "2022-11-02 12:36:58,361 INFO     Training average positive_sample_loss at step 42800: 0.349324\n",
      "2022-11-02 12:36:58,361 INFO     Training average negative_sample_loss at step 42800: 0.401920\n",
      "2022-11-02 12:36:58,361 INFO     Training average loss at step 42800: 0.375622\n",
      "2022-11-02 12:37:00,915 INFO     Training average positive_sample_loss at step 42900: 0.344808\n",
      "2022-11-02 12:37:00,915 INFO     Training average negative_sample_loss at step 42900: 0.398972\n",
      "2022-11-02 12:37:00,915 INFO     Training average loss at step 42900: 0.371890\n",
      "2022-11-02 12:37:03,466 INFO     Training average positive_sample_loss at step 43000: 0.350665\n",
      "2022-11-02 12:37:03,467 INFO     Training average negative_sample_loss at step 43000: 0.398779\n",
      "2022-11-02 12:37:03,467 INFO     Training average loss at step 43000: 0.374722\n",
      "2022-11-02 12:37:06,053 INFO     Training average positive_sample_loss at step 43100: 0.349239\n",
      "2022-11-02 12:37:06,054 INFO     Training average negative_sample_loss at step 43100: 0.398305\n",
      "2022-11-02 12:37:06,054 INFO     Training average loss at step 43100: 0.373772\n",
      "2022-11-02 12:37:08,653 INFO     Training average positive_sample_loss at step 43200: 0.359128\n",
      "2022-11-02 12:37:08,653 INFO     Training average negative_sample_loss at step 43200: 0.395603\n",
      "2022-11-02 12:37:08,653 INFO     Training average loss at step 43200: 0.377365\n",
      "2022-11-02 12:37:11,250 INFO     Training average positive_sample_loss at step 43300: 0.350393\n",
      "2022-11-02 12:37:11,250 INFO     Training average negative_sample_loss at step 43300: 0.400187\n",
      "2022-11-02 12:37:11,250 INFO     Training average loss at step 43300: 0.375290\n",
      "2022-11-02 12:37:13,789 INFO     Training average positive_sample_loss at step 43400: 0.352875\n",
      "2022-11-02 12:37:13,789 INFO     Training average negative_sample_loss at step 43400: 0.389973\n",
      "2022-11-02 12:37:13,789 INFO     Training average loss at step 43400: 0.371424\n",
      "2022-11-02 12:37:16,343 INFO     Training average positive_sample_loss at step 43500: 0.348107\n",
      "2022-11-02 12:37:16,343 INFO     Training average negative_sample_loss at step 43500: 0.397411\n",
      "2022-11-02 12:37:16,343 INFO     Training average loss at step 43500: 0.372759\n",
      "2022-11-02 12:37:18,898 INFO     Training average positive_sample_loss at step 43600: 0.356285\n",
      "2022-11-02 12:37:18,898 INFO     Training average negative_sample_loss at step 43600: 0.394343\n",
      "2022-11-02 12:37:18,898 INFO     Training average loss at step 43600: 0.375314\n",
      "2022-11-02 12:37:21,494 INFO     Training average positive_sample_loss at step 43700: 0.354667\n",
      "2022-11-02 12:37:21,494 INFO     Training average negative_sample_loss at step 43700: 0.392009\n",
      "2022-11-02 12:37:21,494 INFO     Training average loss at step 43700: 0.373338\n",
      "2022-11-02 12:37:24,071 INFO     Training average positive_sample_loss at step 43800: 0.349856\n",
      "2022-11-02 12:37:24,071 INFO     Training average negative_sample_loss at step 43800: 0.395331\n",
      "2022-11-02 12:37:24,071 INFO     Training average loss at step 43800: 0.372594\n",
      "2022-11-02 12:37:26,673 INFO     Training average positive_sample_loss at step 43900: 0.346220\n",
      "2022-11-02 12:37:26,673 INFO     Training average negative_sample_loss at step 43900: 0.389976\n",
      "2022-11-02 12:37:26,673 INFO     Training average loss at step 43900: 0.368098\n",
      "2022-11-02 12:37:28,394 INFO     Training average positive_sample_loss at step 44000: 0.360965\n",
      "2022-11-02 12:37:28,394 INFO     Training average negative_sample_loss at step 44000: 0.396347\n",
      "2022-11-02 12:37:28,394 INFO     Training average loss at step 44000: 0.378656\n",
      "2022-11-02 12:37:30,959 INFO     Training average positive_sample_loss at step 44100: 0.342556\n",
      "2022-11-02 12:37:30,959 INFO     Training average negative_sample_loss at step 44100: 0.392892\n",
      "2022-11-02 12:37:30,959 INFO     Training average loss at step 44100: 0.367724\n",
      "2022-11-02 12:37:33,447 INFO     Training average positive_sample_loss at step 44200: 0.346535\n",
      "2022-11-02 12:37:33,447 INFO     Training average negative_sample_loss at step 44200: 0.389735\n",
      "2022-11-02 12:37:33,447 INFO     Training average loss at step 44200: 0.368135\n",
      "2022-11-02 12:37:35,211 INFO     Training average positive_sample_loss at step 44300: 0.340892\n",
      "2022-11-02 12:37:35,211 INFO     Training average negative_sample_loss at step 44300: 0.388075\n",
      "2022-11-02 12:37:35,211 INFO     Training average loss at step 44300: 0.364483\n",
      "2022-11-02 12:37:37,819 INFO     Training average positive_sample_loss at step 44400: 0.348789\n",
      "2022-11-02 12:37:37,819 INFO     Training average negative_sample_loss at step 44400: 0.394198\n",
      "2022-11-02 12:37:37,819 INFO     Training average loss at step 44400: 0.371493\n",
      "2022-11-02 12:37:39,584 INFO     Training average positive_sample_loss at step 44500: 0.354825\n",
      "2022-11-02 12:37:39,584 INFO     Training average negative_sample_loss at step 44500: 0.393829\n",
      "2022-11-02 12:37:39,584 INFO     Training average loss at step 44500: 0.374327\n",
      "2022-11-02 12:37:41,976 INFO     Training average positive_sample_loss at step 44600: 0.346688\n",
      "2022-11-02 12:37:41,976 INFO     Training average negative_sample_loss at step 44600: 0.397190\n",
      "2022-11-02 12:37:41,976 INFO     Training average loss at step 44600: 0.371939\n",
      "2022-11-02 12:37:44,596 INFO     Training average positive_sample_loss at step 44700: 0.344105\n",
      "2022-11-02 12:37:44,596 INFO     Training average negative_sample_loss at step 44700: 0.393665\n",
      "2022-11-02 12:37:44,596 INFO     Training average loss at step 44700: 0.368885\n",
      "2022-11-02 12:37:46,261 INFO     Training average positive_sample_loss at step 44800: 0.358827\n",
      "2022-11-02 12:37:46,261 INFO     Training average negative_sample_loss at step 44800: 0.387629\n",
      "2022-11-02 12:37:46,261 INFO     Training average loss at step 44800: 0.373228\n",
      "2022-11-02 12:37:48,885 INFO     Training average positive_sample_loss at step 44900: 0.341802\n",
      "2022-11-02 12:37:48,885 INFO     Training average negative_sample_loss at step 44900: 0.400489\n",
      "2022-11-02 12:37:48,885 INFO     Training average loss at step 44900: 0.371146\n",
      "2022-11-02 12:37:51,493 INFO     Training average positive_sample_loss at step 45000: 0.342016\n",
      "2022-11-02 12:37:51,493 INFO     Training average negative_sample_loss at step 45000: 0.391845\n",
      "2022-11-02 12:37:51,493 INFO     Training average loss at step 45000: 0.366930\n",
      "2022-11-02 12:37:54,071 INFO     Training average positive_sample_loss at step 45100: 0.348594\n",
      "2022-11-02 12:37:54,071 INFO     Training average negative_sample_loss at step 45100: 0.385555\n",
      "2022-11-02 12:37:54,071 INFO     Training average loss at step 45100: 0.367075\n",
      "2022-11-02 12:37:56,671 INFO     Training average positive_sample_loss at step 45200: 0.338800\n",
      "2022-11-02 12:37:56,671 INFO     Training average negative_sample_loss at step 45200: 0.392817\n",
      "2022-11-02 12:37:56,671 INFO     Training average loss at step 45200: 0.365809\n",
      "2022-11-02 12:37:59,240 INFO     Training average positive_sample_loss at step 45300: 0.340084\n",
      "2022-11-02 12:37:59,240 INFO     Training average negative_sample_loss at step 45300: 0.387591\n",
      "2022-11-02 12:37:59,240 INFO     Training average loss at step 45300: 0.363838\n",
      "2022-11-02 12:38:01,822 INFO     Training average positive_sample_loss at step 45400: 0.346917\n",
      "2022-11-02 12:38:01,822 INFO     Training average negative_sample_loss at step 45400: 0.387270\n",
      "2022-11-02 12:38:01,822 INFO     Training average loss at step 45400: 0.367093\n",
      "2022-11-02 12:38:04,434 INFO     Training average positive_sample_loss at step 45500: 0.356617\n",
      "2022-11-02 12:38:04,434 INFO     Training average negative_sample_loss at step 45500: 0.394881\n",
      "2022-11-02 12:38:04,434 INFO     Training average loss at step 45500: 0.375749\n",
      "2022-11-02 12:38:07,045 INFO     Training average positive_sample_loss at step 45600: 0.349628\n",
      "2022-11-02 12:38:07,045 INFO     Training average negative_sample_loss at step 45600: 0.390874\n",
      "2022-11-02 12:38:07,045 INFO     Training average loss at step 45600: 0.370251\n",
      "2022-11-02 12:38:09,672 INFO     Training average positive_sample_loss at step 45700: 0.351376\n",
      "2022-11-02 12:38:09,672 INFO     Training average negative_sample_loss at step 45700: 0.388700\n",
      "2022-11-02 12:38:09,672 INFO     Training average loss at step 45700: 0.370038\n",
      "2022-11-02 12:38:12,229 INFO     Training average positive_sample_loss at step 45800: 0.334508\n",
      "2022-11-02 12:38:12,229 INFO     Training average negative_sample_loss at step 45800: 0.378240\n",
      "2022-11-02 12:38:12,230 INFO     Training average loss at step 45800: 0.356374\n",
      "2022-11-02 12:38:14,832 INFO     Training average positive_sample_loss at step 45900: 0.340222\n",
      "2022-11-02 12:38:14,832 INFO     Training average negative_sample_loss at step 45900: 0.388070\n",
      "2022-11-02 12:38:14,832 INFO     Training average loss at step 45900: 0.364146\n",
      "2022-11-02 12:38:17,406 INFO     Training average positive_sample_loss at step 46000: 0.347361\n",
      "2022-11-02 12:38:17,406 INFO     Training average negative_sample_loss at step 46000: 0.393372\n",
      "2022-11-02 12:38:17,406 INFO     Training average loss at step 46000: 0.370366\n",
      "2022-11-02 12:38:20,405 INFO     Training average positive_sample_loss at step 46100: 0.330093\n",
      "2022-11-02 12:38:20,405 INFO     Training average negative_sample_loss at step 46100: 0.386704\n",
      "2022-11-02 12:38:20,405 INFO     Training average loss at step 46100: 0.358399\n",
      "2022-11-02 12:38:24,256 INFO     Training average positive_sample_loss at step 46200: 0.348122\n",
      "2022-11-02 12:38:24,257 INFO     Training average negative_sample_loss at step 46200: 0.393276\n",
      "2022-11-02 12:38:24,257 INFO     Training average loss at step 46200: 0.370699\n",
      "2022-11-02 12:38:28,150 INFO     Training average positive_sample_loss at step 46300: 0.344455\n",
      "2022-11-02 12:38:28,151 INFO     Training average negative_sample_loss at step 46300: 0.384315\n",
      "2022-11-02 12:38:28,151 INFO     Training average loss at step 46300: 0.364385\n",
      "2022-11-02 12:38:32,042 INFO     Training average positive_sample_loss at step 46400: 0.346450\n",
      "2022-11-02 12:38:32,042 INFO     Training average negative_sample_loss at step 46400: 0.387056\n",
      "2022-11-02 12:38:32,042 INFO     Training average loss at step 46400: 0.366753\n",
      "2022-11-02 12:38:35,924 INFO     Training average positive_sample_loss at step 46500: 0.330865\n",
      "2022-11-02 12:38:35,924 INFO     Training average negative_sample_loss at step 46500: 0.387208\n",
      "2022-11-02 12:38:35,924 INFO     Training average loss at step 46500: 0.359036\n",
      "2022-11-02 12:38:39,802 INFO     Training average positive_sample_loss at step 46600: 0.344807\n",
      "2022-11-02 12:38:39,802 INFO     Training average negative_sample_loss at step 46600: 0.386432\n",
      "2022-11-02 12:38:39,802 INFO     Training average loss at step 46600: 0.365620\n",
      "2022-11-02 12:38:43,673 INFO     Training average positive_sample_loss at step 46700: 0.343828\n",
      "2022-11-02 12:38:43,673 INFO     Training average negative_sample_loss at step 46700: 0.391646\n",
      "2022-11-02 12:38:43,673 INFO     Training average loss at step 46700: 0.367737\n",
      "2022-11-02 12:38:47,542 INFO     Training average positive_sample_loss at step 46800: 0.331242\n",
      "2022-11-02 12:38:47,542 INFO     Training average negative_sample_loss at step 46800: 0.382147\n",
      "2022-11-02 12:38:47,543 INFO     Training average loss at step 46800: 0.356695\n",
      "2022-11-02 12:38:51,412 INFO     Training average positive_sample_loss at step 46900: 0.340463\n",
      "2022-11-02 12:38:51,412 INFO     Training average negative_sample_loss at step 46900: 0.388190\n",
      "2022-11-02 12:38:51,412 INFO     Training average loss at step 46900: 0.364327\n",
      "2022-11-02 12:38:55,281 INFO     Training average positive_sample_loss at step 47000: 0.350237\n",
      "2022-11-02 12:38:55,281 INFO     Training average negative_sample_loss at step 47000: 0.390389\n",
      "2022-11-02 12:38:55,281 INFO     Training average loss at step 47000: 0.370313\n",
      "2022-11-02 12:38:59,206 INFO     Training average positive_sample_loss at step 47100: 0.356644\n",
      "2022-11-02 12:38:59,207 INFO     Training average negative_sample_loss at step 47100: 0.383453\n",
      "2022-11-02 12:38:59,207 INFO     Training average loss at step 47100: 0.370048\n",
      "2022-11-02 12:39:03,094 INFO     Training average positive_sample_loss at step 47200: 0.348287\n",
      "2022-11-02 12:39:03,094 INFO     Training average negative_sample_loss at step 47200: 0.384632\n",
      "2022-11-02 12:39:03,094 INFO     Training average loss at step 47200: 0.366460\n",
      "2022-11-02 12:39:07,004 INFO     Training average positive_sample_loss at step 47300: 0.346191\n",
      "2022-11-02 12:39:07,004 INFO     Training average negative_sample_loss at step 47300: 0.391364\n",
      "2022-11-02 12:39:07,004 INFO     Training average loss at step 47300: 0.368778\n",
      "2022-11-02 12:39:10,889 INFO     Training average positive_sample_loss at step 47400: 0.337758\n",
      "2022-11-02 12:39:10,890 INFO     Training average negative_sample_loss at step 47400: 0.390188\n",
      "2022-11-02 12:39:10,890 INFO     Training average loss at step 47400: 0.363973\n",
      "2022-11-02 12:39:14,800 INFO     Training average positive_sample_loss at step 47500: 0.326361\n",
      "2022-11-02 12:39:14,800 INFO     Training average negative_sample_loss at step 47500: 0.387046\n",
      "2022-11-02 12:39:14,800 INFO     Training average loss at step 47500: 0.356703\n",
      "2022-11-02 12:39:18,723 INFO     Training average positive_sample_loss at step 47600: 0.337750\n",
      "2022-11-02 12:39:18,723 INFO     Training average negative_sample_loss at step 47600: 0.376334\n",
      "2022-11-02 12:39:18,724 INFO     Training average loss at step 47600: 0.357042\n",
      "2022-11-02 12:39:22,645 INFO     Training average positive_sample_loss at step 47700: 0.338276\n",
      "2022-11-02 12:39:22,645 INFO     Training average negative_sample_loss at step 47700: 0.382939\n",
      "2022-11-02 12:39:22,645 INFO     Training average loss at step 47700: 0.360607\n",
      "2022-11-02 12:39:26,602 INFO     Training average positive_sample_loss at step 47800: 0.334664\n",
      "2022-11-02 12:39:26,602 INFO     Training average negative_sample_loss at step 47800: 0.386254\n",
      "2022-11-02 12:39:26,602 INFO     Training average loss at step 47800: 0.360459\n",
      "2022-11-02 12:39:30,573 INFO     Training average positive_sample_loss at step 47900: 0.340302\n",
      "2022-11-02 12:39:30,573 INFO     Training average negative_sample_loss at step 47900: 0.384205\n",
      "2022-11-02 12:39:30,573 INFO     Training average loss at step 47900: 0.362254\n",
      "2022-11-02 12:39:34,496 INFO     Training average positive_sample_loss at step 48000: 0.332980\n",
      "2022-11-02 12:39:34,496 INFO     Training average negative_sample_loss at step 48000: 0.378303\n",
      "2022-11-02 12:39:34,496 INFO     Training average loss at step 48000: 0.355642\n",
      "2022-11-02 12:39:38,402 INFO     Training average positive_sample_loss at step 48100: 0.320562\n",
      "2022-11-02 12:39:38,402 INFO     Training average negative_sample_loss at step 48100: 0.372729\n",
      "2022-11-02 12:39:38,402 INFO     Training average loss at step 48100: 0.346645\n",
      "2022-11-02 12:39:42,313 INFO     Training average positive_sample_loss at step 48200: 0.339035\n",
      "2022-11-02 12:39:42,314 INFO     Training average negative_sample_loss at step 48200: 0.387067\n",
      "2022-11-02 12:39:42,314 INFO     Training average loss at step 48200: 0.363051\n"
     ]
    }
   ],
   "source": [
    "# Batch Sz/ Neg_samp_Sz/ Dims/ gamma/ alpha/ lr/ steps/ test batch size/ double ent/ double rel/ regularization\n",
    "!bash run.sh train DistMult MIND_CtD 0 optimized 200 100 225 48.0 1.0 0.001 1000000 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b111e5-f3ad-4826-9f0f-5a86d748b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u codes/run.py --do_test -init models/DistMult_MIND_CtD_optimized --cuda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
