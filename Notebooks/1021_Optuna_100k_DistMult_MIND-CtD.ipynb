{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogertu/python_venvs/RotatE/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../codes/\")\n",
    "from dataloader import TestDataset, TrainDataset, BidirectionalOneShotIterator\n",
    "from run import parse_args\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# L119 in run.py\n",
    "def read_triple(file_path, entity2id, relation2id):\n",
    "    \"\"\"\n",
    "    Read triples and map them into ids.\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    with open(file_path) as fin:\n",
    "        for line in fin:\n",
    "            h, r, t = line.strip().split(\"\\t\")\n",
    "            triples.append((entity2id[h], relation2id[r], entity2id[t]))\n",
    "    return triples\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, save_variable_list, args):\n",
    "    \"\"\"\n",
    "    Save the parameters of the model and the optimizer,\n",
    "    as well as some other variables such as step and learning_rate\n",
    "    \"\"\"\n",
    "\n",
    "    argparse_dict = vars(args)\n",
    "    with open(os.path.join(args.save_path, \"config.json\"), \"w\") as fjson:\n",
    "        json.dump(argparse_dict, fjson)\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            **save_variable_list,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        },\n",
    "        os.path.join(args.save_path, \"checkpoint\"),\n",
    "    )\n",
    "\n",
    "    entity_embedding = model.entity_embedding.detach().cpu().numpy()\n",
    "    np.save(os.path.join(args.save_path, \"entity_embedding\"), entity_embedding)\n",
    "\n",
    "    relation_embedding = model.relation_embedding.detach().cpu().numpy()\n",
    "    np.save(os.path.join(args.save_path, \"relation_embedding\"), relation_embedding)\n",
    "\n",
    "\n",
    "def set_logger(args):\n",
    "    \"\"\"\n",
    "    Write logs to checkpoint and console\n",
    "    \"\"\"\n",
    "\n",
    "    if args.do_train:\n",
    "        log_file = os.path.join(args.save_path or args.init_checkpoint, \"train.log\")\n",
    "    else:\n",
    "        log_file = os.path.join(args.save_path or args.init_checkpoint, \"test.log\")\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "        level=logging.INFO,\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "        filename=log_file,\n",
    "        filemode=\"w\",\n",
    "    )\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\"%(asctime)s %(levelname)-8s %(message)s\")\n",
    "    console.setFormatter(formatter)\n",
    "    logging.getLogger(\"\").addHandler(console)\n",
    "\n",
    "\n",
    "def log_metrics(mode, step, metrics):\n",
    "    \"\"\"\n",
    "    Print the evaluation logs\n",
    "    \"\"\"\n",
    "    for metric in metrics:\n",
    "        logging.info(\"%s %s at step %d: %f\" % (mode, metric, step, metrics[metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.data_path = \"/home/rogertu/projects/KnowledgeGraphEmbedding00/data/MIND_CtD/\"\n",
    "# more parameters\n",
    "args.uni_weight = True\n",
    "args.cpu_num = 10\n",
    "args.cuda = True\n",
    "args.model = \"DistMult\"\n",
    "args.save_path = os.path.join(\n",
    "    \"/home/rogertu/projects/KnowledgeGraphEmbedding00/models/\",\n",
    "    args.model,\n",
    ")\n",
    "args.negative_adversarial_sampling = True\n",
    "args.gamma = 48  # controls embedding range.  (gamma+2)/hidden_dim\n",
    "# should range from +/-1 to 0.1667\n",
    "args.regularization = 0.00001  # controls loss, have it off for default, on for DistMult and ComplEx\n",
    "args.save_checkpoint_steps = 10000\n",
    "args.valid_steps = 100000\n",
    "args.do_valid = True\n",
    "args.log_steps = 100\n",
    "args.test_log_steps = 10000\n",
    "\n",
    "args.double_entity_embedding = False  #  True for ComplEx\n",
    "args.double_relation_embedding = False  # True for ComplEx and RotatE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if args.save_path and not os.path.exists(args.save_path):\n",
    "    os.makedirs(args.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "with open(os.path.join(args.data_path, \"entities.dict\")) as fin:\n",
    "    entity2id = dict()\n",
    "    for line in fin:\n",
    "        eid, entity = line.strip().split(\"\\t\")\n",
    "        entity2id[entity] = int(eid)\n",
    "\n",
    "with open(os.path.join(args.data_path, \"relations.dict\")) as fin:\n",
    "    relation2id = dict()\n",
    "    for line in fin:\n",
    "        rid, relation = line.strip().split(\"\\t\")\n",
    "        relation2id[relation] = int(rid)\n",
    "\n",
    "nentity = len(entity2id)\n",
    "nrelation = len(relation2id)\n",
    "\n",
    "args.nentity = nentity\n",
    "args.nrelation = nrelation\n",
    "\n",
    "train_triples = read_triple(\n",
    "    os.path.join(args.data_path, \"train.txt\"), entity2id, relation2id\n",
    ")\n",
    "valid_triples = read_triple(\n",
    "    os.path.join(args.data_path, \"valid.txt\"), entity2id, relation2id\n",
    ")\n",
    "test_triples = read_triple(\n",
    "    os.path.join(args.data_path, \"test.txt\"), entity2id, relation2id\n",
    ")\n",
    "\n",
    "all_true_triples = train_triples + valid_triples + test_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.adversarial_temperature = 1.0  # default. Modulates negative effect on loss.\n",
    "args.test_batch_size = 4\n",
    "args.warm_up_steps = None\n",
    "args.countries = None\n",
    "args.optimizer = \"adam\"\n",
    "args.do_test = False\n",
    "args.do_predict = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    \"\"\"Set items to be optimized in this\"\"\"\n",
    "\n",
    "    # varied\n",
    "    args.batch_size = trial.suggest_int(f\"batch_size\", 64, 256, step=4)\n",
    "    args.negative_sample_size = trial.suggest_int(\n",
    "        f\"negative_sample_size\", 64, 128, step=4\n",
    "    )\n",
    "    args.hidden_dim = trial.suggest_int(f\"hidden_dimension_size\", 100, 300, step=25)\n",
    "    args.learning_rate = trial.suggest_float(f\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    args.max_steps = trial.suggest_int(\"max_steps\", 50000, 100000, step=10000)\n",
    "\n",
    "    # constant var can't be referenced outside of function?\n",
    "    # if args.warm_up_steps:\n",
    "    #    warm_up_steps = args.warm_up_steps\n",
    "    # else:\n",
    "    #    warm_up_steps = args.max_steps // 2\n",
    "\n",
    "    # model\n",
    "    kge_model = model.KGEModel(\n",
    "        model_name=args.model,\n",
    "        nentity=args.nentity,\n",
    "        nrelation=args.nrelation,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        gamma=args.gamma,\n",
    "        double_entity_embedding=args.double_entity_embedding,\n",
    "        double_relation_embedding=args.double_relation_embedding,\n",
    "    )\n",
    "\n",
    "    kge_model.cuda()\n",
    "\n",
    "    # load train data\n",
    "    train_dataloader_head = DataLoader(\n",
    "        TrainDataset(\n",
    "            train_triples, nentity, nrelation, args.negative_sample_size, \"head-batch\"\n",
    "        ),\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=max(1, args.cpu_num // 2),\n",
    "        collate_fn=TrainDataset.collate_fn,\n",
    "    )\n",
    "\n",
    "    train_dataloader_tail = DataLoader(\n",
    "        TrainDataset(\n",
    "            train_triples, nentity, nrelation, args.negative_sample_size, \"tail-batch\"\n",
    "        ),\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=max(1, args.cpu_num // 2),\n",
    "        collate_fn=TrainDataset.collate_fn,\n",
    "    )\n",
    "    # every other sample will be head or tail\n",
    "    train_iterator = BidirectionalOneShotIterator(\n",
    "        train_dataloader_head, train_dataloader_tail\n",
    "    )\n",
    "\n",
    "    # Set training configuration and optimizer\n",
    "    current_learning_rate = args.learning_rate\n",
    "    if args.optimizer == \"adam\":\n",
    "        optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, kge_model.parameters()),\n",
    "            lr=current_learning_rate,\n",
    "        )\n",
    "    elif args.optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(\n",
    "            filter(lambda p: p.requires_grad, kge_model.parameters()),\n",
    "            lr=current_learning_rate,\n",
    "        )\n",
    "    elif args.optimizer == \"adagrad\":\n",
    "        optimizer = torch.optim.Adagrad(\n",
    "            filter(lambda p: p.requires_grad, kge_model.parameters()),\n",
    "            lr=current_learning_rate,\n",
    "        )\n",
    "\n",
    "    # add in optimizer for steps otherwise LR doesn't really matter\n",
    "    training_logs = []\n",
    "    for step in range(0, args.max_steps):\n",
    "        log = kge_model.train_step(kge_model, optimizer, train_iterator, args)\n",
    "\n",
    "        training_logs.append(log)\n",
    "\n",
    "        if step % args.save_checkpoint_steps == 0:\n",
    "            save_variable_list = {\n",
    "                \"step\": step,\n",
    "                \"current_learning_rate\": current_learning_rate,\n",
    "                #'warm_up_steps': warm_up_steps\n",
    "            }\n",
    "            save_model(kge_model, optimizer, save_variable_list, args)\n",
    "\n",
    "        if step % args.log_steps == 0:\n",
    "            metrics = {}\n",
    "            for metric in training_logs[0].keys():\n",
    "                metrics[metric] = sum([log[metric] for log in training_logs]) / len(\n",
    "                    training_logs\n",
    "                )\n",
    "            log_metrics(\"Training average\", step, metrics)\n",
    "            training_logs = []\n",
    "\n",
    "        if args.do_valid and (step / (args.max_steps - 1) == 1):\n",
    "            logging.info(\"Evaluating on Valid Dataset...\")\n",
    "            metrics = kge_model.test_step(\n",
    "                kge_model, valid_triples, all_true_triples, args\n",
    "            )\n",
    "            log_metrics(\"Valid\", step, metrics)\n",
    "\n",
    "    save_variable_list = {\n",
    "        \"step\": step,\n",
    "        \"current_learning_rate\": current_learning_rate,\n",
    "        #'warm_up_steps': warm_up_steps\n",
    "    }\n",
    "    save_model(kge_model, optimizer, save_variable_list, args)\n",
    "\n",
    "    # return log['loss'] #for loss\n",
    "    torch.cuda.empty_cache() # clear memory buildup from multiple models\n",
    "    return metrics[\"MRR\"]  # MRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# other server url\n",
    "url=\"postgresql+psycopg2://root:su07dev@su07:5432/optuna_test\"\n",
    "```\n",
    "\n",
    "If you get an error to update your optuna storage, follow the code below\n",
    "```bash\n",
    "optuna storage upgrade --storage $STORAGE_URL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other server url \n",
    "storage = optuna.storages.RDBStorage(\n",
    "    url=\"postgresql+psycopg2://rogertu:admin@localhost/optuna_test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 21:23:07,767]\u001b[0m A new study created in RDB with name: DistMult_MIND_CtD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create a new study.\n",
    "study = optuna.create_study(\n",
    "    study_name=\"DistMult_MIND_CtD\",\n",
    "    direction=\"maximize\",\n",
    "    storage=storage,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 22:48:56,401]\u001b[0m Trial 0 finished with value: 0.034782304808024835 and parameters: {'batch_size': 84, 'negative_sample_size': 120, 'hidden_dimension_size': 300, 'learning_rate': 0.0007620044578484338, 'max_steps': 100000}. Best is trial 0 with value: 0.034782304808024835.\u001b[0m\n",
      "\u001b[32m[I 2022-10-22 23:27:45,416]\u001b[0m Trial 1 finished with value: 0.02086777819904476 and parameters: {'batch_size': 92, 'negative_sample_size': 68, 'hidden_dimension_size': 275, 'learning_rate': 0.002272573194676816, 'max_steps': 50000}. Best is trial 0 with value: 0.034782304808024835.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 00:06:33,849]\u001b[0m Trial 2 finished with value: 0.03561822720369424 and parameters: {'batch_size': 208, 'negative_sample_size': 88, 'hidden_dimension_size': 250, 'learning_rate': 0.0001481313609934388, 'max_steps': 50000}. Best is trial 2 with value: 0.03561822720369424.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 01:00:52,076]\u001b[0m Trial 3 finished with value: 0.0272215639234438 and parameters: {'batch_size': 152, 'negative_sample_size': 112, 'hidden_dimension_size': 225, 'learning_rate': 0.00045206167967472044, 'max_steps': 80000}. Best is trial 2 with value: 0.03561822720369424.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 01:39:03,881]\u001b[0m Trial 4 finished with value: 0.024374264835701178 and parameters: {'batch_size': 172, 'negative_sample_size': 64, 'hidden_dimension_size': 150, 'learning_rate': 0.0012761734530685033, 'max_steps': 80000}. Best is trial 2 with value: 0.03561822720369424.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 02:17:52,856]\u001b[0m Trial 5 finished with value: 0.040797621584996446 and parameters: {'batch_size': 244, 'negative_sample_size': 92, 'hidden_dimension_size': 225, 'learning_rate': 0.005763805733460256, 'max_steps': 50000}. Best is trial 5 with value: 0.040797621584996446.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 03:30:04,240]\u001b[0m Trial 6 finished with value: 0.01264783765236365 and parameters: {'batch_size': 104, 'negative_sample_size': 76, 'hidden_dimension_size': 250, 'learning_rate': 0.001962551746290459, 'max_steps': 90000}. Best is trial 5 with value: 0.040797621584996446.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 04:10:26,987]\u001b[0m Trial 7 finished with value: 0.03137899598502893 and parameters: {'batch_size': 148, 'negative_sample_size': 100, 'hidden_dimension_size': 125, 'learning_rate': 0.0010930185256474848, 'max_steps': 90000}. Best is trial 5 with value: 0.040797621584996446.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 05:13:05,184]\u001b[0m Trial 8 finished with value: 0.03722397180328317 and parameters: {'batch_size': 220, 'negative_sample_size': 84, 'hidden_dimension_size': 300, 'learning_rate': 0.0010939512857163624, 'max_steps': 70000}. Best is trial 5 with value: 0.040797621584996446.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 06:09:46,837]\u001b[0m Trial 9 finished with value: 0.03680539193959587 and parameters: {'batch_size': 256, 'negative_sample_size': 96, 'hidden_dimension_size': 175, 'learning_rate': 0.0003465487152268619, 'max_steps': 90000}. Best is trial 5 with value: 0.040797621584996446.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 06:35:01,397]\u001b[0m Trial 10 finished with value: 0.04101792056087263 and parameters: {'batch_size': 256, 'negative_sample_size': 128, 'hidden_dimension_size': 100, 'learning_rate': 0.007125206169296983, 'max_steps': 60000}. Best is trial 10 with value: 0.04101792056087263.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 07:00:09,002]\u001b[0m Trial 11 finished with value: 0.01448215681491838 and parameters: {'batch_size': 256, 'negative_sample_size': 128, 'hidden_dimension_size': 100, 'learning_rate': 0.007404219289800973, 'max_steps': 60000}. Best is trial 10 with value: 0.04101792056087263.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 07:39:56,581]\u001b[0m Trial 12 finished with value: 0.020489813438312986 and parameters: {'batch_size': 220, 'negative_sample_size': 104, 'hidden_dimension_size': 200, 'learning_rate': 0.008559387874295494, 'max_steps': 60000}. Best is trial 10 with value: 0.04101792056087263.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 08:19:17,484]\u001b[0m Trial 13 finished with value: 0.04367188210119303 and parameters: {'batch_size': 192, 'negative_sample_size': 112, 'hidden_dimension_size': 175, 'learning_rate': 0.00425895160715848, 'max_steps': 60000}. Best is trial 13 with value: 0.04367188210119303.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 08:45:21,745]\u001b[0m Trial 14 finished with value: 0.02808680300972199 and parameters: {'batch_size': 188, 'negative_sample_size': 128, 'hidden_dimension_size': 100, 'learning_rate': 0.0038874157050165646, 'max_steps': 60000}. Best is trial 13 with value: 0.04367188210119303.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 09:24:13,910]\u001b[0m Trial 15 finished with value: 0.035340037458133564 and parameters: {'batch_size': 192, 'negative_sample_size': 112, 'hidden_dimension_size': 150, 'learning_rate': 0.003262768834396996, 'max_steps': 70000}. Best is trial 13 with value: 0.04367188210119303.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 09:54:59,002]\u001b[0m Trial 16 finished with value: 0.017723498886141675 and parameters: {'batch_size': 120, 'negative_sample_size': 116, 'hidden_dimension_size': 150, 'learning_rate': 0.004312119983934433, 'max_steps': 60000}. Best is trial 13 with value: 0.04367188210119303.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 10:36:32,020]\u001b[0m Trial 17 finished with value: 0.01315941140729519 and parameters: {'batch_size': 64, 'negative_sample_size': 120, 'hidden_dimension_size': 175, 'learning_rate': 0.009883187730823239, 'max_steps': 70000}. Best is trial 13 with value: 0.04367188210119303.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 11:05:24,696]\u001b[0m Trial 18 finished with value: 0.02939225158111642 and parameters: {'batch_size': 132, 'negative_sample_size': 104, 'hidden_dimension_size': 125, 'learning_rate': 0.0023404735120811492, 'max_steps': 60000}. Best is trial 13 with value: 0.04367188210119303.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 11:33:58,344]\u001b[0m Trial 19 finished with value: 0.037397119200018356 and parameters: {'batch_size': 224, 'negative_sample_size': 124, 'hidden_dimension_size': 200, 'learning_rate': 0.005330238416506104, 'max_steps': 50000}. Best is trial 13 with value: 0.04367188210119303.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 12:06:22,459]\u001b[0m Trial 20 finished with value: 0.0362655215470416 and parameters: {'batch_size': 176, 'negative_sample_size': 108, 'hidden_dimension_size': 125, 'learning_rate': 0.00013613424349792863, 'max_steps': 70000}. Best is trial 13 with value: 0.04367188210119303.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 12:42:13,161]\u001b[0m Trial 21 finished with value: 0.02121963547292248 and parameters: {'batch_size': 240, 'negative_sample_size': 92, 'hidden_dimension_size': 225, 'learning_rate': 0.005886257635705227, 'max_steps': 50000}. Best is trial 13 with value: 0.04367188210119303.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 13:16:11,547]\u001b[0m Trial 22 finished with value: 0.05443778830057699 and parameters: {'batch_size': 240, 'negative_sample_size': 84, 'hidden_dimension_size': 200, 'learning_rate': 0.0061396790844814204, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 13:57:25,881]\u001b[0m Trial 23 finished with value: 0.03521316513733276 and parameters: {'batch_size': 236, 'negative_sample_size': 80, 'hidden_dimension_size': 175, 'learning_rate': 0.0030483699841862256, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 14:33:29,653]\u001b[0m Trial 24 finished with value: 0.030675205023457223 and parameters: {'batch_size': 204, 'negative_sample_size': 120, 'hidden_dimension_size': 200, 'learning_rate': 0.0071404525870532734, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 14:59:29,773]\u001b[0m Trial 25 finished with value: 0.02048129720205219 and parameters: {'batch_size': 232, 'negative_sample_size': 76, 'hidden_dimension_size': 100, 'learning_rate': 0.004462432701841923, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 15:46:00,831]\u001b[0m Trial 26 finished with value: 0.03958591117496949 and parameters: {'batch_size': 204, 'negative_sample_size': 100, 'hidden_dimension_size': 175, 'learning_rate': 0.0017214592420737938, 'max_steps': 70000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 16:28:00,206]\u001b[0m Trial 27 finished with value: 0.03498136651828454 and parameters: {'batch_size': 256, 'negative_sample_size': 112, 'hidden_dimension_size': 250, 'learning_rate': 0.009806874295039765, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 17:22:43,959]\u001b[0m Trial 28 finished with value: 0.0407688294979902 and parameters: {'batch_size': 168, 'negative_sample_size': 128, 'hidden_dimension_size': 200, 'learning_rate': 0.0028048578863865276, 'max_steps': 80000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 17:56:58,744]\u001b[0m Trial 29 finished with value: 0.03838113480649278 and parameters: {'batch_size': 188, 'negative_sample_size': 116, 'hidden_dimension_size': 150, 'learning_rate': 0.0006531179173384839, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 18:45:56,520]\u001b[0m Trial 30 finished with value: 0.03450290147185032 and parameters: {'batch_size': 216, 'negative_sample_size': 72, 'hidden_dimension_size': 125, 'learning_rate': 0.006410569930928993, 'max_steps': 100000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 19:24:59,956]\u001b[0m Trial 31 finished with value: 0.028502274871211077 and parameters: {'batch_size': 244, 'negative_sample_size': 88, 'hidden_dimension_size': 225, 'learning_rate': 0.005094069796455313, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 20:09:06,759]\u001b[0m Trial 32 finished with value: 0.02266847529489114 and parameters: {'batch_size': 248, 'negative_sample_size': 92, 'hidden_dimension_size': 275, 'learning_rate': 0.0036433268564013003, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 20:46:15,575]\u001b[0m Trial 33 finished with value: 0.03848500704729875 and parameters: {'batch_size': 232, 'negative_sample_size': 84, 'hidden_dimension_size': 225, 'learning_rate': 0.007026147104063794, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 21:28:21,159]\u001b[0m Trial 34 finished with value: 0.04457171600624465 and parameters: {'batch_size': 232, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.005334962162489731, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 22:24:10,727]\u001b[0m Trial 35 finished with value: 0.04368922188301282 and parameters: {'batch_size': 208, 'negative_sample_size': 100, 'hidden_dimension_size': 300, 'learning_rate': 0.0025891183690105904, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 23:11:56,591]\u001b[0m Trial 36 finished with value: 0.0386864410959334 and parameters: {'batch_size': 196, 'negative_sample_size': 100, 'hidden_dimension_size': 300, 'learning_rate': 0.0022741908621013852, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 23:54:23,369]\u001b[0m Trial 37 finished with value: 0.00966719631735692 and parameters: {'batch_size': 208, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.0016247149309573919, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 00:46:28,110]\u001b[0m Trial 38 finished with value: 0.017252636278977714 and parameters: {'batch_size': 180, 'negative_sample_size': 108, 'hidden_dimension_size': 275, 'learning_rate': 0.002677257244156737, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 01:33:13,749]\u001b[0m Trial 39 finished with value: 0.033518577281384326 and parameters: {'batch_size': 164, 'negative_sample_size': 88, 'hidden_dimension_size': 300, 'learning_rate': 0.0014262751715094463, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 02:32:22,784]\u001b[0m Trial 40 finished with value: 0.03657640790455272 and parameters: {'batch_size': 148, 'negative_sample_size': 64, 'hidden_dimension_size': 275, 'learning_rate': 0.00020194045295738396, 'max_steps': 70000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 03:26:29,213]\u001b[0m Trial 41 finished with value: 0.024932446668420923 and parameters: {'batch_size': 228, 'negative_sample_size': 104, 'hidden_dimension_size': 300, 'learning_rate': 0.004521629879198593, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 04:14:49,250]\u001b[0m Trial 42 finished with value: 0.03217829856010876 and parameters: {'batch_size': 216, 'negative_sample_size': 108, 'hidden_dimension_size': 250, 'learning_rate': 0.0007808905625759625, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 05:05:10,087]\u001b[0m Trial 43 finished with value: 0.03977510335575663 and parameters: {'batch_size': 248, 'negative_sample_size': 84, 'hidden_dimension_size': 250, 'learning_rate': 0.008035340881139875, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 06:01:05,868]\u001b[0m Trial 44 finished with value: 0.02672232813735295 and parameters: {'batch_size': 208, 'negative_sample_size': 96, 'hidden_dimension_size': 200, 'learning_rate': 0.003373142327297382, 'max_steps': 80000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 06:49:27,087]\u001b[0m Trial 45 finished with value: 0.03448765977251536 and parameters: {'batch_size': 240, 'negative_sample_size': 124, 'hidden_dimension_size': 300, 'learning_rate': 0.005435936698118383, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 07:37:10,151]\u001b[0m Trial 46 finished with value: 0.038159206465747816 and parameters: {'batch_size': 224, 'negative_sample_size': 116, 'hidden_dimension_size': 225, 'learning_rate': 0.0043989391626940155, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 08:38:23,367]\u001b[0m Trial 47 finished with value: 0.019609528163527498 and parameters: {'batch_size': 196, 'negative_sample_size': 80, 'hidden_dimension_size': 275, 'learning_rate': 0.008312069988458197, 'max_steps': 70000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 09:18:11,018]\u001b[0m Trial 48 finished with value: 0.04807407182329396 and parameters: {'batch_size': 252, 'negative_sample_size': 100, 'hidden_dimension_size': 175, 'learning_rate': 0.006290489510054283, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 09:52:42,190]\u001b[0m Trial 49 finished with value: 0.03856386420661668 and parameters: {'batch_size': 212, 'negative_sample_size': 100, 'hidden_dimension_size': 175, 'learning_rate': 0.0018989726789506935, 'max_steps': 50000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 10:51:36,848]\u001b[0m Trial 50 finished with value: 0.021157122680798005 and parameters: {'batch_size': 248, 'negative_sample_size': 92, 'hidden_dimension_size': 150, 'learning_rate': 0.0038877925767609517, 'max_steps': 100000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 11:34:52,176]\u001b[0m Trial 51 finished with value: 0.019228717958059586 and parameters: {'batch_size': 256, 'negative_sample_size': 104, 'hidden_dimension_size': 175, 'learning_rate': 0.006380854030325503, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 12:23:44,678]\u001b[0m Trial 52 finished with value: 0.04192603913710498 and parameters: {'batch_size': 236, 'negative_sample_size': 112, 'hidden_dimension_size': 200, 'learning_rate': 0.005283083177893487, 'max_steps': 70000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 13:12:13,567]\u001b[0m Trial 53 finished with value: 0.03057934039693451 and parameters: {'batch_size': 228, 'negative_sample_size': 112, 'hidden_dimension_size': 200, 'learning_rate': 0.00010547180767848253, 'max_steps': 70000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 14:03:48,171]\u001b[0m Trial 54 finished with value: 0.014665016855318125 and parameters: {'batch_size': 236, 'negative_sample_size': 96, 'hidden_dimension_size': 200, 'learning_rate': 0.004856440776696198, 'max_steps': 70000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 14:57:47,953]\u001b[0m Trial 55 finished with value: 0.04085686316291377 and parameters: {'batch_size': 220, 'negative_sample_size': 108, 'hidden_dimension_size': 175, 'learning_rate': 0.005964980934112099, 'max_steps': 80000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 15:41:00,140]\u001b[0m Trial 56 finished with value: 0.0358533691320983 and parameters: {'batch_size': 244, 'negative_sample_size': 88, 'hidden_dimension_size': 200, 'learning_rate': 0.002547306873946208, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 16:22:20,755]\u001b[0m Trial 57 finished with value: 0.04157570706851909 and parameters: {'batch_size': 232, 'negative_sample_size': 68, 'hidden_dimension_size': 175, 'learning_rate': 0.0038488393492638424, 'max_steps': 60000}. Best is trial 22 with value: 0.05443778830057699.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 17:17:57,528]\u001b[0m Trial 58 finished with value: 0.07018471468688428 and parameters: {'batch_size': 200, 'negative_sample_size': 100, 'hidden_dimension_size': 225, 'learning_rate': 0.009380369158284479, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 18:02:14,819]\u001b[0m Trial 59 finished with value: 0.033196471231236396 and parameters: {'batch_size': 180, 'negative_sample_size': 104, 'hidden_dimension_size': 250, 'learning_rate': 0.009589749327402395, 'max_steps': 50000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 18:50:27,483]\u001b[0m Trial 60 finished with value: 0.03452253939970241 and parameters: {'batch_size': 156, 'negative_sample_size': 100, 'hidden_dimension_size': 225, 'learning_rate': 0.008577193387123695, 'max_steps': 60000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 19:39:37,064]\u001b[0m Trial 61 finished with value: 0.04791063197361518 and parameters: {'batch_size': 200, 'negative_sample_size': 112, 'hidden_dimension_size': 200, 'learning_rate': 0.007208940684437051, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 20:31:41,359]\u001b[0m Trial 62 finished with value: 0.036004399374323065 and parameters: {'batch_size': 192, 'negative_sample_size': 116, 'hidden_dimension_size': 175, 'learning_rate': 0.007026459024138478, 'max_steps': 80000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 21:12:31,077]\u001b[0m Trial 63 finished with value: 0.03170734360398029 and parameters: {'batch_size': 200, 'negative_sample_size': 100, 'hidden_dimension_size': 150, 'learning_rate': 0.006497320617859119, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 22:24:16,807]\u001b[0m Trial 64 finished with value: 0.030514206699411975 and parameters: {'batch_size': 188, 'negative_sample_size': 96, 'hidden_dimension_size': 225, 'learning_rate': 0.008788051363655434, 'max_steps': 90000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 23:12:45,240]\u001b[0m Trial 65 finished with value: 0.044535126093340385 and parameters: {'batch_size': 212, 'negative_sample_size': 108, 'hidden_dimension_size': 200, 'learning_rate': 0.0030864497474584504, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 00:00:40,092]\u001b[0m Trial 66 finished with value: 0.04441950819018039 and parameters: {'batch_size': 216, 'negative_sample_size': 104, 'hidden_dimension_size': 200, 'learning_rate': 0.0030475898001644593, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 00:49:49,663]\u001b[0m Trial 67 finished with value: 0.01114369836361111 and parameters: {'batch_size': 216, 'negative_sample_size': 108, 'hidden_dimension_size': 200, 'learning_rate': 0.007597634065410885, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 01:37:44,205]\u001b[0m Trial 68 finished with value: 0.03129201238098297 and parameters: {'batch_size': 220, 'negative_sample_size': 104, 'hidden_dimension_size': 200, 'learning_rate': 0.0057707825675723185, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 02:39:36,330]\u001b[0m Trial 69 finished with value: 0.014179421809283697 and parameters: {'batch_size': 88, 'negative_sample_size': 104, 'hidden_dimension_size': 225, 'learning_rate': 0.003337013345767008, 'max_steps': 80000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 03:23:38,534]\u001b[0m Trial 70 finished with value: 0.03605972005979008 and parameters: {'batch_size': 224, 'negative_sample_size': 108, 'hidden_dimension_size': 200, 'learning_rate': 0.0003399644390731911, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 04:15:33,098]\u001b[0m Trial 71 finished with value: 0.011252186918571471 and parameters: {'batch_size': 208, 'negative_sample_size': 100, 'hidden_dimension_size': 225, 'learning_rate': 0.0020648804859042915, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 05:03:53,434]\u001b[0m Trial 72 finished with value: 0.03463902562192629 and parameters: {'batch_size': 200, 'negative_sample_size': 92, 'hidden_dimension_size': 200, 'learning_rate': 0.002841241410963546, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 06:19:03,773]\u001b[0m Trial 73 finished with value: 0.038192383965103834 and parameters: {'batch_size': 212, 'negative_sample_size': 100, 'hidden_dimension_size': 300, 'learning_rate': 0.004688313161659093, 'max_steps': 80000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 07:04:23,794]\u001b[0m Trial 74 finished with value: 0.03926616660677473 and parameters: {'batch_size': 112, 'negative_sample_size': 112, 'hidden_dimension_size': 175, 'learning_rate': 0.0011479881483464857, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 07:58:28,334]\u001b[0m Trial 75 finished with value: 0.04487511585983822 and parameters: {'batch_size': 252, 'negative_sample_size': 96, 'hidden_dimension_size': 225, 'learning_rate': 0.009944247455141974, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 08:53:35,098]\u001b[0m Trial 76 finished with value: 0.022978705207961057 and parameters: {'batch_size': 252, 'negative_sample_size': 96, 'hidden_dimension_size': 225, 'learning_rate': 0.009299512876012397, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 09:50:38,582]\u001b[0m Trial 77 finished with value: 0.04283716441791894 and parameters: {'batch_size': 252, 'negative_sample_size': 96, 'hidden_dimension_size': 200, 'learning_rate': 0.006990514577658771, 'max_steps': 80000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 10:51:38,566]\u001b[0m Trial 78 finished with value: 0.033661992841684224 and parameters: {'batch_size': 240, 'negative_sample_size': 92, 'hidden_dimension_size': 250, 'learning_rate': 0.009767608552913276, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 11:46:31,854]\u001b[0m Trial 79 finished with value: 0.021607865915070506 and parameters: {'batch_size': 228, 'negative_sample_size': 88, 'hidden_dimension_size': 225, 'learning_rate': 0.007791187570551115, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 12:41:53,262]\u001b[0m Trial 80 finished with value: 0.03887746075180652 and parameters: {'batch_size': 240, 'negative_sample_size': 104, 'hidden_dimension_size': 200, 'learning_rate': 0.006070184319891951, 'max_steps': 80000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 13:44:48,934]\u001b[0m Trial 81 finished with value: 0.0432299551316832 and parameters: {'batch_size': 204, 'negative_sample_size': 104, 'hidden_dimension_size': 275, 'learning_rate': 0.00408073601313996, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 14:24:21,514]\u001b[0m Trial 82 finished with value: 0.01981808237939509 and parameters: {'batch_size': 136, 'negative_sample_size': 100, 'hidden_dimension_size': 175, 'learning_rate': 0.0030646337874023623, 'max_steps': 60000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 15:03:44,262]\u001b[0m Trial 83 finished with value: 0.05394833428796393 and parameters: {'batch_size': 212, 'negative_sample_size': 108, 'hidden_dimension_size': 225, 'learning_rate': 0.005110437313273272, 'max_steps': 50000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 15:43:37,510]\u001b[0m Trial 84 finished with value: 0.03876120277694639 and parameters: {'batch_size': 72, 'negative_sample_size': 108, 'hidden_dimension_size': 225, 'learning_rate': 0.00503068242422867, 'max_steps': 50000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 16:22:20,931]\u001b[0m Trial 85 finished with value: 0.03983320611763098 and parameters: {'batch_size': 248, 'negative_sample_size': 112, 'hidden_dimension_size': 225, 'learning_rate': 0.007826378197685233, 'max_steps': 50000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 17:00:04,854]\u001b[0m Trial 86 finished with value: 0.033819185987355165 and parameters: {'batch_size': 232, 'negative_sample_size': 116, 'hidden_dimension_size': 200, 'learning_rate': 0.0066387768690870045, 'max_steps': 50000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 17:40:03,416]\u001b[0m Trial 87 finished with value: 0.02008646474317097 and parameters: {'batch_size': 212, 'negative_sample_size': 108, 'hidden_dimension_size': 250, 'learning_rate': 0.005455739929040775, 'max_steps': 50000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 18:31:18,924]\u001b[0m Trial 88 finished with value: 0.03549824127239439 and parameters: {'batch_size': 216, 'negative_sample_size': 84, 'hidden_dimension_size': 225, 'learning_rate': 0.0035261434126396046, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 19:05:13,538]\u001b[0m Trial 89 finished with value: 0.027065425966128587 and parameters: {'batch_size': 244, 'negative_sample_size': 120, 'hidden_dimension_size': 200, 'learning_rate': 0.008964582120198504, 'max_steps': 50000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 19:38:37,638]\u001b[0m Trial 90 finished with value: 0.03959950583255206 and parameters: {'batch_size': 252, 'negative_sample_size': 76, 'hidden_dimension_size': 200, 'learning_rate': 0.007879165182642903, 'max_steps': 50000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 20:28:52,869]\u001b[0m Trial 91 finished with value: 0.041166844183699265 and parameters: {'batch_size': 200, 'negative_sample_size': 100, 'hidden_dimension_size': 250, 'learning_rate': 0.004245647824670735, 'max_steps': 60000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 21:34:29,970]\u001b[0m Trial 92 finished with value: 0.033672701042949296 and parameters: {'batch_size': 220, 'negative_sample_size': 104, 'hidden_dimension_size': 300, 'learning_rate': 0.0015388918099249005, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 22:03:24,626]\u001b[0m Trial 93 finished with value: 0.03928916480154764 and parameters: {'batch_size': 224, 'negative_sample_size': 96, 'hidden_dimension_size': 150, 'learning_rate': 0.0024567537760438298, 'max_steps': 50000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 22:58:36,065]\u001b[0m Trial 94 finished with value: 0.028575524363851135 and parameters: {'batch_size': 184, 'negative_sample_size': 92, 'hidden_dimension_size': 225, 'learning_rate': 0.005789806442406803, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 23:39:29,725]\u001b[0m Trial 95 finished with value: 0.022958750232195936 and parameters: {'batch_size': 196, 'negative_sample_size': 100, 'hidden_dimension_size': 175, 'learning_rate': 0.0009315969444930574, 'max_steps': 60000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-26 00:36:46,875]\u001b[0m Trial 96 finished with value: 0.036015992764626734 and parameters: {'batch_size': 236, 'negative_sample_size': 108, 'hidden_dimension_size': 250, 'learning_rate': 0.004870853755837423, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-26 01:19:50,491]\u001b[0m Trial 97 finished with value: 0.04165707273357712 and parameters: {'batch_size': 172, 'negative_sample_size': 104, 'hidden_dimension_size': 200, 'learning_rate': 0.0029344380515505587, 'max_steps': 60000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-26 01:58:11,827]\u001b[0m Trial 98 finished with value: 0.03989105194373967 and parameters: {'batch_size': 208, 'negative_sample_size': 104, 'hidden_dimension_size': 225, 'learning_rate': 0.0021509042691915435, 'max_steps': 50000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n",
      "\u001b[32m[I 2022-10-26 02:59:18,545]\u001b[0m Trial 99 finished with value: 0.03538317463513519 and parameters: {'batch_size': 228, 'negative_sample_size': 112, 'hidden_dimension_size': 275, 'learning_rate': 0.006864720830739432, 'max_steps': 70000}. Best is trial 58 with value: 0.07018471468688428.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(define_model, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=58, values=[0.07018471468688428], datetime_start=datetime.datetime(2022, 10, 24, 16, 22, 20, 767474), datetime_complete=datetime.datetime(2022, 10, 24, 17, 17, 57, 506841), params={'batch_size': 200, 'negative_sample_size': 100, 'hidden_dimension_size': 225, 'learning_rate': 0.009380369158284479, 'max_steps': 70000}, distributions={'batch_size': IntDistribution(high=256, log=False, low=64, step=4), 'negative_sample_size': IntDistribution(high=128, log=False, low=64, step=4), 'hidden_dimension_size': IntDistribution(high=300, log=False, low=100, step=25), 'learning_rate': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'max_steps': IntDistribution(high=100000, log=False, low=50000, step=10000)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1058, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.41595422608153837),\n",
       "             ('batch_size', 0.4124538499791961),\n",
       "             ('negative_sample_size', 0.08271854301873817),\n",
       "             ('hidden_dimension_size', 0.058352477595330986),\n",
       "             ('max_steps', 0.030520903325196417)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.importance.get_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
