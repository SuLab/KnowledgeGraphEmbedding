{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d6bf3a-b341-4282-9470-beaa8f275cf3",
   "metadata": {},
   "source": [
    "# Run RotatE algorithm on MIND-CtD dataset\n",
    "## Parameters:\n",
    "* batch_size: 244\n",
    "* hidden_dimension_size: 250\n",
    "* learning_rate: 0.0008470985144688076\n",
    "* negative_sample_size: 108\n",
    "* `double_entity_embedding`: True for ComplEx and RotatE\n",
    "* `double_relation_embedding`: True for ComplEx\n",
    "\n",
    "\n",
    "## Code for Hyperparameter Optimization\n",
    "```python\n",
    "# Code for Generating MCtD best trials\n",
    "storage = optuna.storages.RDBStorage(\n",
    "    url=\"postgresql+psycopg2://rogertu:admin@localhost/optuna_test\",\n",
    ")\n",
    "mctd_rotate = optuna.load_study(study_name = 'RotatE_MIND_CtD', storage = storage)\n",
    "mctd_rotate.best_trial\n",
    "```\n",
    "\n",
    "## Results\n",
    "```pyhton\n",
    "{'batch_size': 244,\n",
    " 'hidden_dimension_size': 250,\n",
    " 'learning_rate': 0.0008470985144688076,\n",
    " 'max_steps': 100000,\n",
    " 'negative_sample_size': 108}\n",
    "```\n",
    "```\n",
    "FrozenTrial(number=90, values=[0.07596450934939111], datetime_start=datetime.datetime(2022, 11, 3, 10, 28, 53, 538395), datetime_complete=datetime.datetime(2022, 11, 3, 12, 52, 48, 241601), params={'batch_size': 244, 'hidden_dimension_size': 250, 'learning_rate': 0.0008470985144688076, 'max_steps': 100000, 'negative_sample_size': 108}, distributions={'batch_size': IntDistribution(high=256, log=False, low=64, step=4), 'hidden_dimension_size': IntDistribution(high=300, log=False, low=100, step=25), 'learning_rate': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'max_steps': IntDistribution(high=100000, log=False, low=50000, step=10000), 'negative_sample_size': IntDistribution(high=128, log=False, low=64, step=4)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1562, state=TrialState.COMPLETE, value=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757f0b5c-43a4-434b-8dcf-e4128bd9b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e04cec2-4efe-4ff5-9186-8d3ae66aaaaf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu117\n",
      "Start Training......\n",
      "2022-11-08 08:41:55,711 INFO     Model: RotatE\n",
      "2022-11-08 08:41:55,711 INFO     Data Path: data/MIND_CtD\n",
      "2022-11-08 08:41:55,711 INFO     #entity: 249605\n",
      "2022-11-08 08:41:55,711 INFO     #relation: 83\n",
      "2022-11-08 08:42:00,369 INFO     #train: 9657134\n",
      "2022-11-08 08:42:00,369 INFO     #valid: 473\n",
      "2022-11-08 08:42:00,370 INFO     #test: 511\n",
      "2022-11-08 08:42:01,143 INFO     Model Parameter Configuration:\n",
      "2022-11-08 08:42:01,143 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2022-11-08 08:42:01,143 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2022-11-08 08:42:01,143 INFO     Parameter entity_embedding: torch.Size([249605, 500]), require_grad = True\n",
      "2022-11-08 08:42:01,143 INFO     Parameter relation_embedding: torch.Size([83, 250]), require_grad = True\n",
      "2022-11-08 08:42:42,632 INFO     Ramdomly Initializing RotatE Model...\n",
      "2022-11-08 08:42:42,632 INFO     Start Training...\n",
      "2022-11-08 08:42:42,632 INFO     init_step = 0\n",
      "2022-11-08 08:42:42,632 INFO     batch_size = 244\n",
      "2022-11-08 08:42:42,632 INFO     negative_adversarial_sampling = 1\n",
      "2022-11-08 08:42:42,632 INFO     hidden_dim = 250\n",
      "2022-11-08 08:42:42,632 INFO     gamma = 48.000000\n",
      "2022-11-08 08:42:42,632 INFO     negative_adversarial_sampling = True\n",
      "2022-11-08 08:42:42,632 INFO     adversarial_temperature = 1.000000\n",
      "2022-11-08 08:42:42,632 INFO     learning_rate = 0\n",
      "2022-11-08 08:42:45,190 INFO     Training average positive_sample_loss at step 0: 4.137024\n",
      "2022-11-08 08:42:45,190 INFO     Training average negative_sample_loss at step 0: 0.226493\n",
      "2022-11-08 08:42:45,190 INFO     Training average loss at step 0: 2.181758\n",
      "2022-11-08 08:42:49,186 INFO     Training average positive_sample_loss at step 100: 4.238764\n",
      "2022-11-08 08:42:49,186 INFO     Training average negative_sample_loss at step 100: 0.208247\n",
      "2022-11-08 08:42:49,186 INFO     Training average loss at step 100: 2.223506\n",
      "2022-11-08 08:42:52,421 INFO     Training average positive_sample_loss at step 200: 4.176417\n",
      "2022-11-08 08:42:52,421 INFO     Training average negative_sample_loss at step 200: 0.199736\n",
      "2022-11-08 08:42:52,421 INFO     Training average loss at step 200: 2.188077\n",
      "2022-11-08 08:42:55,684 INFO     Training average positive_sample_loss at step 300: 4.033347\n",
      "2022-11-08 08:42:55,684 INFO     Training average negative_sample_loss at step 300: 0.205732\n",
      "2022-11-08 08:42:55,684 INFO     Training average loss at step 300: 2.119539\n",
      "2022-11-08 08:42:59,132 INFO     Training average positive_sample_loss at step 400: 3.872350\n",
      "2022-11-08 08:42:59,132 INFO     Training average negative_sample_loss at step 400: 0.224262\n",
      "2022-11-08 08:42:59,132 INFO     Training average loss at step 400: 2.048306\n",
      "2022-11-08 08:43:02,608 INFO     Training average positive_sample_loss at step 500: 3.675606\n",
      "2022-11-08 08:43:02,608 INFO     Training average negative_sample_loss at step 500: 0.251845\n",
      "2022-11-08 08:43:02,608 INFO     Training average loss at step 500: 1.963726\n",
      "2022-11-08 08:43:05,890 INFO     Training average positive_sample_loss at step 600: 3.531251\n",
      "2022-11-08 08:43:05,890 INFO     Training average negative_sample_loss at step 600: 0.278097\n",
      "2022-11-08 08:43:05,890 INFO     Training average loss at step 600: 1.904674\n",
      "2022-11-08 08:43:09,228 INFO     Training average positive_sample_loss at step 700: 3.399382\n",
      "2022-11-08 08:43:09,228 INFO     Training average negative_sample_loss at step 700: 0.315285\n",
      "2022-11-08 08:43:09,228 INFO     Training average loss at step 700: 1.857333\n",
      "2022-11-08 08:43:12,638 INFO     Training average positive_sample_loss at step 800: 3.292077\n",
      "2022-11-08 08:43:12,638 INFO     Training average negative_sample_loss at step 800: 0.352678\n",
      "2022-11-08 08:43:12,638 INFO     Training average loss at step 800: 1.822377\n",
      "2022-11-08 08:43:15,972 INFO     Training average positive_sample_loss at step 900: 3.145454\n",
      "2022-11-08 08:43:15,972 INFO     Training average negative_sample_loss at step 900: 0.402638\n",
      "2022-11-08 08:43:15,972 INFO     Training average loss at step 900: 1.774046\n",
      "2022-11-08 08:43:19,239 INFO     Training average positive_sample_loss at step 1000: 3.035090\n",
      "2022-11-08 08:43:19,239 INFO     Training average negative_sample_loss at step 1000: 0.445791\n",
      "2022-11-08 08:43:19,239 INFO     Training average loss at step 1000: 1.740441\n",
      "2022-11-08 08:43:22,601 INFO     Training average positive_sample_loss at step 1100: 2.969558\n",
      "2022-11-08 08:43:22,601 INFO     Training average negative_sample_loss at step 1100: 0.484592\n",
      "2022-11-08 08:43:22,601 INFO     Training average loss at step 1100: 1.727075\n",
      "2022-11-08 08:43:25,989 INFO     Training average positive_sample_loss at step 1200: 2.961054\n",
      "2022-11-08 08:43:25,989 INFO     Training average negative_sample_loss at step 1200: 0.522016\n",
      "2022-11-08 08:43:25,989 INFO     Training average loss at step 1200: 1.741535\n",
      "2022-11-08 08:43:29,272 INFO     Training average positive_sample_loss at step 1300: 2.793129\n",
      "2022-11-08 08:43:29,272 INFO     Training average negative_sample_loss at step 1300: 0.570682\n",
      "2022-11-08 08:43:29,272 INFO     Training average loss at step 1300: 1.681906\n",
      "2022-11-08 08:43:32,528 INFO     Training average positive_sample_loss at step 1400: 2.735673\n",
      "2022-11-08 08:43:32,528 INFO     Training average negative_sample_loss at step 1400: 0.597878\n",
      "2022-11-08 08:43:32,528 INFO     Training average loss at step 1400: 1.666775\n",
      "2022-11-08 08:43:35,699 INFO     Training average positive_sample_loss at step 1500: 2.709560\n",
      "2022-11-08 08:43:35,699 INFO     Training average negative_sample_loss at step 1500: 0.629635\n",
      "2022-11-08 08:43:35,699 INFO     Training average loss at step 1500: 1.669597\n",
      "2022-11-08 08:43:38,848 INFO     Training average positive_sample_loss at step 1600: 2.654481\n",
      "2022-11-08 08:43:38,848 INFO     Training average negative_sample_loss at step 1600: 0.656690\n",
      "2022-11-08 08:43:38,848 INFO     Training average loss at step 1600: 1.655585\n",
      "2022-11-08 08:43:42,005 INFO     Training average positive_sample_loss at step 1700: 2.604825\n",
      "2022-11-08 08:43:42,006 INFO     Training average negative_sample_loss at step 1700: 0.695276\n",
      "2022-11-08 08:43:42,006 INFO     Training average loss at step 1700: 1.650050\n",
      "2022-11-08 08:43:45,156 INFO     Training average positive_sample_loss at step 1800: 2.540514\n",
      "2022-11-08 08:43:45,156 INFO     Training average negative_sample_loss at step 1800: 0.720730\n",
      "2022-11-08 08:43:45,156 INFO     Training average loss at step 1800: 1.630622\n",
      "2022-11-08 08:43:48,319 INFO     Training average positive_sample_loss at step 1900: 2.523813\n",
      "2022-11-08 08:43:48,319 INFO     Training average negative_sample_loss at step 1900: 0.740200\n",
      "2022-11-08 08:43:48,319 INFO     Training average loss at step 1900: 1.632006\n",
      "2022-11-08 08:43:51,500 INFO     Training average positive_sample_loss at step 2000: 2.547830\n",
      "2022-11-08 08:43:51,500 INFO     Training average negative_sample_loss at step 2000: 0.751382\n",
      "2022-11-08 08:43:51,500 INFO     Training average loss at step 2000: 1.649606\n",
      "2022-11-08 08:43:54,657 INFO     Training average positive_sample_loss at step 2100: 2.458001\n",
      "2022-11-08 08:43:54,657 INFO     Training average negative_sample_loss at step 2100: 0.789525\n",
      "2022-11-08 08:43:54,657 INFO     Training average loss at step 2100: 1.623763\n",
      "2022-11-08 08:43:57,816 INFO     Training average positive_sample_loss at step 2200: 2.440518\n",
      "2022-11-08 08:43:57,816 INFO     Training average negative_sample_loss at step 2200: 0.797476\n",
      "2022-11-08 08:43:57,816 INFO     Training average loss at step 2200: 1.618997\n",
      "2022-11-08 08:44:00,987 INFO     Training average positive_sample_loss at step 2300: 2.408047\n",
      "2022-11-08 08:44:00,987 INFO     Training average negative_sample_loss at step 2300: 0.818789\n",
      "2022-11-08 08:44:00,987 INFO     Training average loss at step 2300: 1.613418\n",
      "2022-11-08 08:44:04,166 INFO     Training average positive_sample_loss at step 2400: 2.415498\n",
      "2022-11-08 08:44:04,166 INFO     Training average negative_sample_loss at step 2400: 0.818987\n",
      "2022-11-08 08:44:04,166 INFO     Training average loss at step 2400: 1.617243\n",
      "2022-11-08 08:44:07,328 INFO     Training average positive_sample_loss at step 2500: 2.379993\n",
      "2022-11-08 08:44:07,328 INFO     Training average negative_sample_loss at step 2500: 0.844976\n",
      "2022-11-08 08:44:07,328 INFO     Training average loss at step 2500: 1.612485\n",
      "2022-11-08 08:44:10,498 INFO     Training average positive_sample_loss at step 2600: 2.390162\n",
      "2022-11-08 08:44:10,498 INFO     Training average negative_sample_loss at step 2600: 0.856588\n",
      "2022-11-08 08:44:10,498 INFO     Training average loss at step 2600: 1.623375\n",
      "2022-11-08 08:44:13,650 INFO     Training average positive_sample_loss at step 2700: 2.369398\n",
      "2022-11-08 08:44:13,650 INFO     Training average negative_sample_loss at step 2700: 0.855494\n",
      "2022-11-08 08:44:13,650 INFO     Training average loss at step 2700: 1.612446\n",
      "2022-11-08 08:44:16,810 INFO     Training average positive_sample_loss at step 2800: 2.374906\n",
      "2022-11-08 08:44:16,810 INFO     Training average negative_sample_loss at step 2800: 0.872717\n",
      "2022-11-08 08:44:16,810 INFO     Training average loss at step 2800: 1.623812\n",
      "2022-11-08 08:44:19,973 INFO     Training average positive_sample_loss at step 2900: 2.340608\n",
      "2022-11-08 08:44:19,973 INFO     Training average negative_sample_loss at step 2900: 0.892340\n",
      "2022-11-08 08:44:19,973 INFO     Training average loss at step 2900: 1.616474\n",
      "2022-11-08 08:44:23,137 INFO     Training average positive_sample_loss at step 3000: 2.334977\n",
      "2022-11-08 08:44:23,138 INFO     Training average negative_sample_loss at step 3000: 0.893739\n",
      "2022-11-08 08:44:23,138 INFO     Training average loss at step 3000: 1.614358\n",
      "2022-11-08 08:44:26,308 INFO     Training average positive_sample_loss at step 3100: 2.332924\n",
      "2022-11-08 08:44:26,308 INFO     Training average negative_sample_loss at step 3100: 0.896946\n",
      "2022-11-08 08:44:26,308 INFO     Training average loss at step 3100: 1.614935\n",
      "2022-11-08 08:44:29,478 INFO     Training average positive_sample_loss at step 3200: 2.287711\n",
      "2022-11-08 08:44:29,478 INFO     Training average negative_sample_loss at step 3200: 0.912423\n",
      "2022-11-08 08:44:29,478 INFO     Training average loss at step 3200: 1.600067\n",
      "2022-11-08 08:44:32,652 INFO     Training average positive_sample_loss at step 3300: 2.240646\n",
      "2022-11-08 08:44:32,652 INFO     Training average negative_sample_loss at step 3300: 0.918234\n",
      "2022-11-08 08:44:32,652 INFO     Training average loss at step 3300: 1.579440\n",
      "2022-11-08 08:44:35,816 INFO     Training average positive_sample_loss at step 3400: 2.243241\n",
      "2022-11-08 08:44:35,816 INFO     Training average negative_sample_loss at step 3400: 0.924425\n",
      "2022-11-08 08:44:35,816 INFO     Training average loss at step 3400: 1.583833\n",
      "2022-11-08 08:44:38,967 INFO     Training average positive_sample_loss at step 3500: 2.251178\n",
      "2022-11-08 08:44:38,967 INFO     Training average negative_sample_loss at step 3500: 0.933798\n",
      "2022-11-08 08:44:38,967 INFO     Training average loss at step 3500: 1.592488\n",
      "2022-11-08 08:44:42,144 INFO     Training average positive_sample_loss at step 3600: 2.240853\n",
      "2022-11-08 08:44:42,144 INFO     Training average negative_sample_loss at step 3600: 0.939354\n",
      "2022-11-08 08:44:42,144 INFO     Training average loss at step 3600: 1.590104\n",
      "2022-11-08 08:44:45,311 INFO     Training average positive_sample_loss at step 3700: 2.232958\n",
      "2022-11-08 08:44:45,311 INFO     Training average negative_sample_loss at step 3700: 0.932353\n",
      "2022-11-08 08:44:45,311 INFO     Training average loss at step 3700: 1.582655\n",
      "2022-11-08 08:44:48,477 INFO     Training average positive_sample_loss at step 3800: 2.190554\n",
      "2022-11-08 08:44:48,477 INFO     Training average negative_sample_loss at step 3800: 0.950671\n",
      "2022-11-08 08:44:48,477 INFO     Training average loss at step 3800: 1.570613\n",
      "2022-11-08 08:44:51,645 INFO     Training average positive_sample_loss at step 3900: 2.197310\n",
      "2022-11-08 08:44:51,645 INFO     Training average negative_sample_loss at step 3900: 0.949816\n",
      "2022-11-08 08:44:51,645 INFO     Training average loss at step 3900: 1.573563\n",
      "2022-11-08 08:44:54,802 INFO     Training average positive_sample_loss at step 4000: 2.191385\n",
      "2022-11-08 08:44:54,802 INFO     Training average negative_sample_loss at step 4000: 0.962094\n",
      "2022-11-08 08:44:54,802 INFO     Training average loss at step 4000: 1.576739\n",
      "2022-11-08 08:44:57,968 INFO     Training average positive_sample_loss at step 4100: 2.222363\n",
      "2022-11-08 08:44:57,968 INFO     Training average negative_sample_loss at step 4100: 0.954912\n",
      "2022-11-08 08:44:57,968 INFO     Training average loss at step 4100: 1.588638\n",
      "2022-11-08 08:45:01,135 INFO     Training average positive_sample_loss at step 4200: 2.172605\n",
      "2022-11-08 08:45:01,135 INFO     Training average negative_sample_loss at step 4200: 0.953896\n",
      "2022-11-08 08:45:01,135 INFO     Training average loss at step 4200: 1.563251\n",
      "2022-11-08 08:45:04,293 INFO     Training average positive_sample_loss at step 4300: 2.206542\n",
      "2022-11-08 08:45:04,293 INFO     Training average negative_sample_loss at step 4300: 0.962170\n",
      "2022-11-08 08:45:04,293 INFO     Training average loss at step 4300: 1.584356\n",
      "2022-11-08 08:45:07,507 INFO     Training average positive_sample_loss at step 4400: 2.182881\n",
      "2022-11-08 08:45:07,507 INFO     Training average negative_sample_loss at step 4400: 0.965760\n",
      "2022-11-08 08:45:07,507 INFO     Training average loss at step 4400: 1.574320\n",
      "2022-11-08 08:45:10,681 INFO     Training average positive_sample_loss at step 4500: 2.204608\n",
      "2022-11-08 08:45:10,681 INFO     Training average negative_sample_loss at step 4500: 0.964832\n",
      "2022-11-08 08:45:10,681 INFO     Training average loss at step 4500: 1.584720\n",
      "2022-11-08 08:45:13,844 INFO     Training average positive_sample_loss at step 4600: 2.106212\n",
      "2022-11-08 08:45:13,844 INFO     Training average negative_sample_loss at step 4600: 0.976529\n",
      "2022-11-08 08:45:13,844 INFO     Training average loss at step 4600: 1.541371\n",
      "2022-11-08 08:45:17,004 INFO     Training average positive_sample_loss at step 4700: 2.149787\n",
      "2022-11-08 08:45:17,004 INFO     Training average negative_sample_loss at step 4700: 0.981267\n",
      "2022-11-08 08:45:17,004 INFO     Training average loss at step 4700: 1.565527\n",
      "2022-11-08 08:45:20,147 INFO     Training average positive_sample_loss at step 4800: 2.147239\n",
      "2022-11-08 08:45:20,147 INFO     Training average negative_sample_loss at step 4800: 0.980564\n",
      "2022-11-08 08:45:20,147 INFO     Training average loss at step 4800: 1.563902\n",
      "2022-11-08 08:45:23,297 INFO     Training average positive_sample_loss at step 4900: 2.153757\n",
      "2022-11-08 08:45:23,297 INFO     Training average negative_sample_loss at step 4900: 0.975198\n",
      "2022-11-08 08:45:23,297 INFO     Training average loss at step 4900: 1.564477\n",
      "2022-11-08 08:45:26,536 INFO     Training average positive_sample_loss at step 5000: 2.200726\n",
      "2022-11-08 08:45:26,536 INFO     Training average negative_sample_loss at step 5000: 0.982135\n",
      "2022-11-08 08:45:26,536 INFO     Training average loss at step 5000: 1.591431\n",
      "2022-11-08 08:45:29,800 INFO     Training average positive_sample_loss at step 5100: 2.141867\n",
      "2022-11-08 08:45:29,800 INFO     Training average negative_sample_loss at step 5100: 0.995260\n",
      "2022-11-08 08:45:29,800 INFO     Training average loss at step 5100: 1.568564\n",
      "2022-11-08 08:45:33,075 INFO     Training average positive_sample_loss at step 5200: 2.128290\n",
      "2022-11-08 08:45:33,075 INFO     Training average negative_sample_loss at step 5200: 1.001655\n",
      "2022-11-08 08:45:33,075 INFO     Training average loss at step 5200: 1.564973\n",
      "2022-11-08 08:45:36,350 INFO     Training average positive_sample_loss at step 5300: 2.120916\n",
      "2022-11-08 08:45:36,350 INFO     Training average negative_sample_loss at step 5300: 0.987146\n",
      "2022-11-08 08:45:36,350 INFO     Training average loss at step 5300: 1.554031\n",
      "2022-11-08 08:45:39,534 INFO     Training average positive_sample_loss at step 5400: 2.138316\n",
      "2022-11-08 08:45:39,534 INFO     Training average negative_sample_loss at step 5400: 0.997350\n",
      "2022-11-08 08:45:39,534 INFO     Training average loss at step 5400: 1.567833\n",
      "2022-11-08 08:45:42,804 INFO     Training average positive_sample_loss at step 5500: 2.162959\n",
      "2022-11-08 08:45:42,805 INFO     Training average negative_sample_loss at step 5500: 0.997286\n",
      "2022-11-08 08:45:42,805 INFO     Training average loss at step 5500: 1.580122\n",
      "2022-11-08 08:45:46,041 INFO     Training average positive_sample_loss at step 5600: 2.124240\n",
      "2022-11-08 08:45:46,041 INFO     Training average negative_sample_loss at step 5600: 1.009539\n",
      "2022-11-08 08:45:46,041 INFO     Training average loss at step 5600: 1.566889\n",
      "2022-11-08 08:45:49,345 INFO     Training average positive_sample_loss at step 5700: 2.120911\n",
      "2022-11-08 08:45:49,346 INFO     Training average negative_sample_loss at step 5700: 1.005127\n",
      "2022-11-08 08:45:49,346 INFO     Training average loss at step 5700: 1.563019\n",
      "2022-11-08 08:45:52,654 INFO     Training average positive_sample_loss at step 5800: 2.102832\n",
      "2022-11-08 08:45:52,655 INFO     Training average negative_sample_loss at step 5800: 0.999845\n",
      "2022-11-08 08:45:52,655 INFO     Training average loss at step 5800: 1.551339\n",
      "2022-11-08 08:45:55,856 INFO     Training average positive_sample_loss at step 5900: 2.077252\n",
      "2022-11-08 08:45:55,857 INFO     Training average negative_sample_loss at step 5900: 1.009748\n",
      "2022-11-08 08:45:55,857 INFO     Training average loss at step 5900: 1.543500\n",
      "2022-11-08 08:45:59,008 INFO     Training average positive_sample_loss at step 6000: 2.086213\n",
      "2022-11-08 08:45:59,008 INFO     Training average negative_sample_loss at step 6000: 1.021962\n",
      "2022-11-08 08:45:59,008 INFO     Training average loss at step 6000: 1.554087\n",
      "2022-11-08 08:46:02,172 INFO     Training average positive_sample_loss at step 6100: 2.108043\n",
      "2022-11-08 08:46:02,172 INFO     Training average negative_sample_loss at step 6100: 1.013514\n",
      "2022-11-08 08:46:02,172 INFO     Training average loss at step 6100: 1.560778\n",
      "2022-11-08 08:46:05,333 INFO     Training average positive_sample_loss at step 6200: 2.084204\n",
      "2022-11-08 08:46:05,333 INFO     Training average negative_sample_loss at step 6200: 1.018961\n",
      "2022-11-08 08:46:05,333 INFO     Training average loss at step 6200: 1.551582\n",
      "2022-11-08 08:46:08,511 INFO     Training average positive_sample_loss at step 6300: 2.086345\n",
      "2022-11-08 08:46:08,511 INFO     Training average negative_sample_loss at step 6300: 1.017764\n",
      "2022-11-08 08:46:08,511 INFO     Training average loss at step 6300: 1.552054\n",
      "2022-11-08 08:46:11,734 INFO     Training average positive_sample_loss at step 6400: 2.054618\n",
      "2022-11-08 08:46:11,735 INFO     Training average negative_sample_loss at step 6400: 1.027238\n",
      "2022-11-08 08:46:11,735 INFO     Training average loss at step 6400: 1.540928\n",
      "2022-11-08 08:46:14,920 INFO     Training average positive_sample_loss at step 6500: 2.073550\n",
      "2022-11-08 08:46:14,920 INFO     Training average negative_sample_loss at step 6500: 1.020336\n",
      "2022-11-08 08:46:14,920 INFO     Training average loss at step 6500: 1.546943\n",
      "2022-11-08 08:46:18,101 INFO     Training average positive_sample_loss at step 6600: 2.107534\n",
      "2022-11-08 08:46:18,101 INFO     Training average negative_sample_loss at step 6600: 1.020332\n",
      "2022-11-08 08:46:18,101 INFO     Training average loss at step 6600: 1.563933\n",
      "2022-11-08 08:46:21,335 INFO     Training average positive_sample_loss at step 6700: 2.115686\n",
      "2022-11-08 08:46:21,336 INFO     Training average negative_sample_loss at step 6700: 1.021394\n",
      "2022-11-08 08:46:21,336 INFO     Training average loss at step 6700: 1.568540\n",
      "2022-11-08 08:46:24,642 INFO     Training average positive_sample_loss at step 6800: 2.079232\n",
      "2022-11-08 08:46:24,643 INFO     Training average negative_sample_loss at step 6800: 1.021711\n",
      "2022-11-08 08:46:24,643 INFO     Training average loss at step 6800: 1.550471\n",
      "2022-11-08 08:46:27,898 INFO     Training average positive_sample_loss at step 6900: 2.101619\n",
      "2022-11-08 08:46:27,898 INFO     Training average negative_sample_loss at step 6900: 1.022554\n",
      "2022-11-08 08:46:27,898 INFO     Training average loss at step 6900: 1.562086\n",
      "2022-11-08 08:46:31,171 INFO     Training average positive_sample_loss at step 7000: 2.090968\n",
      "2022-11-08 08:46:31,171 INFO     Training average negative_sample_loss at step 7000: 1.021524\n",
      "2022-11-08 08:46:31,171 INFO     Training average loss at step 7000: 1.556246\n",
      "2022-11-08 08:46:34,453 INFO     Training average positive_sample_loss at step 7100: 2.055878\n",
      "2022-11-08 08:46:34,453 INFO     Training average negative_sample_loss at step 7100: 1.018280\n",
      "2022-11-08 08:46:34,453 INFO     Training average loss at step 7100: 1.537079\n",
      "2022-11-08 08:46:37,723 INFO     Training average positive_sample_loss at step 7200: 2.062949\n",
      "2022-11-08 08:46:37,723 INFO     Training average negative_sample_loss at step 7200: 1.020625\n",
      "2022-11-08 08:46:37,723 INFO     Training average loss at step 7200: 1.541787\n",
      "2022-11-08 08:46:40,973 INFO     Training average positive_sample_loss at step 7300: 2.071515\n",
      "2022-11-08 08:46:40,973 INFO     Training average negative_sample_loss at step 7300: 1.024526\n",
      "2022-11-08 08:46:40,973 INFO     Training average loss at step 7300: 1.548021\n",
      "2022-11-08 08:46:44,139 INFO     Training average positive_sample_loss at step 7400: 2.059502\n",
      "2022-11-08 08:46:44,139 INFO     Training average negative_sample_loss at step 7400: 1.032209\n",
      "2022-11-08 08:46:44,139 INFO     Training average loss at step 7400: 1.545856\n",
      "2022-11-08 08:46:47,381 INFO     Training average positive_sample_loss at step 7500: 2.039429\n",
      "2022-11-08 08:46:47,381 INFO     Training average negative_sample_loss at step 7500: 1.041884\n",
      "2022-11-08 08:46:47,381 INFO     Training average loss at step 7500: 1.540656\n",
      "2022-11-08 08:46:50,637 INFO     Training average positive_sample_loss at step 7600: 2.047215\n",
      "2022-11-08 08:46:50,637 INFO     Training average negative_sample_loss at step 7600: 1.032750\n",
      "2022-11-08 08:46:50,637 INFO     Training average loss at step 7600: 1.539982\n",
      "2022-11-08 08:46:53,869 INFO     Training average positive_sample_loss at step 7700: 2.034646\n",
      "2022-11-08 08:46:53,869 INFO     Training average negative_sample_loss at step 7700: 1.035672\n",
      "2022-11-08 08:46:53,869 INFO     Training average loss at step 7700: 1.535159\n",
      "2022-11-08 08:46:57,105 INFO     Training average positive_sample_loss at step 7800: 2.050483\n",
      "2022-11-08 08:46:57,105 INFO     Training average negative_sample_loss at step 7800: 1.029322\n",
      "2022-11-08 08:46:57,105 INFO     Training average loss at step 7800: 1.539903\n",
      "2022-11-08 08:47:00,328 INFO     Training average positive_sample_loss at step 7900: 2.022759\n",
      "2022-11-08 08:47:00,328 INFO     Training average negative_sample_loss at step 7900: 1.031365\n",
      "2022-11-08 08:47:00,328 INFO     Training average loss at step 7900: 1.527062\n",
      "2022-11-08 08:47:03,533 INFO     Training average positive_sample_loss at step 8000: 2.046589\n",
      "2022-11-08 08:47:03,534 INFO     Training average negative_sample_loss at step 8000: 1.035329\n",
      "2022-11-08 08:47:03,534 INFO     Training average loss at step 8000: 1.540959\n",
      "2022-11-08 08:47:06,725 INFO     Training average positive_sample_loss at step 8100: 2.063823\n",
      "2022-11-08 08:47:06,725 INFO     Training average negative_sample_loss at step 8100: 1.031794\n",
      "2022-11-08 08:47:06,725 INFO     Training average loss at step 8100: 1.547809\n",
      "2022-11-08 08:47:09,923 INFO     Training average positive_sample_loss at step 8200: 2.059114\n",
      "2022-11-08 08:47:09,923 INFO     Training average negative_sample_loss at step 8200: 1.036141\n",
      "2022-11-08 08:47:09,923 INFO     Training average loss at step 8200: 1.547628\n",
      "2022-11-08 08:47:13,245 INFO     Training average positive_sample_loss at step 8300: 2.014597\n",
      "2022-11-08 08:47:13,246 INFO     Training average negative_sample_loss at step 8300: 1.039367\n",
      "2022-11-08 08:47:13,246 INFO     Training average loss at step 8300: 1.526982\n",
      "2022-11-08 08:47:16,683 INFO     Training average positive_sample_loss at step 8400: 2.042646\n",
      "2022-11-08 08:47:16,683 INFO     Training average negative_sample_loss at step 8400: 1.036325\n",
      "2022-11-08 08:47:16,683 INFO     Training average loss at step 8400: 1.539486\n",
      "2022-11-08 08:47:20,035 INFO     Training average positive_sample_loss at step 8500: 2.015494\n",
      "2022-11-08 08:47:20,035 INFO     Training average negative_sample_loss at step 8500: 1.035126\n",
      "2022-11-08 08:47:20,035 INFO     Training average loss at step 8500: 1.525310\n",
      "2022-11-08 08:47:23,345 INFO     Training average positive_sample_loss at step 8600: 2.042693\n",
      "2022-11-08 08:47:23,345 INFO     Training average negative_sample_loss at step 8600: 1.027500\n",
      "2022-11-08 08:47:23,345 INFO     Training average loss at step 8600: 1.535096\n",
      "2022-11-08 08:47:26,628 INFO     Training average positive_sample_loss at step 8700: 2.078965\n",
      "2022-11-08 08:47:26,628 INFO     Training average negative_sample_loss at step 8700: 1.038833\n",
      "2022-11-08 08:47:26,628 INFO     Training average loss at step 8700: 1.558899\n",
      "2022-11-08 08:47:29,879 INFO     Training average positive_sample_loss at step 8800: 2.054348\n",
      "2022-11-08 08:47:29,879 INFO     Training average negative_sample_loss at step 8800: 1.039103\n",
      "2022-11-08 08:47:29,879 INFO     Training average loss at step 8800: 1.546725\n",
      "2022-11-08 08:47:33,133 INFO     Training average positive_sample_loss at step 8900: 2.040941\n",
      "2022-11-08 08:47:33,133 INFO     Training average negative_sample_loss at step 8900: 1.041397\n",
      "2022-11-08 08:47:33,133 INFO     Training average loss at step 8900: 1.541169\n",
      "2022-11-08 08:47:36,350 INFO     Training average positive_sample_loss at step 9000: 2.030346\n",
      "2022-11-08 08:47:36,350 INFO     Training average negative_sample_loss at step 9000: 1.041878\n",
      "2022-11-08 08:47:36,350 INFO     Training average loss at step 9000: 1.536112\n",
      "2022-11-08 08:47:39,706 INFO     Training average positive_sample_loss at step 9100: 2.051187\n",
      "2022-11-08 08:47:39,706 INFO     Training average negative_sample_loss at step 9100: 1.037590\n",
      "2022-11-08 08:47:39,706 INFO     Training average loss at step 9100: 1.544389\n",
      "2022-11-08 08:47:42,880 INFO     Training average positive_sample_loss at step 9200: 2.032244\n",
      "2022-11-08 08:47:42,881 INFO     Training average negative_sample_loss at step 9200: 1.042997\n",
      "2022-11-08 08:47:42,881 INFO     Training average loss at step 9200: 1.537620\n",
      "2022-11-08 08:47:46,074 INFO     Training average positive_sample_loss at step 9300: 2.060299\n",
      "2022-11-08 08:47:46,074 INFO     Training average negative_sample_loss at step 9300: 1.031004\n",
      "2022-11-08 08:47:46,074 INFO     Training average loss at step 9300: 1.545651\n",
      "2022-11-08 08:47:49,252 INFO     Training average positive_sample_loss at step 9400: 2.036411\n",
      "2022-11-08 08:47:49,252 INFO     Training average negative_sample_loss at step 9400: 1.044192\n",
      "2022-11-08 08:47:49,252 INFO     Training average loss at step 9400: 1.540301\n",
      "2022-11-08 08:47:52,439 INFO     Training average positive_sample_loss at step 9500: 2.063534\n",
      "2022-11-08 08:47:52,439 INFO     Training average negative_sample_loss at step 9500: 1.032845\n",
      "2022-11-08 08:47:52,439 INFO     Training average loss at step 9500: 1.548189\n",
      "2022-11-08 08:47:55,754 INFO     Training average positive_sample_loss at step 9600: 1.978101\n",
      "2022-11-08 08:47:55,754 INFO     Training average negative_sample_loss at step 9600: 1.038135\n",
      "2022-11-08 08:47:55,754 INFO     Training average loss at step 9600: 1.508118\n",
      "2022-11-08 08:47:59,084 INFO     Training average positive_sample_loss at step 9700: 2.036593\n",
      "2022-11-08 08:47:59,084 INFO     Training average negative_sample_loss at step 9700: 1.049281\n",
      "2022-11-08 08:47:59,084 INFO     Training average loss at step 9700: 1.542937\n",
      "2022-11-08 08:48:02,357 INFO     Training average positive_sample_loss at step 9800: 2.070117\n",
      "2022-11-08 08:48:02,357 INFO     Training average negative_sample_loss at step 9800: 1.032014\n",
      "2022-11-08 08:48:02,357 INFO     Training average loss at step 9800: 1.551065\n",
      "2022-11-08 08:48:05,574 INFO     Training average positive_sample_loss at step 9900: 2.124398\n",
      "2022-11-08 08:48:05,574 INFO     Training average negative_sample_loss at step 9900: 1.026282\n",
      "2022-11-08 08:48:05,574 INFO     Training average loss at step 9900: 1.575340\n",
      "2022-11-08 08:48:11,471 INFO     Training average positive_sample_loss at step 10000: 1.979400\n",
      "2022-11-08 08:48:11,471 INFO     Training average negative_sample_loss at step 10000: 1.050845\n",
      "2022-11-08 08:48:11,472 INFO     Training average loss at step 10000: 1.515123\n",
      "2022-11-08 08:48:14,788 INFO     Training average positive_sample_loss at step 10100: 2.033358\n",
      "2022-11-08 08:48:14,789 INFO     Training average negative_sample_loss at step 10100: 1.037149\n",
      "2022-11-08 08:48:14,789 INFO     Training average loss at step 10100: 1.535254\n",
      "2022-11-08 08:48:17,944 INFO     Training average positive_sample_loss at step 10200: 2.009445\n",
      "2022-11-08 08:48:17,944 INFO     Training average negative_sample_loss at step 10200: 1.038446\n",
      "2022-11-08 08:48:17,944 INFO     Training average loss at step 10200: 1.523946\n",
      "2022-11-08 08:48:24,283 INFO     Training average positive_sample_loss at step 10300: 2.031973\n",
      "2022-11-08 08:48:24,284 INFO     Training average negative_sample_loss at step 10300: 1.039966\n",
      "2022-11-08 08:48:24,284 INFO     Training average loss at step 10300: 1.535970\n",
      "2022-11-08 08:48:27,431 INFO     Training average positive_sample_loss at step 10400: 1.963011\n",
      "2022-11-08 08:48:27,431 INFO     Training average negative_sample_loss at step 10400: 1.056984\n",
      "2022-11-08 08:48:27,431 INFO     Training average loss at step 10400: 1.509998\n",
      "2022-11-08 08:48:30,576 INFO     Training average positive_sample_loss at step 10500: 2.015251\n",
      "2022-11-08 08:48:30,576 INFO     Training average negative_sample_loss at step 10500: 1.047797\n",
      "2022-11-08 08:48:30,576 INFO     Training average loss at step 10500: 1.531524\n",
      "2022-11-08 08:48:33,740 INFO     Training average positive_sample_loss at step 10600: 2.045003\n",
      "2022-11-08 08:48:33,740 INFO     Training average negative_sample_loss at step 10600: 1.044140\n",
      "2022-11-08 08:48:33,740 INFO     Training average loss at step 10600: 1.544571\n",
      "2022-11-08 08:48:36,941 INFO     Training average positive_sample_loss at step 10700: 2.044729\n",
      "2022-11-08 08:48:36,941 INFO     Training average negative_sample_loss at step 10700: 1.040513\n",
      "2022-11-08 08:48:36,941 INFO     Training average loss at step 10700: 1.542621\n",
      "2022-11-08 08:48:40,087 INFO     Training average positive_sample_loss at step 10800: 2.051139\n",
      "2022-11-08 08:48:40,087 INFO     Training average negative_sample_loss at step 10800: 1.045345\n",
      "2022-11-08 08:48:40,088 INFO     Training average loss at step 10800: 1.548242\n",
      "2022-11-08 08:48:43,229 INFO     Training average positive_sample_loss at step 10900: 2.012917\n",
      "2022-11-08 08:48:43,229 INFO     Training average negative_sample_loss at step 10900: 1.042619\n",
      "2022-11-08 08:48:43,229 INFO     Training average loss at step 10900: 1.527768\n",
      "2022-11-08 08:48:46,384 INFO     Training average positive_sample_loss at step 11000: 1.999090\n",
      "2022-11-08 08:48:46,385 INFO     Training average negative_sample_loss at step 11000: 1.059771\n",
      "2022-11-08 08:48:46,385 INFO     Training average loss at step 11000: 1.529431\n",
      "2022-11-08 08:48:49,541 INFO     Training average positive_sample_loss at step 11100: 2.060799\n",
      "2022-11-08 08:48:49,541 INFO     Training average negative_sample_loss at step 11100: 1.025911\n",
      "2022-11-08 08:48:49,541 INFO     Training average loss at step 11100: 1.543355\n",
      "2022-11-08 08:48:52,691 INFO     Training average positive_sample_loss at step 11200: 1.998773\n",
      "2022-11-08 08:48:52,691 INFO     Training average negative_sample_loss at step 11200: 1.038990\n",
      "2022-11-08 08:48:52,691 INFO     Training average loss at step 11200: 1.518882\n",
      "2022-11-08 08:48:55,835 INFO     Training average positive_sample_loss at step 11300: 1.980336\n",
      "2022-11-08 08:48:55,835 INFO     Training average negative_sample_loss at step 11300: 1.049322\n",
      "2022-11-08 08:48:55,835 INFO     Training average loss at step 11300: 1.514829\n",
      "2022-11-08 08:48:58,965 INFO     Training average positive_sample_loss at step 11400: 2.003482\n",
      "2022-11-08 08:48:58,965 INFO     Training average negative_sample_loss at step 11400: 1.044830\n",
      "2022-11-08 08:48:58,965 INFO     Training average loss at step 11400: 1.524156\n",
      "2022-11-08 08:49:02,098 INFO     Training average positive_sample_loss at step 11500: 2.029621\n",
      "2022-11-08 08:49:02,098 INFO     Training average negative_sample_loss at step 11500: 1.047237\n",
      "2022-11-08 08:49:02,098 INFO     Training average loss at step 11500: 1.538429\n",
      "2022-11-08 08:49:05,245 INFO     Training average positive_sample_loss at step 11600: 2.003811\n",
      "2022-11-08 08:49:05,245 INFO     Training average negative_sample_loss at step 11600: 1.058190\n",
      "2022-11-08 08:49:05,245 INFO     Training average loss at step 11600: 1.531000\n",
      "2022-11-08 08:49:08,397 INFO     Training average positive_sample_loss at step 11700: 2.035585\n",
      "2022-11-08 08:49:08,397 INFO     Training average negative_sample_loss at step 11700: 1.046601\n",
      "2022-11-08 08:49:08,397 INFO     Training average loss at step 11700: 1.541093\n",
      "2022-11-08 08:49:11,535 INFO     Training average positive_sample_loss at step 11800: 2.062233\n",
      "2022-11-08 08:49:11,536 INFO     Training average negative_sample_loss at step 11800: 1.034729\n",
      "2022-11-08 08:49:11,536 INFO     Training average loss at step 11800: 1.548481\n",
      "2022-11-08 08:49:14,680 INFO     Training average positive_sample_loss at step 11900: 1.987141\n",
      "2022-11-08 08:49:14,680 INFO     Training average negative_sample_loss at step 11900: 1.051716\n",
      "2022-11-08 08:49:14,680 INFO     Training average loss at step 11900: 1.519428\n",
      "2022-11-08 08:49:17,909 INFO     Training average positive_sample_loss at step 12000: 2.027765\n",
      "2022-11-08 08:49:17,909 INFO     Training average negative_sample_loss at step 12000: 1.042825\n",
      "2022-11-08 08:49:17,909 INFO     Training average loss at step 12000: 1.535295\n",
      "2022-11-08 08:49:21,254 INFO     Training average positive_sample_loss at step 12100: 2.009947\n",
      "2022-11-08 08:49:21,254 INFO     Training average negative_sample_loss at step 12100: 1.036395\n",
      "2022-11-08 08:49:21,254 INFO     Training average loss at step 12100: 1.523171\n",
      "2022-11-08 08:49:24,388 INFO     Training average positive_sample_loss at step 12200: 2.018206\n",
      "2022-11-08 08:49:24,389 INFO     Training average negative_sample_loss at step 12200: 1.034672\n",
      "2022-11-08 08:49:24,389 INFO     Training average loss at step 12200: 1.526439\n",
      "2022-11-08 08:49:27,551 INFO     Training average positive_sample_loss at step 12300: 1.984704\n",
      "2022-11-08 08:49:27,551 INFO     Training average negative_sample_loss at step 12300: 1.041092\n",
      "2022-11-08 08:49:27,551 INFO     Training average loss at step 12300: 1.512898\n",
      "2022-11-08 08:49:30,681 INFO     Training average positive_sample_loss at step 12400: 2.032284\n",
      "2022-11-08 08:49:30,681 INFO     Training average negative_sample_loss at step 12400: 1.039882\n",
      "2022-11-08 08:49:30,681 INFO     Training average loss at step 12400: 1.536083\n",
      "2022-11-08 08:49:33,808 INFO     Training average positive_sample_loss at step 12500: 2.008731\n",
      "2022-11-08 08:49:33,808 INFO     Training average negative_sample_loss at step 12500: 1.045592\n",
      "2022-11-08 08:49:33,808 INFO     Training average loss at step 12500: 1.527162\n",
      "2022-11-08 08:49:36,940 INFO     Training average positive_sample_loss at step 12600: 1.995282\n",
      "2022-11-08 08:49:36,940 INFO     Training average negative_sample_loss at step 12600: 1.050881\n",
      "2022-11-08 08:49:36,941 INFO     Training average loss at step 12600: 1.523082\n",
      "2022-11-08 08:49:40,084 INFO     Training average positive_sample_loss at step 12700: 2.027781\n",
      "2022-11-08 08:49:40,084 INFO     Training average negative_sample_loss at step 12700: 1.043752\n",
      "2022-11-08 08:49:40,084 INFO     Training average loss at step 12700: 1.535767\n",
      "2022-11-08 08:49:43,233 INFO     Training average positive_sample_loss at step 12800: 1.983806\n",
      "2022-11-08 08:49:43,233 INFO     Training average negative_sample_loss at step 12800: 1.039169\n",
      "2022-11-08 08:49:43,233 INFO     Training average loss at step 12800: 1.511487\n",
      "2022-11-08 08:49:46,379 INFO     Training average positive_sample_loss at step 12900: 1.993640\n",
      "2022-11-08 08:49:46,379 INFO     Training average negative_sample_loss at step 12900: 1.046384\n",
      "2022-11-08 08:49:46,379 INFO     Training average loss at step 12900: 1.520012\n",
      "2022-11-08 08:49:49,510 INFO     Training average positive_sample_loss at step 13000: 1.978181\n",
      "2022-11-08 08:49:49,510 INFO     Training average negative_sample_loss at step 13000: 1.053488\n",
      "2022-11-08 08:49:49,510 INFO     Training average loss at step 13000: 1.515835\n",
      "2022-11-08 08:49:52,654 INFO     Training average positive_sample_loss at step 13100: 2.017574\n",
      "2022-11-08 08:49:52,655 INFO     Training average negative_sample_loss at step 13100: 1.034628\n",
      "2022-11-08 08:49:52,655 INFO     Training average loss at step 13100: 1.526101\n",
      "2022-11-08 08:49:55,798 INFO     Training average positive_sample_loss at step 13200: 2.026009\n",
      "2022-11-08 08:49:55,798 INFO     Training average negative_sample_loss at step 13200: 1.036065\n",
      "2022-11-08 08:49:55,798 INFO     Training average loss at step 13200: 1.531037\n",
      "2022-11-08 08:49:58,927 INFO     Training average positive_sample_loss at step 13300: 2.021146\n",
      "2022-11-08 08:49:58,927 INFO     Training average negative_sample_loss at step 13300: 1.040631\n",
      "2022-11-08 08:49:58,927 INFO     Training average loss at step 13300: 1.530888\n",
      "2022-11-08 08:50:02,048 INFO     Training average positive_sample_loss at step 13400: 2.040953\n",
      "2022-11-08 08:50:02,048 INFO     Training average negative_sample_loss at step 13400: 1.046408\n",
      "2022-11-08 08:50:02,048 INFO     Training average loss at step 13400: 1.543681\n",
      "2022-11-08 08:50:05,178 INFO     Training average positive_sample_loss at step 13500: 1.982556\n",
      "2022-11-08 08:50:05,178 INFO     Training average negative_sample_loss at step 13500: 1.043329\n",
      "2022-11-08 08:50:05,179 INFO     Training average loss at step 13500: 1.512942\n",
      "2022-11-08 08:50:08,313 INFO     Training average positive_sample_loss at step 13600: 2.027784\n",
      "2022-11-08 08:50:08,313 INFO     Training average negative_sample_loss at step 13600: 1.046955\n",
      "2022-11-08 08:50:08,313 INFO     Training average loss at step 13600: 1.537370\n",
      "2022-11-08 08:50:11,445 INFO     Training average positive_sample_loss at step 13700: 2.029111\n",
      "2022-11-08 08:50:11,445 INFO     Training average negative_sample_loss at step 13700: 1.045514\n",
      "2022-11-08 08:50:11,445 INFO     Training average loss at step 13700: 1.537313\n",
      "2022-11-08 08:50:14,585 INFO     Training average positive_sample_loss at step 13800: 2.052288\n",
      "2022-11-08 08:50:14,585 INFO     Training average negative_sample_loss at step 13800: 1.037616\n",
      "2022-11-08 08:50:14,585 INFO     Training average loss at step 13800: 1.544952\n",
      "2022-11-08 08:50:17,731 INFO     Training average positive_sample_loss at step 13900: 1.961213\n",
      "2022-11-08 08:50:17,731 INFO     Training average negative_sample_loss at step 13900: 1.044637\n",
      "2022-11-08 08:50:17,731 INFO     Training average loss at step 13900: 1.502925\n",
      "2022-11-08 08:50:20,859 INFO     Training average positive_sample_loss at step 14000: 2.028370\n",
      "2022-11-08 08:50:20,859 INFO     Training average negative_sample_loss at step 14000: 1.047490\n",
      "2022-11-08 08:50:20,859 INFO     Training average loss at step 14000: 1.537930\n",
      "2022-11-08 08:50:24,009 INFO     Training average positive_sample_loss at step 14100: 2.035929\n",
      "2022-11-08 08:50:24,009 INFO     Training average negative_sample_loss at step 14100: 1.043496\n",
      "2022-11-08 08:50:24,009 INFO     Training average loss at step 14100: 1.539712\n",
      "2022-11-08 08:50:27,140 INFO     Training average positive_sample_loss at step 14200: 1.980447\n",
      "2022-11-08 08:50:27,140 INFO     Training average negative_sample_loss at step 14200: 1.058743\n",
      "2022-11-08 08:50:27,141 INFO     Training average loss at step 14200: 1.519595\n",
      "2022-11-08 08:50:30,289 INFO     Training average positive_sample_loss at step 14300: 1.937221\n",
      "2022-11-08 08:50:30,289 INFO     Training average negative_sample_loss at step 14300: 1.053337\n",
      "2022-11-08 08:50:30,289 INFO     Training average loss at step 14300: 1.495279\n",
      "2022-11-08 08:50:33,443 INFO     Training average positive_sample_loss at step 14400: 1.953857\n",
      "2022-11-08 08:50:33,443 INFO     Training average negative_sample_loss at step 14400: 1.045732\n",
      "2022-11-08 08:50:33,443 INFO     Training average loss at step 14400: 1.499795\n",
      "2022-11-08 08:50:36,595 INFO     Training average positive_sample_loss at step 14500: 1.974925\n",
      "2022-11-08 08:50:36,595 INFO     Training average negative_sample_loss at step 14500: 1.043344\n",
      "2022-11-08 08:50:36,595 INFO     Training average loss at step 14500: 1.509134\n",
      "2022-11-08 08:50:39,751 INFO     Training average positive_sample_loss at step 14600: 1.964487\n",
      "2022-11-08 08:50:39,751 INFO     Training average negative_sample_loss at step 14600: 1.050587\n",
      "2022-11-08 08:50:39,752 INFO     Training average loss at step 14600: 1.507537\n",
      "2022-11-08 08:50:42,923 INFO     Training average positive_sample_loss at step 14700: 1.976978\n",
      "2022-11-08 08:50:42,923 INFO     Training average negative_sample_loss at step 14700: 1.044739\n",
      "2022-11-08 08:50:42,923 INFO     Training average loss at step 14700: 1.510859\n",
      "2022-11-08 08:50:46,187 INFO     Training average positive_sample_loss at step 14800: 1.993125\n",
      "2022-11-08 08:50:46,187 INFO     Training average negative_sample_loss at step 14800: 1.042911\n",
      "2022-11-08 08:50:46,187 INFO     Training average loss at step 14800: 1.518018\n",
      "2022-11-08 08:50:50,652 INFO     Training average positive_sample_loss at step 14900: 2.004182\n",
      "2022-11-08 08:50:50,652 INFO     Training average negative_sample_loss at step 14900: 1.032327\n",
      "2022-11-08 08:50:50,652 INFO     Training average loss at step 14900: 1.518255\n",
      "2022-11-08 08:50:56,215 INFO     Training average positive_sample_loss at step 15000: 1.986610\n",
      "2022-11-08 08:50:56,215 INFO     Training average negative_sample_loss at step 15000: 1.045729\n",
      "2022-11-08 08:50:56,215 INFO     Training average loss at step 15000: 1.516170\n",
      "2022-11-08 08:50:59,358 INFO     Training average positive_sample_loss at step 15100: 1.981373\n",
      "2022-11-08 08:50:59,359 INFO     Training average negative_sample_loss at step 15100: 1.040026\n",
      "2022-11-08 08:50:59,359 INFO     Training average loss at step 15100: 1.510699\n",
      "2022-11-08 08:51:02,549 INFO     Training average positive_sample_loss at step 15200: 2.024143\n",
      "2022-11-08 08:51:02,549 INFO     Training average negative_sample_loss at step 15200: 1.035068\n",
      "2022-11-08 08:51:02,549 INFO     Training average loss at step 15200: 1.529605\n",
      "2022-11-08 08:51:05,714 INFO     Training average positive_sample_loss at step 15300: 1.992814\n",
      "2022-11-08 08:51:05,714 INFO     Training average negative_sample_loss at step 15300: 1.037289\n",
      "2022-11-08 08:51:05,714 INFO     Training average loss at step 15300: 1.515052\n",
      "2022-11-08 08:51:08,974 INFO     Training average positive_sample_loss at step 15400: 1.979173\n",
      "2022-11-08 08:51:08,974 INFO     Training average negative_sample_loss at step 15400: 1.058215\n",
      "2022-11-08 08:51:08,974 INFO     Training average loss at step 15400: 1.518694\n",
      "2022-11-08 08:51:12,216 INFO     Training average positive_sample_loss at step 15500: 1.976473\n",
      "2022-11-08 08:51:12,216 INFO     Training average negative_sample_loss at step 15500: 1.050887\n",
      "2022-11-08 08:51:12,216 INFO     Training average loss at step 15500: 1.513680\n",
      "2022-11-08 08:51:15,386 INFO     Training average positive_sample_loss at step 15600: 1.981321\n",
      "2022-11-08 08:51:15,386 INFO     Training average negative_sample_loss at step 15600: 1.043693\n",
      "2022-11-08 08:51:15,386 INFO     Training average loss at step 15600: 1.512507\n",
      "2022-11-08 08:51:18,623 INFO     Training average positive_sample_loss at step 15700: 1.969732\n",
      "2022-11-08 08:51:18,623 INFO     Training average negative_sample_loss at step 15700: 1.056756\n",
      "2022-11-08 08:51:18,623 INFO     Training average loss at step 15700: 1.513244\n",
      "2022-11-08 08:51:21,922 INFO     Training average positive_sample_loss at step 15800: 1.985038\n",
      "2022-11-08 08:51:21,922 INFO     Training average negative_sample_loss at step 15800: 1.044677\n",
      "2022-11-08 08:51:21,923 INFO     Training average loss at step 15800: 1.514857\n",
      "2022-11-08 08:51:25,145 INFO     Training average positive_sample_loss at step 15900: 2.001018\n",
      "2022-11-08 08:51:25,145 INFO     Training average negative_sample_loss at step 15900: 1.040768\n",
      "2022-11-08 08:51:25,145 INFO     Training average loss at step 15900: 1.520893\n",
      "2022-11-08 08:51:28,306 INFO     Training average positive_sample_loss at step 16000: 2.036173\n",
      "2022-11-08 08:51:28,306 INFO     Training average negative_sample_loss at step 16000: 1.029373\n",
      "2022-11-08 08:51:28,306 INFO     Training average loss at step 16000: 1.532773\n",
      "2022-11-08 08:51:31,457 INFO     Training average positive_sample_loss at step 16100: 1.968744\n",
      "2022-11-08 08:51:31,457 INFO     Training average negative_sample_loss at step 16100: 1.043776\n",
      "2022-11-08 08:51:31,457 INFO     Training average loss at step 16100: 1.506260\n",
      "2022-11-08 08:51:34,711 INFO     Training average positive_sample_loss at step 16200: 1.953830\n",
      "2022-11-08 08:51:34,711 INFO     Training average negative_sample_loss at step 16200: 1.044992\n",
      "2022-11-08 08:51:34,711 INFO     Training average loss at step 16200: 1.499411\n",
      "2022-11-08 08:51:37,910 INFO     Training average positive_sample_loss at step 16300: 1.996232\n",
      "2022-11-08 08:51:37,910 INFO     Training average negative_sample_loss at step 16300: 1.044481\n",
      "2022-11-08 08:51:37,910 INFO     Training average loss at step 16300: 1.520356\n",
      "2022-11-08 08:51:41,093 INFO     Training average positive_sample_loss at step 16400: 1.954057\n",
      "2022-11-08 08:51:41,093 INFO     Training average negative_sample_loss at step 16400: 1.036145\n",
      "2022-11-08 08:51:41,093 INFO     Training average loss at step 16400: 1.495101\n",
      "2022-11-08 08:51:44,364 INFO     Training average positive_sample_loss at step 16500: 1.930362\n",
      "2022-11-08 08:51:44,364 INFO     Training average negative_sample_loss at step 16500: 1.046450\n",
      "2022-11-08 08:51:44,364 INFO     Training average loss at step 16500: 1.488406\n",
      "2022-11-08 08:51:47,537 INFO     Training average positive_sample_loss at step 16600: 1.963776\n",
      "2022-11-08 08:51:47,537 INFO     Training average negative_sample_loss at step 16600: 1.040684\n",
      "2022-11-08 08:51:47,537 INFO     Training average loss at step 16600: 1.502230\n",
      "2022-11-08 08:51:50,684 INFO     Training average positive_sample_loss at step 16700: 2.004111\n",
      "2022-11-08 08:51:50,684 INFO     Training average negative_sample_loss at step 16700: 1.033881\n",
      "2022-11-08 08:51:50,684 INFO     Training average loss at step 16700: 1.518996\n",
      "2022-11-08 08:51:53,833 INFO     Training average positive_sample_loss at step 16800: 1.980524\n",
      "2022-11-08 08:51:53,833 INFO     Training average negative_sample_loss at step 16800: 1.038567\n",
      "2022-11-08 08:51:53,833 INFO     Training average loss at step 16800: 1.509546\n",
      "2022-11-08 08:51:56,986 INFO     Training average positive_sample_loss at step 16900: 1.956779\n",
      "2022-11-08 08:51:56,987 INFO     Training average negative_sample_loss at step 16900: 1.032420\n",
      "2022-11-08 08:51:56,987 INFO     Training average loss at step 16900: 1.494600\n",
      "2022-11-08 08:52:00,126 INFO     Training average positive_sample_loss at step 17000: 1.982883\n",
      "2022-11-08 08:52:00,126 INFO     Training average negative_sample_loss at step 17000: 1.038529\n",
      "2022-11-08 08:52:00,126 INFO     Training average loss at step 17000: 1.510706\n",
      "2022-11-08 08:52:03,266 INFO     Training average positive_sample_loss at step 17100: 1.960920\n",
      "2022-11-08 08:52:03,267 INFO     Training average negative_sample_loss at step 17100: 1.034151\n",
      "2022-11-08 08:52:03,267 INFO     Training average loss at step 17100: 1.497536\n",
      "2022-11-08 08:52:06,426 INFO     Training average positive_sample_loss at step 17200: 1.965063\n",
      "2022-11-08 08:52:06,426 INFO     Training average negative_sample_loss at step 17200: 1.041623\n",
      "2022-11-08 08:52:06,427 INFO     Training average loss at step 17200: 1.503343\n",
      "2022-11-08 08:52:09,589 INFO     Training average positive_sample_loss at step 17300: 1.982153\n",
      "2022-11-08 08:52:09,589 INFO     Training average negative_sample_loss at step 17300: 1.034986\n",
      "2022-11-08 08:52:09,589 INFO     Training average loss at step 17300: 1.508569\n",
      "2022-11-08 08:52:12,737 INFO     Training average positive_sample_loss at step 17400: 2.021316\n",
      "2022-11-08 08:52:12,737 INFO     Training average negative_sample_loss at step 17400: 1.045511\n",
      "2022-11-08 08:52:12,737 INFO     Training average loss at step 17400: 1.533414\n",
      "2022-11-08 08:52:15,888 INFO     Training average positive_sample_loss at step 17500: 1.977049\n",
      "2022-11-08 08:52:15,889 INFO     Training average negative_sample_loss at step 17500: 1.043487\n",
      "2022-11-08 08:52:15,889 INFO     Training average loss at step 17500: 1.510268\n",
      "2022-11-08 08:52:19,049 INFO     Training average positive_sample_loss at step 17600: 1.997200\n",
      "2022-11-08 08:52:19,050 INFO     Training average negative_sample_loss at step 17600: 1.041532\n",
      "2022-11-08 08:52:19,050 INFO     Training average loss at step 17600: 1.519366\n",
      "2022-11-08 08:52:22,191 INFO     Training average positive_sample_loss at step 17700: 2.000228\n",
      "2022-11-08 08:52:22,191 INFO     Training average negative_sample_loss at step 17700: 1.041346\n",
      "2022-11-08 08:52:22,191 INFO     Training average loss at step 17700: 1.520787\n",
      "2022-11-08 08:52:25,343 INFO     Training average positive_sample_loss at step 17800: 1.964092\n",
      "2022-11-08 08:52:25,343 INFO     Training average negative_sample_loss at step 17800: 1.034216\n",
      "2022-11-08 08:52:25,343 INFO     Training average loss at step 17800: 1.499154\n",
      "2022-11-08 08:52:28,490 INFO     Training average positive_sample_loss at step 17900: 1.947292\n",
      "2022-11-08 08:52:28,490 INFO     Training average negative_sample_loss at step 17900: 1.038441\n",
      "2022-11-08 08:52:28,491 INFO     Training average loss at step 17900: 1.492867\n",
      "2022-11-08 08:52:31,646 INFO     Training average positive_sample_loss at step 18000: 1.969764\n",
      "2022-11-08 08:52:31,647 INFO     Training average negative_sample_loss at step 18000: 1.037304\n",
      "2022-11-08 08:52:31,647 INFO     Training average loss at step 18000: 1.503534\n",
      "2022-11-08 08:52:34,804 INFO     Training average positive_sample_loss at step 18100: 1.972169\n",
      "2022-11-08 08:52:34,804 INFO     Training average negative_sample_loss at step 18100: 1.031810\n",
      "2022-11-08 08:52:34,804 INFO     Training average loss at step 18100: 1.501989\n",
      "2022-11-08 08:52:37,950 INFO     Training average positive_sample_loss at step 18200: 1.975701\n",
      "2022-11-08 08:52:37,950 INFO     Training average negative_sample_loss at step 18200: 1.043949\n",
      "2022-11-08 08:52:37,950 INFO     Training average loss at step 18200: 1.509825\n",
      "2022-11-08 08:52:41,094 INFO     Training average positive_sample_loss at step 18300: 1.936240\n",
      "2022-11-08 08:52:41,095 INFO     Training average negative_sample_loss at step 18300: 1.046007\n",
      "2022-11-08 08:52:41,095 INFO     Training average loss at step 18300: 1.491124\n",
      "2022-11-08 08:52:44,222 INFO     Training average positive_sample_loss at step 18400: 1.922837\n",
      "2022-11-08 08:52:44,222 INFO     Training average negative_sample_loss at step 18400: 1.040335\n",
      "2022-11-08 08:52:44,222 INFO     Training average loss at step 18400: 1.481586\n",
      "2022-11-08 08:52:47,368 INFO     Training average positive_sample_loss at step 18500: 1.929064\n",
      "2022-11-08 08:52:47,369 INFO     Training average negative_sample_loss at step 18500: 1.039871\n",
      "2022-11-08 08:52:47,369 INFO     Training average loss at step 18500: 1.484467\n",
      "2022-11-08 08:52:50,511 INFO     Training average positive_sample_loss at step 18600: 1.989779\n",
      "2022-11-08 08:52:50,512 INFO     Training average negative_sample_loss at step 18600: 1.032040\n",
      "2022-11-08 08:52:50,512 INFO     Training average loss at step 18600: 1.510910\n",
      "2022-11-08 08:52:53,654 INFO     Training average positive_sample_loss at step 18700: 1.986710\n",
      "2022-11-08 08:52:53,654 INFO     Training average negative_sample_loss at step 18700: 1.045249\n",
      "2022-11-08 08:52:53,654 INFO     Training average loss at step 18700: 1.515980\n",
      "2022-11-08 08:52:56,805 INFO     Training average positive_sample_loss at step 18800: 1.967543\n",
      "2022-11-08 08:52:56,805 INFO     Training average negative_sample_loss at step 18800: 1.042785\n",
      "2022-11-08 08:52:56,805 INFO     Training average loss at step 18800: 1.505164\n",
      "2022-11-08 08:52:59,961 INFO     Training average positive_sample_loss at step 18900: 2.001940\n",
      "2022-11-08 08:52:59,961 INFO     Training average negative_sample_loss at step 18900: 1.042602\n",
      "2022-11-08 08:52:59,961 INFO     Training average loss at step 18900: 1.522271\n",
      "2022-11-08 08:53:03,110 INFO     Training average positive_sample_loss at step 19000: 1.960306\n",
      "2022-11-08 08:53:03,110 INFO     Training average negative_sample_loss at step 19000: 1.037847\n",
      "2022-11-08 08:53:03,110 INFO     Training average loss at step 19000: 1.499077\n",
      "2022-11-08 08:53:06,318 INFO     Training average positive_sample_loss at step 19100: 1.977122\n",
      "2022-11-08 08:53:06,318 INFO     Training average negative_sample_loss at step 19100: 1.034739\n",
      "2022-11-08 08:53:06,318 INFO     Training average loss at step 19100: 1.505931\n",
      "2022-11-08 08:53:09,484 INFO     Training average positive_sample_loss at step 19200: 1.903172\n",
      "2022-11-08 08:53:09,484 INFO     Training average negative_sample_loss at step 19200: 1.055220\n",
      "2022-11-08 08:53:09,484 INFO     Training average loss at step 19200: 1.479196\n",
      "2022-11-08 08:53:12,680 INFO     Training average positive_sample_loss at step 19300: 1.952115\n",
      "2022-11-08 08:53:12,681 INFO     Training average negative_sample_loss at step 19300: 1.033459\n",
      "2022-11-08 08:53:12,681 INFO     Training average loss at step 19300: 1.492787\n",
      "2022-11-08 08:53:15,894 INFO     Training average positive_sample_loss at step 19400: 1.956965\n",
      "2022-11-08 08:53:15,894 INFO     Training average negative_sample_loss at step 19400: 1.038530\n",
      "2022-11-08 08:53:15,894 INFO     Training average loss at step 19400: 1.497747\n",
      "2022-11-08 08:53:19,082 INFO     Training average positive_sample_loss at step 19500: 2.010580\n",
      "2022-11-08 08:53:19,082 INFO     Training average negative_sample_loss at step 19500: 1.033094\n",
      "2022-11-08 08:53:19,082 INFO     Training average loss at step 19500: 1.521837\n",
      "2022-11-08 08:53:23,465 INFO     Training average positive_sample_loss at step 19600: 1.939719\n",
      "2022-11-08 08:53:23,465 INFO     Training average negative_sample_loss at step 19600: 1.051709\n",
      "2022-11-08 08:53:23,465 INFO     Training average loss at step 19600: 1.495714\n",
      "2022-11-08 08:53:28,902 INFO     Training average positive_sample_loss at step 19700: 1.967132\n",
      "2022-11-08 08:53:28,902 INFO     Training average negative_sample_loss at step 19700: 1.033485\n",
      "2022-11-08 08:53:28,902 INFO     Training average loss at step 19700: 1.500309\n",
      "2022-11-08 08:53:32,161 INFO     Training average positive_sample_loss at step 19800: 1.975236\n",
      "2022-11-08 08:53:32,161 INFO     Training average negative_sample_loss at step 19800: 1.025725\n",
      "2022-11-08 08:53:32,161 INFO     Training average loss at step 19800: 1.500480\n",
      "2022-11-08 08:53:35,310 INFO     Training average positive_sample_loss at step 19900: 1.992996\n",
      "2022-11-08 08:53:35,310 INFO     Training average negative_sample_loss at step 19900: 1.020264\n",
      "2022-11-08 08:53:35,310 INFO     Training average loss at step 19900: 1.506630\n",
      "2022-11-08 08:53:41,275 INFO     Training average positive_sample_loss at step 20000: 1.964132\n",
      "2022-11-08 08:53:41,275 INFO     Training average negative_sample_loss at step 20000: 1.034603\n",
      "2022-11-08 08:53:41,275 INFO     Training average loss at step 20000: 1.499368\n",
      "2022-11-08 08:53:44,442 INFO     Training average positive_sample_loss at step 20100: 2.015284\n",
      "2022-11-08 08:53:44,442 INFO     Training average negative_sample_loss at step 20100: 1.029991\n",
      "2022-11-08 08:53:44,442 INFO     Training average loss at step 20100: 1.522638\n",
      "2022-11-08 08:53:47,602 INFO     Training average positive_sample_loss at step 20200: 1.974798\n",
      "2022-11-08 08:53:47,602 INFO     Training average negative_sample_loss at step 20200: 1.036582\n",
      "2022-11-08 08:53:47,602 INFO     Training average loss at step 20200: 1.505690\n",
      "2022-11-08 08:53:50,768 INFO     Training average positive_sample_loss at step 20300: 1.977882\n",
      "2022-11-08 08:53:50,768 INFO     Training average negative_sample_loss at step 20300: 1.023684\n",
      "2022-11-08 08:53:50,768 INFO     Training average loss at step 20300: 1.500783\n",
      "2022-11-08 08:53:53,945 INFO     Training average positive_sample_loss at step 20400: 1.991243\n",
      "2022-11-08 08:53:53,945 INFO     Training average negative_sample_loss at step 20400: 1.025038\n",
      "2022-11-08 08:53:53,945 INFO     Training average loss at step 20400: 1.508140\n",
      "2022-11-08 08:53:57,093 INFO     Training average positive_sample_loss at step 20500: 1.941990\n",
      "2022-11-08 08:53:57,093 INFO     Training average negative_sample_loss at step 20500: 1.037744\n",
      "2022-11-08 08:53:57,093 INFO     Training average loss at step 20500: 1.489867\n",
      "2022-11-08 08:54:00,231 INFO     Training average positive_sample_loss at step 20600: 1.935432\n",
      "2022-11-08 08:54:00,231 INFO     Training average negative_sample_loss at step 20600: 1.038036\n",
      "2022-11-08 08:54:00,231 INFO     Training average loss at step 20600: 1.486734\n",
      "2022-11-08 08:54:03,377 INFO     Training average positive_sample_loss at step 20700: 1.951626\n",
      "2022-11-08 08:54:03,377 INFO     Training average negative_sample_loss at step 20700: 1.042802\n",
      "2022-11-08 08:54:03,377 INFO     Training average loss at step 20700: 1.497214\n",
      "2022-11-08 08:54:06,537 INFO     Training average positive_sample_loss at step 20800: 1.973562\n",
      "2022-11-08 08:54:06,537 INFO     Training average negative_sample_loss at step 20800: 1.027132\n",
      "2022-11-08 08:54:06,537 INFO     Training average loss at step 20800: 1.500347\n",
      "2022-11-08 08:54:09,683 INFO     Training average positive_sample_loss at step 20900: 1.951570\n",
      "2022-11-08 08:54:09,684 INFO     Training average negative_sample_loss at step 20900: 1.019899\n",
      "2022-11-08 08:54:09,684 INFO     Training average loss at step 20900: 1.485735\n",
      "2022-11-08 08:54:12,838 INFO     Training average positive_sample_loss at step 21000: 1.915512\n",
      "2022-11-08 08:54:12,838 INFO     Training average negative_sample_loss at step 21000: 1.035561\n",
      "2022-11-08 08:54:12,838 INFO     Training average loss at step 21000: 1.475536\n",
      "2022-11-08 08:54:15,991 INFO     Training average positive_sample_loss at step 21100: 1.914268\n",
      "2022-11-08 08:54:15,991 INFO     Training average negative_sample_loss at step 21100: 1.034895\n",
      "2022-11-08 08:54:15,991 INFO     Training average loss at step 21100: 1.474582\n",
      "2022-11-08 08:54:19,125 INFO     Training average positive_sample_loss at step 21200: 1.964231\n",
      "2022-11-08 08:54:19,125 INFO     Training average negative_sample_loss at step 21200: 1.022449\n",
      "2022-11-08 08:54:19,125 INFO     Training average loss at step 21200: 1.493340\n",
      "2022-11-08 08:54:22,266 INFO     Training average positive_sample_loss at step 21300: 1.976927\n",
      "2022-11-08 08:54:22,266 INFO     Training average negative_sample_loss at step 21300: 1.035790\n",
      "2022-11-08 08:54:22,266 INFO     Training average loss at step 21300: 1.506358\n",
      "2022-11-08 08:54:25,473 INFO     Training average positive_sample_loss at step 21400: 1.940288\n",
      "2022-11-08 08:54:25,473 INFO     Training average negative_sample_loss at step 21400: 1.026917\n",
      "2022-11-08 08:54:25,473 INFO     Training average loss at step 21400: 1.483603\n",
      "2022-11-08 08:54:28,787 INFO     Training average positive_sample_loss at step 21500: 1.992840\n",
      "2022-11-08 08:54:28,787 INFO     Training average negative_sample_loss at step 21500: 1.029076\n",
      "2022-11-08 08:54:28,787 INFO     Training average loss at step 21500: 1.510958\n",
      "2022-11-08 08:54:31,942 INFO     Training average positive_sample_loss at step 21600: 1.963800\n",
      "2022-11-08 08:54:31,942 INFO     Training average negative_sample_loss at step 21600: 1.034314\n",
      "2022-11-08 08:54:31,942 INFO     Training average loss at step 21600: 1.499057\n",
      "2022-11-08 08:54:35,089 INFO     Training average positive_sample_loss at step 21700: 1.969381\n",
      "2022-11-08 08:54:35,089 INFO     Training average negative_sample_loss at step 21700: 1.027112\n",
      "2022-11-08 08:54:35,089 INFO     Training average loss at step 21700: 1.498246\n",
      "2022-11-08 08:54:38,226 INFO     Training average positive_sample_loss at step 21800: 1.942349\n",
      "2022-11-08 08:54:38,226 INFO     Training average negative_sample_loss at step 21800: 1.028974\n",
      "2022-11-08 08:54:38,226 INFO     Training average loss at step 21800: 1.485661\n",
      "2022-11-08 08:54:41,372 INFO     Training average positive_sample_loss at step 21900: 1.933176\n",
      "2022-11-08 08:54:41,372 INFO     Training average negative_sample_loss at step 21900: 1.028922\n",
      "2022-11-08 08:54:41,372 INFO     Training average loss at step 21900: 1.481049\n",
      "2022-11-08 08:54:44,533 INFO     Training average positive_sample_loss at step 22000: 1.959334\n",
      "2022-11-08 08:54:44,533 INFO     Training average negative_sample_loss at step 22000: 1.033398\n",
      "2022-11-08 08:54:44,533 INFO     Training average loss at step 22000: 1.496366\n",
      "2022-11-08 08:54:47,691 INFO     Training average positive_sample_loss at step 22100: 1.926959\n",
      "2022-11-08 08:54:47,691 INFO     Training average negative_sample_loss at step 22100: 1.033345\n",
      "2022-11-08 08:54:47,691 INFO     Training average loss at step 22100: 1.480152\n",
      "2022-11-08 08:54:50,847 INFO     Training average positive_sample_loss at step 22200: 1.940175\n",
      "2022-11-08 08:54:50,847 INFO     Training average negative_sample_loss at step 22200: 1.039411\n",
      "2022-11-08 08:54:50,847 INFO     Training average loss at step 22200: 1.489793\n",
      "2022-11-08 08:54:53,997 INFO     Training average positive_sample_loss at step 22300: 1.949024\n",
      "2022-11-08 08:54:53,997 INFO     Training average negative_sample_loss at step 22300: 1.033767\n",
      "2022-11-08 08:54:53,997 INFO     Training average loss at step 22300: 1.491396\n",
      "2022-11-08 08:54:57,152 INFO     Training average positive_sample_loss at step 22400: 1.955129\n",
      "2022-11-08 08:54:57,152 INFO     Training average negative_sample_loss at step 22400: 1.032160\n",
      "2022-11-08 08:54:57,152 INFO     Training average loss at step 22400: 1.493645\n",
      "2022-11-08 08:55:00,280 INFO     Training average positive_sample_loss at step 22500: 1.999174\n",
      "2022-11-08 08:55:00,280 INFO     Training average negative_sample_loss at step 22500: 1.026433\n",
      "2022-11-08 08:55:00,281 INFO     Training average loss at step 22500: 1.512804\n",
      "2022-11-08 08:55:03,421 INFO     Training average positive_sample_loss at step 22600: 1.965557\n",
      "2022-11-08 08:55:03,421 INFO     Training average negative_sample_loss at step 22600: 1.020508\n",
      "2022-11-08 08:55:03,421 INFO     Training average loss at step 22600: 1.493032\n",
      "2022-11-08 08:55:06,573 INFO     Training average positive_sample_loss at step 22700: 1.945800\n",
      "2022-11-08 08:55:06,573 INFO     Training average negative_sample_loss at step 22700: 1.023577\n",
      "2022-11-08 08:55:06,573 INFO     Training average loss at step 22700: 1.484688\n",
      "2022-11-08 08:55:09,736 INFO     Training average positive_sample_loss at step 22800: 1.965084\n",
      "2022-11-08 08:55:09,736 INFO     Training average negative_sample_loss at step 22800: 1.029678\n",
      "2022-11-08 08:55:09,736 INFO     Training average loss at step 22800: 1.497381\n",
      "2022-11-08 08:55:12,886 INFO     Training average positive_sample_loss at step 22900: 1.954745\n",
      "2022-11-08 08:55:12,886 INFO     Training average negative_sample_loss at step 22900: 1.031545\n",
      "2022-11-08 08:55:12,886 INFO     Training average loss at step 22900: 1.493145\n",
      "2022-11-08 08:55:16,064 INFO     Training average positive_sample_loss at step 23000: 1.956345\n",
      "2022-11-08 08:55:16,064 INFO     Training average negative_sample_loss at step 23000: 1.029687\n",
      "2022-11-08 08:55:16,065 INFO     Training average loss at step 23000: 1.493016\n",
      "2022-11-08 08:55:19,218 INFO     Training average positive_sample_loss at step 23100: 1.930408\n",
      "2022-11-08 08:55:19,218 INFO     Training average negative_sample_loss at step 23100: 1.039216\n",
      "2022-11-08 08:55:19,218 INFO     Training average loss at step 23100: 1.484812\n",
      "2022-11-08 08:55:22,357 INFO     Training average positive_sample_loss at step 23200: 1.953938\n",
      "2022-11-08 08:55:22,357 INFO     Training average negative_sample_loss at step 23200: 1.031596\n",
      "2022-11-08 08:55:22,357 INFO     Training average loss at step 23200: 1.492767\n",
      "2022-11-08 08:55:25,505 INFO     Training average positive_sample_loss at step 23300: 1.941884\n",
      "2022-11-08 08:55:25,505 INFO     Training average negative_sample_loss at step 23300: 1.034650\n",
      "2022-11-08 08:55:25,505 INFO     Training average loss at step 23300: 1.488267\n",
      "2022-11-08 08:55:28,647 INFO     Training average positive_sample_loss at step 23400: 1.988869\n",
      "2022-11-08 08:55:28,647 INFO     Training average negative_sample_loss at step 23400: 1.028800\n",
      "2022-11-08 08:55:28,647 INFO     Training average loss at step 23400: 1.508835\n",
      "2022-11-08 08:55:31,812 INFO     Training average positive_sample_loss at step 23500: 1.936094\n",
      "2022-11-08 08:55:31,812 INFO     Training average negative_sample_loss at step 23500: 1.016161\n",
      "2022-11-08 08:55:31,812 INFO     Training average loss at step 23500: 1.476127\n",
      "2022-11-08 08:55:34,982 INFO     Training average positive_sample_loss at step 23600: 1.982172\n",
      "2022-11-08 08:55:34,983 INFO     Training average negative_sample_loss at step 23600: 1.024579\n",
      "2022-11-08 08:55:34,983 INFO     Training average loss at step 23600: 1.503375\n",
      "2022-11-08 08:55:38,153 INFO     Training average positive_sample_loss at step 23700: 1.966474\n",
      "2022-11-08 08:55:38,153 INFO     Training average negative_sample_loss at step 23700: 1.023629\n",
      "2022-11-08 08:55:38,153 INFO     Training average loss at step 23700: 1.495052\n",
      "2022-11-08 08:55:41,311 INFO     Training average positive_sample_loss at step 23800: 1.924254\n",
      "2022-11-08 08:55:41,311 INFO     Training average negative_sample_loss at step 23800: 1.027375\n",
      "2022-11-08 08:55:41,311 INFO     Training average loss at step 23800: 1.475814\n",
      "2022-11-08 08:55:44,489 INFO     Training average positive_sample_loss at step 23900: 1.948696\n",
      "2022-11-08 08:55:44,489 INFO     Training average negative_sample_loss at step 23900: 1.031907\n",
      "2022-11-08 08:55:44,489 INFO     Training average loss at step 23900: 1.490301\n",
      "2022-11-08 08:55:47,640 INFO     Training average positive_sample_loss at step 24000: 1.954930\n",
      "2022-11-08 08:55:47,640 INFO     Training average negative_sample_loss at step 24000: 1.029626\n",
      "2022-11-08 08:55:47,640 INFO     Training average loss at step 24000: 1.492278\n",
      "2022-11-08 08:55:50,796 INFO     Training average positive_sample_loss at step 24100: 1.957434\n",
      "2022-11-08 08:55:50,796 INFO     Training average negative_sample_loss at step 24100: 1.028958\n",
      "2022-11-08 08:55:50,796 INFO     Training average loss at step 24100: 1.493196\n",
      "2022-11-08 08:55:55,606 INFO     Training average positive_sample_loss at step 24200: 1.976895\n",
      "2022-11-08 08:55:55,607 INFO     Training average negative_sample_loss at step 24200: 1.030537\n",
      "2022-11-08 08:55:55,607 INFO     Training average loss at step 24200: 1.503716\n",
      "2022-11-08 08:55:59,964 INFO     Training average positive_sample_loss at step 24300: 1.923027\n",
      "2022-11-08 08:55:59,964 INFO     Training average negative_sample_loss at step 24300: 1.023654\n",
      "2022-11-08 08:55:59,964 INFO     Training average loss at step 24300: 1.473340\n",
      "2022-11-08 08:56:03,917 INFO     Training average positive_sample_loss at step 24400: 1.965681\n",
      "2022-11-08 08:56:03,917 INFO     Training average negative_sample_loss at step 24400: 1.030138\n",
      "2022-11-08 08:56:03,917 INFO     Training average loss at step 24400: 1.497910\n",
      "2022-11-08 08:56:07,114 INFO     Training average positive_sample_loss at step 24500: 1.969773\n",
      "2022-11-08 08:56:07,114 INFO     Training average negative_sample_loss at step 24500: 1.024548\n",
      "2022-11-08 08:56:07,114 INFO     Training average loss at step 24500: 1.497160\n",
      "2022-11-08 08:56:10,274 INFO     Training average positive_sample_loss at step 24600: 2.001370\n",
      "2022-11-08 08:56:10,274 INFO     Training average negative_sample_loss at step 24600: 1.022755\n",
      "2022-11-08 08:56:10,274 INFO     Training average loss at step 24600: 1.512063\n",
      "2022-11-08 08:56:13,435 INFO     Training average positive_sample_loss at step 24700: 1.980329\n",
      "2022-11-08 08:56:13,435 INFO     Training average negative_sample_loss at step 24700: 1.022211\n",
      "2022-11-08 08:56:13,435 INFO     Training average loss at step 24700: 1.501270\n",
      "2022-11-08 08:56:16,631 INFO     Training average positive_sample_loss at step 24800: 1.947376\n",
      "2022-11-08 08:56:16,631 INFO     Training average negative_sample_loss at step 24800: 1.029788\n",
      "2022-11-08 08:56:16,632 INFO     Training average loss at step 24800: 1.488582\n",
      "2022-11-08 08:56:19,779 INFO     Training average positive_sample_loss at step 24900: 1.985458\n",
      "2022-11-08 08:56:19,779 INFO     Training average negative_sample_loss at step 24900: 1.023550\n",
      "2022-11-08 08:56:19,779 INFO     Training average loss at step 24900: 1.504504\n",
      "2022-11-08 08:56:22,929 INFO     Training average positive_sample_loss at step 25000: 1.944111\n",
      "2022-11-08 08:56:22,929 INFO     Training average negative_sample_loss at step 25000: 1.017634\n",
      "2022-11-08 08:56:22,929 INFO     Training average loss at step 25000: 1.480872\n",
      "2022-11-08 08:56:26,095 INFO     Training average positive_sample_loss at step 25100: 1.981179\n",
      "2022-11-08 08:56:26,096 INFO     Training average negative_sample_loss at step 25100: 1.026671\n",
      "2022-11-08 08:56:26,096 INFO     Training average loss at step 25100: 1.503925\n",
      "2022-11-08 08:56:29,249 INFO     Training average positive_sample_loss at step 25200: 1.923933\n",
      "2022-11-08 08:56:29,249 INFO     Training average negative_sample_loss at step 25200: 1.023434\n",
      "2022-11-08 08:56:29,249 INFO     Training average loss at step 25200: 1.473684\n",
      "2022-11-08 08:56:32,401 INFO     Training average positive_sample_loss at step 25300: 1.953949\n",
      "2022-11-08 08:56:32,401 INFO     Training average negative_sample_loss at step 25300: 1.021261\n",
      "2022-11-08 08:56:32,401 INFO     Training average loss at step 25300: 1.487605\n",
      "2022-11-08 08:56:35,570 INFO     Training average positive_sample_loss at step 25400: 1.948701\n",
      "2022-11-08 08:56:35,570 INFO     Training average negative_sample_loss at step 25400: 1.023131\n",
      "2022-11-08 08:56:35,570 INFO     Training average loss at step 25400: 1.485916\n",
      "2022-11-08 08:56:38,705 INFO     Training average positive_sample_loss at step 25500: 2.002510\n",
      "2022-11-08 08:56:38,705 INFO     Training average negative_sample_loss at step 25500: 1.023371\n",
      "2022-11-08 08:56:38,705 INFO     Training average loss at step 25500: 1.512941\n",
      "2022-11-08 08:56:41,857 INFO     Training average positive_sample_loss at step 25600: 1.953501\n",
      "2022-11-08 08:56:41,857 INFO     Training average negative_sample_loss at step 25600: 1.030874\n",
      "2022-11-08 08:56:41,857 INFO     Training average loss at step 25600: 1.492187\n",
      "2022-11-08 08:56:45,024 INFO     Training average positive_sample_loss at step 25700: 1.973075\n",
      "2022-11-08 08:56:45,024 INFO     Training average negative_sample_loss at step 25700: 1.012573\n",
      "2022-11-08 08:56:45,024 INFO     Training average loss at step 25700: 1.492824\n",
      "2022-11-08 08:56:48,192 INFO     Training average positive_sample_loss at step 25800: 1.968977\n",
      "2022-11-08 08:56:48,192 INFO     Training average negative_sample_loss at step 25800: 1.017591\n",
      "2022-11-08 08:56:48,192 INFO     Training average loss at step 25800: 1.493284\n",
      "2022-11-08 08:56:51,353 INFO     Training average positive_sample_loss at step 25900: 1.901410\n",
      "2022-11-08 08:56:51,353 INFO     Training average negative_sample_loss at step 25900: 1.029792\n",
      "2022-11-08 08:56:51,353 INFO     Training average loss at step 25900: 1.465601\n",
      "2022-11-08 08:56:54,523 INFO     Training average positive_sample_loss at step 26000: 1.922717\n",
      "2022-11-08 08:56:54,523 INFO     Training average negative_sample_loss at step 26000: 1.029916\n",
      "2022-11-08 08:56:54,523 INFO     Training average loss at step 26000: 1.476317\n",
      "2022-11-08 08:56:57,671 INFO     Training average positive_sample_loss at step 26100: 1.920442\n",
      "2022-11-08 08:56:57,671 INFO     Training average negative_sample_loss at step 26100: 1.013926\n",
      "2022-11-08 08:56:57,671 INFO     Training average loss at step 26100: 1.467184\n",
      "2022-11-08 08:57:00,805 INFO     Training average positive_sample_loss at step 26200: 1.949443\n",
      "2022-11-08 08:57:00,806 INFO     Training average negative_sample_loss at step 26200: 1.014045\n",
      "2022-11-08 08:57:00,806 INFO     Training average loss at step 26200: 1.481744\n",
      "2022-11-08 08:57:03,952 INFO     Training average positive_sample_loss at step 26300: 1.942264\n",
      "2022-11-08 08:57:03,952 INFO     Training average negative_sample_loss at step 26300: 1.021166\n",
      "2022-11-08 08:57:03,952 INFO     Training average loss at step 26300: 1.481715\n",
      "2022-11-08 08:57:07,113 INFO     Training average positive_sample_loss at step 26400: 1.937981\n",
      "2022-11-08 08:57:07,114 INFO     Training average negative_sample_loss at step 26400: 1.019775\n",
      "2022-11-08 08:57:07,114 INFO     Training average loss at step 26400: 1.478878\n",
      "2022-11-08 08:57:10,275 INFO     Training average positive_sample_loss at step 26500: 1.978833\n",
      "2022-11-08 08:57:10,275 INFO     Training average negative_sample_loss at step 26500: 1.023574\n",
      "2022-11-08 08:57:10,275 INFO     Training average loss at step 26500: 1.501203\n",
      "2022-11-08 08:57:13,444 INFO     Training average positive_sample_loss at step 26600: 1.922731\n",
      "2022-11-08 08:57:13,444 INFO     Training average negative_sample_loss at step 26600: 1.016684\n",
      "2022-11-08 08:57:13,444 INFO     Training average loss at step 26600: 1.469708\n",
      "2022-11-08 08:57:16,623 INFO     Training average positive_sample_loss at step 26700: 1.931417\n",
      "2022-11-08 08:57:16,623 INFO     Training average negative_sample_loss at step 26700: 1.027814\n",
      "2022-11-08 08:57:16,623 INFO     Training average loss at step 26700: 1.479616\n",
      "2022-11-08 08:57:19,763 INFO     Training average positive_sample_loss at step 26800: 1.982777\n",
      "2022-11-08 08:57:19,764 INFO     Training average negative_sample_loss at step 26800: 1.004783\n",
      "2022-11-08 08:57:19,764 INFO     Training average loss at step 26800: 1.493780\n",
      "2022-11-08 08:57:22,898 INFO     Training average positive_sample_loss at step 26900: 1.943532\n",
      "2022-11-08 08:57:22,898 INFO     Training average negative_sample_loss at step 26900: 1.010644\n",
      "2022-11-08 08:57:22,898 INFO     Training average loss at step 26900: 1.477088\n",
      "2022-11-08 08:57:26,081 INFO     Training average positive_sample_loss at step 27000: 1.973448\n",
      "2022-11-08 08:57:26,081 INFO     Training average negative_sample_loss at step 27000: 1.021331\n",
      "2022-11-08 08:57:26,081 INFO     Training average loss at step 27000: 1.497389\n",
      "2022-11-08 08:57:29,234 INFO     Training average positive_sample_loss at step 27100: 1.965996\n",
      "2022-11-08 08:57:29,234 INFO     Training average negative_sample_loss at step 27100: 1.020503\n",
      "2022-11-08 08:57:29,234 INFO     Training average loss at step 27100: 1.493249\n",
      "2022-11-08 08:57:32,392 INFO     Training average positive_sample_loss at step 27200: 1.943364\n",
      "2022-11-08 08:57:32,392 INFO     Training average negative_sample_loss at step 27200: 1.020363\n",
      "2022-11-08 08:57:32,392 INFO     Training average loss at step 27200: 1.481864\n",
      "2022-11-08 08:57:35,557 INFO     Training average positive_sample_loss at step 27300: 1.937807\n",
      "2022-11-08 08:57:35,557 INFO     Training average negative_sample_loss at step 27300: 1.021720\n",
      "2022-11-08 08:57:35,557 INFO     Training average loss at step 27300: 1.479763\n",
      "2022-11-08 08:57:38,702 INFO     Training average positive_sample_loss at step 27400: 1.930447\n",
      "2022-11-08 08:57:38,702 INFO     Training average negative_sample_loss at step 27400: 1.016123\n",
      "2022-11-08 08:57:38,702 INFO     Training average loss at step 27400: 1.473285\n",
      "2022-11-08 08:57:41,840 INFO     Training average positive_sample_loss at step 27500: 1.945226\n",
      "2022-11-08 08:57:41,840 INFO     Training average negative_sample_loss at step 27500: 1.010265\n",
      "2022-11-08 08:57:41,840 INFO     Training average loss at step 27500: 1.477746\n",
      "2022-11-08 08:57:44,991 INFO     Training average positive_sample_loss at step 27600: 1.970047\n",
      "2022-11-08 08:57:44,992 INFO     Training average negative_sample_loss at step 27600: 1.009048\n",
      "2022-11-08 08:57:44,992 INFO     Training average loss at step 27600: 1.489547\n",
      "2022-11-08 08:57:48,164 INFO     Training average positive_sample_loss at step 27700: 1.870177\n",
      "2022-11-08 08:57:48,164 INFO     Training average negative_sample_loss at step 27700: 1.029949\n",
      "2022-11-08 08:57:48,164 INFO     Training average loss at step 27700: 1.450063\n",
      "2022-11-08 08:57:51,304 INFO     Training average positive_sample_loss at step 27800: 1.923805\n",
      "2022-11-08 08:57:51,304 INFO     Training average negative_sample_loss at step 27800: 1.019336\n",
      "2022-11-08 08:57:51,304 INFO     Training average loss at step 27800: 1.471570\n",
      "2022-11-08 08:57:54,466 INFO     Training average positive_sample_loss at step 27900: 1.977953\n",
      "2022-11-08 08:57:54,466 INFO     Training average negative_sample_loss at step 27900: 1.013929\n",
      "2022-11-08 08:57:54,466 INFO     Training average loss at step 27900: 1.495941\n",
      "2022-11-08 08:57:57,642 INFO     Training average positive_sample_loss at step 28000: 1.948793\n",
      "2022-11-08 08:57:57,642 INFO     Training average negative_sample_loss at step 28000: 1.005766\n",
      "2022-11-08 08:57:57,642 INFO     Training average loss at step 28000: 1.477280\n",
      "2022-11-08 08:58:00,802 INFO     Training average positive_sample_loss at step 28100: 1.885469\n",
      "2022-11-08 08:58:00,803 INFO     Training average negative_sample_loss at step 28100: 1.022072\n",
      "2022-11-08 08:58:00,803 INFO     Training average loss at step 28100: 1.453771\n",
      "2022-11-08 08:58:03,958 INFO     Training average positive_sample_loss at step 28200: 1.948891\n",
      "2022-11-08 08:58:03,958 INFO     Training average negative_sample_loss at step 28200: 1.007283\n",
      "2022-11-08 08:58:03,958 INFO     Training average loss at step 28200: 1.478087\n",
      "2022-11-08 08:58:07,117 INFO     Training average positive_sample_loss at step 28300: 1.928561\n",
      "2022-11-08 08:58:07,117 INFO     Training average negative_sample_loss at step 28300: 1.004638\n",
      "2022-11-08 08:58:07,117 INFO     Training average loss at step 28300: 1.466600\n",
      "2022-11-08 08:58:10,271 INFO     Training average positive_sample_loss at step 28400: 1.923523\n",
      "2022-11-08 08:58:10,271 INFO     Training average negative_sample_loss at step 28400: 1.021544\n",
      "2022-11-08 08:58:10,271 INFO     Training average loss at step 28400: 1.472533\n",
      "2022-11-08 08:58:13,423 INFO     Training average positive_sample_loss at step 28500: 2.000548\n",
      "2022-11-08 08:58:13,423 INFO     Training average negative_sample_loss at step 28500: 1.007291\n",
      "2022-11-08 08:58:13,423 INFO     Training average loss at step 28500: 1.503920\n",
      "2022-11-08 08:58:16,586 INFO     Training average positive_sample_loss at step 28600: 1.976954\n",
      "2022-11-08 08:58:16,586 INFO     Training average negative_sample_loss at step 28600: 1.012736\n",
      "2022-11-08 08:58:16,586 INFO     Training average loss at step 28600: 1.494845\n",
      "2022-11-08 08:58:19,755 INFO     Training average positive_sample_loss at step 28700: 1.946478\n",
      "2022-11-08 08:58:19,755 INFO     Training average negative_sample_loss at step 28700: 1.005265\n",
      "2022-11-08 08:58:19,755 INFO     Training average loss at step 28700: 1.475871\n",
      "2022-11-08 08:58:25,340 INFO     Training average positive_sample_loss at step 28800: 1.923563\n",
      "2022-11-08 08:58:25,340 INFO     Training average negative_sample_loss at step 28800: 1.013861\n",
      "2022-11-08 08:58:25,340 INFO     Training average loss at step 28800: 1.468712\n",
      "2022-11-08 08:58:29,629 INFO     Training average positive_sample_loss at step 28900: 1.872610\n",
      "2022-11-08 08:58:29,629 INFO     Training average negative_sample_loss at step 28900: 1.028401\n",
      "2022-11-08 08:58:29,629 INFO     Training average loss at step 28900: 1.450506\n",
      "2022-11-08 08:58:32,786 INFO     Training average positive_sample_loss at step 29000: 1.901003\n",
      "2022-11-08 08:58:32,786 INFO     Training average negative_sample_loss at step 29000: 1.013347\n",
      "2022-11-08 08:58:32,786 INFO     Training average loss at step 29000: 1.457175\n",
      "2022-11-08 08:58:35,937 INFO     Training average positive_sample_loss at step 29100: 1.906021\n",
      "2022-11-08 08:58:35,937 INFO     Training average negative_sample_loss at step 29100: 1.008494\n",
      "2022-11-08 08:58:35,937 INFO     Training average loss at step 29100: 1.457258\n",
      "2022-11-08 08:58:39,104 INFO     Training average positive_sample_loss at step 29200: 1.923964\n",
      "2022-11-08 08:58:39,104 INFO     Training average negative_sample_loss at step 29200: 1.009612\n",
      "2022-11-08 08:58:39,104 INFO     Training average loss at step 29200: 1.466788\n",
      "2022-11-08 08:58:42,249 INFO     Training average positive_sample_loss at step 29300: 1.930405\n",
      "2022-11-08 08:58:42,249 INFO     Training average negative_sample_loss at step 29300: 1.009583\n",
      "2022-11-08 08:58:42,250 INFO     Training average loss at step 29300: 1.469994\n",
      "2022-11-08 08:58:45,403 INFO     Training average positive_sample_loss at step 29400: 1.972618\n",
      "2022-11-08 08:58:45,404 INFO     Training average negative_sample_loss at step 29400: 1.010137\n",
      "2022-11-08 08:58:45,404 INFO     Training average loss at step 29400: 1.491378\n",
      "2022-11-08 08:58:48,548 INFO     Training average positive_sample_loss at step 29500: 1.941881\n",
      "2022-11-08 08:58:48,548 INFO     Training average negative_sample_loss at step 29500: 1.012489\n",
      "2022-11-08 08:58:48,548 INFO     Training average loss at step 29500: 1.477185\n",
      "2022-11-08 08:58:51,720 INFO     Training average positive_sample_loss at step 29600: 1.895357\n",
      "2022-11-08 08:58:51,720 INFO     Training average negative_sample_loss at step 29600: 1.013691\n",
      "2022-11-08 08:58:51,720 INFO     Training average loss at step 29600: 1.454524\n",
      "2022-11-08 08:58:54,871 INFO     Training average positive_sample_loss at step 29700: 1.905211\n",
      "2022-11-08 08:58:54,871 INFO     Training average negative_sample_loss at step 29700: 1.024913\n",
      "2022-11-08 08:58:54,871 INFO     Training average loss at step 29700: 1.465062\n",
      "2022-11-08 08:58:58,041 INFO     Training average positive_sample_loss at step 29800: 1.921566\n",
      "2022-11-08 08:58:58,041 INFO     Training average negative_sample_loss at step 29800: 1.008553\n",
      "2022-11-08 08:58:58,042 INFO     Training average loss at step 29800: 1.465059\n",
      "2022-11-08 08:59:01,226 INFO     Training average positive_sample_loss at step 29900: 1.950089\n",
      "2022-11-08 08:59:01,226 INFO     Training average negative_sample_loss at step 29900: 1.009248\n",
      "2022-11-08 08:59:01,226 INFO     Training average loss at step 29900: 1.479669\n",
      "2022-11-08 08:59:07,185 INFO     Training average positive_sample_loss at step 30000: 1.916587\n",
      "2022-11-08 08:59:07,186 INFO     Training average negative_sample_loss at step 30000: 1.014841\n",
      "2022-11-08 08:59:07,186 INFO     Training average loss at step 30000: 1.465714\n",
      "2022-11-08 08:59:10,390 INFO     Training average positive_sample_loss at step 30100: 1.937629\n",
      "2022-11-08 08:59:10,390 INFO     Training average negative_sample_loss at step 30100: 1.004925\n",
      "2022-11-08 08:59:10,390 INFO     Training average loss at step 30100: 1.471277\n",
      "2022-11-08 08:59:13,585 INFO     Training average positive_sample_loss at step 30200: 1.899920\n",
      "2022-11-08 08:59:13,585 INFO     Training average negative_sample_loss at step 30200: 1.009729\n",
      "2022-11-08 08:59:13,585 INFO     Training average loss at step 30200: 1.454824\n",
      "2022-11-08 08:59:16,811 INFO     Training average positive_sample_loss at step 30300: 1.896315\n",
      "2022-11-08 08:59:16,811 INFO     Training average negative_sample_loss at step 30300: 1.017904\n",
      "2022-11-08 08:59:16,811 INFO     Training average loss at step 30300: 1.457109\n",
      "2022-11-08 08:59:20,040 INFO     Training average positive_sample_loss at step 30400: 1.930774\n",
      "2022-11-08 08:59:20,041 INFO     Training average negative_sample_loss at step 30400: 1.008595\n",
      "2022-11-08 08:59:20,041 INFO     Training average loss at step 30400: 1.469684\n",
      "2022-11-08 08:59:23,190 INFO     Training average positive_sample_loss at step 30500: 1.933424\n",
      "2022-11-08 08:59:23,190 INFO     Training average negative_sample_loss at step 30500: 1.005587\n",
      "2022-11-08 08:59:23,190 INFO     Training average loss at step 30500: 1.469506\n",
      "2022-11-08 08:59:26,411 INFO     Training average positive_sample_loss at step 30600: 1.907146\n",
      "2022-11-08 08:59:26,411 INFO     Training average negative_sample_loss at step 30600: 1.021497\n",
      "2022-11-08 08:59:26,411 INFO     Training average loss at step 30600: 1.464321\n",
      "2022-11-08 08:59:29,612 INFO     Training average positive_sample_loss at step 30700: 1.944170\n",
      "2022-11-08 08:59:29,612 INFO     Training average negative_sample_loss at step 30700: 1.001204\n",
      "2022-11-08 08:59:29,612 INFO     Training average loss at step 30700: 1.472687\n",
      "2022-11-08 08:59:33,013 INFO     Training average positive_sample_loss at step 30800: 1.955577\n",
      "2022-11-08 08:59:33,013 INFO     Training average negative_sample_loss at step 30800: 1.001420\n",
      "2022-11-08 08:59:33,013 INFO     Training average loss at step 30800: 1.478499\n",
      "2022-11-08 08:59:36,293 INFO     Training average positive_sample_loss at step 30900: 1.956962\n",
      "2022-11-08 08:59:36,293 INFO     Training average negative_sample_loss at step 30900: 1.003089\n",
      "2022-11-08 08:59:36,293 INFO     Training average loss at step 30900: 1.480025\n",
      "2022-11-08 08:59:39,499 INFO     Training average positive_sample_loss at step 31000: 1.923722\n",
      "2022-11-08 08:59:39,499 INFO     Training average negative_sample_loss at step 31000: 1.006353\n",
      "2022-11-08 08:59:39,499 INFO     Training average loss at step 31000: 1.465038\n",
      "2022-11-08 08:59:42,721 INFO     Training average positive_sample_loss at step 31100: 1.942791\n",
      "2022-11-08 08:59:42,721 INFO     Training average negative_sample_loss at step 31100: 1.009249\n",
      "2022-11-08 08:59:42,721 INFO     Training average loss at step 31100: 1.476020\n",
      "2022-11-08 08:59:45,946 INFO     Training average positive_sample_loss at step 31200: 1.931261\n",
      "2022-11-08 08:59:45,946 INFO     Training average negative_sample_loss at step 31200: 0.999790\n",
      "2022-11-08 08:59:45,946 INFO     Training average loss at step 31200: 1.465525\n",
      "2022-11-08 08:59:49,209 INFO     Training average positive_sample_loss at step 31300: 1.928192\n",
      "2022-11-08 08:59:49,209 INFO     Training average negative_sample_loss at step 31300: 1.009314\n",
      "2022-11-08 08:59:49,209 INFO     Training average loss at step 31300: 1.468753\n",
      "2022-11-08 08:59:52,387 INFO     Training average positive_sample_loss at step 31400: 1.918040\n",
      "2022-11-08 08:59:52,387 INFO     Training average negative_sample_loss at step 31400: 1.018990\n",
      "2022-11-08 08:59:52,387 INFO     Training average loss at step 31400: 1.468515\n",
      "2022-11-08 08:59:55,558 INFO     Training average positive_sample_loss at step 31500: 1.927463\n",
      "2022-11-08 08:59:55,558 INFO     Training average negative_sample_loss at step 31500: 1.000366\n",
      "2022-11-08 08:59:55,558 INFO     Training average loss at step 31500: 1.463914\n",
      "2022-11-08 08:59:58,735 INFO     Training average positive_sample_loss at step 31600: 1.918523\n",
      "2022-11-08 08:59:58,735 INFO     Training average negative_sample_loss at step 31600: 0.999108\n",
      "2022-11-08 08:59:58,735 INFO     Training average loss at step 31600: 1.458815\n",
      "2022-11-08 09:00:01,902 INFO     Training average positive_sample_loss at step 31700: 1.934277\n",
      "2022-11-08 09:00:01,902 INFO     Training average negative_sample_loss at step 31700: 1.003872\n",
      "2022-11-08 09:00:01,902 INFO     Training average loss at step 31700: 1.469074\n",
      "2022-11-08 09:00:05,066 INFO     Training average positive_sample_loss at step 31800: 1.928203\n",
      "2022-11-08 09:00:05,066 INFO     Training average negative_sample_loss at step 31800: 1.014918\n",
      "2022-11-08 09:00:05,066 INFO     Training average loss at step 31800: 1.471561\n",
      "2022-11-08 09:00:08,216 INFO     Training average positive_sample_loss at step 31900: 1.858576\n",
      "2022-11-08 09:00:08,216 INFO     Training average negative_sample_loss at step 31900: 1.005894\n",
      "2022-11-08 09:00:08,216 INFO     Training average loss at step 31900: 1.432235\n",
      "2022-11-08 09:00:11,353 INFO     Training average positive_sample_loss at step 32000: 1.937867\n",
      "2022-11-08 09:00:11,353 INFO     Training average negative_sample_loss at step 32000: 1.009737\n",
      "2022-11-08 09:00:11,353 INFO     Training average loss at step 32000: 1.473802\n",
      "2022-11-08 09:00:14,505 INFO     Training average positive_sample_loss at step 32100: 1.922841\n",
      "2022-11-08 09:00:14,505 INFO     Training average negative_sample_loss at step 32100: 0.999465\n",
      "2022-11-08 09:00:14,505 INFO     Training average loss at step 32100: 1.461153\n",
      "2022-11-08 09:00:17,653 INFO     Training average positive_sample_loss at step 32200: 1.919109\n",
      "2022-11-08 09:00:17,653 INFO     Training average negative_sample_loss at step 32200: 1.004060\n",
      "2022-11-08 09:00:17,653 INFO     Training average loss at step 32200: 1.461584\n",
      "2022-11-08 09:00:20,794 INFO     Training average positive_sample_loss at step 32300: 1.907049\n",
      "2022-11-08 09:00:20,794 INFO     Training average negative_sample_loss at step 32300: 1.009096\n",
      "2022-11-08 09:00:20,794 INFO     Training average loss at step 32300: 1.458073\n",
      "2022-11-08 09:00:23,949 INFO     Training average positive_sample_loss at step 32400: 1.956518\n",
      "2022-11-08 09:00:23,949 INFO     Training average negative_sample_loss at step 32400: 1.002647\n",
      "2022-11-08 09:00:23,949 INFO     Training average loss at step 32400: 1.479583\n",
      "2022-11-08 09:00:27,126 INFO     Training average positive_sample_loss at step 32500: 1.893469\n",
      "2022-11-08 09:00:27,126 INFO     Training average negative_sample_loss at step 32500: 1.008925\n",
      "2022-11-08 09:00:27,126 INFO     Training average loss at step 32500: 1.451197\n",
      "2022-11-08 09:00:30,277 INFO     Training average positive_sample_loss at step 32600: 1.895744\n",
      "2022-11-08 09:00:30,277 INFO     Training average negative_sample_loss at step 32600: 1.005958\n",
      "2022-11-08 09:00:30,277 INFO     Training average loss at step 32600: 1.450851\n",
      "2022-11-08 09:00:33,478 INFO     Training average positive_sample_loss at step 32700: 1.887844\n",
      "2022-11-08 09:00:33,478 INFO     Training average negative_sample_loss at step 32700: 1.008887\n",
      "2022-11-08 09:00:33,478 INFO     Training average loss at step 32700: 1.448366\n",
      "2022-11-08 09:00:36,825 INFO     Training average positive_sample_loss at step 32800: 1.928379\n",
      "2022-11-08 09:00:36,825 INFO     Training average negative_sample_loss at step 32800: 0.999890\n",
      "2022-11-08 09:00:36,825 INFO     Training average loss at step 32800: 1.464135\n",
      "2022-11-08 09:00:40,295 INFO     Training average positive_sample_loss at step 32900: 1.891814\n",
      "2022-11-08 09:00:40,295 INFO     Training average negative_sample_loss at step 32900: 1.004026\n",
      "2022-11-08 09:00:40,295 INFO     Training average loss at step 32900: 1.447920\n",
      "2022-11-08 09:00:43,694 INFO     Training average positive_sample_loss at step 33000: 1.870131\n",
      "2022-11-08 09:00:43,694 INFO     Training average negative_sample_loss at step 33000: 1.000242\n",
      "2022-11-08 09:00:43,694 INFO     Training average loss at step 33000: 1.435186\n",
      "2022-11-08 09:00:47,002 INFO     Training average positive_sample_loss at step 33100: 1.900049\n",
      "2022-11-08 09:00:47,003 INFO     Training average negative_sample_loss at step 33100: 0.989871\n",
      "2022-11-08 09:00:47,003 INFO     Training average loss at step 33100: 1.444960\n",
      "2022-11-08 09:00:50,280 INFO     Training average positive_sample_loss at step 33200: 1.908934\n",
      "2022-11-08 09:00:50,280 INFO     Training average negative_sample_loss at step 33200: 1.001182\n",
      "2022-11-08 09:00:50,280 INFO     Training average loss at step 33200: 1.455058\n",
      "2022-11-08 09:00:53,575 INFO     Training average positive_sample_loss at step 33300: 1.900903\n",
      "2022-11-08 09:00:53,575 INFO     Training average negative_sample_loss at step 33300: 0.995977\n",
      "2022-11-08 09:00:53,575 INFO     Training average loss at step 33300: 1.448440\n",
      "2022-11-08 09:00:57,806 INFO     Training average positive_sample_loss at step 33400: 1.926254\n",
      "2022-11-08 09:00:57,806 INFO     Training average negative_sample_loss at step 33400: 1.000242\n",
      "2022-11-08 09:00:57,806 INFO     Training average loss at step 33400: 1.463248\n",
      "2022-11-08 09:01:03,791 INFO     Training average positive_sample_loss at step 33500: 2.005359\n",
      "2022-11-08 09:01:03,791 INFO     Training average negative_sample_loss at step 33500: 0.984332\n",
      "2022-11-08 09:01:03,791 INFO     Training average loss at step 33500: 1.494846\n",
      "2022-11-08 09:01:07,106 INFO     Training average positive_sample_loss at step 33600: 1.903455\n",
      "2022-11-08 09:01:07,106 INFO     Training average negative_sample_loss at step 33600: 1.003963\n",
      "2022-11-08 09:01:07,106 INFO     Training average loss at step 33600: 1.453709\n",
      "2022-11-08 09:01:10,356 INFO     Training average positive_sample_loss at step 33700: 1.934446\n",
      "2022-11-08 09:01:10,356 INFO     Training average negative_sample_loss at step 33700: 0.997033\n",
      "2022-11-08 09:01:10,356 INFO     Training average loss at step 33700: 1.465739\n",
      "2022-11-08 09:01:13,662 INFO     Training average positive_sample_loss at step 33800: 1.907678\n",
      "2022-11-08 09:01:13,662 INFO     Training average negative_sample_loss at step 33800: 0.998817\n",
      "2022-11-08 09:01:13,662 INFO     Training average loss at step 33800: 1.453247\n",
      "2022-11-08 09:01:16,941 INFO     Training average positive_sample_loss at step 33900: 1.895600\n",
      "2022-11-08 09:01:16,941 INFO     Training average negative_sample_loss at step 33900: 0.991254\n",
      "2022-11-08 09:01:16,941 INFO     Training average loss at step 33900: 1.443427\n",
      "2022-11-08 09:01:20,255 INFO     Training average positive_sample_loss at step 34000: 1.960741\n",
      "2022-11-08 09:01:20,255 INFO     Training average negative_sample_loss at step 34000: 0.988613\n",
      "2022-11-08 09:01:20,255 INFO     Training average loss at step 34000: 1.474677\n",
      "2022-11-08 09:01:23,524 INFO     Training average positive_sample_loss at step 34100: 1.922603\n",
      "2022-11-08 09:01:23,524 INFO     Training average negative_sample_loss at step 34100: 0.999914\n",
      "2022-11-08 09:01:23,524 INFO     Training average loss at step 34100: 1.461258\n",
      "2022-11-08 09:01:26,789 INFO     Training average positive_sample_loss at step 34200: 1.921095\n",
      "2022-11-08 09:01:26,789 INFO     Training average negative_sample_loss at step 34200: 1.004984\n",
      "2022-11-08 09:01:26,789 INFO     Training average loss at step 34200: 1.463040\n",
      "2022-11-08 09:01:30,054 INFO     Training average positive_sample_loss at step 34300: 1.880843\n",
      "2022-11-08 09:01:30,054 INFO     Training average negative_sample_loss at step 34300: 0.999175\n",
      "2022-11-08 09:01:30,054 INFO     Training average loss at step 34300: 1.440009\n",
      "2022-11-08 09:01:33,347 INFO     Training average positive_sample_loss at step 34400: 1.934461\n",
      "2022-11-08 09:01:33,347 INFO     Training average negative_sample_loss at step 34400: 0.985427\n",
      "2022-11-08 09:01:33,347 INFO     Training average loss at step 34400: 1.459944\n",
      "2022-11-08 09:01:36,625 INFO     Training average positive_sample_loss at step 34500: 1.878854\n",
      "2022-11-08 09:01:36,625 INFO     Training average negative_sample_loss at step 34500: 0.997806\n",
      "2022-11-08 09:01:36,625 INFO     Training average loss at step 34500: 1.438330\n",
      "2022-11-08 09:01:39,919 INFO     Training average positive_sample_loss at step 34600: 1.933069\n",
      "2022-11-08 09:01:39,919 INFO     Training average negative_sample_loss at step 34600: 0.981539\n",
      "2022-11-08 09:01:39,919 INFO     Training average loss at step 34600: 1.457304\n",
      "2022-11-08 09:01:43,221 INFO     Training average positive_sample_loss at step 34700: 1.938802\n",
      "2022-11-08 09:01:43,221 INFO     Training average negative_sample_loss at step 34700: 0.990000\n",
      "2022-11-08 09:01:43,221 INFO     Training average loss at step 34700: 1.464401\n",
      "2022-11-08 09:01:46,505 INFO     Training average positive_sample_loss at step 34800: 1.923080\n",
      "2022-11-08 09:01:46,505 INFO     Training average negative_sample_loss at step 34800: 0.993729\n",
      "2022-11-08 09:01:46,505 INFO     Training average loss at step 34800: 1.458404\n",
      "2022-11-08 09:01:49,781 INFO     Training average positive_sample_loss at step 34900: 1.908119\n",
      "2022-11-08 09:01:49,781 INFO     Training average negative_sample_loss at step 34900: 0.994054\n",
      "2022-11-08 09:01:49,781 INFO     Training average loss at step 34900: 1.451087\n",
      "2022-11-08 09:01:53,058 INFO     Training average positive_sample_loss at step 35000: 1.890574\n",
      "2022-11-08 09:01:53,058 INFO     Training average negative_sample_loss at step 35000: 0.998383\n",
      "2022-11-08 09:01:53,058 INFO     Training average loss at step 35000: 1.444479\n",
      "2022-11-08 09:01:56,327 INFO     Training average positive_sample_loss at step 35100: 1.906949\n",
      "2022-11-08 09:01:56,328 INFO     Training average negative_sample_loss at step 35100: 0.987226\n",
      "2022-11-08 09:01:56,328 INFO     Training average loss at step 35100: 1.447088\n",
      "2022-11-08 09:01:59,527 INFO     Training average positive_sample_loss at step 35200: 1.871584\n",
      "2022-11-08 09:01:59,527 INFO     Training average negative_sample_loss at step 35200: 0.997757\n",
      "2022-11-08 09:01:59,527 INFO     Training average loss at step 35200: 1.434671\n",
      "2022-11-08 09:02:02,688 INFO     Training average positive_sample_loss at step 35300: 1.905770\n",
      "2022-11-08 09:02:02,688 INFO     Training average negative_sample_loss at step 35300: 0.990525\n",
      "2022-11-08 09:02:02,688 INFO     Training average loss at step 35300: 1.448147\n",
      "2022-11-08 09:02:05,882 INFO     Training average positive_sample_loss at step 35400: 1.876791\n",
      "2022-11-08 09:02:05,882 INFO     Training average negative_sample_loss at step 35400: 1.000073\n",
      "2022-11-08 09:02:05,882 INFO     Training average loss at step 35400: 1.438432\n",
      "2022-11-08 09:02:09,071 INFO     Training average positive_sample_loss at step 35500: 1.911621\n",
      "2022-11-08 09:02:09,071 INFO     Training average negative_sample_loss at step 35500: 0.989087\n",
      "2022-11-08 09:02:09,071 INFO     Training average loss at step 35500: 1.450354\n",
      "2022-11-08 09:02:12,269 INFO     Training average positive_sample_loss at step 35600: 1.892892\n",
      "2022-11-08 09:02:12,269 INFO     Training average negative_sample_loss at step 35600: 1.001516\n",
      "2022-11-08 09:02:12,269 INFO     Training average loss at step 35600: 1.447204\n",
      "2022-11-08 09:02:15,456 INFO     Training average positive_sample_loss at step 35700: 1.891178\n",
      "2022-11-08 09:02:15,456 INFO     Training average negative_sample_loss at step 35700: 0.982505\n",
      "2022-11-08 09:02:15,456 INFO     Training average loss at step 35700: 1.436842\n",
      "2022-11-08 09:02:18,782 INFO     Training average positive_sample_loss at step 35800: 1.901869\n",
      "2022-11-08 09:02:18,783 INFO     Training average negative_sample_loss at step 35800: 0.980361\n",
      "2022-11-08 09:02:18,783 INFO     Training average loss at step 35800: 1.441115\n",
      "2022-11-08 09:02:22,237 INFO     Training average positive_sample_loss at step 35900: 1.915055\n",
      "2022-11-08 09:02:22,237 INFO     Training average negative_sample_loss at step 35900: 0.994708\n",
      "2022-11-08 09:02:22,237 INFO     Training average loss at step 35900: 1.454882\n",
      "2022-11-08 09:02:25,525 INFO     Training average positive_sample_loss at step 36000: 1.891445\n",
      "2022-11-08 09:02:25,525 INFO     Training average negative_sample_loss at step 36000: 0.995552\n",
      "2022-11-08 09:02:25,525 INFO     Training average loss at step 36000: 1.443498\n",
      "2022-11-08 09:02:28,745 INFO     Training average positive_sample_loss at step 36100: 1.968426\n",
      "2022-11-08 09:02:28,745 INFO     Training average negative_sample_loss at step 36100: 0.966586\n",
      "2022-11-08 09:02:28,745 INFO     Training average loss at step 36100: 1.467506\n",
      "2022-11-08 09:02:31,937 INFO     Training average positive_sample_loss at step 36200: 1.872850\n",
      "2022-11-08 09:02:31,937 INFO     Training average negative_sample_loss at step 36200: 0.995779\n",
      "2022-11-08 09:02:31,937 INFO     Training average loss at step 36200: 1.434315\n",
      "2022-11-08 09:02:35,104 INFO     Training average positive_sample_loss at step 36300: 1.861391\n",
      "2022-11-08 09:02:35,104 INFO     Training average negative_sample_loss at step 36300: 0.987133\n",
      "2022-11-08 09:02:35,104 INFO     Training average loss at step 36300: 1.424262\n",
      "2022-11-08 09:02:38,249 INFO     Training average positive_sample_loss at step 36400: 1.876019\n",
      "2022-11-08 09:02:38,250 INFO     Training average negative_sample_loss at step 36400: 0.992735\n",
      "2022-11-08 09:02:38,250 INFO     Training average loss at step 36400: 1.434377\n",
      "2022-11-08 09:02:41,439 INFO     Training average positive_sample_loss at step 36500: 1.859371\n",
      "2022-11-08 09:02:41,440 INFO     Training average negative_sample_loss at step 36500: 0.996192\n",
      "2022-11-08 09:02:41,440 INFO     Training average loss at step 36500: 1.427782\n",
      "2022-11-08 09:02:44,659 INFO     Training average positive_sample_loss at step 36600: 1.903667\n",
      "2022-11-08 09:02:44,659 INFO     Training average negative_sample_loss at step 36600: 0.974732\n",
      "2022-11-08 09:02:44,659 INFO     Training average loss at step 36600: 1.439200\n",
      "2022-11-08 09:02:47,894 INFO     Training average positive_sample_loss at step 36700: 1.963594\n",
      "2022-11-08 09:02:47,894 INFO     Training average negative_sample_loss at step 36700: 0.981296\n",
      "2022-11-08 09:02:47,894 INFO     Training average loss at step 36700: 1.472445\n",
      "2022-11-08 09:02:51,193 INFO     Training average positive_sample_loss at step 36800: 1.865412\n",
      "2022-11-08 09:02:51,193 INFO     Training average negative_sample_loss at step 36800: 0.983788\n",
      "2022-11-08 09:02:51,193 INFO     Training average loss at step 36800: 1.424600\n",
      "2022-11-08 09:02:54,459 INFO     Training average positive_sample_loss at step 36900: 1.844202\n",
      "2022-11-08 09:02:54,460 INFO     Training average negative_sample_loss at step 36900: 0.987857\n",
      "2022-11-08 09:02:54,460 INFO     Training average loss at step 36900: 1.416029\n",
      "2022-11-08 09:02:57,719 INFO     Training average positive_sample_loss at step 37000: 1.913591\n",
      "2022-11-08 09:02:57,720 INFO     Training average negative_sample_loss at step 37000: 0.981785\n",
      "2022-11-08 09:02:57,720 INFO     Training average loss at step 37000: 1.447688\n",
      "2022-11-08 09:03:00,958 INFO     Training average positive_sample_loss at step 37100: 1.953071\n",
      "2022-11-08 09:03:00,958 INFO     Training average negative_sample_loss at step 37100: 0.972054\n",
      "2022-11-08 09:03:00,958 INFO     Training average loss at step 37100: 1.462562\n",
      "2022-11-08 09:03:04,185 INFO     Training average positive_sample_loss at step 37200: 1.906576\n",
      "2022-11-08 09:03:04,185 INFO     Training average negative_sample_loss at step 37200: 0.975396\n",
      "2022-11-08 09:03:04,185 INFO     Training average loss at step 37200: 1.440986\n",
      "2022-11-08 09:03:07,455 INFO     Training average positive_sample_loss at step 37300: 1.878027\n",
      "2022-11-08 09:03:07,455 INFO     Training average negative_sample_loss at step 37300: 0.974469\n",
      "2022-11-08 09:03:07,455 INFO     Training average loss at step 37300: 1.426248\n",
      "2022-11-08 09:03:10,815 INFO     Training average positive_sample_loss at step 37400: 1.867593\n",
      "2022-11-08 09:03:10,815 INFO     Training average negative_sample_loss at step 37400: 0.992330\n",
      "2022-11-08 09:03:10,815 INFO     Training average loss at step 37400: 1.429962\n",
      "2022-11-08 09:03:14,147 INFO     Training average positive_sample_loss at step 37500: 1.917404\n",
      "2022-11-08 09:03:14,147 INFO     Training average negative_sample_loss at step 37500: 0.976838\n",
      "2022-11-08 09:03:14,147 INFO     Training average loss at step 37500: 1.447121\n",
      "2022-11-08 09:03:17,430 INFO     Training average positive_sample_loss at step 37600: 1.934533\n",
      "2022-11-08 09:03:17,431 INFO     Training average negative_sample_loss at step 37600: 0.973590\n",
      "2022-11-08 09:03:17,431 INFO     Training average loss at step 37600: 1.454061\n",
      "2022-11-08 09:03:20,925 INFO     Training average positive_sample_loss at step 37700: 1.861965\n",
      "2022-11-08 09:03:20,925 INFO     Training average negative_sample_loss at step 37700: 0.982268\n",
      "2022-11-08 09:03:20,925 INFO     Training average loss at step 37700: 1.422117\n",
      "2022-11-08 09:03:24,188 INFO     Training average positive_sample_loss at step 37800: 1.948939\n",
      "2022-11-08 09:03:24,188 INFO     Training average negative_sample_loss at step 37800: 0.978757\n",
      "2022-11-08 09:03:24,188 INFO     Training average loss at step 37800: 1.463848\n",
      "2022-11-08 09:03:27,383 INFO     Training average positive_sample_loss at step 37900: 1.857368\n",
      "2022-11-08 09:03:27,383 INFO     Training average negative_sample_loss at step 37900: 0.985814\n",
      "2022-11-08 09:03:27,383 INFO     Training average loss at step 37900: 1.421591\n",
      "2022-11-08 09:03:31,512 INFO     Training average positive_sample_loss at step 38000: 1.901012\n",
      "2022-11-08 09:03:31,512 INFO     Training average negative_sample_loss at step 38000: 0.968472\n",
      "2022-11-08 09:03:31,512 INFO     Training average loss at step 38000: 1.434742\n",
      "2022-11-08 09:03:35,773 INFO     Training average positive_sample_loss at step 38100: 1.870579\n",
      "2022-11-08 09:03:35,774 INFO     Training average negative_sample_loss at step 38100: 0.981862\n",
      "2022-11-08 09:03:35,774 INFO     Training average loss at step 38100: 1.426221\n",
      "2022-11-08 09:03:40,611 INFO     Training average positive_sample_loss at step 38200: 1.856846\n",
      "2022-11-08 09:03:40,611 INFO     Training average negative_sample_loss at step 38200: 0.975096\n",
      "2022-11-08 09:03:40,611 INFO     Training average loss at step 38200: 1.415971\n",
      "2022-11-08 09:03:43,869 INFO     Training average positive_sample_loss at step 38300: 1.912885\n",
      "2022-11-08 09:03:43,869 INFO     Training average negative_sample_loss at step 38300: 0.977179\n",
      "2022-11-08 09:03:43,869 INFO     Training average loss at step 38300: 1.445032\n",
      "2022-11-08 09:03:47,125 INFO     Training average positive_sample_loss at step 38400: 1.919217\n",
      "2022-11-08 09:03:47,125 INFO     Training average negative_sample_loss at step 38400: 0.974647\n",
      "2022-11-08 09:03:47,125 INFO     Training average loss at step 38400: 1.446932\n",
      "2022-11-08 09:03:50,391 INFO     Training average positive_sample_loss at step 38500: 1.854165\n",
      "2022-11-08 09:03:50,391 INFO     Training average negative_sample_loss at step 38500: 0.987903\n",
      "2022-11-08 09:03:50,391 INFO     Training average loss at step 38500: 1.421034\n",
      "2022-11-08 09:03:53,615 INFO     Training average positive_sample_loss at step 38600: 1.875219\n",
      "2022-11-08 09:03:53,615 INFO     Training average negative_sample_loss at step 38600: 0.977851\n",
      "2022-11-08 09:03:53,615 INFO     Training average loss at step 38600: 1.426535\n",
      "2022-11-08 09:03:56,894 INFO     Training average positive_sample_loss at step 38700: 1.872129\n",
      "2022-11-08 09:03:56,894 INFO     Training average negative_sample_loss at step 38700: 0.977601\n",
      "2022-11-08 09:03:56,894 INFO     Training average loss at step 38700: 1.424865\n",
      "2022-11-08 09:04:00,059 INFO     Training average positive_sample_loss at step 38800: 1.908310\n",
      "2022-11-08 09:04:00,059 INFO     Training average negative_sample_loss at step 38800: 0.969487\n",
      "2022-11-08 09:04:00,059 INFO     Training average loss at step 38800: 1.438899\n",
      "2022-11-08 09:04:03,216 INFO     Training average positive_sample_loss at step 38900: 1.896110\n",
      "2022-11-08 09:04:03,216 INFO     Training average negative_sample_loss at step 38900: 0.974774\n",
      "2022-11-08 09:04:03,216 INFO     Training average loss at step 38900: 1.435442\n",
      "2022-11-08 09:04:06,396 INFO     Training average positive_sample_loss at step 39000: 1.849326\n",
      "2022-11-08 09:04:06,396 INFO     Training average negative_sample_loss at step 39000: 0.975410\n",
      "2022-11-08 09:04:06,396 INFO     Training average loss at step 39000: 1.412368\n",
      "2022-11-08 09:04:09,578 INFO     Training average positive_sample_loss at step 39100: 1.951400\n",
      "2022-11-08 09:04:09,578 INFO     Training average negative_sample_loss at step 39100: 0.974424\n",
      "2022-11-08 09:04:09,578 INFO     Training average loss at step 39100: 1.462912\n",
      "2022-11-08 09:04:12,821 INFO     Training average positive_sample_loss at step 39200: 1.856157\n",
      "2022-11-08 09:04:12,821 INFO     Training average negative_sample_loss at step 39200: 0.988034\n",
      "2022-11-08 09:04:12,821 INFO     Training average loss at step 39200: 1.422095\n",
      "2022-11-08 09:04:15,987 INFO     Training average positive_sample_loss at step 39300: 1.874992\n",
      "2022-11-08 09:04:15,987 INFO     Training average negative_sample_loss at step 39300: 0.974717\n",
      "2022-11-08 09:04:15,987 INFO     Training average loss at step 39300: 1.424855\n",
      "2022-11-08 09:04:19,136 INFO     Training average positive_sample_loss at step 39400: 1.866534\n",
      "2022-11-08 09:04:19,136 INFO     Training average negative_sample_loss at step 39400: 0.972152\n",
      "2022-11-08 09:04:19,136 INFO     Training average loss at step 39400: 1.419343\n",
      "2022-11-08 09:04:22,292 INFO     Training average positive_sample_loss at step 39500: 1.884897\n",
      "2022-11-08 09:04:22,292 INFO     Training average negative_sample_loss at step 39500: 0.981616\n",
      "2022-11-08 09:04:22,292 INFO     Training average loss at step 39500: 1.433257\n",
      "2022-11-08 09:04:25,474 INFO     Training average positive_sample_loss at step 39600: 1.811879\n",
      "2022-11-08 09:04:25,474 INFO     Training average negative_sample_loss at step 39600: 0.980401\n",
      "2022-11-08 09:04:25,474 INFO     Training average loss at step 39600: 1.396140\n",
      "2022-11-08 09:04:28,782 INFO     Training average positive_sample_loss at step 39700: 1.882274\n",
      "2022-11-08 09:04:28,782 INFO     Training average negative_sample_loss at step 39700: 0.978686\n",
      "2022-11-08 09:04:28,782 INFO     Training average loss at step 39700: 1.430480\n",
      "2022-11-08 09:04:32,031 INFO     Training average positive_sample_loss at step 39800: 1.834343\n",
      "2022-11-08 09:04:32,031 INFO     Training average negative_sample_loss at step 39800: 0.971816\n",
      "2022-11-08 09:04:32,031 INFO     Training average loss at step 39800: 1.403079\n",
      "2022-11-08 09:04:35,240 INFO     Training average positive_sample_loss at step 39900: 1.896390\n",
      "2022-11-08 09:04:35,240 INFO     Training average negative_sample_loss at step 39900: 0.968452\n",
      "2022-11-08 09:04:35,241 INFO     Training average loss at step 39900: 1.432421\n",
      "2022-11-08 09:04:41,235 INFO     Training average positive_sample_loss at step 40000: 1.872663\n",
      "2022-11-08 09:04:41,235 INFO     Training average negative_sample_loss at step 40000: 0.981094\n",
      "2022-11-08 09:04:41,235 INFO     Training average loss at step 40000: 1.426878\n",
      "2022-11-08 09:04:44,483 INFO     Training average positive_sample_loss at step 40100: 1.851452\n",
      "2022-11-08 09:04:44,483 INFO     Training average negative_sample_loss at step 40100: 0.973764\n",
      "2022-11-08 09:04:44,483 INFO     Training average loss at step 40100: 1.412608\n",
      "2022-11-08 09:04:47,710 INFO     Training average positive_sample_loss at step 40200: 1.889700\n",
      "2022-11-08 09:04:47,710 INFO     Training average negative_sample_loss at step 40200: 0.979276\n",
      "2022-11-08 09:04:47,710 INFO     Training average loss at step 40200: 1.434488\n",
      "2022-11-08 09:04:50,941 INFO     Training average positive_sample_loss at step 40300: 1.916129\n",
      "2022-11-08 09:04:50,941 INFO     Training average negative_sample_loss at step 40300: 0.969840\n",
      "2022-11-08 09:04:50,941 INFO     Training average loss at step 40300: 1.442984\n",
      "2022-11-08 09:04:54,146 INFO     Training average positive_sample_loss at step 40400: 1.900595\n",
      "2022-11-08 09:04:54,146 INFO     Training average negative_sample_loss at step 40400: 0.961442\n",
      "2022-11-08 09:04:54,146 INFO     Training average loss at step 40400: 1.431018\n",
      "2022-11-08 09:04:57,349 INFO     Training average positive_sample_loss at step 40500: 1.876434\n",
      "2022-11-08 09:04:57,349 INFO     Training average negative_sample_loss at step 40500: 0.971986\n",
      "2022-11-08 09:04:57,349 INFO     Training average loss at step 40500: 1.424210\n",
      "2022-11-08 09:05:00,507 INFO     Training average positive_sample_loss at step 40600: 1.854439\n",
      "2022-11-08 09:05:00,507 INFO     Training average negative_sample_loss at step 40600: 0.977468\n",
      "2022-11-08 09:05:00,507 INFO     Training average loss at step 40600: 1.415953\n",
      "2022-11-08 09:05:03,670 INFO     Training average positive_sample_loss at step 40700: 1.905382\n",
      "2022-11-08 09:05:03,670 INFO     Training average negative_sample_loss at step 40700: 0.962534\n",
      "2022-11-08 09:05:03,670 INFO     Training average loss at step 40700: 1.433958\n",
      "2022-11-08 09:05:06,825 INFO     Training average positive_sample_loss at step 40800: 1.862555\n",
      "2022-11-08 09:05:06,825 INFO     Training average negative_sample_loss at step 40800: 0.964434\n",
      "2022-11-08 09:05:06,825 INFO     Training average loss at step 40800: 1.413495\n",
      "2022-11-08 09:05:09,973 INFO     Training average positive_sample_loss at step 40900: 1.863517\n",
      "2022-11-08 09:05:09,973 INFO     Training average negative_sample_loss at step 40900: 0.972486\n",
      "2022-11-08 09:05:09,973 INFO     Training average loss at step 40900: 1.418001\n",
      "2022-11-08 09:05:13,131 INFO     Training average positive_sample_loss at step 41000: 1.828183\n",
      "2022-11-08 09:05:13,131 INFO     Training average negative_sample_loss at step 41000: 0.972558\n",
      "2022-11-08 09:05:13,131 INFO     Training average loss at step 41000: 1.400371\n",
      "2022-11-08 09:05:16,289 INFO     Training average positive_sample_loss at step 41100: 1.854119\n",
      "2022-11-08 09:05:16,289 INFO     Training average negative_sample_loss at step 41100: 0.965739\n",
      "2022-11-08 09:05:16,289 INFO     Training average loss at step 41100: 1.409929\n",
      "2022-11-08 09:05:19,440 INFO     Training average positive_sample_loss at step 41200: 1.868430\n",
      "2022-11-08 09:05:19,440 INFO     Training average negative_sample_loss at step 41200: 0.974811\n",
      "2022-11-08 09:05:19,440 INFO     Training average loss at step 41200: 1.421621\n",
      "2022-11-08 09:05:22,605 INFO     Training average positive_sample_loss at step 41300: 1.925420\n",
      "2022-11-08 09:05:22,605 INFO     Training average negative_sample_loss at step 41300: 0.953640\n",
      "2022-11-08 09:05:22,605 INFO     Training average loss at step 41300: 1.439530\n",
      "2022-11-08 09:05:25,761 INFO     Training average positive_sample_loss at step 41400: 1.866019\n",
      "2022-11-08 09:05:25,761 INFO     Training average negative_sample_loss at step 41400: 0.977078\n",
      "2022-11-08 09:05:25,761 INFO     Training average loss at step 41400: 1.421548\n",
      "2022-11-08 09:05:28,913 INFO     Training average positive_sample_loss at step 41500: 1.839393\n",
      "2022-11-08 09:05:28,913 INFO     Training average negative_sample_loss at step 41500: 0.970140\n",
      "2022-11-08 09:05:28,913 INFO     Training average loss at step 41500: 1.404766\n",
      "2022-11-08 09:05:32,069 INFO     Training average positive_sample_loss at step 41600: 1.868322\n",
      "2022-11-08 09:05:32,069 INFO     Training average negative_sample_loss at step 41600: 0.970207\n",
      "2022-11-08 09:05:32,069 INFO     Training average loss at step 41600: 1.419264\n",
      "2022-11-08 09:05:35,224 INFO     Training average positive_sample_loss at step 41700: 1.878959\n",
      "2022-11-08 09:05:35,224 INFO     Training average negative_sample_loss at step 41700: 0.960801\n",
      "2022-11-08 09:05:35,224 INFO     Training average loss at step 41700: 1.419880\n",
      "2022-11-08 09:05:38,386 INFO     Training average positive_sample_loss at step 41800: 1.874512\n",
      "2022-11-08 09:05:38,386 INFO     Training average negative_sample_loss at step 41800: 0.950413\n",
      "2022-11-08 09:05:38,386 INFO     Training average loss at step 41800: 1.412462\n",
      "2022-11-08 09:05:41,577 INFO     Training average positive_sample_loss at step 41900: 1.889340\n",
      "2022-11-08 09:05:41,577 INFO     Training average negative_sample_loss at step 41900: 0.952404\n",
      "2022-11-08 09:05:41,577 INFO     Training average loss at step 41900: 1.420872\n",
      "2022-11-08 09:05:44,754 INFO     Training average positive_sample_loss at step 42000: 1.893243\n",
      "2022-11-08 09:05:44,754 INFO     Training average negative_sample_loss at step 42000: 0.946159\n",
      "2022-11-08 09:05:44,754 INFO     Training average loss at step 42000: 1.419701\n",
      "2022-11-08 09:05:47,905 INFO     Training average positive_sample_loss at step 42100: 1.894877\n",
      "2022-11-08 09:05:47,905 INFO     Training average negative_sample_loss at step 42100: 0.959375\n",
      "2022-11-08 09:05:47,905 INFO     Training average loss at step 42100: 1.427126\n",
      "2022-11-08 09:05:51,054 INFO     Training average positive_sample_loss at step 42200: 1.890420\n",
      "2022-11-08 09:05:51,054 INFO     Training average negative_sample_loss at step 42200: 0.956956\n",
      "2022-11-08 09:05:51,054 INFO     Training average loss at step 42200: 1.423688\n",
      "2022-11-08 09:05:54,216 INFO     Training average positive_sample_loss at step 42300: 1.896275\n",
      "2022-11-08 09:05:54,216 INFO     Training average negative_sample_loss at step 42300: 0.953169\n",
      "2022-11-08 09:05:54,216 INFO     Training average loss at step 42300: 1.424722\n",
      "2022-11-08 09:05:57,379 INFO     Training average positive_sample_loss at step 42400: 1.886399\n",
      "2022-11-08 09:05:57,379 INFO     Training average negative_sample_loss at step 42400: 0.955017\n",
      "2022-11-08 09:05:57,379 INFO     Training average loss at step 42400: 1.420708\n",
      "2022-11-08 09:06:01,431 INFO     Training average positive_sample_loss at step 42500: 1.873507\n",
      "2022-11-08 09:06:01,431 INFO     Training average negative_sample_loss at step 42500: 0.960971\n",
      "2022-11-08 09:06:01,431 INFO     Training average loss at step 42500: 1.417239\n",
      "2022-11-08 09:06:04,607 INFO     Training average positive_sample_loss at step 42600: 1.855152\n",
      "2022-11-08 09:06:04,607 INFO     Training average negative_sample_loss at step 42600: 0.962434\n",
      "2022-11-08 09:06:04,607 INFO     Training average loss at step 42600: 1.408793\n",
      "2022-11-08 09:06:08,757 INFO     Training average positive_sample_loss at step 42700: 1.833188\n",
      "2022-11-08 09:06:08,757 INFO     Training average negative_sample_loss at step 42700: 0.957458\n",
      "2022-11-08 09:06:08,757 INFO     Training average loss at step 42700: 1.395323\n",
      "2022-11-08 09:06:13,977 INFO     Training average positive_sample_loss at step 42800: 1.876984\n",
      "2022-11-08 09:06:13,977 INFO     Training average negative_sample_loss at step 42800: 0.962720\n",
      "2022-11-08 09:06:13,977 INFO     Training average loss at step 42800: 1.419852\n",
      "2022-11-08 09:06:18,325 INFO     Training average positive_sample_loss at step 42900: 1.861899\n",
      "2022-11-08 09:06:18,325 INFO     Training average negative_sample_loss at step 42900: 0.957134\n",
      "2022-11-08 09:06:18,325 INFO     Training average loss at step 42900: 1.409517\n",
      "2022-11-08 09:06:21,558 INFO     Training average positive_sample_loss at step 43000: 1.850510\n",
      "2022-11-08 09:06:21,559 INFO     Training average negative_sample_loss at step 43000: 0.950500\n",
      "2022-11-08 09:06:21,559 INFO     Training average loss at step 43000: 1.400505\n",
      "2022-11-08 09:06:24,800 INFO     Training average positive_sample_loss at step 43100: 1.839419\n",
      "2022-11-08 09:06:24,800 INFO     Training average negative_sample_loss at step 43100: 0.962734\n",
      "2022-11-08 09:06:24,800 INFO     Training average loss at step 43100: 1.401076\n",
      "2022-11-08 09:06:27,962 INFO     Training average positive_sample_loss at step 43200: 1.858133\n",
      "2022-11-08 09:06:27,962 INFO     Training average negative_sample_loss at step 43200: 0.956525\n",
      "2022-11-08 09:06:27,962 INFO     Training average loss at step 43200: 1.407329\n",
      "2022-11-08 09:06:31,250 INFO     Training average positive_sample_loss at step 43300: 1.925041\n",
      "2022-11-08 09:06:31,250 INFO     Training average negative_sample_loss at step 43300: 0.952869\n",
      "2022-11-08 09:06:31,250 INFO     Training average loss at step 43300: 1.438955\n",
      "2022-11-08 09:06:34,414 INFO     Training average positive_sample_loss at step 43400: 1.863751\n",
      "2022-11-08 09:06:34,414 INFO     Training average negative_sample_loss at step 43400: 0.952918\n",
      "2022-11-08 09:06:34,414 INFO     Training average loss at step 43400: 1.408335\n",
      "2022-11-08 09:06:37,576 INFO     Training average positive_sample_loss at step 43500: 1.832930\n",
      "2022-11-08 09:06:37,576 INFO     Training average negative_sample_loss at step 43500: 0.959263\n",
      "2022-11-08 09:06:37,576 INFO     Training average loss at step 43500: 1.396096\n",
      "2022-11-08 09:06:40,743 INFO     Training average positive_sample_loss at step 43600: 1.888688\n",
      "2022-11-08 09:06:40,743 INFO     Training average negative_sample_loss at step 43600: 0.942222\n",
      "2022-11-08 09:06:40,743 INFO     Training average loss at step 43600: 1.415455\n",
      "2022-11-08 09:06:43,901 INFO     Training average positive_sample_loss at step 43700: 1.859564\n",
      "2022-11-08 09:06:43,901 INFO     Training average negative_sample_loss at step 43700: 0.944269\n",
      "2022-11-08 09:06:43,901 INFO     Training average loss at step 43700: 1.401917\n",
      "2022-11-08 09:06:47,095 INFO     Training average positive_sample_loss at step 43800: 1.858588\n",
      "2022-11-08 09:06:47,095 INFO     Training average negative_sample_loss at step 43800: 0.951819\n",
      "2022-11-08 09:06:47,095 INFO     Training average loss at step 43800: 1.405204\n",
      "2022-11-08 09:06:50,245 INFO     Training average positive_sample_loss at step 43900: 1.835388\n",
      "2022-11-08 09:06:50,246 INFO     Training average negative_sample_loss at step 43900: 0.958892\n",
      "2022-11-08 09:06:50,246 INFO     Training average loss at step 43900: 1.397140\n",
      "2022-11-08 09:06:53,421 INFO     Training average positive_sample_loss at step 44000: 1.836804\n",
      "2022-11-08 09:06:53,421 INFO     Training average negative_sample_loss at step 44000: 0.948788\n",
      "2022-11-08 09:06:53,421 INFO     Training average loss at step 44000: 1.392796\n",
      "2022-11-08 09:06:56,726 INFO     Training average positive_sample_loss at step 44100: 1.827495\n",
      "2022-11-08 09:06:56,727 INFO     Training average negative_sample_loss at step 44100: 0.952705\n",
      "2022-11-08 09:06:56,727 INFO     Training average loss at step 44100: 1.390100\n",
      "2022-11-08 09:06:59,876 INFO     Training average positive_sample_loss at step 44200: 1.866878\n",
      "2022-11-08 09:06:59,876 INFO     Training average negative_sample_loss at step 44200: 0.949198\n",
      "2022-11-08 09:06:59,876 INFO     Training average loss at step 44200: 1.408038\n",
      "2022-11-08 09:07:03,153 INFO     Training average positive_sample_loss at step 44300: 1.839566\n",
      "2022-11-08 09:07:03,154 INFO     Training average negative_sample_loss at step 44300: 0.949514\n",
      "2022-11-08 09:07:03,154 INFO     Training average loss at step 44300: 1.394540\n",
      "2022-11-08 09:07:06,355 INFO     Training average positive_sample_loss at step 44400: 1.836396\n",
      "2022-11-08 09:07:06,355 INFO     Training average negative_sample_loss at step 44400: 0.953138\n",
      "2022-11-08 09:07:06,355 INFO     Training average loss at step 44400: 1.394767\n",
      "2022-11-08 09:07:09,563 INFO     Training average positive_sample_loss at step 44500: 1.897756\n",
      "2022-11-08 09:07:09,563 INFO     Training average negative_sample_loss at step 44500: 0.949489\n",
      "2022-11-08 09:07:09,563 INFO     Training average loss at step 44500: 1.423623\n",
      "2022-11-08 09:07:12,722 INFO     Training average positive_sample_loss at step 44600: 1.889113\n",
      "2022-11-08 09:07:12,722 INFO     Training average negative_sample_loss at step 44600: 0.947570\n",
      "2022-11-08 09:07:12,722 INFO     Training average loss at step 44600: 1.418341\n",
      "2022-11-08 09:07:15,873 INFO     Training average positive_sample_loss at step 44700: 1.914245\n",
      "2022-11-08 09:07:15,873 INFO     Training average negative_sample_loss at step 44700: 0.947984\n",
      "2022-11-08 09:07:15,874 INFO     Training average loss at step 44700: 1.431114\n",
      "2022-11-08 09:07:19,039 INFO     Training average positive_sample_loss at step 44800: 1.828235\n",
      "2022-11-08 09:07:19,039 INFO     Training average negative_sample_loss at step 44800: 0.953732\n",
      "2022-11-08 09:07:19,039 INFO     Training average loss at step 44800: 1.390983\n",
      "2022-11-08 09:07:22,184 INFO     Training average positive_sample_loss at step 44900: 1.806689\n",
      "2022-11-08 09:07:22,184 INFO     Training average negative_sample_loss at step 44900: 0.940805\n",
      "2022-11-08 09:07:22,184 INFO     Training average loss at step 44900: 1.373747\n",
      "2022-11-08 09:07:25,314 INFO     Training average positive_sample_loss at step 45000: 1.891984\n",
      "2022-11-08 09:07:25,314 INFO     Training average negative_sample_loss at step 45000: 0.948507\n",
      "2022-11-08 09:07:25,315 INFO     Training average loss at step 45000: 1.420245\n",
      "2022-11-08 09:07:28,461 INFO     Training average positive_sample_loss at step 45100: 1.810363\n",
      "2022-11-08 09:07:28,461 INFO     Training average negative_sample_loss at step 45100: 0.945581\n",
      "2022-11-08 09:07:28,461 INFO     Training average loss at step 45100: 1.377972\n",
      "2022-11-08 09:07:31,629 INFO     Training average positive_sample_loss at step 45200: 1.856193\n",
      "2022-11-08 09:07:31,629 INFO     Training average negative_sample_loss at step 45200: 0.932319\n",
      "2022-11-08 09:07:31,629 INFO     Training average loss at step 45200: 1.394256\n",
      "2022-11-08 09:07:34,776 INFO     Training average positive_sample_loss at step 45300: 1.840801\n",
      "2022-11-08 09:07:34,776 INFO     Training average negative_sample_loss at step 45300: 0.960627\n",
      "2022-11-08 09:07:34,776 INFO     Training average loss at step 45300: 1.400714\n",
      "2022-11-08 09:07:37,926 INFO     Training average positive_sample_loss at step 45400: 1.814574\n",
      "2022-11-08 09:07:37,926 INFO     Training average negative_sample_loss at step 45400: 0.946889\n",
      "2022-11-08 09:07:37,926 INFO     Training average loss at step 45400: 1.380732\n",
      "2022-11-08 09:07:41,184 INFO     Training average positive_sample_loss at step 45500: 1.828468\n",
      "2022-11-08 09:07:41,185 INFO     Training average negative_sample_loss at step 45500: 0.951938\n",
      "2022-11-08 09:07:41,185 INFO     Training average loss at step 45500: 1.390203\n",
      "2022-11-08 09:07:44,349 INFO     Training average positive_sample_loss at step 45600: 1.787634\n",
      "2022-11-08 09:07:44,349 INFO     Training average negative_sample_loss at step 45600: 0.944972\n",
      "2022-11-08 09:07:44,349 INFO     Training average loss at step 45600: 1.366303\n",
      "2022-11-08 09:07:47,522 INFO     Training average positive_sample_loss at step 45700: 1.817332\n",
      "2022-11-08 09:07:47,522 INFO     Training average negative_sample_loss at step 45700: 0.959553\n",
      "2022-11-08 09:07:47,522 INFO     Training average loss at step 45700: 1.388442\n",
      "2022-11-08 09:07:50,751 INFO     Training average positive_sample_loss at step 45800: 1.839697\n",
      "2022-11-08 09:07:50,751 INFO     Training average negative_sample_loss at step 45800: 0.951807\n",
      "2022-11-08 09:07:50,751 INFO     Training average loss at step 45800: 1.395752\n",
      "2022-11-08 09:07:53,912 INFO     Training average positive_sample_loss at step 45900: 1.834814\n",
      "2022-11-08 09:07:53,912 INFO     Training average negative_sample_loss at step 45900: 0.941268\n",
      "2022-11-08 09:07:53,912 INFO     Training average loss at step 45900: 1.388041\n",
      "2022-11-08 09:07:57,154 INFO     Training average positive_sample_loss at step 46000: 1.820835\n",
      "2022-11-08 09:07:57,154 INFO     Training average negative_sample_loss at step 46000: 0.937367\n",
      "2022-11-08 09:07:57,154 INFO     Training average loss at step 46000: 1.379101\n",
      "2022-11-08 09:08:00,479 INFO     Training average positive_sample_loss at step 46100: 1.883574\n",
      "2022-11-08 09:08:00,479 INFO     Training average negative_sample_loss at step 46100: 0.936741\n",
      "2022-11-08 09:08:00,479 INFO     Training average loss at step 46100: 1.410157\n",
      "2022-11-08 09:08:03,710 INFO     Training average positive_sample_loss at step 46200: 1.767715\n",
      "2022-11-08 09:08:03,710 INFO     Training average negative_sample_loss at step 46200: 0.946454\n",
      "2022-11-08 09:08:03,710 INFO     Training average loss at step 46200: 1.357085\n",
      "2022-11-08 09:08:06,928 INFO     Training average positive_sample_loss at step 46300: 1.848242\n",
      "2022-11-08 09:08:06,928 INFO     Training average negative_sample_loss at step 46300: 0.932439\n",
      "2022-11-08 09:08:06,928 INFO     Training average loss at step 46300: 1.390341\n",
      "2022-11-08 09:08:10,152 INFO     Training average positive_sample_loss at step 46400: 1.872881\n",
      "2022-11-08 09:08:10,152 INFO     Training average negative_sample_loss at step 46400: 0.936049\n",
      "2022-11-08 09:08:10,152 INFO     Training average loss at step 46400: 1.404465\n",
      "2022-11-08 09:08:13,440 INFO     Training average positive_sample_loss at step 46500: 1.837579\n",
      "2022-11-08 09:08:13,440 INFO     Training average negative_sample_loss at step 46500: 0.934115\n",
      "2022-11-08 09:08:13,440 INFO     Training average loss at step 46500: 1.385847\n",
      "2022-11-08 09:08:16,744 INFO     Training average positive_sample_loss at step 46600: 1.792184\n",
      "2022-11-08 09:08:16,744 INFO     Training average negative_sample_loss at step 46600: 0.943901\n",
      "2022-11-08 09:08:16,744 INFO     Training average loss at step 46600: 1.368043\n",
      "2022-11-08 09:08:20,054 INFO     Training average positive_sample_loss at step 46700: 1.853074\n",
      "2022-11-08 09:08:20,054 INFO     Training average negative_sample_loss at step 46700: 0.935831\n",
      "2022-11-08 09:08:20,054 INFO     Training average loss at step 46700: 1.394452\n",
      "2022-11-08 09:08:23,292 INFO     Training average positive_sample_loss at step 46800: 1.815609\n",
      "2022-11-08 09:08:23,292 INFO     Training average negative_sample_loss at step 46800: 0.932901\n",
      "2022-11-08 09:08:23,292 INFO     Training average loss at step 46800: 1.374255\n",
      "2022-11-08 09:08:26,470 INFO     Training average positive_sample_loss at step 46900: 1.841597\n",
      "2022-11-08 09:08:26,471 INFO     Training average negative_sample_loss at step 46900: 0.936226\n",
      "2022-11-08 09:08:26,471 INFO     Training average loss at step 46900: 1.388912\n",
      "2022-11-08 09:08:29,635 INFO     Training average positive_sample_loss at step 47000: 1.812344\n",
      "2022-11-08 09:08:29,635 INFO     Training average negative_sample_loss at step 47000: 0.936703\n",
      "2022-11-08 09:08:29,635 INFO     Training average loss at step 47000: 1.374523\n",
      "2022-11-08 09:08:32,810 INFO     Training average positive_sample_loss at step 47100: 1.873741\n",
      "2022-11-08 09:08:32,810 INFO     Training average negative_sample_loss at step 47100: 0.919216\n",
      "2022-11-08 09:08:32,810 INFO     Training average loss at step 47100: 1.396478\n",
      "2022-11-08 09:08:36,957 INFO     Training average positive_sample_loss at step 47200: 1.860348\n",
      "2022-11-08 09:08:36,957 INFO     Training average negative_sample_loss at step 47200: 0.934393\n",
      "2022-11-08 09:08:36,957 INFO     Training average loss at step 47200: 1.397371\n",
      "2022-11-08 09:08:42,271 INFO     Training average positive_sample_loss at step 47300: 1.834699\n",
      "2022-11-08 09:08:42,271 INFO     Training average negative_sample_loss at step 47300: 0.930622\n",
      "2022-11-08 09:08:42,271 INFO     Training average loss at step 47300: 1.382661\n",
      "2022-11-08 09:08:45,443 INFO     Training average positive_sample_loss at step 47400: 1.848059\n",
      "2022-11-08 09:08:45,443 INFO     Training average negative_sample_loss at step 47400: 0.927421\n",
      "2022-11-08 09:08:45,443 INFO     Training average loss at step 47400: 1.387740\n",
      "2022-11-08 09:08:50,380 INFO     Training average positive_sample_loss at step 47500: 1.827390\n",
      "2022-11-08 09:08:50,380 INFO     Training average negative_sample_loss at step 47500: 0.931091\n",
      "2022-11-08 09:08:50,380 INFO     Training average loss at step 47500: 1.379241\n",
      "2022-11-08 09:08:53,582 INFO     Training average positive_sample_loss at step 47600: 1.807408\n",
      "2022-11-08 09:08:53,582 INFO     Training average negative_sample_loss at step 47600: 0.937009\n",
      "2022-11-08 09:08:53,582 INFO     Training average loss at step 47600: 1.372209\n",
      "2022-11-08 09:08:56,829 INFO     Training average positive_sample_loss at step 47700: 1.810854\n",
      "2022-11-08 09:08:56,829 INFO     Training average negative_sample_loss at step 47700: 0.934839\n",
      "2022-11-08 09:08:56,829 INFO     Training average loss at step 47700: 1.372847\n",
      "2022-11-08 09:09:00,054 INFO     Training average positive_sample_loss at step 47800: 1.774991\n",
      "2022-11-08 09:09:00,054 INFO     Training average negative_sample_loss at step 47800: 0.945883\n",
      "2022-11-08 09:09:00,054 INFO     Training average loss at step 47800: 1.360437\n",
      "2022-11-08 09:09:03,244 INFO     Training average positive_sample_loss at step 47900: 1.857339\n",
      "2022-11-08 09:09:03,245 INFO     Training average negative_sample_loss at step 47900: 0.922492\n",
      "2022-11-08 09:09:03,245 INFO     Training average loss at step 47900: 1.389916\n",
      "2022-11-08 09:09:06,414 INFO     Training average positive_sample_loss at step 48000: 1.806379\n",
      "2022-11-08 09:09:06,414 INFO     Training average negative_sample_loss at step 48000: 0.928885\n",
      "2022-11-08 09:09:06,414 INFO     Training average loss at step 48000: 1.367632\n",
      "2022-11-08 09:09:09,602 INFO     Training average positive_sample_loss at step 48100: 1.790241\n",
      "2022-11-08 09:09:09,602 INFO     Training average negative_sample_loss at step 48100: 0.934325\n",
      "2022-11-08 09:09:09,602 INFO     Training average loss at step 48100: 1.362283\n",
      "2022-11-08 09:09:12,783 INFO     Training average positive_sample_loss at step 48200: 1.846698\n",
      "2022-11-08 09:09:12,783 INFO     Training average negative_sample_loss at step 48200: 0.932963\n",
      "2022-11-08 09:09:12,783 INFO     Training average loss at step 48200: 1.389831\n",
      "2022-11-08 09:09:15,951 INFO     Training average positive_sample_loss at step 48300: 1.827908\n",
      "2022-11-08 09:09:15,951 INFO     Training average negative_sample_loss at step 48300: 0.923272\n",
      "2022-11-08 09:09:15,951 INFO     Training average loss at step 48300: 1.375590\n",
      "2022-11-08 09:09:19,122 INFO     Training average positive_sample_loss at step 48400: 1.803303\n",
      "2022-11-08 09:09:19,122 INFO     Training average negative_sample_loss at step 48400: 0.937023\n",
      "2022-11-08 09:09:19,122 INFO     Training average loss at step 48400: 1.370163\n",
      "2022-11-08 09:09:22,304 INFO     Training average positive_sample_loss at step 48500: 1.813551\n",
      "2022-11-08 09:09:22,304 INFO     Training average negative_sample_loss at step 48500: 0.932882\n",
      "2022-11-08 09:09:22,304 INFO     Training average loss at step 48500: 1.373216\n",
      "2022-11-08 09:09:25,547 INFO     Training average positive_sample_loss at step 48600: 1.834623\n",
      "2022-11-08 09:09:25,548 INFO     Training average negative_sample_loss at step 48600: 0.929905\n",
      "2022-11-08 09:09:25,548 INFO     Training average loss at step 48600: 1.382264\n",
      "2022-11-08 09:09:28,705 INFO     Training average positive_sample_loss at step 48700: 1.784846\n",
      "2022-11-08 09:09:28,705 INFO     Training average negative_sample_loss at step 48700: 0.945141\n",
      "2022-11-08 09:09:28,705 INFO     Training average loss at step 48700: 1.364993\n",
      "2022-11-08 09:09:31,854 INFO     Training average positive_sample_loss at step 48800: 1.839665\n",
      "2022-11-08 09:09:31,854 INFO     Training average negative_sample_loss at step 48800: 0.916588\n",
      "2022-11-08 09:09:31,854 INFO     Training average loss at step 48800: 1.378126\n",
      "2022-11-08 09:09:35,055 INFO     Training average positive_sample_loss at step 48900: 1.834920\n",
      "2022-11-08 09:09:35,056 INFO     Training average negative_sample_loss at step 48900: 0.928901\n",
      "2022-11-08 09:09:35,056 INFO     Training average loss at step 48900: 1.381910\n",
      "2022-11-08 09:09:38,219 INFO     Training average positive_sample_loss at step 49000: 1.817832\n",
      "2022-11-08 09:09:38,219 INFO     Training average negative_sample_loss at step 49000: 0.914930\n",
      "2022-11-08 09:09:38,219 INFO     Training average loss at step 49000: 1.366381\n",
      "2022-11-08 09:09:41,520 INFO     Training average positive_sample_loss at step 49100: 1.790145\n",
      "2022-11-08 09:09:41,520 INFO     Training average negative_sample_loss at step 49100: 0.926543\n",
      "2022-11-08 09:09:41,520 INFO     Training average loss at step 49100: 1.358344\n",
      "2022-11-08 09:09:44,848 INFO     Training average positive_sample_loss at step 49200: 1.782000\n",
      "2022-11-08 09:09:44,849 INFO     Training average negative_sample_loss at step 49200: 0.924275\n",
      "2022-11-08 09:09:44,849 INFO     Training average loss at step 49200: 1.353137\n",
      "2022-11-08 09:09:48,098 INFO     Training average positive_sample_loss at step 49300: 1.823044\n",
      "2022-11-08 09:09:48,098 INFO     Training average negative_sample_loss at step 49300: 0.921574\n",
      "2022-11-08 09:09:48,098 INFO     Training average loss at step 49300: 1.372309\n",
      "2022-11-08 09:09:51,361 INFO     Training average positive_sample_loss at step 49400: 1.811401\n",
      "2022-11-08 09:09:51,361 INFO     Training average negative_sample_loss at step 49400: 0.927136\n",
      "2022-11-08 09:09:51,361 INFO     Training average loss at step 49400: 1.369268\n",
      "2022-11-08 09:09:54,618 INFO     Training average positive_sample_loss at step 49500: 1.807436\n",
      "2022-11-08 09:09:54,618 INFO     Training average negative_sample_loss at step 49500: 0.923529\n",
      "2022-11-08 09:09:54,618 INFO     Training average loss at step 49500: 1.365483\n",
      "2022-11-08 09:09:57,925 INFO     Training average positive_sample_loss at step 49600: 1.774429\n",
      "2022-11-08 09:09:57,925 INFO     Training average negative_sample_loss at step 49600: 0.930751\n",
      "2022-11-08 09:09:57,925 INFO     Training average loss at step 49600: 1.352590\n",
      "2022-11-08 09:10:01,210 INFO     Training average positive_sample_loss at step 49700: 1.791510\n",
      "2022-11-08 09:10:01,210 INFO     Training average negative_sample_loss at step 49700: 0.926974\n",
      "2022-11-08 09:10:01,210 INFO     Training average loss at step 49700: 1.359242\n",
      "2022-11-08 09:10:04,431 INFO     Training average positive_sample_loss at step 49800: 1.841012\n",
      "2022-11-08 09:10:04,431 INFO     Training average negative_sample_loss at step 49800: 0.922843\n",
      "2022-11-08 09:10:04,431 INFO     Training average loss at step 49800: 1.381928\n",
      "2022-11-08 09:10:07,638 INFO     Training average positive_sample_loss at step 49900: 1.826147\n",
      "2022-11-08 09:10:07,638 INFO     Training average negative_sample_loss at step 49900: 0.917663\n",
      "2022-11-08 09:10:07,638 INFO     Training average loss at step 49900: 1.371905\n",
      "2022-11-08 09:10:13,625 INFO     Training average positive_sample_loss at step 50000: 1.807748\n",
      "2022-11-08 09:10:13,625 INFO     Training average negative_sample_loss at step 50000: 0.915806\n",
      "2022-11-08 09:10:13,625 INFO     Training average loss at step 50000: 1.361777\n",
      "2022-11-08 09:10:16,937 INFO     Training average positive_sample_loss at step 50100: 1.812014\n",
      "2022-11-08 09:10:16,938 INFO     Training average negative_sample_loss at step 50100: 0.924702\n",
      "2022-11-08 09:10:16,938 INFO     Training average loss at step 50100: 1.368358\n",
      "2022-11-08 09:10:20,244 INFO     Training average positive_sample_loss at step 50200: 1.843169\n",
      "2022-11-08 09:10:20,244 INFO     Training average negative_sample_loss at step 50200: 0.912476\n",
      "2022-11-08 09:10:20,244 INFO     Training average loss at step 50200: 1.377822\n",
      "2022-11-08 09:10:23,421 INFO     Training average positive_sample_loss at step 50300: 1.840714\n",
      "2022-11-08 09:10:23,421 INFO     Training average negative_sample_loss at step 50300: 0.912749\n",
      "2022-11-08 09:10:23,421 INFO     Training average loss at step 50300: 1.376731\n",
      "2022-11-08 09:10:26,698 INFO     Training average positive_sample_loss at step 50400: 1.853862\n",
      "2022-11-08 09:10:26,698 INFO     Training average negative_sample_loss at step 50400: 0.900683\n",
      "2022-11-08 09:10:26,698 INFO     Training average loss at step 50400: 1.377273\n",
      "2022-11-08 09:10:29,977 INFO     Training average positive_sample_loss at step 50500: 1.791714\n",
      "2022-11-08 09:10:29,977 INFO     Training average negative_sample_loss at step 50500: 0.920280\n",
      "2022-11-08 09:10:29,977 INFO     Training average loss at step 50500: 1.355997\n",
      "2022-11-08 09:10:33,183 INFO     Training average positive_sample_loss at step 50600: 1.852511\n",
      "2022-11-08 09:10:33,183 INFO     Training average negative_sample_loss at step 50600: 0.908102\n",
      "2022-11-08 09:10:33,183 INFO     Training average loss at step 50600: 1.380306\n",
      "2022-11-08 09:10:36,365 INFO     Training average positive_sample_loss at step 50700: 1.791995\n",
      "2022-11-08 09:10:36,365 INFO     Training average negative_sample_loss at step 50700: 0.908887\n",
      "2022-11-08 09:10:36,365 INFO     Training average loss at step 50700: 1.350441\n",
      "2022-11-08 09:10:39,602 INFO     Training average positive_sample_loss at step 50800: 1.801434\n",
      "2022-11-08 09:10:39,602 INFO     Training average negative_sample_loss at step 50800: 0.906935\n",
      "2022-11-08 09:10:39,602 INFO     Training average loss at step 50800: 1.354184\n",
      "2022-11-08 09:10:42,827 INFO     Training average positive_sample_loss at step 50900: 1.807178\n",
      "2022-11-08 09:10:42,827 INFO     Training average negative_sample_loss at step 50900: 0.908720\n",
      "2022-11-08 09:10:42,827 INFO     Training average loss at step 50900: 1.357949\n",
      "2022-11-08 09:10:45,977 INFO     Training average positive_sample_loss at step 51000: 1.840232\n",
      "2022-11-08 09:10:45,977 INFO     Training average negative_sample_loss at step 51000: 0.903261\n",
      "2022-11-08 09:10:45,977 INFO     Training average loss at step 51000: 1.371746\n",
      "2022-11-08 09:10:49,290 INFO     Training average positive_sample_loss at step 51100: 1.803395\n",
      "2022-11-08 09:10:49,290 INFO     Training average negative_sample_loss at step 51100: 0.920166\n",
      "2022-11-08 09:10:49,290 INFO     Training average loss at step 51100: 1.361780\n",
      "2022-11-08 09:10:52,513 INFO     Training average positive_sample_loss at step 51200: 1.810961\n",
      "2022-11-08 09:10:52,513 INFO     Training average negative_sample_loss at step 51200: 0.911596\n",
      "2022-11-08 09:10:52,513 INFO     Training average loss at step 51200: 1.361278\n",
      "2022-11-08 09:10:55,797 INFO     Training average positive_sample_loss at step 51300: 1.821467\n",
      "2022-11-08 09:10:55,797 INFO     Training average negative_sample_loss at step 51300: 0.912324\n",
      "2022-11-08 09:10:55,797 INFO     Training average loss at step 51300: 1.366895\n",
      "2022-11-08 09:10:59,035 INFO     Training average positive_sample_loss at step 51400: 1.789900\n",
      "2022-11-08 09:10:59,036 INFO     Training average negative_sample_loss at step 51400: 0.903372\n",
      "2022-11-08 09:10:59,036 INFO     Training average loss at step 51400: 1.346636\n",
      "2022-11-08 09:11:02,274 INFO     Training average positive_sample_loss at step 51500: 1.816543\n",
      "2022-11-08 09:11:02,274 INFO     Training average negative_sample_loss at step 51500: 0.903170\n",
      "2022-11-08 09:11:02,274 INFO     Training average loss at step 51500: 1.359857\n",
      "2022-11-08 09:11:05,474 INFO     Training average positive_sample_loss at step 51600: 1.763245\n",
      "2022-11-08 09:11:05,474 INFO     Training average negative_sample_loss at step 51600: 0.914169\n",
      "2022-11-08 09:11:05,474 INFO     Training average loss at step 51600: 1.338707\n",
      "2022-11-08 09:11:08,686 INFO     Training average positive_sample_loss at step 51700: 1.782691\n",
      "2022-11-08 09:11:08,686 INFO     Training average negative_sample_loss at step 51700: 0.910964\n",
      "2022-11-08 09:11:08,686 INFO     Training average loss at step 51700: 1.346828\n",
      "2022-11-08 09:11:11,887 INFO     Training average positive_sample_loss at step 51800: 1.823543\n",
      "2022-11-08 09:11:11,887 INFO     Training average negative_sample_loss at step 51800: 0.908578\n",
      "2022-11-08 09:11:11,887 INFO     Training average loss at step 51800: 1.366061\n",
      "2022-11-08 09:11:16,025 INFO     Training average positive_sample_loss at step 51900: 1.815583\n",
      "2022-11-08 09:11:16,025 INFO     Training average negative_sample_loss at step 51900: 0.899080\n",
      "2022-11-08 09:11:16,025 INFO     Training average loss at step 51900: 1.357332\n",
      "2022-11-08 09:11:21,522 INFO     Training average positive_sample_loss at step 52000: 1.747525\n",
      "2022-11-08 09:11:21,522 INFO     Training average negative_sample_loss at step 52000: 0.914011\n",
      "2022-11-08 09:11:21,522 INFO     Training average loss at step 52000: 1.330768\n",
      "2022-11-08 09:11:25,761 INFO     Training average positive_sample_loss at step 52100: 1.839029\n",
      "2022-11-08 09:11:25,761 INFO     Training average negative_sample_loss at step 52100: 0.906774\n",
      "2022-11-08 09:11:25,761 INFO     Training average loss at step 52100: 1.372901\n",
      "2022-11-08 09:11:28,960 INFO     Training average positive_sample_loss at step 52200: 1.807406\n",
      "2022-11-08 09:11:28,961 INFO     Training average negative_sample_loss at step 52200: 0.913248\n",
      "2022-11-08 09:11:28,961 INFO     Training average loss at step 52200: 1.360327\n",
      "2022-11-08 09:11:32,136 INFO     Training average positive_sample_loss at step 52300: 1.774317\n",
      "2022-11-08 09:11:32,136 INFO     Training average negative_sample_loss at step 52300: 0.913178\n",
      "2022-11-08 09:11:32,136 INFO     Training average loss at step 52300: 1.343748\n",
      "2022-11-08 09:11:35,438 INFO     Training average positive_sample_loss at step 52400: 1.793722\n",
      "2022-11-08 09:11:35,438 INFO     Training average negative_sample_loss at step 52400: 0.903659\n",
      "2022-11-08 09:11:35,438 INFO     Training average loss at step 52400: 1.348690\n",
      "2022-11-08 09:11:38,636 INFO     Training average positive_sample_loss at step 52500: 1.753738\n",
      "2022-11-08 09:11:38,636 INFO     Training average negative_sample_loss at step 52500: 0.903619\n",
      "2022-11-08 09:11:38,636 INFO     Training average loss at step 52500: 1.328679\n",
      "2022-11-08 09:11:41,805 INFO     Training average positive_sample_loss at step 52600: 1.815047\n",
      "2022-11-08 09:11:41,805 INFO     Training average negative_sample_loss at step 52600: 0.902370\n",
      "2022-11-08 09:11:41,805 INFO     Training average loss at step 52600: 1.358708\n",
      "2022-11-08 09:11:44,990 INFO     Training average positive_sample_loss at step 52700: 1.791976\n",
      "2022-11-08 09:11:44,990 INFO     Training average negative_sample_loss at step 52700: 0.907859\n",
      "2022-11-08 09:11:44,990 INFO     Training average loss at step 52700: 1.349918\n",
      "2022-11-08 09:11:48,179 INFO     Training average positive_sample_loss at step 52800: 1.777917\n",
      "2022-11-08 09:11:48,179 INFO     Training average negative_sample_loss at step 52800: 0.904937\n",
      "2022-11-08 09:11:48,179 INFO     Training average loss at step 52800: 1.341427\n",
      "2022-11-08 09:11:51,347 INFO     Training average positive_sample_loss at step 52900: 1.768555\n",
      "2022-11-08 09:11:51,347 INFO     Training average negative_sample_loss at step 52900: 0.900128\n",
      "2022-11-08 09:11:51,347 INFO     Training average loss at step 52900: 1.334342\n",
      "2022-11-08 09:11:54,531 INFO     Training average positive_sample_loss at step 53000: 1.784546\n",
      "2022-11-08 09:11:54,531 INFO     Training average negative_sample_loss at step 53000: 0.905459\n",
      "2022-11-08 09:11:54,531 INFO     Training average loss at step 53000: 1.345003\n",
      "2022-11-08 09:11:57,812 INFO     Training average positive_sample_loss at step 53100: 1.773259\n",
      "2022-11-08 09:11:57,813 INFO     Training average negative_sample_loss at step 53100: 0.897455\n",
      "2022-11-08 09:11:57,813 INFO     Training average loss at step 53100: 1.335357\n",
      "2022-11-08 09:12:01,015 INFO     Training average positive_sample_loss at step 53200: 1.795208\n",
      "2022-11-08 09:12:01,015 INFO     Training average negative_sample_loss at step 53200: 0.898919\n",
      "2022-11-08 09:12:01,015 INFO     Training average loss at step 53200: 1.347063\n",
      "2022-11-08 09:12:04,202 INFO     Training average positive_sample_loss at step 53300: 1.801973\n",
      "2022-11-08 09:12:04,202 INFO     Training average negative_sample_loss at step 53300: 0.903491\n",
      "2022-11-08 09:12:04,202 INFO     Training average loss at step 53300: 1.352732\n",
      "2022-11-08 09:12:07,422 INFO     Training average positive_sample_loss at step 53400: 1.750860\n",
      "2022-11-08 09:12:07,422 INFO     Training average negative_sample_loss at step 53400: 0.910151\n",
      "2022-11-08 09:12:07,422 INFO     Training average loss at step 53400: 1.330505\n",
      "2022-11-08 09:12:10,629 INFO     Training average positive_sample_loss at step 53500: 1.760002\n",
      "2022-11-08 09:12:10,630 INFO     Training average negative_sample_loss at step 53500: 0.895983\n",
      "2022-11-08 09:12:10,630 INFO     Training average loss at step 53500: 1.327993\n",
      "2022-11-08 09:12:13,848 INFO     Training average positive_sample_loss at step 53600: 1.847680\n",
      "2022-11-08 09:12:13,848 INFO     Training average negative_sample_loss at step 53600: 0.883338\n",
      "2022-11-08 09:12:13,848 INFO     Training average loss at step 53600: 1.365509\n",
      "2022-11-08 09:12:17,038 INFO     Training average positive_sample_loss at step 53700: 1.746240\n",
      "2022-11-08 09:12:17,039 INFO     Training average negative_sample_loss at step 53700: 0.899864\n",
      "2022-11-08 09:12:17,039 INFO     Training average loss at step 53700: 1.323052\n",
      "2022-11-08 09:12:20,243 INFO     Training average positive_sample_loss at step 53800: 1.816462\n",
      "2022-11-08 09:12:20,243 INFO     Training average negative_sample_loss at step 53800: 0.892388\n",
      "2022-11-08 09:12:20,243 INFO     Training average loss at step 53800: 1.354425\n",
      "2022-11-08 09:12:23,499 INFO     Training average positive_sample_loss at step 53900: 1.772205\n",
      "2022-11-08 09:12:23,499 INFO     Training average negative_sample_loss at step 53900: 0.895992\n",
      "2022-11-08 09:12:23,499 INFO     Training average loss at step 53900: 1.334098\n",
      "2022-11-08 09:12:26,679 INFO     Training average positive_sample_loss at step 54000: 1.768466\n",
      "2022-11-08 09:12:26,679 INFO     Training average negative_sample_loss at step 54000: 0.893126\n",
      "2022-11-08 09:12:26,679 INFO     Training average loss at step 54000: 1.330796\n",
      "2022-11-08 09:12:29,850 INFO     Training average positive_sample_loss at step 54100: 1.762650\n",
      "2022-11-08 09:12:29,850 INFO     Training average negative_sample_loss at step 54100: 0.894836\n",
      "2022-11-08 09:12:29,850 INFO     Training average loss at step 54100: 1.328743\n",
      "2022-11-08 09:12:33,148 INFO     Training average positive_sample_loss at step 54200: 1.779658\n",
      "2022-11-08 09:12:33,148 INFO     Training average negative_sample_loss at step 54200: 0.892566\n",
      "2022-11-08 09:12:33,148 INFO     Training average loss at step 54200: 1.336112\n",
      "2022-11-08 09:12:36,374 INFO     Training average positive_sample_loss at step 54300: 1.720656\n",
      "2022-11-08 09:12:36,374 INFO     Training average negative_sample_loss at step 54300: 0.893678\n",
      "2022-11-08 09:12:36,374 INFO     Training average loss at step 54300: 1.307167\n",
      "2022-11-08 09:12:39,671 INFO     Training average positive_sample_loss at step 54400: 1.797481\n",
      "2022-11-08 09:12:39,671 INFO     Training average negative_sample_loss at step 54400: 0.884976\n",
      "2022-11-08 09:12:39,671 INFO     Training average loss at step 54400: 1.341229\n",
      "2022-11-08 09:12:42,882 INFO     Training average positive_sample_loss at step 54500: 1.770141\n",
      "2022-11-08 09:12:42,882 INFO     Training average negative_sample_loss at step 54500: 0.892885\n",
      "2022-11-08 09:12:42,882 INFO     Training average loss at step 54500: 1.331513\n",
      "2022-11-08 09:12:46,079 INFO     Training average positive_sample_loss at step 54600: 1.811114\n",
      "2022-11-08 09:12:46,079 INFO     Training average negative_sample_loss at step 54600: 0.887067\n",
      "2022-11-08 09:12:46,079 INFO     Training average loss at step 54600: 1.349091\n",
      "2022-11-08 09:12:49,350 INFO     Training average positive_sample_loss at step 54700: 1.838117\n",
      "2022-11-08 09:12:49,350 INFO     Training average negative_sample_loss at step 54700: 0.880521\n",
      "2022-11-08 09:12:49,350 INFO     Training average loss at step 54700: 1.359319\n",
      "2022-11-08 09:12:52,577 INFO     Training average positive_sample_loss at step 54800: 1.834170\n",
      "2022-11-08 09:12:52,577 INFO     Training average negative_sample_loss at step 54800: 0.896485\n",
      "2022-11-08 09:12:52,577 INFO     Training average loss at step 54800: 1.365328\n",
      "2022-11-08 09:12:55,773 INFO     Training average positive_sample_loss at step 54900: 1.831834\n",
      "2022-11-08 09:12:55,773 INFO     Training average negative_sample_loss at step 54900: 0.888495\n",
      "2022-11-08 09:12:55,773 INFO     Training average loss at step 54900: 1.360165\n",
      "2022-11-08 09:12:58,932 INFO     Training average positive_sample_loss at step 55000: 1.770467\n",
      "2022-11-08 09:12:58,932 INFO     Training average negative_sample_loss at step 55000: 0.890903\n",
      "2022-11-08 09:12:58,932 INFO     Training average loss at step 55000: 1.330685\n",
      "2022-11-08 09:13:02,110 INFO     Training average positive_sample_loss at step 55100: 1.770583\n",
      "2022-11-08 09:13:02,110 INFO     Training average negative_sample_loss at step 55100: 0.892956\n",
      "2022-11-08 09:13:02,110 INFO     Training average loss at step 55100: 1.331769\n",
      "2022-11-08 09:13:05,337 INFO     Training average positive_sample_loss at step 55200: 1.756012\n",
      "2022-11-08 09:13:05,337 INFO     Training average negative_sample_loss at step 55200: 0.885267\n",
      "2022-11-08 09:13:05,337 INFO     Training average loss at step 55200: 1.320640\n",
      "2022-11-08 09:13:08,562 INFO     Training average positive_sample_loss at step 55300: 1.805073\n",
      "2022-11-08 09:13:08,562 INFO     Training average negative_sample_loss at step 55300: 0.882327\n",
      "2022-11-08 09:13:08,562 INFO     Training average loss at step 55300: 1.343700\n",
      "2022-11-08 09:13:11,794 INFO     Training average positive_sample_loss at step 55400: 1.762641\n",
      "2022-11-08 09:13:11,794 INFO     Training average negative_sample_loss at step 55400: 0.890815\n",
      "2022-11-08 09:13:11,794 INFO     Training average loss at step 55400: 1.326728\n",
      "2022-11-08 09:13:15,044 INFO     Training average positive_sample_loss at step 55500: 1.824581\n",
      "2022-11-08 09:13:15,044 INFO     Training average negative_sample_loss at step 55500: 0.876920\n",
      "2022-11-08 09:13:15,044 INFO     Training average loss at step 55500: 1.350750\n",
      "2022-11-08 09:13:18,238 INFO     Training average positive_sample_loss at step 55600: 1.782853\n",
      "2022-11-08 09:13:18,238 INFO     Training average negative_sample_loss at step 55600: 0.885722\n",
      "2022-11-08 09:13:18,239 INFO     Training average loss at step 55600: 1.334287\n",
      "2022-11-08 09:13:21,408 INFO     Training average positive_sample_loss at step 55700: 1.833045\n",
      "2022-11-08 09:13:21,409 INFO     Training average negative_sample_loss at step 55700: 0.878428\n",
      "2022-11-08 09:13:21,409 INFO     Training average loss at step 55700: 1.355737\n",
      "2022-11-08 09:13:24,571 INFO     Training average positive_sample_loss at step 55800: 1.763254\n",
      "2022-11-08 09:13:24,571 INFO     Training average negative_sample_loss at step 55800: 0.890878\n",
      "2022-11-08 09:13:24,571 INFO     Training average loss at step 55800: 1.327066\n",
      "2022-11-08 09:13:27,807 INFO     Training average positive_sample_loss at step 55900: 1.736352\n",
      "2022-11-08 09:13:27,807 INFO     Training average negative_sample_loss at step 55900: 0.887486\n",
      "2022-11-08 09:13:27,807 INFO     Training average loss at step 55900: 1.311919\n",
      "2022-11-08 09:13:31,042 INFO     Training average positive_sample_loss at step 56000: 1.796109\n",
      "2022-11-08 09:13:31,042 INFO     Training average negative_sample_loss at step 56000: 0.881453\n",
      "2022-11-08 09:13:31,042 INFO     Training average loss at step 56000: 1.338781\n",
      "2022-11-08 09:13:34,237 INFO     Training average positive_sample_loss at step 56100: 1.777463\n",
      "2022-11-08 09:13:34,237 INFO     Training average negative_sample_loss at step 56100: 0.881144\n",
      "2022-11-08 09:13:34,237 INFO     Training average loss at step 56100: 1.329303\n",
      "2022-11-08 09:13:37,507 INFO     Training average positive_sample_loss at step 56200: 1.783765\n",
      "2022-11-08 09:13:37,507 INFO     Training average negative_sample_loss at step 56200: 0.873765\n",
      "2022-11-08 09:13:37,507 INFO     Training average loss at step 56200: 1.328765\n",
      "2022-11-08 09:13:40,903 INFO     Training average positive_sample_loss at step 56300: 1.816292\n",
      "2022-11-08 09:13:40,903 INFO     Training average negative_sample_loss at step 56300: 0.862466\n",
      "2022-11-08 09:13:40,903 INFO     Training average loss at step 56300: 1.339379\n",
      "2022-11-08 09:13:44,131 INFO     Training average positive_sample_loss at step 56400: 1.775798\n",
      "2022-11-08 09:13:44,131 INFO     Training average negative_sample_loss at step 56400: 0.878536\n",
      "2022-11-08 09:13:44,131 INFO     Training average loss at step 56400: 1.327167\n",
      "2022-11-08 09:13:47,374 INFO     Training average positive_sample_loss at step 56500: 1.723264\n",
      "2022-11-08 09:13:47,375 INFO     Training average negative_sample_loss at step 56500: 0.881136\n",
      "2022-11-08 09:13:47,375 INFO     Training average loss at step 56500: 1.302200\n",
      "2022-11-08 09:13:51,812 INFO     Training average positive_sample_loss at step 56600: 1.766804\n",
      "2022-11-08 09:13:51,812 INFO     Training average negative_sample_loss at step 56600: 0.886582\n",
      "2022-11-08 09:13:51,812 INFO     Training average loss at step 56600: 1.326693\n",
      "2022-11-08 09:13:57,358 INFO     Training average positive_sample_loss at step 56700: 1.771503\n",
      "2022-11-08 09:13:57,358 INFO     Training average negative_sample_loss at step 56700: 0.876257\n",
      "2022-11-08 09:13:57,358 INFO     Training average loss at step 56700: 1.323880\n",
      "2022-11-08 09:14:01,765 INFO     Training average positive_sample_loss at step 56800: 1.768399\n",
      "2022-11-08 09:14:01,765 INFO     Training average negative_sample_loss at step 56800: 0.867244\n",
      "2022-11-08 09:14:01,766 INFO     Training average loss at step 56800: 1.317822\n",
      "2022-11-08 09:14:05,129 INFO     Training average positive_sample_loss at step 56900: 1.740861\n",
      "2022-11-08 09:14:05,129 INFO     Training average negative_sample_loss at step 56900: 0.873617\n",
      "2022-11-08 09:14:05,129 INFO     Training average loss at step 56900: 1.307239\n",
      "2022-11-08 09:14:08,505 INFO     Training average positive_sample_loss at step 57000: 1.750681\n",
      "2022-11-08 09:14:08,505 INFO     Training average negative_sample_loss at step 57000: 0.870129\n",
      "2022-11-08 09:14:08,505 INFO     Training average loss at step 57000: 1.310405\n",
      "2022-11-08 09:14:11,871 INFO     Training average positive_sample_loss at step 57100: 1.746985\n",
      "2022-11-08 09:14:11,871 INFO     Training average negative_sample_loss at step 57100: 0.876109\n",
      "2022-11-08 09:14:11,871 INFO     Training average loss at step 57100: 1.311547\n",
      "2022-11-08 09:14:15,238 INFO     Training average positive_sample_loss at step 57200: 1.800656\n",
      "2022-11-08 09:14:15,238 INFO     Training average negative_sample_loss at step 57200: 0.879785\n",
      "2022-11-08 09:14:15,238 INFO     Training average loss at step 57200: 1.340220\n",
      "2022-11-08 09:14:18,599 INFO     Training average positive_sample_loss at step 57300: 1.780626\n",
      "2022-11-08 09:14:18,599 INFO     Training average negative_sample_loss at step 57300: 0.871623\n",
      "2022-11-08 09:14:18,599 INFO     Training average loss at step 57300: 1.326125\n",
      "2022-11-08 09:14:21,981 INFO     Training average positive_sample_loss at step 57400: 1.777739\n",
      "2022-11-08 09:14:21,981 INFO     Training average negative_sample_loss at step 57400: 0.870194\n",
      "2022-11-08 09:14:21,981 INFO     Training average loss at step 57400: 1.323967\n",
      "2022-11-08 09:14:25,320 INFO     Training average positive_sample_loss at step 57500: 1.723567\n",
      "2022-11-08 09:14:25,320 INFO     Training average negative_sample_loss at step 57500: 0.876418\n",
      "2022-11-08 09:14:25,320 INFO     Training average loss at step 57500: 1.299993\n",
      "2022-11-08 09:14:28,647 INFO     Training average positive_sample_loss at step 57600: 1.733642\n",
      "2022-11-08 09:14:28,647 INFO     Training average negative_sample_loss at step 57600: 0.874807\n",
      "2022-11-08 09:14:28,647 INFO     Training average loss at step 57600: 1.304225\n",
      "2022-11-08 09:14:32,007 INFO     Training average positive_sample_loss at step 57700: 1.711114\n",
      "2022-11-08 09:14:32,007 INFO     Training average negative_sample_loss at step 57700: 0.879437\n",
      "2022-11-08 09:14:32,008 INFO     Training average loss at step 57700: 1.295276\n",
      "2022-11-08 09:14:35,362 INFO     Training average positive_sample_loss at step 57800: 1.739469\n",
      "2022-11-08 09:14:35,362 INFO     Training average negative_sample_loss at step 57800: 0.875539\n",
      "2022-11-08 09:14:35,362 INFO     Training average loss at step 57800: 1.307504\n",
      "2022-11-08 09:14:38,702 INFO     Training average positive_sample_loss at step 57900: 1.775460\n",
      "2022-11-08 09:14:38,702 INFO     Training average negative_sample_loss at step 57900: 0.874111\n",
      "2022-11-08 09:14:38,702 INFO     Training average loss at step 57900: 1.324785\n",
      "2022-11-08 09:14:42,054 INFO     Training average positive_sample_loss at step 58000: 1.730123\n",
      "2022-11-08 09:14:42,054 INFO     Training average negative_sample_loss at step 58000: 0.878197\n",
      "2022-11-08 09:14:42,054 INFO     Training average loss at step 58000: 1.304160\n",
      "2022-11-08 09:14:45,292 INFO     Training average positive_sample_loss at step 58100: 1.766727\n",
      "2022-11-08 09:14:45,292 INFO     Training average negative_sample_loss at step 58100: 0.856672\n",
      "2022-11-08 09:14:45,292 INFO     Training average loss at step 58100: 1.311700\n",
      "2022-11-08 09:14:48,501 INFO     Training average positive_sample_loss at step 58200: 1.767654\n",
      "2022-11-08 09:14:48,501 INFO     Training average negative_sample_loss at step 58200: 0.859214\n",
      "2022-11-08 09:14:48,501 INFO     Training average loss at step 58200: 1.313434\n",
      "2022-11-08 09:14:51,795 INFO     Training average positive_sample_loss at step 58300: 1.787128\n",
      "2022-11-08 09:14:51,795 INFO     Training average negative_sample_loss at step 58300: 0.867998\n",
      "2022-11-08 09:14:51,795 INFO     Training average loss at step 58300: 1.327563\n",
      "2022-11-08 09:14:55,073 INFO     Training average positive_sample_loss at step 58400: 1.737513\n",
      "2022-11-08 09:14:55,073 INFO     Training average negative_sample_loss at step 58400: 0.866146\n",
      "2022-11-08 09:14:55,073 INFO     Training average loss at step 58400: 1.301830\n",
      "2022-11-08 09:14:58,232 INFO     Training average positive_sample_loss at step 58500: 1.726935\n",
      "2022-11-08 09:14:58,232 INFO     Training average negative_sample_loss at step 58500: 0.861453\n",
      "2022-11-08 09:14:58,232 INFO     Training average loss at step 58500: 1.294194\n",
      "2022-11-08 09:15:01,494 INFO     Training average positive_sample_loss at step 58600: 1.732653\n",
      "2022-11-08 09:15:01,494 INFO     Training average negative_sample_loss at step 58600: 0.867658\n",
      "2022-11-08 09:15:01,494 INFO     Training average loss at step 58600: 1.300155\n",
      "2022-11-08 09:15:04,783 INFO     Training average positive_sample_loss at step 58700: 1.735601\n",
      "2022-11-08 09:15:04,783 INFO     Training average negative_sample_loss at step 58700: 0.872848\n",
      "2022-11-08 09:15:04,783 INFO     Training average loss at step 58700: 1.304225\n",
      "2022-11-08 09:15:08,148 INFO     Training average positive_sample_loss at step 58800: 1.769957\n",
      "2022-11-08 09:15:08,149 INFO     Training average negative_sample_loss at step 58800: 0.864417\n",
      "2022-11-08 09:15:08,149 INFO     Training average loss at step 58800: 1.317187\n",
      "2022-11-08 09:15:11,804 INFO     Training average positive_sample_loss at step 58900: 1.723701\n",
      "2022-11-08 09:15:11,804 INFO     Training average negative_sample_loss at step 58900: 0.861329\n",
      "2022-11-08 09:15:11,804 INFO     Training average loss at step 58900: 1.292515\n",
      "2022-11-08 09:15:15,194 INFO     Training average positive_sample_loss at step 59000: 1.737859\n",
      "2022-11-08 09:15:15,194 INFO     Training average negative_sample_loss at step 59000: 0.867118\n",
      "2022-11-08 09:15:15,194 INFO     Training average loss at step 59000: 1.302488\n",
      "2022-11-08 09:15:18,388 INFO     Training average positive_sample_loss at step 59100: 1.779958\n",
      "2022-11-08 09:15:18,389 INFO     Training average negative_sample_loss at step 59100: 0.862264\n",
      "2022-11-08 09:15:18,389 INFO     Training average loss at step 59100: 1.321111\n",
      "2022-11-08 09:15:21,646 INFO     Training average positive_sample_loss at step 59200: 1.759145\n",
      "2022-11-08 09:15:21,646 INFO     Training average negative_sample_loss at step 59200: 0.860219\n",
      "2022-11-08 09:15:21,646 INFO     Training average loss at step 59200: 1.309682\n",
      "2022-11-08 09:15:24,828 INFO     Training average positive_sample_loss at step 59300: 1.802420\n",
      "2022-11-08 09:15:24,828 INFO     Training average negative_sample_loss at step 59300: 0.859476\n",
      "2022-11-08 09:15:24,828 INFO     Training average loss at step 59300: 1.330948\n",
      "2022-11-08 09:15:28,096 INFO     Training average positive_sample_loss at step 59400: 1.741220\n",
      "2022-11-08 09:15:28,097 INFO     Training average negative_sample_loss at step 59400: 0.868294\n",
      "2022-11-08 09:15:28,097 INFO     Training average loss at step 59400: 1.304757\n",
      "2022-11-08 09:15:31,294 INFO     Training average positive_sample_loss at step 59500: 1.742549\n",
      "2022-11-08 09:15:31,294 INFO     Training average negative_sample_loss at step 59500: 0.860027\n",
      "2022-11-08 09:15:31,294 INFO     Training average loss at step 59500: 1.301288\n",
      "2022-11-08 09:15:34,512 INFO     Training average positive_sample_loss at step 59600: 1.710772\n",
      "2022-11-08 09:15:34,512 INFO     Training average negative_sample_loss at step 59600: 0.853436\n",
      "2022-11-08 09:15:34,512 INFO     Training average loss at step 59600: 1.282104\n",
      "2022-11-08 09:15:37,726 INFO     Training average positive_sample_loss at step 59700: 1.714211\n",
      "2022-11-08 09:15:37,726 INFO     Training average negative_sample_loss at step 59700: 0.859878\n",
      "2022-11-08 09:15:37,726 INFO     Training average loss at step 59700: 1.287045\n",
      "2022-11-08 09:15:40,982 INFO     Training average positive_sample_loss at step 59800: 1.722164\n",
      "2022-11-08 09:15:40,982 INFO     Training average negative_sample_loss at step 59800: 0.859976\n",
      "2022-11-08 09:15:40,982 INFO     Training average loss at step 59800: 1.291070\n",
      "2022-11-08 09:15:44,196 INFO     Training average positive_sample_loss at step 59900: 1.754313\n",
      "2022-11-08 09:15:44,196 INFO     Training average negative_sample_loss at step 59900: 0.856103\n",
      "2022-11-08 09:15:44,196 INFO     Training average loss at step 59900: 1.305208\n",
      "2022-11-08 09:15:50,115 INFO     Training average positive_sample_loss at step 60000: 1.777870\n",
      "2022-11-08 09:15:50,115 INFO     Training average negative_sample_loss at step 60000: 0.853822\n",
      "2022-11-08 09:15:50,115 INFO     Training average loss at step 60000: 1.315846\n",
      "2022-11-08 09:15:53,312 INFO     Training average positive_sample_loss at step 60100: 1.723712\n",
      "2022-11-08 09:15:53,312 INFO     Training average negative_sample_loss at step 60100: 0.863208\n",
      "2022-11-08 09:15:53,312 INFO     Training average loss at step 60100: 1.293460\n",
      "2022-11-08 09:15:56,481 INFO     Training average positive_sample_loss at step 60200: 1.745537\n",
      "2022-11-08 09:15:56,481 INFO     Training average negative_sample_loss at step 60200: 0.848373\n",
      "2022-11-08 09:15:56,481 INFO     Training average loss at step 60200: 1.296955\n",
      "2022-11-08 09:15:59,642 INFO     Training average positive_sample_loss at step 60300: 1.758536\n",
      "2022-11-08 09:15:59,642 INFO     Training average negative_sample_loss at step 60300: 0.844676\n",
      "2022-11-08 09:15:59,642 INFO     Training average loss at step 60300: 1.301606\n",
      "2022-11-08 09:16:02,852 INFO     Training average positive_sample_loss at step 60400: 1.705362\n",
      "2022-11-08 09:16:02,852 INFO     Training average negative_sample_loss at step 60400: 0.851476\n",
      "2022-11-08 09:16:02,852 INFO     Training average loss at step 60400: 1.278419\n",
      "2022-11-08 09:16:06,051 INFO     Training average positive_sample_loss at step 60500: 1.763795\n",
      "2022-11-08 09:16:06,051 INFO     Training average negative_sample_loss at step 60500: 0.850285\n",
      "2022-11-08 09:16:06,051 INFO     Training average loss at step 60500: 1.307040\n",
      "2022-11-08 09:16:09,242 INFO     Training average positive_sample_loss at step 60600: 1.736216\n",
      "2022-11-08 09:16:09,242 INFO     Training average negative_sample_loss at step 60600: 0.855035\n",
      "2022-11-08 09:16:09,242 INFO     Training average loss at step 60600: 1.295626\n",
      "2022-11-08 09:16:12,479 INFO     Training average positive_sample_loss at step 60700: 1.731337\n",
      "2022-11-08 09:16:12,479 INFO     Training average negative_sample_loss at step 60700: 0.849074\n",
      "2022-11-08 09:16:12,479 INFO     Training average loss at step 60700: 1.290206\n",
      "2022-11-08 09:16:15,666 INFO     Training average positive_sample_loss at step 60800: 1.724480\n",
      "2022-11-08 09:16:15,667 INFO     Training average negative_sample_loss at step 60800: 0.849795\n",
      "2022-11-08 09:16:15,667 INFO     Training average loss at step 60800: 1.287138\n",
      "2022-11-08 09:16:18,882 INFO     Training average positive_sample_loss at step 60900: 1.722695\n",
      "2022-11-08 09:16:18,882 INFO     Training average negative_sample_loss at step 60900: 0.853676\n",
      "2022-11-08 09:16:18,882 INFO     Training average loss at step 60900: 1.288185\n",
      "2022-11-08 09:16:22,093 INFO     Training average positive_sample_loss at step 61000: 1.759357\n",
      "2022-11-08 09:16:22,093 INFO     Training average negative_sample_loss at step 61000: 0.842933\n",
      "2022-11-08 09:16:22,093 INFO     Training average loss at step 61000: 1.301145\n",
      "2022-11-08 09:16:25,276 INFO     Training average positive_sample_loss at step 61100: 1.769823\n",
      "2022-11-08 09:16:25,276 INFO     Training average negative_sample_loss at step 61100: 0.851620\n",
      "2022-11-08 09:16:25,276 INFO     Training average loss at step 61100: 1.310721\n",
      "2022-11-08 09:16:29,805 INFO     Training average positive_sample_loss at step 61200: 1.745262\n",
      "2022-11-08 09:16:29,806 INFO     Training average negative_sample_loss at step 61200: 0.850313\n",
      "2022-11-08 09:16:29,806 INFO     Training average loss at step 61200: 1.297787\n",
      "2022-11-08 09:16:34,015 INFO     Training average positive_sample_loss at step 61300: 1.712018\n",
      "2022-11-08 09:16:34,016 INFO     Training average negative_sample_loss at step 61300: 0.853435\n",
      "2022-11-08 09:16:34,016 INFO     Training average loss at step 61300: 1.282727\n",
      "2022-11-08 09:16:38,399 INFO     Training average positive_sample_loss at step 61400: 1.745591\n",
      "2022-11-08 09:16:38,399 INFO     Training average negative_sample_loss at step 61400: 0.843355\n",
      "2022-11-08 09:16:38,399 INFO     Training average loss at step 61400: 1.294473\n",
      "2022-11-08 09:16:42,633 INFO     Training average positive_sample_loss at step 61500: 1.686288\n",
      "2022-11-08 09:16:42,633 INFO     Training average negative_sample_loss at step 61500: 0.858279\n",
      "2022-11-08 09:16:42,633 INFO     Training average loss at step 61500: 1.272284\n",
      "2022-11-08 09:16:45,845 INFO     Training average positive_sample_loss at step 61600: 1.720536\n",
      "2022-11-08 09:16:45,845 INFO     Training average negative_sample_loss at step 61600: 0.851921\n",
      "2022-11-08 09:16:45,846 INFO     Training average loss at step 61600: 1.286229\n",
      "2022-11-08 09:16:49,103 INFO     Training average positive_sample_loss at step 61700: 1.666769\n",
      "2022-11-08 09:16:49,103 INFO     Training average negative_sample_loss at step 61700: 0.853668\n",
      "2022-11-08 09:16:49,103 INFO     Training average loss at step 61700: 1.260219\n",
      "2022-11-08 09:16:52,317 INFO     Training average positive_sample_loss at step 61800: 1.710624\n",
      "2022-11-08 09:16:52,317 INFO     Training average negative_sample_loss at step 61800: 0.847187\n",
      "2022-11-08 09:16:52,317 INFO     Training average loss at step 61800: 1.278905\n",
      "2022-11-08 09:16:55,484 INFO     Training average positive_sample_loss at step 61900: 1.687983\n",
      "2022-11-08 09:16:55,484 INFO     Training average negative_sample_loss at step 61900: 0.837049\n",
      "2022-11-08 09:16:55,484 INFO     Training average loss at step 61900: 1.262516\n",
      "2022-11-08 09:16:58,684 INFO     Training average positive_sample_loss at step 62000: 1.656571\n",
      "2022-11-08 09:16:58,684 INFO     Training average negative_sample_loss at step 62000: 0.847879\n",
      "2022-11-08 09:16:58,684 INFO     Training average loss at step 62000: 1.252225\n",
      "2022-11-08 09:17:01,849 INFO     Training average positive_sample_loss at step 62100: 1.699129\n",
      "2022-11-08 09:17:01,849 INFO     Training average negative_sample_loss at step 62100: 0.847245\n",
      "2022-11-08 09:17:01,849 INFO     Training average loss at step 62100: 1.273187\n",
      "2022-11-08 09:17:05,020 INFO     Training average positive_sample_loss at step 62200: 1.766203\n",
      "2022-11-08 09:17:05,020 INFO     Training average negative_sample_loss at step 62200: 0.840387\n",
      "2022-11-08 09:17:05,020 INFO     Training average loss at step 62200: 1.303295\n",
      "2022-11-08 09:17:08,225 INFO     Training average positive_sample_loss at step 62300: 1.716095\n",
      "2022-11-08 09:17:08,225 INFO     Training average negative_sample_loss at step 62300: 0.848876\n",
      "2022-11-08 09:17:08,225 INFO     Training average loss at step 62300: 1.282486\n",
      "2022-11-08 09:17:11,382 INFO     Training average positive_sample_loss at step 62400: 1.704117\n",
      "2022-11-08 09:17:11,382 INFO     Training average negative_sample_loss at step 62400: 0.847644\n",
      "2022-11-08 09:17:11,382 INFO     Training average loss at step 62400: 1.275880\n",
      "2022-11-08 09:17:14,563 INFO     Training average positive_sample_loss at step 62500: 1.766740\n",
      "2022-11-08 09:17:14,563 INFO     Training average negative_sample_loss at step 62500: 0.823812\n",
      "2022-11-08 09:17:14,563 INFO     Training average loss at step 62500: 1.295276\n",
      "2022-11-08 09:17:17,758 INFO     Training average positive_sample_loss at step 62600: 1.714101\n",
      "2022-11-08 09:17:17,759 INFO     Training average negative_sample_loss at step 62600: 0.823283\n",
      "2022-11-08 09:17:17,759 INFO     Training average loss at step 62600: 1.268692\n",
      "2022-11-08 09:17:20,916 INFO     Training average positive_sample_loss at step 62700: 1.660146\n",
      "2022-11-08 09:17:20,917 INFO     Training average negative_sample_loss at step 62700: 0.848509\n",
      "2022-11-08 09:17:20,917 INFO     Training average loss at step 62700: 1.254327\n",
      "2022-11-08 09:17:24,124 INFO     Training average positive_sample_loss at step 62800: 1.666269\n",
      "2022-11-08 09:17:24,125 INFO     Training average negative_sample_loss at step 62800: 0.834265\n",
      "2022-11-08 09:17:24,125 INFO     Training average loss at step 62800: 1.250267\n",
      "2022-11-08 09:17:27,285 INFO     Training average positive_sample_loss at step 62900: 1.722575\n",
      "2022-11-08 09:17:27,285 INFO     Training average negative_sample_loss at step 62900: 0.834017\n",
      "2022-11-08 09:17:27,285 INFO     Training average loss at step 62900: 1.278296\n",
      "2022-11-08 09:17:30,451 INFO     Training average positive_sample_loss at step 63000: 1.721583\n",
      "2022-11-08 09:17:30,452 INFO     Training average negative_sample_loss at step 63000: 0.839661\n",
      "2022-11-08 09:17:30,452 INFO     Training average loss at step 63000: 1.280622\n",
      "2022-11-08 09:17:33,648 INFO     Training average positive_sample_loss at step 63100: 1.735272\n",
      "2022-11-08 09:17:33,648 INFO     Training average negative_sample_loss at step 63100: 0.836988\n",
      "2022-11-08 09:17:33,648 INFO     Training average loss at step 63100: 1.286130\n",
      "2022-11-08 09:17:36,798 INFO     Training average positive_sample_loss at step 63200: 1.674044\n",
      "2022-11-08 09:17:36,798 INFO     Training average negative_sample_loss at step 63200: 0.836826\n",
      "2022-11-08 09:17:36,798 INFO     Training average loss at step 63200: 1.255435\n",
      "2022-11-08 09:17:39,982 INFO     Training average positive_sample_loss at step 63300: 1.751160\n",
      "2022-11-08 09:17:39,982 INFO     Training average negative_sample_loss at step 63300: 0.835139\n",
      "2022-11-08 09:17:39,982 INFO     Training average loss at step 63300: 1.293150\n",
      "2022-11-08 09:17:43,152 INFO     Training average positive_sample_loss at step 63400: 1.721751\n",
      "2022-11-08 09:17:43,152 INFO     Training average negative_sample_loss at step 63400: 0.838991\n",
      "2022-11-08 09:17:43,152 INFO     Training average loss at step 63400: 1.280371\n",
      "2022-11-08 09:17:46,299 INFO     Training average positive_sample_loss at step 63500: 1.731318\n",
      "2022-11-08 09:17:46,300 INFO     Training average negative_sample_loss at step 63500: 0.840753\n",
      "2022-11-08 09:17:46,300 INFO     Training average loss at step 63500: 1.286036\n",
      "2022-11-08 09:17:49,506 INFO     Training average positive_sample_loss at step 63600: 1.710904\n",
      "2022-11-08 09:17:49,506 INFO     Training average negative_sample_loss at step 63600: 0.845462\n",
      "2022-11-08 09:17:49,506 INFO     Training average loss at step 63600: 1.278183\n",
      "2022-11-08 09:17:52,657 INFO     Training average positive_sample_loss at step 63700: 1.678952\n",
      "2022-11-08 09:17:52,657 INFO     Training average negative_sample_loss at step 63700: 0.844268\n",
      "2022-11-08 09:17:52,657 INFO     Training average loss at step 63700: 1.261610\n",
      "2022-11-08 09:17:55,808 INFO     Training average positive_sample_loss at step 63800: 1.699117\n",
      "2022-11-08 09:17:55,808 INFO     Training average negative_sample_loss at step 63800: 0.843787\n",
      "2022-11-08 09:17:55,808 INFO     Training average loss at step 63800: 1.271452\n",
      "2022-11-08 09:17:59,010 INFO     Training average positive_sample_loss at step 63900: 1.668222\n",
      "2022-11-08 09:17:59,010 INFO     Training average negative_sample_loss at step 63900: 0.836756\n",
      "2022-11-08 09:17:59,010 INFO     Training average loss at step 63900: 1.252489\n",
      "2022-11-08 09:18:02,175 INFO     Training average positive_sample_loss at step 64000: 1.677228\n",
      "2022-11-08 09:18:02,175 INFO     Training average negative_sample_loss at step 64000: 0.836949\n",
      "2022-11-08 09:18:02,175 INFO     Training average loss at step 64000: 1.257088\n",
      "2022-11-08 09:18:05,376 INFO     Training average positive_sample_loss at step 64100: 1.717294\n",
      "2022-11-08 09:18:05,376 INFO     Training average negative_sample_loss at step 64100: 0.833487\n",
      "2022-11-08 09:18:05,376 INFO     Training average loss at step 64100: 1.275390\n",
      "2022-11-08 09:18:08,546 INFO     Training average positive_sample_loss at step 64200: 1.707695\n",
      "2022-11-08 09:18:08,546 INFO     Training average negative_sample_loss at step 64200: 0.829416\n",
      "2022-11-08 09:18:08,546 INFO     Training average loss at step 64200: 1.268556\n",
      "2022-11-08 09:18:11,695 INFO     Training average positive_sample_loss at step 64300: 1.778790\n",
      "2022-11-08 09:18:11,696 INFO     Training average negative_sample_loss at step 64300: 0.819005\n",
      "2022-11-08 09:18:11,696 INFO     Training average loss at step 64300: 1.298897\n",
      "2022-11-08 09:18:14,898 INFO     Training average positive_sample_loss at step 64400: 1.733912\n",
      "2022-11-08 09:18:14,898 INFO     Training average negative_sample_loss at step 64400: 0.834514\n",
      "2022-11-08 09:18:14,898 INFO     Training average loss at step 64400: 1.284213\n",
      "2022-11-08 09:18:18,069 INFO     Training average positive_sample_loss at step 64500: 1.726682\n",
      "2022-11-08 09:18:18,069 INFO     Training average negative_sample_loss at step 64500: 0.820790\n",
      "2022-11-08 09:18:18,069 INFO     Training average loss at step 64500: 1.273736\n",
      "2022-11-08 09:18:21,260 INFO     Training average positive_sample_loss at step 64600: 1.718119\n",
      "2022-11-08 09:18:21,260 INFO     Training average negative_sample_loss at step 64600: 0.817514\n",
      "2022-11-08 09:18:21,260 INFO     Training average loss at step 64600: 1.267816\n",
      "2022-11-08 09:18:24,460 INFO     Training average positive_sample_loss at step 64700: 1.727715\n",
      "2022-11-08 09:18:24,460 INFO     Training average negative_sample_loss at step 64700: 0.822954\n",
      "2022-11-08 09:18:24,460 INFO     Training average loss at step 64700: 1.275334\n",
      "2022-11-08 09:18:27,647 INFO     Training average positive_sample_loss at step 64800: 1.651715\n",
      "2022-11-08 09:18:27,647 INFO     Training average negative_sample_loss at step 64800: 0.827708\n",
      "2022-11-08 09:18:27,647 INFO     Training average loss at step 64800: 1.239711\n",
      "2022-11-08 09:18:30,839 INFO     Training average positive_sample_loss at step 64900: 1.673643\n",
      "2022-11-08 09:18:30,840 INFO     Training average negative_sample_loss at step 64900: 0.827631\n",
      "2022-11-08 09:18:30,840 INFO     Training average loss at step 64900: 1.250637\n",
      "2022-11-08 09:18:34,012 INFO     Training average positive_sample_loss at step 65000: 1.700673\n",
      "2022-11-08 09:18:34,012 INFO     Training average negative_sample_loss at step 65000: 0.821347\n",
      "2022-11-08 09:18:34,012 INFO     Training average loss at step 65000: 1.261010\n",
      "2022-11-08 09:18:37,168 INFO     Training average positive_sample_loss at step 65100: 1.694156\n",
      "2022-11-08 09:18:37,168 INFO     Training average negative_sample_loss at step 65100: 0.829454\n",
      "2022-11-08 09:18:37,168 INFO     Training average loss at step 65100: 1.261805\n",
      "2022-11-08 09:18:40,360 INFO     Training average positive_sample_loss at step 65200: 1.701484\n",
      "2022-11-08 09:18:40,360 INFO     Training average negative_sample_loss at step 65200: 0.826988\n",
      "2022-11-08 09:18:40,360 INFO     Training average loss at step 65200: 1.264236\n",
      "2022-11-08 09:18:43,520 INFO     Training average positive_sample_loss at step 65300: 1.702872\n",
      "2022-11-08 09:18:43,520 INFO     Training average negative_sample_loss at step 65300: 0.819623\n",
      "2022-11-08 09:18:43,520 INFO     Training average loss at step 65300: 1.261247\n",
      "2022-11-08 09:18:46,704 INFO     Training average positive_sample_loss at step 65400: 1.723697\n",
      "2022-11-08 09:18:46,704 INFO     Training average negative_sample_loss at step 65400: 0.822059\n",
      "2022-11-08 09:18:46,704 INFO     Training average loss at step 65400: 1.272878\n",
      "2022-11-08 09:18:49,851 INFO     Training average positive_sample_loss at step 65500: 1.646841\n",
      "2022-11-08 09:18:49,851 INFO     Training average negative_sample_loss at step 65500: 0.828272\n",
      "2022-11-08 09:18:49,851 INFO     Training average loss at step 65500: 1.237556\n",
      "2022-11-08 09:18:52,998 INFO     Training average positive_sample_loss at step 65600: 1.701434\n",
      "2022-11-08 09:18:52,998 INFO     Training average negative_sample_loss at step 65600: 0.822129\n",
      "2022-11-08 09:18:52,998 INFO     Training average loss at step 65600: 1.261781\n",
      "2022-11-08 09:18:57,271 INFO     Training average positive_sample_loss at step 65700: 1.653578\n",
      "2022-11-08 09:18:57,271 INFO     Training average negative_sample_loss at step 65700: 0.822324\n",
      "2022-11-08 09:18:57,272 INFO     Training average loss at step 65700: 1.237951\n",
      "2022-11-08 09:19:00,423 INFO     Training average positive_sample_loss at step 65800: 1.687757\n",
      "2022-11-08 09:19:00,424 INFO     Training average negative_sample_loss at step 65800: 0.811963\n",
      "2022-11-08 09:19:00,424 INFO     Training average loss at step 65800: 1.249860\n",
      "2022-11-08 09:19:04,607 INFO     Training average positive_sample_loss at step 65900: 1.650547\n",
      "2022-11-08 09:19:04,607 INFO     Training average negative_sample_loss at step 65900: 0.813948\n",
      "2022-11-08 09:19:04,607 INFO     Training average loss at step 65900: 1.232247\n",
      "2022-11-08 09:19:08,913 INFO     Training average positive_sample_loss at step 66000: 1.695133\n",
      "2022-11-08 09:19:08,913 INFO     Training average negative_sample_loss at step 66000: 0.820690\n",
      "2022-11-08 09:19:08,913 INFO     Training average loss at step 66000: 1.257912\n",
      "2022-11-08 09:19:12,951 INFO     Training average positive_sample_loss at step 66100: 1.687022\n",
      "2022-11-08 09:19:12,951 INFO     Training average negative_sample_loss at step 66100: 0.810137\n",
      "2022-11-08 09:19:12,951 INFO     Training average loss at step 66100: 1.248579\n",
      "2022-11-08 09:19:16,991 INFO     Training average positive_sample_loss at step 66200: 1.684989\n",
      "2022-11-08 09:19:16,991 INFO     Training average negative_sample_loss at step 66200: 0.823409\n",
      "2022-11-08 09:19:16,991 INFO     Training average loss at step 66200: 1.254199\n",
      "2022-11-08 09:19:20,161 INFO     Training average positive_sample_loss at step 66300: 1.643100\n",
      "2022-11-08 09:19:20,161 INFO     Training average negative_sample_loss at step 66300: 0.823654\n",
      "2022-11-08 09:19:20,161 INFO     Training average loss at step 66300: 1.233377\n",
      "2022-11-08 09:19:23,345 INFO     Training average positive_sample_loss at step 66400: 1.686098\n",
      "2022-11-08 09:19:23,345 INFO     Training average negative_sample_loss at step 66400: 0.811317\n",
      "2022-11-08 09:19:23,345 INFO     Training average loss at step 66400: 1.248708\n",
      "2022-11-08 09:19:26,510 INFO     Training average positive_sample_loss at step 66500: 1.606545\n",
      "2022-11-08 09:19:26,510 INFO     Training average negative_sample_loss at step 66500: 0.824579\n",
      "2022-11-08 09:19:26,510 INFO     Training average loss at step 66500: 1.215562\n",
      "2022-11-08 09:19:29,700 INFO     Training average positive_sample_loss at step 66600: 1.666828\n",
      "2022-11-08 09:19:29,701 INFO     Training average negative_sample_loss at step 66600: 0.823163\n",
      "2022-11-08 09:19:29,701 INFO     Training average loss at step 66600: 1.244995\n",
      "2022-11-08 09:19:32,832 INFO     Training average positive_sample_loss at step 66700: 1.684660\n",
      "2022-11-08 09:19:32,832 INFO     Training average negative_sample_loss at step 66700: 0.810086\n",
      "2022-11-08 09:19:32,832 INFO     Training average loss at step 66700: 1.247373\n",
      "2022-11-08 09:19:36,025 INFO     Training average positive_sample_loss at step 66800: 1.695612\n",
      "2022-11-08 09:19:36,025 INFO     Training average negative_sample_loss at step 66800: 0.810150\n",
      "2022-11-08 09:19:36,025 INFO     Training average loss at step 66800: 1.252881\n",
      "2022-11-08 09:19:39,164 INFO     Training average positive_sample_loss at step 66900: 1.665245\n",
      "2022-11-08 09:19:39,164 INFO     Training average negative_sample_loss at step 66900: 0.809608\n",
      "2022-11-08 09:19:39,164 INFO     Training average loss at step 66900: 1.237426\n",
      "2022-11-08 09:19:42,326 INFO     Training average positive_sample_loss at step 67000: 1.673510\n",
      "2022-11-08 09:19:42,326 INFO     Training average negative_sample_loss at step 67000: 0.810386\n",
      "2022-11-08 09:19:42,326 INFO     Training average loss at step 67000: 1.241948\n",
      "2022-11-08 09:19:45,496 INFO     Training average positive_sample_loss at step 67100: 1.629493\n",
      "2022-11-08 09:19:45,496 INFO     Training average negative_sample_loss at step 67100: 0.813041\n",
      "2022-11-08 09:19:45,496 INFO     Training average loss at step 67100: 1.221267\n",
      "2022-11-08 09:19:48,629 INFO     Training average positive_sample_loss at step 67200: 1.646319\n",
      "2022-11-08 09:19:48,629 INFO     Training average negative_sample_loss at step 67200: 0.810320\n",
      "2022-11-08 09:19:48,629 INFO     Training average loss at step 67200: 1.228319\n",
      "2022-11-08 09:19:51,830 INFO     Training average positive_sample_loss at step 67300: 1.698587\n",
      "2022-11-08 09:19:51,830 INFO     Training average negative_sample_loss at step 67300: 0.800493\n",
      "2022-11-08 09:19:51,830 INFO     Training average loss at step 67300: 1.249540\n",
      "2022-11-08 09:19:54,985 INFO     Training average positive_sample_loss at step 67400: 1.685102\n",
      "2022-11-08 09:19:54,985 INFO     Training average negative_sample_loss at step 67400: 0.803559\n",
      "2022-11-08 09:19:54,985 INFO     Training average loss at step 67400: 1.244331\n",
      "2022-11-08 09:19:58,184 INFO     Training average positive_sample_loss at step 67500: 1.636459\n",
      "2022-11-08 09:19:58,184 INFO     Training average negative_sample_loss at step 67500: 0.816851\n",
      "2022-11-08 09:19:58,184 INFO     Training average loss at step 67500: 1.226655\n",
      "2022-11-08 09:20:01,327 INFO     Training average positive_sample_loss at step 67600: 1.673229\n",
      "2022-11-08 09:20:01,327 INFO     Training average negative_sample_loss at step 67600: 0.811790\n",
      "2022-11-08 09:20:01,327 INFO     Training average loss at step 67600: 1.242509\n",
      "2022-11-08 09:20:04,499 INFO     Training average positive_sample_loss at step 67700: 1.682677\n",
      "2022-11-08 09:20:04,499 INFO     Training average negative_sample_loss at step 67700: 0.803684\n",
      "2022-11-08 09:20:04,499 INFO     Training average loss at step 67700: 1.243180\n",
      "2022-11-08 09:20:07,718 INFO     Training average positive_sample_loss at step 67800: 1.685206\n",
      "2022-11-08 09:20:07,718 INFO     Training average negative_sample_loss at step 67800: 0.810432\n",
      "2022-11-08 09:20:07,718 INFO     Training average loss at step 67800: 1.247819\n",
      "2022-11-08 09:20:10,995 INFO     Training average positive_sample_loss at step 67900: 1.657575\n",
      "2022-11-08 09:20:10,995 INFO     Training average negative_sample_loss at step 67900: 0.813416\n",
      "2022-11-08 09:20:10,995 INFO     Training average loss at step 67900: 1.235495\n",
      "2022-11-08 09:20:14,260 INFO     Training average positive_sample_loss at step 68000: 1.689631\n",
      "2022-11-08 09:20:14,260 INFO     Training average negative_sample_loss at step 68000: 0.800390\n",
      "2022-11-08 09:20:14,260 INFO     Training average loss at step 68000: 1.245010\n",
      "2022-11-08 09:20:17,489 INFO     Training average positive_sample_loss at step 68100: 1.671488\n",
      "2022-11-08 09:20:17,489 INFO     Training average negative_sample_loss at step 68100: 0.807299\n",
      "2022-11-08 09:20:17,489 INFO     Training average loss at step 68100: 1.239394\n",
      "2022-11-08 09:20:20,787 INFO     Training average positive_sample_loss at step 68200: 1.675567\n",
      "2022-11-08 09:20:20,787 INFO     Training average negative_sample_loss at step 68200: 0.805864\n",
      "2022-11-08 09:20:20,788 INFO     Training average loss at step 68200: 1.240715\n",
      "2022-11-08 09:20:24,018 INFO     Training average positive_sample_loss at step 68300: 1.677687\n",
      "2022-11-08 09:20:24,018 INFO     Training average negative_sample_loss at step 68300: 0.805737\n",
      "2022-11-08 09:20:24,018 INFO     Training average loss at step 68300: 1.241712\n",
      "2022-11-08 09:20:27,261 INFO     Training average positive_sample_loss at step 68400: 1.629331\n",
      "2022-11-08 09:20:27,261 INFO     Training average negative_sample_loss at step 68400: 0.804955\n",
      "2022-11-08 09:20:27,261 INFO     Training average loss at step 68400: 1.217143\n",
      "2022-11-08 09:20:30,454 INFO     Training average positive_sample_loss at step 68500: 1.671581\n",
      "2022-11-08 09:20:30,454 INFO     Training average negative_sample_loss at step 68500: 0.793752\n",
      "2022-11-08 09:20:30,454 INFO     Training average loss at step 68500: 1.232666\n",
      "2022-11-08 09:20:33,811 INFO     Training average positive_sample_loss at step 68600: 1.652664\n",
      "2022-11-08 09:20:33,811 INFO     Training average negative_sample_loss at step 68600: 0.801865\n",
      "2022-11-08 09:20:33,811 INFO     Training average loss at step 68600: 1.227265\n",
      "2022-11-08 09:20:37,040 INFO     Training average positive_sample_loss at step 68700: 1.673727\n",
      "2022-11-08 09:20:37,040 INFO     Training average negative_sample_loss at step 68700: 0.804075\n",
      "2022-11-08 09:20:37,040 INFO     Training average loss at step 68700: 1.238901\n",
      "2022-11-08 09:20:40,296 INFO     Training average positive_sample_loss at step 68800: 1.668728\n",
      "2022-11-08 09:20:40,296 INFO     Training average negative_sample_loss at step 68800: 0.800909\n",
      "2022-11-08 09:20:40,296 INFO     Training average loss at step 68800: 1.234819\n",
      "2022-11-08 09:20:43,480 INFO     Training average positive_sample_loss at step 68900: 1.621706\n",
      "2022-11-08 09:20:43,480 INFO     Training average negative_sample_loss at step 68900: 0.795813\n",
      "2022-11-08 09:20:43,480 INFO     Training average loss at step 68900: 1.208759\n",
      "2022-11-08 09:20:46,681 INFO     Training average positive_sample_loss at step 69000: 1.658201\n",
      "2022-11-08 09:20:46,681 INFO     Training average negative_sample_loss at step 69000: 0.792895\n",
      "2022-11-08 09:20:46,681 INFO     Training average loss at step 69000: 1.225548\n",
      "2022-11-08 09:20:49,827 INFO     Training average positive_sample_loss at step 69100: 1.719618\n",
      "2022-11-08 09:20:49,827 INFO     Training average negative_sample_loss at step 69100: 0.788624\n",
      "2022-11-08 09:20:49,827 INFO     Training average loss at step 69100: 1.254121\n",
      "2022-11-08 09:20:53,046 INFO     Training average positive_sample_loss at step 69200: 1.702847\n",
      "2022-11-08 09:20:53,046 INFO     Training average negative_sample_loss at step 69200: 0.797476\n",
      "2022-11-08 09:20:53,046 INFO     Training average loss at step 69200: 1.250162\n",
      "2022-11-08 09:20:56,283 INFO     Training average positive_sample_loss at step 69300: 1.711176\n",
      "2022-11-08 09:20:56,284 INFO     Training average negative_sample_loss at step 69300: 0.793588\n",
      "2022-11-08 09:20:56,284 INFO     Training average loss at step 69300: 1.252382\n",
      "2022-11-08 09:20:59,455 INFO     Training average positive_sample_loss at step 69400: 1.649482\n",
      "2022-11-08 09:20:59,455 INFO     Training average negative_sample_loss at step 69400: 0.796773\n",
      "2022-11-08 09:20:59,455 INFO     Training average loss at step 69400: 1.223127\n",
      "2022-11-08 09:21:02,689 INFO     Training average positive_sample_loss at step 69500: 1.686035\n",
      "2022-11-08 09:21:02,689 INFO     Training average negative_sample_loss at step 69500: 0.790902\n",
      "2022-11-08 09:21:02,689 INFO     Training average loss at step 69500: 1.238468\n",
      "2022-11-08 09:21:05,892 INFO     Training average positive_sample_loss at step 69600: 1.622991\n",
      "2022-11-08 09:21:05,892 INFO     Training average negative_sample_loss at step 69600: 0.799613\n",
      "2022-11-08 09:21:05,892 INFO     Training average loss at step 69600: 1.211302\n",
      "2022-11-08 09:21:09,129 INFO     Training average positive_sample_loss at step 69700: 1.669101\n",
      "2022-11-08 09:21:09,129 INFO     Training average negative_sample_loss at step 69700: 0.791343\n",
      "2022-11-08 09:21:09,129 INFO     Training average loss at step 69700: 1.230222\n",
      "2022-11-08 09:21:12,361 INFO     Training average positive_sample_loss at step 69800: 1.661812\n",
      "2022-11-08 09:21:12,361 INFO     Training average negative_sample_loss at step 69800: 0.787256\n",
      "2022-11-08 09:21:12,361 INFO     Training average loss at step 69800: 1.224534\n",
      "2022-11-08 09:21:15,665 INFO     Training average positive_sample_loss at step 69900: 1.615604\n",
      "2022-11-08 09:21:15,665 INFO     Training average negative_sample_loss at step 69900: 0.779283\n",
      "2022-11-08 09:21:15,665 INFO     Training average loss at step 69900: 1.197444\n",
      "2022-11-08 09:21:21,845 INFO     Training average positive_sample_loss at step 70000: 1.658767\n",
      "2022-11-08 09:21:21,845 INFO     Training average negative_sample_loss at step 70000: 0.790515\n",
      "2022-11-08 09:21:21,845 INFO     Training average loss at step 70000: 1.224641\n",
      "2022-11-08 09:21:25,068 INFO     Training average positive_sample_loss at step 70100: 1.672242\n",
      "2022-11-08 09:21:25,068 INFO     Training average negative_sample_loss at step 70100: 0.791590\n",
      "2022-11-08 09:21:25,068 INFO     Training average loss at step 70100: 1.231916\n",
      "2022-11-08 09:21:28,286 INFO     Training average positive_sample_loss at step 70200: 1.607608\n",
      "2022-11-08 09:21:28,286 INFO     Training average negative_sample_loss at step 70200: 0.790782\n",
      "2022-11-08 09:21:28,286 INFO     Training average loss at step 70200: 1.199195\n",
      "2022-11-08 09:21:32,369 INFO     Training average positive_sample_loss at step 70300: 1.691947\n",
      "2022-11-08 09:21:32,369 INFO     Training average negative_sample_loss at step 70300: 0.784659\n",
      "2022-11-08 09:21:32,369 INFO     Training average loss at step 70300: 1.238303\n",
      "2022-11-08 09:21:36,739 INFO     Training average positive_sample_loss at step 70400: 1.648629\n",
      "2022-11-08 09:21:36,739 INFO     Training average negative_sample_loss at step 70400: 0.781737\n",
      "2022-11-08 09:21:36,739 INFO     Training average loss at step 70400: 1.215183\n",
      "2022-11-08 09:21:40,047 INFO     Training average positive_sample_loss at step 70500: 1.706762\n",
      "2022-11-08 09:21:40,047 INFO     Training average negative_sample_loss at step 70500: 0.779833\n",
      "2022-11-08 09:21:40,047 INFO     Training average loss at step 70500: 1.243298\n",
      "2022-11-08 09:21:43,345 INFO     Training average positive_sample_loss at step 70600: 1.661328\n",
      "2022-11-08 09:21:43,345 INFO     Training average negative_sample_loss at step 70600: 0.796457\n",
      "2022-11-08 09:21:43,345 INFO     Training average loss at step 70600: 1.228892\n",
      "2022-11-08 09:21:47,732 INFO     Training average positive_sample_loss at step 70700: 1.624321\n",
      "2022-11-08 09:21:47,732 INFO     Training average negative_sample_loss at step 70700: 0.789952\n",
      "2022-11-08 09:21:47,732 INFO     Training average loss at step 70700: 1.207136\n",
      "2022-11-08 09:21:51,882 INFO     Training average positive_sample_loss at step 70800: 1.619200\n",
      "2022-11-08 09:21:51,883 INFO     Training average negative_sample_loss at step 70800: 0.785958\n",
      "2022-11-08 09:21:51,883 INFO     Training average loss at step 70800: 1.202579\n",
      "2022-11-08 09:21:56,099 INFO     Training average positive_sample_loss at step 70900: 1.627274\n",
      "2022-11-08 09:21:56,100 INFO     Training average negative_sample_loss at step 70900: 0.787119\n",
      "2022-11-08 09:21:56,100 INFO     Training average loss at step 70900: 1.207196\n",
      "2022-11-08 09:21:59,319 INFO     Training average positive_sample_loss at step 71000: 1.642526\n",
      "2022-11-08 09:21:59,319 INFO     Training average negative_sample_loss at step 71000: 0.782322\n",
      "2022-11-08 09:21:59,319 INFO     Training average loss at step 71000: 1.212424\n",
      "2022-11-08 09:22:02,620 INFO     Training average positive_sample_loss at step 71100: 1.598334\n",
      "2022-11-08 09:22:02,620 INFO     Training average negative_sample_loss at step 71100: 0.789545\n",
      "2022-11-08 09:22:02,620 INFO     Training average loss at step 71100: 1.193940\n",
      "2022-11-08 09:22:05,861 INFO     Training average positive_sample_loss at step 71200: 1.627827\n",
      "2022-11-08 09:22:05,861 INFO     Training average negative_sample_loss at step 71200: 0.783647\n",
      "2022-11-08 09:22:05,861 INFO     Training average loss at step 71200: 1.205737\n",
      "2022-11-08 09:22:09,035 INFO     Training average positive_sample_loss at step 71300: 1.664612\n",
      "2022-11-08 09:22:09,036 INFO     Training average negative_sample_loss at step 71300: 0.778153\n",
      "2022-11-08 09:22:09,036 INFO     Training average loss at step 71300: 1.221382\n",
      "2022-11-08 09:22:12,236 INFO     Training average positive_sample_loss at step 71400: 1.641253\n",
      "2022-11-08 09:22:12,236 INFO     Training average negative_sample_loss at step 71400: 0.785535\n",
      "2022-11-08 09:22:12,236 INFO     Training average loss at step 71400: 1.213394\n",
      "2022-11-08 09:22:15,488 INFO     Training average positive_sample_loss at step 71500: 1.665406\n",
      "2022-11-08 09:22:15,488 INFO     Training average negative_sample_loss at step 71500: 0.779499\n",
      "2022-11-08 09:22:15,488 INFO     Training average loss at step 71500: 1.222452\n",
      "2022-11-08 09:22:18,704 INFO     Training average positive_sample_loss at step 71600: 1.600274\n",
      "2022-11-08 09:22:18,705 INFO     Training average negative_sample_loss at step 71600: 0.779540\n",
      "2022-11-08 09:22:18,705 INFO     Training average loss at step 71600: 1.189907\n",
      "2022-11-08 09:22:21,882 INFO     Training average positive_sample_loss at step 71700: 1.602630\n",
      "2022-11-08 09:22:21,882 INFO     Training average negative_sample_loss at step 71700: 0.778879\n",
      "2022-11-08 09:22:21,882 INFO     Training average loss at step 71700: 1.190755\n",
      "2022-11-08 09:22:25,062 INFO     Training average positive_sample_loss at step 71800: 1.625109\n",
      "2022-11-08 09:22:25,062 INFO     Training average negative_sample_loss at step 71800: 0.779744\n",
      "2022-11-08 09:22:25,062 INFO     Training average loss at step 71800: 1.202426\n",
      "2022-11-08 09:22:28,284 INFO     Training average positive_sample_loss at step 71900: 1.622379\n",
      "2022-11-08 09:22:28,284 INFO     Training average negative_sample_loss at step 71900: 0.774218\n",
      "2022-11-08 09:22:28,284 INFO     Training average loss at step 71900: 1.198298\n",
      "2022-11-08 09:22:31,460 INFO     Training average positive_sample_loss at step 72000: 1.621722\n",
      "2022-11-08 09:22:31,460 INFO     Training average negative_sample_loss at step 72000: 0.775374\n",
      "2022-11-08 09:22:31,460 INFO     Training average loss at step 72000: 1.198548\n",
      "2022-11-08 09:22:34,615 INFO     Training average positive_sample_loss at step 72100: 1.654719\n",
      "2022-11-08 09:22:34,615 INFO     Training average negative_sample_loss at step 72100: 0.772788\n",
      "2022-11-08 09:22:34,615 INFO     Training average loss at step 72100: 1.213753\n",
      "2022-11-08 09:22:37,812 INFO     Training average positive_sample_loss at step 72200: 1.606665\n",
      "2022-11-08 09:22:37,812 INFO     Training average negative_sample_loss at step 72200: 0.764580\n",
      "2022-11-08 09:22:37,812 INFO     Training average loss at step 72200: 1.185623\n",
      "2022-11-08 09:22:41,050 INFO     Training average positive_sample_loss at step 72300: 1.655170\n",
      "2022-11-08 09:22:41,051 INFO     Training average negative_sample_loss at step 72300: 0.771225\n",
      "2022-11-08 09:22:41,051 INFO     Training average loss at step 72300: 1.213198\n",
      "2022-11-08 09:22:44,275 INFO     Training average positive_sample_loss at step 72400: 1.629142\n",
      "2022-11-08 09:22:44,275 INFO     Training average negative_sample_loss at step 72400: 0.767772\n",
      "2022-11-08 09:22:44,276 INFO     Training average loss at step 72400: 1.198457\n",
      "2022-11-08 09:22:47,466 INFO     Training average positive_sample_loss at step 72500: 1.607684\n",
      "2022-11-08 09:22:47,466 INFO     Training average negative_sample_loss at step 72500: 0.777915\n",
      "2022-11-08 09:22:47,467 INFO     Training average loss at step 72500: 1.192800\n",
      "2022-11-08 09:22:50,653 INFO     Training average positive_sample_loss at step 72600: 1.677976\n",
      "2022-11-08 09:22:50,653 INFO     Training average negative_sample_loss at step 72600: 0.759360\n",
      "2022-11-08 09:22:50,653 INFO     Training average loss at step 72600: 1.218668\n",
      "2022-11-08 09:22:53,921 INFO     Training average positive_sample_loss at step 72700: 1.637671\n",
      "2022-11-08 09:22:53,921 INFO     Training average negative_sample_loss at step 72700: 0.773411\n",
      "2022-11-08 09:22:53,921 INFO     Training average loss at step 72700: 1.205541\n",
      "2022-11-08 09:22:57,177 INFO     Training average positive_sample_loss at step 72800: 1.617582\n",
      "2022-11-08 09:22:57,177 INFO     Training average negative_sample_loss at step 72800: 0.775832\n",
      "2022-11-08 09:22:57,177 INFO     Training average loss at step 72800: 1.196707\n",
      "2022-11-08 09:23:00,378 INFO     Training average positive_sample_loss at step 72900: 1.563502\n",
      "2022-11-08 09:23:00,378 INFO     Training average negative_sample_loss at step 72900: 0.775203\n",
      "2022-11-08 09:23:00,378 INFO     Training average loss at step 72900: 1.169352\n",
      "2022-11-08 09:23:03,594 INFO     Training average positive_sample_loss at step 73000: 1.621105\n",
      "2022-11-08 09:23:03,594 INFO     Training average negative_sample_loss at step 73000: 0.765783\n",
      "2022-11-08 09:23:03,594 INFO     Training average loss at step 73000: 1.193444\n",
      "2022-11-08 09:23:06,804 INFO     Training average positive_sample_loss at step 73100: 1.619241\n",
      "2022-11-08 09:23:06,804 INFO     Training average negative_sample_loss at step 73100: 0.768402\n",
      "2022-11-08 09:23:06,804 INFO     Training average loss at step 73100: 1.193822\n",
      "2022-11-08 09:23:10,004 INFO     Training average positive_sample_loss at step 73200: 1.614051\n",
      "2022-11-08 09:23:10,004 INFO     Training average negative_sample_loss at step 73200: 0.768689\n",
      "2022-11-08 09:23:10,004 INFO     Training average loss at step 73200: 1.191370\n",
      "2022-11-08 09:23:13,200 INFO     Training average positive_sample_loss at step 73300: 1.598740\n",
      "2022-11-08 09:23:13,201 INFO     Training average negative_sample_loss at step 73300: 0.772711\n",
      "2022-11-08 09:23:13,201 INFO     Training average loss at step 73300: 1.185725\n",
      "2022-11-08 09:23:16,352 INFO     Training average positive_sample_loss at step 73400: 1.590855\n",
      "2022-11-08 09:23:16,352 INFO     Training average negative_sample_loss at step 73400: 0.771641\n",
      "2022-11-08 09:23:16,352 INFO     Training average loss at step 73400: 1.181248\n",
      "2022-11-08 09:23:19,578 INFO     Training average positive_sample_loss at step 73500: 1.622990\n",
      "2022-11-08 09:23:19,578 INFO     Training average negative_sample_loss at step 73500: 0.764884\n",
      "2022-11-08 09:23:19,578 INFO     Training average loss at step 73500: 1.193937\n",
      "2022-11-08 09:23:22,743 INFO     Training average positive_sample_loss at step 73600: 1.657023\n",
      "2022-11-08 09:23:22,743 INFO     Training average negative_sample_loss at step 73600: 0.767932\n",
      "2022-11-08 09:23:22,743 INFO     Training average loss at step 73600: 1.212478\n",
      "2022-11-08 09:23:25,917 INFO     Training average positive_sample_loss at step 73700: 1.602626\n",
      "2022-11-08 09:23:25,917 INFO     Training average negative_sample_loss at step 73700: 0.764729\n",
      "2022-11-08 09:23:25,917 INFO     Training average loss at step 73700: 1.183677\n",
      "2022-11-08 09:23:29,135 INFO     Training average positive_sample_loss at step 73800: 1.636952\n",
      "2022-11-08 09:23:29,136 INFO     Training average negative_sample_loss at step 73800: 0.750394\n",
      "2022-11-08 09:23:29,136 INFO     Training average loss at step 73800: 1.193673\n",
      "2022-11-08 09:23:32,320 INFO     Training average positive_sample_loss at step 73900: 1.591779\n",
      "2022-11-08 09:23:32,320 INFO     Training average negative_sample_loss at step 73900: 0.775401\n",
      "2022-11-08 09:23:32,320 INFO     Training average loss at step 73900: 1.183590\n",
      "2022-11-08 09:23:35,603 INFO     Training average positive_sample_loss at step 74000: 1.632858\n",
      "2022-11-08 09:23:35,603 INFO     Training average negative_sample_loss at step 74000: 0.756188\n",
      "2022-11-08 09:23:35,603 INFO     Training average loss at step 74000: 1.194523\n",
      "2022-11-08 09:23:38,945 INFO     Training average positive_sample_loss at step 74100: 1.557203\n",
      "2022-11-08 09:23:38,945 INFO     Training average negative_sample_loss at step 74100: 0.767471\n",
      "2022-11-08 09:23:38,945 INFO     Training average loss at step 74100: 1.162337\n",
      "2022-11-08 09:23:42,237 INFO     Training average positive_sample_loss at step 74200: 1.598115\n",
      "2022-11-08 09:23:42,238 INFO     Training average negative_sample_loss at step 74200: 0.761933\n",
      "2022-11-08 09:23:42,238 INFO     Training average loss at step 74200: 1.180024\n",
      "2022-11-08 09:23:45,516 INFO     Training average positive_sample_loss at step 74300: 1.575767\n",
      "2022-11-08 09:23:45,516 INFO     Training average negative_sample_loss at step 74300: 0.765696\n",
      "2022-11-08 09:23:45,516 INFO     Training average loss at step 74300: 1.170732\n",
      "2022-11-08 09:23:48,867 INFO     Training average positive_sample_loss at step 74400: 1.599899\n",
      "2022-11-08 09:23:48,867 INFO     Training average negative_sample_loss at step 74400: 0.770355\n",
      "2022-11-08 09:23:48,867 INFO     Training average loss at step 74400: 1.185127\n",
      "2022-11-08 09:23:52,140 INFO     Training average positive_sample_loss at step 74500: 1.602288\n",
      "2022-11-08 09:23:52,141 INFO     Training average negative_sample_loss at step 74500: 0.759974\n",
      "2022-11-08 09:23:52,141 INFO     Training average loss at step 74500: 1.181131\n",
      "2022-11-08 09:23:55,367 INFO     Training average positive_sample_loss at step 74600: 1.626229\n",
      "2022-11-08 09:23:55,367 INFO     Training average negative_sample_loss at step 74600: 0.751499\n",
      "2022-11-08 09:23:55,367 INFO     Training average loss at step 74600: 1.188864\n",
      "2022-11-08 09:23:58,609 INFO     Training average positive_sample_loss at step 74700: 1.577047\n",
      "2022-11-08 09:23:58,609 INFO     Training average negative_sample_loss at step 74700: 0.759036\n",
      "2022-11-08 09:23:58,609 INFO     Training average loss at step 74700: 1.168042\n",
      "2022-11-08 09:24:01,808 INFO     Training average positive_sample_loss at step 74800: 1.603862\n",
      "2022-11-08 09:24:01,808 INFO     Training average negative_sample_loss at step 74800: 0.759464\n",
      "2022-11-08 09:24:01,808 INFO     Training average loss at step 74800: 1.181663\n",
      "2022-11-08 09:24:05,029 INFO     Training average positive_sample_loss at step 74900: 1.624439\n",
      "2022-11-08 09:24:05,029 INFO     Training average negative_sample_loss at step 74900: 0.764814\n",
      "2022-11-08 09:24:05,029 INFO     Training average loss at step 74900: 1.194626\n",
      "2022-11-08 09:24:09,188 INFO     Training average positive_sample_loss at step 75000: 1.631551\n",
      "2022-11-08 09:24:09,188 INFO     Training average negative_sample_loss at step 75000: 0.763232\n",
      "2022-11-08 09:24:09,188 INFO     Training average loss at step 75000: 1.197392\n",
      "2022-11-08 09:24:13,494 INFO     Training average positive_sample_loss at step 75100: 1.543621\n",
      "2022-11-08 09:24:13,494 INFO     Training average negative_sample_loss at step 75100: 0.764087\n",
      "2022-11-08 09:24:13,494 INFO     Training average loss at step 75100: 1.153854\n",
      "2022-11-08 09:24:16,718 INFO     Training average positive_sample_loss at step 75200: 1.594201\n",
      "2022-11-08 09:24:16,718 INFO     Training average negative_sample_loss at step 75200: 0.754284\n",
      "2022-11-08 09:24:16,718 INFO     Training average loss at step 75200: 1.174242\n",
      "2022-11-08 09:24:19,927 INFO     Training average positive_sample_loss at step 75300: 1.587030\n",
      "2022-11-08 09:24:19,927 INFO     Training average negative_sample_loss at step 75300: 0.763406\n",
      "2022-11-08 09:24:19,927 INFO     Training average loss at step 75300: 1.175218\n",
      "2022-11-08 09:24:24,312 INFO     Training average positive_sample_loss at step 75400: 1.618146\n",
      "2022-11-08 09:24:24,312 INFO     Training average negative_sample_loss at step 75400: 0.758411\n",
      "2022-11-08 09:24:24,312 INFO     Training average loss at step 75400: 1.188278\n",
      "2022-11-08 09:24:28,363 INFO     Training average positive_sample_loss at step 75500: 1.597802\n",
      "2022-11-08 09:24:28,363 INFO     Training average negative_sample_loss at step 75500: 0.751818\n",
      "2022-11-08 09:24:28,363 INFO     Training average loss at step 75500: 1.174810\n",
      "2022-11-08 09:24:32,367 INFO     Training average positive_sample_loss at step 75600: 1.589417\n",
      "2022-11-08 09:24:32,367 INFO     Training average negative_sample_loss at step 75600: 0.749085\n",
      "2022-11-08 09:24:32,367 INFO     Training average loss at step 75600: 1.169251\n",
      "2022-11-08 09:24:35,536 INFO     Training average positive_sample_loss at step 75700: 1.596112\n",
      "2022-11-08 09:24:35,537 INFO     Training average negative_sample_loss at step 75700: 0.754437\n",
      "2022-11-08 09:24:35,537 INFO     Training average loss at step 75700: 1.175275\n",
      "2022-11-08 09:24:38,696 INFO     Training average positive_sample_loss at step 75800: 1.571879\n",
      "2022-11-08 09:24:38,696 INFO     Training average negative_sample_loss at step 75800: 0.752183\n",
      "2022-11-08 09:24:38,696 INFO     Training average loss at step 75800: 1.162031\n",
      "2022-11-08 09:24:41,944 INFO     Training average positive_sample_loss at step 75900: 1.649228\n",
      "2022-11-08 09:24:41,944 INFO     Training average negative_sample_loss at step 75900: 0.742494\n",
      "2022-11-08 09:24:41,944 INFO     Training average loss at step 75900: 1.195861\n",
      "2022-11-08 09:24:45,151 INFO     Training average positive_sample_loss at step 76000: 1.552792\n",
      "2022-11-08 09:24:45,151 INFO     Training average negative_sample_loss at step 76000: 0.757693\n",
      "2022-11-08 09:24:45,152 INFO     Training average loss at step 76000: 1.155242\n",
      "2022-11-08 09:24:48,366 INFO     Training average positive_sample_loss at step 76100: 1.611910\n",
      "2022-11-08 09:24:48,366 INFO     Training average negative_sample_loss at step 76100: 0.740768\n",
      "2022-11-08 09:24:48,366 INFO     Training average loss at step 76100: 1.176339\n",
      "2022-11-08 09:24:51,594 INFO     Training average positive_sample_loss at step 76200: 1.590795\n",
      "2022-11-08 09:24:51,594 INFO     Training average negative_sample_loss at step 76200: 0.743110\n",
      "2022-11-08 09:24:51,594 INFO     Training average loss at step 76200: 1.166953\n",
      "2022-11-08 09:24:54,904 INFO     Training average positive_sample_loss at step 76300: 1.600404\n",
      "2022-11-08 09:24:54,904 INFO     Training average negative_sample_loss at step 76300: 0.740540\n",
      "2022-11-08 09:24:54,904 INFO     Training average loss at step 76300: 1.170472\n",
      "2022-11-08 09:24:58,374 INFO     Training average positive_sample_loss at step 76400: 1.608342\n",
      "2022-11-08 09:24:58,375 INFO     Training average negative_sample_loss at step 76400: 0.746334\n",
      "2022-11-08 09:24:58,375 INFO     Training average loss at step 76400: 1.177338\n",
      "2022-11-08 09:25:01,829 INFO     Training average positive_sample_loss at step 76500: 1.603029\n",
      "2022-11-08 09:25:01,829 INFO     Training average negative_sample_loss at step 76500: 0.745927\n",
      "2022-11-08 09:25:01,829 INFO     Training average loss at step 76500: 1.174478\n",
      "2022-11-08 09:25:05,317 INFO     Training average positive_sample_loss at step 76600: 1.583743\n",
      "2022-11-08 09:25:05,317 INFO     Training average negative_sample_loss at step 76600: 0.739681\n",
      "2022-11-08 09:25:05,317 INFO     Training average loss at step 76600: 1.161712\n",
      "2022-11-08 09:25:08,709 INFO     Training average positive_sample_loss at step 76700: 1.616935\n",
      "2022-11-08 09:25:08,709 INFO     Training average negative_sample_loss at step 76700: 0.741010\n",
      "2022-11-08 09:25:08,709 INFO     Training average loss at step 76700: 1.178972\n",
      "2022-11-08 09:25:12,101 INFO     Training average positive_sample_loss at step 76800: 1.606807\n",
      "2022-11-08 09:25:12,101 INFO     Training average negative_sample_loss at step 76800: 0.741077\n",
      "2022-11-08 09:25:12,101 INFO     Training average loss at step 76800: 1.173942\n",
      "2022-11-08 09:25:15,400 INFO     Training average positive_sample_loss at step 76900: 1.582539\n",
      "2022-11-08 09:25:15,400 INFO     Training average negative_sample_loss at step 76900: 0.742602\n",
      "2022-11-08 09:25:15,400 INFO     Training average loss at step 76900: 1.162571\n",
      "2022-11-08 09:25:18,673 INFO     Training average positive_sample_loss at step 77000: 1.608191\n",
      "2022-11-08 09:25:18,673 INFO     Training average negative_sample_loss at step 77000: 0.740419\n",
      "2022-11-08 09:25:18,673 INFO     Training average loss at step 77000: 1.174305\n",
      "2022-11-08 09:25:21,878 INFO     Training average positive_sample_loss at step 77100: 1.562638\n",
      "2022-11-08 09:25:21,878 INFO     Training average negative_sample_loss at step 77100: 0.742266\n",
      "2022-11-08 09:25:21,878 INFO     Training average loss at step 77100: 1.152452\n",
      "2022-11-08 09:25:25,063 INFO     Training average positive_sample_loss at step 77200: 1.617636\n",
      "2022-11-08 09:25:25,063 INFO     Training average negative_sample_loss at step 77200: 0.738497\n",
      "2022-11-08 09:25:25,063 INFO     Training average loss at step 77200: 1.178067\n",
      "2022-11-08 09:25:28,299 INFO     Training average positive_sample_loss at step 77300: 1.551459\n",
      "2022-11-08 09:25:28,299 INFO     Training average negative_sample_loss at step 77300: 0.746616\n",
      "2022-11-08 09:25:28,299 INFO     Training average loss at step 77300: 1.149038\n",
      "2022-11-08 09:25:31,533 INFO     Training average positive_sample_loss at step 77400: 1.530048\n",
      "2022-11-08 09:25:31,533 INFO     Training average negative_sample_loss at step 77400: 0.735110\n",
      "2022-11-08 09:25:31,533 INFO     Training average loss at step 77400: 1.132579\n",
      "2022-11-08 09:25:34,725 INFO     Training average positive_sample_loss at step 77500: 1.573789\n",
      "2022-11-08 09:25:34,725 INFO     Training average negative_sample_loss at step 77500: 0.736880\n",
      "2022-11-08 09:25:34,725 INFO     Training average loss at step 77500: 1.155335\n",
      "2022-11-08 09:25:37,916 INFO     Training average positive_sample_loss at step 77600: 1.600717\n",
      "2022-11-08 09:25:37,916 INFO     Training average negative_sample_loss at step 77600: 0.731300\n",
      "2022-11-08 09:25:37,916 INFO     Training average loss at step 77600: 1.166008\n",
      "2022-11-08 09:25:41,175 INFO     Training average positive_sample_loss at step 77700: 1.577693\n",
      "2022-11-08 09:25:41,175 INFO     Training average negative_sample_loss at step 77700: 0.728051\n",
      "2022-11-08 09:25:41,175 INFO     Training average loss at step 77700: 1.152872\n",
      "2022-11-08 09:25:44,357 INFO     Training average positive_sample_loss at step 77800: 1.560061\n",
      "2022-11-08 09:25:44,357 INFO     Training average negative_sample_loss at step 77800: 0.732895\n",
      "2022-11-08 09:25:44,357 INFO     Training average loss at step 77800: 1.146478\n",
      "2022-11-08 09:25:47,572 INFO     Training average positive_sample_loss at step 77900: 1.592789\n",
      "2022-11-08 09:25:47,572 INFO     Training average negative_sample_loss at step 77900: 0.734561\n",
      "2022-11-08 09:25:47,572 INFO     Training average loss at step 77900: 1.163675\n",
      "2022-11-08 09:25:50,829 INFO     Training average positive_sample_loss at step 78000: 1.573981\n",
      "2022-11-08 09:25:50,829 INFO     Training average negative_sample_loss at step 78000: 0.736281\n",
      "2022-11-08 09:25:50,829 INFO     Training average loss at step 78000: 1.155131\n",
      "2022-11-08 09:25:54,039 INFO     Training average positive_sample_loss at step 78100: 1.611970\n",
      "2022-11-08 09:25:54,039 INFO     Training average negative_sample_loss at step 78100: 0.728640\n",
      "2022-11-08 09:25:54,039 INFO     Training average loss at step 78100: 1.170305\n",
      "2022-11-08 09:25:57,242 INFO     Training average positive_sample_loss at step 78200: 1.588610\n",
      "2022-11-08 09:25:57,242 INFO     Training average negative_sample_loss at step 78200: 0.727025\n",
      "2022-11-08 09:25:57,242 INFO     Training average loss at step 78200: 1.157818\n",
      "2022-11-08 09:26:00,572 INFO     Training average positive_sample_loss at step 78300: 1.594068\n",
      "2022-11-08 09:26:00,572 INFO     Training average negative_sample_loss at step 78300: 0.733847\n",
      "2022-11-08 09:26:00,572 INFO     Training average loss at step 78300: 1.163958\n",
      "2022-11-08 09:26:03,944 INFO     Training average positive_sample_loss at step 78400: 1.590902\n",
      "2022-11-08 09:26:03,945 INFO     Training average negative_sample_loss at step 78400: 0.732232\n",
      "2022-11-08 09:26:03,945 INFO     Training average loss at step 78400: 1.161567\n",
      "2022-11-08 09:26:07,276 INFO     Training average positive_sample_loss at step 78500: 1.544354\n",
      "2022-11-08 09:26:07,276 INFO     Training average negative_sample_loss at step 78500: 0.738616\n",
      "2022-11-08 09:26:07,276 INFO     Training average loss at step 78500: 1.141485\n",
      "2022-11-08 09:26:10,525 INFO     Training average positive_sample_loss at step 78600: 1.563422\n",
      "2022-11-08 09:26:10,525 INFO     Training average negative_sample_loss at step 78600: 0.728794\n",
      "2022-11-08 09:26:10,525 INFO     Training average loss at step 78600: 1.146108\n",
      "2022-11-08 09:26:13,867 INFO     Training average positive_sample_loss at step 78700: 1.565350\n",
      "2022-11-08 09:26:13,867 INFO     Training average negative_sample_loss at step 78700: 0.721153\n",
      "2022-11-08 09:26:13,867 INFO     Training average loss at step 78700: 1.143252\n",
      "2022-11-08 09:26:17,178 INFO     Training average positive_sample_loss at step 78800: 1.575130\n",
      "2022-11-08 09:26:17,179 INFO     Training average negative_sample_loss at step 78800: 0.723135\n",
      "2022-11-08 09:26:17,179 INFO     Training average loss at step 78800: 1.149133\n",
      "2022-11-08 09:26:20,545 INFO     Training average positive_sample_loss at step 78900: 1.539928\n",
      "2022-11-08 09:26:20,545 INFO     Training average negative_sample_loss at step 78900: 0.730794\n",
      "2022-11-08 09:26:20,546 INFO     Training average loss at step 78900: 1.135361\n",
      "2022-11-08 09:26:23,717 INFO     Training average positive_sample_loss at step 79000: 1.593877\n",
      "2022-11-08 09:26:23,717 INFO     Training average negative_sample_loss at step 79000: 0.715236\n",
      "2022-11-08 09:26:23,718 INFO     Training average loss at step 79000: 1.154556\n",
      "2022-11-08 09:26:27,127 INFO     Training average positive_sample_loss at step 79100: 1.625318\n",
      "2022-11-08 09:26:27,127 INFO     Training average negative_sample_loss at step 79100: 0.716362\n",
      "2022-11-08 09:26:27,127 INFO     Training average loss at step 79100: 1.170840\n",
      "2022-11-08 09:26:33,473 INFO     Training average positive_sample_loss at step 79200: 1.414337\n",
      "2022-11-08 09:26:33,473 INFO     Training average negative_sample_loss at step 79200: 0.725085\n",
      "2022-11-08 09:26:33,473 INFO     Training average loss at step 79200: 1.069711\n",
      "2022-11-08 09:26:36,901 INFO     Training average positive_sample_loss at step 79300: 1.255416\n",
      "2022-11-08 09:26:36,901 INFO     Training average negative_sample_loss at step 79300: 0.716085\n",
      "2022-11-08 09:26:36,901 INFO     Training average loss at step 79300: 0.985750\n",
      "2022-11-08 09:26:40,240 INFO     Training average positive_sample_loss at step 79400: 1.232620\n",
      "2022-11-08 09:26:40,240 INFO     Training average negative_sample_loss at step 79400: 0.719800\n",
      "2022-11-08 09:26:40,241 INFO     Training average loss at step 79400: 0.976210\n",
      "2022-11-08 09:26:43,508 INFO     Training average positive_sample_loss at step 79500: 1.232878\n",
      "2022-11-08 09:26:43,508 INFO     Training average negative_sample_loss at step 79500: 0.706267\n",
      "2022-11-08 09:26:43,508 INFO     Training average loss at step 79500: 0.969573\n",
      "2022-11-08 09:26:46,751 INFO     Training average positive_sample_loss at step 79600: 1.205593\n",
      "2022-11-08 09:26:46,751 INFO     Training average negative_sample_loss at step 79600: 0.701845\n",
      "2022-11-08 09:26:46,751 INFO     Training average loss at step 79600: 0.953719\n",
      "2022-11-08 09:26:50,112 INFO     Training average positive_sample_loss at step 79700: 1.207713\n",
      "2022-11-08 09:26:50,112 INFO     Training average negative_sample_loss at step 79700: 0.695928\n",
      "2022-11-08 09:26:50,112 INFO     Training average loss at step 79700: 0.951821\n",
      "2022-11-08 09:26:53,448 INFO     Training average positive_sample_loss at step 79800: 1.224728\n",
      "2022-11-08 09:26:53,448 INFO     Training average negative_sample_loss at step 79800: 0.692973\n",
      "2022-11-08 09:26:53,448 INFO     Training average loss at step 79800: 0.958851\n",
      "2022-11-08 09:26:56,762 INFO     Training average positive_sample_loss at step 79900: 1.257972\n",
      "2022-11-08 09:26:56,762 INFO     Training average negative_sample_loss at step 79900: 0.689827\n",
      "2022-11-08 09:26:56,762 INFO     Training average loss at step 79900: 0.973899\n",
      "2022-11-08 09:27:02,729 INFO     Training average positive_sample_loss at step 80000: 1.250203\n",
      "2022-11-08 09:27:02,729 INFO     Training average negative_sample_loss at step 80000: 0.691604\n",
      "2022-11-08 09:27:02,729 INFO     Training average loss at step 80000: 0.970903\n",
      "2022-11-08 09:27:06,104 INFO     Training average positive_sample_loss at step 80100: 1.250051\n",
      "2022-11-08 09:27:06,104 INFO     Training average negative_sample_loss at step 80100: 0.678440\n",
      "2022-11-08 09:27:06,104 INFO     Training average loss at step 80100: 0.964245\n",
      "2022-11-08 09:27:09,473 INFO     Training average positive_sample_loss at step 80200: 1.234886\n",
      "2022-11-08 09:27:09,473 INFO     Training average negative_sample_loss at step 80200: 0.679060\n",
      "2022-11-08 09:27:09,473 INFO     Training average loss at step 80200: 0.956973\n",
      "2022-11-08 09:27:12,785 INFO     Training average positive_sample_loss at step 80300: 1.283756\n",
      "2022-11-08 09:27:12,786 INFO     Training average negative_sample_loss at step 80300: 0.674913\n",
      "2022-11-08 09:27:12,786 INFO     Training average loss at step 80300: 0.979334\n",
      "2022-11-08 09:27:16,073 INFO     Training average positive_sample_loss at step 80400: 1.248213\n",
      "2022-11-08 09:27:16,073 INFO     Training average negative_sample_loss at step 80400: 0.672732\n",
      "2022-11-08 09:27:16,073 INFO     Training average loss at step 80400: 0.960473\n",
      "2022-11-08 09:27:19,311 INFO     Training average positive_sample_loss at step 80500: 1.223083\n",
      "2022-11-08 09:27:19,311 INFO     Training average negative_sample_loss at step 80500: 0.668605\n",
      "2022-11-08 09:27:19,311 INFO     Training average loss at step 80500: 0.945844\n",
      "2022-11-08 09:27:22,535 INFO     Training average positive_sample_loss at step 80600: 1.243091\n",
      "2022-11-08 09:27:22,535 INFO     Training average negative_sample_loss at step 80600: 0.665126\n",
      "2022-11-08 09:27:22,535 INFO     Training average loss at step 80600: 0.954108\n",
      "2022-11-08 09:27:25,735 INFO     Training average positive_sample_loss at step 80700: 1.252337\n",
      "2022-11-08 09:27:25,735 INFO     Training average negative_sample_loss at step 80700: 0.665605\n",
      "2022-11-08 09:27:25,735 INFO     Training average loss at step 80700: 0.958971\n",
      "2022-11-08 09:27:28,919 INFO     Training average positive_sample_loss at step 80800: 1.274678\n",
      "2022-11-08 09:27:28,919 INFO     Training average negative_sample_loss at step 80800: 0.665740\n",
      "2022-11-08 09:27:28,919 INFO     Training average loss at step 80800: 0.970209\n",
      "2022-11-08 09:27:32,083 INFO     Training average positive_sample_loss at step 80900: 1.282380\n",
      "2022-11-08 09:27:32,083 INFO     Training average negative_sample_loss at step 80900: 0.658498\n",
      "2022-11-08 09:27:32,083 INFO     Training average loss at step 80900: 0.970439\n",
      "2022-11-08 09:27:35,243 INFO     Training average positive_sample_loss at step 81000: 1.251461\n",
      "2022-11-08 09:27:35,243 INFO     Training average negative_sample_loss at step 81000: 0.667529\n",
      "2022-11-08 09:27:35,243 INFO     Training average loss at step 81000: 0.959495\n",
      "2022-11-08 09:27:38,408 INFO     Training average positive_sample_loss at step 81100: 1.251746\n",
      "2022-11-08 09:27:38,408 INFO     Training average negative_sample_loss at step 81100: 0.661050\n",
      "2022-11-08 09:27:38,409 INFO     Training average loss at step 81100: 0.956398\n",
      "2022-11-08 09:27:41,543 INFO     Training average positive_sample_loss at step 81200: 1.268696\n",
      "2022-11-08 09:27:41,543 INFO     Training average negative_sample_loss at step 81200: 0.659070\n",
      "2022-11-08 09:27:41,543 INFO     Training average loss at step 81200: 0.963883\n",
      "2022-11-08 09:27:44,675 INFO     Training average positive_sample_loss at step 81300: 1.248277\n",
      "2022-11-08 09:27:44,675 INFO     Training average negative_sample_loss at step 81300: 0.654990\n",
      "2022-11-08 09:27:44,675 INFO     Training average loss at step 81300: 0.951634\n",
      "2022-11-08 09:27:47,910 INFO     Training average positive_sample_loss at step 81400: 1.259537\n",
      "2022-11-08 09:27:47,910 INFO     Training average negative_sample_loss at step 81400: 0.653887\n",
      "2022-11-08 09:27:47,910 INFO     Training average loss at step 81400: 0.956712\n",
      "2022-11-08 09:27:51,068 INFO     Training average positive_sample_loss at step 81500: 1.246258\n",
      "2022-11-08 09:27:51,068 INFO     Training average negative_sample_loss at step 81500: 0.664171\n",
      "2022-11-08 09:27:51,068 INFO     Training average loss at step 81500: 0.955215\n",
      "2022-11-08 09:27:54,272 INFO     Training average positive_sample_loss at step 81600: 1.255942\n",
      "2022-11-08 09:27:54,272 INFO     Training average negative_sample_loss at step 81600: 0.656252\n",
      "2022-11-08 09:27:54,273 INFO     Training average loss at step 81600: 0.956097\n",
      "2022-11-08 09:27:57,441 INFO     Training average positive_sample_loss at step 81700: 1.227371\n",
      "2022-11-08 09:27:57,441 INFO     Training average negative_sample_loss at step 81700: 0.665502\n",
      "2022-11-08 09:27:57,441 INFO     Training average loss at step 81700: 0.946437\n",
      "2022-11-08 09:28:00,607 INFO     Training average positive_sample_loss at step 81800: 1.304045\n",
      "2022-11-08 09:28:00,607 INFO     Training average negative_sample_loss at step 81800: 0.653751\n",
      "2022-11-08 09:28:00,607 INFO     Training average loss at step 81800: 0.978898\n",
      "2022-11-08 09:28:03,756 INFO     Training average positive_sample_loss at step 81900: 1.264176\n",
      "2022-11-08 09:28:03,756 INFO     Training average negative_sample_loss at step 81900: 0.647047\n",
      "2022-11-08 09:28:03,756 INFO     Training average loss at step 81900: 0.955611\n",
      "2022-11-08 09:28:06,888 INFO     Training average positive_sample_loss at step 82000: 1.268874\n",
      "2022-11-08 09:28:06,888 INFO     Training average negative_sample_loss at step 82000: 0.647743\n",
      "2022-11-08 09:28:06,888 INFO     Training average loss at step 82000: 0.958309\n",
      "2022-11-08 09:28:10,029 INFO     Training average positive_sample_loss at step 82100: 1.261383\n",
      "2022-11-08 09:28:10,030 INFO     Training average negative_sample_loss at step 82100: 0.642626\n",
      "2022-11-08 09:28:10,030 INFO     Training average loss at step 82100: 0.952005\n",
      "2022-11-08 09:28:13,184 INFO     Training average positive_sample_loss at step 82200: 1.276236\n",
      "2022-11-08 09:28:13,184 INFO     Training average negative_sample_loss at step 82200: 0.650675\n",
      "2022-11-08 09:28:13,184 INFO     Training average loss at step 82200: 0.963455\n",
      "2022-11-08 09:28:16,332 INFO     Training average positive_sample_loss at step 82300: 1.250667\n",
      "2022-11-08 09:28:16,332 INFO     Training average negative_sample_loss at step 82300: 0.649145\n",
      "2022-11-08 09:28:16,332 INFO     Training average loss at step 82300: 0.949906\n",
      "2022-11-08 09:28:19,491 INFO     Training average positive_sample_loss at step 82400: 1.277942\n",
      "2022-11-08 09:28:19,491 INFO     Training average negative_sample_loss at step 82400: 0.636907\n",
      "2022-11-08 09:28:19,491 INFO     Training average loss at step 82400: 0.957424\n",
      "2022-11-08 09:28:22,652 INFO     Training average positive_sample_loss at step 82500: 1.261529\n",
      "2022-11-08 09:28:22,652 INFO     Training average negative_sample_loss at step 82500: 0.638360\n",
      "2022-11-08 09:28:22,652 INFO     Training average loss at step 82500: 0.949945\n",
      "2022-11-08 09:28:25,790 INFO     Training average positive_sample_loss at step 82600: 1.270028\n",
      "2022-11-08 09:28:25,790 INFO     Training average negative_sample_loss at step 82600: 0.644447\n",
      "2022-11-08 09:28:25,790 INFO     Training average loss at step 82600: 0.957237\n",
      "2022-11-08 09:28:28,935 INFO     Training average positive_sample_loss at step 82700: 1.247229\n",
      "2022-11-08 09:28:28,935 INFO     Training average negative_sample_loss at step 82700: 0.645857\n",
      "2022-11-08 09:28:28,935 INFO     Training average loss at step 82700: 0.946543\n",
      "2022-11-08 09:28:32,082 INFO     Training average positive_sample_loss at step 82800: 1.256567\n",
      "2022-11-08 09:28:32,082 INFO     Training average negative_sample_loss at step 82800: 0.649865\n",
      "2022-11-08 09:28:32,082 INFO     Training average loss at step 82800: 0.953216\n",
      "2022-11-08 09:28:35,224 INFO     Training average positive_sample_loss at step 82900: 1.263642\n",
      "2022-11-08 09:28:35,224 INFO     Training average negative_sample_loss at step 82900: 0.640010\n",
      "2022-11-08 09:28:35,224 INFO     Training average loss at step 82900: 0.951826\n",
      "2022-11-08 09:28:38,361 INFO     Training average positive_sample_loss at step 83000: 1.267138\n",
      "2022-11-08 09:28:38,361 INFO     Training average negative_sample_loss at step 83000: 0.650714\n",
      "2022-11-08 09:28:38,361 INFO     Training average loss at step 83000: 0.958926\n",
      "2022-11-08 09:28:41,552 INFO     Training average positive_sample_loss at step 83100: 1.247789\n",
      "2022-11-08 09:28:41,552 INFO     Training average negative_sample_loss at step 83100: 0.646341\n",
      "2022-11-08 09:28:41,552 INFO     Training average loss at step 83100: 0.947065\n",
      "2022-11-08 09:28:44,744 INFO     Training average positive_sample_loss at step 83200: 1.251635\n",
      "2022-11-08 09:28:44,744 INFO     Training average negative_sample_loss at step 83200: 0.645570\n",
      "2022-11-08 09:28:44,744 INFO     Training average loss at step 83200: 0.948602\n",
      "2022-11-08 09:28:47,906 INFO     Training average positive_sample_loss at step 83300: 1.254950\n",
      "2022-11-08 09:28:47,907 INFO     Training average negative_sample_loss at step 83300: 0.645646\n",
      "2022-11-08 09:28:47,907 INFO     Training average loss at step 83300: 0.950298\n",
      "2022-11-08 09:28:51,111 INFO     Training average positive_sample_loss at step 83400: 1.230029\n",
      "2022-11-08 09:28:51,111 INFO     Training average negative_sample_loss at step 83400: 0.647916\n",
      "2022-11-08 09:28:51,111 INFO     Training average loss at step 83400: 0.938972\n",
      "2022-11-08 09:28:54,327 INFO     Training average positive_sample_loss at step 83500: 1.269104\n",
      "2022-11-08 09:28:54,327 INFO     Training average negative_sample_loss at step 83500: 0.645274\n",
      "2022-11-08 09:28:54,327 INFO     Training average loss at step 83500: 0.957189\n",
      "2022-11-08 09:28:57,522 INFO     Training average positive_sample_loss at step 83600: 1.269779\n",
      "2022-11-08 09:28:57,522 INFO     Training average negative_sample_loss at step 83600: 0.633050\n",
      "2022-11-08 09:28:57,522 INFO     Training average loss at step 83600: 0.951414\n",
      "2022-11-08 09:29:00,723 INFO     Training average positive_sample_loss at step 83700: 1.265587\n",
      "2022-11-08 09:29:00,723 INFO     Training average negative_sample_loss at step 83700: 0.636487\n",
      "2022-11-08 09:29:00,723 INFO     Training average loss at step 83700: 0.951037\n",
      "2022-11-08 09:29:03,956 INFO     Training average positive_sample_loss at step 83800: 1.240827\n",
      "2022-11-08 09:29:03,956 INFO     Training average negative_sample_loss at step 83800: 0.635983\n",
      "2022-11-08 09:29:03,956 INFO     Training average loss at step 83800: 0.938405\n",
      "2022-11-08 09:29:07,147 INFO     Training average positive_sample_loss at step 83900: 1.256937\n",
      "2022-11-08 09:29:07,147 INFO     Training average negative_sample_loss at step 83900: 0.633048\n",
      "2022-11-08 09:29:07,147 INFO     Training average loss at step 83900: 0.944993\n",
      "2022-11-08 09:29:10,364 INFO     Training average positive_sample_loss at step 84000: 1.277463\n",
      "2022-11-08 09:29:10,364 INFO     Training average negative_sample_loss at step 84000: 0.631839\n",
      "2022-11-08 09:29:10,364 INFO     Training average loss at step 84000: 0.954651\n",
      "2022-11-08 09:29:13,585 INFO     Training average positive_sample_loss at step 84100: 1.255024\n",
      "2022-11-08 09:29:13,585 INFO     Training average negative_sample_loss at step 84100: 0.636237\n",
      "2022-11-08 09:29:13,585 INFO     Training average loss at step 84100: 0.945630\n",
      "2022-11-08 09:29:16,866 INFO     Training average positive_sample_loss at step 84200: 1.243712\n",
      "2022-11-08 09:29:16,866 INFO     Training average negative_sample_loss at step 84200: 0.631260\n",
      "2022-11-08 09:29:16,866 INFO     Training average loss at step 84200: 0.937486\n",
      "2022-11-08 09:29:20,105 INFO     Training average positive_sample_loss at step 84300: 1.270424\n",
      "2022-11-08 09:29:20,105 INFO     Training average negative_sample_loss at step 84300: 0.644231\n",
      "2022-11-08 09:29:20,105 INFO     Training average loss at step 84300: 0.957327\n",
      "2022-11-08 09:29:23,362 INFO     Training average positive_sample_loss at step 84400: 1.258272\n",
      "2022-11-08 09:29:23,362 INFO     Training average negative_sample_loss at step 84400: 0.632505\n",
      "2022-11-08 09:29:23,362 INFO     Training average loss at step 84400: 0.945388\n",
      "2022-11-08 09:29:26,623 INFO     Training average positive_sample_loss at step 84500: 1.256246\n",
      "2022-11-08 09:29:26,623 INFO     Training average negative_sample_loss at step 84500: 0.633194\n",
      "2022-11-08 09:29:26,623 INFO     Training average loss at step 84500: 0.944720\n",
      "2022-11-08 09:29:29,806 INFO     Training average positive_sample_loss at step 84600: 1.235808\n",
      "2022-11-08 09:29:29,806 INFO     Training average negative_sample_loss at step 84600: 0.634349\n",
      "2022-11-08 09:29:29,806 INFO     Training average loss at step 84600: 0.935078\n",
      "2022-11-08 09:29:33,042 INFO     Training average positive_sample_loss at step 84700: 1.210406\n",
      "2022-11-08 09:29:33,042 INFO     Training average negative_sample_loss at step 84700: 0.645144\n",
      "2022-11-08 09:29:33,042 INFO     Training average loss at step 84700: 0.927775\n",
      "2022-11-08 09:29:36,247 INFO     Training average positive_sample_loss at step 84800: 1.243818\n",
      "2022-11-08 09:29:36,247 INFO     Training average negative_sample_loss at step 84800: 0.630976\n",
      "2022-11-08 09:29:36,247 INFO     Training average loss at step 84800: 0.937397\n",
      "2022-11-08 09:29:39,447 INFO     Training average positive_sample_loss at step 84900: 1.249792\n",
      "2022-11-08 09:29:39,447 INFO     Training average negative_sample_loss at step 84900: 0.628695\n",
      "2022-11-08 09:29:39,447 INFO     Training average loss at step 84900: 0.939244\n",
      "2022-11-08 09:29:42,720 INFO     Training average positive_sample_loss at step 85000: 1.267258\n",
      "2022-11-08 09:29:42,720 INFO     Training average negative_sample_loss at step 85000: 0.623761\n",
      "2022-11-08 09:29:42,720 INFO     Training average loss at step 85000: 0.945510\n",
      "2022-11-08 09:29:45,908 INFO     Training average positive_sample_loss at step 85100: 1.267131\n",
      "2022-11-08 09:29:45,908 INFO     Training average negative_sample_loss at step 85100: 0.632626\n",
      "2022-11-08 09:29:45,908 INFO     Training average loss at step 85100: 0.949878\n",
      "2022-11-08 09:29:49,140 INFO     Training average positive_sample_loss at step 85200: 1.258530\n",
      "2022-11-08 09:29:49,140 INFO     Training average negative_sample_loss at step 85200: 0.629406\n",
      "2022-11-08 09:29:49,140 INFO     Training average loss at step 85200: 0.943968\n",
      "2022-11-08 09:29:52,326 INFO     Training average positive_sample_loss at step 85300: 1.261326\n",
      "2022-11-08 09:29:52,326 INFO     Training average negative_sample_loss at step 85300: 0.635177\n",
      "2022-11-08 09:29:52,326 INFO     Training average loss at step 85300: 0.948251\n",
      "2022-11-08 09:29:55,496 INFO     Training average positive_sample_loss at step 85400: 1.292082\n",
      "2022-11-08 09:29:55,496 INFO     Training average negative_sample_loss at step 85400: 0.621469\n",
      "2022-11-08 09:29:55,496 INFO     Training average loss at step 85400: 0.956775\n",
      "2022-11-08 09:29:58,671 INFO     Training average positive_sample_loss at step 85500: 1.254680\n",
      "2022-11-08 09:29:58,671 INFO     Training average negative_sample_loss at step 85500: 0.629555\n",
      "2022-11-08 09:29:58,671 INFO     Training average loss at step 85500: 0.942117\n",
      "2022-11-08 09:30:01,832 INFO     Training average positive_sample_loss at step 85600: 1.252213\n",
      "2022-11-08 09:30:01,832 INFO     Training average negative_sample_loss at step 85600: 0.622559\n",
      "2022-11-08 09:30:01,832 INFO     Training average loss at step 85600: 0.937386\n",
      "2022-11-08 09:30:05,102 INFO     Training average positive_sample_loss at step 85700: 1.253277\n",
      "2022-11-08 09:30:05,102 INFO     Training average negative_sample_loss at step 85700: 0.633684\n",
      "2022-11-08 09:30:05,102 INFO     Training average loss at step 85700: 0.943480\n",
      "2022-11-08 09:30:08,308 INFO     Training average positive_sample_loss at step 85800: 1.265952\n",
      "2022-11-08 09:30:08,309 INFO     Training average negative_sample_loss at step 85800: 0.622567\n",
      "2022-11-08 09:30:08,309 INFO     Training average loss at step 85800: 0.944260\n",
      "2022-11-08 09:30:11,622 INFO     Training average positive_sample_loss at step 85900: 1.310753\n",
      "2022-11-08 09:30:11,622 INFO     Training average negative_sample_loss at step 85900: 0.619105\n",
      "2022-11-08 09:30:11,622 INFO     Training average loss at step 85900: 0.964929\n",
      "2022-11-08 09:30:14,822 INFO     Training average positive_sample_loss at step 86000: 1.271938\n",
      "2022-11-08 09:30:14,822 INFO     Training average negative_sample_loss at step 86000: 0.615834\n",
      "2022-11-08 09:30:14,822 INFO     Training average loss at step 86000: 0.943886\n",
      "2022-11-08 09:30:18,023 INFO     Training average positive_sample_loss at step 86100: 1.243685\n",
      "2022-11-08 09:30:18,023 INFO     Training average negative_sample_loss at step 86100: 0.626047\n",
      "2022-11-08 09:30:18,023 INFO     Training average loss at step 86100: 0.934866\n",
      "2022-11-08 09:30:21,308 INFO     Training average positive_sample_loss at step 86200: 1.276945\n",
      "2022-11-08 09:30:21,308 INFO     Training average negative_sample_loss at step 86200: 0.609777\n",
      "2022-11-08 09:30:21,308 INFO     Training average loss at step 86200: 0.943361\n",
      "2022-11-08 09:30:24,556 INFO     Training average positive_sample_loss at step 86300: 1.251070\n",
      "2022-11-08 09:30:24,556 INFO     Training average negative_sample_loss at step 86300: 0.625467\n",
      "2022-11-08 09:30:24,556 INFO     Training average loss at step 86300: 0.938268\n",
      "2022-11-08 09:30:27,892 INFO     Training average positive_sample_loss at step 86400: 1.281951\n",
      "2022-11-08 09:30:27,893 INFO     Training average negative_sample_loss at step 86400: 0.622692\n",
      "2022-11-08 09:30:27,893 INFO     Training average loss at step 86400: 0.952321\n",
      "2022-11-08 09:30:31,120 INFO     Training average positive_sample_loss at step 86500: 1.228710\n",
      "2022-11-08 09:30:31,120 INFO     Training average negative_sample_loss at step 86500: 0.618818\n",
      "2022-11-08 09:30:31,120 INFO     Training average loss at step 86500: 0.923764\n",
      "2022-11-08 09:30:34,305 INFO     Training average positive_sample_loss at step 86600: 1.269176\n",
      "2022-11-08 09:30:34,305 INFO     Training average negative_sample_loss at step 86600: 0.617929\n",
      "2022-11-08 09:30:34,305 INFO     Training average loss at step 86600: 0.943553\n",
      "2022-11-08 09:30:37,525 INFO     Training average positive_sample_loss at step 86700: 1.222449\n",
      "2022-11-08 09:30:37,526 INFO     Training average negative_sample_loss at step 86700: 0.628418\n",
      "2022-11-08 09:30:37,526 INFO     Training average loss at step 86700: 0.925434\n",
      "2022-11-08 09:30:40,738 INFO     Training average positive_sample_loss at step 86800: 1.234171\n",
      "2022-11-08 09:30:40,738 INFO     Training average negative_sample_loss at step 86800: 0.625378\n",
      "2022-11-08 09:30:40,738 INFO     Training average loss at step 86800: 0.929774\n",
      "2022-11-08 09:30:43,962 INFO     Training average positive_sample_loss at step 86900: 1.243410\n",
      "2022-11-08 09:30:43,962 INFO     Training average negative_sample_loss at step 86900: 0.624109\n",
      "2022-11-08 09:30:43,962 INFO     Training average loss at step 86900: 0.933759\n",
      "2022-11-08 09:30:47,191 INFO     Training average positive_sample_loss at step 87000: 1.255692\n",
      "2022-11-08 09:30:47,191 INFO     Training average negative_sample_loss at step 87000: 0.617681\n",
      "2022-11-08 09:30:47,191 INFO     Training average loss at step 87000: 0.936687\n",
      "2022-11-08 09:30:50,392 INFO     Training average positive_sample_loss at step 87100: 1.267034\n",
      "2022-11-08 09:30:50,392 INFO     Training average negative_sample_loss at step 87100: 0.612015\n",
      "2022-11-08 09:30:50,393 INFO     Training average loss at step 87100: 0.939524\n",
      "2022-11-08 09:30:53,662 INFO     Training average positive_sample_loss at step 87200: 1.235171\n",
      "2022-11-08 09:30:53,662 INFO     Training average negative_sample_loss at step 87200: 0.611849\n",
      "2022-11-08 09:30:53,662 INFO     Training average loss at step 87200: 0.923510\n",
      "2022-11-08 09:30:56,849 INFO     Training average positive_sample_loss at step 87300: 1.279349\n",
      "2022-11-08 09:30:56,849 INFO     Training average negative_sample_loss at step 87300: 0.616917\n",
      "2022-11-08 09:30:56,849 INFO     Training average loss at step 87300: 0.948133\n",
      "2022-11-08 09:31:00,024 INFO     Training average positive_sample_loss at step 87400: 1.249807\n",
      "2022-11-08 09:31:00,024 INFO     Training average negative_sample_loss at step 87400: 0.613856\n",
      "2022-11-08 09:31:00,024 INFO     Training average loss at step 87400: 0.931831\n",
      "2022-11-08 09:31:03,304 INFO     Training average positive_sample_loss at step 87500: 1.271552\n",
      "2022-11-08 09:31:03,304 INFO     Training average negative_sample_loss at step 87500: 0.605756\n",
      "2022-11-08 09:31:03,304 INFO     Training average loss at step 87500: 0.938654\n",
      "2022-11-08 09:31:06,511 INFO     Training average positive_sample_loss at step 87600: 1.251524\n",
      "2022-11-08 09:31:06,512 INFO     Training average negative_sample_loss at step 87600: 0.609746\n",
      "2022-11-08 09:31:06,512 INFO     Training average loss at step 87600: 0.930635\n",
      "2022-11-08 09:31:09,656 INFO     Training average positive_sample_loss at step 87700: 1.235889\n",
      "2022-11-08 09:31:09,656 INFO     Training average negative_sample_loss at step 87700: 0.613222\n",
      "2022-11-08 09:31:09,656 INFO     Training average loss at step 87700: 0.924555\n",
      "2022-11-08 09:31:13,209 INFO     Training average positive_sample_loss at step 87800: 1.243132\n",
      "2022-11-08 09:31:13,209 INFO     Training average negative_sample_loss at step 87800: 0.606561\n",
      "2022-11-08 09:31:13,209 INFO     Training average loss at step 87800: 0.924846\n",
      "2022-11-08 09:31:19,654 INFO     Training average positive_sample_loss at step 87900: 1.264023\n",
      "2022-11-08 09:31:19,654 INFO     Training average negative_sample_loss at step 87900: 0.614363\n",
      "2022-11-08 09:31:19,654 INFO     Training average loss at step 87900: 0.939193\n",
      "2022-11-08 09:31:26,072 INFO     Training average positive_sample_loss at step 88000: 1.267971\n",
      "2022-11-08 09:31:26,072 INFO     Training average negative_sample_loss at step 88000: 0.616857\n",
      "2022-11-08 09:31:26,072 INFO     Training average loss at step 88000: 0.942414\n",
      "2022-11-08 09:31:32,495 INFO     Training average positive_sample_loss at step 88100: 1.221262\n",
      "2022-11-08 09:31:32,495 INFO     Training average negative_sample_loss at step 88100: 0.618567\n",
      "2022-11-08 09:31:32,495 INFO     Training average loss at step 88100: 0.919915\n",
      "2022-11-08 09:31:38,918 INFO     Training average positive_sample_loss at step 88200: 1.252418\n",
      "2022-11-08 09:31:38,919 INFO     Training average negative_sample_loss at step 88200: 0.612005\n",
      "2022-11-08 09:31:38,919 INFO     Training average loss at step 88200: 0.932211\n",
      "2022-11-08 09:31:45,331 INFO     Training average positive_sample_loss at step 88300: 1.267807\n",
      "2022-11-08 09:31:45,331 INFO     Training average negative_sample_loss at step 88300: 0.611709\n",
      "2022-11-08 09:31:45,331 INFO     Training average loss at step 88300: 0.939758\n",
      "2022-11-08 09:31:51,733 INFO     Training average positive_sample_loss at step 88400: 1.245642\n",
      "2022-11-08 09:31:51,733 INFO     Training average negative_sample_loss at step 88400: 0.610961\n",
      "2022-11-08 09:31:51,734 INFO     Training average loss at step 88400: 0.928302\n",
      "2022-11-08 09:31:58,198 INFO     Training average positive_sample_loss at step 88500: 1.242350\n",
      "2022-11-08 09:31:58,198 INFO     Training average negative_sample_loss at step 88500: 0.612983\n",
      "2022-11-08 09:31:58,198 INFO     Training average loss at step 88500: 0.927667\n",
      "2022-11-08 09:32:04,624 INFO     Training average positive_sample_loss at step 88600: 1.258648\n",
      "2022-11-08 09:32:04,625 INFO     Training average negative_sample_loss at step 88600: 0.613396\n",
      "2022-11-08 09:32:04,625 INFO     Training average loss at step 88600: 0.936022\n",
      "2022-11-08 09:32:11,052 INFO     Training average positive_sample_loss at step 88700: 1.250839\n",
      "2022-11-08 09:32:11,052 INFO     Training average negative_sample_loss at step 88700: 0.609659\n",
      "2022-11-08 09:32:11,052 INFO     Training average loss at step 88700: 0.930249\n",
      "2022-11-08 09:32:17,520 INFO     Training average positive_sample_loss at step 88800: 1.223239\n",
      "2022-11-08 09:32:17,520 INFO     Training average negative_sample_loss at step 88800: 0.608167\n",
      "2022-11-08 09:32:17,520 INFO     Training average loss at step 88800: 0.915703\n",
      "2022-11-08 09:32:23,967 INFO     Training average positive_sample_loss at step 88900: 1.218630\n",
      "2022-11-08 09:32:23,967 INFO     Training average negative_sample_loss at step 88900: 0.617812\n",
      "2022-11-08 09:32:23,967 INFO     Training average loss at step 88900: 0.918221\n",
      "2022-11-08 09:32:30,412 INFO     Training average positive_sample_loss at step 89000: 1.248843\n",
      "2022-11-08 09:32:30,412 INFO     Training average negative_sample_loss at step 89000: 0.606232\n",
      "2022-11-08 09:32:30,412 INFO     Training average loss at step 89000: 0.927538\n",
      "2022-11-08 09:32:36,834 INFO     Training average positive_sample_loss at step 89100: 1.223011\n",
      "2022-11-08 09:32:36,834 INFO     Training average negative_sample_loss at step 89100: 0.600082\n",
      "2022-11-08 09:32:36,834 INFO     Training average loss at step 89100: 0.911546\n",
      "2022-11-08 09:32:43,276 INFO     Training average positive_sample_loss at step 89200: 1.222772\n",
      "2022-11-08 09:32:43,277 INFO     Training average negative_sample_loss at step 89200: 0.601788\n",
      "2022-11-08 09:32:43,277 INFO     Training average loss at step 89200: 0.912280\n",
      "2022-11-08 09:32:49,710 INFO     Training average positive_sample_loss at step 89300: 1.249061\n",
      "2022-11-08 09:32:49,710 INFO     Training average negative_sample_loss at step 89300: 0.602077\n",
      "2022-11-08 09:32:49,710 INFO     Training average loss at step 89300: 0.925569\n",
      "2022-11-08 09:32:59,635 INFO     Training average positive_sample_loss at step 89400: 1.223504\n",
      "2022-11-08 09:32:59,635 INFO     Training average negative_sample_loss at step 89400: 0.607643\n",
      "2022-11-08 09:32:59,635 INFO     Training average loss at step 89400: 0.915573\n",
      "2022-11-08 09:33:06,098 INFO     Training average positive_sample_loss at step 89500: 1.211115\n",
      "2022-11-08 09:33:06,098 INFO     Training average negative_sample_loss at step 89500: 0.610616\n",
      "2022-11-08 09:33:06,098 INFO     Training average loss at step 89500: 0.910865\n",
      "2022-11-08 09:33:12,541 INFO     Training average positive_sample_loss at step 89600: 1.239442\n",
      "2022-11-08 09:33:12,541 INFO     Training average negative_sample_loss at step 89600: 0.603512\n",
      "2022-11-08 09:33:12,541 INFO     Training average loss at step 89600: 0.921477\n",
      "2022-11-08 09:33:19,008 INFO     Training average positive_sample_loss at step 89700: 1.223808\n",
      "2022-11-08 09:33:19,008 INFO     Training average negative_sample_loss at step 89700: 0.611470\n",
      "2022-11-08 09:33:19,008 INFO     Training average loss at step 89700: 0.917639\n",
      "2022-11-08 09:33:25,480 INFO     Training average positive_sample_loss at step 89800: 1.203771\n",
      "2022-11-08 09:33:25,480 INFO     Training average negative_sample_loss at step 89800: 0.596116\n",
      "2022-11-08 09:33:25,480 INFO     Training average loss at step 89800: 0.899944\n",
      "2022-11-08 09:33:31,916 INFO     Training average positive_sample_loss at step 89900: 1.211206\n",
      "2022-11-08 09:33:31,916 INFO     Training average negative_sample_loss at step 89900: 0.605833\n",
      "2022-11-08 09:33:31,916 INFO     Training average loss at step 89900: 0.908520\n",
      "2022-11-08 09:33:41,163 INFO     Training average positive_sample_loss at step 90000: 1.224395\n",
      "2022-11-08 09:33:41,163 INFO     Training average negative_sample_loss at step 90000: 0.607292\n",
      "2022-11-08 09:33:41,163 INFO     Training average loss at step 90000: 0.915844\n",
      "2022-11-08 09:33:47,604 INFO     Training average positive_sample_loss at step 90100: 1.221764\n",
      "2022-11-08 09:33:47,604 INFO     Training average negative_sample_loss at step 90100: 0.599473\n",
      "2022-11-08 09:33:47,604 INFO     Training average loss at step 90100: 0.910619\n",
      "2022-11-08 09:33:54,023 INFO     Training average positive_sample_loss at step 90200: 1.234233\n",
      "2022-11-08 09:33:54,023 INFO     Training average negative_sample_loss at step 90200: 0.596633\n",
      "2022-11-08 09:33:54,023 INFO     Training average loss at step 90200: 0.915433\n",
      "2022-11-08 09:34:00,476 INFO     Training average positive_sample_loss at step 90300: 1.256129\n",
      "2022-11-08 09:34:00,476 INFO     Training average negative_sample_loss at step 90300: 0.600579\n",
      "2022-11-08 09:34:00,476 INFO     Training average loss at step 90300: 0.928354\n",
      "2022-11-08 09:34:06,926 INFO     Training average positive_sample_loss at step 90400: 1.225210\n",
      "2022-11-08 09:34:06,926 INFO     Training average negative_sample_loss at step 90400: 0.595630\n",
      "2022-11-08 09:34:06,926 INFO     Training average loss at step 90400: 0.910420\n",
      "2022-11-08 09:34:13,350 INFO     Training average positive_sample_loss at step 90500: 1.235637\n",
      "2022-11-08 09:34:13,350 INFO     Training average negative_sample_loss at step 90500: 0.594198\n",
      "2022-11-08 09:34:13,350 INFO     Training average loss at step 90500: 0.914917\n",
      "2022-11-08 09:34:19,786 INFO     Training average positive_sample_loss at step 90600: 1.243245\n",
      "2022-11-08 09:34:19,786 INFO     Training average negative_sample_loss at step 90600: 0.598642\n",
      "2022-11-08 09:34:19,786 INFO     Training average loss at step 90600: 0.920944\n",
      "2022-11-08 09:34:26,247 INFO     Training average positive_sample_loss at step 90700: 1.212787\n",
      "2022-11-08 09:34:26,247 INFO     Training average negative_sample_loss at step 90700: 0.599931\n",
      "2022-11-08 09:34:26,247 INFO     Training average loss at step 90700: 0.906359\n",
      "2022-11-08 09:34:32,688 INFO     Training average positive_sample_loss at step 90800: 1.200247\n",
      "2022-11-08 09:34:32,688 INFO     Training average negative_sample_loss at step 90800: 0.604028\n",
      "2022-11-08 09:34:32,688 INFO     Training average loss at step 90800: 0.902138\n",
      "2022-11-08 09:34:39,131 INFO     Training average positive_sample_loss at step 90900: 1.277453\n",
      "2022-11-08 09:34:39,131 INFO     Training average negative_sample_loss at step 90900: 0.595050\n",
      "2022-11-08 09:34:39,131 INFO     Training average loss at step 90900: 0.936252\n",
      "2022-11-08 09:34:45,560 INFO     Training average positive_sample_loss at step 91000: 1.221357\n",
      "2022-11-08 09:34:45,560 INFO     Training average negative_sample_loss at step 91000: 0.601074\n",
      "2022-11-08 09:34:45,560 INFO     Training average loss at step 91000: 0.911215\n",
      "2022-11-08 09:34:52,019 INFO     Training average positive_sample_loss at step 91100: 1.235192\n",
      "2022-11-08 09:34:52,020 INFO     Training average negative_sample_loss at step 91100: 0.603381\n",
      "2022-11-08 09:34:52,020 INFO     Training average loss at step 91100: 0.919287\n",
      "2022-11-08 09:34:58,483 INFO     Training average positive_sample_loss at step 91200: 1.203152\n",
      "2022-11-08 09:34:58,483 INFO     Training average negative_sample_loss at step 91200: 0.594428\n",
      "2022-11-08 09:34:58,483 INFO     Training average loss at step 91200: 0.898790\n",
      "2022-11-08 09:35:04,920 INFO     Training average positive_sample_loss at step 91300: 1.215117\n",
      "2022-11-08 09:35:04,920 INFO     Training average negative_sample_loss at step 91300: 0.593911\n",
      "2022-11-08 09:35:04,920 INFO     Training average loss at step 91300: 0.904514\n",
      "2022-11-08 09:35:11,376 INFO     Training average positive_sample_loss at step 91400: 1.239758\n",
      "2022-11-08 09:35:11,376 INFO     Training average negative_sample_loss at step 91400: 0.602642\n",
      "2022-11-08 09:35:11,376 INFO     Training average loss at step 91400: 0.921200\n",
      "2022-11-08 09:35:17,802 INFO     Training average positive_sample_loss at step 91500: 1.244327\n",
      "2022-11-08 09:35:17,802 INFO     Training average negative_sample_loss at step 91500: 0.600267\n",
      "2022-11-08 09:35:17,802 INFO     Training average loss at step 91500: 0.922297\n",
      "2022-11-08 09:35:24,237 INFO     Training average positive_sample_loss at step 91600: 1.233783\n",
      "2022-11-08 09:35:24,238 INFO     Training average negative_sample_loss at step 91600: 0.594869\n",
      "2022-11-08 09:35:24,238 INFO     Training average loss at step 91600: 0.914326\n",
      "2022-11-08 09:35:30,697 INFO     Training average positive_sample_loss at step 91700: 1.259862\n",
      "2022-11-08 09:35:30,697 INFO     Training average negative_sample_loss at step 91700: 0.589778\n",
      "2022-11-08 09:35:30,697 INFO     Training average loss at step 91700: 0.924820\n",
      "2022-11-08 09:35:37,132 INFO     Training average positive_sample_loss at step 91800: 1.260396\n",
      "2022-11-08 09:35:37,132 INFO     Training average negative_sample_loss at step 91800: 0.587774\n",
      "2022-11-08 09:35:37,132 INFO     Training average loss at step 91800: 0.924085\n",
      "2022-11-08 09:35:43,564 INFO     Training average positive_sample_loss at step 91900: 1.217368\n",
      "2022-11-08 09:35:43,565 INFO     Training average negative_sample_loss at step 91900: 0.594155\n",
      "2022-11-08 09:35:43,565 INFO     Training average loss at step 91900: 0.905761\n",
      "2022-11-08 09:35:49,991 INFO     Training average positive_sample_loss at step 92000: 1.221270\n",
      "2022-11-08 09:35:49,991 INFO     Training average negative_sample_loss at step 92000: 0.595923\n",
      "2022-11-08 09:35:49,991 INFO     Training average loss at step 92000: 0.908596\n",
      "2022-11-08 09:35:56,406 INFO     Training average positive_sample_loss at step 92100: 1.264453\n",
      "2022-11-08 09:35:56,406 INFO     Training average negative_sample_loss at step 92100: 0.590566\n",
      "2022-11-08 09:35:56,406 INFO     Training average loss at step 92100: 0.927509\n",
      "2022-11-08 09:36:02,856 INFO     Training average positive_sample_loss at step 92200: 1.238461\n",
      "2022-11-08 09:36:02,856 INFO     Training average negative_sample_loss at step 92200: 0.574432\n",
      "2022-11-08 09:36:02,856 INFO     Training average loss at step 92200: 0.906446\n",
      "2022-11-08 09:36:09,280 INFO     Training average positive_sample_loss at step 92300: 1.234939\n",
      "2022-11-08 09:36:09,281 INFO     Training average negative_sample_loss at step 92300: 0.587577\n",
      "2022-11-08 09:36:09,281 INFO     Training average loss at step 92300: 0.911258\n",
      "2022-11-08 09:36:15,722 INFO     Training average positive_sample_loss at step 92400: 1.228763\n",
      "2022-11-08 09:36:15,722 INFO     Training average negative_sample_loss at step 92400: 0.595442\n",
      "2022-11-08 09:36:15,722 INFO     Training average loss at step 92400: 0.912102\n",
      "2022-11-08 09:36:22,145 INFO     Training average positive_sample_loss at step 92500: 1.195578\n",
      "2022-11-08 09:36:22,145 INFO     Training average negative_sample_loss at step 92500: 0.593301\n",
      "2022-11-08 09:36:22,145 INFO     Training average loss at step 92500: 0.894440\n",
      "2022-11-08 09:36:28,559 INFO     Training average positive_sample_loss at step 92600: 1.198375\n",
      "2022-11-08 09:36:28,559 INFO     Training average negative_sample_loss at step 92600: 0.593675\n",
      "2022-11-08 09:36:28,559 INFO     Training average loss at step 92600: 0.896025\n",
      "2022-11-08 09:36:34,973 INFO     Training average positive_sample_loss at step 92700: 1.229228\n",
      "2022-11-08 09:36:34,973 INFO     Training average negative_sample_loss at step 92700: 0.587475\n",
      "2022-11-08 09:36:34,973 INFO     Training average loss at step 92700: 0.908352\n",
      "2022-11-08 09:36:41,493 INFO     Training average positive_sample_loss at step 92800: 1.227605\n",
      "2022-11-08 09:36:41,493 INFO     Training average negative_sample_loss at step 92800: 0.591067\n",
      "2022-11-08 09:36:41,493 INFO     Training average loss at step 92800: 0.909336\n",
      "2022-11-08 09:36:47,978 INFO     Training average positive_sample_loss at step 92900: 1.222833\n",
      "2022-11-08 09:36:47,978 INFO     Training average negative_sample_loss at step 92900: 0.587989\n",
      "2022-11-08 09:36:47,978 INFO     Training average loss at step 92900: 0.905411\n",
      "2022-11-08 09:36:54,454 INFO     Training average positive_sample_loss at step 93000: 1.230662\n",
      "2022-11-08 09:36:54,454 INFO     Training average negative_sample_loss at step 93000: 0.585603\n",
      "2022-11-08 09:36:54,454 INFO     Training average loss at step 93000: 0.908133\n",
      "2022-11-08 09:37:00,962 INFO     Training average positive_sample_loss at step 93100: 1.214288\n",
      "2022-11-08 09:37:00,962 INFO     Training average negative_sample_loss at step 93100: 0.583704\n",
      "2022-11-08 09:37:00,962 INFO     Training average loss at step 93100: 0.898996\n",
      "2022-11-08 09:37:07,402 INFO     Training average positive_sample_loss at step 93200: 1.211052\n",
      "2022-11-08 09:37:07,402 INFO     Training average negative_sample_loss at step 93200: 0.594627\n",
      "2022-11-08 09:37:07,402 INFO     Training average loss at step 93200: 0.902840\n",
      "2022-11-08 09:37:12,530 INFO     Training average positive_sample_loss at step 93300: 1.198092\n",
      "2022-11-08 09:37:12,530 INFO     Training average negative_sample_loss at step 93300: 0.586389\n",
      "2022-11-08 09:37:12,531 INFO     Training average loss at step 93300: 0.892241\n",
      "2022-11-08 09:37:18,954 INFO     Training average positive_sample_loss at step 93400: 1.208371\n",
      "2022-11-08 09:37:18,954 INFO     Training average negative_sample_loss at step 93400: 0.584208\n",
      "2022-11-08 09:37:18,954 INFO     Training average loss at step 93400: 0.896290\n",
      "2022-11-08 09:37:25,423 INFO     Training average positive_sample_loss at step 93500: 1.216185\n",
      "2022-11-08 09:37:25,423 INFO     Training average negative_sample_loss at step 93500: 0.577023\n",
      "2022-11-08 09:37:25,423 INFO     Training average loss at step 93500: 0.896604\n",
      "2022-11-08 09:37:31,907 INFO     Training average positive_sample_loss at step 93600: 1.253638\n",
      "2022-11-08 09:37:31,907 INFO     Training average negative_sample_loss at step 93600: 0.580932\n",
      "2022-11-08 09:37:31,907 INFO     Training average loss at step 93600: 0.917285\n",
      "2022-11-08 09:37:38,387 INFO     Training average positive_sample_loss at step 93700: 1.200515\n",
      "2022-11-08 09:37:38,387 INFO     Training average negative_sample_loss at step 93700: 0.580477\n",
      "2022-11-08 09:37:38,387 INFO     Training average loss at step 93700: 0.890496\n",
      "2022-11-08 09:37:44,817 INFO     Training average positive_sample_loss at step 93800: 1.202753\n",
      "2022-11-08 09:37:44,817 INFO     Training average negative_sample_loss at step 93800: 0.581882\n",
      "2022-11-08 09:37:44,817 INFO     Training average loss at step 93800: 0.892318\n",
      "2022-11-08 09:37:51,260 INFO     Training average positive_sample_loss at step 93900: 1.252905\n",
      "2022-11-08 09:37:51,260 INFO     Training average negative_sample_loss at step 93900: 0.588579\n",
      "2022-11-08 09:37:51,260 INFO     Training average loss at step 93900: 0.920742\n",
      "2022-11-08 09:37:59,083 INFO     Training average positive_sample_loss at step 94000: 1.247938\n",
      "2022-11-08 09:37:59,083 INFO     Training average negative_sample_loss at step 94000: 0.568200\n",
      "2022-11-08 09:37:59,083 INFO     Training average loss at step 94000: 0.908069\n",
      "2022-11-08 09:38:06,921 INFO     Training average positive_sample_loss at step 94100: 1.236864\n",
      "2022-11-08 09:38:06,921 INFO     Training average negative_sample_loss at step 94100: 0.572354\n",
      "2022-11-08 09:38:06,921 INFO     Training average loss at step 94100: 0.904609\n",
      "2022-11-08 09:38:13,469 INFO     Training average positive_sample_loss at step 94200: 1.202556\n",
      "2022-11-08 09:38:13,469 INFO     Training average negative_sample_loss at step 94200: 0.586591\n",
      "2022-11-08 09:38:13,469 INFO     Training average loss at step 94200: 0.894573\n",
      "2022-11-08 09:38:19,990 INFO     Training average positive_sample_loss at step 94300: 1.243028\n",
      "2022-11-08 09:38:19,991 INFO     Training average negative_sample_loss at step 94300: 0.579706\n",
      "2022-11-08 09:38:19,991 INFO     Training average loss at step 94300: 0.911367\n",
      "2022-11-08 09:38:26,454 INFO     Training average positive_sample_loss at step 94400: 1.225190\n",
      "2022-11-08 09:38:26,454 INFO     Training average negative_sample_loss at step 94400: 0.579629\n",
      "2022-11-08 09:38:26,454 INFO     Training average loss at step 94400: 0.902410\n",
      "2022-11-08 09:38:32,932 INFO     Training average positive_sample_loss at step 94500: 1.210294\n",
      "2022-11-08 09:38:32,932 INFO     Training average negative_sample_loss at step 94500: 0.582180\n",
      "2022-11-08 09:38:32,932 INFO     Training average loss at step 94500: 0.896237\n",
      "2022-11-08 09:38:39,352 INFO     Training average positive_sample_loss at step 94600: 1.196640\n",
      "2022-11-08 09:38:39,352 INFO     Training average negative_sample_loss at step 94600: 0.580480\n",
      "2022-11-08 09:38:39,352 INFO     Training average loss at step 94600: 0.888560\n",
      "2022-11-08 09:38:45,802 INFO     Training average positive_sample_loss at step 94700: 1.204897\n",
      "2022-11-08 09:38:45,802 INFO     Training average negative_sample_loss at step 94700: 0.583583\n",
      "2022-11-08 09:38:45,802 INFO     Training average loss at step 94700: 0.894240\n",
      "2022-11-08 09:38:52,270 INFO     Training average positive_sample_loss at step 94800: 1.197867\n",
      "2022-11-08 09:38:52,270 INFO     Training average negative_sample_loss at step 94800: 0.580968\n",
      "2022-11-08 09:38:52,270 INFO     Training average loss at step 94800: 0.889418\n",
      "2022-11-08 09:38:58,725 INFO     Training average positive_sample_loss at step 94900: 1.191460\n",
      "2022-11-08 09:38:58,726 INFO     Training average negative_sample_loss at step 94900: 0.583926\n",
      "2022-11-08 09:38:58,726 INFO     Training average loss at step 94900: 0.887693\n",
      "2022-11-08 09:39:05,174 INFO     Training average positive_sample_loss at step 95000: 1.219540\n",
      "2022-11-08 09:39:05,174 INFO     Training average negative_sample_loss at step 95000: 0.580024\n",
      "2022-11-08 09:39:05,174 INFO     Training average loss at step 95000: 0.899782\n",
      "2022-11-08 09:39:11,619 INFO     Training average positive_sample_loss at step 95100: 1.230093\n",
      "2022-11-08 09:39:11,619 INFO     Training average negative_sample_loss at step 95100: 0.574533\n",
      "2022-11-08 09:39:11,619 INFO     Training average loss at step 95100: 0.902313\n",
      "2022-11-08 09:39:18,084 INFO     Training average positive_sample_loss at step 95200: 1.217281\n",
      "2022-11-08 09:39:18,084 INFO     Training average negative_sample_loss at step 95200: 0.569566\n",
      "2022-11-08 09:39:18,084 INFO     Training average loss at step 95200: 0.893424\n",
      "2022-11-08 09:39:24,556 INFO     Training average positive_sample_loss at step 95300: 1.166704\n",
      "2022-11-08 09:39:24,557 INFO     Training average negative_sample_loss at step 95300: 0.577542\n",
      "2022-11-08 09:39:24,557 INFO     Training average loss at step 95300: 0.872123\n",
      "2022-11-08 09:39:30,985 INFO     Training average positive_sample_loss at step 95400: 1.190828\n",
      "2022-11-08 09:39:30,985 INFO     Training average negative_sample_loss at step 95400: 0.578779\n",
      "2022-11-08 09:39:30,985 INFO     Training average loss at step 95400: 0.884804\n",
      "2022-11-08 09:39:37,427 INFO     Training average positive_sample_loss at step 95500: 1.238152\n",
      "2022-11-08 09:39:37,427 INFO     Training average negative_sample_loss at step 95500: 0.577505\n",
      "2022-11-08 09:39:37,427 INFO     Training average loss at step 95500: 0.907828\n",
      "2022-11-08 09:39:43,878 INFO     Training average positive_sample_loss at step 95600: 1.239186\n",
      "2022-11-08 09:39:43,878 INFO     Training average negative_sample_loss at step 95600: 0.576120\n",
      "2022-11-08 09:39:43,878 INFO     Training average loss at step 95600: 0.907653\n",
      "2022-11-08 09:39:50,315 INFO     Training average positive_sample_loss at step 95700: 1.211737\n",
      "2022-11-08 09:39:50,315 INFO     Training average negative_sample_loss at step 95700: 0.569693\n",
      "2022-11-08 09:39:50,315 INFO     Training average loss at step 95700: 0.890715\n",
      "2022-11-08 09:39:56,750 INFO     Training average positive_sample_loss at step 95800: 1.216592\n",
      "2022-11-08 09:39:56,750 INFO     Training average negative_sample_loss at step 95800: 0.575156\n",
      "2022-11-08 09:39:56,750 INFO     Training average loss at step 95800: 0.895874\n",
      "2022-11-08 09:40:03,205 INFO     Training average positive_sample_loss at step 95900: 1.223337\n",
      "2022-11-08 09:40:03,205 INFO     Training average negative_sample_loss at step 95900: 0.569822\n",
      "2022-11-08 09:40:03,205 INFO     Training average loss at step 95900: 0.896579\n",
      "2022-11-08 09:40:09,663 INFO     Training average positive_sample_loss at step 96000: 1.200443\n",
      "2022-11-08 09:40:09,663 INFO     Training average negative_sample_loss at step 96000: 0.570021\n",
      "2022-11-08 09:40:09,663 INFO     Training average loss at step 96000: 0.885232\n",
      "2022-11-08 09:40:16,119 INFO     Training average positive_sample_loss at step 96100: 1.203654\n",
      "2022-11-08 09:40:16,119 INFO     Training average negative_sample_loss at step 96100: 0.572132\n",
      "2022-11-08 09:40:16,119 INFO     Training average loss at step 96100: 0.887893\n",
      "2022-11-08 09:40:22,574 INFO     Training average positive_sample_loss at step 96200: 1.197971\n",
      "2022-11-08 09:40:22,574 INFO     Training average negative_sample_loss at step 96200: 0.582293\n",
      "2022-11-08 09:40:22,574 INFO     Training average loss at step 96200: 0.890132\n",
      "2022-11-08 09:40:29,026 INFO     Training average positive_sample_loss at step 96300: 1.178304\n",
      "2022-11-08 09:40:29,026 INFO     Training average negative_sample_loss at step 96300: 0.580933\n",
      "2022-11-08 09:40:29,026 INFO     Training average loss at step 96300: 0.879619\n",
      "2022-11-08 09:40:35,491 INFO     Training average positive_sample_loss at step 96400: 1.222214\n",
      "2022-11-08 09:40:35,491 INFO     Training average negative_sample_loss at step 96400: 0.581936\n",
      "2022-11-08 09:40:35,491 INFO     Training average loss at step 96400: 0.902075\n",
      "2022-11-08 09:40:41,946 INFO     Training average positive_sample_loss at step 96500: 1.249490\n",
      "2022-11-08 09:40:41,947 INFO     Training average negative_sample_loss at step 96500: 0.566686\n",
      "2022-11-08 09:40:41,947 INFO     Training average loss at step 96500: 0.908088\n",
      "2022-11-08 09:40:48,414 INFO     Training average positive_sample_loss at step 96600: 1.210625\n",
      "2022-11-08 09:40:48,414 INFO     Training average negative_sample_loss at step 96600: 0.575607\n",
      "2022-11-08 09:40:48,414 INFO     Training average loss at step 96600: 0.893116\n",
      "2022-11-08 09:40:54,866 INFO     Training average positive_sample_loss at step 96700: 1.236959\n",
      "2022-11-08 09:40:54,866 INFO     Training average negative_sample_loss at step 96700: 0.565589\n",
      "2022-11-08 09:40:54,866 INFO     Training average loss at step 96700: 0.901274\n",
      "2022-11-08 09:41:01,319 INFO     Training average positive_sample_loss at step 96800: 1.193106\n",
      "2022-11-08 09:41:01,319 INFO     Training average negative_sample_loss at step 96800: 0.577882\n",
      "2022-11-08 09:41:01,319 INFO     Training average loss at step 96800: 0.885494\n",
      "2022-11-08 09:41:07,786 INFO     Training average positive_sample_loss at step 96900: 1.213278\n",
      "2022-11-08 09:41:07,786 INFO     Training average negative_sample_loss at step 96900: 0.571547\n",
      "2022-11-08 09:41:07,786 INFO     Training average loss at step 96900: 0.892413\n",
      "2022-11-08 09:41:14,232 INFO     Training average positive_sample_loss at step 97000: 1.215744\n",
      "2022-11-08 09:41:14,232 INFO     Training average negative_sample_loss at step 97000: 0.570436\n",
      "2022-11-08 09:41:14,232 INFO     Training average loss at step 97000: 0.893090\n",
      "2022-11-08 09:41:20,681 INFO     Training average positive_sample_loss at step 97100: 1.178016\n",
      "2022-11-08 09:41:20,681 INFO     Training average negative_sample_loss at step 97100: 0.578453\n",
      "2022-11-08 09:41:20,681 INFO     Training average loss at step 97100: 0.878234\n",
      "2022-11-08 09:41:27,129 INFO     Training average positive_sample_loss at step 97200: 1.221391\n",
      "2022-11-08 09:41:27,129 INFO     Training average negative_sample_loss at step 97200: 0.564220\n",
      "2022-11-08 09:41:27,129 INFO     Training average loss at step 97200: 0.892806\n",
      "2022-11-08 09:41:33,592 INFO     Training average positive_sample_loss at step 97300: 1.248008\n",
      "2022-11-08 09:41:33,592 INFO     Training average negative_sample_loss at step 97300: 0.565163\n",
      "2022-11-08 09:41:33,592 INFO     Training average loss at step 97300: 0.906585\n",
      "2022-11-08 09:41:40,043 INFO     Training average positive_sample_loss at step 97400: 1.206819\n",
      "2022-11-08 09:41:40,043 INFO     Training average negative_sample_loss at step 97400: 0.566702\n",
      "2022-11-08 09:41:40,043 INFO     Training average loss at step 97400: 0.886760\n",
      "2022-11-08 09:41:46,493 INFO     Training average positive_sample_loss at step 97500: 1.193933\n",
      "2022-11-08 09:41:46,493 INFO     Training average negative_sample_loss at step 97500: 0.577873\n",
      "2022-11-08 09:41:46,493 INFO     Training average loss at step 97500: 0.885903\n",
      "2022-11-08 09:41:52,949 INFO     Training average positive_sample_loss at step 97600: 1.193811\n",
      "2022-11-08 09:41:52,949 INFO     Training average negative_sample_loss at step 97600: 0.574655\n",
      "2022-11-08 09:41:52,949 INFO     Training average loss at step 97600: 0.884233\n",
      "2022-11-08 09:41:59,417 INFO     Training average positive_sample_loss at step 97700: 1.198028\n",
      "2022-11-08 09:41:59,418 INFO     Training average negative_sample_loss at step 97700: 0.557223\n",
      "2022-11-08 09:41:59,418 INFO     Training average loss at step 97700: 0.877626\n",
      "2022-11-08 09:42:05,872 INFO     Training average positive_sample_loss at step 97800: 1.159578\n",
      "2022-11-08 09:42:05,872 INFO     Training average negative_sample_loss at step 97800: 0.577407\n",
      "2022-11-08 09:42:05,872 INFO     Training average loss at step 97800: 0.868492\n",
      "2022-11-08 09:42:12,322 INFO     Training average positive_sample_loss at step 97900: 1.205992\n",
      "2022-11-08 09:42:12,322 INFO     Training average negative_sample_loss at step 97900: 0.569961\n",
      "2022-11-08 09:42:12,322 INFO     Training average loss at step 97900: 0.887976\n",
      "2022-11-08 09:42:18,814 INFO     Training average positive_sample_loss at step 98000: 1.184460\n",
      "2022-11-08 09:42:18,814 INFO     Training average negative_sample_loss at step 98000: 0.567203\n",
      "2022-11-08 09:42:18,814 INFO     Training average loss at step 98000: 0.875832\n",
      "2022-11-08 09:42:25,346 INFO     Training average positive_sample_loss at step 98100: 1.172504\n",
      "2022-11-08 09:42:25,346 INFO     Training average negative_sample_loss at step 98100: 0.568329\n",
      "2022-11-08 09:42:25,346 INFO     Training average loss at step 98100: 0.870417\n",
      "2022-11-08 09:42:31,819 INFO     Training average positive_sample_loss at step 98200: 1.198799\n",
      "2022-11-08 09:42:31,819 INFO     Training average negative_sample_loss at step 98200: 0.568231\n",
      "2022-11-08 09:42:31,819 INFO     Training average loss at step 98200: 0.883515\n",
      "2022-11-08 09:42:38,313 INFO     Training average positive_sample_loss at step 98300: 1.164401\n",
      "2022-11-08 09:42:38,313 INFO     Training average negative_sample_loss at step 98300: 0.568864\n",
      "2022-11-08 09:42:38,313 INFO     Training average loss at step 98300: 0.866633\n",
      "2022-11-08 09:42:44,801 INFO     Training average positive_sample_loss at step 98400: 1.157383\n",
      "2022-11-08 09:42:44,802 INFO     Training average negative_sample_loss at step 98400: 0.569190\n",
      "2022-11-08 09:42:44,802 INFO     Training average loss at step 98400: 0.863286\n",
      "2022-11-08 09:42:51,513 INFO     Training average positive_sample_loss at step 98500: 1.198546\n",
      "2022-11-08 09:42:51,513 INFO     Training average negative_sample_loss at step 98500: 0.567600\n",
      "2022-11-08 09:42:51,513 INFO     Training average loss at step 98500: 0.883073\n",
      "2022-11-08 09:42:58,073 INFO     Training average positive_sample_loss at step 98600: 1.190430\n",
      "2022-11-08 09:42:58,073 INFO     Training average negative_sample_loss at step 98600: 0.567051\n",
      "2022-11-08 09:42:58,073 INFO     Training average loss at step 98600: 0.878741\n",
      "2022-11-08 09:43:05,883 INFO     Training average positive_sample_loss at step 98700: 1.187539\n",
      "2022-11-08 09:43:05,883 INFO     Training average negative_sample_loss at step 98700: 0.570199\n",
      "2022-11-08 09:43:05,883 INFO     Training average loss at step 98700: 0.878869\n",
      "2022-11-08 09:43:13,635 INFO     Training average positive_sample_loss at step 98800: 1.206381\n",
      "2022-11-08 09:43:13,635 INFO     Training average negative_sample_loss at step 98800: 0.563667\n",
      "2022-11-08 09:43:13,635 INFO     Training average loss at step 98800: 0.885024\n",
      "2022-11-08 09:43:18,738 INFO     Training average positive_sample_loss at step 98900: 1.201854\n",
      "2022-11-08 09:43:18,738 INFO     Training average negative_sample_loss at step 98900: 0.556870\n",
      "2022-11-08 09:43:18,738 INFO     Training average loss at step 98900: 0.879362\n",
      "2022-11-08 09:43:25,176 INFO     Training average positive_sample_loss at step 99000: 1.181094\n",
      "2022-11-08 09:43:25,176 INFO     Training average negative_sample_loss at step 99000: 0.573992\n",
      "2022-11-08 09:43:25,176 INFO     Training average loss at step 99000: 0.877543\n",
      "2022-11-08 09:43:31,707 INFO     Training average positive_sample_loss at step 99100: 1.183105\n",
      "2022-11-08 09:43:31,707 INFO     Training average negative_sample_loss at step 99100: 0.568982\n",
      "2022-11-08 09:43:31,707 INFO     Training average loss at step 99100: 0.876043\n",
      "2022-11-08 09:43:38,265 INFO     Training average positive_sample_loss at step 99200: 1.170490\n",
      "2022-11-08 09:43:38,265 INFO     Training average negative_sample_loss at step 99200: 0.566833\n",
      "2022-11-08 09:43:38,265 INFO     Training average loss at step 99200: 0.868661\n",
      "2022-11-08 09:43:44,719 INFO     Training average positive_sample_loss at step 99300: 1.203142\n",
      "2022-11-08 09:43:44,720 INFO     Training average negative_sample_loss at step 99300: 0.563476\n",
      "2022-11-08 09:43:44,720 INFO     Training average loss at step 99300: 0.883309\n",
      "2022-11-08 09:43:51,170 INFO     Training average positive_sample_loss at step 99400: 1.204403\n",
      "2022-11-08 09:43:51,170 INFO     Training average negative_sample_loss at step 99400: 0.559320\n",
      "2022-11-08 09:43:51,170 INFO     Training average loss at step 99400: 0.881862\n",
      "2022-11-08 09:43:57,623 INFO     Training average positive_sample_loss at step 99500: 1.182016\n",
      "2022-11-08 09:43:57,624 INFO     Training average negative_sample_loss at step 99500: 0.562678\n",
      "2022-11-08 09:43:57,624 INFO     Training average loss at step 99500: 0.872347\n",
      "2022-11-08 09:44:04,053 INFO     Training average positive_sample_loss at step 99600: 1.182826\n",
      "2022-11-08 09:44:04,053 INFO     Training average negative_sample_loss at step 99600: 0.566581\n",
      "2022-11-08 09:44:04,053 INFO     Training average loss at step 99600: 0.874703\n",
      "2022-11-08 09:44:10,476 INFO     Training average positive_sample_loss at step 99700: 1.142759\n",
      "2022-11-08 09:44:10,476 INFO     Training average negative_sample_loss at step 99700: 0.562621\n",
      "2022-11-08 09:44:10,476 INFO     Training average loss at step 99700: 0.852690\n",
      "2022-11-08 09:44:16,879 INFO     Training average positive_sample_loss at step 99800: 1.178822\n",
      "2022-11-08 09:44:16,879 INFO     Training average negative_sample_loss at step 99800: 0.566299\n",
      "2022-11-08 09:44:16,879 INFO     Training average loss at step 99800: 0.872560\n",
      "2022-11-08 09:44:23,266 INFO     Training average positive_sample_loss at step 99900: 1.232468\n",
      "2022-11-08 09:44:23,266 INFO     Training average negative_sample_loss at step 99900: 0.562775\n",
      "2022-11-08 09:44:23,266 INFO     Training average loss at step 99900: 0.897622\n",
      "2022-11-08 09:44:32,420 INFO     Training average positive_sample_loss at step 100000: 1.174316\n",
      "2022-11-08 09:44:32,420 INFO     Training average negative_sample_loss at step 100000: 0.561633\n",
      "2022-11-08 09:44:32,420 INFO     Training average loss at step 100000: 0.867974\n",
      "2022-11-08 09:44:38,902 INFO     Training average positive_sample_loss at step 100100: 1.197224\n",
      "2022-11-08 09:44:38,902 INFO     Training average negative_sample_loss at step 100100: 0.552908\n",
      "2022-11-08 09:44:38,902 INFO     Training average loss at step 100100: 0.875066\n",
      "2022-11-08 09:44:45,331 INFO     Training average positive_sample_loss at step 100200: 1.219801\n",
      "2022-11-08 09:44:45,331 INFO     Training average negative_sample_loss at step 100200: 0.557900\n",
      "2022-11-08 09:44:45,331 INFO     Training average loss at step 100200: 0.888851\n",
      "2022-11-08 09:44:51,772 INFO     Training average positive_sample_loss at step 100300: 1.159683\n",
      "2022-11-08 09:44:51,772 INFO     Training average negative_sample_loss at step 100300: 0.558076\n",
      "2022-11-08 09:44:51,772 INFO     Training average loss at step 100300: 0.858879\n",
      "2022-11-08 09:44:58,227 INFO     Training average positive_sample_loss at step 100400: 1.202824\n",
      "2022-11-08 09:44:58,227 INFO     Training average negative_sample_loss at step 100400: 0.561464\n",
      "2022-11-08 09:44:58,227 INFO     Training average loss at step 100400: 0.882144\n",
      "2022-11-08 09:45:04,689 INFO     Training average positive_sample_loss at step 100500: 1.176497\n",
      "2022-11-08 09:45:04,689 INFO     Training average negative_sample_loss at step 100500: 0.564146\n",
      "2022-11-08 09:45:04,689 INFO     Training average loss at step 100500: 0.870322\n",
      "2022-11-08 09:45:11,145 INFO     Training average positive_sample_loss at step 100600: 1.193865\n",
      "2022-11-08 09:45:11,145 INFO     Training average negative_sample_loss at step 100600: 0.554412\n",
      "2022-11-08 09:45:11,145 INFO     Training average loss at step 100600: 0.874139\n",
      "2022-11-08 09:45:17,607 INFO     Training average positive_sample_loss at step 100700: 1.170481\n",
      "2022-11-08 09:45:17,607 INFO     Training average negative_sample_loss at step 100700: 0.554344\n",
      "2022-11-08 09:45:17,607 INFO     Training average loss at step 100700: 0.862412\n",
      "2022-11-08 09:45:24,065 INFO     Training average positive_sample_loss at step 100800: 1.218752\n",
      "2022-11-08 09:45:24,065 INFO     Training average negative_sample_loss at step 100800: 0.552953\n",
      "2022-11-08 09:45:24,065 INFO     Training average loss at step 100800: 0.885852\n",
      "2022-11-08 09:45:30,524 INFO     Training average positive_sample_loss at step 100900: 1.179217\n",
      "2022-11-08 09:45:30,524 INFO     Training average negative_sample_loss at step 100900: 0.553572\n",
      "2022-11-08 09:45:30,524 INFO     Training average loss at step 100900: 0.866394\n",
      "2022-11-08 09:45:36,930 INFO     Training average positive_sample_loss at step 101000: 1.159545\n",
      "2022-11-08 09:45:36,931 INFO     Training average negative_sample_loss at step 101000: 0.556494\n",
      "2022-11-08 09:45:36,931 INFO     Training average loss at step 101000: 0.858019\n",
      "2022-11-08 09:45:43,347 INFO     Training average positive_sample_loss at step 101100: 1.169440\n",
      "2022-11-08 09:45:43,347 INFO     Training average negative_sample_loss at step 101100: 0.553900\n",
      "2022-11-08 09:45:43,347 INFO     Training average loss at step 101100: 0.861670\n",
      "2022-11-08 09:45:49,762 INFO     Training average positive_sample_loss at step 101200: 1.202392\n",
      "2022-11-08 09:45:49,763 INFO     Training average negative_sample_loss at step 101200: 0.546263\n",
      "2022-11-08 09:45:49,763 INFO     Training average loss at step 101200: 0.874328\n",
      "2022-11-08 09:45:56,184 INFO     Training average positive_sample_loss at step 101300: 1.179546\n",
      "2022-11-08 09:45:56,184 INFO     Training average negative_sample_loss at step 101300: 0.553499\n",
      "2022-11-08 09:45:56,184 INFO     Training average loss at step 101300: 0.866522\n",
      "2022-11-08 09:46:02,575 INFO     Training average positive_sample_loss at step 101400: 1.161486\n",
      "2022-11-08 09:46:02,576 INFO     Training average negative_sample_loss at step 101400: 0.550685\n",
      "2022-11-08 09:46:02,576 INFO     Training average loss at step 101400: 0.856085\n",
      "2022-11-08 09:46:08,972 INFO     Training average positive_sample_loss at step 101500: 1.189194\n",
      "2022-11-08 09:46:08,972 INFO     Training average negative_sample_loss at step 101500: 0.551714\n",
      "2022-11-08 09:46:08,972 INFO     Training average loss at step 101500: 0.870454\n",
      "2022-11-08 09:46:15,364 INFO     Training average positive_sample_loss at step 101600: 1.191433\n",
      "2022-11-08 09:46:15,364 INFO     Training average negative_sample_loss at step 101600: 0.552212\n",
      "2022-11-08 09:46:15,364 INFO     Training average loss at step 101600: 0.871822\n",
      "2022-11-08 09:46:21,794 INFO     Training average positive_sample_loss at step 101700: 1.199690\n",
      "2022-11-08 09:46:21,795 INFO     Training average negative_sample_loss at step 101700: 0.543697\n",
      "2022-11-08 09:46:21,795 INFO     Training average loss at step 101700: 0.871693\n",
      "2022-11-08 09:46:28,218 INFO     Training average positive_sample_loss at step 101800: 1.184586\n",
      "2022-11-08 09:46:28,218 INFO     Training average negative_sample_loss at step 101800: 0.555031\n",
      "2022-11-08 09:46:28,218 INFO     Training average loss at step 101800: 0.869809\n",
      "2022-11-08 09:46:34,618 INFO     Training average positive_sample_loss at step 101900: 1.190959\n",
      "2022-11-08 09:46:34,618 INFO     Training average negative_sample_loss at step 101900: 0.554126\n",
      "2022-11-08 09:46:34,618 INFO     Training average loss at step 101900: 0.872542\n",
      "2022-11-08 09:46:41,024 INFO     Training average positive_sample_loss at step 102000: 1.177256\n",
      "2022-11-08 09:46:41,024 INFO     Training average negative_sample_loss at step 102000: 0.551115\n",
      "2022-11-08 09:46:41,024 INFO     Training average loss at step 102000: 0.864185\n",
      "2022-11-08 09:46:47,457 INFO     Training average positive_sample_loss at step 102100: 1.201837\n",
      "2022-11-08 09:46:47,457 INFO     Training average negative_sample_loss at step 102100: 0.550302\n",
      "2022-11-08 09:46:47,457 INFO     Training average loss at step 102100: 0.876070\n",
      "2022-11-08 09:46:53,868 INFO     Training average positive_sample_loss at step 102200: 1.212379\n",
      "2022-11-08 09:46:53,868 INFO     Training average negative_sample_loss at step 102200: 0.550788\n",
      "2022-11-08 09:46:53,868 INFO     Training average loss at step 102200: 0.881583\n",
      "2022-11-08 09:47:00,285 INFO     Training average positive_sample_loss at step 102300: 1.197260\n",
      "2022-11-08 09:47:00,285 INFO     Training average negative_sample_loss at step 102300: 0.559753\n",
      "2022-11-08 09:47:00,285 INFO     Training average loss at step 102300: 0.878506\n",
      "2022-11-08 09:47:06,697 INFO     Training average positive_sample_loss at step 102400: 1.179211\n",
      "2022-11-08 09:47:06,697 INFO     Training average negative_sample_loss at step 102400: 0.552697\n",
      "2022-11-08 09:47:06,697 INFO     Training average loss at step 102400: 0.865954\n",
      "2022-11-08 09:47:13,113 INFO     Training average positive_sample_loss at step 102500: 1.212373\n",
      "2022-11-08 09:47:13,114 INFO     Training average negative_sample_loss at step 102500: 0.541768\n",
      "2022-11-08 09:47:13,114 INFO     Training average loss at step 102500: 0.877070\n",
      "2022-11-08 09:47:19,544 INFO     Training average positive_sample_loss at step 102600: 1.197706\n",
      "2022-11-08 09:47:19,544 INFO     Training average negative_sample_loss at step 102600: 0.545586\n",
      "2022-11-08 09:47:19,544 INFO     Training average loss at step 102600: 0.871646\n",
      "2022-11-08 09:47:25,961 INFO     Training average positive_sample_loss at step 102700: 1.145766\n",
      "2022-11-08 09:47:25,961 INFO     Training average negative_sample_loss at step 102700: 0.549961\n",
      "2022-11-08 09:47:25,961 INFO     Training average loss at step 102700: 0.847863\n",
      "2022-11-08 09:47:32,401 INFO     Training average positive_sample_loss at step 102800: 1.200475\n",
      "2022-11-08 09:47:32,401 INFO     Training average negative_sample_loss at step 102800: 0.551283\n",
      "2022-11-08 09:47:32,401 INFO     Training average loss at step 102800: 0.875879\n",
      "2022-11-08 09:47:38,879 INFO     Training average positive_sample_loss at step 102900: 1.145091\n",
      "2022-11-08 09:47:38,880 INFO     Training average negative_sample_loss at step 102900: 0.546499\n",
      "2022-11-08 09:47:38,880 INFO     Training average loss at step 102900: 0.845795\n",
      "2022-11-08 09:47:45,345 INFO     Training average positive_sample_loss at step 103000: 1.157878\n",
      "2022-11-08 09:47:45,345 INFO     Training average negative_sample_loss at step 103000: 0.547551\n",
      "2022-11-08 09:47:45,345 INFO     Training average loss at step 103000: 0.852715\n",
      "2022-11-08 09:47:51,800 INFO     Training average positive_sample_loss at step 103100: 1.171543\n",
      "2022-11-08 09:47:51,800 INFO     Training average negative_sample_loss at step 103100: 0.552760\n",
      "2022-11-08 09:47:51,801 INFO     Training average loss at step 103100: 0.862151\n",
      "2022-11-08 09:47:58,244 INFO     Training average positive_sample_loss at step 103200: 1.184303\n",
      "2022-11-08 09:47:58,244 INFO     Training average negative_sample_loss at step 103200: 0.547201\n",
      "2022-11-08 09:47:58,244 INFO     Training average loss at step 103200: 0.865752\n",
      "2022-11-08 09:48:04,699 INFO     Training average positive_sample_loss at step 103300: 1.161288\n",
      "2022-11-08 09:48:04,699 INFO     Training average negative_sample_loss at step 103300: 0.554924\n",
      "2022-11-08 09:48:04,699 INFO     Training average loss at step 103300: 0.858106\n",
      "2022-11-08 09:48:12,326 INFO     Training average positive_sample_loss at step 103400: 1.209120\n",
      "2022-11-08 09:48:12,326 INFO     Training average negative_sample_loss at step 103400: 0.547536\n",
      "2022-11-08 09:48:12,326 INFO     Training average loss at step 103400: 0.878328\n",
      "2022-11-08 09:48:20,208 INFO     Training average positive_sample_loss at step 103500: 1.182420\n",
      "2022-11-08 09:48:20,208 INFO     Training average negative_sample_loss at step 103500: 0.551517\n",
      "2022-11-08 09:48:20,208 INFO     Training average loss at step 103500: 0.866968\n",
      "2022-11-08 09:48:26,725 INFO     Training average positive_sample_loss at step 103600: 1.157482\n",
      "2022-11-08 09:48:26,725 INFO     Training average negative_sample_loss at step 103600: 0.543927\n",
      "2022-11-08 09:48:26,725 INFO     Training average loss at step 103600: 0.850705\n",
      "2022-11-08 09:48:33,295 INFO     Training average positive_sample_loss at step 103700: 1.160567\n",
      "2022-11-08 09:48:33,295 INFO     Training average negative_sample_loss at step 103700: 0.548131\n",
      "2022-11-08 09:48:33,295 INFO     Training average loss at step 103700: 0.854349\n",
      "2022-11-08 09:48:39,779 INFO     Training average positive_sample_loss at step 103800: 1.162134\n",
      "2022-11-08 09:48:39,779 INFO     Training average negative_sample_loss at step 103800: 0.549512\n",
      "2022-11-08 09:48:39,779 INFO     Training average loss at step 103800: 0.855823\n",
      "2022-11-08 09:48:46,241 INFO     Training average positive_sample_loss at step 103900: 1.203259\n",
      "2022-11-08 09:48:46,241 INFO     Training average negative_sample_loss at step 103900: 0.539738\n",
      "2022-11-08 09:48:46,241 INFO     Training average loss at step 103900: 0.871499\n",
      "2022-11-08 09:48:52,660 INFO     Training average positive_sample_loss at step 104000: 1.161462\n",
      "2022-11-08 09:48:52,661 INFO     Training average negative_sample_loss at step 104000: 0.538895\n",
      "2022-11-08 09:48:52,661 INFO     Training average loss at step 104000: 0.850178\n",
      "2022-11-08 09:48:59,092 INFO     Training average positive_sample_loss at step 104100: 1.135191\n",
      "2022-11-08 09:48:59,092 INFO     Training average negative_sample_loss at step 104100: 0.547815\n",
      "2022-11-08 09:48:59,092 INFO     Training average loss at step 104100: 0.841503\n",
      "2022-11-08 09:49:05,511 INFO     Training average positive_sample_loss at step 104200: 1.145958\n",
      "2022-11-08 09:49:05,511 INFO     Training average negative_sample_loss at step 104200: 0.548788\n",
      "2022-11-08 09:49:05,511 INFO     Training average loss at step 104200: 0.847373\n",
      "2022-11-08 09:49:11,988 INFO     Training average positive_sample_loss at step 104300: 1.141536\n",
      "2022-11-08 09:49:11,988 INFO     Training average negative_sample_loss at step 104300: 0.544282\n",
      "2022-11-08 09:49:11,988 INFO     Training average loss at step 104300: 0.842909\n",
      "2022-11-08 09:49:17,133 INFO     Training average positive_sample_loss at step 104400: 1.158800\n",
      "2022-11-08 09:49:17,133 INFO     Training average negative_sample_loss at step 104400: 0.551977\n",
      "2022-11-08 09:49:17,133 INFO     Training average loss at step 104400: 0.855388\n",
      "2022-11-08 09:49:23,572 INFO     Training average positive_sample_loss at step 104500: 1.171721\n",
      "2022-11-08 09:49:23,572 INFO     Training average negative_sample_loss at step 104500: 0.538761\n",
      "2022-11-08 09:49:23,572 INFO     Training average loss at step 104500: 0.855241\n",
      "2022-11-08 09:49:30,000 INFO     Training average positive_sample_loss at step 104600: 1.232842\n",
      "2022-11-08 09:49:30,001 INFO     Training average negative_sample_loss at step 104600: 0.538336\n",
      "2022-11-08 09:49:30,001 INFO     Training average loss at step 104600: 0.885589\n",
      "2022-11-08 09:49:36,443 INFO     Training average positive_sample_loss at step 104700: 1.136501\n",
      "2022-11-08 09:49:36,443 INFO     Training average negative_sample_loss at step 104700: 0.542255\n",
      "2022-11-08 09:49:36,443 INFO     Training average loss at step 104700: 0.839378\n",
      "2022-11-08 09:49:42,871 INFO     Training average positive_sample_loss at step 104800: 1.149853\n",
      "2022-11-08 09:49:42,871 INFO     Training average negative_sample_loss at step 104800: 0.541640\n",
      "2022-11-08 09:49:42,871 INFO     Training average loss at step 104800: 0.845746\n",
      "2022-11-08 09:49:49,284 INFO     Training average positive_sample_loss at step 104900: 1.213123\n",
      "2022-11-08 09:49:49,284 INFO     Training average negative_sample_loss at step 104900: 0.541533\n",
      "2022-11-08 09:49:49,284 INFO     Training average loss at step 104900: 0.877328\n",
      "2022-11-08 09:49:55,727 INFO     Training average positive_sample_loss at step 105000: 1.189485\n",
      "2022-11-08 09:49:55,727 INFO     Training average negative_sample_loss at step 105000: 0.539142\n",
      "2022-11-08 09:49:55,727 INFO     Training average loss at step 105000: 0.864314\n",
      "2022-11-08 09:50:02,175 INFO     Training average positive_sample_loss at step 105100: 1.175138\n",
      "2022-11-08 09:50:02,175 INFO     Training average negative_sample_loss at step 105100: 0.534557\n",
      "2022-11-08 09:50:02,175 INFO     Training average loss at step 105100: 0.854848\n",
      "2022-11-08 09:50:08,621 INFO     Training average positive_sample_loss at step 105200: 1.138305\n",
      "2022-11-08 09:50:08,621 INFO     Training average negative_sample_loss at step 105200: 0.547266\n",
      "2022-11-08 09:50:08,621 INFO     Training average loss at step 105200: 0.842785\n",
      "2022-11-08 09:50:15,053 INFO     Training average positive_sample_loss at step 105300: 1.130647\n",
      "2022-11-08 09:50:15,053 INFO     Training average negative_sample_loss at step 105300: 0.541342\n",
      "2022-11-08 09:50:15,053 INFO     Training average loss at step 105300: 0.835994\n",
      "2022-11-08 09:50:21,478 INFO     Training average positive_sample_loss at step 105400: 1.192341\n",
      "2022-11-08 09:50:21,478 INFO     Training average negative_sample_loss at step 105400: 0.538169\n",
      "2022-11-08 09:50:21,478 INFO     Training average loss at step 105400: 0.865255\n",
      "2022-11-08 09:50:27,983 INFO     Training average positive_sample_loss at step 105500: 1.141113\n",
      "2022-11-08 09:50:27,983 INFO     Training average negative_sample_loss at step 105500: 0.535605\n",
      "2022-11-08 09:50:27,983 INFO     Training average loss at step 105500: 0.838359\n",
      "2022-11-08 09:50:34,488 INFO     Training average positive_sample_loss at step 105600: 1.172296\n",
      "2022-11-08 09:50:34,488 INFO     Training average negative_sample_loss at step 105600: 0.533731\n",
      "2022-11-08 09:50:34,488 INFO     Training average loss at step 105600: 0.853014\n",
      "2022-11-08 09:50:40,922 INFO     Training average positive_sample_loss at step 105700: 1.180368\n",
      "2022-11-08 09:50:40,922 INFO     Training average negative_sample_loss at step 105700: 0.535684\n",
      "2022-11-08 09:50:40,922 INFO     Training average loss at step 105700: 0.858026\n",
      "2022-11-08 09:50:47,398 INFO     Training average positive_sample_loss at step 105800: 1.194242\n",
      "2022-11-08 09:50:47,398 INFO     Training average negative_sample_loss at step 105800: 0.538643\n",
      "2022-11-08 09:50:47,398 INFO     Training average loss at step 105800: 0.866443\n",
      "2022-11-08 09:50:53,848 INFO     Training average positive_sample_loss at step 105900: 1.187276\n",
      "2022-11-08 09:50:53,848 INFO     Training average negative_sample_loss at step 105900: 0.538915\n",
      "2022-11-08 09:50:53,848 INFO     Training average loss at step 105900: 0.863095\n",
      "2022-11-08 09:51:00,257 INFO     Training average positive_sample_loss at step 106000: 1.135788\n",
      "2022-11-08 09:51:00,257 INFO     Training average negative_sample_loss at step 106000: 0.544755\n",
      "2022-11-08 09:51:00,257 INFO     Training average loss at step 106000: 0.840271\n",
      "2022-11-08 09:51:06,663 INFO     Training average positive_sample_loss at step 106100: 1.175157\n",
      "2022-11-08 09:51:06,664 INFO     Training average negative_sample_loss at step 106100: 0.533402\n",
      "2022-11-08 09:51:06,664 INFO     Training average loss at step 106100: 0.854280\n",
      "2022-11-08 09:51:13,088 INFO     Training average positive_sample_loss at step 106200: 1.152394\n",
      "2022-11-08 09:51:13,088 INFO     Training average negative_sample_loss at step 106200: 0.538350\n",
      "2022-11-08 09:51:13,088 INFO     Training average loss at step 106200: 0.845372\n",
      "2022-11-08 09:51:19,510 INFO     Training average positive_sample_loss at step 106300: 1.134611\n",
      "2022-11-08 09:51:19,511 INFO     Training average negative_sample_loss at step 106300: 0.536231\n",
      "2022-11-08 09:51:19,511 INFO     Training average loss at step 106300: 0.835421\n",
      "2022-11-08 09:51:25,932 INFO     Training average positive_sample_loss at step 106400: 1.195314\n",
      "2022-11-08 09:51:25,932 INFO     Training average negative_sample_loss at step 106400: 0.534389\n",
      "2022-11-08 09:51:25,932 INFO     Training average loss at step 106400: 0.864851\n",
      "2022-11-08 09:51:32,374 INFO     Training average positive_sample_loss at step 106500: 1.142435\n",
      "2022-11-08 09:51:32,374 INFO     Training average negative_sample_loss at step 106500: 0.534712\n",
      "2022-11-08 09:51:32,374 INFO     Training average loss at step 106500: 0.838574\n",
      "2022-11-08 09:51:38,796 INFO     Training average positive_sample_loss at step 106600: 1.142008\n",
      "2022-11-08 09:51:38,796 INFO     Training average negative_sample_loss at step 106600: 0.536494\n",
      "2022-11-08 09:51:38,796 INFO     Training average loss at step 106600: 0.839251\n",
      "2022-11-08 09:51:45,191 INFO     Training average positive_sample_loss at step 106700: 1.179062\n",
      "2022-11-08 09:51:45,191 INFO     Training average negative_sample_loss at step 106700: 0.532023\n",
      "2022-11-08 09:51:45,191 INFO     Training average loss at step 106700: 0.855542\n",
      "2022-11-08 09:51:51,614 INFO     Training average positive_sample_loss at step 106800: 1.139453\n",
      "2022-11-08 09:51:51,614 INFO     Training average negative_sample_loss at step 106800: 0.535511\n",
      "2022-11-08 09:51:51,614 INFO     Training average loss at step 106800: 0.837482\n",
      "2022-11-08 09:51:58,020 INFO     Training average positive_sample_loss at step 106900: 1.186749\n",
      "2022-11-08 09:51:58,020 INFO     Training average negative_sample_loss at step 106900: 0.540715\n",
      "2022-11-08 09:51:58,020 INFO     Training average loss at step 106900: 0.863732\n",
      "2022-11-08 09:52:04,445 INFO     Training average positive_sample_loss at step 107000: 1.124593\n",
      "2022-11-08 09:52:04,445 INFO     Training average negative_sample_loss at step 107000: 0.542150\n",
      "2022-11-08 09:52:04,445 INFO     Training average loss at step 107000: 0.833371\n",
      "2022-11-08 09:52:10,863 INFO     Training average positive_sample_loss at step 107100: 1.169696\n",
      "2022-11-08 09:52:10,864 INFO     Training average negative_sample_loss at step 107100: 0.538865\n",
      "2022-11-08 09:52:10,864 INFO     Training average loss at step 107100: 0.854280\n",
      "2022-11-08 09:52:17,252 INFO     Training average positive_sample_loss at step 107200: 1.166773\n",
      "2022-11-08 09:52:17,252 INFO     Training average negative_sample_loss at step 107200: 0.538908\n",
      "2022-11-08 09:52:17,252 INFO     Training average loss at step 107200: 0.852841\n",
      "2022-11-08 09:52:23,680 INFO     Training average positive_sample_loss at step 107300: 1.142687\n",
      "2022-11-08 09:52:23,680 INFO     Training average negative_sample_loss at step 107300: 0.536803\n",
      "2022-11-08 09:52:23,680 INFO     Training average loss at step 107300: 0.839745\n",
      "2022-11-08 09:52:30,129 INFO     Training average positive_sample_loss at step 107400: 1.145486\n",
      "2022-11-08 09:52:30,129 INFO     Training average negative_sample_loss at step 107400: 0.530649\n",
      "2022-11-08 09:52:30,129 INFO     Training average loss at step 107400: 0.838067\n",
      "2022-11-08 09:52:36,535 INFO     Training average positive_sample_loss at step 107500: 1.191136\n",
      "2022-11-08 09:52:36,535 INFO     Training average negative_sample_loss at step 107500: 0.529841\n",
      "2022-11-08 09:52:36,535 INFO     Training average loss at step 107500: 0.860488\n",
      "2022-11-08 09:52:42,940 INFO     Training average positive_sample_loss at step 107600: 1.167947\n",
      "2022-11-08 09:52:42,940 INFO     Training average negative_sample_loss at step 107600: 0.528362\n",
      "2022-11-08 09:52:42,940 INFO     Training average loss at step 107600: 0.848155\n",
      "2022-11-08 09:52:49,358 INFO     Training average positive_sample_loss at step 107700: 1.161015\n",
      "2022-11-08 09:52:49,358 INFO     Training average negative_sample_loss at step 107700: 0.529885\n",
      "2022-11-08 09:52:49,358 INFO     Training average loss at step 107700: 0.845450\n",
      "2022-11-08 09:52:55,769 INFO     Training average positive_sample_loss at step 107800: 1.137310\n",
      "2022-11-08 09:52:55,769 INFO     Training average negative_sample_loss at step 107800: 0.535656\n",
      "2022-11-08 09:52:55,769 INFO     Training average loss at step 107800: 0.836483\n",
      "2022-11-08 09:53:02,228 INFO     Training average positive_sample_loss at step 107900: 1.141310\n",
      "2022-11-08 09:53:02,228 INFO     Training average negative_sample_loss at step 107900: 0.530879\n",
      "2022-11-08 09:53:02,228 INFO     Training average loss at step 107900: 0.836095\n",
      "2022-11-08 09:53:08,665 INFO     Training average positive_sample_loss at step 108000: 1.100019\n",
      "2022-11-08 09:53:08,665 INFO     Training average negative_sample_loss at step 108000: 0.530592\n",
      "2022-11-08 09:53:08,665 INFO     Training average loss at step 108000: 0.815306\n",
      "2022-11-08 09:53:17,935 INFO     Training average positive_sample_loss at step 108100: 1.154992\n",
      "2022-11-08 09:53:17,936 INFO     Training average negative_sample_loss at step 108100: 0.528644\n",
      "2022-11-08 09:53:17,936 INFO     Training average loss at step 108100: 0.841818\n",
      "2022-11-08 09:53:24,348 INFO     Training average positive_sample_loss at step 108200: 1.145340\n",
      "2022-11-08 09:53:24,348 INFO     Training average negative_sample_loss at step 108200: 0.527906\n",
      "2022-11-08 09:53:24,348 INFO     Training average loss at step 108200: 0.836623\n",
      "2022-11-08 09:53:30,751 INFO     Training average positive_sample_loss at step 108300: 1.148027\n",
      "2022-11-08 09:53:30,751 INFO     Training average negative_sample_loss at step 108300: 0.534421\n",
      "2022-11-08 09:53:30,751 INFO     Training average loss at step 108300: 0.841224\n",
      "2022-11-08 09:53:37,167 INFO     Training average positive_sample_loss at step 108400: 1.169881\n",
      "2022-11-08 09:53:37,167 INFO     Training average negative_sample_loss at step 108400: 0.532385\n",
      "2022-11-08 09:53:37,167 INFO     Training average loss at step 108400: 0.851133\n",
      "2022-11-08 09:53:43,560 INFO     Training average positive_sample_loss at step 108500: 1.122549\n",
      "2022-11-08 09:53:43,560 INFO     Training average negative_sample_loss at step 108500: 0.533088\n",
      "2022-11-08 09:53:43,560 INFO     Training average loss at step 108500: 0.827819\n",
      "2022-11-08 09:53:49,981 INFO     Training average positive_sample_loss at step 108600: 1.196972\n",
      "2022-11-08 09:53:49,981 INFO     Training average negative_sample_loss at step 108600: 0.527238\n",
      "2022-11-08 09:53:49,981 INFO     Training average loss at step 108600: 0.862105\n",
      "2022-11-08 09:53:56,380 INFO     Training average positive_sample_loss at step 108700: 1.130419\n",
      "2022-11-08 09:53:56,380 INFO     Training average negative_sample_loss at step 108700: 0.536415\n",
      "2022-11-08 09:53:56,380 INFO     Training average loss at step 108700: 0.833417\n",
      "2022-11-08 09:54:02,766 INFO     Training average positive_sample_loss at step 108800: 1.137229\n",
      "2022-11-08 09:54:02,767 INFO     Training average negative_sample_loss at step 108800: 0.533039\n",
      "2022-11-08 09:54:02,767 INFO     Training average loss at step 108800: 0.835134\n",
      "2022-11-08 09:54:09,169 INFO     Training average positive_sample_loss at step 108900: 1.159152\n",
      "2022-11-08 09:54:09,169 INFO     Training average negative_sample_loss at step 108900: 0.533322\n",
      "2022-11-08 09:54:09,169 INFO     Training average loss at step 108900: 0.846237\n",
      "2022-11-08 09:54:15,586 INFO     Training average positive_sample_loss at step 109000: 1.157203\n",
      "2022-11-08 09:54:15,587 INFO     Training average negative_sample_loss at step 109000: 0.522175\n",
      "2022-11-08 09:54:15,587 INFO     Training average loss at step 109000: 0.839689\n",
      "2022-11-08 09:54:22,024 INFO     Training average positive_sample_loss at step 109100: 1.120701\n",
      "2022-11-08 09:54:22,024 INFO     Training average negative_sample_loss at step 109100: 0.535394\n",
      "2022-11-08 09:54:22,024 INFO     Training average loss at step 109100: 0.828047\n",
      "2022-11-08 09:54:28,448 INFO     Training average positive_sample_loss at step 109200: 1.158566\n",
      "2022-11-08 09:54:28,449 INFO     Training average negative_sample_loss at step 109200: 0.528881\n",
      "2022-11-08 09:54:28,449 INFO     Training average loss at step 109200: 0.843723\n",
      "2022-11-08 09:54:34,861 INFO     Training average positive_sample_loss at step 109300: 1.145367\n",
      "2022-11-08 09:54:34,861 INFO     Training average negative_sample_loss at step 109300: 0.528126\n",
      "2022-11-08 09:54:34,861 INFO     Training average loss at step 109300: 0.836746\n",
      "2022-11-08 09:54:41,274 INFO     Training average positive_sample_loss at step 109400: 1.103915\n",
      "2022-11-08 09:54:41,275 INFO     Training average negative_sample_loss at step 109400: 0.526967\n",
      "2022-11-08 09:54:41,275 INFO     Training average loss at step 109400: 0.815441\n",
      "2022-11-08 09:54:47,696 INFO     Training average positive_sample_loss at step 109500: 1.195318\n",
      "2022-11-08 09:54:47,696 INFO     Training average negative_sample_loss at step 109500: 0.522811\n",
      "2022-11-08 09:54:47,696 INFO     Training average loss at step 109500: 0.859065\n",
      "2022-11-08 09:54:54,106 INFO     Training average positive_sample_loss at step 109600: 1.137277\n",
      "2022-11-08 09:54:54,106 INFO     Training average negative_sample_loss at step 109600: 0.525385\n",
      "2022-11-08 09:54:54,106 INFO     Training average loss at step 109600: 0.831331\n",
      "2022-11-08 09:55:00,522 INFO     Training average positive_sample_loss at step 109700: 1.123901\n",
      "2022-11-08 09:55:00,522 INFO     Training average negative_sample_loss at step 109700: 0.529637\n",
      "2022-11-08 09:55:00,522 INFO     Training average loss at step 109700: 0.826769\n",
      "2022-11-08 09:55:06,944 INFO     Training average positive_sample_loss at step 109800: 1.165108\n",
      "2022-11-08 09:55:06,945 INFO     Training average negative_sample_loss at step 109800: 0.531903\n",
      "2022-11-08 09:55:06,945 INFO     Training average loss at step 109800: 0.848506\n",
      "2022-11-08 09:55:13,350 INFO     Training average positive_sample_loss at step 109900: 1.133021\n",
      "2022-11-08 09:55:13,351 INFO     Training average negative_sample_loss at step 109900: 0.532660\n",
      "2022-11-08 09:55:13,351 INFO     Training average loss at step 109900: 0.832841\n",
      "2022-11-08 09:55:21,633 INFO     Training average positive_sample_loss at step 110000: 1.161231\n",
      "2022-11-08 09:55:21,633 INFO     Training average negative_sample_loss at step 110000: 0.530519\n",
      "2022-11-08 09:55:21,633 INFO     Training average loss at step 110000: 0.845875\n",
      "2022-11-08 09:55:28,038 INFO     Training average positive_sample_loss at step 110100: 1.199453\n",
      "2022-11-08 09:55:28,038 INFO     Training average negative_sample_loss at step 110100: 0.516435\n",
      "2022-11-08 09:55:28,038 INFO     Training average loss at step 110100: 0.857944\n",
      "2022-11-08 09:55:34,455 INFO     Training average positive_sample_loss at step 110200: 1.162613\n",
      "2022-11-08 09:55:34,455 INFO     Training average negative_sample_loss at step 110200: 0.524204\n",
      "2022-11-08 09:55:34,455 INFO     Training average loss at step 110200: 0.843409\n",
      "2022-11-08 09:55:40,860 INFO     Training average positive_sample_loss at step 110300: 1.142812\n",
      "2022-11-08 09:55:40,860 INFO     Training average negative_sample_loss at step 110300: 0.525306\n",
      "2022-11-08 09:55:40,860 INFO     Training average loss at step 110300: 0.834059\n",
      "2022-11-08 09:55:47,264 INFO     Training average positive_sample_loss at step 110400: 1.130989\n",
      "2022-11-08 09:55:47,264 INFO     Training average negative_sample_loss at step 110400: 0.526261\n",
      "2022-11-08 09:55:47,264 INFO     Training average loss at step 110400: 0.828625\n",
      "2022-11-08 09:55:53,722 INFO     Training average positive_sample_loss at step 110500: 1.164206\n",
      "2022-11-08 09:55:53,722 INFO     Training average negative_sample_loss at step 110500: 0.527524\n",
      "2022-11-08 09:55:53,722 INFO     Training average loss at step 110500: 0.845865\n",
      "2022-11-08 09:56:00,153 INFO     Training average positive_sample_loss at step 110600: 1.150301\n",
      "2022-11-08 09:56:00,153 INFO     Training average negative_sample_loss at step 110600: 0.531039\n",
      "2022-11-08 09:56:00,153 INFO     Training average loss at step 110600: 0.840670\n",
      "2022-11-08 09:56:06,570 INFO     Training average positive_sample_loss at step 110700: 1.166872\n",
      "2022-11-08 09:56:06,570 INFO     Training average negative_sample_loss at step 110700: 0.531105\n",
      "2022-11-08 09:56:06,570 INFO     Training average loss at step 110700: 0.848989\n",
      "2022-11-08 09:56:12,997 INFO     Training average positive_sample_loss at step 110800: 1.160054\n",
      "2022-11-08 09:56:12,997 INFO     Training average negative_sample_loss at step 110800: 0.523292\n",
      "2022-11-08 09:56:12,997 INFO     Training average loss at step 110800: 0.841673\n",
      "2022-11-08 09:56:19,400 INFO     Training average positive_sample_loss at step 110900: 1.139726\n",
      "2022-11-08 09:56:19,400 INFO     Training average negative_sample_loss at step 110900: 0.514494\n",
      "2022-11-08 09:56:19,400 INFO     Training average loss at step 110900: 0.827110\n",
      "2022-11-08 09:56:25,817 INFO     Training average positive_sample_loss at step 111000: 1.144715\n",
      "2022-11-08 09:56:25,817 INFO     Training average negative_sample_loss at step 111000: 0.526798\n",
      "2022-11-08 09:56:25,817 INFO     Training average loss at step 111000: 0.835756\n",
      "2022-11-08 09:56:32,231 INFO     Training average positive_sample_loss at step 111100: 1.151541\n",
      "2022-11-08 09:56:32,231 INFO     Training average negative_sample_loss at step 111100: 0.522297\n",
      "2022-11-08 09:56:32,232 INFO     Training average loss at step 111100: 0.836919\n",
      "2022-11-08 09:56:38,655 INFO     Training average positive_sample_loss at step 111200: 1.129650\n",
      "2022-11-08 09:56:38,655 INFO     Training average negative_sample_loss at step 111200: 0.514441\n",
      "2022-11-08 09:56:38,655 INFO     Training average loss at step 111200: 0.822046\n",
      "2022-11-08 09:56:45,105 INFO     Training average positive_sample_loss at step 111300: 1.124522\n",
      "2022-11-08 09:56:45,105 INFO     Training average negative_sample_loss at step 111300: 0.526430\n",
      "2022-11-08 09:56:45,105 INFO     Training average loss at step 111300: 0.825476\n",
      "2022-11-08 09:56:51,516 INFO     Training average positive_sample_loss at step 111400: 1.119134\n",
      "2022-11-08 09:56:51,516 INFO     Training average negative_sample_loss at step 111400: 0.524887\n",
      "2022-11-08 09:56:51,516 INFO     Training average loss at step 111400: 0.822011\n",
      "2022-11-08 09:56:57,937 INFO     Training average positive_sample_loss at step 111500: 1.126660\n",
      "2022-11-08 09:56:57,937 INFO     Training average negative_sample_loss at step 111500: 0.527140\n",
      "2022-11-08 09:56:57,937 INFO     Training average loss at step 111500: 0.826900\n",
      "2022-11-08 09:57:04,355 INFO     Training average positive_sample_loss at step 111600: 1.161493\n",
      "2022-11-08 09:57:04,355 INFO     Training average negative_sample_loss at step 111600: 0.520978\n",
      "2022-11-08 09:57:04,355 INFO     Training average loss at step 111600: 0.841235\n",
      "2022-11-08 09:57:10,759 INFO     Training average positive_sample_loss at step 111700: 1.206743\n",
      "2022-11-08 09:57:10,759 INFO     Training average negative_sample_loss at step 111700: 0.524365\n",
      "2022-11-08 09:57:10,759 INFO     Training average loss at step 111700: 0.865554\n",
      "2022-11-08 09:57:17,185 INFO     Training average positive_sample_loss at step 111800: 1.124141\n",
      "2022-11-08 09:57:17,185 INFO     Training average negative_sample_loss at step 111800: 0.521470\n",
      "2022-11-08 09:57:17,185 INFO     Training average loss at step 111800: 0.822806\n",
      "2022-11-08 09:57:23,570 INFO     Training average positive_sample_loss at step 111900: 1.126082\n",
      "2022-11-08 09:57:23,570 INFO     Training average negative_sample_loss at step 111900: 0.530325\n",
      "2022-11-08 09:57:23,570 INFO     Training average loss at step 111900: 0.828204\n",
      "2022-11-08 09:57:29,968 INFO     Training average positive_sample_loss at step 112000: 1.127737\n",
      "2022-11-08 09:57:29,968 INFO     Training average negative_sample_loss at step 112000: 0.521095\n",
      "2022-11-08 09:57:29,968 INFO     Training average loss at step 112000: 0.824416\n",
      "2022-11-08 09:57:36,398 INFO     Training average positive_sample_loss at step 112100: 1.153165\n",
      "2022-11-08 09:57:36,398 INFO     Training average negative_sample_loss at step 112100: 0.506675\n",
      "2022-11-08 09:57:36,398 INFO     Training average loss at step 112100: 0.829920\n",
      "2022-11-08 09:57:42,808 INFO     Training average positive_sample_loss at step 112200: 1.139190\n",
      "2022-11-08 09:57:42,808 INFO     Training average negative_sample_loss at step 112200: 0.521338\n",
      "2022-11-08 09:57:42,808 INFO     Training average loss at step 112200: 0.830264\n",
      "2022-11-08 09:57:49,235 INFO     Training average positive_sample_loss at step 112300: 1.092876\n",
      "2022-11-08 09:57:49,235 INFO     Training average negative_sample_loss at step 112300: 0.516584\n",
      "2022-11-08 09:57:49,235 INFO     Training average loss at step 112300: 0.804730\n",
      "2022-11-08 09:57:55,688 INFO     Training average positive_sample_loss at step 112400: 1.160616\n",
      "2022-11-08 09:57:55,688 INFO     Training average negative_sample_loss at step 112400: 0.523388\n",
      "2022-11-08 09:57:55,688 INFO     Training average loss at step 112400: 0.842002\n",
      "2022-11-08 09:58:02,112 INFO     Training average positive_sample_loss at step 112500: 1.127613\n",
      "2022-11-08 09:58:02,112 INFO     Training average negative_sample_loss at step 112500: 0.525735\n",
      "2022-11-08 09:58:02,112 INFO     Training average loss at step 112500: 0.826674\n",
      "2022-11-08 09:58:09,531 INFO     Training average positive_sample_loss at step 112600: 1.141592\n",
      "2022-11-08 09:58:09,531 INFO     Training average negative_sample_loss at step 112600: 0.514479\n",
      "2022-11-08 09:58:09,531 INFO     Training average loss at step 112600: 0.828035\n",
      "2022-11-08 09:58:15,922 INFO     Training average positive_sample_loss at step 112700: 1.143150\n",
      "2022-11-08 09:58:15,922 INFO     Training average negative_sample_loss at step 112700: 0.517737\n",
      "2022-11-08 09:58:15,922 INFO     Training average loss at step 112700: 0.830444\n",
      "2022-11-08 09:58:23,848 INFO     Training average positive_sample_loss at step 112800: 1.119952\n",
      "2022-11-08 09:58:23,848 INFO     Training average negative_sample_loss at step 112800: 0.515936\n",
      "2022-11-08 09:58:23,848 INFO     Training average loss at step 112800: 0.817944\n",
      "2022-11-08 09:58:30,256 INFO     Training average positive_sample_loss at step 112900: 1.120343\n",
      "2022-11-08 09:58:30,256 INFO     Training average negative_sample_loss at step 112900: 0.520311\n",
      "2022-11-08 09:58:30,256 INFO     Training average loss at step 112900: 0.820327\n",
      "2022-11-08 09:58:36,689 INFO     Training average positive_sample_loss at step 113000: 1.106454\n",
      "2022-11-08 09:58:36,689 INFO     Training average negative_sample_loss at step 113000: 0.524153\n",
      "2022-11-08 09:58:36,689 INFO     Training average loss at step 113000: 0.815304\n",
      "2022-11-08 09:58:43,110 INFO     Training average positive_sample_loss at step 113100: 1.089913\n",
      "2022-11-08 09:58:43,110 INFO     Training average negative_sample_loss at step 113100: 0.527643\n",
      "2022-11-08 09:58:43,110 INFO     Training average loss at step 113100: 0.808778\n",
      "2022-11-08 09:58:49,526 INFO     Training average positive_sample_loss at step 113200: 1.156608\n",
      "2022-11-08 09:58:49,526 INFO     Training average negative_sample_loss at step 113200: 0.512139\n",
      "2022-11-08 09:58:49,526 INFO     Training average loss at step 113200: 0.834374\n",
      "2022-11-08 09:58:55,949 INFO     Training average positive_sample_loss at step 113300: 1.111243\n",
      "2022-11-08 09:58:55,949 INFO     Training average negative_sample_loss at step 113300: 0.519605\n",
      "2022-11-08 09:58:55,949 INFO     Training average loss at step 113300: 0.815424\n",
      "2022-11-08 09:59:02,385 INFO     Training average positive_sample_loss at step 113400: 1.145896\n",
      "2022-11-08 09:59:02,385 INFO     Training average negative_sample_loss at step 113400: 0.518529\n",
      "2022-11-08 09:59:02,385 INFO     Training average loss at step 113400: 0.832213\n",
      "2022-11-08 09:59:08,800 INFO     Training average positive_sample_loss at step 113500: 1.122296\n",
      "2022-11-08 09:59:08,800 INFO     Training average negative_sample_loss at step 113500: 0.520555\n",
      "2022-11-08 09:59:08,800 INFO     Training average loss at step 113500: 0.821425\n",
      "2022-11-08 09:59:15,197 INFO     Training average positive_sample_loss at step 113600: 1.093769\n",
      "2022-11-08 09:59:15,197 INFO     Training average negative_sample_loss at step 113600: 0.519483\n",
      "2022-11-08 09:59:15,197 INFO     Training average loss at step 113600: 0.806626\n",
      "2022-11-08 09:59:21,613 INFO     Training average positive_sample_loss at step 113700: 1.100156\n",
      "2022-11-08 09:59:21,613 INFO     Training average negative_sample_loss at step 113700: 0.513123\n",
      "2022-11-08 09:59:21,613 INFO     Training average loss at step 113700: 0.806640\n",
      "2022-11-08 09:59:28,034 INFO     Training average positive_sample_loss at step 113800: 1.123772\n",
      "2022-11-08 09:59:28,034 INFO     Training average negative_sample_loss at step 113800: 0.516293\n",
      "2022-11-08 09:59:28,034 INFO     Training average loss at step 113800: 0.820032\n",
      "2022-11-08 09:59:34,460 INFO     Training average positive_sample_loss at step 113900: 1.145641\n",
      "2022-11-08 09:59:34,460 INFO     Training average negative_sample_loss at step 113900: 0.517852\n",
      "2022-11-08 09:59:34,460 INFO     Training average loss at step 113900: 0.831746\n",
      "2022-11-08 09:59:40,865 INFO     Training average positive_sample_loss at step 114000: 1.129054\n",
      "2022-11-08 09:59:40,865 INFO     Training average negative_sample_loss at step 114000: 0.516203\n",
      "2022-11-08 09:59:40,865 INFO     Training average loss at step 114000: 0.822628\n",
      "2022-11-08 09:59:47,286 INFO     Training average positive_sample_loss at step 114100: 1.119783\n",
      "2022-11-08 09:59:47,286 INFO     Training average negative_sample_loss at step 114100: 0.514963\n",
      "2022-11-08 09:59:47,286 INFO     Training average loss at step 114100: 0.817373\n",
      "2022-11-08 09:59:53,704 INFO     Training average positive_sample_loss at step 114200: 1.105732\n",
      "2022-11-08 09:59:53,704 INFO     Training average negative_sample_loss at step 114200: 0.519974\n",
      "2022-11-08 09:59:53,704 INFO     Training average loss at step 114200: 0.812853\n",
      "2022-11-08 10:00:00,123 INFO     Training average positive_sample_loss at step 114300: 1.101546\n",
      "2022-11-08 10:00:00,123 INFO     Training average negative_sample_loss at step 114300: 0.513200\n",
      "2022-11-08 10:00:00,123 INFO     Training average loss at step 114300: 0.807373\n",
      "2022-11-08 10:00:06,541 INFO     Training average positive_sample_loss at step 114400: 1.152193\n",
      "2022-11-08 10:00:06,541 INFO     Training average negative_sample_loss at step 114400: 0.508197\n",
      "2022-11-08 10:00:06,541 INFO     Training average loss at step 114400: 0.830195\n",
      "2022-11-08 10:00:12,948 INFO     Training average positive_sample_loss at step 114500: 1.077638\n",
      "2022-11-08 10:00:12,948 INFO     Training average negative_sample_loss at step 114500: 0.520671\n",
      "2022-11-08 10:00:12,948 INFO     Training average loss at step 114500: 0.799155\n",
      "2022-11-08 10:00:19,354 INFO     Training average positive_sample_loss at step 114600: 1.118470\n",
      "2022-11-08 10:00:19,354 INFO     Training average negative_sample_loss at step 114600: 0.513434\n",
      "2022-11-08 10:00:19,354 INFO     Training average loss at step 114600: 0.815952\n",
      "2022-11-08 10:00:25,767 INFO     Training average positive_sample_loss at step 114700: 1.129153\n",
      "2022-11-08 10:00:25,767 INFO     Training average negative_sample_loss at step 114700: 0.514073\n",
      "2022-11-08 10:00:25,767 INFO     Training average loss at step 114700: 0.821613\n",
      "2022-11-08 10:00:32,192 INFO     Training average positive_sample_loss at step 114800: 1.131015\n",
      "2022-11-08 10:00:32,192 INFO     Training average negative_sample_loss at step 114800: 0.514182\n",
      "2022-11-08 10:00:32,192 INFO     Training average loss at step 114800: 0.822598\n",
      "2022-11-08 10:00:38,590 INFO     Training average positive_sample_loss at step 114900: 1.124769\n",
      "2022-11-08 10:00:38,590 INFO     Training average negative_sample_loss at step 114900: 0.515882\n",
      "2022-11-08 10:00:38,590 INFO     Training average loss at step 114900: 0.820326\n",
      "2022-11-08 10:00:44,996 INFO     Training average positive_sample_loss at step 115000: 1.115704\n",
      "2022-11-08 10:00:44,996 INFO     Training average negative_sample_loss at step 115000: 0.512428\n",
      "2022-11-08 10:00:44,996 INFO     Training average loss at step 115000: 0.814066\n",
      "2022-11-08 10:00:51,405 INFO     Training average positive_sample_loss at step 115100: 1.104510\n",
      "2022-11-08 10:00:51,405 INFO     Training average negative_sample_loss at step 115100: 0.517209\n",
      "2022-11-08 10:00:51,405 INFO     Training average loss at step 115100: 0.810859\n",
      "2022-11-08 10:00:57,848 INFO     Training average positive_sample_loss at step 115200: 1.156640\n",
      "2022-11-08 10:00:57,848 INFO     Training average negative_sample_loss at step 115200: 0.512957\n",
      "2022-11-08 10:00:57,848 INFO     Training average loss at step 115200: 0.834799\n",
      "2022-11-08 10:01:04,347 INFO     Training average positive_sample_loss at step 115300: 1.125269\n",
      "2022-11-08 10:01:04,347 INFO     Training average negative_sample_loss at step 115300: 0.511789\n",
      "2022-11-08 10:01:04,347 INFO     Training average loss at step 115300: 0.818529\n",
      "2022-11-08 10:01:10,824 INFO     Training average positive_sample_loss at step 115400: 1.124133\n",
      "2022-11-08 10:01:10,824 INFO     Training average negative_sample_loss at step 115400: 0.506422\n",
      "2022-11-08 10:01:10,824 INFO     Training average loss at step 115400: 0.815278\n",
      "2022-11-08 10:01:17,113 INFO     Training average positive_sample_loss at step 115500: 1.152242\n",
      "2022-11-08 10:01:17,113 INFO     Training average negative_sample_loss at step 115500: 0.503829\n",
      "2022-11-08 10:01:17,113 INFO     Training average loss at step 115500: 0.828035\n",
      "2022-11-08 10:01:22,076 INFO     Training average positive_sample_loss at step 115600: 1.111209\n",
      "2022-11-08 10:01:22,076 INFO     Training average negative_sample_loss at step 115600: 0.514576\n",
      "2022-11-08 10:01:22,076 INFO     Training average loss at step 115600: 0.812893\n",
      "2022-11-08 10:01:28,312 INFO     Training average positive_sample_loss at step 115700: 1.117070\n",
      "2022-11-08 10:01:28,312 INFO     Training average negative_sample_loss at step 115700: 0.508665\n",
      "2022-11-08 10:01:28,312 INFO     Training average loss at step 115700: 0.812868\n",
      "2022-11-08 10:01:34,542 INFO     Training average positive_sample_loss at step 115800: 1.167526\n",
      "2022-11-08 10:01:34,543 INFO     Training average negative_sample_loss at step 115800: 0.504664\n",
      "2022-11-08 10:01:34,543 INFO     Training average loss at step 115800: 0.836095\n",
      "2022-11-08 10:01:40,789 INFO     Training average positive_sample_loss at step 115900: 1.085814\n",
      "2022-11-08 10:01:40,789 INFO     Training average negative_sample_loss at step 115900: 0.512077\n",
      "2022-11-08 10:01:40,789 INFO     Training average loss at step 115900: 0.798945\n",
      "2022-11-08 10:01:47,030 INFO     Training average positive_sample_loss at step 116000: 1.174789\n",
      "2022-11-08 10:01:47,031 INFO     Training average negative_sample_loss at step 116000: 0.504742\n",
      "2022-11-08 10:01:47,031 INFO     Training average loss at step 116000: 0.839766\n",
      "2022-11-08 10:01:53,250 INFO     Training average positive_sample_loss at step 116100: 1.135957\n",
      "2022-11-08 10:01:53,251 INFO     Training average negative_sample_loss at step 116100: 0.505932\n",
      "2022-11-08 10:01:53,251 INFO     Training average loss at step 116100: 0.820944\n",
      "2022-11-08 10:01:59,482 INFO     Training average positive_sample_loss at step 116200: 1.140716\n",
      "2022-11-08 10:01:59,482 INFO     Training average negative_sample_loss at step 116200: 0.511635\n",
      "2022-11-08 10:01:59,483 INFO     Training average loss at step 116200: 0.826175\n",
      "2022-11-08 10:02:05,713 INFO     Training average positive_sample_loss at step 116300: 1.137018\n",
      "2022-11-08 10:02:05,713 INFO     Training average negative_sample_loss at step 116300: 0.510049\n",
      "2022-11-08 10:02:05,713 INFO     Training average loss at step 116300: 0.823533\n",
      "2022-11-08 10:02:11,945 INFO     Training average positive_sample_loss at step 116400: 1.159146\n",
      "2022-11-08 10:02:11,945 INFO     Training average negative_sample_loss at step 116400: 0.507288\n",
      "2022-11-08 10:02:11,945 INFO     Training average loss at step 116400: 0.833217\n",
      "2022-11-08 10:02:18,178 INFO     Training average positive_sample_loss at step 116500: 1.148744\n",
      "2022-11-08 10:02:18,178 INFO     Training average negative_sample_loss at step 116500: 0.507593\n",
      "2022-11-08 10:02:18,178 INFO     Training average loss at step 116500: 0.828169\n",
      "2022-11-08 10:02:24,406 INFO     Training average positive_sample_loss at step 116600: 1.099433\n",
      "2022-11-08 10:02:24,406 INFO     Training average negative_sample_loss at step 116600: 0.504510\n",
      "2022-11-08 10:02:24,406 INFO     Training average loss at step 116600: 0.801972\n",
      "2022-11-08 10:02:30,644 INFO     Training average positive_sample_loss at step 116700: 1.089123\n",
      "2022-11-08 10:02:30,644 INFO     Training average negative_sample_loss at step 116700: 0.511078\n",
      "2022-11-08 10:02:30,644 INFO     Training average loss at step 116700: 0.800101\n",
      "2022-11-08 10:02:36,862 INFO     Training average positive_sample_loss at step 116800: 1.097736\n",
      "2022-11-08 10:02:36,862 INFO     Training average negative_sample_loss at step 116800: 0.504364\n",
      "2022-11-08 10:02:36,862 INFO     Training average loss at step 116800: 0.801050\n",
      "2022-11-08 10:02:43,113 INFO     Training average positive_sample_loss at step 116900: 1.133617\n",
      "2022-11-08 10:02:43,113 INFO     Training average negative_sample_loss at step 116900: 0.499812\n",
      "2022-11-08 10:02:43,113 INFO     Training average loss at step 116900: 0.816714\n",
      "2022-11-08 10:02:49,349 INFO     Training average positive_sample_loss at step 117000: 1.102750\n",
      "2022-11-08 10:02:49,350 INFO     Training average negative_sample_loss at step 117000: 0.501372\n",
      "2022-11-08 10:02:49,350 INFO     Training average loss at step 117000: 0.802061\n",
      "2022-11-08 10:02:55,590 INFO     Training average positive_sample_loss at step 117100: 1.094147\n",
      "2022-11-08 10:02:55,590 INFO     Training average negative_sample_loss at step 117100: 0.504172\n",
      "2022-11-08 10:02:55,590 INFO     Training average loss at step 117100: 0.799160\n",
      "2022-11-08 10:03:01,822 INFO     Training average positive_sample_loss at step 117200: 1.085501\n",
      "2022-11-08 10:03:01,822 INFO     Training average negative_sample_loss at step 117200: 0.509587\n",
      "2022-11-08 10:03:01,822 INFO     Training average loss at step 117200: 0.797544\n",
      "2022-11-08 10:03:09,115 INFO     Training average positive_sample_loss at step 117300: 1.118698\n",
      "2022-11-08 10:03:09,115 INFO     Training average negative_sample_loss at step 117300: 0.506135\n",
      "2022-11-08 10:03:09,115 INFO     Training average loss at step 117300: 0.812416\n",
      "2022-11-08 10:03:15,333 INFO     Training average positive_sample_loss at step 117400: 1.102476\n",
      "2022-11-08 10:03:15,333 INFO     Training average negative_sample_loss at step 117400: 0.512013\n",
      "2022-11-08 10:03:15,333 INFO     Training average loss at step 117400: 0.807245\n",
      "2022-11-08 10:03:23,030 INFO     Training average positive_sample_loss at step 117500: 1.097157\n",
      "2022-11-08 10:03:23,030 INFO     Training average negative_sample_loss at step 117500: 0.511513\n",
      "2022-11-08 10:03:23,030 INFO     Training average loss at step 117500: 0.804335\n",
      "2022-11-08 10:03:29,267 INFO     Training average positive_sample_loss at step 117600: 1.113684\n",
      "2022-11-08 10:03:29,267 INFO     Training average negative_sample_loss at step 117600: 0.496493\n",
      "2022-11-08 10:03:29,267 INFO     Training average loss at step 117600: 0.805088\n",
      "2022-11-08 10:03:35,501 INFO     Training average positive_sample_loss at step 117700: 1.084554\n",
      "2022-11-08 10:03:35,501 INFO     Training average negative_sample_loss at step 117700: 0.498537\n",
      "2022-11-08 10:03:35,501 INFO     Training average loss at step 117700: 0.791545\n",
      "2022-11-08 10:03:41,783 INFO     Training average positive_sample_loss at step 117800: 1.079199\n",
      "2022-11-08 10:03:41,783 INFO     Training average negative_sample_loss at step 117800: 0.502916\n",
      "2022-11-08 10:03:41,783 INFO     Training average loss at step 117800: 0.791058\n",
      "2022-11-08 10:03:48,022 INFO     Training average positive_sample_loss at step 117900: 1.098358\n",
      "2022-11-08 10:03:48,022 INFO     Training average negative_sample_loss at step 117900: 0.498197\n",
      "2022-11-08 10:03:48,022 INFO     Training average loss at step 117900: 0.798277\n",
      "2022-11-08 10:03:54,251 INFO     Training average positive_sample_loss at step 118000: 1.091083\n",
      "2022-11-08 10:03:54,251 INFO     Training average negative_sample_loss at step 118000: 0.501275\n",
      "2022-11-08 10:03:54,251 INFO     Training average loss at step 118000: 0.796179\n",
      "2022-11-08 10:04:00,483 INFO     Training average positive_sample_loss at step 118100: 1.128556\n",
      "2022-11-08 10:04:00,483 INFO     Training average negative_sample_loss at step 118100: 0.502175\n",
      "2022-11-08 10:04:00,483 INFO     Training average loss at step 118100: 0.815365\n",
      "2022-11-08 10:04:06,737 INFO     Training average positive_sample_loss at step 118200: 1.111879\n",
      "2022-11-08 10:04:06,737 INFO     Training average negative_sample_loss at step 118200: 0.498236\n",
      "2022-11-08 10:04:06,737 INFO     Training average loss at step 118200: 0.805057\n",
      "2022-11-08 10:04:12,969 INFO     Training average positive_sample_loss at step 118300: 1.138232\n",
      "2022-11-08 10:04:12,969 INFO     Training average negative_sample_loss at step 118300: 0.496682\n",
      "2022-11-08 10:04:12,969 INFO     Training average loss at step 118300: 0.817457\n",
      "2022-11-08 10:04:19,189 INFO     Training average positive_sample_loss at step 118400: 1.114630\n",
      "2022-11-08 10:04:19,189 INFO     Training average negative_sample_loss at step 118400: 0.499926\n",
      "2022-11-08 10:04:19,189 INFO     Training average loss at step 118400: 0.807278\n",
      "2022-11-08 10:04:25,422 INFO     Training average positive_sample_loss at step 118500: 1.113023\n",
      "2022-11-08 10:04:25,422 INFO     Training average negative_sample_loss at step 118500: 0.505572\n",
      "2022-11-08 10:04:25,422 INFO     Training average loss at step 118500: 0.809297\n",
      "2022-11-08 10:04:31,661 INFO     Training average positive_sample_loss at step 118600: 1.080532\n",
      "2022-11-08 10:04:31,661 INFO     Training average negative_sample_loss at step 118600: 0.497711\n",
      "2022-11-08 10:04:31,661 INFO     Training average loss at step 118600: 0.789122\n",
      "2022-11-08 10:04:37,927 INFO     Training average positive_sample_loss at step 118700: 1.058388\n",
      "2022-11-08 10:04:37,928 INFO     Training average negative_sample_loss at step 118700: 0.503014\n",
      "2022-11-08 10:04:37,928 INFO     Training average loss at step 118700: 0.780701\n",
      "2022-11-08 10:04:44,176 INFO     Training average positive_sample_loss at step 118800: 1.139072\n",
      "2022-11-08 10:04:44,176 INFO     Training average negative_sample_loss at step 118800: 0.504484\n",
      "2022-11-08 10:04:44,176 INFO     Training average loss at step 118800: 0.821778\n",
      "2022-11-08 10:04:50,406 INFO     Training average positive_sample_loss at step 118900: 1.067192\n",
      "2022-11-08 10:04:50,406 INFO     Training average negative_sample_loss at step 118900: 0.499375\n",
      "2022-11-08 10:04:50,406 INFO     Training average loss at step 118900: 0.783284\n",
      "2022-11-08 10:04:56,640 INFO     Training average positive_sample_loss at step 119000: 1.069238\n",
      "2022-11-08 10:04:56,640 INFO     Training average negative_sample_loss at step 119000: 0.494208\n",
      "2022-11-08 10:04:56,640 INFO     Training average loss at step 119000: 0.781723\n",
      "2022-11-08 10:05:02,868 INFO     Training average positive_sample_loss at step 119100: 1.104680\n",
      "2022-11-08 10:05:02,868 INFO     Training average negative_sample_loss at step 119100: 0.499145\n",
      "2022-11-08 10:05:02,868 INFO     Training average loss at step 119100: 0.801913\n",
      "2022-11-08 10:05:09,122 INFO     Training average positive_sample_loss at step 119200: 1.111906\n",
      "2022-11-08 10:05:09,122 INFO     Training average negative_sample_loss at step 119200: 0.510717\n",
      "2022-11-08 10:05:09,122 INFO     Training average loss at step 119200: 0.811311\n",
      "2022-11-08 10:05:15,386 INFO     Training average positive_sample_loss at step 119300: 1.110641\n",
      "2022-11-08 10:05:15,386 INFO     Training average negative_sample_loss at step 119300: 0.499431\n",
      "2022-11-08 10:05:15,386 INFO     Training average loss at step 119300: 0.805036\n",
      "2022-11-08 10:05:21,626 INFO     Training average positive_sample_loss at step 119400: 1.101707\n",
      "2022-11-08 10:05:21,626 INFO     Training average negative_sample_loss at step 119400: 0.490787\n",
      "2022-11-08 10:05:21,626 INFO     Training average loss at step 119400: 0.796247\n",
      "2022-11-08 10:05:27,838 INFO     Training average positive_sample_loss at step 119500: 1.097713\n",
      "2022-11-08 10:05:27,838 INFO     Training average negative_sample_loss at step 119500: 0.502795\n",
      "2022-11-08 10:05:27,838 INFO     Training average loss at step 119500: 0.800254\n",
      "2022-11-08 10:05:34,066 INFO     Training average positive_sample_loss at step 119600: 1.115843\n",
      "2022-11-08 10:05:34,066 INFO     Training average negative_sample_loss at step 119600: 0.492897\n",
      "2022-11-08 10:05:34,066 INFO     Training average loss at step 119600: 0.804370\n",
      "2022-11-08 10:05:40,281 INFO     Training average positive_sample_loss at step 119700: 1.118664\n",
      "2022-11-08 10:05:40,281 INFO     Training average negative_sample_loss at step 119700: 0.500630\n",
      "2022-11-08 10:05:40,281 INFO     Training average loss at step 119700: 0.809647\n",
      "2022-11-08 10:05:46,513 INFO     Training average positive_sample_loss at step 119800: 1.078651\n",
      "2022-11-08 10:05:46,513 INFO     Training average negative_sample_loss at step 119800: 0.499345\n",
      "2022-11-08 10:05:46,514 INFO     Training average loss at step 119800: 0.788998\n",
      "2022-11-08 10:05:52,768 INFO     Training average positive_sample_loss at step 119900: 1.096110\n",
      "2022-11-08 10:05:52,768 INFO     Training average negative_sample_loss at step 119900: 0.505206\n",
      "2022-11-08 10:05:52,768 INFO     Training average loss at step 119900: 0.800658\n",
      "2022-11-08 10:06:01,733 INFO     Training average positive_sample_loss at step 120000: 1.082985\n",
      "2022-11-08 10:06:01,733 INFO     Training average negative_sample_loss at step 120000: 0.498755\n",
      "2022-11-08 10:06:01,733 INFO     Training average loss at step 120000: 0.790870\n",
      "2022-11-08 10:06:07,951 INFO     Training average positive_sample_loss at step 120100: 1.086539\n",
      "2022-11-08 10:06:07,951 INFO     Training average negative_sample_loss at step 120100: 0.485980\n",
      "2022-11-08 10:06:07,951 INFO     Training average loss at step 120100: 0.786260\n",
      "2022-11-08 10:06:14,177 INFO     Training average positive_sample_loss at step 120200: 1.134026\n",
      "2022-11-08 10:06:14,177 INFO     Training average negative_sample_loss at step 120200: 0.502240\n",
      "2022-11-08 10:06:14,177 INFO     Training average loss at step 120200: 0.818133\n",
      "2022-11-08 10:06:20,456 INFO     Training average positive_sample_loss at step 120300: 1.085179\n",
      "2022-11-08 10:06:20,456 INFO     Training average negative_sample_loss at step 120300: 0.495696\n",
      "2022-11-08 10:06:20,456 INFO     Training average loss at step 120300: 0.790438\n",
      "2022-11-08 10:06:26,827 INFO     Training average positive_sample_loss at step 120400: 1.075428\n",
      "2022-11-08 10:06:26,827 INFO     Training average negative_sample_loss at step 120400: 0.502496\n",
      "2022-11-08 10:06:26,827 INFO     Training average loss at step 120400: 0.788962\n",
      "2022-11-08 10:06:33,300 INFO     Training average positive_sample_loss at step 120500: 1.095681\n",
      "2022-11-08 10:06:33,300 INFO     Training average negative_sample_loss at step 120500: 0.494837\n",
      "2022-11-08 10:06:33,300 INFO     Training average loss at step 120500: 0.795259\n",
      "2022-11-08 10:06:39,718 INFO     Training average positive_sample_loss at step 120600: 1.097671\n",
      "2022-11-08 10:06:39,718 INFO     Training average negative_sample_loss at step 120600: 0.503861\n",
      "2022-11-08 10:06:39,718 INFO     Training average loss at step 120600: 0.800766\n",
      "2022-11-08 10:06:46,182 INFO     Training average positive_sample_loss at step 120700: 1.098593\n",
      "2022-11-08 10:06:46,182 INFO     Training average negative_sample_loss at step 120700: 0.493841\n",
      "2022-11-08 10:06:46,182 INFO     Training average loss at step 120700: 0.796217\n",
      "2022-11-08 10:06:52,651 INFO     Training average positive_sample_loss at step 120800: 1.097518\n",
      "2022-11-08 10:06:52,651 INFO     Training average negative_sample_loss at step 120800: 0.491574\n",
      "2022-11-08 10:06:52,651 INFO     Training average loss at step 120800: 0.794546\n",
      "2022-11-08 10:06:59,123 INFO     Training average positive_sample_loss at step 120900: 1.120882\n",
      "2022-11-08 10:06:59,123 INFO     Training average negative_sample_loss at step 120900: 0.501204\n",
      "2022-11-08 10:06:59,123 INFO     Training average loss at step 120900: 0.811043\n",
      "2022-11-08 10:07:05,617 INFO     Training average positive_sample_loss at step 121000: 1.081366\n",
      "2022-11-08 10:07:05,617 INFO     Training average negative_sample_loss at step 121000: 0.497493\n",
      "2022-11-08 10:07:05,617 INFO     Training average loss at step 121000: 0.789429\n",
      "2022-11-08 10:07:11,156 INFO     Training average positive_sample_loss at step 121100: 1.069271\n",
      "2022-11-08 10:07:11,156 INFO     Training average negative_sample_loss at step 121100: 0.490989\n",
      "2022-11-08 10:07:11,156 INFO     Training average loss at step 121100: 0.780130\n",
      "2022-11-08 10:07:17,317 INFO     Training average positive_sample_loss at step 121200: 1.129398\n",
      "2022-11-08 10:07:17,317 INFO     Training average negative_sample_loss at step 121200: 0.488621\n",
      "2022-11-08 10:07:17,317 INFO     Training average loss at step 121200: 0.809010\n",
      "2022-11-08 10:07:23,863 INFO     Training average positive_sample_loss at step 121300: 1.082682\n",
      "2022-11-08 10:07:23,863 INFO     Training average negative_sample_loss at step 121300: 0.494769\n",
      "2022-11-08 10:07:23,863 INFO     Training average loss at step 121300: 0.788726\n",
      "2022-11-08 10:07:30,405 INFO     Training average positive_sample_loss at step 121400: 1.083750\n",
      "2022-11-08 10:07:30,405 INFO     Training average negative_sample_loss at step 121400: 0.495935\n",
      "2022-11-08 10:07:30,405 INFO     Training average loss at step 121400: 0.789842\n",
      "2022-11-08 10:07:36,864 INFO     Training average positive_sample_loss at step 121500: 1.066846\n",
      "2022-11-08 10:07:36,864 INFO     Training average negative_sample_loss at step 121500: 0.501232\n",
      "2022-11-08 10:07:36,864 INFO     Training average loss at step 121500: 0.784039\n",
      "2022-11-08 10:07:43,297 INFO     Training average positive_sample_loss at step 121600: 1.088492\n",
      "2022-11-08 10:07:43,297 INFO     Training average negative_sample_loss at step 121600: 0.496553\n",
      "2022-11-08 10:07:43,298 INFO     Training average loss at step 121600: 0.792522\n",
      "2022-11-08 10:07:49,733 INFO     Training average positive_sample_loss at step 121700: 1.053043\n",
      "2022-11-08 10:07:49,733 INFO     Training average negative_sample_loss at step 121700: 0.489810\n",
      "2022-11-08 10:07:49,733 INFO     Training average loss at step 121700: 0.771427\n",
      "2022-11-08 10:07:56,174 INFO     Training average positive_sample_loss at step 121800: 1.048192\n",
      "2022-11-08 10:07:56,174 INFO     Training average negative_sample_loss at step 121800: 0.491558\n",
      "2022-11-08 10:07:56,174 INFO     Training average loss at step 121800: 0.769875\n",
      "2022-11-08 10:08:02,577 INFO     Training average positive_sample_loss at step 121900: 1.088987\n",
      "2022-11-08 10:08:02,577 INFO     Training average negative_sample_loss at step 121900: 0.490415\n",
      "2022-11-08 10:08:02,577 INFO     Training average loss at step 121900: 0.789701\n",
      "2022-11-08 10:08:10,517 INFO     Training average positive_sample_loss at step 122000: 1.078905\n",
      "2022-11-08 10:08:10,517 INFO     Training average negative_sample_loss at step 122000: 0.495097\n",
      "2022-11-08 10:08:10,517 INFO     Training average loss at step 122000: 0.787001\n",
      "2022-11-08 10:08:16,944 INFO     Training average positive_sample_loss at step 122100: 1.106175\n",
      "2022-11-08 10:08:16,944 INFO     Training average negative_sample_loss at step 122100: 0.486951\n",
      "2022-11-08 10:08:16,944 INFO     Training average loss at step 122100: 0.796563\n",
      "2022-11-08 10:08:24,534 INFO     Training average positive_sample_loss at step 122200: 1.074278\n",
      "2022-11-08 10:08:24,534 INFO     Training average negative_sample_loss at step 122200: 0.493861\n",
      "2022-11-08 10:08:24,534 INFO     Training average loss at step 122200: 0.784070\n",
      "2022-11-08 10:08:30,970 INFO     Training average positive_sample_loss at step 122300: 1.091678\n",
      "2022-11-08 10:08:30,970 INFO     Training average negative_sample_loss at step 122300: 0.488754\n",
      "2022-11-08 10:08:30,970 INFO     Training average loss at step 122300: 0.790216\n",
      "2022-11-08 10:08:37,433 INFO     Training average positive_sample_loss at step 122400: 1.100905\n",
      "2022-11-08 10:08:37,433 INFO     Training average negative_sample_loss at step 122400: 0.487838\n",
      "2022-11-08 10:08:37,433 INFO     Training average loss at step 122400: 0.794371\n",
      "2022-11-08 10:08:43,899 INFO     Training average positive_sample_loss at step 122500: 1.092618\n",
      "2022-11-08 10:08:43,899 INFO     Training average negative_sample_loss at step 122500: 0.490227\n",
      "2022-11-08 10:08:43,899 INFO     Training average loss at step 122500: 0.791422\n",
      "2022-11-08 10:08:50,317 INFO     Training average positive_sample_loss at step 122600: 1.079438\n",
      "2022-11-08 10:08:50,317 INFO     Training average negative_sample_loss at step 122600: 0.489082\n",
      "2022-11-08 10:08:50,317 INFO     Training average loss at step 122600: 0.784260\n",
      "2022-11-08 10:08:56,740 INFO     Training average positive_sample_loss at step 122700: 1.060495\n",
      "2022-11-08 10:08:56,741 INFO     Training average negative_sample_loss at step 122700: 0.485610\n",
      "2022-11-08 10:08:56,741 INFO     Training average loss at step 122700: 0.773052\n",
      "2022-11-08 10:09:03,170 INFO     Training average positive_sample_loss at step 122800: 1.136295\n",
      "2022-11-08 10:09:03,170 INFO     Training average negative_sample_loss at step 122800: 0.490659\n",
      "2022-11-08 10:09:03,170 INFO     Training average loss at step 122800: 0.813477\n",
      "2022-11-08 10:09:09,609 INFO     Training average positive_sample_loss at step 122900: 1.076327\n",
      "2022-11-08 10:09:09,610 INFO     Training average negative_sample_loss at step 122900: 0.487272\n",
      "2022-11-08 10:09:09,610 INFO     Training average loss at step 122900: 0.781800\n",
      "2022-11-08 10:09:16,049 INFO     Training average positive_sample_loss at step 123000: 1.097815\n",
      "2022-11-08 10:09:16,049 INFO     Training average negative_sample_loss at step 123000: 0.490421\n",
      "2022-11-08 10:09:16,049 INFO     Training average loss at step 123000: 0.794118\n",
      "2022-11-08 10:09:22,502 INFO     Training average positive_sample_loss at step 123100: 1.073297\n",
      "2022-11-08 10:09:22,502 INFO     Training average negative_sample_loss at step 123100: 0.493988\n",
      "2022-11-08 10:09:22,502 INFO     Training average loss at step 123100: 0.783642\n",
      "2022-11-08 10:09:28,918 INFO     Training average positive_sample_loss at step 123200: 1.081564\n",
      "2022-11-08 10:09:28,918 INFO     Training average negative_sample_loss at step 123200: 0.491627\n",
      "2022-11-08 10:09:28,918 INFO     Training average loss at step 123200: 0.786595\n",
      "2022-11-08 10:09:35,365 INFO     Training average positive_sample_loss at step 123300: 1.084493\n",
      "2022-11-08 10:09:35,365 INFO     Training average negative_sample_loss at step 123300: 0.490192\n",
      "2022-11-08 10:09:35,365 INFO     Training average loss at step 123300: 0.787342\n",
      "2022-11-08 10:09:41,834 INFO     Training average positive_sample_loss at step 123400: 1.062052\n",
      "2022-11-08 10:09:41,834 INFO     Training average negative_sample_loss at step 123400: 0.491389\n",
      "2022-11-08 10:09:41,834 INFO     Training average loss at step 123400: 0.776721\n",
      "2022-11-08 10:09:48,247 INFO     Training average positive_sample_loss at step 123500: 1.087837\n",
      "2022-11-08 10:09:48,247 INFO     Training average negative_sample_loss at step 123500: 0.488628\n",
      "2022-11-08 10:09:48,247 INFO     Training average loss at step 123500: 0.788232\n",
      "2022-11-08 10:09:54,686 INFO     Training average positive_sample_loss at step 123600: 1.058868\n",
      "2022-11-08 10:09:54,686 INFO     Training average negative_sample_loss at step 123600: 0.488166\n",
      "2022-11-08 10:09:54,687 INFO     Training average loss at step 123600: 0.773517\n",
      "2022-11-08 10:10:01,114 INFO     Training average positive_sample_loss at step 123700: 1.092469\n",
      "2022-11-08 10:10:01,114 INFO     Training average negative_sample_loss at step 123700: 0.492303\n",
      "2022-11-08 10:10:01,114 INFO     Training average loss at step 123700: 0.792386\n",
      "2022-11-08 10:10:07,553 INFO     Training average positive_sample_loss at step 123800: 1.078449\n",
      "2022-11-08 10:10:07,553 INFO     Training average negative_sample_loss at step 123800: 0.491112\n",
      "2022-11-08 10:10:07,553 INFO     Training average loss at step 123800: 0.784780\n",
      "2022-11-08 10:10:13,959 INFO     Training average positive_sample_loss at step 123900: 1.060847\n",
      "2022-11-08 10:10:13,959 INFO     Training average negative_sample_loss at step 123900: 0.485832\n",
      "2022-11-08 10:10:13,959 INFO     Training average loss at step 123900: 0.773339\n",
      "2022-11-08 10:10:20,405 INFO     Training average positive_sample_loss at step 124000: 1.123762\n",
      "2022-11-08 10:10:20,406 INFO     Training average negative_sample_loss at step 124000: 0.480450\n",
      "2022-11-08 10:10:20,406 INFO     Training average loss at step 124000: 0.802106\n",
      "2022-11-08 10:10:26,854 INFO     Training average positive_sample_loss at step 124100: 1.098266\n",
      "2022-11-08 10:10:26,855 INFO     Training average negative_sample_loss at step 124100: 0.481379\n",
      "2022-11-08 10:10:26,855 INFO     Training average loss at step 124100: 0.789822\n",
      "2022-11-08 10:10:33,294 INFO     Training average positive_sample_loss at step 124200: 1.056343\n",
      "2022-11-08 10:10:33,294 INFO     Training average negative_sample_loss at step 124200: 0.489973\n",
      "2022-11-08 10:10:33,295 INFO     Training average loss at step 124200: 0.773158\n",
      "2022-11-08 10:10:39,742 INFO     Training average positive_sample_loss at step 124300: 1.107613\n",
      "2022-11-08 10:10:39,742 INFO     Training average negative_sample_loss at step 124300: 0.483338\n",
      "2022-11-08 10:10:39,742 INFO     Training average loss at step 124300: 0.795476\n",
      "2022-11-08 10:10:46,153 INFO     Training average positive_sample_loss at step 124400: 1.077321\n",
      "2022-11-08 10:10:46,154 INFO     Training average negative_sample_loss at step 124400: 0.484600\n",
      "2022-11-08 10:10:46,154 INFO     Training average loss at step 124400: 0.780960\n",
      "2022-11-08 10:10:52,566 INFO     Training average positive_sample_loss at step 124500: 1.084069\n",
      "2022-11-08 10:10:52,566 INFO     Training average negative_sample_loss at step 124500: 0.482958\n",
      "2022-11-08 10:10:52,567 INFO     Training average loss at step 124500: 0.783513\n",
      "2022-11-08 10:10:58,982 INFO     Training average positive_sample_loss at step 124600: 1.105865\n",
      "2022-11-08 10:10:58,982 INFO     Training average negative_sample_loss at step 124600: 0.493606\n",
      "2022-11-08 10:10:58,982 INFO     Training average loss at step 124600: 0.799735\n",
      "2022-11-08 10:11:05,414 INFO     Training average positive_sample_loss at step 124700: 1.074234\n",
      "2022-11-08 10:11:05,414 INFO     Training average negative_sample_loss at step 124700: 0.485348\n",
      "2022-11-08 10:11:05,414 INFO     Training average loss at step 124700: 0.779791\n",
      "2022-11-08 10:11:11,880 INFO     Training average positive_sample_loss at step 124800: 1.081212\n",
      "2022-11-08 10:11:11,880 INFO     Training average negative_sample_loss at step 124800: 0.481484\n",
      "2022-11-08 10:11:11,880 INFO     Training average loss at step 124800: 0.781348\n",
      "2022-11-08 10:11:18,318 INFO     Training average positive_sample_loss at step 124900: 1.075304\n",
      "2022-11-08 10:11:18,318 INFO     Training average negative_sample_loss at step 124900: 0.488972\n",
      "2022-11-08 10:11:18,318 INFO     Training average loss at step 124900: 0.782138\n",
      "2022-11-08 10:11:24,757 INFO     Training average positive_sample_loss at step 125000: 1.081458\n",
      "2022-11-08 10:11:24,757 INFO     Training average negative_sample_loss at step 125000: 0.482804\n",
      "2022-11-08 10:11:24,757 INFO     Training average loss at step 125000: 0.782131\n",
      "2022-11-08 10:11:31,203 INFO     Training average positive_sample_loss at step 125100: 1.080008\n",
      "2022-11-08 10:11:31,203 INFO     Training average negative_sample_loss at step 125100: 0.487053\n",
      "2022-11-08 10:11:31,203 INFO     Training average loss at step 125100: 0.783530\n",
      "2022-11-08 10:11:37,647 INFO     Training average positive_sample_loss at step 125200: 1.071952\n",
      "2022-11-08 10:11:37,647 INFO     Training average negative_sample_loss at step 125200: 0.486958\n",
      "2022-11-08 10:11:37,647 INFO     Training average loss at step 125200: 0.779455\n",
      "2022-11-08 10:11:44,055 INFO     Training average positive_sample_loss at step 125300: 1.036364\n",
      "2022-11-08 10:11:44,055 INFO     Training average negative_sample_loss at step 125300: 0.481620\n",
      "2022-11-08 10:11:44,055 INFO     Training average loss at step 125300: 0.758992\n",
      "2022-11-08 10:11:50,454 INFO     Training average positive_sample_loss at step 125400: 1.080364\n",
      "2022-11-08 10:11:50,454 INFO     Training average negative_sample_loss at step 125400: 0.485259\n",
      "2022-11-08 10:11:50,454 INFO     Training average loss at step 125400: 0.782812\n",
      "2022-11-08 10:11:56,880 INFO     Training average positive_sample_loss at step 125500: 1.066143\n",
      "2022-11-08 10:11:56,880 INFO     Training average negative_sample_loss at step 125500: 0.483821\n",
      "2022-11-08 10:11:56,880 INFO     Training average loss at step 125500: 0.774982\n",
      "2022-11-08 10:12:03,370 INFO     Training average positive_sample_loss at step 125600: 1.065287\n",
      "2022-11-08 10:12:03,370 INFO     Training average negative_sample_loss at step 125600: 0.483014\n",
      "2022-11-08 10:12:03,370 INFO     Training average loss at step 125600: 0.774150\n",
      "2022-11-08 10:12:09,843 INFO     Training average positive_sample_loss at step 125700: 1.097086\n",
      "2022-11-08 10:12:09,843 INFO     Training average negative_sample_loss at step 125700: 0.491365\n",
      "2022-11-08 10:12:09,843 INFO     Training average loss at step 125700: 0.794225\n",
      "2022-11-08 10:12:16,248 INFO     Training average positive_sample_loss at step 125800: 1.057839\n",
      "2022-11-08 10:12:16,248 INFO     Training average negative_sample_loss at step 125800: 0.478744\n",
      "2022-11-08 10:12:16,248 INFO     Training average loss at step 125800: 0.768291\n",
      "2022-11-08 10:12:22,706 INFO     Training average positive_sample_loss at step 125900: 1.094649\n",
      "2022-11-08 10:12:22,706 INFO     Training average negative_sample_loss at step 125900: 0.481726\n",
      "2022-11-08 10:12:22,706 INFO     Training average loss at step 125900: 0.788187\n",
      "2022-11-08 10:12:29,146 INFO     Training average positive_sample_loss at step 126000: 1.083525\n",
      "2022-11-08 10:12:29,146 INFO     Training average negative_sample_loss at step 126000: 0.482779\n",
      "2022-11-08 10:12:29,146 INFO     Training average loss at step 126000: 0.783152\n",
      "2022-11-08 10:12:35,559 INFO     Training average positive_sample_loss at step 126100: 1.078622\n",
      "2022-11-08 10:12:35,559 INFO     Training average negative_sample_loss at step 126100: 0.479035\n",
      "2022-11-08 10:12:35,559 INFO     Training average loss at step 126100: 0.778828\n",
      "2022-11-08 10:12:41,954 INFO     Training average positive_sample_loss at step 126200: 1.083623\n",
      "2022-11-08 10:12:41,954 INFO     Training average negative_sample_loss at step 126200: 0.486825\n",
      "2022-11-08 10:12:41,954 INFO     Training average loss at step 126200: 0.785224\n",
      "2022-11-08 10:12:48,409 INFO     Training average positive_sample_loss at step 126300: 1.085685\n",
      "2022-11-08 10:12:48,409 INFO     Training average negative_sample_loss at step 126300: 0.480537\n",
      "2022-11-08 10:12:48,409 INFO     Training average loss at step 126300: 0.783111\n",
      "2022-11-08 10:12:54,847 INFO     Training average positive_sample_loss at step 126400: 1.070975\n",
      "2022-11-08 10:12:54,847 INFO     Training average negative_sample_loss at step 126400: 0.480356\n",
      "2022-11-08 10:12:54,847 INFO     Training average loss at step 126400: 0.775666\n",
      "2022-11-08 10:13:01,264 INFO     Training average positive_sample_loss at step 126500: 1.077780\n",
      "2022-11-08 10:13:01,264 INFO     Training average negative_sample_loss at step 126500: 0.483312\n",
      "2022-11-08 10:13:01,264 INFO     Training average loss at step 126500: 0.780546\n",
      "2022-11-08 10:13:08,387 INFO     Training average positive_sample_loss at step 126600: 1.080543\n",
      "2022-11-08 10:13:08,387 INFO     Training average negative_sample_loss at step 126600: 0.483718\n",
      "2022-11-08 10:13:08,388 INFO     Training average loss at step 126600: 0.782130\n",
      "2022-11-08 10:13:15,950 INFO     Training average positive_sample_loss at step 126700: 1.081180\n",
      "2022-11-08 10:13:15,950 INFO     Training average negative_sample_loss at step 126700: 0.482746\n",
      "2022-11-08 10:13:15,950 INFO     Training average loss at step 126700: 0.781963\n",
      "2022-11-08 10:13:23,471 INFO     Training average positive_sample_loss at step 126800: 1.065052\n",
      "2022-11-08 10:13:23,471 INFO     Training average negative_sample_loss at step 126800: 0.483452\n",
      "2022-11-08 10:13:23,471 INFO     Training average loss at step 126800: 0.774252\n",
      "2022-11-08 10:13:30,041 INFO     Training average positive_sample_loss at step 126900: 1.045637\n",
      "2022-11-08 10:13:30,041 INFO     Training average negative_sample_loss at step 126900: 0.481700\n",
      "2022-11-08 10:13:30,041 INFO     Training average loss at step 126900: 0.763669\n",
      "2022-11-08 10:13:36,487 INFO     Training average positive_sample_loss at step 127000: 1.079294\n",
      "2022-11-08 10:13:36,487 INFO     Training average negative_sample_loss at step 127000: 0.480014\n",
      "2022-11-08 10:13:36,487 INFO     Training average loss at step 127000: 0.779654\n",
      "2022-11-08 10:13:43,190 INFO     Training average positive_sample_loss at step 127100: 1.050972\n",
      "2022-11-08 10:13:43,191 INFO     Training average negative_sample_loss at step 127100: 0.482448\n",
      "2022-11-08 10:13:43,191 INFO     Training average loss at step 127100: 0.766710\n",
      "2022-11-08 10:13:49,764 INFO     Training average positive_sample_loss at step 127200: 1.055718\n",
      "2022-11-08 10:13:49,764 INFO     Training average negative_sample_loss at step 127200: 0.481625\n",
      "2022-11-08 10:13:49,764 INFO     Training average loss at step 127200: 0.768671\n",
      "2022-11-08 10:13:56,284 INFO     Training average positive_sample_loss at step 127300: 1.069761\n",
      "2022-11-08 10:13:56,284 INFO     Training average negative_sample_loss at step 127300: 0.477888\n",
      "2022-11-08 10:13:56,284 INFO     Training average loss at step 127300: 0.773824\n",
      "2022-11-08 10:14:02,697 INFO     Training average positive_sample_loss at step 127400: 1.040629\n",
      "2022-11-08 10:14:02,697 INFO     Training average negative_sample_loss at step 127400: 0.484138\n",
      "2022-11-08 10:14:02,697 INFO     Training average loss at step 127400: 0.762383\n",
      "2022-11-08 10:14:09,285 INFO     Training average positive_sample_loss at step 127500: 1.097991\n",
      "2022-11-08 10:14:09,285 INFO     Training average negative_sample_loss at step 127500: 0.473128\n",
      "2022-11-08 10:14:09,285 INFO     Training average loss at step 127500: 0.785559\n",
      "2022-11-08 10:14:15,865 INFO     Training average positive_sample_loss at step 127600: 1.062987\n",
      "2022-11-08 10:14:15,865 INFO     Training average negative_sample_loss at step 127600: 0.489290\n",
      "2022-11-08 10:14:15,865 INFO     Training average loss at step 127600: 0.776138\n",
      "2022-11-08 10:14:22,458 INFO     Training average positive_sample_loss at step 127700: 1.033872\n",
      "2022-11-08 10:14:22,458 INFO     Training average negative_sample_loss at step 127700: 0.480457\n",
      "2022-11-08 10:14:22,458 INFO     Training average loss at step 127700: 0.757164\n",
      "2022-11-08 10:14:29,021 INFO     Training average positive_sample_loss at step 127800: 1.057926\n",
      "2022-11-08 10:14:29,021 INFO     Training average negative_sample_loss at step 127800: 0.479187\n",
      "2022-11-08 10:14:29,021 INFO     Training average loss at step 127800: 0.768557\n",
      "2022-11-08 10:14:35,623 INFO     Training average positive_sample_loss at step 127900: 1.049536\n",
      "2022-11-08 10:14:35,623 INFO     Training average negative_sample_loss at step 127900: 0.479813\n",
      "2022-11-08 10:14:35,623 INFO     Training average loss at step 127900: 0.764675\n",
      "2022-11-08 10:14:42,223 INFO     Training average positive_sample_loss at step 128000: 1.015229\n",
      "2022-11-08 10:14:42,223 INFO     Training average negative_sample_loss at step 128000: 0.479796\n",
      "2022-11-08 10:14:42,223 INFO     Training average loss at step 128000: 0.747513\n",
      "2022-11-08 10:14:48,810 INFO     Training average positive_sample_loss at step 128100: 1.068721\n",
      "2022-11-08 10:14:48,810 INFO     Training average negative_sample_loss at step 128100: 0.476026\n",
      "2022-11-08 10:14:48,810 INFO     Training average loss at step 128100: 0.772374\n",
      "2022-11-08 10:14:55,405 INFO     Training average positive_sample_loss at step 128200: 1.032822\n",
      "2022-11-08 10:14:55,405 INFO     Training average negative_sample_loss at step 128200: 0.484886\n",
      "2022-11-08 10:14:55,405 INFO     Training average loss at step 128200: 0.758854\n",
      "2022-11-08 10:15:02,016 INFO     Training average positive_sample_loss at step 128300: 1.060803\n",
      "2022-11-08 10:15:02,016 INFO     Training average negative_sample_loss at step 128300: 0.477864\n",
      "2022-11-08 10:15:02,016 INFO     Training average loss at step 128300: 0.769333\n",
      "2022-11-08 10:15:08,589 INFO     Training average positive_sample_loss at step 128400: 1.049406\n",
      "2022-11-08 10:15:08,589 INFO     Training average negative_sample_loss at step 128400: 0.487228\n",
      "2022-11-08 10:15:08,590 INFO     Training average loss at step 128400: 0.768317\n",
      "2022-11-08 10:15:15,207 INFO     Training average positive_sample_loss at step 128500: 1.053969\n",
      "2022-11-08 10:15:15,207 INFO     Training average negative_sample_loss at step 128500: 0.472424\n",
      "2022-11-08 10:15:15,207 INFO     Training average loss at step 128500: 0.763197\n",
      "2022-11-08 10:15:21,817 INFO     Training average positive_sample_loss at step 128600: 1.075262\n",
      "2022-11-08 10:15:21,818 INFO     Training average negative_sample_loss at step 128600: 0.476072\n",
      "2022-11-08 10:15:21,818 INFO     Training average loss at step 128600: 0.775667\n",
      "2022-11-08 10:15:28,433 INFO     Training average positive_sample_loss at step 128700: 1.071961\n",
      "2022-11-08 10:15:28,433 INFO     Training average negative_sample_loss at step 128700: 0.476647\n",
      "2022-11-08 10:15:28,433 INFO     Training average loss at step 128700: 0.774304\n",
      "2022-11-08 10:15:35,123 INFO     Training average positive_sample_loss at step 128800: 1.067164\n",
      "2022-11-08 10:15:35,123 INFO     Training average negative_sample_loss at step 128800: 0.475283\n",
      "2022-11-08 10:15:35,124 INFO     Training average loss at step 128800: 0.771223\n",
      "2022-11-08 10:15:41,533 INFO     Training average positive_sample_loss at step 128900: 1.074078\n",
      "2022-11-08 10:15:41,533 INFO     Training average negative_sample_loss at step 128900: 0.480086\n",
      "2022-11-08 10:15:41,533 INFO     Training average loss at step 128900: 0.777082\n",
      "2022-11-08 10:15:47,964 INFO     Training average positive_sample_loss at step 129000: 1.089505\n",
      "2022-11-08 10:15:47,964 INFO     Training average negative_sample_loss at step 129000: 0.480169\n",
      "2022-11-08 10:15:47,965 INFO     Training average loss at step 129000: 0.784837\n",
      "2022-11-08 10:15:54,397 INFO     Training average positive_sample_loss at step 129100: 1.014623\n",
      "2022-11-08 10:15:54,397 INFO     Training average negative_sample_loss at step 129100: 0.475940\n",
      "2022-11-08 10:15:54,397 INFO     Training average loss at step 129100: 0.745281\n",
      "2022-11-08 10:16:00,804 INFO     Training average positive_sample_loss at step 129200: 1.083360\n",
      "2022-11-08 10:16:00,804 INFO     Training average negative_sample_loss at step 129200: 0.467188\n",
      "2022-11-08 10:16:00,804 INFO     Training average loss at step 129200: 0.775274\n",
      "2022-11-08 10:16:07,220 INFO     Training average positive_sample_loss at step 129300: 1.068912\n",
      "2022-11-08 10:16:07,220 INFO     Training average negative_sample_loss at step 129300: 0.472712\n",
      "2022-11-08 10:16:07,220 INFO     Training average loss at step 129300: 0.770812\n",
      "2022-11-08 10:16:13,670 INFO     Training average positive_sample_loss at step 129400: 1.074667\n",
      "2022-11-08 10:16:13,670 INFO     Training average negative_sample_loss at step 129400: 0.473279\n",
      "2022-11-08 10:16:13,670 INFO     Training average loss at step 129400: 0.773973\n",
      "2022-11-08 10:16:20,176 INFO     Training average positive_sample_loss at step 129500: 1.034007\n",
      "2022-11-08 10:16:20,176 INFO     Training average negative_sample_loss at step 129500: 0.474813\n",
      "2022-11-08 10:16:20,176 INFO     Training average loss at step 129500: 0.754410\n",
      "2022-11-08 10:16:26,658 INFO     Training average positive_sample_loss at step 129600: 1.070604\n",
      "2022-11-08 10:16:26,658 INFO     Training average negative_sample_loss at step 129600: 0.469906\n",
      "2022-11-08 10:16:26,658 INFO     Training average loss at step 129600: 0.770255\n",
      "2022-11-08 10:16:33,084 INFO     Training average positive_sample_loss at step 129700: 1.038951\n",
      "2022-11-08 10:16:33,084 INFO     Training average negative_sample_loss at step 129700: 0.468377\n",
      "2022-11-08 10:16:33,084 INFO     Training average loss at step 129700: 0.753664\n",
      "2022-11-08 10:16:39,514 INFO     Training average positive_sample_loss at step 129800: 1.054065\n",
      "2022-11-08 10:16:39,514 INFO     Training average negative_sample_loss at step 129800: 0.479571\n",
      "2022-11-08 10:16:39,514 INFO     Training average loss at step 129800: 0.766818\n",
      "2022-11-08 10:16:45,978 INFO     Training average positive_sample_loss at step 129900: 1.061436\n",
      "2022-11-08 10:16:45,978 INFO     Training average negative_sample_loss at step 129900: 0.475119\n",
      "2022-11-08 10:16:45,978 INFO     Training average loss at step 129900: 0.768278\n",
      "2022-11-08 10:16:55,204 INFO     Training average positive_sample_loss at step 130000: 1.045865\n",
      "2022-11-08 10:16:55,204 INFO     Training average negative_sample_loss at step 130000: 0.475099\n",
      "2022-11-08 10:16:55,204 INFO     Training average loss at step 130000: 0.760482\n",
      "2022-11-08 10:17:01,648 INFO     Training average positive_sample_loss at step 130100: 1.015503\n",
      "2022-11-08 10:17:01,648 INFO     Training average negative_sample_loss at step 130100: 0.467937\n",
      "2022-11-08 10:17:01,648 INFO     Training average loss at step 130100: 0.741720\n",
      "2022-11-08 10:17:08,052 INFO     Training average positive_sample_loss at step 130200: 1.100359\n",
      "2022-11-08 10:17:08,052 INFO     Training average negative_sample_loss at step 130200: 0.470412\n",
      "2022-11-08 10:17:08,052 INFO     Training average loss at step 130200: 0.785385\n",
      "2022-11-08 10:17:14,463 INFO     Training average positive_sample_loss at step 130300: 1.052986\n",
      "2022-11-08 10:17:14,463 INFO     Training average negative_sample_loss at step 130300: 0.475693\n",
      "2022-11-08 10:17:14,463 INFO     Training average loss at step 130300: 0.764339\n",
      "2022-11-08 10:17:20,903 INFO     Training average positive_sample_loss at step 130400: 1.051682\n",
      "2022-11-08 10:17:20,903 INFO     Training average negative_sample_loss at step 130400: 0.478297\n",
      "2022-11-08 10:17:20,903 INFO     Training average loss at step 130400: 0.764990\n",
      "2022-11-08 10:17:27,383 INFO     Training average positive_sample_loss at step 130500: 1.067687\n",
      "2022-11-08 10:17:27,383 INFO     Training average negative_sample_loss at step 130500: 0.470720\n",
      "2022-11-08 10:17:27,383 INFO     Training average loss at step 130500: 0.769203\n",
      "2022-11-08 10:17:33,897 INFO     Training average positive_sample_loss at step 130600: 1.040557\n",
      "2022-11-08 10:17:33,897 INFO     Training average negative_sample_loss at step 130600: 0.476128\n",
      "2022-11-08 10:17:33,897 INFO     Training average loss at step 130600: 0.758343\n",
      "2022-11-08 10:17:40,418 INFO     Training average positive_sample_loss at step 130700: 1.086064\n",
      "2022-11-08 10:17:40,418 INFO     Training average negative_sample_loss at step 130700: 0.469911\n",
      "2022-11-08 10:17:40,418 INFO     Training average loss at step 130700: 0.777987\n",
      "2022-11-08 10:17:47,083 INFO     Training average positive_sample_loss at step 130800: 1.076068\n",
      "2022-11-08 10:17:47,083 INFO     Training average negative_sample_loss at step 130800: 0.473098\n",
      "2022-11-08 10:17:47,084 INFO     Training average loss at step 130800: 0.774583\n",
      "2022-11-08 10:17:53,630 INFO     Training average positive_sample_loss at step 130900: 1.017469\n",
      "2022-11-08 10:17:53,631 INFO     Training average negative_sample_loss at step 130900: 0.466040\n",
      "2022-11-08 10:17:53,631 INFO     Training average loss at step 130900: 0.741754\n",
      "2022-11-08 10:18:00,190 INFO     Training average positive_sample_loss at step 131000: 1.032004\n",
      "2022-11-08 10:18:00,190 INFO     Training average negative_sample_loss at step 131000: 0.473781\n",
      "2022-11-08 10:18:00,190 INFO     Training average loss at step 131000: 0.752893\n",
      "2022-11-08 10:18:06,670 INFO     Training average positive_sample_loss at step 131100: 1.023434\n",
      "2022-11-08 10:18:06,670 INFO     Training average negative_sample_loss at step 131100: 0.475432\n",
      "2022-11-08 10:18:06,670 INFO     Training average loss at step 131100: 0.749433\n",
      "2022-11-08 10:18:13,165 INFO     Training average positive_sample_loss at step 131200: 1.062384\n",
      "2022-11-08 10:18:13,165 INFO     Training average negative_sample_loss at step 131200: 0.464595\n",
      "2022-11-08 10:18:13,165 INFO     Training average loss at step 131200: 0.763489\n",
      "2022-11-08 10:18:21,391 INFO     Training average positive_sample_loss at step 131300: 1.058355\n",
      "2022-11-08 10:18:21,391 INFO     Training average negative_sample_loss at step 131300: 0.467115\n",
      "2022-11-08 10:18:21,391 INFO     Training average loss at step 131300: 0.762735\n",
      "2022-11-08 10:18:29,097 INFO     Training average positive_sample_loss at step 131400: 1.048954\n",
      "2022-11-08 10:18:29,097 INFO     Training average negative_sample_loss at step 131400: 0.472183\n",
      "2022-11-08 10:18:29,097 INFO     Training average loss at step 131400: 0.760568\n",
      "2022-11-08 10:18:37,020 INFO     Training average positive_sample_loss at step 131500: 1.036244\n",
      "2022-11-08 10:18:37,020 INFO     Training average negative_sample_loss at step 131500: 0.469811\n",
      "2022-11-08 10:18:37,020 INFO     Training average loss at step 131500: 0.753028\n",
      "2022-11-08 10:18:43,483 INFO     Training average positive_sample_loss at step 131600: 1.004845\n",
      "2022-11-08 10:18:43,483 INFO     Training average negative_sample_loss at step 131600: 0.476924\n",
      "2022-11-08 10:18:43,483 INFO     Training average loss at step 131600: 0.740885\n",
      "2022-11-08 10:18:49,970 INFO     Training average positive_sample_loss at step 131700: 1.015295\n",
      "2022-11-08 10:18:49,971 INFO     Training average negative_sample_loss at step 131700: 0.473680\n",
      "2022-11-08 10:18:49,971 INFO     Training average loss at step 131700: 0.744488\n",
      "2022-11-08 10:18:56,515 INFO     Training average positive_sample_loss at step 131800: 1.043701\n",
      "2022-11-08 10:18:56,515 INFO     Training average negative_sample_loss at step 131800: 0.468786\n",
      "2022-11-08 10:18:56,515 INFO     Training average loss at step 131800: 0.756244\n",
      "2022-11-08 10:19:02,949 INFO     Training average positive_sample_loss at step 131900: 1.075593\n",
      "2022-11-08 10:19:02,949 INFO     Training average negative_sample_loss at step 131900: 0.474935\n",
      "2022-11-08 10:19:02,949 INFO     Training average loss at step 131900: 0.775264\n",
      "2022-11-08 10:19:09,521 INFO     Training average positive_sample_loss at step 132000: 1.020631\n",
      "2022-11-08 10:19:09,522 INFO     Training average negative_sample_loss at step 132000: 0.467884\n",
      "2022-11-08 10:19:09,522 INFO     Training average loss at step 132000: 0.744258\n",
      "2022-11-08 10:19:16,018 INFO     Training average positive_sample_loss at step 132100: 1.020992\n",
      "2022-11-08 10:19:16,018 INFO     Training average negative_sample_loss at step 132100: 0.480640\n",
      "2022-11-08 10:19:16,018 INFO     Training average loss at step 132100: 0.750816\n",
      "2022-11-08 10:19:21,259 INFO     Training average positive_sample_loss at step 132200: 1.061084\n",
      "2022-11-08 10:19:21,259 INFO     Training average negative_sample_loss at step 132200: 0.472267\n",
      "2022-11-08 10:19:21,259 INFO     Training average loss at step 132200: 0.766675\n",
      "2022-11-08 10:19:27,781 INFO     Training average positive_sample_loss at step 132300: 1.002527\n",
      "2022-11-08 10:19:27,781 INFO     Training average negative_sample_loss at step 132300: 0.469146\n",
      "2022-11-08 10:19:27,782 INFO     Training average loss at step 132300: 0.735836\n",
      "2022-11-08 10:19:34,213 INFO     Training average positive_sample_loss at step 132400: 1.057143\n",
      "2022-11-08 10:19:34,213 INFO     Training average negative_sample_loss at step 132400: 0.470667\n",
      "2022-11-08 10:19:34,213 INFO     Training average loss at step 132400: 0.763905\n",
      "2022-11-08 10:19:40,637 INFO     Training average positive_sample_loss at step 132500: 1.039736\n",
      "2022-11-08 10:19:40,637 INFO     Training average negative_sample_loss at step 132500: 0.467112\n",
      "2022-11-08 10:19:40,637 INFO     Training average loss at step 132500: 0.753424\n",
      "2022-11-08 10:19:47,031 INFO     Training average positive_sample_loss at step 132600: 1.006509\n",
      "2022-11-08 10:19:47,031 INFO     Training average negative_sample_loss at step 132600: 0.470262\n",
      "2022-11-08 10:19:47,031 INFO     Training average loss at step 132600: 0.738386\n",
      "2022-11-08 10:19:53,475 INFO     Training average positive_sample_loss at step 132700: 1.004490\n",
      "2022-11-08 10:19:53,475 INFO     Training average negative_sample_loss at step 132700: 0.466661\n",
      "2022-11-08 10:19:53,475 INFO     Training average loss at step 132700: 0.735576\n",
      "2022-11-08 10:19:59,899 INFO     Training average positive_sample_loss at step 132800: 1.045022\n",
      "2022-11-08 10:19:59,899 INFO     Training average negative_sample_loss at step 132800: 0.466416\n",
      "2022-11-08 10:19:59,899 INFO     Training average loss at step 132800: 0.755719\n",
      "2022-11-08 10:20:06,353 INFO     Training average positive_sample_loss at step 132900: 1.063603\n",
      "2022-11-08 10:20:06,353 INFO     Training average negative_sample_loss at step 132900: 0.469085\n",
      "2022-11-08 10:20:06,353 INFO     Training average loss at step 132900: 0.766344\n",
      "2022-11-08 10:20:12,844 INFO     Training average positive_sample_loss at step 133000: 1.062467\n",
      "2022-11-08 10:20:12,844 INFO     Training average negative_sample_loss at step 133000: 0.470598\n",
      "2022-11-08 10:20:12,844 INFO     Training average loss at step 133000: 0.766533\n",
      "2022-11-08 10:20:19,359 INFO     Training average positive_sample_loss at step 133100: 0.997092\n",
      "2022-11-08 10:20:19,359 INFO     Training average negative_sample_loss at step 133100: 0.461477\n",
      "2022-11-08 10:20:19,359 INFO     Training average loss at step 133100: 0.729284\n",
      "2022-11-08 10:20:25,868 INFO     Training average positive_sample_loss at step 133200: 0.995367\n",
      "2022-11-08 10:20:25,868 INFO     Training average negative_sample_loss at step 133200: 0.466525\n",
      "2022-11-08 10:20:25,868 INFO     Training average loss at step 133200: 0.730946\n",
      "2022-11-08 10:20:32,354 INFO     Training average positive_sample_loss at step 133300: 1.042776\n",
      "2022-11-08 10:20:32,354 INFO     Training average negative_sample_loss at step 133300: 0.461694\n",
      "2022-11-08 10:20:32,354 INFO     Training average loss at step 133300: 0.752235\n",
      "2022-11-08 10:20:38,871 INFO     Training average positive_sample_loss at step 133400: 1.021372\n",
      "2022-11-08 10:20:38,871 INFO     Training average negative_sample_loss at step 133400: 0.472163\n",
      "2022-11-08 10:20:38,871 INFO     Training average loss at step 133400: 0.746767\n",
      "2022-11-08 10:20:45,339 INFO     Training average positive_sample_loss at step 133500: 1.039522\n",
      "2022-11-08 10:20:45,339 INFO     Training average negative_sample_loss at step 133500: 0.470370\n",
      "2022-11-08 10:20:45,339 INFO     Training average loss at step 133500: 0.754946\n",
      "2022-11-08 10:20:51,797 INFO     Training average positive_sample_loss at step 133600: 1.015151\n",
      "2022-11-08 10:20:51,798 INFO     Training average negative_sample_loss at step 133600: 0.468588\n",
      "2022-11-08 10:20:51,798 INFO     Training average loss at step 133600: 0.741869\n",
      "2022-11-08 10:20:58,258 INFO     Training average positive_sample_loss at step 133700: 1.033012\n",
      "2022-11-08 10:20:58,258 INFO     Training average negative_sample_loss at step 133700: 0.462988\n",
      "2022-11-08 10:20:58,258 INFO     Training average loss at step 133700: 0.748000\n",
      "2022-11-08 10:21:04,697 INFO     Training average positive_sample_loss at step 133800: 1.020162\n",
      "2022-11-08 10:21:04,697 INFO     Training average negative_sample_loss at step 133800: 0.463925\n",
      "2022-11-08 10:21:04,697 INFO     Training average loss at step 133800: 0.742044\n",
      "2022-11-08 10:21:11,140 INFO     Training average positive_sample_loss at step 133900: 1.084203\n",
      "2022-11-08 10:21:11,140 INFO     Training average negative_sample_loss at step 133900: 0.462067\n",
      "2022-11-08 10:21:11,140 INFO     Training average loss at step 133900: 0.773135\n",
      "2022-11-08 10:21:17,634 INFO     Training average positive_sample_loss at step 134000: 1.036624\n",
      "2022-11-08 10:21:17,634 INFO     Training average negative_sample_loss at step 134000: 0.459111\n",
      "2022-11-08 10:21:17,634 INFO     Training average loss at step 134000: 0.747868\n",
      "2022-11-08 10:21:24,135 INFO     Training average positive_sample_loss at step 134100: 1.034221\n",
      "2022-11-08 10:21:24,135 INFO     Training average negative_sample_loss at step 134100: 0.459415\n",
      "2022-11-08 10:21:24,135 INFO     Training average loss at step 134100: 0.746818\n",
      "2022-11-08 10:21:30,662 INFO     Training average positive_sample_loss at step 134200: 0.999612\n",
      "2022-11-08 10:21:30,662 INFO     Training average negative_sample_loss at step 134200: 0.459773\n",
      "2022-11-08 10:21:30,662 INFO     Training average loss at step 134200: 0.729693\n",
      "2022-11-08 10:21:37,243 INFO     Training average positive_sample_loss at step 134300: 1.028224\n",
      "2022-11-08 10:21:37,243 INFO     Training average negative_sample_loss at step 134300: 0.462663\n",
      "2022-11-08 10:21:37,243 INFO     Training average loss at step 134300: 0.745444\n",
      "2022-11-08 10:21:43,735 INFO     Training average positive_sample_loss at step 134400: 1.082595\n",
      "2022-11-08 10:21:43,736 INFO     Training average negative_sample_loss at step 134400: 0.456784\n",
      "2022-11-08 10:21:43,736 INFO     Training average loss at step 134400: 0.769690\n",
      "2022-11-08 10:21:50,188 INFO     Training average positive_sample_loss at step 134500: 1.018378\n",
      "2022-11-08 10:21:50,188 INFO     Training average negative_sample_loss at step 134500: 0.467487\n",
      "2022-11-08 10:21:50,188 INFO     Training average loss at step 134500: 0.742933\n",
      "2022-11-08 10:21:56,658 INFO     Training average positive_sample_loss at step 134600: 1.019054\n",
      "2022-11-08 10:21:56,658 INFO     Training average negative_sample_loss at step 134600: 0.464484\n",
      "2022-11-08 10:21:56,658 INFO     Training average loss at step 134600: 0.741769\n",
      "2022-11-08 10:22:03,214 INFO     Training average positive_sample_loss at step 134700: 1.024933\n",
      "2022-11-08 10:22:03,214 INFO     Training average negative_sample_loss at step 134700: 0.466618\n",
      "2022-11-08 10:22:03,214 INFO     Training average loss at step 134700: 0.745776\n",
      "2022-11-08 10:22:09,643 INFO     Training average positive_sample_loss at step 134800: 1.025792\n",
      "2022-11-08 10:22:09,644 INFO     Training average negative_sample_loss at step 134800: 0.461396\n",
      "2022-11-08 10:22:09,644 INFO     Training average loss at step 134800: 0.743594\n",
      "2022-11-08 10:22:16,138 INFO     Training average positive_sample_loss at step 134900: 1.012016\n",
      "2022-11-08 10:22:16,138 INFO     Training average negative_sample_loss at step 134900: 0.465061\n",
      "2022-11-08 10:22:16,138 INFO     Training average loss at step 134900: 0.738538\n",
      "2022-11-08 10:22:22,738 INFO     Training average positive_sample_loss at step 135000: 1.008822\n",
      "2022-11-08 10:22:22,738 INFO     Training average negative_sample_loss at step 135000: 0.464798\n",
      "2022-11-08 10:22:22,738 INFO     Training average loss at step 135000: 0.736810\n",
      "2022-11-08 10:22:29,144 INFO     Training average positive_sample_loss at step 135100: 1.021687\n",
      "2022-11-08 10:22:29,144 INFO     Training average negative_sample_loss at step 135100: 0.453122\n",
      "2022-11-08 10:22:29,144 INFO     Training average loss at step 135100: 0.737404\n",
      "2022-11-08 10:22:35,589 INFO     Training average positive_sample_loss at step 135200: 0.984946\n",
      "2022-11-08 10:22:35,589 INFO     Training average negative_sample_loss at step 135200: 0.468426\n",
      "2022-11-08 10:22:35,589 INFO     Training average loss at step 135200: 0.726686\n",
      "2022-11-08 10:22:42,109 INFO     Training average positive_sample_loss at step 135300: 1.029560\n",
      "2022-11-08 10:22:42,109 INFO     Training average negative_sample_loss at step 135300: 0.465344\n",
      "2022-11-08 10:22:42,109 INFO     Training average loss at step 135300: 0.747452\n",
      "2022-11-08 10:22:48,636 INFO     Training average positive_sample_loss at step 135400: 1.013658\n",
      "2022-11-08 10:22:48,636 INFO     Training average negative_sample_loss at step 135400: 0.458047\n",
      "2022-11-08 10:22:48,636 INFO     Training average loss at step 135400: 0.735853\n",
      "2022-11-08 10:22:55,183 INFO     Training average positive_sample_loss at step 135500: 1.050827\n",
      "2022-11-08 10:22:55,183 INFO     Training average negative_sample_loss at step 135500: 0.461521\n",
      "2022-11-08 10:22:55,183 INFO     Training average loss at step 135500: 0.756174\n",
      "2022-11-08 10:23:01,685 INFO     Training average positive_sample_loss at step 135600: 1.029800\n",
      "2022-11-08 10:23:01,685 INFO     Training average negative_sample_loss at step 135600: 0.459262\n",
      "2022-11-08 10:23:01,685 INFO     Training average loss at step 135600: 0.744531\n",
      "2022-11-08 10:23:08,207 INFO     Training average positive_sample_loss at step 135700: 0.995734\n",
      "2022-11-08 10:23:08,207 INFO     Training average negative_sample_loss at step 135700: 0.460265\n",
      "2022-11-08 10:23:08,207 INFO     Training average loss at step 135700: 0.727999\n",
      "2022-11-08 10:23:14,751 INFO     Training average positive_sample_loss at step 135800: 1.024216\n",
      "2022-11-08 10:23:14,752 INFO     Training average negative_sample_loss at step 135800: 0.462370\n",
      "2022-11-08 10:23:14,752 INFO     Training average loss at step 135800: 0.743293\n",
      "2022-11-08 10:23:21,211 INFO     Training average positive_sample_loss at step 135900: 1.016445\n",
      "2022-11-08 10:23:21,211 INFO     Training average negative_sample_loss at step 135900: 0.464182\n",
      "2022-11-08 10:23:21,211 INFO     Training average loss at step 135900: 0.740313\n",
      "2022-11-08 10:23:29,389 INFO     Training average positive_sample_loss at step 136000: 1.038558\n",
      "2022-11-08 10:23:29,389 INFO     Training average negative_sample_loss at step 136000: 0.456960\n",
      "2022-11-08 10:23:29,389 INFO     Training average loss at step 136000: 0.747759\n",
      "2022-11-08 10:23:36,432 INFO     Training average positive_sample_loss at step 136100: 1.056825\n",
      "2022-11-08 10:23:36,432 INFO     Training average negative_sample_loss at step 136100: 0.456870\n",
      "2022-11-08 10:23:36,432 INFO     Training average loss at step 136100: 0.756848\n",
      "2022-11-08 10:23:43,849 INFO     Training average positive_sample_loss at step 136200: 1.015099\n",
      "2022-11-08 10:23:43,850 INFO     Training average negative_sample_loss at step 136200: 0.456994\n",
      "2022-11-08 10:23:43,850 INFO     Training average loss at step 136200: 0.736046\n",
      "2022-11-08 10:23:50,266 INFO     Training average positive_sample_loss at step 136300: 1.029897\n",
      "2022-11-08 10:23:50,266 INFO     Training average negative_sample_loss at step 136300: 0.458239\n",
      "2022-11-08 10:23:50,266 INFO     Training average loss at step 136300: 0.744068\n",
      "2022-11-08 10:23:56,710 INFO     Training average positive_sample_loss at step 136400: 0.997561\n",
      "2022-11-08 10:23:56,710 INFO     Training average negative_sample_loss at step 136400: 0.453065\n",
      "2022-11-08 10:23:56,710 INFO     Training average loss at step 136400: 0.725313\n",
      "2022-11-08 10:24:03,197 INFO     Training average positive_sample_loss at step 136500: 1.061759\n",
      "2022-11-08 10:24:03,197 INFO     Training average negative_sample_loss at step 136500: 0.461873\n",
      "2022-11-08 10:24:03,197 INFO     Training average loss at step 136500: 0.761816\n",
      "2022-11-08 10:24:09,718 INFO     Training average positive_sample_loss at step 136600: 0.990294\n",
      "2022-11-08 10:24:09,718 INFO     Training average negative_sample_loss at step 136600: 0.454322\n",
      "2022-11-08 10:24:09,718 INFO     Training average loss at step 136600: 0.722308\n",
      "2022-11-08 10:24:16,148 INFO     Training average positive_sample_loss at step 136700: 0.994456\n",
      "2022-11-08 10:24:16,148 INFO     Training average negative_sample_loss at step 136700: 0.469300\n",
      "2022-11-08 10:24:16,148 INFO     Training average loss at step 136700: 0.731878\n",
      "2022-11-08 10:24:22,554 INFO     Training average positive_sample_loss at step 136800: 1.013685\n",
      "2022-11-08 10:24:22,554 INFO     Training average negative_sample_loss at step 136800: 0.456264\n",
      "2022-11-08 10:24:22,554 INFO     Training average loss at step 136800: 0.734975\n",
      "2022-11-08 10:24:29,035 INFO     Training average positive_sample_loss at step 136900: 1.062867\n",
      "2022-11-08 10:24:29,035 INFO     Training average negative_sample_loss at step 136900: 0.453966\n",
      "2022-11-08 10:24:29,035 INFO     Training average loss at step 136900: 0.758416\n",
      "2022-11-08 10:24:35,484 INFO     Training average positive_sample_loss at step 137000: 0.986301\n",
      "2022-11-08 10:24:35,484 INFO     Training average negative_sample_loss at step 137000: 0.462077\n",
      "2022-11-08 10:24:35,484 INFO     Training average loss at step 137000: 0.724189\n",
      "2022-11-08 10:24:41,909 INFO     Training average positive_sample_loss at step 137100: 0.999790\n",
      "2022-11-08 10:24:41,909 INFO     Training average negative_sample_loss at step 137100: 0.457243\n",
      "2022-11-08 10:24:41,909 INFO     Training average loss at step 137100: 0.728517\n",
      "2022-11-08 10:24:48,333 INFO     Training average positive_sample_loss at step 137200: 1.004214\n",
      "2022-11-08 10:24:48,333 INFO     Training average negative_sample_loss at step 137200: 0.459349\n",
      "2022-11-08 10:24:48,333 INFO     Training average loss at step 137200: 0.731782\n",
      "2022-11-08 10:24:54,905 INFO     Training average positive_sample_loss at step 137300: 1.021907\n",
      "2022-11-08 10:24:54,905 INFO     Training average negative_sample_loss at step 137300: 0.457926\n",
      "2022-11-08 10:24:54,905 INFO     Training average loss at step 137300: 0.739917\n",
      "2022-11-08 10:25:01,361 INFO     Training average positive_sample_loss at step 137400: 1.067221\n",
      "2022-11-08 10:25:01,362 INFO     Training average negative_sample_loss at step 137400: 0.456189\n",
      "2022-11-08 10:25:01,362 INFO     Training average loss at step 137400: 0.761705\n",
      "2022-11-08 10:25:07,783 INFO     Training average positive_sample_loss at step 137500: 1.029046\n",
      "2022-11-08 10:25:07,783 INFO     Training average negative_sample_loss at step 137500: 0.456063\n",
      "2022-11-08 10:25:07,784 INFO     Training average loss at step 137500: 0.742555\n",
      "2022-11-08 10:25:14,191 INFO     Training average positive_sample_loss at step 137600: 1.011114\n",
      "2022-11-08 10:25:14,191 INFO     Training average negative_sample_loss at step 137600: 0.452457\n",
      "2022-11-08 10:25:14,191 INFO     Training average loss at step 137600: 0.731786\n",
      "2022-11-08 10:25:20,622 INFO     Training average positive_sample_loss at step 137700: 1.027038\n",
      "2022-11-08 10:25:20,622 INFO     Training average negative_sample_loss at step 137700: 0.459984\n",
      "2022-11-08 10:25:20,622 INFO     Training average loss at step 137700: 0.743511\n",
      "2022-11-08 10:25:25,715 INFO     Training average positive_sample_loss at step 137800: 0.987105\n",
      "2022-11-08 10:25:25,716 INFO     Training average negative_sample_loss at step 137800: 0.455026\n",
      "2022-11-08 10:25:25,716 INFO     Training average loss at step 137800: 0.721066\n",
      "2022-11-08 10:25:32,180 INFO     Training average positive_sample_loss at step 137900: 1.010084\n",
      "2022-11-08 10:25:32,180 INFO     Training average negative_sample_loss at step 137900: 0.458152\n",
      "2022-11-08 10:25:32,180 INFO     Training average loss at step 137900: 0.734118\n",
      "2022-11-08 10:25:38,602 INFO     Training average positive_sample_loss at step 138000: 0.987560\n",
      "2022-11-08 10:25:38,602 INFO     Training average negative_sample_loss at step 138000: 0.459754\n",
      "2022-11-08 10:25:38,602 INFO     Training average loss at step 138000: 0.723657\n",
      "2022-11-08 10:25:45,014 INFO     Training average positive_sample_loss at step 138100: 1.038881\n",
      "2022-11-08 10:25:45,014 INFO     Training average negative_sample_loss at step 138100: 0.449647\n",
      "2022-11-08 10:25:45,014 INFO     Training average loss at step 138100: 0.744264\n",
      "2022-11-08 10:25:51,413 INFO     Training average positive_sample_loss at step 138200: 0.989998\n",
      "2022-11-08 10:25:51,413 INFO     Training average negative_sample_loss at step 138200: 0.456608\n",
      "2022-11-08 10:25:51,413 INFO     Training average loss at step 138200: 0.723303\n",
      "2022-11-08 10:25:57,842 INFO     Training average positive_sample_loss at step 138300: 1.011846\n",
      "2022-11-08 10:25:57,842 INFO     Training average negative_sample_loss at step 138300: 0.459424\n",
      "2022-11-08 10:25:57,842 INFO     Training average loss at step 138300: 0.735635\n",
      "2022-11-08 10:26:04,262 INFO     Training average positive_sample_loss at step 138400: 0.984866\n",
      "2022-11-08 10:26:04,262 INFO     Training average negative_sample_loss at step 138400: 0.459175\n",
      "2022-11-08 10:26:04,262 INFO     Training average loss at step 138400: 0.722021\n",
      "2022-11-08 10:26:10,700 INFO     Training average positive_sample_loss at step 138500: 1.033070\n",
      "2022-11-08 10:26:10,700 INFO     Training average negative_sample_loss at step 138500: 0.452709\n",
      "2022-11-08 10:26:10,700 INFO     Training average loss at step 138500: 0.742889\n",
      "2022-11-08 10:26:17,144 INFO     Training average positive_sample_loss at step 138600: 1.069291\n",
      "2022-11-08 10:26:17,144 INFO     Training average negative_sample_loss at step 138600: 0.449255\n",
      "2022-11-08 10:26:17,144 INFO     Training average loss at step 138600: 0.759273\n",
      "2022-11-08 10:26:23,574 INFO     Training average positive_sample_loss at step 138700: 1.003758\n",
      "2022-11-08 10:26:23,574 INFO     Training average negative_sample_loss at step 138700: 0.455238\n",
      "2022-11-08 10:26:23,574 INFO     Training average loss at step 138700: 0.729498\n",
      "2022-11-08 10:26:30,005 INFO     Training average positive_sample_loss at step 138800: 1.026913\n",
      "2022-11-08 10:26:30,006 INFO     Training average negative_sample_loss at step 138800: 0.450264\n",
      "2022-11-08 10:26:30,006 INFO     Training average loss at step 138800: 0.738589\n",
      "2022-11-08 10:26:36,409 INFO     Training average positive_sample_loss at step 138900: 1.013319\n",
      "2022-11-08 10:26:36,409 INFO     Training average negative_sample_loss at step 138900: 0.457233\n",
      "2022-11-08 10:26:36,409 INFO     Training average loss at step 138900: 0.735276\n",
      "2022-11-08 10:26:42,815 INFO     Training average positive_sample_loss at step 139000: 1.020467\n",
      "2022-11-08 10:26:42,815 INFO     Training average negative_sample_loss at step 139000: 0.446547\n",
      "2022-11-08 10:26:42,815 INFO     Training average loss at step 139000: 0.733507\n",
      "2022-11-08 10:26:49,242 INFO     Training average positive_sample_loss at step 139100: 1.025826\n",
      "2022-11-08 10:26:49,242 INFO     Training average negative_sample_loss at step 139100: 0.453798\n",
      "2022-11-08 10:26:49,242 INFO     Training average loss at step 139100: 0.739812\n",
      "2022-11-08 10:26:55,652 INFO     Training average positive_sample_loss at step 139200: 1.044729\n",
      "2022-11-08 10:26:55,652 INFO     Training average negative_sample_loss at step 139200: 0.451745\n",
      "2022-11-08 10:26:55,652 INFO     Training average loss at step 139200: 0.748237\n",
      "2022-11-08 10:27:02,073 INFO     Training average positive_sample_loss at step 139300: 0.982753\n",
      "2022-11-08 10:27:02,073 INFO     Training average negative_sample_loss at step 139300: 0.458236\n",
      "2022-11-08 10:27:02,073 INFO     Training average loss at step 139300: 0.720495\n",
      "2022-11-08 10:27:08,484 INFO     Training average positive_sample_loss at step 139400: 0.987338\n",
      "2022-11-08 10:27:08,485 INFO     Training average negative_sample_loss at step 139400: 0.453846\n",
      "2022-11-08 10:27:08,485 INFO     Training average loss at step 139400: 0.720592\n",
      "2022-11-08 10:27:14,894 INFO     Training average positive_sample_loss at step 139500: 1.012587\n",
      "2022-11-08 10:27:14,894 INFO     Training average negative_sample_loss at step 139500: 0.450402\n",
      "2022-11-08 10:27:14,894 INFO     Training average loss at step 139500: 0.731495\n",
      "2022-11-08 10:27:21,298 INFO     Training average positive_sample_loss at step 139600: 1.012062\n",
      "2022-11-08 10:27:21,298 INFO     Training average negative_sample_loss at step 139600: 0.456202\n",
      "2022-11-08 10:27:21,298 INFO     Training average loss at step 139600: 0.734132\n",
      "2022-11-08 10:27:27,723 INFO     Training average positive_sample_loss at step 139700: 1.014410\n",
      "2022-11-08 10:27:27,723 INFO     Training average negative_sample_loss at step 139700: 0.455810\n",
      "2022-11-08 10:27:27,724 INFO     Training average loss at step 139700: 0.735110\n",
      "2022-11-08 10:27:34,145 INFO     Training average positive_sample_loss at step 139800: 1.017089\n",
      "2022-11-08 10:27:34,145 INFO     Training average negative_sample_loss at step 139800: 0.458743\n",
      "2022-11-08 10:27:34,145 INFO     Training average loss at step 139800: 0.737916\n",
      "2022-11-08 10:27:40,539 INFO     Training average positive_sample_loss at step 139900: 0.992012\n",
      "2022-11-08 10:27:40,539 INFO     Training average negative_sample_loss at step 139900: 0.455253\n",
      "2022-11-08 10:27:40,539 INFO     Training average loss at step 139900: 0.723632\n",
      "2022-11-08 10:27:49,732 INFO     Training average positive_sample_loss at step 140000: 1.032681\n",
      "2022-11-08 10:27:49,732 INFO     Training average negative_sample_loss at step 140000: 0.443460\n",
      "2022-11-08 10:27:49,732 INFO     Training average loss at step 140000: 0.738070\n",
      "2022-11-08 10:27:56,136 INFO     Training average positive_sample_loss at step 140100: 1.008063\n",
      "2022-11-08 10:27:56,136 INFO     Training average negative_sample_loss at step 140100: 0.454221\n",
      "2022-11-08 10:27:56,136 INFO     Training average loss at step 140100: 0.731142\n",
      "2022-11-08 10:28:02,551 INFO     Training average positive_sample_loss at step 140200: 0.989071\n",
      "2022-11-08 10:28:02,551 INFO     Training average negative_sample_loss at step 140200: 0.448621\n",
      "2022-11-08 10:28:02,551 INFO     Training average loss at step 140200: 0.718846\n",
      "2022-11-08 10:28:08,960 INFO     Training average positive_sample_loss at step 140300: 1.016990\n",
      "2022-11-08 10:28:08,960 INFO     Training average negative_sample_loss at step 140300: 0.449222\n",
      "2022-11-08 10:28:08,960 INFO     Training average loss at step 140300: 0.733106\n",
      "2022-11-08 10:28:15,381 INFO     Training average positive_sample_loss at step 140400: 0.977852\n",
      "2022-11-08 10:28:15,381 INFO     Training average negative_sample_loss at step 140400: 0.450892\n",
      "2022-11-08 10:28:15,381 INFO     Training average loss at step 140400: 0.714372\n",
      "2022-11-08 10:28:21,814 INFO     Training average positive_sample_loss at step 140500: 1.002484\n",
      "2022-11-08 10:28:21,814 INFO     Training average negative_sample_loss at step 140500: 0.456309\n",
      "2022-11-08 10:28:21,814 INFO     Training average loss at step 140500: 0.729396\n",
      "2022-11-08 10:28:28,208 INFO     Training average positive_sample_loss at step 140600: 1.027253\n",
      "2022-11-08 10:28:28,209 INFO     Training average negative_sample_loss at step 140600: 0.453326\n",
      "2022-11-08 10:28:28,209 INFO     Training average loss at step 140600: 0.740289\n",
      "2022-11-08 10:28:36,208 INFO     Training average positive_sample_loss at step 140700: 1.036306\n",
      "2022-11-08 10:28:36,208 INFO     Training average negative_sample_loss at step 140700: 0.445595\n",
      "2022-11-08 10:28:36,208 INFO     Training average loss at step 140700: 0.740951\n",
      "2022-11-08 10:28:43,632 INFO     Training average positive_sample_loss at step 140800: 1.007129\n",
      "2022-11-08 10:28:43,632 INFO     Training average negative_sample_loss at step 140800: 0.444779\n",
      "2022-11-08 10:28:43,632 INFO     Training average loss at step 140800: 0.725954\n",
      "2022-11-08 10:28:50,581 INFO     Training average positive_sample_loss at step 140900: 1.011793\n",
      "2022-11-08 10:28:50,581 INFO     Training average negative_sample_loss at step 140900: 0.451919\n",
      "2022-11-08 10:28:50,581 INFO     Training average loss at step 140900: 0.731856\n",
      "2022-11-08 10:28:57,004 INFO     Training average positive_sample_loss at step 141000: 0.997132\n",
      "2022-11-08 10:28:57,004 INFO     Training average negative_sample_loss at step 141000: 0.446315\n",
      "2022-11-08 10:28:57,004 INFO     Training average loss at step 141000: 0.721724\n",
      "2022-11-08 10:29:03,443 INFO     Training average positive_sample_loss at step 141100: 1.027779\n",
      "2022-11-08 10:29:03,443 INFO     Training average negative_sample_loss at step 141100: 0.447648\n",
      "2022-11-08 10:29:03,443 INFO     Training average loss at step 141100: 0.737714\n",
      "2022-11-08 10:29:09,842 INFO     Training average positive_sample_loss at step 141200: 0.987107\n",
      "2022-11-08 10:29:09,842 INFO     Training average negative_sample_loss at step 141200: 0.452049\n",
      "2022-11-08 10:29:09,842 INFO     Training average loss at step 141200: 0.719578\n",
      "2022-11-08 10:29:16,281 INFO     Training average positive_sample_loss at step 141300: 0.993278\n",
      "2022-11-08 10:29:16,281 INFO     Training average negative_sample_loss at step 141300: 0.452723\n",
      "2022-11-08 10:29:16,281 INFO     Training average loss at step 141300: 0.723000\n",
      "2022-11-08 10:29:22,704 INFO     Training average positive_sample_loss at step 141400: 0.982545\n",
      "2022-11-08 10:29:22,704 INFO     Training average negative_sample_loss at step 141400: 0.444338\n",
      "2022-11-08 10:29:22,704 INFO     Training average loss at step 141400: 0.713442\n",
      "2022-11-08 10:29:29,201 INFO     Training average positive_sample_loss at step 141500: 0.950678\n",
      "2022-11-08 10:29:29,201 INFO     Training average negative_sample_loss at step 141500: 0.455744\n",
      "2022-11-08 10:29:29,202 INFO     Training average loss at step 141500: 0.703211\n",
      "2022-11-08 10:29:35,604 INFO     Training average positive_sample_loss at step 141600: 1.005323\n",
      "2022-11-08 10:29:35,604 INFO     Training average negative_sample_loss at step 141600: 0.447025\n",
      "2022-11-08 10:29:35,604 INFO     Training average loss at step 141600: 0.726174\n",
      "2022-11-08 10:29:42,045 INFO     Training average positive_sample_loss at step 141700: 0.993037\n",
      "2022-11-08 10:29:42,045 INFO     Training average negative_sample_loss at step 141700: 0.448373\n",
      "2022-11-08 10:29:42,045 INFO     Training average loss at step 141700: 0.720705\n",
      "2022-11-08 10:29:48,474 INFO     Training average positive_sample_loss at step 141800: 0.972381\n",
      "2022-11-08 10:29:48,474 INFO     Training average negative_sample_loss at step 141800: 0.453923\n",
      "2022-11-08 10:29:48,474 INFO     Training average loss at step 141800: 0.713152\n",
      "2022-11-08 10:29:54,883 INFO     Training average positive_sample_loss at step 141900: 1.013297\n",
      "2022-11-08 10:29:54,883 INFO     Training average negative_sample_loss at step 141900: 0.441110\n",
      "2022-11-08 10:29:54,883 INFO     Training average loss at step 141900: 0.727204\n",
      "2022-11-08 10:30:01,403 INFO     Training average positive_sample_loss at step 142000: 0.979456\n",
      "2022-11-08 10:30:01,403 INFO     Training average negative_sample_loss at step 142000: 0.443487\n",
      "2022-11-08 10:30:01,403 INFO     Training average loss at step 142000: 0.711472\n",
      "2022-11-08 10:30:07,864 INFO     Training average positive_sample_loss at step 142100: 0.976604\n",
      "2022-11-08 10:30:07,864 INFO     Training average negative_sample_loss at step 142100: 0.450912\n",
      "2022-11-08 10:30:07,864 INFO     Training average loss at step 142100: 0.713758\n",
      "2022-11-08 10:30:14,283 INFO     Training average positive_sample_loss at step 142200: 1.043425\n",
      "2022-11-08 10:30:14,283 INFO     Training average negative_sample_loss at step 142200: 0.444705\n",
      "2022-11-08 10:30:14,283 INFO     Training average loss at step 142200: 0.744065\n",
      "2022-11-08 10:30:20,709 INFO     Training average positive_sample_loss at step 142300: 0.949889\n",
      "2022-11-08 10:30:20,709 INFO     Training average negative_sample_loss at step 142300: 0.455372\n",
      "2022-11-08 10:30:20,709 INFO     Training average loss at step 142300: 0.702631\n",
      "2022-11-08 10:30:27,112 INFO     Training average positive_sample_loss at step 142400: 0.980575\n",
      "2022-11-08 10:30:27,112 INFO     Training average negative_sample_loss at step 142400: 0.448273\n",
      "2022-11-08 10:30:27,112 INFO     Training average loss at step 142400: 0.714424\n",
      "2022-11-08 10:30:33,654 INFO     Training average positive_sample_loss at step 142500: 0.977418\n",
      "2022-11-08 10:30:33,654 INFO     Training average negative_sample_loss at step 142500: 0.445075\n",
      "2022-11-08 10:30:33,654 INFO     Training average loss at step 142500: 0.711246\n",
      "2022-11-08 10:30:40,243 INFO     Training average positive_sample_loss at step 142600: 0.947762\n",
      "2022-11-08 10:30:40,244 INFO     Training average negative_sample_loss at step 142600: 0.449182\n",
      "2022-11-08 10:30:40,244 INFO     Training average loss at step 142600: 0.698472\n",
      "2022-11-08 10:30:46,995 INFO     Training average positive_sample_loss at step 142700: 0.990080\n",
      "2022-11-08 10:30:46,995 INFO     Training average negative_sample_loss at step 142700: 0.447149\n",
      "2022-11-08 10:30:46,995 INFO     Training average loss at step 142700: 0.718614\n",
      "2022-11-08 10:30:53,732 INFO     Training average positive_sample_loss at step 142800: 1.000749\n",
      "2022-11-08 10:30:53,732 INFO     Training average negative_sample_loss at step 142800: 0.442922\n",
      "2022-11-08 10:30:53,732 INFO     Training average loss at step 142800: 0.721835\n",
      "2022-11-08 10:31:00,455 INFO     Training average positive_sample_loss at step 142900: 0.988964\n",
      "2022-11-08 10:31:00,455 INFO     Training average negative_sample_loss at step 142900: 0.441914\n",
      "2022-11-08 10:31:00,455 INFO     Training average loss at step 142900: 0.715439\n",
      "2022-11-08 10:31:06,950 INFO     Training average positive_sample_loss at step 143000: 0.997231\n",
      "2022-11-08 10:31:06,950 INFO     Training average negative_sample_loss at step 143000: 0.441301\n",
      "2022-11-08 10:31:06,950 INFO     Training average loss at step 143000: 0.719266\n",
      "2022-11-08 10:31:13,414 INFO     Training average positive_sample_loss at step 143100: 0.966686\n",
      "2022-11-08 10:31:13,414 INFO     Training average negative_sample_loss at step 143100: 0.452278\n",
      "2022-11-08 10:31:13,414 INFO     Training average loss at step 143100: 0.709482\n",
      "2022-11-08 10:31:19,845 INFO     Training average positive_sample_loss at step 143200: 1.010662\n",
      "2022-11-08 10:31:19,846 INFO     Training average negative_sample_loss at step 143200: 0.448716\n",
      "2022-11-08 10:31:19,846 INFO     Training average loss at step 143200: 0.729689\n",
      "2022-11-08 10:31:25,034 INFO     Training average positive_sample_loss at step 143300: 0.967428\n",
      "2022-11-08 10:31:25,034 INFO     Training average negative_sample_loss at step 143300: 0.448187\n",
      "2022-11-08 10:31:25,034 INFO     Training average loss at step 143300: 0.707808\n",
      "2022-11-08 10:31:31,564 INFO     Training average positive_sample_loss at step 143400: 0.994803\n",
      "2022-11-08 10:31:31,564 INFO     Training average negative_sample_loss at step 143400: 0.444448\n",
      "2022-11-08 10:31:31,564 INFO     Training average loss at step 143400: 0.719626\n",
      "2022-11-08 10:31:37,983 INFO     Training average positive_sample_loss at step 143500: 0.949502\n",
      "2022-11-08 10:31:37,983 INFO     Training average negative_sample_loss at step 143500: 0.453858\n",
      "2022-11-08 10:31:37,983 INFO     Training average loss at step 143500: 0.701680\n",
      "2022-11-08 10:31:44,506 INFO     Training average positive_sample_loss at step 143600: 0.974873\n",
      "2022-11-08 10:31:44,506 INFO     Training average negative_sample_loss at step 143600: 0.444470\n",
      "2022-11-08 10:31:44,506 INFO     Training average loss at step 143600: 0.709671\n",
      "2022-11-08 10:31:50,957 INFO     Training average positive_sample_loss at step 143700: 0.963518\n",
      "2022-11-08 10:31:50,957 INFO     Training average negative_sample_loss at step 143700: 0.447022\n",
      "2022-11-08 10:31:50,957 INFO     Training average loss at step 143700: 0.705270\n",
      "2022-11-08 10:31:57,438 INFO     Training average positive_sample_loss at step 143800: 0.997167\n",
      "2022-11-08 10:31:57,438 INFO     Training average negative_sample_loss at step 143800: 0.442324\n",
      "2022-11-08 10:31:57,438 INFO     Training average loss at step 143800: 0.719745\n",
      "2022-11-08 10:32:03,856 INFO     Training average positive_sample_loss at step 143900: 1.013270\n",
      "2022-11-08 10:32:03,856 INFO     Training average negative_sample_loss at step 143900: 0.443552\n",
      "2022-11-08 10:32:03,856 INFO     Training average loss at step 143900: 0.728411\n",
      "2022-11-08 10:32:10,268 INFO     Training average positive_sample_loss at step 144000: 1.009874\n",
      "2022-11-08 10:32:10,268 INFO     Training average negative_sample_loss at step 144000: 0.433854\n",
      "2022-11-08 10:32:10,268 INFO     Training average loss at step 144000: 0.721864\n",
      "2022-11-08 10:32:16,949 INFO     Training average positive_sample_loss at step 144100: 0.997992\n",
      "2022-11-08 10:32:16,950 INFO     Training average negative_sample_loss at step 144100: 0.439139\n",
      "2022-11-08 10:32:16,950 INFO     Training average loss at step 144100: 0.718565\n",
      "2022-11-08 10:32:23,483 INFO     Training average positive_sample_loss at step 144200: 0.982359\n",
      "2022-11-08 10:32:23,483 INFO     Training average negative_sample_loss at step 144200: 0.442615\n",
      "2022-11-08 10:32:23,483 INFO     Training average loss at step 144200: 0.712487\n",
      "2022-11-08 10:32:30,102 INFO     Training average positive_sample_loss at step 144300: 0.956720\n",
      "2022-11-08 10:32:30,102 INFO     Training average negative_sample_loss at step 144300: 0.444318\n",
      "2022-11-08 10:32:30,102 INFO     Training average loss at step 144300: 0.700519\n",
      "2022-11-08 10:32:36,539 INFO     Training average positive_sample_loss at step 144400: 0.973691\n",
      "2022-11-08 10:32:36,539 INFO     Training average negative_sample_loss at step 144400: 0.439125\n",
      "2022-11-08 10:32:36,539 INFO     Training average loss at step 144400: 0.706408\n",
      "2022-11-08 10:32:42,949 INFO     Training average positive_sample_loss at step 144500: 0.985911\n",
      "2022-11-08 10:32:42,949 INFO     Training average negative_sample_loss at step 144500: 0.448104\n",
      "2022-11-08 10:32:42,949 INFO     Training average loss at step 144500: 0.717007\n",
      "2022-11-08 10:32:49,349 INFO     Training average positive_sample_loss at step 144600: 0.956885\n",
      "2022-11-08 10:32:49,349 INFO     Training average negative_sample_loss at step 144600: 0.433803\n",
      "2022-11-08 10:32:49,349 INFO     Training average loss at step 144600: 0.695344\n",
      "2022-11-08 10:32:55,932 INFO     Training average positive_sample_loss at step 144700: 0.976672\n",
      "2022-11-08 10:32:55,932 INFO     Training average negative_sample_loss at step 144700: 0.440954\n",
      "2022-11-08 10:32:55,932 INFO     Training average loss at step 144700: 0.708813\n",
      "2022-11-08 10:33:02,523 INFO     Training average positive_sample_loss at step 144800: 0.985151\n",
      "2022-11-08 10:33:02,523 INFO     Training average negative_sample_loss at step 144800: 0.441852\n",
      "2022-11-08 10:33:02,523 INFO     Training average loss at step 144800: 0.713501\n",
      "2022-11-08 10:33:09,008 INFO     Training average positive_sample_loss at step 144900: 0.940377\n",
      "2022-11-08 10:33:09,008 INFO     Training average negative_sample_loss at step 144900: 0.445984\n",
      "2022-11-08 10:33:09,008 INFO     Training average loss at step 144900: 0.693180\n",
      "2022-11-08 10:33:15,433 INFO     Training average positive_sample_loss at step 145000: 1.026831\n",
      "2022-11-08 10:33:15,433 INFO     Training average negative_sample_loss at step 145000: 0.440335\n",
      "2022-11-08 10:33:15,433 INFO     Training average loss at step 145000: 0.733583\n",
      "2022-11-08 10:33:21,994 INFO     Training average positive_sample_loss at step 145100: 0.959748\n",
      "2022-11-08 10:33:21,994 INFO     Training average negative_sample_loss at step 145100: 0.435334\n",
      "2022-11-08 10:33:21,994 INFO     Training average loss at step 145100: 0.697541\n",
      "2022-11-08 10:33:29,898 INFO     Training average positive_sample_loss at step 145200: 0.979376\n",
      "2022-11-08 10:33:29,898 INFO     Training average negative_sample_loss at step 145200: 0.439729\n",
      "2022-11-08 10:33:29,899 INFO     Training average loss at step 145200: 0.709552\n",
      "2022-11-08 10:33:36,419 INFO     Training average positive_sample_loss at step 145300: 0.983237\n",
      "2022-11-08 10:33:36,420 INFO     Training average negative_sample_loss at step 145300: 0.444528\n",
      "2022-11-08 10:33:36,420 INFO     Training average loss at step 145300: 0.713882\n",
      "2022-11-08 10:33:44,201 INFO     Training average positive_sample_loss at step 145400: 0.967790\n",
      "2022-11-08 10:33:44,201 INFO     Training average negative_sample_loss at step 145400: 0.443079\n",
      "2022-11-08 10:33:44,201 INFO     Training average loss at step 145400: 0.705435\n",
      "2022-11-08 10:33:50,677 INFO     Training average positive_sample_loss at step 145500: 0.981806\n",
      "2022-11-08 10:33:50,677 INFO     Training average negative_sample_loss at step 145500: 0.436118\n",
      "2022-11-08 10:33:50,677 INFO     Training average loss at step 145500: 0.708962\n",
      "2022-11-08 10:33:57,649 INFO     Training average positive_sample_loss at step 145600: 0.981695\n",
      "2022-11-08 10:33:57,649 INFO     Training average negative_sample_loss at step 145600: 0.440322\n",
      "2022-11-08 10:33:57,649 INFO     Training average loss at step 145600: 0.711009\n",
      "2022-11-08 10:34:04,322 INFO     Training average positive_sample_loss at step 145700: 0.990449\n",
      "2022-11-08 10:34:04,322 INFO     Training average negative_sample_loss at step 145700: 0.435505\n",
      "2022-11-08 10:34:04,322 INFO     Training average loss at step 145700: 0.712977\n",
      "2022-11-08 10:34:10,751 INFO     Training average positive_sample_loss at step 145800: 0.986281\n",
      "2022-11-08 10:34:10,751 INFO     Training average negative_sample_loss at step 145800: 0.434610\n",
      "2022-11-08 10:34:10,751 INFO     Training average loss at step 145800: 0.710446\n",
      "2022-11-08 10:34:17,251 INFO     Training average positive_sample_loss at step 145900: 0.964546\n",
      "2022-11-08 10:34:17,251 INFO     Training average negative_sample_loss at step 145900: 0.436308\n",
      "2022-11-08 10:34:17,251 INFO     Training average loss at step 145900: 0.700427\n",
      "2022-11-08 10:34:23,875 INFO     Training average positive_sample_loss at step 146000: 0.963395\n",
      "2022-11-08 10:34:23,875 INFO     Training average negative_sample_loss at step 146000: 0.447555\n",
      "2022-11-08 10:34:23,875 INFO     Training average loss at step 146000: 0.705475\n",
      "2022-11-08 10:34:30,496 INFO     Training average positive_sample_loss at step 146100: 0.973431\n",
      "2022-11-08 10:34:30,496 INFO     Training average negative_sample_loss at step 146100: 0.437568\n",
      "2022-11-08 10:34:30,496 INFO     Training average loss at step 146100: 0.705500\n",
      "2022-11-08 10:34:36,973 INFO     Training average positive_sample_loss at step 146200: 0.940604\n",
      "2022-11-08 10:34:36,973 INFO     Training average negative_sample_loss at step 146200: 0.445201\n",
      "2022-11-08 10:34:36,973 INFO     Training average loss at step 146200: 0.692902\n",
      "2022-11-08 10:34:43,453 INFO     Training average positive_sample_loss at step 146300: 0.981788\n",
      "2022-11-08 10:34:43,453 INFO     Training average negative_sample_loss at step 146300: 0.439462\n",
      "2022-11-08 10:34:43,453 INFO     Training average loss at step 146300: 0.710625\n",
      "2022-11-08 10:34:49,939 INFO     Training average positive_sample_loss at step 146400: 0.991747\n",
      "2022-11-08 10:34:49,939 INFO     Training average negative_sample_loss at step 146400: 0.439175\n",
      "2022-11-08 10:34:49,939 INFO     Training average loss at step 146400: 0.715461\n",
      "2022-11-08 10:34:56,496 INFO     Training average positive_sample_loss at step 146500: 0.940493\n",
      "2022-11-08 10:34:56,496 INFO     Training average negative_sample_loss at step 146500: 0.440993\n",
      "2022-11-08 10:34:56,496 INFO     Training average loss at step 146500: 0.690743\n",
      "2022-11-08 10:35:03,080 INFO     Training average positive_sample_loss at step 146600: 0.972920\n",
      "2022-11-08 10:35:03,080 INFO     Training average negative_sample_loss at step 146600: 0.432486\n",
      "2022-11-08 10:35:03,080 INFO     Training average loss at step 146600: 0.702703\n",
      "2022-11-08 10:35:09,697 INFO     Training average positive_sample_loss at step 146700: 0.976538\n",
      "2022-11-08 10:35:09,697 INFO     Training average negative_sample_loss at step 146700: 0.437355\n",
      "2022-11-08 10:35:09,697 INFO     Training average loss at step 146700: 0.706946\n",
      "2022-11-08 10:35:16,245 INFO     Training average positive_sample_loss at step 146800: 0.979713\n",
      "2022-11-08 10:35:16,245 INFO     Training average negative_sample_loss at step 146800: 0.440868\n",
      "2022-11-08 10:35:16,245 INFO     Training average loss at step 146800: 0.710290\n",
      "2022-11-08 10:35:22,782 INFO     Training average positive_sample_loss at step 146900: 0.965015\n",
      "2022-11-08 10:35:22,783 INFO     Training average negative_sample_loss at step 146900: 0.430302\n",
      "2022-11-08 10:35:22,783 INFO     Training average loss at step 146900: 0.697658\n",
      "2022-11-08 10:35:29,384 INFO     Training average positive_sample_loss at step 147000: 0.967010\n",
      "2022-11-08 10:35:29,384 INFO     Training average negative_sample_loss at step 147000: 0.439798\n",
      "2022-11-08 10:35:29,384 INFO     Training average loss at step 147000: 0.703404\n",
      "2022-11-08 10:35:36,001 INFO     Training average positive_sample_loss at step 147100: 0.986629\n",
      "2022-11-08 10:35:36,001 INFO     Training average negative_sample_loss at step 147100: 0.434502\n",
      "2022-11-08 10:35:36,001 INFO     Training average loss at step 147100: 0.710566\n",
      "2022-11-08 10:35:42,449 INFO     Training average positive_sample_loss at step 147200: 0.965199\n",
      "2022-11-08 10:35:42,449 INFO     Training average negative_sample_loss at step 147200: 0.435265\n",
      "2022-11-08 10:35:42,449 INFO     Training average loss at step 147200: 0.700232\n",
      "2022-11-08 10:35:48,880 INFO     Training average positive_sample_loss at step 147300: 0.985469\n",
      "2022-11-08 10:35:48,880 INFO     Training average negative_sample_loss at step 147300: 0.439348\n",
      "2022-11-08 10:35:48,880 INFO     Training average loss at step 147300: 0.712408\n",
      "2022-11-08 10:35:55,345 INFO     Training average positive_sample_loss at step 147400: 0.985273\n",
      "2022-11-08 10:35:55,346 INFO     Training average negative_sample_loss at step 147400: 0.437754\n",
      "2022-11-08 10:35:55,346 INFO     Training average loss at step 147400: 0.711514\n",
      "2022-11-08 10:36:01,824 INFO     Training average positive_sample_loss at step 147500: 0.944089\n",
      "2022-11-08 10:36:01,824 INFO     Training average negative_sample_loss at step 147500: 0.433809\n",
      "2022-11-08 10:36:01,824 INFO     Training average loss at step 147500: 0.688949\n",
      "2022-11-08 10:36:08,342 INFO     Training average positive_sample_loss at step 147600: 0.942457\n",
      "2022-11-08 10:36:08,343 INFO     Training average negative_sample_loss at step 147600: 0.429443\n",
      "2022-11-08 10:36:08,343 INFO     Training average loss at step 147600: 0.685950\n",
      "2022-11-08 10:36:14,996 INFO     Training average positive_sample_loss at step 147700: 0.976936\n",
      "2022-11-08 10:36:14,996 INFO     Training average negative_sample_loss at step 147700: 0.438626\n",
      "2022-11-08 10:36:14,996 INFO     Training average loss at step 147700: 0.707781\n",
      "2022-11-08 10:36:21,617 INFO     Training average positive_sample_loss at step 147800: 0.931266\n",
      "2022-11-08 10:36:21,617 INFO     Training average negative_sample_loss at step 147800: 0.442025\n",
      "2022-11-08 10:36:21,617 INFO     Training average loss at step 147800: 0.686646\n",
      "2022-11-08 10:36:28,148 INFO     Training average positive_sample_loss at step 147900: 0.953199\n",
      "2022-11-08 10:36:28,148 INFO     Training average negative_sample_loss at step 147900: 0.431639\n",
      "2022-11-08 10:36:28,148 INFO     Training average loss at step 147900: 0.692419\n",
      "2022-11-08 10:36:34,596 INFO     Training average positive_sample_loss at step 148000: 0.982050\n",
      "2022-11-08 10:36:34,596 INFO     Training average negative_sample_loss at step 148000: 0.437626\n",
      "2022-11-08 10:36:34,596 INFO     Training average loss at step 148000: 0.709838\n",
      "2022-11-08 10:36:40,997 INFO     Training average positive_sample_loss at step 148100: 0.955039\n",
      "2022-11-08 10:36:40,998 INFO     Training average negative_sample_loss at step 148100: 0.433712\n",
      "2022-11-08 10:36:40,998 INFO     Training average loss at step 148100: 0.694375\n",
      "2022-11-08 10:36:47,407 INFO     Training average positive_sample_loss at step 148200: 0.962451\n",
      "2022-11-08 10:36:47,407 INFO     Training average negative_sample_loss at step 148200: 0.424109\n",
      "2022-11-08 10:36:47,407 INFO     Training average loss at step 148200: 0.693280\n",
      "2022-11-08 10:36:53,803 INFO     Training average positive_sample_loss at step 148300: 0.981144\n",
      "2022-11-08 10:36:53,803 INFO     Training average negative_sample_loss at step 148300: 0.436780\n",
      "2022-11-08 10:36:53,803 INFO     Training average loss at step 148300: 0.708962\n",
      "2022-11-08 10:37:00,357 INFO     Training average positive_sample_loss at step 148400: 0.958547\n",
      "2022-11-08 10:37:00,357 INFO     Training average negative_sample_loss at step 148400: 0.427953\n",
      "2022-11-08 10:37:00,357 INFO     Training average loss at step 148400: 0.693250\n",
      "2022-11-08 10:37:06,931 INFO     Training average positive_sample_loss at step 148500: 0.980827\n",
      "2022-11-08 10:37:06,932 INFO     Training average negative_sample_loss at step 148500: 0.430390\n",
      "2022-11-08 10:37:06,932 INFO     Training average loss at step 148500: 0.705608\n",
      "2022-11-08 10:37:13,346 INFO     Training average positive_sample_loss at step 148600: 0.963582\n",
      "2022-11-08 10:37:13,346 INFO     Training average negative_sample_loss at step 148600: 0.435822\n",
      "2022-11-08 10:37:13,346 INFO     Training average loss at step 148600: 0.699702\n",
      "2022-11-08 10:37:19,752 INFO     Training average positive_sample_loss at step 148700: 1.000083\n",
      "2022-11-08 10:37:19,752 INFO     Training average negative_sample_loss at step 148700: 0.429657\n",
      "2022-11-08 10:37:19,752 INFO     Training average loss at step 148700: 0.714870\n",
      "2022-11-08 10:37:26,146 INFO     Training average positive_sample_loss at step 148800: 0.972614\n",
      "2022-11-08 10:37:26,146 INFO     Training average negative_sample_loss at step 148800: 0.431198\n",
      "2022-11-08 10:37:26,146 INFO     Training average loss at step 148800: 0.701906\n",
      "2022-11-08 10:37:31,222 INFO     Training average positive_sample_loss at step 148900: 0.957454\n",
      "2022-11-08 10:37:31,222 INFO     Training average negative_sample_loss at step 148900: 0.436313\n",
      "2022-11-08 10:37:31,222 INFO     Training average loss at step 148900: 0.696883\n",
      "2022-11-08 10:37:37,835 INFO     Training average positive_sample_loss at step 149000: 0.960554\n",
      "2022-11-08 10:37:37,835 INFO     Training average negative_sample_loss at step 149000: 0.435431\n",
      "2022-11-08 10:37:37,835 INFO     Training average loss at step 149000: 0.697992\n",
      "2022-11-08 10:37:44,409 INFO     Training average positive_sample_loss at step 149100: 0.967968\n",
      "2022-11-08 10:37:44,410 INFO     Training average negative_sample_loss at step 149100: 0.436146\n",
      "2022-11-08 10:37:44,410 INFO     Training average loss at step 149100: 0.702057\n",
      "2022-11-08 10:37:50,940 INFO     Training average positive_sample_loss at step 149200: 0.972470\n",
      "2022-11-08 10:37:50,940 INFO     Training average negative_sample_loss at step 149200: 0.435619\n",
      "2022-11-08 10:37:50,940 INFO     Training average loss at step 149200: 0.704045\n",
      "2022-11-08 10:37:57,531 INFO     Training average positive_sample_loss at step 149300: 0.977580\n",
      "2022-11-08 10:37:57,531 INFO     Training average negative_sample_loss at step 149300: 0.435545\n",
      "2022-11-08 10:37:57,531 INFO     Training average loss at step 149300: 0.706563\n",
      "2022-11-08 10:38:03,992 INFO     Training average positive_sample_loss at step 149400: 0.964236\n",
      "2022-11-08 10:38:03,992 INFO     Training average negative_sample_loss at step 149400: 0.432786\n",
      "2022-11-08 10:38:03,992 INFO     Training average loss at step 149400: 0.698511\n",
      "2022-11-08 10:38:10,464 INFO     Training average positive_sample_loss at step 149500: 0.957820\n",
      "2022-11-08 10:38:10,464 INFO     Training average negative_sample_loss at step 149500: 0.428322\n",
      "2022-11-08 10:38:10,464 INFO     Training average loss at step 149500: 0.693071\n",
      "2022-11-08 10:38:16,931 INFO     Training average positive_sample_loss at step 149600: 0.981198\n",
      "2022-11-08 10:38:16,931 INFO     Training average negative_sample_loss at step 149600: 0.428877\n",
      "2022-11-08 10:38:16,931 INFO     Training average loss at step 149600: 0.705037\n",
      "2022-11-08 10:38:23,367 INFO     Training average positive_sample_loss at step 149700: 0.938830\n",
      "2022-11-08 10:38:23,367 INFO     Training average negative_sample_loss at step 149700: 0.432041\n",
      "2022-11-08 10:38:23,367 INFO     Training average loss at step 149700: 0.685436\n",
      "2022-11-08 10:38:30,545 INFO     Training average positive_sample_loss at step 149800: 0.967992\n",
      "2022-11-08 10:38:30,545 INFO     Training average negative_sample_loss at step 149800: 0.429501\n",
      "2022-11-08 10:38:30,545 INFO     Training average loss at step 149800: 0.698746\n",
      "2022-11-08 10:38:38,019 INFO     Training average positive_sample_loss at step 149900: 0.959521\n",
      "2022-11-08 10:38:38,019 INFO     Training average negative_sample_loss at step 149900: 0.433294\n",
      "2022-11-08 10:38:38,019 INFO     Training average loss at step 149900: 0.696407\n",
      "2022-11-08 10:38:47,488 INFO     Training average positive_sample_loss at step 150000: 0.978630\n",
      "2022-11-08 10:38:47,488 INFO     Training average negative_sample_loss at step 150000: 0.432913\n",
      "2022-11-08 10:38:47,488 INFO     Training average loss at step 150000: 0.705772\n",
      "2022-11-08 10:38:53,916 INFO     Training average positive_sample_loss at step 150100: 0.996524\n",
      "2022-11-08 10:38:53,916 INFO     Training average negative_sample_loss at step 150100: 0.436064\n",
      "2022-11-08 10:38:53,916 INFO     Training average loss at step 150100: 0.716294\n",
      "2022-11-08 10:39:00,954 INFO     Training average positive_sample_loss at step 150200: 0.942080\n",
      "2022-11-08 10:39:00,954 INFO     Training average negative_sample_loss at step 150200: 0.429271\n",
      "2022-11-08 10:39:00,954 INFO     Training average loss at step 150200: 0.685675\n",
      "2022-11-08 10:39:07,406 INFO     Training average positive_sample_loss at step 150300: 0.970021\n",
      "2022-11-08 10:39:07,406 INFO     Training average negative_sample_loss at step 150300: 0.424194\n",
      "2022-11-08 10:39:07,406 INFO     Training average loss at step 150300: 0.697107\n",
      "2022-11-08 10:39:13,872 INFO     Training average positive_sample_loss at step 150400: 0.946510\n",
      "2022-11-08 10:39:13,873 INFO     Training average negative_sample_loss at step 150400: 0.427607\n",
      "2022-11-08 10:39:13,873 INFO     Training average loss at step 150400: 0.687059\n",
      "2022-11-08 10:39:20,338 INFO     Training average positive_sample_loss at step 150500: 0.933946\n",
      "2022-11-08 10:39:20,338 INFO     Training average negative_sample_loss at step 150500: 0.437099\n",
      "2022-11-08 10:39:20,338 INFO     Training average loss at step 150500: 0.685523\n",
      "2022-11-08 10:39:26,781 INFO     Training average positive_sample_loss at step 150600: 0.971370\n",
      "2022-11-08 10:39:26,781 INFO     Training average negative_sample_loss at step 150600: 0.427599\n",
      "2022-11-08 10:39:26,781 INFO     Training average loss at step 150600: 0.699485\n",
      "2022-11-08 10:39:33,237 INFO     Training average positive_sample_loss at step 150700: 0.944065\n",
      "2022-11-08 10:39:33,237 INFO     Training average negative_sample_loss at step 150700: 0.432741\n",
      "2022-11-08 10:39:33,237 INFO     Training average loss at step 150700: 0.688403\n",
      "2022-11-08 10:39:39,671 INFO     Training average positive_sample_loss at step 150800: 0.928837\n",
      "2022-11-08 10:39:39,671 INFO     Training average negative_sample_loss at step 150800: 0.433668\n",
      "2022-11-08 10:39:39,671 INFO     Training average loss at step 150800: 0.681253\n",
      "2022-11-08 10:39:46,150 INFO     Training average positive_sample_loss at step 150900: 0.979571\n",
      "2022-11-08 10:39:46,150 INFO     Training average negative_sample_loss at step 150900: 0.424130\n",
      "2022-11-08 10:39:46,150 INFO     Training average loss at step 150900: 0.701851\n",
      "2022-11-08 10:39:52,610 INFO     Training average positive_sample_loss at step 151000: 0.935253\n",
      "2022-11-08 10:39:52,610 INFO     Training average negative_sample_loss at step 151000: 0.427359\n",
      "2022-11-08 10:39:52,610 INFO     Training average loss at step 151000: 0.681306\n",
      "2022-11-08 10:39:59,082 INFO     Training average positive_sample_loss at step 151100: 0.938024\n",
      "2022-11-08 10:39:59,082 INFO     Training average negative_sample_loss at step 151100: 0.427271\n",
      "2022-11-08 10:39:59,083 INFO     Training average loss at step 151100: 0.682648\n",
      "2022-11-08 10:40:05,606 INFO     Training average positive_sample_loss at step 151200: 0.991086\n",
      "2022-11-08 10:40:05,606 INFO     Training average negative_sample_loss at step 151200: 0.435203\n",
      "2022-11-08 10:40:05,606 INFO     Training average loss at step 151200: 0.713144\n",
      "2022-11-08 10:40:12,078 INFO     Training average positive_sample_loss at step 151300: 0.977475\n",
      "2022-11-08 10:40:12,078 INFO     Training average negative_sample_loss at step 151300: 0.428180\n",
      "2022-11-08 10:40:12,078 INFO     Training average loss at step 151300: 0.702827\n",
      "2022-11-08 10:40:18,517 INFO     Training average positive_sample_loss at step 151400: 0.927058\n",
      "2022-11-08 10:40:18,517 INFO     Training average negative_sample_loss at step 151400: 0.434862\n",
      "2022-11-08 10:40:18,517 INFO     Training average loss at step 151400: 0.680960\n",
      "2022-11-08 10:40:25,009 INFO     Training average positive_sample_loss at step 151500: 0.915175\n",
      "2022-11-08 10:40:25,009 INFO     Training average negative_sample_loss at step 151500: 0.429478\n",
      "2022-11-08 10:40:25,009 INFO     Training average loss at step 151500: 0.672327\n",
      "2022-11-08 10:40:31,486 INFO     Training average positive_sample_loss at step 151600: 0.980804\n",
      "2022-11-08 10:40:31,486 INFO     Training average negative_sample_loss at step 151600: 0.425333\n",
      "2022-11-08 10:40:31,486 INFO     Training average loss at step 151600: 0.703068\n",
      "2022-11-08 10:40:37,934 INFO     Training average positive_sample_loss at step 151700: 0.937365\n",
      "2022-11-08 10:40:37,934 INFO     Training average negative_sample_loss at step 151700: 0.422788\n",
      "2022-11-08 10:40:37,934 INFO     Training average loss at step 151700: 0.680077\n",
      "2022-11-08 10:40:44,415 INFO     Training average positive_sample_loss at step 151800: 0.969733\n",
      "2022-11-08 10:40:44,415 INFO     Training average negative_sample_loss at step 151800: 0.435028\n",
      "2022-11-08 10:40:44,415 INFO     Training average loss at step 151800: 0.702380\n",
      "2022-11-08 10:40:50,877 INFO     Training average positive_sample_loss at step 151900: 0.952833\n",
      "2022-11-08 10:40:50,877 INFO     Training average negative_sample_loss at step 151900: 0.418872\n",
      "2022-11-08 10:40:50,877 INFO     Training average loss at step 151900: 0.685852\n",
      "2022-11-08 10:40:57,321 INFO     Training average positive_sample_loss at step 152000: 0.971219\n",
      "2022-11-08 10:40:57,321 INFO     Training average negative_sample_loss at step 152000: 0.428275\n",
      "2022-11-08 10:40:57,321 INFO     Training average loss at step 152000: 0.699747\n",
      "2022-11-08 10:41:03,804 INFO     Training average positive_sample_loss at step 152100: 0.926355\n",
      "2022-11-08 10:41:03,804 INFO     Training average negative_sample_loss at step 152100: 0.426451\n",
      "2022-11-08 10:41:03,804 INFO     Training average loss at step 152100: 0.676403\n",
      "2022-11-08 10:41:10,250 INFO     Training average positive_sample_loss at step 152200: 0.960853\n",
      "2022-11-08 10:41:10,251 INFO     Training average negative_sample_loss at step 152200: 0.427961\n",
      "2022-11-08 10:41:10,251 INFO     Training average loss at step 152200: 0.694407\n",
      "2022-11-08 10:41:16,745 INFO     Training average positive_sample_loss at step 152300: 0.953837\n",
      "2022-11-08 10:41:16,745 INFO     Training average negative_sample_loss at step 152300: 0.425162\n",
      "2022-11-08 10:41:16,745 INFO     Training average loss at step 152300: 0.689500\n",
      "2022-11-08 10:41:23,214 INFO     Training average positive_sample_loss at step 152400: 0.917410\n",
      "2022-11-08 10:41:23,214 INFO     Training average negative_sample_loss at step 152400: 0.432379\n",
      "2022-11-08 10:41:23,214 INFO     Training average loss at step 152400: 0.674895\n",
      "2022-11-08 10:41:29,680 INFO     Training average positive_sample_loss at step 152500: 0.935061\n",
      "2022-11-08 10:41:29,681 INFO     Training average negative_sample_loss at step 152500: 0.423001\n",
      "2022-11-08 10:41:29,681 INFO     Training average loss at step 152500: 0.679031\n",
      "2022-11-08 10:41:36,105 INFO     Training average positive_sample_loss at step 152600: 0.937365\n",
      "2022-11-08 10:41:36,105 INFO     Training average negative_sample_loss at step 152600: 0.430339\n",
      "2022-11-08 10:41:36,105 INFO     Training average loss at step 152600: 0.683852\n",
      "2022-11-08 10:41:42,543 INFO     Training average positive_sample_loss at step 152700: 0.930591\n",
      "2022-11-08 10:41:42,543 INFO     Training average negative_sample_loss at step 152700: 0.424618\n",
      "2022-11-08 10:41:42,543 INFO     Training average loss at step 152700: 0.677605\n",
      "2022-11-08 10:41:48,960 INFO     Training average positive_sample_loss at step 152800: 0.938387\n",
      "2022-11-08 10:41:48,960 INFO     Training average negative_sample_loss at step 152800: 0.421553\n",
      "2022-11-08 10:41:48,960 INFO     Training average loss at step 152800: 0.679970\n",
      "2022-11-08 10:41:55,435 INFO     Training average positive_sample_loss at step 152900: 0.973475\n",
      "2022-11-08 10:41:55,435 INFO     Training average negative_sample_loss at step 152900: 0.419302\n",
      "2022-11-08 10:41:55,435 INFO     Training average loss at step 152900: 0.696388\n",
      "2022-11-08 10:42:01,860 INFO     Training average positive_sample_loss at step 153000: 0.907838\n",
      "2022-11-08 10:42:01,860 INFO     Training average negative_sample_loss at step 153000: 0.422499\n",
      "2022-11-08 10:42:01,860 INFO     Training average loss at step 153000: 0.665168\n",
      "2022-11-08 10:42:08,265 INFO     Training average positive_sample_loss at step 153100: 0.944417\n",
      "2022-11-08 10:42:08,266 INFO     Training average negative_sample_loss at step 153100: 0.421485\n",
      "2022-11-08 10:42:08,266 INFO     Training average loss at step 153100: 0.682951\n",
      "2022-11-08 10:42:14,687 INFO     Training average positive_sample_loss at step 153200: 0.945150\n",
      "2022-11-08 10:42:14,687 INFO     Training average negative_sample_loss at step 153200: 0.424266\n",
      "2022-11-08 10:42:14,687 INFO     Training average loss at step 153200: 0.684708\n",
      "2022-11-08 10:42:21,121 INFO     Training average positive_sample_loss at step 153300: 0.932390\n",
      "2022-11-08 10:42:21,121 INFO     Training average negative_sample_loss at step 153300: 0.427722\n",
      "2022-11-08 10:42:21,121 INFO     Training average loss at step 153300: 0.680056\n",
      "2022-11-08 10:42:27,550 INFO     Training average positive_sample_loss at step 153400: 0.891020\n",
      "2022-11-08 10:42:27,550 INFO     Training average negative_sample_loss at step 153400: 0.429897\n",
      "2022-11-08 10:42:27,550 INFO     Training average loss at step 153400: 0.660458\n",
      "2022-11-08 10:42:33,939 INFO     Training average positive_sample_loss at step 153500: 0.911930\n",
      "2022-11-08 10:42:33,939 INFO     Training average negative_sample_loss at step 153500: 0.426022\n",
      "2022-11-08 10:42:33,939 INFO     Training average loss at step 153500: 0.668976\n",
      "2022-11-08 10:42:40,351 INFO     Training average positive_sample_loss at step 153600: 0.920493\n",
      "2022-11-08 10:42:40,351 INFO     Training average negative_sample_loss at step 153600: 0.431250\n",
      "2022-11-08 10:42:40,351 INFO     Training average loss at step 153600: 0.675872\n",
      "2022-11-08 10:42:46,772 INFO     Training average positive_sample_loss at step 153700: 0.992201\n",
      "2022-11-08 10:42:46,772 INFO     Training average negative_sample_loss at step 153700: 0.414884\n",
      "2022-11-08 10:42:46,772 INFO     Training average loss at step 153700: 0.703543\n",
      "2022-11-08 10:42:53,236 INFO     Training average positive_sample_loss at step 153800: 0.951086\n",
      "2022-11-08 10:42:53,236 INFO     Training average negative_sample_loss at step 153800: 0.420662\n",
      "2022-11-08 10:42:53,236 INFO     Training average loss at step 153800: 0.685874\n",
      "2022-11-08 10:42:59,691 INFO     Training average positive_sample_loss at step 153900: 0.930165\n",
      "2022-11-08 10:42:59,691 INFO     Training average negative_sample_loss at step 153900: 0.431526\n",
      "2022-11-08 10:42:59,691 INFO     Training average loss at step 153900: 0.680845\n",
      "2022-11-08 10:43:06,150 INFO     Training average positive_sample_loss at step 154000: 0.944389\n",
      "2022-11-08 10:43:06,150 INFO     Training average negative_sample_loss at step 154000: 0.419241\n",
      "2022-11-08 10:43:06,151 INFO     Training average loss at step 154000: 0.681815\n",
      "2022-11-08 10:43:12,570 INFO     Training average positive_sample_loss at step 154100: 0.945415\n",
      "2022-11-08 10:43:12,570 INFO     Training average negative_sample_loss at step 154100: 0.427998\n",
      "2022-11-08 10:43:12,570 INFO     Training average loss at step 154100: 0.686706\n",
      "2022-11-08 10:43:19,014 INFO     Training average positive_sample_loss at step 154200: 0.967402\n",
      "2022-11-08 10:43:19,014 INFO     Training average negative_sample_loss at step 154200: 0.422198\n",
      "2022-11-08 10:43:19,014 INFO     Training average loss at step 154200: 0.694800\n",
      "2022-11-08 10:43:25,421 INFO     Training average positive_sample_loss at step 154300: 0.943895\n",
      "2022-11-08 10:43:25,421 INFO     Training average negative_sample_loss at step 154300: 0.427929\n",
      "2022-11-08 10:43:25,421 INFO     Training average loss at step 154300: 0.685912\n",
      "2022-11-08 10:43:31,148 INFO     Training average positive_sample_loss at step 154400: 0.985311\n",
      "2022-11-08 10:43:31,148 INFO     Training average negative_sample_loss at step 154400: 0.418178\n",
      "2022-11-08 10:43:31,148 INFO     Training average loss at step 154400: 0.701745\n",
      "2022-11-08 10:43:37,794 INFO     Training average positive_sample_loss at step 154500: 0.938866\n",
      "2022-11-08 10:43:37,794 INFO     Training average negative_sample_loss at step 154500: 0.419658\n",
      "2022-11-08 10:43:37,794 INFO     Training average loss at step 154500: 0.679262\n",
      "2022-11-08 10:43:45,190 INFO     Training average positive_sample_loss at step 154600: 0.905429\n",
      "2022-11-08 10:43:45,190 INFO     Training average negative_sample_loss at step 154600: 0.421965\n",
      "2022-11-08 10:43:45,190 INFO     Training average loss at step 154600: 0.663697\n",
      "2022-11-08 10:43:52,847 INFO     Training average positive_sample_loss at step 154700: 0.921304\n",
      "2022-11-08 10:43:52,847 INFO     Training average negative_sample_loss at step 154700: 0.417532\n",
      "2022-11-08 10:43:52,847 INFO     Training average loss at step 154700: 0.669418\n",
      "2022-11-08 10:43:59,308 INFO     Training average positive_sample_loss at step 154800: 0.943516\n",
      "2022-11-08 10:43:59,308 INFO     Training average negative_sample_loss at step 154800: 0.417674\n",
      "2022-11-08 10:43:59,308 INFO     Training average loss at step 154800: 0.680595\n",
      "2022-11-08 10:44:06,313 INFO     Training average positive_sample_loss at step 154900: 0.948580\n",
      "2022-11-08 10:44:06,313 INFO     Training average negative_sample_loss at step 154900: 0.419177\n",
      "2022-11-08 10:44:06,313 INFO     Training average loss at step 154900: 0.683878\n",
      "2022-11-08 10:44:12,737 INFO     Training average positive_sample_loss at step 155000: 0.890010\n",
      "2022-11-08 10:44:12,737 INFO     Training average negative_sample_loss at step 155000: 0.424143\n",
      "2022-11-08 10:44:12,737 INFO     Training average loss at step 155000: 0.657077\n",
      "2022-11-08 10:44:19,203 INFO     Training average positive_sample_loss at step 155100: 0.947843\n",
      "2022-11-08 10:44:19,203 INFO     Training average negative_sample_loss at step 155100: 0.427211\n",
      "2022-11-08 10:44:19,203 INFO     Training average loss at step 155100: 0.687527\n",
      "2022-11-08 10:44:25,638 INFO     Training average positive_sample_loss at step 155200: 0.921756\n",
      "2022-11-08 10:44:25,638 INFO     Training average negative_sample_loss at step 155200: 0.417009\n",
      "2022-11-08 10:44:25,639 INFO     Training average loss at step 155200: 0.669382\n",
      "2022-11-08 10:44:32,056 INFO     Training average positive_sample_loss at step 155300: 0.962298\n",
      "2022-11-08 10:44:32,056 INFO     Training average negative_sample_loss at step 155300: 0.416193\n",
      "2022-11-08 10:44:32,056 INFO     Training average loss at step 155300: 0.689245\n",
      "2022-11-08 10:44:38,456 INFO     Training average positive_sample_loss at step 155400: 0.939660\n",
      "2022-11-08 10:44:38,456 INFO     Training average negative_sample_loss at step 155400: 0.422011\n",
      "2022-11-08 10:44:38,456 INFO     Training average loss at step 155400: 0.680836\n",
      "2022-11-08 10:44:44,864 INFO     Training average positive_sample_loss at step 155500: 0.944531\n",
      "2022-11-08 10:44:44,864 INFO     Training average negative_sample_loss at step 155500: 0.419380\n",
      "2022-11-08 10:44:44,864 INFO     Training average loss at step 155500: 0.681956\n",
      "2022-11-08 10:44:51,258 INFO     Training average positive_sample_loss at step 155600: 0.909482\n",
      "2022-11-08 10:44:51,258 INFO     Training average negative_sample_loss at step 155600: 0.420430\n",
      "2022-11-08 10:44:51,258 INFO     Training average loss at step 155600: 0.664956\n",
      "2022-11-08 10:44:57,654 INFO     Training average positive_sample_loss at step 155700: 0.954400\n",
      "2022-11-08 10:44:57,654 INFO     Training average negative_sample_loss at step 155700: 0.416284\n",
      "2022-11-08 10:44:57,654 INFO     Training average loss at step 155700: 0.685342\n",
      "2022-11-08 10:45:04,067 INFO     Training average positive_sample_loss at step 155800: 0.916687\n",
      "2022-11-08 10:45:04,067 INFO     Training average negative_sample_loss at step 155800: 0.416477\n",
      "2022-11-08 10:45:04,067 INFO     Training average loss at step 155800: 0.666582\n",
      "2022-11-08 10:45:10,451 INFO     Training average positive_sample_loss at step 155900: 0.915396\n",
      "2022-11-08 10:45:10,451 INFO     Training average negative_sample_loss at step 155900: 0.430398\n",
      "2022-11-08 10:45:10,451 INFO     Training average loss at step 155900: 0.672897\n",
      "2022-11-08 10:45:16,927 INFO     Training average positive_sample_loss at step 156000: 0.933285\n",
      "2022-11-08 10:45:16,927 INFO     Training average negative_sample_loss at step 156000: 0.420455\n",
      "2022-11-08 10:45:16,927 INFO     Training average loss at step 156000: 0.676870\n",
      "2022-11-08 10:45:23,536 INFO     Training average positive_sample_loss at step 156100: 0.931740\n",
      "2022-11-08 10:45:23,536 INFO     Training average negative_sample_loss at step 156100: 0.410317\n",
      "2022-11-08 10:45:23,536 INFO     Training average loss at step 156100: 0.671029\n",
      "2022-11-08 10:45:29,955 INFO     Training average positive_sample_loss at step 156200: 0.917090\n",
      "2022-11-08 10:45:29,955 INFO     Training average negative_sample_loss at step 156200: 0.413006\n",
      "2022-11-08 10:45:29,955 INFO     Training average loss at step 156200: 0.665048\n",
      "2022-11-08 10:45:36,341 INFO     Training average positive_sample_loss at step 156300: 0.925256\n",
      "2022-11-08 10:45:36,341 INFO     Training average negative_sample_loss at step 156300: 0.415883\n",
      "2022-11-08 10:45:36,341 INFO     Training average loss at step 156300: 0.670570\n",
      "2022-11-08 10:45:42,755 INFO     Training average positive_sample_loss at step 156400: 0.924913\n",
      "2022-11-08 10:45:42,755 INFO     Training average negative_sample_loss at step 156400: 0.414522\n",
      "2022-11-08 10:45:42,755 INFO     Training average loss at step 156400: 0.669718\n",
      "2022-11-08 10:45:49,147 INFO     Training average positive_sample_loss at step 156500: 0.946745\n",
      "2022-11-08 10:45:49,147 INFO     Training average negative_sample_loss at step 156500: 0.416978\n",
      "2022-11-08 10:45:49,147 INFO     Training average loss at step 156500: 0.681861\n",
      "2022-11-08 10:45:55,559 INFO     Training average positive_sample_loss at step 156600: 0.898475\n",
      "2022-11-08 10:45:55,559 INFO     Training average negative_sample_loss at step 156600: 0.419475\n",
      "2022-11-08 10:45:55,559 INFO     Training average loss at step 156600: 0.658975\n",
      "2022-11-08 10:46:01,981 INFO     Training average positive_sample_loss at step 156700: 0.939738\n",
      "2022-11-08 10:46:01,981 INFO     Training average negative_sample_loss at step 156700: 0.418998\n",
      "2022-11-08 10:46:01,981 INFO     Training average loss at step 156700: 0.679368\n",
      "2022-11-08 10:46:08,450 INFO     Training average positive_sample_loss at step 156800: 0.960377\n",
      "2022-11-08 10:46:08,450 INFO     Training average negative_sample_loss at step 156800: 0.410617\n",
      "2022-11-08 10:46:08,450 INFO     Training average loss at step 156800: 0.685497\n",
      "2022-11-08 10:46:14,877 INFO     Training average positive_sample_loss at step 156900: 0.937304\n",
      "2022-11-08 10:46:14,877 INFO     Training average negative_sample_loss at step 156900: 0.421434\n",
      "2022-11-08 10:46:14,877 INFO     Training average loss at step 156900: 0.679369\n",
      "2022-11-08 10:46:21,318 INFO     Training average positive_sample_loss at step 157000: 0.931605\n",
      "2022-11-08 10:46:21,319 INFO     Training average negative_sample_loss at step 157000: 0.418130\n",
      "2022-11-08 10:46:21,319 INFO     Training average loss at step 157000: 0.674867\n",
      "2022-11-08 10:46:27,742 INFO     Training average positive_sample_loss at step 157100: 0.919995\n",
      "2022-11-08 10:46:27,742 INFO     Training average negative_sample_loss at step 157100: 0.418932\n",
      "2022-11-08 10:46:27,742 INFO     Training average loss at step 157100: 0.669463\n",
      "2022-11-08 10:46:34,163 INFO     Training average positive_sample_loss at step 157200: 0.910528\n",
      "2022-11-08 10:46:34,163 INFO     Training average negative_sample_loss at step 157200: 0.422596\n",
      "2022-11-08 10:46:34,163 INFO     Training average loss at step 157200: 0.666562\n",
      "2022-11-08 10:46:40,553 INFO     Training average positive_sample_loss at step 157300: 0.940466\n",
      "2022-11-08 10:46:40,553 INFO     Training average negative_sample_loss at step 157300: 0.416298\n",
      "2022-11-08 10:46:40,553 INFO     Training average loss at step 157300: 0.678382\n",
      "2022-11-08 10:46:46,976 INFO     Training average positive_sample_loss at step 157400: 0.936413\n",
      "2022-11-08 10:46:46,976 INFO     Training average negative_sample_loss at step 157400: 0.414050\n",
      "2022-11-08 10:46:46,976 INFO     Training average loss at step 157400: 0.675231\n",
      "2022-11-08 10:46:53,425 INFO     Training average positive_sample_loss at step 157500: 0.907015\n",
      "2022-11-08 10:46:53,425 INFO     Training average negative_sample_loss at step 157500: 0.414168\n",
      "2022-11-08 10:46:53,425 INFO     Training average loss at step 157500: 0.660591\n",
      "2022-11-08 10:46:59,839 INFO     Training average positive_sample_loss at step 157600: 0.913350\n",
      "2022-11-08 10:46:59,839 INFO     Training average negative_sample_loss at step 157600: 0.423916\n",
      "2022-11-08 10:46:59,839 INFO     Training average loss at step 157600: 0.668633\n",
      "2022-11-08 10:47:06,269 INFO     Training average positive_sample_loss at step 157700: 0.987416\n",
      "2022-11-08 10:47:06,269 INFO     Training average negative_sample_loss at step 157700: 0.409635\n",
      "2022-11-08 10:47:06,269 INFO     Training average loss at step 157700: 0.698525\n",
      "2022-11-08 10:47:12,719 INFO     Training average positive_sample_loss at step 157800: 0.933471\n",
      "2022-11-08 10:47:12,719 INFO     Training average negative_sample_loss at step 157800: 0.416592\n",
      "2022-11-08 10:47:12,719 INFO     Training average loss at step 157800: 0.675032\n",
      "2022-11-08 10:47:19,139 INFO     Training average positive_sample_loss at step 157900: 0.923539\n",
      "2022-11-08 10:47:19,139 INFO     Training average negative_sample_loss at step 157900: 0.420993\n",
      "2022-11-08 10:47:19,139 INFO     Training average loss at step 157900: 0.672266\n",
      "2022-11-08 10:47:25,554 INFO     Training average positive_sample_loss at step 158000: 0.883521\n",
      "2022-11-08 10:47:25,554 INFO     Training average negative_sample_loss at step 158000: 0.420208\n",
      "2022-11-08 10:47:25,554 INFO     Training average loss at step 158000: 0.651865\n",
      "2022-11-08 10:47:31,959 INFO     Training average positive_sample_loss at step 158100: 0.924290\n",
      "2022-11-08 10:47:31,959 INFO     Training average negative_sample_loss at step 158100: 0.418924\n",
      "2022-11-08 10:47:31,959 INFO     Training average loss at step 158100: 0.671607\n",
      "2022-11-08 10:47:38,436 INFO     Training average positive_sample_loss at step 158200: 0.923210\n",
      "2022-11-08 10:47:38,436 INFO     Training average negative_sample_loss at step 158200: 0.415104\n",
      "2022-11-08 10:47:38,436 INFO     Training average loss at step 158200: 0.669157\n",
      "2022-11-08 10:47:46,094 INFO     Training average positive_sample_loss at step 158300: 0.929156\n",
      "2022-11-08 10:47:46,094 INFO     Training average negative_sample_loss at step 158300: 0.415032\n",
      "2022-11-08 10:47:46,094 INFO     Training average loss at step 158300: 0.672094\n",
      "2022-11-08 10:47:54,598 INFO     Training average positive_sample_loss at step 158400: 0.698472\n",
      "2022-11-08 10:47:54,598 INFO     Training average negative_sample_loss at step 158400: 0.410729\n",
      "2022-11-08 10:47:54,598 INFO     Training average loss at step 158400: 0.554601\n",
      "2022-11-08 10:48:01,028 INFO     Training average positive_sample_loss at step 158500: 0.679474\n",
      "2022-11-08 10:48:01,028 INFO     Training average negative_sample_loss at step 158500: 0.409071\n",
      "2022-11-08 10:48:01,028 INFO     Training average loss at step 158500: 0.544273\n",
      "2022-11-08 10:48:07,476 INFO     Training average positive_sample_loss at step 158600: 0.649875\n",
      "2022-11-08 10:48:07,477 INFO     Training average negative_sample_loss at step 158600: 0.403053\n",
      "2022-11-08 10:48:07,477 INFO     Training average loss at step 158600: 0.526464\n",
      "2022-11-08 10:48:13,970 INFO     Training average positive_sample_loss at step 158700: 0.687224\n",
      "2022-11-08 10:48:13,970 INFO     Training average negative_sample_loss at step 158700: 0.401125\n",
      "2022-11-08 10:48:13,970 INFO     Training average loss at step 158700: 0.544175\n",
      "2022-11-08 10:48:20,488 INFO     Training average positive_sample_loss at step 158800: 0.695736\n",
      "2022-11-08 10:48:20,488 INFO     Training average negative_sample_loss at step 158800: 0.391858\n",
      "2022-11-08 10:48:20,488 INFO     Training average loss at step 158800: 0.543797\n",
      "2022-11-08 10:48:27,017 INFO     Training average positive_sample_loss at step 158900: 0.678720\n",
      "2022-11-08 10:48:27,017 INFO     Training average negative_sample_loss at step 158900: 0.400691\n",
      "2022-11-08 10:48:27,017 INFO     Training average loss at step 158900: 0.539705\n",
      "2022-11-08 10:48:33,463 INFO     Training average positive_sample_loss at step 159000: 0.735200\n",
      "2022-11-08 10:48:33,463 INFO     Training average negative_sample_loss at step 159000: 0.397596\n",
      "2022-11-08 10:48:33,463 INFO     Training average loss at step 159000: 0.566398\n",
      "2022-11-08 10:48:39,905 INFO     Training average positive_sample_loss at step 159100: 0.674905\n",
      "2022-11-08 10:48:39,905 INFO     Training average negative_sample_loss at step 159100: 0.392781\n",
      "2022-11-08 10:48:39,905 INFO     Training average loss at step 159100: 0.533843\n",
      "2022-11-08 10:48:46,373 INFO     Training average positive_sample_loss at step 159200: 0.694854\n",
      "2022-11-08 10:48:46,373 INFO     Training average negative_sample_loss at step 159200: 0.392488\n",
      "2022-11-08 10:48:46,373 INFO     Training average loss at step 159200: 0.543671\n",
      "2022-11-08 10:48:52,897 INFO     Training average positive_sample_loss at step 159300: 0.699595\n",
      "2022-11-08 10:48:52,897 INFO     Training average negative_sample_loss at step 159300: 0.390997\n",
      "2022-11-08 10:48:52,897 INFO     Training average loss at step 159300: 0.545296\n",
      "2022-11-08 10:48:59,396 INFO     Training average positive_sample_loss at step 159400: 0.695774\n",
      "2022-11-08 10:48:59,396 INFO     Training average negative_sample_loss at step 159400: 0.383501\n",
      "2022-11-08 10:48:59,396 INFO     Training average loss at step 159400: 0.539638\n",
      "2022-11-08 10:49:05,879 INFO     Training average positive_sample_loss at step 159500: 0.703421\n",
      "2022-11-08 10:49:05,880 INFO     Training average negative_sample_loss at step 159500: 0.389053\n",
      "2022-11-08 10:49:05,880 INFO     Training average loss at step 159500: 0.546237\n",
      "2022-11-08 10:49:12,328 INFO     Training average positive_sample_loss at step 159600: 0.678735\n",
      "2022-11-08 10:49:12,328 INFO     Training average negative_sample_loss at step 159600: 0.385020\n",
      "2022-11-08 10:49:12,328 INFO     Training average loss at step 159600: 0.531878\n",
      "2022-11-08 10:49:18,762 INFO     Training average positive_sample_loss at step 159700: 0.694025\n",
      "2022-11-08 10:49:18,762 INFO     Training average negative_sample_loss at step 159700: 0.387612\n",
      "2022-11-08 10:49:18,762 INFO     Training average loss at step 159700: 0.540819\n",
      "2022-11-08 10:49:25,348 INFO     Training average positive_sample_loss at step 159800: 0.685579\n",
      "2022-11-08 10:49:25,348 INFO     Training average negative_sample_loss at step 159800: 0.384161\n",
      "2022-11-08 10:49:25,348 INFO     Training average loss at step 159800: 0.534870\n",
      "2022-11-08 10:49:31,063 INFO     Training average positive_sample_loss at step 159900: 0.688717\n",
      "2022-11-08 10:49:31,063 INFO     Training average negative_sample_loss at step 159900: 0.383331\n",
      "2022-11-08 10:49:31,063 INFO     Training average loss at step 159900: 0.536024\n",
      "2022-11-08 10:49:40,064 INFO     Training average positive_sample_loss at step 160000: 0.724031\n",
      "2022-11-08 10:49:40,064 INFO     Training average negative_sample_loss at step 160000: 0.387424\n",
      "2022-11-08 10:49:40,064 INFO     Training average loss at step 160000: 0.555728\n",
      "2022-11-08 10:49:46,734 INFO     Training average positive_sample_loss at step 160100: 0.702599\n",
      "2022-11-08 10:49:46,734 INFO     Training average negative_sample_loss at step 160100: 0.382821\n",
      "2022-11-08 10:49:46,734 INFO     Training average loss at step 160100: 0.542710\n",
      "2022-11-08 10:49:53,309 INFO     Training average positive_sample_loss at step 160200: 0.680204\n",
      "2022-11-08 10:49:53,309 INFO     Training average negative_sample_loss at step 160200: 0.383693\n",
      "2022-11-08 10:49:53,309 INFO     Training average loss at step 160200: 0.531949\n",
      "2022-11-08 10:49:59,771 INFO     Training average positive_sample_loss at step 160300: 0.693488\n",
      "2022-11-08 10:49:59,771 INFO     Training average negative_sample_loss at step 160300: 0.377352\n",
      "2022-11-08 10:49:59,771 INFO     Training average loss at step 160300: 0.535420\n",
      "2022-11-08 10:50:06,206 INFO     Training average positive_sample_loss at step 160400: 0.702251\n",
      "2022-11-08 10:50:06,206 INFO     Training average negative_sample_loss at step 160400: 0.378981\n",
      "2022-11-08 10:50:06,206 INFO     Training average loss at step 160400: 0.540616\n",
      "2022-11-08 10:50:12,636 INFO     Training average positive_sample_loss at step 160500: 0.702210\n",
      "2022-11-08 10:50:12,636 INFO     Training average negative_sample_loss at step 160500: 0.376002\n",
      "2022-11-08 10:50:12,636 INFO     Training average loss at step 160500: 0.539106\n",
      "2022-11-08 10:50:19,097 INFO     Training average positive_sample_loss at step 160600: 0.739739\n",
      "2022-11-08 10:50:19,097 INFO     Training average negative_sample_loss at step 160600: 0.372506\n",
      "2022-11-08 10:50:19,097 INFO     Training average loss at step 160600: 0.556123\n",
      "2022-11-08 10:50:25,523 INFO     Training average positive_sample_loss at step 160700: 0.718948\n",
      "2022-11-08 10:50:25,524 INFO     Training average negative_sample_loss at step 160700: 0.380549\n",
      "2022-11-08 10:50:25,524 INFO     Training average loss at step 160700: 0.549749\n",
      "2022-11-08 10:50:31,986 INFO     Training average positive_sample_loss at step 160800: 0.692532\n",
      "2022-11-08 10:50:31,986 INFO     Training average negative_sample_loss at step 160800: 0.380148\n",
      "2022-11-08 10:50:31,986 INFO     Training average loss at step 160800: 0.536340\n",
      "2022-11-08 10:50:38,438 INFO     Training average positive_sample_loss at step 160900: 0.714210\n",
      "2022-11-08 10:50:38,438 INFO     Training average negative_sample_loss at step 160900: 0.373698\n",
      "2022-11-08 10:50:38,438 INFO     Training average loss at step 160900: 0.543954\n",
      "2022-11-08 10:50:44,837 INFO     Training average positive_sample_loss at step 161000: 0.703214\n",
      "2022-11-08 10:50:44,837 INFO     Training average negative_sample_loss at step 161000: 0.376351\n",
      "2022-11-08 10:50:44,837 INFO     Training average loss at step 161000: 0.539783\n",
      "2022-11-08 10:50:51,269 INFO     Training average positive_sample_loss at step 161100: 0.701719\n",
      "2022-11-08 10:50:51,269 INFO     Training average negative_sample_loss at step 161100: 0.377854\n",
      "2022-11-08 10:50:51,269 INFO     Training average loss at step 161100: 0.539786\n",
      "2022-11-08 10:50:57,682 INFO     Training average positive_sample_loss at step 161200: 0.675057\n",
      "2022-11-08 10:50:57,682 INFO     Training average negative_sample_loss at step 161200: 0.373699\n",
      "2022-11-08 10:50:57,682 INFO     Training average loss at step 161200: 0.524378\n",
      "2022-11-08 10:51:04,176 INFO     Training average positive_sample_loss at step 161300: 0.670401\n",
      "2022-11-08 10:51:04,176 INFO     Training average negative_sample_loss at step 161300: 0.377734\n",
      "2022-11-08 10:51:04,176 INFO     Training average loss at step 161300: 0.524067\n",
      "2022-11-08 10:51:10,802 INFO     Training average positive_sample_loss at step 161400: 0.724855\n",
      "2022-11-08 10:51:10,802 INFO     Training average negative_sample_loss at step 161400: 0.381627\n",
      "2022-11-08 10:51:10,802 INFO     Training average loss at step 161400: 0.553241\n",
      "2022-11-08 10:51:17,410 INFO     Training average positive_sample_loss at step 161500: 0.708057\n",
      "2022-11-08 10:51:17,411 INFO     Training average negative_sample_loss at step 161500: 0.370169\n",
      "2022-11-08 10:51:17,411 INFO     Training average loss at step 161500: 0.539113\n",
      "2022-11-08 10:51:24,056 INFO     Training average positive_sample_loss at step 161600: 0.699535\n",
      "2022-11-08 10:51:24,056 INFO     Training average negative_sample_loss at step 161600: 0.370271\n",
      "2022-11-08 10:51:24,056 INFO     Training average loss at step 161600: 0.534903\n",
      "2022-11-08 10:51:30,658 INFO     Training average positive_sample_loss at step 161700: 0.698765\n",
      "2022-11-08 10:51:30,658 INFO     Training average negative_sample_loss at step 161700: 0.374498\n",
      "2022-11-08 10:51:30,658 INFO     Training average loss at step 161700: 0.536631\n",
      "2022-11-08 10:51:37,247 INFO     Training average positive_sample_loss at step 161800: 0.708368\n",
      "2022-11-08 10:51:37,248 INFO     Training average negative_sample_loss at step 161800: 0.365888\n",
      "2022-11-08 10:51:37,248 INFO     Training average loss at step 161800: 0.537128\n",
      "2022-11-08 10:51:43,882 INFO     Training average positive_sample_loss at step 161900: 0.708818\n",
      "2022-11-08 10:51:43,882 INFO     Training average negative_sample_loss at step 161900: 0.371342\n",
      "2022-11-08 10:51:43,882 INFO     Training average loss at step 161900: 0.540080\n",
      "2022-11-08 10:51:50,473 INFO     Training average positive_sample_loss at step 162000: 0.706981\n",
      "2022-11-08 10:51:50,473 INFO     Training average negative_sample_loss at step 162000: 0.371332\n",
      "2022-11-08 10:51:50,473 INFO     Training average loss at step 162000: 0.539157\n",
      "2022-11-08 10:51:57,116 INFO     Training average positive_sample_loss at step 162100: 0.717674\n",
      "2022-11-08 10:51:57,116 INFO     Training average negative_sample_loss at step 162100: 0.368200\n",
      "2022-11-08 10:51:57,116 INFO     Training average loss at step 162100: 0.542937\n",
      "2022-11-08 10:52:03,714 INFO     Training average positive_sample_loss at step 162200: 0.706422\n",
      "2022-11-08 10:52:03,714 INFO     Training average negative_sample_loss at step 162200: 0.363670\n",
      "2022-11-08 10:52:03,714 INFO     Training average loss at step 162200: 0.535046\n",
      "2022-11-08 10:52:10,345 INFO     Training average positive_sample_loss at step 162300: 0.709274\n",
      "2022-11-08 10:52:10,346 INFO     Training average negative_sample_loss at step 162300: 0.371006\n",
      "2022-11-08 10:52:10,346 INFO     Training average loss at step 162300: 0.540140\n",
      "2022-11-08 10:52:16,962 INFO     Training average positive_sample_loss at step 162400: 0.720269\n",
      "2022-11-08 10:52:16,962 INFO     Training average negative_sample_loss at step 162400: 0.378241\n",
      "2022-11-08 10:52:16,962 INFO     Training average loss at step 162400: 0.549255\n",
      "2022-11-08 10:52:23,620 INFO     Training average positive_sample_loss at step 162500: 0.716346\n",
      "2022-11-08 10:52:23,620 INFO     Training average negative_sample_loss at step 162500: 0.373981\n",
      "2022-11-08 10:52:23,620 INFO     Training average loss at step 162500: 0.545164\n",
      "2022-11-08 10:52:30,291 INFO     Training average positive_sample_loss at step 162600: 0.699920\n",
      "2022-11-08 10:52:30,291 INFO     Training average negative_sample_loss at step 162600: 0.370453\n",
      "2022-11-08 10:52:30,291 INFO     Training average loss at step 162600: 0.535186\n",
      "2022-11-08 10:52:36,929 INFO     Training average positive_sample_loss at step 162700: 0.715412\n",
      "2022-11-08 10:52:36,929 INFO     Training average negative_sample_loss at step 162700: 0.375354\n",
      "2022-11-08 10:52:36,929 INFO     Training average loss at step 162700: 0.545383\n",
      "2022-11-08 10:52:43,529 INFO     Training average positive_sample_loss at step 162800: 0.718668\n",
      "2022-11-08 10:52:43,529 INFO     Training average negative_sample_loss at step 162800: 0.371748\n",
      "2022-11-08 10:52:43,529 INFO     Training average loss at step 162800: 0.545208\n",
      "2022-11-08 10:52:50,140 INFO     Training average positive_sample_loss at step 162900: 0.713919\n",
      "2022-11-08 10:52:50,140 INFO     Training average negative_sample_loss at step 162900: 0.375630\n",
      "2022-11-08 10:52:50,140 INFO     Training average loss at step 162900: 0.544774\n",
      "2022-11-08 10:52:56,725 INFO     Training average positive_sample_loss at step 163000: 0.685893\n",
      "2022-11-08 10:52:56,725 INFO     Training average negative_sample_loss at step 163000: 0.369534\n",
      "2022-11-08 10:52:56,725 INFO     Training average loss at step 163000: 0.527713\n",
      "2022-11-08 10:53:03,317 INFO     Training average positive_sample_loss at step 163100: 0.687544\n",
      "2022-11-08 10:53:03,317 INFO     Training average negative_sample_loss at step 163100: 0.373980\n",
      "2022-11-08 10:53:03,317 INFO     Training average loss at step 163100: 0.530762\n",
      "2022-11-08 10:53:09,926 INFO     Training average positive_sample_loss at step 163200: 0.681295\n",
      "2022-11-08 10:53:09,926 INFO     Training average negative_sample_loss at step 163200: 0.374274\n",
      "2022-11-08 10:53:09,926 INFO     Training average loss at step 163200: 0.527785\n",
      "2022-11-08 10:53:16,445 INFO     Training average positive_sample_loss at step 163300: 0.698259\n",
      "2022-11-08 10:53:16,445 INFO     Training average negative_sample_loss at step 163300: 0.369960\n",
      "2022-11-08 10:53:16,445 INFO     Training average loss at step 163300: 0.534109\n",
      "2022-11-08 10:53:22,980 INFO     Training average positive_sample_loss at step 163400: 0.698964\n",
      "2022-11-08 10:53:22,981 INFO     Training average negative_sample_loss at step 163400: 0.368517\n",
      "2022-11-08 10:53:22,981 INFO     Training average loss at step 163400: 0.533740\n",
      "2022-11-08 10:53:29,508 INFO     Training average positive_sample_loss at step 163500: 0.690749\n",
      "2022-11-08 10:53:29,509 INFO     Training average negative_sample_loss at step 163500: 0.363430\n",
      "2022-11-08 10:53:29,509 INFO     Training average loss at step 163500: 0.527090\n",
      "2022-11-08 10:53:36,106 INFO     Training average positive_sample_loss at step 163600: 0.731138\n",
      "2022-11-08 10:53:36,106 INFO     Training average negative_sample_loss at step 163600: 0.364108\n",
      "2022-11-08 10:53:36,106 INFO     Training average loss at step 163600: 0.547623\n",
      "2022-11-08 10:53:42,721 INFO     Training average positive_sample_loss at step 163700: 0.731265\n",
      "2022-11-08 10:53:42,721 INFO     Training average negative_sample_loss at step 163700: 0.365297\n",
      "2022-11-08 10:53:42,721 INFO     Training average loss at step 163700: 0.548281\n",
      "2022-11-08 10:53:49,352 INFO     Training average positive_sample_loss at step 163800: 0.724242\n",
      "2022-11-08 10:53:49,352 INFO     Training average negative_sample_loss at step 163800: 0.367747\n",
      "2022-11-08 10:53:49,352 INFO     Training average loss at step 163800: 0.545994\n",
      "2022-11-08 10:53:55,963 INFO     Training average positive_sample_loss at step 163900: 0.692734\n",
      "2022-11-08 10:53:55,963 INFO     Training average negative_sample_loss at step 163900: 0.361119\n",
      "2022-11-08 10:53:55,963 INFO     Training average loss at step 163900: 0.526927\n",
      "2022-11-08 10:54:02,522 INFO     Training average positive_sample_loss at step 164000: 0.699859\n",
      "2022-11-08 10:54:02,522 INFO     Training average negative_sample_loss at step 164000: 0.373630\n",
      "2022-11-08 10:54:02,522 INFO     Training average loss at step 164000: 0.536745\n",
      "2022-11-08 10:54:09,139 INFO     Training average positive_sample_loss at step 164100: 0.689045\n",
      "2022-11-08 10:54:09,139 INFO     Training average negative_sample_loss at step 164100: 0.372345\n",
      "2022-11-08 10:54:09,139 INFO     Training average loss at step 164100: 0.530695\n",
      "2022-11-08 10:54:15,674 INFO     Training average positive_sample_loss at step 164200: 0.715177\n",
      "2022-11-08 10:54:15,674 INFO     Training average negative_sample_loss at step 164200: 0.363013\n",
      "2022-11-08 10:54:15,674 INFO     Training average loss at step 164200: 0.539095\n",
      "2022-11-08 10:54:22,215 INFO     Training average positive_sample_loss at step 164300: 0.707795\n",
      "2022-11-08 10:54:22,215 INFO     Training average negative_sample_loss at step 164300: 0.373354\n",
      "2022-11-08 10:54:22,215 INFO     Training average loss at step 164300: 0.540574\n",
      "2022-11-08 10:54:26,552 INFO     Training average positive_sample_loss at step 164400: 0.704511\n",
      "2022-11-08 10:54:26,552 INFO     Training average negative_sample_loss at step 164400: 0.368069\n",
      "2022-11-08 10:54:26,552 INFO     Training average loss at step 164400: 0.536290\n",
      "2022-11-08 10:54:32,557 INFO     Training average positive_sample_loss at step 164500: 0.718574\n",
      "2022-11-08 10:54:32,557 INFO     Training average negative_sample_loss at step 164500: 0.370088\n",
      "2022-11-08 10:54:32,557 INFO     Training average loss at step 164500: 0.544331\n",
      "2022-11-08 10:54:39,163 INFO     Training average positive_sample_loss at step 164600: 0.700907\n",
      "2022-11-08 10:54:39,163 INFO     Training average negative_sample_loss at step 164600: 0.370380\n",
      "2022-11-08 10:54:39,163 INFO     Training average loss at step 164600: 0.535643\n",
      "2022-11-08 10:54:45,725 INFO     Training average positive_sample_loss at step 164700: 0.709876\n",
      "2022-11-08 10:54:45,725 INFO     Training average negative_sample_loss at step 164700: 0.358961\n",
      "2022-11-08 10:54:45,725 INFO     Training average loss at step 164700: 0.534418\n",
      "2022-11-08 10:54:52,280 INFO     Training average positive_sample_loss at step 164800: 0.730046\n",
      "2022-11-08 10:54:52,280 INFO     Training average negative_sample_loss at step 164800: 0.361801\n",
      "2022-11-08 10:54:52,280 INFO     Training average loss at step 164800: 0.545923\n",
      "2022-11-08 10:54:58,874 INFO     Training average positive_sample_loss at step 164900: 0.707441\n",
      "2022-11-08 10:54:58,874 INFO     Training average negative_sample_loss at step 164900: 0.369232\n",
      "2022-11-08 10:54:58,874 INFO     Training average loss at step 164900: 0.538337\n",
      "2022-11-08 10:55:05,482 INFO     Training average positive_sample_loss at step 165000: 0.704718\n",
      "2022-11-08 10:55:05,483 INFO     Training average negative_sample_loss at step 165000: 0.370055\n",
      "2022-11-08 10:55:05,483 INFO     Training average loss at step 165000: 0.537386\n",
      "2022-11-08 10:55:12,038 INFO     Training average positive_sample_loss at step 165100: 0.699483\n",
      "2022-11-08 10:55:12,038 INFO     Training average negative_sample_loss at step 165100: 0.373078\n",
      "2022-11-08 10:55:12,038 INFO     Training average loss at step 165100: 0.536280\n",
      "2022-11-08 10:55:18,681 INFO     Training average positive_sample_loss at step 165200: 0.706710\n",
      "2022-11-08 10:55:18,681 INFO     Training average negative_sample_loss at step 165200: 0.367942\n",
      "2022-11-08 10:55:18,681 INFO     Training average loss at step 165200: 0.537326\n",
      "2022-11-08 10:55:25,237 INFO     Training average positive_sample_loss at step 165300: 0.699556\n",
      "2022-11-08 10:55:25,237 INFO     Training average negative_sample_loss at step 165300: 0.359608\n",
      "2022-11-08 10:55:25,237 INFO     Training average loss at step 165300: 0.529582\n",
      "2022-11-08 10:55:31,748 INFO     Training average positive_sample_loss at step 165400: 0.719395\n",
      "2022-11-08 10:55:31,748 INFO     Training average negative_sample_loss at step 165400: 0.366373\n",
      "2022-11-08 10:55:31,748 INFO     Training average loss at step 165400: 0.542884\n",
      "2022-11-08 10:55:38,276 INFO     Training average positive_sample_loss at step 165500: 0.712346\n",
      "2022-11-08 10:55:38,277 INFO     Training average negative_sample_loss at step 165500: 0.367228\n",
      "2022-11-08 10:55:38,277 INFO     Training average loss at step 165500: 0.539787\n",
      "2022-11-08 10:55:43,974 INFO     Training average positive_sample_loss at step 165600: 0.722250\n",
      "2022-11-08 10:55:43,974 INFO     Training average negative_sample_loss at step 165600: 0.376453\n",
      "2022-11-08 10:55:43,975 INFO     Training average loss at step 165600: 0.549351\n",
      "2022-11-08 10:55:50,110 INFO     Training average positive_sample_loss at step 165700: 0.716127\n",
      "2022-11-08 10:55:50,110 INFO     Training average negative_sample_loss at step 165700: 0.359006\n",
      "2022-11-08 10:55:50,110 INFO     Training average loss at step 165700: 0.537567\n",
      "2022-11-08 10:55:56,670 INFO     Training average positive_sample_loss at step 165800: 0.691709\n",
      "2022-11-08 10:55:56,670 INFO     Training average negative_sample_loss at step 165800: 0.365131\n",
      "2022-11-08 10:55:56,670 INFO     Training average loss at step 165800: 0.528420\n",
      "2022-11-08 10:56:03,193 INFO     Training average positive_sample_loss at step 165900: 0.693508\n",
      "2022-11-08 10:56:03,193 INFO     Training average negative_sample_loss at step 165900: 0.359469\n",
      "2022-11-08 10:56:03,193 INFO     Training average loss at step 165900: 0.526489\n",
      "2022-11-08 10:56:09,693 INFO     Training average positive_sample_loss at step 166000: 0.712381\n",
      "2022-11-08 10:56:09,693 INFO     Training average negative_sample_loss at step 166000: 0.365177\n",
      "2022-11-08 10:56:09,693 INFO     Training average loss at step 166000: 0.538779\n",
      "2022-11-08 10:56:16,221 INFO     Training average positive_sample_loss at step 166100: 0.695013\n",
      "2022-11-08 10:56:16,221 INFO     Training average negative_sample_loss at step 166100: 0.373439\n",
      "2022-11-08 10:56:16,221 INFO     Training average loss at step 166100: 0.534226\n",
      "2022-11-08 10:56:22,785 INFO     Training average positive_sample_loss at step 166200: 0.719548\n",
      "2022-11-08 10:56:22,786 INFO     Training average negative_sample_loss at step 166200: 0.364383\n",
      "2022-11-08 10:56:22,786 INFO     Training average loss at step 166200: 0.541966\n",
      "2022-11-08 10:56:29,322 INFO     Training average positive_sample_loss at step 166300: 0.709893\n",
      "2022-11-08 10:56:29,322 INFO     Training average negative_sample_loss at step 166300: 0.363353\n",
      "2022-11-08 10:56:29,322 INFO     Training average loss at step 166300: 0.536623\n",
      "2022-11-08 10:56:35,862 INFO     Training average positive_sample_loss at step 166400: 0.700797\n",
      "2022-11-08 10:56:35,862 INFO     Training average negative_sample_loss at step 166400: 0.366239\n",
      "2022-11-08 10:56:35,863 INFO     Training average loss at step 166400: 0.533518\n",
      "2022-11-08 10:56:42,396 INFO     Training average positive_sample_loss at step 166500: 0.724268\n",
      "2022-11-08 10:56:42,396 INFO     Training average negative_sample_loss at step 166500: 0.362222\n",
      "2022-11-08 10:56:42,396 INFO     Training average loss at step 166500: 0.543245\n",
      "2022-11-08 10:56:48,986 INFO     Training average positive_sample_loss at step 166600: 0.729633\n",
      "2022-11-08 10:56:48,986 INFO     Training average negative_sample_loss at step 166600: 0.366660\n",
      "2022-11-08 10:56:48,986 INFO     Training average loss at step 166600: 0.548146\n",
      "2022-11-08 10:56:55,571 INFO     Training average positive_sample_loss at step 166700: 0.743507\n",
      "2022-11-08 10:56:55,571 INFO     Training average negative_sample_loss at step 166700: 0.363880\n",
      "2022-11-08 10:56:55,571 INFO     Training average loss at step 166700: 0.553694\n",
      "2022-11-08 10:57:02,103 INFO     Training average positive_sample_loss at step 166800: 0.723738\n",
      "2022-11-08 10:57:02,103 INFO     Training average negative_sample_loss at step 166800: 0.364954\n",
      "2022-11-08 10:57:02,103 INFO     Training average loss at step 166800: 0.544346\n",
      "2022-11-08 10:57:08,643 INFO     Training average positive_sample_loss at step 166900: 0.703002\n",
      "2022-11-08 10:57:08,643 INFO     Training average negative_sample_loss at step 166900: 0.362335\n",
      "2022-11-08 10:57:08,643 INFO     Training average loss at step 166900: 0.532668\n",
      "2022-11-08 10:57:15,157 INFO     Training average positive_sample_loss at step 167000: 0.702067\n",
      "2022-11-08 10:57:15,157 INFO     Training average negative_sample_loss at step 167000: 0.362066\n",
      "2022-11-08 10:57:15,157 INFO     Training average loss at step 167000: 0.532067\n",
      "2022-11-08 10:57:21,647 INFO     Training average positive_sample_loss at step 167100: 0.714189\n",
      "2022-11-08 10:57:21,648 INFO     Training average negative_sample_loss at step 167100: 0.368108\n",
      "2022-11-08 10:57:21,648 INFO     Training average loss at step 167100: 0.541149\n",
      "2022-11-08 10:57:28,257 INFO     Training average positive_sample_loss at step 167200: 0.699356\n",
      "2022-11-08 10:57:28,257 INFO     Training average negative_sample_loss at step 167200: 0.368860\n",
      "2022-11-08 10:57:28,257 INFO     Training average loss at step 167200: 0.534108\n",
      "2022-11-08 10:57:34,896 INFO     Training average positive_sample_loss at step 167300: 0.699246\n",
      "2022-11-08 10:57:34,896 INFO     Training average negative_sample_loss at step 167300: 0.362973\n",
      "2022-11-08 10:57:34,896 INFO     Training average loss at step 167300: 0.531110\n",
      "2022-11-08 10:57:41,398 INFO     Training average positive_sample_loss at step 167400: 0.723224\n",
      "2022-11-08 10:57:41,398 INFO     Training average negative_sample_loss at step 167400: 0.364301\n",
      "2022-11-08 10:57:41,398 INFO     Training average loss at step 167400: 0.543763\n",
      "2022-11-08 10:57:47,917 INFO     Training average positive_sample_loss at step 167500: 0.715560\n",
      "2022-11-08 10:57:47,917 INFO     Training average negative_sample_loss at step 167500: 0.360666\n",
      "2022-11-08 10:57:47,917 INFO     Training average loss at step 167500: 0.538113\n",
      "2022-11-08 10:57:54,457 INFO     Training average positive_sample_loss at step 167600: 0.693828\n",
      "2022-11-08 10:57:54,457 INFO     Training average negative_sample_loss at step 167600: 0.360872\n",
      "2022-11-08 10:57:54,457 INFO     Training average loss at step 167600: 0.527350\n",
      "2022-11-08 10:58:01,011 INFO     Training average positive_sample_loss at step 167700: 0.725047\n",
      "2022-11-08 10:58:01,011 INFO     Training average negative_sample_loss at step 167700: 0.362374\n",
      "2022-11-08 10:58:01,011 INFO     Training average loss at step 167700: 0.543711\n",
      "2022-11-08 10:58:07,569 INFO     Training average positive_sample_loss at step 167800: 0.692758\n",
      "2022-11-08 10:58:07,569 INFO     Training average negative_sample_loss at step 167800: 0.370121\n",
      "2022-11-08 10:58:07,569 INFO     Training average loss at step 167800: 0.531440\n",
      "2022-11-08 10:58:14,159 INFO     Training average positive_sample_loss at step 167900: 0.734155\n",
      "2022-11-08 10:58:14,159 INFO     Training average negative_sample_loss at step 167900: 0.362125\n",
      "2022-11-08 10:58:14,159 INFO     Training average loss at step 167900: 0.548140\n",
      "2022-11-08 10:58:20,834 INFO     Training average positive_sample_loss at step 168000: 0.700672\n",
      "2022-11-08 10:58:20,834 INFO     Training average negative_sample_loss at step 168000: 0.365415\n",
      "2022-11-08 10:58:20,835 INFO     Training average loss at step 168000: 0.533044\n",
      "2022-11-08 10:58:27,494 INFO     Training average positive_sample_loss at step 168100: 0.698713\n",
      "2022-11-08 10:58:27,494 INFO     Training average negative_sample_loss at step 168100: 0.361544\n",
      "2022-11-08 10:58:27,494 INFO     Training average loss at step 168100: 0.530129\n",
      "2022-11-08 10:58:34,181 INFO     Training average positive_sample_loss at step 168200: 0.680562\n",
      "2022-11-08 10:58:34,181 INFO     Training average negative_sample_loss at step 168200: 0.366791\n",
      "2022-11-08 10:58:34,181 INFO     Training average loss at step 168200: 0.523676\n",
      "2022-11-08 10:58:40,821 INFO     Training average positive_sample_loss at step 168300: 0.702669\n",
      "2022-11-08 10:58:40,821 INFO     Training average negative_sample_loss at step 168300: 0.361664\n",
      "2022-11-08 10:58:40,821 INFO     Training average loss at step 168300: 0.532167\n",
      "2022-11-08 10:58:47,384 INFO     Training average positive_sample_loss at step 168400: 0.717974\n",
      "2022-11-08 10:58:47,384 INFO     Training average negative_sample_loss at step 168400: 0.355581\n",
      "2022-11-08 10:58:47,384 INFO     Training average loss at step 168400: 0.536778\n",
      "2022-11-08 10:58:53,928 INFO     Training average positive_sample_loss at step 168500: 0.708905\n",
      "2022-11-08 10:58:53,928 INFO     Training average negative_sample_loss at step 168500: 0.361499\n",
      "2022-11-08 10:58:53,928 INFO     Training average loss at step 168500: 0.535202\n",
      "2022-11-08 10:59:03,834 INFO     Training average positive_sample_loss at step 168600: 0.699013\n",
      "2022-11-08 10:59:03,834 INFO     Training average negative_sample_loss at step 168600: 0.366541\n",
      "2022-11-08 10:59:03,834 INFO     Training average loss at step 168600: 0.532777\n",
      "2022-11-08 10:59:10,392 INFO     Training average positive_sample_loss at step 168700: 0.719101\n",
      "2022-11-08 10:59:10,392 INFO     Training average negative_sample_loss at step 168700: 0.363190\n",
      "2022-11-08 10:59:10,392 INFO     Training average loss at step 168700: 0.541146\n",
      "2022-11-08 10:59:16,978 INFO     Training average positive_sample_loss at step 168800: 0.706079\n",
      "2022-11-08 10:59:16,978 INFO     Training average negative_sample_loss at step 168800: 0.363957\n",
      "2022-11-08 10:59:16,978 INFO     Training average loss at step 168800: 0.535018\n",
      "2022-11-08 10:59:23,546 INFO     Training average positive_sample_loss at step 168900: 0.717899\n",
      "2022-11-08 10:59:23,546 INFO     Training average negative_sample_loss at step 168900: 0.355744\n",
      "2022-11-08 10:59:23,547 INFO     Training average loss at step 168900: 0.536822\n",
      "2022-11-08 10:59:30,167 INFO     Training average positive_sample_loss at step 169000: 0.729027\n",
      "2022-11-08 10:59:30,167 INFO     Training average negative_sample_loss at step 169000: 0.359513\n",
      "2022-11-08 10:59:30,167 INFO     Training average loss at step 169000: 0.544270\n",
      "2022-11-08 10:59:36,740 INFO     Training average positive_sample_loss at step 169100: 0.672962\n",
      "2022-11-08 10:59:36,740 INFO     Training average negative_sample_loss at step 169100: 0.359787\n",
      "2022-11-08 10:59:36,740 INFO     Training average loss at step 169100: 0.516375\n",
      "2022-11-08 10:59:43,323 INFO     Training average positive_sample_loss at step 169200: 0.710296\n",
      "2022-11-08 10:59:43,323 INFO     Training average negative_sample_loss at step 169200: 0.364715\n",
      "2022-11-08 10:59:43,323 INFO     Training average loss at step 169200: 0.537506\n",
      "2022-11-08 10:59:49,852 INFO     Training average positive_sample_loss at step 169300: 0.720362\n",
      "2022-11-08 10:59:49,852 INFO     Training average negative_sample_loss at step 169300: 0.358265\n",
      "2022-11-08 10:59:49,852 INFO     Training average loss at step 169300: 0.539313\n",
      "2022-11-08 10:59:56,321 INFO     Training average positive_sample_loss at step 169400: 0.712907\n",
      "2022-11-08 10:59:56,321 INFO     Training average negative_sample_loss at step 169400: 0.361459\n",
      "2022-11-08 10:59:56,321 INFO     Training average loss at step 169400: 0.537183\n",
      "2022-11-08 11:00:02,793 INFO     Training average positive_sample_loss at step 169500: 0.720022\n",
      "2022-11-08 11:00:02,793 INFO     Training average negative_sample_loss at step 169500: 0.357829\n",
      "2022-11-08 11:00:02,793 INFO     Training average loss at step 169500: 0.538925\n",
      "2022-11-08 11:00:09,304 INFO     Training average positive_sample_loss at step 169600: 0.693571\n",
      "2022-11-08 11:00:09,304 INFO     Training average negative_sample_loss at step 169600: 0.368470\n",
      "2022-11-08 11:00:09,304 INFO     Training average loss at step 169600: 0.531021\n",
      "2022-11-08 11:00:15,749 INFO     Training average positive_sample_loss at step 169700: 0.706701\n",
      "2022-11-08 11:00:15,749 INFO     Training average negative_sample_loss at step 169700: 0.359483\n",
      "2022-11-08 11:00:15,749 INFO     Training average loss at step 169700: 0.533092\n",
      "2022-11-08 11:00:22,179 INFO     Training average positive_sample_loss at step 169800: 0.707951\n",
      "2022-11-08 11:00:22,179 INFO     Training average negative_sample_loss at step 169800: 0.357693\n",
      "2022-11-08 11:00:22,179 INFO     Training average loss at step 169800: 0.532822\n",
      "2022-11-08 11:00:28,633 INFO     Training average positive_sample_loss at step 169900: 0.726463\n",
      "2022-11-08 11:00:28,633 INFO     Training average negative_sample_loss at step 169900: 0.363550\n",
      "2022-11-08 11:00:28,633 INFO     Training average loss at step 169900: 0.545007\n",
      "2022-11-08 11:00:37,812 INFO     Training average positive_sample_loss at step 170000: 0.722926\n",
      "2022-11-08 11:00:37,812 INFO     Training average negative_sample_loss at step 170000: 0.357466\n",
      "2022-11-08 11:00:37,812 INFO     Training average loss at step 170000: 0.540196\n",
      "2022-11-08 11:00:44,264 INFO     Training average positive_sample_loss at step 170100: 0.704525\n",
      "2022-11-08 11:00:44,264 INFO     Training average negative_sample_loss at step 170100: 0.361620\n",
      "2022-11-08 11:00:44,265 INFO     Training average loss at step 170100: 0.533072\n",
      "2022-11-08 11:00:50,704 INFO     Training average positive_sample_loss at step 170200: 0.696081\n",
      "2022-11-08 11:00:50,704 INFO     Training average negative_sample_loss at step 170200: 0.362937\n",
      "2022-11-08 11:00:50,704 INFO     Training average loss at step 170200: 0.529509\n",
      "2022-11-08 11:00:57,122 INFO     Training average positive_sample_loss at step 170300: 0.703401\n",
      "2022-11-08 11:00:57,122 INFO     Training average negative_sample_loss at step 170300: 0.362964\n",
      "2022-11-08 11:00:57,122 INFO     Training average loss at step 170300: 0.533182\n",
      "2022-11-08 11:01:03,538 INFO     Training average positive_sample_loss at step 170400: 0.719071\n",
      "2022-11-08 11:01:03,538 INFO     Training average negative_sample_loss at step 170400: 0.359044\n",
      "2022-11-08 11:01:03,538 INFO     Training average loss at step 170400: 0.539058\n",
      "2022-11-08 11:01:09,962 INFO     Training average positive_sample_loss at step 170500: 0.726610\n",
      "2022-11-08 11:01:09,962 INFO     Training average negative_sample_loss at step 170500: 0.364921\n",
      "2022-11-08 11:01:09,962 INFO     Training average loss at step 170500: 0.545765\n",
      "2022-11-08 11:01:16,476 INFO     Training average positive_sample_loss at step 170600: 0.730405\n",
      "2022-11-08 11:01:16,477 INFO     Training average negative_sample_loss at step 170600: 0.356426\n",
      "2022-11-08 11:01:16,477 INFO     Training average loss at step 170600: 0.543416\n",
      "2022-11-08 11:01:22,946 INFO     Training average positive_sample_loss at step 170700: 0.720047\n",
      "2022-11-08 11:01:22,946 INFO     Training average negative_sample_loss at step 170700: 0.356439\n",
      "2022-11-08 11:01:22,946 INFO     Training average loss at step 170700: 0.538243\n",
      "2022-11-08 11:01:29,411 INFO     Training average positive_sample_loss at step 170800: 0.706558\n",
      "2022-11-08 11:01:29,411 INFO     Training average negative_sample_loss at step 170800: 0.357323\n",
      "2022-11-08 11:01:29,411 INFO     Training average loss at step 170800: 0.531941\n",
      "2022-11-08 11:01:35,907 INFO     Training average positive_sample_loss at step 170900: 0.708128\n",
      "2022-11-08 11:01:35,907 INFO     Training average negative_sample_loss at step 170900: 0.359917\n",
      "2022-11-08 11:01:35,907 INFO     Training average loss at step 170900: 0.534023\n",
      "2022-11-08 11:01:42,425 INFO     Training average positive_sample_loss at step 171000: 0.701327\n",
      "2022-11-08 11:01:42,425 INFO     Training average negative_sample_loss at step 171000: 0.364418\n",
      "2022-11-08 11:01:42,425 INFO     Training average loss at step 171000: 0.532873\n",
      "2022-11-08 11:01:48,537 INFO     Training average positive_sample_loss at step 171100: 0.703025\n",
      "2022-11-08 11:01:48,537 INFO     Training average negative_sample_loss at step 171100: 0.359312\n",
      "2022-11-08 11:01:48,537 INFO     Training average loss at step 171100: 0.531168\n",
      "2022-11-08 11:01:53,983 INFO     Training average positive_sample_loss at step 171200: 0.709371\n",
      "2022-11-08 11:01:53,983 INFO     Training average negative_sample_loss at step 171200: 0.364468\n",
      "2022-11-08 11:01:53,983 INFO     Training average loss at step 171200: 0.536919\n",
      "2022-11-08 11:02:00,386 INFO     Training average positive_sample_loss at step 171300: 0.714433\n",
      "2022-11-08 11:02:00,386 INFO     Training average negative_sample_loss at step 171300: 0.351199\n",
      "2022-11-08 11:02:00,386 INFO     Training average loss at step 171300: 0.532816\n",
      "2022-11-08 11:02:06,807 INFO     Training average positive_sample_loss at step 171400: 0.686562\n",
      "2022-11-08 11:02:06,807 INFO     Training average negative_sample_loss at step 171400: 0.359474\n",
      "2022-11-08 11:02:06,807 INFO     Training average loss at step 171400: 0.523018\n",
      "2022-11-08 11:02:13,196 INFO     Training average positive_sample_loss at step 171500: 0.714893\n",
      "2022-11-08 11:02:13,196 INFO     Training average negative_sample_loss at step 171500: 0.350000\n",
      "2022-11-08 11:02:13,196 INFO     Training average loss at step 171500: 0.532447\n",
      "2022-11-08 11:02:19,628 INFO     Training average positive_sample_loss at step 171600: 0.705113\n",
      "2022-11-08 11:02:19,628 INFO     Training average negative_sample_loss at step 171600: 0.364075\n",
      "2022-11-08 11:02:19,628 INFO     Training average loss at step 171600: 0.534594\n",
      "2022-11-08 11:02:26,088 INFO     Training average positive_sample_loss at step 171700: 0.709575\n",
      "2022-11-08 11:02:26,088 INFO     Training average negative_sample_loss at step 171700: 0.354533\n",
      "2022-11-08 11:02:26,088 INFO     Training average loss at step 171700: 0.532054\n",
      "2022-11-08 11:02:32,527 INFO     Training average positive_sample_loss at step 171800: 0.694688\n",
      "2022-11-08 11:02:32,527 INFO     Training average negative_sample_loss at step 171800: 0.360184\n",
      "2022-11-08 11:02:32,527 INFO     Training average loss at step 171800: 0.527436\n",
      "2022-11-08 11:02:38,948 INFO     Training average positive_sample_loss at step 171900: 0.725002\n",
      "2022-11-08 11:02:38,948 INFO     Training average negative_sample_loss at step 171900: 0.355228\n",
      "2022-11-08 11:02:38,948 INFO     Training average loss at step 171900: 0.540115\n",
      "2022-11-08 11:02:45,340 INFO     Training average positive_sample_loss at step 172000: 0.714599\n",
      "2022-11-08 11:02:45,340 INFO     Training average negative_sample_loss at step 172000: 0.357634\n",
      "2022-11-08 11:02:45,340 INFO     Training average loss at step 172000: 0.536117\n",
      "2022-11-08 11:02:51,754 INFO     Training average positive_sample_loss at step 172100: 0.679229\n",
      "2022-11-08 11:02:51,754 INFO     Training average negative_sample_loss at step 172100: 0.357741\n",
      "2022-11-08 11:02:51,754 INFO     Training average loss at step 172100: 0.518485\n",
      "2022-11-08 11:02:58,239 INFO     Training average positive_sample_loss at step 172200: 0.712579\n",
      "2022-11-08 11:02:58,239 INFO     Training average negative_sample_loss at step 172200: 0.359234\n",
      "2022-11-08 11:02:58,239 INFO     Training average loss at step 172200: 0.535907\n",
      "2022-11-08 11:03:04,710 INFO     Training average positive_sample_loss at step 172300: 0.728068\n",
      "2022-11-08 11:03:04,710 INFO     Training average negative_sample_loss at step 172300: 0.355588\n",
      "2022-11-08 11:03:04,710 INFO     Training average loss at step 172300: 0.541828\n",
      "2022-11-08 11:03:11,230 INFO     Training average positive_sample_loss at step 172400: 0.695371\n",
      "2022-11-08 11:03:11,230 INFO     Training average negative_sample_loss at step 172400: 0.353951\n",
      "2022-11-08 11:03:11,230 INFO     Training average loss at step 172400: 0.524661\n",
      "2022-11-08 11:03:17,696 INFO     Training average positive_sample_loss at step 172500: 0.714583\n",
      "2022-11-08 11:03:17,696 INFO     Training average negative_sample_loss at step 172500: 0.353407\n",
      "2022-11-08 11:03:17,696 INFO     Training average loss at step 172500: 0.533995\n",
      "2022-11-08 11:03:24,207 INFO     Training average positive_sample_loss at step 172600: 0.697118\n",
      "2022-11-08 11:03:24,207 INFO     Training average negative_sample_loss at step 172600: 0.353184\n",
      "2022-11-08 11:03:24,207 INFO     Training average loss at step 172600: 0.525151\n",
      "2022-11-08 11:03:30,635 INFO     Training average positive_sample_loss at step 172700: 0.695446\n",
      "2022-11-08 11:03:30,635 INFO     Training average negative_sample_loss at step 172700: 0.355850\n",
      "2022-11-08 11:03:30,635 INFO     Training average loss at step 172700: 0.525648\n",
      "2022-11-08 11:03:37,134 INFO     Training average positive_sample_loss at step 172800: 0.697543\n",
      "2022-11-08 11:03:37,134 INFO     Training average negative_sample_loss at step 172800: 0.355794\n",
      "2022-11-08 11:03:37,134 INFO     Training average loss at step 172800: 0.526668\n",
      "2022-11-08 11:03:43,740 INFO     Training average positive_sample_loss at step 172900: 0.740187\n",
      "2022-11-08 11:03:43,740 INFO     Training average negative_sample_loss at step 172900: 0.357045\n",
      "2022-11-08 11:03:43,740 INFO     Training average loss at step 172900: 0.548616\n",
      "2022-11-08 11:03:50,248 INFO     Training average positive_sample_loss at step 173000: 0.690364\n",
      "2022-11-08 11:03:50,248 INFO     Training average negative_sample_loss at step 173000: 0.356563\n",
      "2022-11-08 11:03:50,248 INFO     Training average loss at step 173000: 0.523463\n",
      "2022-11-08 11:03:56,715 INFO     Training average positive_sample_loss at step 173100: 0.669750\n",
      "2022-11-08 11:03:56,716 INFO     Training average negative_sample_loss at step 173100: 0.358340\n",
      "2022-11-08 11:03:56,716 INFO     Training average loss at step 173100: 0.514045\n",
      "2022-11-08 11:04:04,872 INFO     Training average positive_sample_loss at step 173200: 0.702662\n",
      "2022-11-08 11:04:04,872 INFO     Training average negative_sample_loss at step 173200: 0.357161\n",
      "2022-11-08 11:04:04,872 INFO     Training average loss at step 173200: 0.529911\n",
      "2022-11-08 11:04:12,978 INFO     Training average positive_sample_loss at step 173300: 0.701759\n",
      "2022-11-08 11:04:12,979 INFO     Training average negative_sample_loss at step 173300: 0.358969\n",
      "2022-11-08 11:04:12,979 INFO     Training average loss at step 173300: 0.530364\n",
      "2022-11-08 11:04:19,367 INFO     Training average positive_sample_loss at step 173400: 0.672003\n",
      "2022-11-08 11:04:19,367 INFO     Training average negative_sample_loss at step 173400: 0.354140\n",
      "2022-11-08 11:04:19,367 INFO     Training average loss at step 173400: 0.513071\n",
      "2022-11-08 11:04:25,798 INFO     Training average positive_sample_loss at step 173500: 0.692146\n",
      "2022-11-08 11:04:25,798 INFO     Training average negative_sample_loss at step 173500: 0.354997\n",
      "2022-11-08 11:04:25,798 INFO     Training average loss at step 173500: 0.523572\n",
      "2022-11-08 11:04:32,256 INFO     Training average positive_sample_loss at step 173600: 0.713670\n",
      "2022-11-08 11:04:32,256 INFO     Training average negative_sample_loss at step 173600: 0.357242\n",
      "2022-11-08 11:04:32,256 INFO     Training average loss at step 173600: 0.535456\n",
      "2022-11-08 11:04:38,674 INFO     Training average positive_sample_loss at step 173700: 0.709769\n",
      "2022-11-08 11:04:38,674 INFO     Training average negative_sample_loss at step 173700: 0.353694\n",
      "2022-11-08 11:04:38,674 INFO     Training average loss at step 173700: 0.531731\n",
      "2022-11-08 11:04:45,378 INFO     Training average positive_sample_loss at step 173800: 0.724072\n",
      "2022-11-08 11:04:45,379 INFO     Training average negative_sample_loss at step 173800: 0.351299\n",
      "2022-11-08 11:04:45,379 INFO     Training average loss at step 173800: 0.537685\n",
      "2022-11-08 11:04:51,910 INFO     Training average positive_sample_loss at step 173900: 0.720550\n",
      "2022-11-08 11:04:51,910 INFO     Training average negative_sample_loss at step 173900: 0.355451\n",
      "2022-11-08 11:04:51,910 INFO     Training average loss at step 173900: 0.538000\n",
      "2022-11-08 11:04:58,463 INFO     Training average positive_sample_loss at step 174000: 0.683972\n",
      "2022-11-08 11:04:58,463 INFO     Training average negative_sample_loss at step 174000: 0.355419\n",
      "2022-11-08 11:04:58,463 INFO     Training average loss at step 174000: 0.519695\n",
      "2022-11-08 11:05:04,984 INFO     Training average positive_sample_loss at step 174100: 0.698079\n",
      "2022-11-08 11:05:04,984 INFO     Training average negative_sample_loss at step 174100: 0.347312\n",
      "2022-11-08 11:05:04,984 INFO     Training average loss at step 174100: 0.522695\n",
      "2022-11-08 11:05:11,478 INFO     Training average positive_sample_loss at step 174200: 0.707953\n",
      "2022-11-08 11:05:11,478 INFO     Training average negative_sample_loss at step 174200: 0.350918\n",
      "2022-11-08 11:05:11,478 INFO     Training average loss at step 174200: 0.529435\n",
      "2022-11-08 11:05:18,039 INFO     Training average positive_sample_loss at step 174300: 0.693864\n",
      "2022-11-08 11:05:18,039 INFO     Training average negative_sample_loss at step 174300: 0.350305\n",
      "2022-11-08 11:05:18,039 INFO     Training average loss at step 174300: 0.522085\n",
      "2022-11-08 11:05:24,495 INFO     Training average positive_sample_loss at step 174400: 0.696422\n",
      "2022-11-08 11:05:24,495 INFO     Training average negative_sample_loss at step 174400: 0.356841\n",
      "2022-11-08 11:05:24,495 INFO     Training average loss at step 174400: 0.526631\n",
      "2022-11-08 11:05:30,919 INFO     Training average positive_sample_loss at step 174500: 0.697908\n",
      "2022-11-08 11:05:30,919 INFO     Training average negative_sample_loss at step 174500: 0.352713\n",
      "2022-11-08 11:05:30,919 INFO     Training average loss at step 174500: 0.525311\n",
      "2022-11-08 11:05:37,428 INFO     Training average positive_sample_loss at step 174600: 0.727740\n",
      "2022-11-08 11:05:37,428 INFO     Training average negative_sample_loss at step 174600: 0.351953\n",
      "2022-11-08 11:05:37,428 INFO     Training average loss at step 174600: 0.539846\n",
      "2022-11-08 11:05:43,893 INFO     Training average positive_sample_loss at step 174700: 0.727527\n",
      "2022-11-08 11:05:43,893 INFO     Training average negative_sample_loss at step 174700: 0.352047\n",
      "2022-11-08 11:05:43,893 INFO     Training average loss at step 174700: 0.539787\n",
      "2022-11-08 11:05:50,322 INFO     Training average positive_sample_loss at step 174800: 0.730302\n",
      "2022-11-08 11:05:50,322 INFO     Training average negative_sample_loss at step 174800: 0.351597\n",
      "2022-11-08 11:05:50,322 INFO     Training average loss at step 174800: 0.540949\n",
      "2022-11-08 11:05:56,758 INFO     Training average positive_sample_loss at step 174900: 0.710218\n",
      "2022-11-08 11:05:56,758 INFO     Training average negative_sample_loss at step 174900: 0.354993\n",
      "2022-11-08 11:05:56,758 INFO     Training average loss at step 174900: 0.532606\n",
      "2022-11-08 11:06:03,207 INFO     Training average positive_sample_loss at step 175000: 0.701835\n",
      "2022-11-08 11:06:03,207 INFO     Training average negative_sample_loss at step 175000: 0.355999\n",
      "2022-11-08 11:06:03,207 INFO     Training average loss at step 175000: 0.528917\n",
      "2022-11-08 11:06:09,651 INFO     Training average positive_sample_loss at step 175100: 0.705847\n",
      "2022-11-08 11:06:09,651 INFO     Training average negative_sample_loss at step 175100: 0.351047\n",
      "2022-11-08 11:06:09,651 INFO     Training average loss at step 175100: 0.528447\n",
      "2022-11-08 11:06:16,061 INFO     Training average positive_sample_loss at step 175200: 0.675345\n",
      "2022-11-08 11:06:16,061 INFO     Training average negative_sample_loss at step 175200: 0.354676\n",
      "2022-11-08 11:06:16,061 INFO     Training average loss at step 175200: 0.515010\n",
      "2022-11-08 11:06:22,520 INFO     Training average positive_sample_loss at step 175300: 0.696635\n",
      "2022-11-08 11:06:22,520 INFO     Training average negative_sample_loss at step 175300: 0.346669\n",
      "2022-11-08 11:06:22,520 INFO     Training average loss at step 175300: 0.521652\n",
      "2022-11-08 11:06:28,928 INFO     Training average positive_sample_loss at step 175400: 0.707197\n",
      "2022-11-08 11:06:28,928 INFO     Training average negative_sample_loss at step 175400: 0.355514\n",
      "2022-11-08 11:06:28,928 INFO     Training average loss at step 175400: 0.531356\n",
      "2022-11-08 11:06:35,364 INFO     Training average positive_sample_loss at step 175500: 0.715902\n",
      "2022-11-08 11:06:35,364 INFO     Training average negative_sample_loss at step 175500: 0.354510\n",
      "2022-11-08 11:06:35,364 INFO     Training average loss at step 175500: 0.535206\n",
      "2022-11-08 11:06:41,789 INFO     Training average positive_sample_loss at step 175600: 0.699041\n",
      "2022-11-08 11:06:41,789 INFO     Training average negative_sample_loss at step 175600: 0.353720\n",
      "2022-11-08 11:06:41,789 INFO     Training average loss at step 175600: 0.526380\n",
      "2022-11-08 11:06:48,254 INFO     Training average positive_sample_loss at step 175700: 0.681418\n",
      "2022-11-08 11:06:48,254 INFO     Training average negative_sample_loss at step 175700: 0.361732\n",
      "2022-11-08 11:06:48,254 INFO     Training average loss at step 175700: 0.521575\n",
      "2022-11-08 11:06:54,687 INFO     Training average positive_sample_loss at step 175800: 0.695567\n",
      "2022-11-08 11:06:54,688 INFO     Training average negative_sample_loss at step 175800: 0.353423\n",
      "2022-11-08 11:06:54,688 INFO     Training average loss at step 175800: 0.524495\n",
      "2022-11-08 11:07:01,128 INFO     Training average positive_sample_loss at step 175900: 0.699952\n",
      "2022-11-08 11:07:01,129 INFO     Training average negative_sample_loss at step 175900: 0.352109\n",
      "2022-11-08 11:07:01,129 INFO     Training average loss at step 175900: 0.526030\n",
      "2022-11-08 11:07:07,699 INFO     Training average positive_sample_loss at step 176000: 0.685562\n",
      "2022-11-08 11:07:07,699 INFO     Training average negative_sample_loss at step 176000: 0.354611\n",
      "2022-11-08 11:07:07,699 INFO     Training average loss at step 176000: 0.520087\n",
      "2022-11-08 11:07:14,178 INFO     Training average positive_sample_loss at step 176100: 0.681922\n",
      "2022-11-08 11:07:14,178 INFO     Training average negative_sample_loss at step 176100: 0.351195\n",
      "2022-11-08 11:07:14,178 INFO     Training average loss at step 176100: 0.516559\n",
      "2022-11-08 11:07:20,614 INFO     Training average positive_sample_loss at step 176200: 0.682395\n",
      "2022-11-08 11:07:20,614 INFO     Training average negative_sample_loss at step 176200: 0.361103\n",
      "2022-11-08 11:07:20,614 INFO     Training average loss at step 176200: 0.521749\n",
      "2022-11-08 11:07:27,023 INFO     Training average positive_sample_loss at step 176300: 0.684886\n",
      "2022-11-08 11:07:27,023 INFO     Training average negative_sample_loss at step 176300: 0.353048\n",
      "2022-11-08 11:07:27,023 INFO     Training average loss at step 176300: 0.518967\n",
      "2022-11-08 11:07:33,492 INFO     Training average positive_sample_loss at step 176400: 0.723418\n",
      "2022-11-08 11:07:33,492 INFO     Training average negative_sample_loss at step 176400: 0.354180\n",
      "2022-11-08 11:07:33,492 INFO     Training average loss at step 176400: 0.538799\n",
      "2022-11-08 11:07:39,992 INFO     Training average positive_sample_loss at step 176500: 0.689678\n",
      "2022-11-08 11:07:39,992 INFO     Training average negative_sample_loss at step 176500: 0.349481\n",
      "2022-11-08 11:07:39,993 INFO     Training average loss at step 176500: 0.519579\n",
      "2022-11-08 11:07:46,514 INFO     Training average positive_sample_loss at step 176600: 0.689832\n",
      "2022-11-08 11:07:46,514 INFO     Training average negative_sample_loss at step 176600: 0.358404\n",
      "2022-11-08 11:07:46,514 INFO     Training average loss at step 176600: 0.524118\n",
      "2022-11-08 11:07:52,956 INFO     Training average positive_sample_loss at step 176700: 0.708773\n",
      "2022-11-08 11:07:52,956 INFO     Training average negative_sample_loss at step 176700: 0.355088\n",
      "2022-11-08 11:07:52,956 INFO     Training average loss at step 176700: 0.531931\n",
      "2022-11-08 11:07:58,118 INFO     Training average positive_sample_loss at step 176800: 0.687240\n",
      "2022-11-08 11:07:58,118 INFO     Training average negative_sample_loss at step 176800: 0.347900\n",
      "2022-11-08 11:07:58,118 INFO     Training average loss at step 176800: 0.517570\n",
      "2022-11-08 11:08:04,615 INFO     Training average positive_sample_loss at step 176900: 0.694992\n",
      "2022-11-08 11:08:04,615 INFO     Training average negative_sample_loss at step 176900: 0.349725\n",
      "2022-11-08 11:08:04,615 INFO     Training average loss at step 176900: 0.522358\n",
      "2022-11-08 11:08:11,152 INFO     Training average positive_sample_loss at step 177000: 0.716891\n",
      "2022-11-08 11:08:11,152 INFO     Training average negative_sample_loss at step 177000: 0.352387\n",
      "2022-11-08 11:08:11,152 INFO     Training average loss at step 177000: 0.534639\n",
      "2022-11-08 11:08:17,648 INFO     Training average positive_sample_loss at step 177100: 0.701834\n",
      "2022-11-08 11:08:17,648 INFO     Training average negative_sample_loss at step 177100: 0.350118\n",
      "2022-11-08 11:08:17,648 INFO     Training average loss at step 177100: 0.525976\n",
      "2022-11-08 11:08:24,134 INFO     Training average positive_sample_loss at step 177200: 0.689472\n",
      "2022-11-08 11:08:24,134 INFO     Training average negative_sample_loss at step 177200: 0.358161\n",
      "2022-11-08 11:08:24,134 INFO     Training average loss at step 177200: 0.523816\n",
      "2022-11-08 11:08:30,603 INFO     Training average positive_sample_loss at step 177300: 0.694448\n",
      "2022-11-08 11:08:30,603 INFO     Training average negative_sample_loss at step 177300: 0.350079\n",
      "2022-11-08 11:08:30,603 INFO     Training average loss at step 177300: 0.522264\n",
      "2022-11-08 11:08:37,068 INFO     Training average positive_sample_loss at step 177400: 0.692247\n",
      "2022-11-08 11:08:37,068 INFO     Training average negative_sample_loss at step 177400: 0.353195\n",
      "2022-11-08 11:08:37,068 INFO     Training average loss at step 177400: 0.522721\n",
      "2022-11-08 11:08:43,634 INFO     Training average positive_sample_loss at step 177500: 0.715005\n",
      "2022-11-08 11:08:43,634 INFO     Training average negative_sample_loss at step 177500: 0.346600\n",
      "2022-11-08 11:08:43,634 INFO     Training average loss at step 177500: 0.530803\n",
      "2022-11-08 11:08:50,121 INFO     Training average positive_sample_loss at step 177600: 0.695729\n",
      "2022-11-08 11:08:50,121 INFO     Training average negative_sample_loss at step 177600: 0.353608\n",
      "2022-11-08 11:08:50,121 INFO     Training average loss at step 177600: 0.524669\n",
      "2022-11-08 11:08:56,507 INFO     Training average positive_sample_loss at step 177700: 0.728972\n",
      "2022-11-08 11:08:56,507 INFO     Training average negative_sample_loss at step 177700: 0.350358\n",
      "2022-11-08 11:08:56,507 INFO     Training average loss at step 177700: 0.539665\n",
      "2022-11-08 11:09:05,644 INFO     Training average positive_sample_loss at step 177800: 0.720462\n",
      "2022-11-08 11:09:05,644 INFO     Training average negative_sample_loss at step 177800: 0.350044\n",
      "2022-11-08 11:09:05,644 INFO     Training average loss at step 177800: 0.535253\n",
      "2022-11-08 11:09:12,108 INFO     Training average positive_sample_loss at step 177900: 0.693678\n",
      "2022-11-08 11:09:12,108 INFO     Training average negative_sample_loss at step 177900: 0.352305\n",
      "2022-11-08 11:09:12,108 INFO     Training average loss at step 177900: 0.522992\n",
      "2022-11-08 11:09:19,137 INFO     Training average positive_sample_loss at step 178000: 0.689427\n",
      "2022-11-08 11:09:19,138 INFO     Training average negative_sample_loss at step 178000: 0.347989\n",
      "2022-11-08 11:09:19,138 INFO     Training average loss at step 178000: 0.518708\n",
      "2022-11-08 11:09:25,663 INFO     Training average positive_sample_loss at step 178100: 0.730309\n",
      "2022-11-08 11:09:25,663 INFO     Training average negative_sample_loss at step 178100: 0.352896\n",
      "2022-11-08 11:09:25,663 INFO     Training average loss at step 178100: 0.541603\n",
      "2022-11-08 11:09:32,164 INFO     Training average positive_sample_loss at step 178200: 0.710951\n",
      "2022-11-08 11:09:32,164 INFO     Training average negative_sample_loss at step 178200: 0.352893\n",
      "2022-11-08 11:09:32,164 INFO     Training average loss at step 178200: 0.531922\n",
      "2022-11-08 11:09:38,744 INFO     Training average positive_sample_loss at step 178300: 0.714717\n",
      "2022-11-08 11:09:38,744 INFO     Training average negative_sample_loss at step 178300: 0.349543\n",
      "2022-11-08 11:09:38,744 INFO     Training average loss at step 178300: 0.532130\n",
      "2022-11-08 11:09:45,271 INFO     Training average positive_sample_loss at step 178400: 0.711356\n",
      "2022-11-08 11:09:45,271 INFO     Training average negative_sample_loss at step 178400: 0.347550\n",
      "2022-11-08 11:09:45,271 INFO     Training average loss at step 178400: 0.529453\n",
      "2022-11-08 11:09:51,830 INFO     Training average positive_sample_loss at step 178500: 0.676184\n",
      "2022-11-08 11:09:51,830 INFO     Training average negative_sample_loss at step 178500: 0.350680\n",
      "2022-11-08 11:09:51,830 INFO     Training average loss at step 178500: 0.513432\n",
      "2022-11-08 11:09:58,373 INFO     Training average positive_sample_loss at step 178600: 0.694952\n",
      "2022-11-08 11:09:58,373 INFO     Training average negative_sample_loss at step 178600: 0.348729\n",
      "2022-11-08 11:09:58,373 INFO     Training average loss at step 178600: 0.521840\n",
      "2022-11-08 11:10:04,892 INFO     Training average positive_sample_loss at step 178700: 0.732648\n",
      "2022-11-08 11:10:04,892 INFO     Training average negative_sample_loss at step 178700: 0.345918\n",
      "2022-11-08 11:10:04,892 INFO     Training average loss at step 178700: 0.539283\n",
      "2022-11-08 11:10:11,383 INFO     Training average positive_sample_loss at step 178800: 0.704092\n",
      "2022-11-08 11:10:11,383 INFO     Training average negative_sample_loss at step 178800: 0.344218\n",
      "2022-11-08 11:10:11,383 INFO     Training average loss at step 178800: 0.524155\n",
      "2022-11-08 11:10:17,842 INFO     Training average positive_sample_loss at step 178900: 0.712873\n",
      "2022-11-08 11:10:17,842 INFO     Training average negative_sample_loss at step 178900: 0.350617\n",
      "2022-11-08 11:10:17,843 INFO     Training average loss at step 178900: 0.531745\n",
      "2022-11-08 11:10:24,356 INFO     Training average positive_sample_loss at step 179000: 0.679575\n",
      "2022-11-08 11:10:24,356 INFO     Training average negative_sample_loss at step 179000: 0.348544\n",
      "2022-11-08 11:10:24,356 INFO     Training average loss at step 179000: 0.514060\n",
      "2022-11-08 11:10:30,837 INFO     Training average positive_sample_loss at step 179100: 0.700236\n",
      "2022-11-08 11:10:30,837 INFO     Training average negative_sample_loss at step 179100: 0.350147\n",
      "2022-11-08 11:10:30,837 INFO     Training average loss at step 179100: 0.525192\n",
      "2022-11-08 11:10:37,396 INFO     Training average positive_sample_loss at step 179200: 0.709143\n",
      "2022-11-08 11:10:37,396 INFO     Training average negative_sample_loss at step 179200: 0.350455\n",
      "2022-11-08 11:10:37,396 INFO     Training average loss at step 179200: 0.529799\n",
      "2022-11-08 11:10:43,891 INFO     Training average positive_sample_loss at step 179300: 0.689372\n",
      "2022-11-08 11:10:43,891 INFO     Training average negative_sample_loss at step 179300: 0.343603\n",
      "2022-11-08 11:10:43,891 INFO     Training average loss at step 179300: 0.516487\n",
      "2022-11-08 11:10:50,445 INFO     Training average positive_sample_loss at step 179400: 0.694876\n",
      "2022-11-08 11:10:50,445 INFO     Training average negative_sample_loss at step 179400: 0.352058\n",
      "2022-11-08 11:10:50,445 INFO     Training average loss at step 179400: 0.523467\n",
      "2022-11-08 11:10:56,906 INFO     Training average positive_sample_loss at step 179500: 0.705197\n",
      "2022-11-08 11:10:56,906 INFO     Training average negative_sample_loss at step 179500: 0.350257\n",
      "2022-11-08 11:10:56,906 INFO     Training average loss at step 179500: 0.527727\n",
      "2022-11-08 11:11:03,342 INFO     Training average positive_sample_loss at step 179600: 0.701278\n",
      "2022-11-08 11:11:03,342 INFO     Training average negative_sample_loss at step 179600: 0.349920\n",
      "2022-11-08 11:11:03,342 INFO     Training average loss at step 179600: 0.525599\n",
      "2022-11-08 11:11:09,774 INFO     Training average positive_sample_loss at step 179700: 0.708040\n",
      "2022-11-08 11:11:09,774 INFO     Training average negative_sample_loss at step 179700: 0.352633\n",
      "2022-11-08 11:11:09,774 INFO     Training average loss at step 179700: 0.530336\n",
      "2022-11-08 11:11:16,194 INFO     Training average positive_sample_loss at step 179800: 0.686023\n",
      "2022-11-08 11:11:16,194 INFO     Training average negative_sample_loss at step 179800: 0.356132\n",
      "2022-11-08 11:11:16,194 INFO     Training average loss at step 179800: 0.521077\n",
      "2022-11-08 11:11:22,659 INFO     Training average positive_sample_loss at step 179900: 0.711346\n",
      "2022-11-08 11:11:22,659 INFO     Training average negative_sample_loss at step 179900: 0.348620\n",
      "2022-11-08 11:11:22,659 INFO     Training average loss at step 179900: 0.529983\n",
      "2022-11-08 11:11:31,844 INFO     Training average positive_sample_loss at step 180000: 0.688523\n",
      "2022-11-08 11:11:31,844 INFO     Training average negative_sample_loss at step 180000: 0.347583\n",
      "2022-11-08 11:11:31,844 INFO     Training average loss at step 180000: 0.518053\n",
      "2022-11-08 11:11:38,236 INFO     Training average positive_sample_loss at step 180100: 0.706559\n",
      "2022-11-08 11:11:38,236 INFO     Training average negative_sample_loss at step 180100: 0.347196\n",
      "2022-11-08 11:11:38,236 INFO     Training average loss at step 180100: 0.526878\n",
      "2022-11-08 11:11:44,637 INFO     Training average positive_sample_loss at step 180200: 0.697162\n",
      "2022-11-08 11:11:44,637 INFO     Training average negative_sample_loss at step 180200: 0.350765\n",
      "2022-11-08 11:11:44,637 INFO     Training average loss at step 180200: 0.523964\n",
      "2022-11-08 11:11:51,050 INFO     Training average positive_sample_loss at step 180300: 0.681588\n",
      "2022-11-08 11:11:51,050 INFO     Training average negative_sample_loss at step 180300: 0.350560\n",
      "2022-11-08 11:11:51,050 INFO     Training average loss at step 180300: 0.516074\n",
      "2022-11-08 11:11:57,474 INFO     Training average positive_sample_loss at step 180400: 0.731678\n",
      "2022-11-08 11:11:57,474 INFO     Training average negative_sample_loss at step 180400: 0.342434\n",
      "2022-11-08 11:11:57,474 INFO     Training average loss at step 180400: 0.537056\n",
      "2022-11-08 11:12:03,878 INFO     Training average positive_sample_loss at step 180500: 0.694698\n",
      "2022-11-08 11:12:03,878 INFO     Training average negative_sample_loss at step 180500: 0.346025\n",
      "2022-11-08 11:12:03,878 INFO     Training average loss at step 180500: 0.520361\n",
      "2022-11-08 11:12:10,302 INFO     Training average positive_sample_loss at step 180600: 0.734527\n",
      "2022-11-08 11:12:10,302 INFO     Training average negative_sample_loss at step 180600: 0.343011\n",
      "2022-11-08 11:12:10,302 INFO     Training average loss at step 180600: 0.538769\n",
      "2022-11-08 11:12:16,724 INFO     Training average positive_sample_loss at step 180700: 0.710176\n",
      "2022-11-08 11:12:16,725 INFO     Training average negative_sample_loss at step 180700: 0.347406\n",
      "2022-11-08 11:12:16,725 INFO     Training average loss at step 180700: 0.528791\n",
      "2022-11-08 11:12:23,149 INFO     Training average positive_sample_loss at step 180800: 0.661650\n",
      "2022-11-08 11:12:23,149 INFO     Training average negative_sample_loss at step 180800: 0.346993\n",
      "2022-11-08 11:12:23,149 INFO     Training average loss at step 180800: 0.504321\n",
      "2022-11-08 11:12:29,576 INFO     Training average positive_sample_loss at step 180900: 0.699623\n",
      "2022-11-08 11:12:29,577 INFO     Training average negative_sample_loss at step 180900: 0.341952\n",
      "2022-11-08 11:12:29,577 INFO     Training average loss at step 180900: 0.520788\n",
      "2022-11-08 11:12:35,986 INFO     Training average positive_sample_loss at step 181000: 0.696254\n",
      "2022-11-08 11:12:35,986 INFO     Training average negative_sample_loss at step 181000: 0.346990\n",
      "2022-11-08 11:12:35,986 INFO     Training average loss at step 181000: 0.521622\n",
      "2022-11-08 11:12:42,402 INFO     Training average positive_sample_loss at step 181100: 0.698817\n",
      "2022-11-08 11:12:42,402 INFO     Training average negative_sample_loss at step 181100: 0.352213\n",
      "2022-11-08 11:12:42,402 INFO     Training average loss at step 181100: 0.525515\n",
      "2022-11-08 11:12:48,925 INFO     Training average positive_sample_loss at step 181200: 0.692311\n",
      "2022-11-08 11:12:48,925 INFO     Training average negative_sample_loss at step 181200: 0.341375\n",
      "2022-11-08 11:12:48,925 INFO     Training average loss at step 181200: 0.516843\n",
      "2022-11-08 11:12:55,419 INFO     Training average positive_sample_loss at step 181300: 0.681072\n",
      "2022-11-08 11:12:55,419 INFO     Training average negative_sample_loss at step 181300: 0.344807\n",
      "2022-11-08 11:12:55,419 INFO     Training average loss at step 181300: 0.512939\n",
      "2022-11-08 11:13:01,849 INFO     Training average positive_sample_loss at step 181400: 0.689326\n",
      "2022-11-08 11:13:01,849 INFO     Training average negative_sample_loss at step 181400: 0.349146\n",
      "2022-11-08 11:13:01,849 INFO     Training average loss at step 181400: 0.519236\n",
      "2022-11-08 11:13:08,287 INFO     Training average positive_sample_loss at step 181500: 0.674725\n",
      "2022-11-08 11:13:08,287 INFO     Training average negative_sample_loss at step 181500: 0.347066\n",
      "2022-11-08 11:13:08,287 INFO     Training average loss at step 181500: 0.510896\n",
      "2022-11-08 11:13:14,727 INFO     Training average positive_sample_loss at step 181600: 0.707025\n",
      "2022-11-08 11:13:14,727 INFO     Training average negative_sample_loss at step 181600: 0.348701\n",
      "2022-11-08 11:13:14,727 INFO     Training average loss at step 181600: 0.527863\n",
      "2022-11-08 11:13:21,211 INFO     Training average positive_sample_loss at step 181700: 0.673932\n",
      "2022-11-08 11:13:21,212 INFO     Training average negative_sample_loss at step 181700: 0.353103\n",
      "2022-11-08 11:13:21,212 INFO     Training average loss at step 181700: 0.513517\n",
      "2022-11-08 11:13:27,809 INFO     Training average positive_sample_loss at step 181800: 0.690998\n",
      "2022-11-08 11:13:27,809 INFO     Training average negative_sample_loss at step 181800: 0.352958\n",
      "2022-11-08 11:13:27,809 INFO     Training average loss at step 181800: 0.521978\n",
      "2022-11-08 11:13:34,444 INFO     Training average positive_sample_loss at step 181900: 0.700610\n",
      "2022-11-08 11:13:34,444 INFO     Training average negative_sample_loss at step 181900: 0.341262\n",
      "2022-11-08 11:13:34,444 INFO     Training average loss at step 181900: 0.520936\n",
      "2022-11-08 11:13:40,941 INFO     Training average positive_sample_loss at step 182000: 0.680919\n",
      "2022-11-08 11:13:40,941 INFO     Training average negative_sample_loss at step 182000: 0.342826\n",
      "2022-11-08 11:13:40,941 INFO     Training average loss at step 182000: 0.511872\n",
      "2022-11-08 11:13:47,388 INFO     Training average positive_sample_loss at step 182100: 0.684933\n",
      "2022-11-08 11:13:47,389 INFO     Training average negative_sample_loss at step 182100: 0.347086\n",
      "2022-11-08 11:13:47,389 INFO     Training average loss at step 182100: 0.516009\n",
      "2022-11-08 11:13:53,862 INFO     Training average positive_sample_loss at step 182200: 0.705286\n",
      "2022-11-08 11:13:53,862 INFO     Training average negative_sample_loss at step 182200: 0.347261\n",
      "2022-11-08 11:13:53,862 INFO     Training average loss at step 182200: 0.526274\n",
      "2022-11-08 11:13:59,102 INFO     Training average positive_sample_loss at step 182300: 0.685676\n",
      "2022-11-08 11:13:59,102 INFO     Training average negative_sample_loss at step 182300: 0.343665\n",
      "2022-11-08 11:13:59,102 INFO     Training average loss at step 182300: 0.514671\n",
      "2022-11-08 11:14:05,543 INFO     Training average positive_sample_loss at step 182400: 0.704316\n",
      "2022-11-08 11:14:05,543 INFO     Training average negative_sample_loss at step 182400: 0.345709\n",
      "2022-11-08 11:14:05,543 INFO     Training average loss at step 182400: 0.525012\n",
      "2022-11-08 11:14:14,672 INFO     Training average positive_sample_loss at step 182500: 0.699817\n",
      "2022-11-08 11:14:14,672 INFO     Training average negative_sample_loss at step 182500: 0.351143\n",
      "2022-11-08 11:14:14,672 INFO     Training average loss at step 182500: 0.525480\n",
      "2022-11-08 11:14:21,099 INFO     Training average positive_sample_loss at step 182600: 0.721206\n",
      "2022-11-08 11:14:21,099 INFO     Training average negative_sample_loss at step 182600: 0.341907\n",
      "2022-11-08 11:14:21,099 INFO     Training average loss at step 182600: 0.531556\n",
      "2022-11-08 11:14:28,079 INFO     Training average positive_sample_loss at step 182700: 0.690676\n",
      "2022-11-08 11:14:28,079 INFO     Training average negative_sample_loss at step 182700: 0.346956\n",
      "2022-11-08 11:14:28,079 INFO     Training average loss at step 182700: 0.518816\n",
      "2022-11-08 11:14:34,494 INFO     Training average positive_sample_loss at step 182800: 0.708132\n",
      "2022-11-08 11:14:34,494 INFO     Training average negative_sample_loss at step 182800: 0.344758\n",
      "2022-11-08 11:14:34,494 INFO     Training average loss at step 182800: 0.526445\n",
      "2022-11-08 11:14:41,012 INFO     Training average positive_sample_loss at step 182900: 0.679296\n",
      "2022-11-08 11:14:41,012 INFO     Training average negative_sample_loss at step 182900: 0.345040\n",
      "2022-11-08 11:14:41,012 INFO     Training average loss at step 182900: 0.512168\n",
      "2022-11-08 11:14:47,578 INFO     Training average positive_sample_loss at step 183000: 0.694159\n",
      "2022-11-08 11:14:47,578 INFO     Training average negative_sample_loss at step 183000: 0.346322\n",
      "2022-11-08 11:14:47,578 INFO     Training average loss at step 183000: 0.520240\n",
      "2022-11-08 11:14:54,141 INFO     Training average positive_sample_loss at step 183100: 0.699857\n",
      "2022-11-08 11:14:54,142 INFO     Training average negative_sample_loss at step 183100: 0.343768\n",
      "2022-11-08 11:14:54,142 INFO     Training average loss at step 183100: 0.521813\n",
      "2022-11-08 11:15:00,605 INFO     Training average positive_sample_loss at step 183200: 0.689670\n",
      "2022-11-08 11:15:00,605 INFO     Training average negative_sample_loss at step 183200: 0.346736\n",
      "2022-11-08 11:15:00,605 INFO     Training average loss at step 183200: 0.518203\n",
      "2022-11-08 11:15:07,141 INFO     Training average positive_sample_loss at step 183300: 0.690282\n",
      "2022-11-08 11:15:07,141 INFO     Training average negative_sample_loss at step 183300: 0.347055\n",
      "2022-11-08 11:15:07,141 INFO     Training average loss at step 183300: 0.518669\n",
      "2022-11-08 11:15:13,659 INFO     Training average positive_sample_loss at step 183400: 0.704775\n",
      "2022-11-08 11:15:13,659 INFO     Training average negative_sample_loss at step 183400: 0.346039\n",
      "2022-11-08 11:15:13,660 INFO     Training average loss at step 183400: 0.525407\n",
      "2022-11-08 11:15:20,111 INFO     Training average positive_sample_loss at step 183500: 0.696974\n",
      "2022-11-08 11:15:20,112 INFO     Training average negative_sample_loss at step 183500: 0.343529\n",
      "2022-11-08 11:15:20,112 INFO     Training average loss at step 183500: 0.520251\n",
      "2022-11-08 11:15:26,548 INFO     Training average positive_sample_loss at step 183600: 0.680729\n",
      "2022-11-08 11:15:26,548 INFO     Training average negative_sample_loss at step 183600: 0.343585\n",
      "2022-11-08 11:15:26,548 INFO     Training average loss at step 183600: 0.512157\n",
      "2022-11-08 11:15:32,979 INFO     Training average positive_sample_loss at step 183700: 0.696489\n",
      "2022-11-08 11:15:32,979 INFO     Training average negative_sample_loss at step 183700: 0.345688\n",
      "2022-11-08 11:15:32,979 INFO     Training average loss at step 183700: 0.521089\n",
      "2022-11-08 11:15:39,438 INFO     Training average positive_sample_loss at step 183800: 0.690309\n",
      "2022-11-08 11:15:39,438 INFO     Training average negative_sample_loss at step 183800: 0.334899\n",
      "2022-11-08 11:15:39,438 INFO     Training average loss at step 183800: 0.512604\n",
      "2022-11-08 11:15:46,032 INFO     Training average positive_sample_loss at step 183900: 0.655226\n",
      "2022-11-08 11:15:46,032 INFO     Training average negative_sample_loss at step 183900: 0.348998\n",
      "2022-11-08 11:15:46,032 INFO     Training average loss at step 183900: 0.502112\n",
      "2022-11-08 11:15:52,578 INFO     Training average positive_sample_loss at step 184000: 0.676512\n",
      "2022-11-08 11:15:52,578 INFO     Training average negative_sample_loss at step 184000: 0.343730\n",
      "2022-11-08 11:15:52,578 INFO     Training average loss at step 184000: 0.510121\n",
      "2022-11-08 11:15:59,092 INFO     Training average positive_sample_loss at step 184100: 0.696867\n",
      "2022-11-08 11:15:59,092 INFO     Training average negative_sample_loss at step 184100: 0.345486\n",
      "2022-11-08 11:15:59,092 INFO     Training average loss at step 184100: 0.521177\n",
      "2022-11-08 11:16:05,568 INFO     Training average positive_sample_loss at step 184200: 0.694142\n",
      "2022-11-08 11:16:05,568 INFO     Training average negative_sample_loss at step 184200: 0.344485\n",
      "2022-11-08 11:16:05,568 INFO     Training average loss at step 184200: 0.519313\n",
      "2022-11-08 11:16:12,038 INFO     Training average positive_sample_loss at step 184300: 0.693292\n",
      "2022-11-08 11:16:12,039 INFO     Training average negative_sample_loss at step 184300: 0.340907\n",
      "2022-11-08 11:16:12,039 INFO     Training average loss at step 184300: 0.517100\n",
      "2022-11-08 11:16:18,518 INFO     Training average positive_sample_loss at step 184400: 0.711209\n",
      "2022-11-08 11:16:18,518 INFO     Training average negative_sample_loss at step 184400: 0.335527\n",
      "2022-11-08 11:16:18,518 INFO     Training average loss at step 184400: 0.523368\n",
      "2022-11-08 11:16:25,050 INFO     Training average positive_sample_loss at step 184500: 0.678070\n",
      "2022-11-08 11:16:25,050 INFO     Training average negative_sample_loss at step 184500: 0.355180\n",
      "2022-11-08 11:16:25,050 INFO     Training average loss at step 184500: 0.516625\n",
      "2022-11-08 11:16:31,541 INFO     Training average positive_sample_loss at step 184600: 0.702722\n",
      "2022-11-08 11:16:31,541 INFO     Training average negative_sample_loss at step 184600: 0.347032\n",
      "2022-11-08 11:16:31,541 INFO     Training average loss at step 184600: 0.524877\n",
      "2022-11-08 11:16:37,970 INFO     Training average positive_sample_loss at step 184700: 0.704909\n",
      "2022-11-08 11:16:37,970 INFO     Training average negative_sample_loss at step 184700: 0.339013\n",
      "2022-11-08 11:16:37,970 INFO     Training average loss at step 184700: 0.521961\n",
      "2022-11-08 11:16:44,437 INFO     Training average positive_sample_loss at step 184800: 0.700777\n",
      "2022-11-08 11:16:44,437 INFO     Training average negative_sample_loss at step 184800: 0.341645\n",
      "2022-11-08 11:16:44,437 INFO     Training average loss at step 184800: 0.521211\n",
      "2022-11-08 11:16:50,911 INFO     Training average positive_sample_loss at step 184900: 0.695741\n",
      "2022-11-08 11:16:50,911 INFO     Training average negative_sample_loss at step 184900: 0.342355\n",
      "2022-11-08 11:16:50,911 INFO     Training average loss at step 184900: 0.519048\n",
      "2022-11-08 11:16:57,406 INFO     Training average positive_sample_loss at step 185000: 0.704030\n",
      "2022-11-08 11:16:57,406 INFO     Training average negative_sample_loss at step 185000: 0.338898\n",
      "2022-11-08 11:16:57,406 INFO     Training average loss at step 185000: 0.521464\n",
      "2022-11-08 11:17:03,865 INFO     Training average positive_sample_loss at step 185100: 0.691703\n",
      "2022-11-08 11:17:03,865 INFO     Training average negative_sample_loss at step 185100: 0.338304\n",
      "2022-11-08 11:17:03,865 INFO     Training average loss at step 185100: 0.515004\n",
      "2022-11-08 11:17:10,338 INFO     Training average positive_sample_loss at step 185200: 0.686911\n",
      "2022-11-08 11:17:10,338 INFO     Training average negative_sample_loss at step 185200: 0.347694\n",
      "2022-11-08 11:17:10,338 INFO     Training average loss at step 185200: 0.517303\n",
      "2022-11-08 11:17:16,862 INFO     Training average positive_sample_loss at step 185300: 0.673545\n",
      "2022-11-08 11:17:16,863 INFO     Training average negative_sample_loss at step 185300: 0.337973\n",
      "2022-11-08 11:17:16,863 INFO     Training average loss at step 185300: 0.505759\n",
      "2022-11-08 11:17:23,316 INFO     Training average positive_sample_loss at step 185400: 0.693894\n",
      "2022-11-08 11:17:23,317 INFO     Training average negative_sample_loss at step 185400: 0.337905\n",
      "2022-11-08 11:17:23,317 INFO     Training average loss at step 185400: 0.515899\n",
      "2022-11-08 11:17:29,805 INFO     Training average positive_sample_loss at step 185500: 0.722038\n",
      "2022-11-08 11:17:29,805 INFO     Training average negative_sample_loss at step 185500: 0.341600\n",
      "2022-11-08 11:17:29,805 INFO     Training average loss at step 185500: 0.531819\n",
      "2022-11-08 11:17:36,286 INFO     Training average positive_sample_loss at step 185600: 0.694508\n",
      "2022-11-08 11:17:36,286 INFO     Training average negative_sample_loss at step 185600: 0.336534\n",
      "2022-11-08 11:17:36,286 INFO     Training average loss at step 185600: 0.515521\n",
      "2022-11-08 11:17:42,769 INFO     Training average positive_sample_loss at step 185700: 0.667352\n",
      "2022-11-08 11:17:42,769 INFO     Training average negative_sample_loss at step 185700: 0.343278\n",
      "2022-11-08 11:17:42,769 INFO     Training average loss at step 185700: 0.505315\n",
      "2022-11-08 11:17:49,234 INFO     Training average positive_sample_loss at step 185800: 0.685051\n",
      "2022-11-08 11:17:49,234 INFO     Training average negative_sample_loss at step 185800: 0.343048\n",
      "2022-11-08 11:17:49,234 INFO     Training average loss at step 185800: 0.514050\n",
      "2022-11-08 11:17:55,726 INFO     Training average positive_sample_loss at step 185900: 0.681877\n",
      "2022-11-08 11:17:55,727 INFO     Training average negative_sample_loss at step 185900: 0.345746\n",
      "2022-11-08 11:17:55,727 INFO     Training average loss at step 185900: 0.513812\n",
      "2022-11-08 11:18:02,196 INFO     Training average positive_sample_loss at step 186000: 0.664774\n",
      "2022-11-08 11:18:02,197 INFO     Training average negative_sample_loss at step 186000: 0.342602\n",
      "2022-11-08 11:18:02,197 INFO     Training average loss at step 186000: 0.503688\n",
      "2022-11-08 11:18:08,757 INFO     Training average positive_sample_loss at step 186100: 0.700775\n",
      "2022-11-08 11:18:08,757 INFO     Training average negative_sample_loss at step 186100: 0.346742\n",
      "2022-11-08 11:18:08,757 INFO     Training average loss at step 186100: 0.523759\n",
      "2022-11-08 11:18:15,184 INFO     Training average positive_sample_loss at step 186200: 0.688956\n",
      "2022-11-08 11:18:15,184 INFO     Training average negative_sample_loss at step 186200: 0.343840\n",
      "2022-11-08 11:18:15,184 INFO     Training average loss at step 186200: 0.516398\n",
      "2022-11-08 11:18:21,644 INFO     Training average positive_sample_loss at step 186300: 0.693709\n",
      "2022-11-08 11:18:21,644 INFO     Training average negative_sample_loss at step 186300: 0.344371\n",
      "2022-11-08 11:18:21,644 INFO     Training average loss at step 186300: 0.519040\n",
      "2022-11-08 11:18:28,079 INFO     Training average positive_sample_loss at step 186400: 0.694064\n",
      "2022-11-08 11:18:28,079 INFO     Training average negative_sample_loss at step 186400: 0.340710\n",
      "2022-11-08 11:18:28,079 INFO     Training average loss at step 186400: 0.517387\n",
      "2022-11-08 11:18:34,561 INFO     Training average positive_sample_loss at step 186500: 0.677365\n",
      "2022-11-08 11:18:34,561 INFO     Training average negative_sample_loss at step 186500: 0.337092\n",
      "2022-11-08 11:18:34,561 INFO     Training average loss at step 186500: 0.507228\n",
      "2022-11-08 11:18:41,000 INFO     Training average positive_sample_loss at step 186600: 0.698272\n",
      "2022-11-08 11:18:41,000 INFO     Training average negative_sample_loss at step 186600: 0.336251\n",
      "2022-11-08 11:18:41,000 INFO     Training average loss at step 186600: 0.517262\n",
      "2022-11-08 11:18:47,509 INFO     Training average positive_sample_loss at step 186700: 0.678114\n",
      "2022-11-08 11:18:47,510 INFO     Training average negative_sample_loss at step 186700: 0.343717\n",
      "2022-11-08 11:18:47,510 INFO     Training average loss at step 186700: 0.510915\n",
      "2022-11-08 11:18:54,023 INFO     Training average positive_sample_loss at step 186800: 0.683875\n",
      "2022-11-08 11:18:54,024 INFO     Training average negative_sample_loss at step 186800: 0.343444\n",
      "2022-11-08 11:18:54,024 INFO     Training average loss at step 186800: 0.513660\n",
      "2022-11-08 11:19:00,501 INFO     Training average positive_sample_loss at step 186900: 0.654301\n",
      "2022-11-08 11:19:00,502 INFO     Training average negative_sample_loss at step 186900: 0.341233\n",
      "2022-11-08 11:19:00,502 INFO     Training average loss at step 186900: 0.497767\n",
      "2022-11-08 11:19:07,016 INFO     Training average positive_sample_loss at step 187000: 0.686687\n",
      "2022-11-08 11:19:07,017 INFO     Training average negative_sample_loss at step 187000: 0.339970\n",
      "2022-11-08 11:19:07,017 INFO     Training average loss at step 187000: 0.513328\n",
      "2022-11-08 11:19:13,528 INFO     Training average positive_sample_loss at step 187100: 0.680679\n",
      "2022-11-08 11:19:13,529 INFO     Training average negative_sample_loss at step 187100: 0.336104\n",
      "2022-11-08 11:19:13,529 INFO     Training average loss at step 187100: 0.508391\n",
      "2022-11-08 11:19:22,798 INFO     Training average positive_sample_loss at step 187200: 0.705998\n",
      "2022-11-08 11:19:22,798 INFO     Training average negative_sample_loss at step 187200: 0.342865\n",
      "2022-11-08 11:19:22,798 INFO     Training average loss at step 187200: 0.524432\n",
      "2022-11-08 11:19:29,340 INFO     Training average positive_sample_loss at step 187300: 0.691818\n",
      "2022-11-08 11:19:29,341 INFO     Training average negative_sample_loss at step 187300: 0.336052\n",
      "2022-11-08 11:19:29,341 INFO     Training average loss at step 187300: 0.513935\n",
      "2022-11-08 11:19:36,525 INFO     Training average positive_sample_loss at step 187400: 0.701940\n",
      "2022-11-08 11:19:36,525 INFO     Training average negative_sample_loss at step 187400: 0.340151\n",
      "2022-11-08 11:19:36,525 INFO     Training average loss at step 187400: 0.521046\n",
      "2022-11-08 11:19:42,908 INFO     Training average positive_sample_loss at step 187500: 0.711388\n",
      "2022-11-08 11:19:42,908 INFO     Training average negative_sample_loss at step 187500: 0.342527\n",
      "2022-11-08 11:19:42,908 INFO     Training average loss at step 187500: 0.526957\n",
      "2022-11-08 11:19:49,433 INFO     Training average positive_sample_loss at step 187600: 0.697927\n",
      "2022-11-08 11:19:49,433 INFO     Training average negative_sample_loss at step 187600: 0.336969\n",
      "2022-11-08 11:19:49,433 INFO     Training average loss at step 187600: 0.517448\n",
      "2022-11-08 11:19:55,840 INFO     Training average positive_sample_loss at step 187700: 0.668303\n",
      "2022-11-08 11:19:55,840 INFO     Training average negative_sample_loss at step 187700: 0.336862\n",
      "2022-11-08 11:19:55,840 INFO     Training average loss at step 187700: 0.502582\n",
      "2022-11-08 11:20:00,922 INFO     Training average positive_sample_loss at step 187800: 0.688416\n",
      "2022-11-08 11:20:00,922 INFO     Training average negative_sample_loss at step 187800: 0.339414\n",
      "2022-11-08 11:20:00,922 INFO     Training average loss at step 187800: 0.513915\n",
      "2022-11-08 11:20:07,361 INFO     Training average positive_sample_loss at step 187900: 0.660146\n",
      "2022-11-08 11:20:07,361 INFO     Training average negative_sample_loss at step 187900: 0.347050\n",
      "2022-11-08 11:20:07,361 INFO     Training average loss at step 187900: 0.503598\n",
      "2022-11-08 11:20:13,828 INFO     Training average positive_sample_loss at step 188000: 0.699120\n",
      "2022-11-08 11:20:13,829 INFO     Training average negative_sample_loss at step 188000: 0.338260\n",
      "2022-11-08 11:20:13,829 INFO     Training average loss at step 188000: 0.518690\n",
      "2022-11-08 11:20:20,416 INFO     Training average positive_sample_loss at step 188100: 0.695380\n",
      "2022-11-08 11:20:20,416 INFO     Training average negative_sample_loss at step 188100: 0.348130\n",
      "2022-11-08 11:20:20,416 INFO     Training average loss at step 188100: 0.521755\n",
      "2022-11-08 11:20:26,877 INFO     Training average positive_sample_loss at step 188200: 0.694124\n",
      "2022-11-08 11:20:26,877 INFO     Training average negative_sample_loss at step 188200: 0.336244\n",
      "2022-11-08 11:20:26,877 INFO     Training average loss at step 188200: 0.515184\n",
      "2022-11-08 11:20:33,342 INFO     Training average positive_sample_loss at step 188300: 0.688034\n",
      "2022-11-08 11:20:33,342 INFO     Training average negative_sample_loss at step 188300: 0.337203\n",
      "2022-11-08 11:20:33,342 INFO     Training average loss at step 188300: 0.512619\n",
      "2022-11-08 11:20:39,793 INFO     Training average positive_sample_loss at step 188400: 0.689170\n",
      "2022-11-08 11:20:39,794 INFO     Training average negative_sample_loss at step 188400: 0.341606\n",
      "2022-11-08 11:20:39,794 INFO     Training average loss at step 188400: 0.515388\n",
      "2022-11-08 11:20:46,253 INFO     Training average positive_sample_loss at step 188500: 0.687266\n",
      "2022-11-08 11:20:46,253 INFO     Training average negative_sample_loss at step 188500: 0.336393\n",
      "2022-11-08 11:20:46,253 INFO     Training average loss at step 188500: 0.511830\n",
      "2022-11-08 11:20:52,726 INFO     Training average positive_sample_loss at step 188600: 0.673265\n",
      "2022-11-08 11:20:52,726 INFO     Training average negative_sample_loss at step 188600: 0.332714\n",
      "2022-11-08 11:20:52,726 INFO     Training average loss at step 188600: 0.502989\n",
      "2022-11-08 11:20:59,261 INFO     Training average positive_sample_loss at step 188700: 0.673125\n",
      "2022-11-08 11:20:59,261 INFO     Training average negative_sample_loss at step 188700: 0.340479\n",
      "2022-11-08 11:20:59,261 INFO     Training average loss at step 188700: 0.506802\n",
      "2022-11-08 11:21:05,808 INFO     Training average positive_sample_loss at step 188800: 0.653833\n",
      "2022-11-08 11:21:05,808 INFO     Training average negative_sample_loss at step 188800: 0.339121\n",
      "2022-11-08 11:21:05,808 INFO     Training average loss at step 188800: 0.496477\n",
      "2022-11-08 11:21:12,265 INFO     Training average positive_sample_loss at step 188900: 0.680754\n",
      "2022-11-08 11:21:12,265 INFO     Training average negative_sample_loss at step 188900: 0.336200\n",
      "2022-11-08 11:21:12,265 INFO     Training average loss at step 188900: 0.508477\n",
      "2022-11-08 11:21:18,676 INFO     Training average positive_sample_loss at step 189000: 0.696710\n",
      "2022-11-08 11:21:18,676 INFO     Training average negative_sample_loss at step 189000: 0.341643\n",
      "2022-11-08 11:21:18,676 INFO     Training average loss at step 189000: 0.519177\n",
      "2022-11-08 11:21:25,217 INFO     Training average positive_sample_loss at step 189100: 0.670268\n",
      "2022-11-08 11:21:25,218 INFO     Training average negative_sample_loss at step 189100: 0.341335\n",
      "2022-11-08 11:21:25,218 INFO     Training average loss at step 189100: 0.505802\n",
      "2022-11-08 11:21:31,782 INFO     Training average positive_sample_loss at step 189200: 0.696728\n",
      "2022-11-08 11:21:31,782 INFO     Training average negative_sample_loss at step 189200: 0.337364\n",
      "2022-11-08 11:21:31,782 INFO     Training average loss at step 189200: 0.517046\n",
      "2022-11-08 11:21:38,310 INFO     Training average positive_sample_loss at step 189300: 0.667829\n",
      "2022-11-08 11:21:38,310 INFO     Training average negative_sample_loss at step 189300: 0.341504\n",
      "2022-11-08 11:21:38,310 INFO     Training average loss at step 189300: 0.504666\n",
      "2022-11-08 11:21:44,885 INFO     Training average positive_sample_loss at step 189400: 0.672483\n",
      "2022-11-08 11:21:44,885 INFO     Training average negative_sample_loss at step 189400: 0.338567\n",
      "2022-11-08 11:21:44,885 INFO     Training average loss at step 189400: 0.505525\n",
      "2022-11-08 11:21:51,425 INFO     Training average positive_sample_loss at step 189500: 0.681010\n",
      "2022-11-08 11:21:51,425 INFO     Training average negative_sample_loss at step 189500: 0.338412\n",
      "2022-11-08 11:21:51,425 INFO     Training average loss at step 189500: 0.509711\n",
      "2022-11-08 11:21:57,903 INFO     Training average positive_sample_loss at step 189600: 0.703298\n",
      "2022-11-08 11:21:57,903 INFO     Training average negative_sample_loss at step 189600: 0.335599\n",
      "2022-11-08 11:21:57,903 INFO     Training average loss at step 189600: 0.519449\n",
      "2022-11-08 11:22:04,494 INFO     Training average positive_sample_loss at step 189700: 0.678344\n",
      "2022-11-08 11:22:04,495 INFO     Training average negative_sample_loss at step 189700: 0.339934\n",
      "2022-11-08 11:22:04,495 INFO     Training average loss at step 189700: 0.509139\n",
      "2022-11-08 11:22:11,038 INFO     Training average positive_sample_loss at step 189800: 0.657918\n",
      "2022-11-08 11:22:11,038 INFO     Training average negative_sample_loss at step 189800: 0.336872\n",
      "2022-11-08 11:22:11,038 INFO     Training average loss at step 189800: 0.497395\n",
      "2022-11-08 11:22:17,549 INFO     Training average positive_sample_loss at step 189900: 0.681813\n",
      "2022-11-08 11:22:17,549 INFO     Training average negative_sample_loss at step 189900: 0.346816\n",
      "2022-11-08 11:22:17,549 INFO     Training average loss at step 189900: 0.514315\n",
      "2022-11-08 11:22:26,750 INFO     Training average positive_sample_loss at step 190000: 0.695827\n",
      "2022-11-08 11:22:26,751 INFO     Training average negative_sample_loss at step 190000: 0.335354\n",
      "2022-11-08 11:22:26,751 INFO     Training average loss at step 190000: 0.515590\n",
      "2022-11-08 11:22:33,169 INFO     Training average positive_sample_loss at step 190100: 0.682309\n",
      "2022-11-08 11:22:33,169 INFO     Training average negative_sample_loss at step 190100: 0.335514\n",
      "2022-11-08 11:22:33,169 INFO     Training average loss at step 190100: 0.508912\n",
      "2022-11-08 11:22:39,575 INFO     Training average positive_sample_loss at step 190200: 0.669447\n",
      "2022-11-08 11:22:39,575 INFO     Training average negative_sample_loss at step 190200: 0.331039\n",
      "2022-11-08 11:22:39,575 INFO     Training average loss at step 190200: 0.500243\n",
      "2022-11-08 11:22:45,988 INFO     Training average positive_sample_loss at step 190300: 0.671473\n",
      "2022-11-08 11:22:45,988 INFO     Training average negative_sample_loss at step 190300: 0.332402\n",
      "2022-11-08 11:22:45,988 INFO     Training average loss at step 190300: 0.501937\n",
      "2022-11-08 11:22:52,440 INFO     Training average positive_sample_loss at step 190400: 0.655898\n",
      "2022-11-08 11:22:52,440 INFO     Training average negative_sample_loss at step 190400: 0.335753\n",
      "2022-11-08 11:22:52,440 INFO     Training average loss at step 190400: 0.495825\n",
      "2022-11-08 11:22:58,887 INFO     Training average positive_sample_loss at step 190500: 0.686113\n",
      "2022-11-08 11:22:58,888 INFO     Training average negative_sample_loss at step 190500: 0.329536\n",
      "2022-11-08 11:22:58,888 INFO     Training average loss at step 190500: 0.507824\n",
      "2022-11-08 11:23:05,327 INFO     Training average positive_sample_loss at step 190600: 0.678761\n",
      "2022-11-08 11:23:05,327 INFO     Training average negative_sample_loss at step 190600: 0.337514\n",
      "2022-11-08 11:23:05,327 INFO     Training average loss at step 190600: 0.508138\n",
      "2022-11-08 11:23:11,762 INFO     Training average positive_sample_loss at step 190700: 0.697348\n",
      "2022-11-08 11:23:11,762 INFO     Training average negative_sample_loss at step 190700: 0.334967\n",
      "2022-11-08 11:23:11,762 INFO     Training average loss at step 190700: 0.516158\n",
      "2022-11-08 11:23:18,190 INFO     Training average positive_sample_loss at step 190800: 0.694683\n",
      "2022-11-08 11:23:18,190 INFO     Training average negative_sample_loss at step 190800: 0.334345\n",
      "2022-11-08 11:23:18,190 INFO     Training average loss at step 190800: 0.514514\n",
      "2022-11-08 11:23:24,646 INFO     Training average positive_sample_loss at step 190900: 0.675175\n",
      "2022-11-08 11:23:24,646 INFO     Training average negative_sample_loss at step 190900: 0.340009\n",
      "2022-11-08 11:23:24,646 INFO     Training average loss at step 190900: 0.507592\n",
      "2022-11-08 11:23:31,052 INFO     Training average positive_sample_loss at step 191000: 0.679071\n",
      "2022-11-08 11:23:31,052 INFO     Training average negative_sample_loss at step 191000: 0.327053\n",
      "2022-11-08 11:23:31,052 INFO     Training average loss at step 191000: 0.503062\n",
      "2022-11-08 11:23:37,501 INFO     Training average positive_sample_loss at step 191100: 0.662030\n",
      "2022-11-08 11:23:37,501 INFO     Training average negative_sample_loss at step 191100: 0.329453\n",
      "2022-11-08 11:23:37,501 INFO     Training average loss at step 191100: 0.495741\n",
      "2022-11-08 11:23:43,923 INFO     Training average positive_sample_loss at step 191200: 0.718358\n",
      "2022-11-08 11:23:43,923 INFO     Training average negative_sample_loss at step 191200: 0.333409\n",
      "2022-11-08 11:23:43,923 INFO     Training average loss at step 191200: 0.525883\n",
      "2022-11-08 11:23:50,389 INFO     Training average positive_sample_loss at step 191300: 0.693684\n",
      "2022-11-08 11:23:50,389 INFO     Training average negative_sample_loss at step 191300: 0.334731\n",
      "2022-11-08 11:23:50,389 INFO     Training average loss at step 191300: 0.514208\n",
      "2022-11-08 11:23:56,841 INFO     Training average positive_sample_loss at step 191400: 0.682238\n",
      "2022-11-08 11:23:56,841 INFO     Training average negative_sample_loss at step 191400: 0.327779\n",
      "2022-11-08 11:23:56,842 INFO     Training average loss at step 191400: 0.505009\n",
      "2022-11-08 11:24:03,305 INFO     Training average positive_sample_loss at step 191500: 0.687875\n",
      "2022-11-08 11:24:03,305 INFO     Training average negative_sample_loss at step 191500: 0.333210\n",
      "2022-11-08 11:24:03,305 INFO     Training average loss at step 191500: 0.510543\n",
      "2022-11-08 11:24:09,776 INFO     Training average positive_sample_loss at step 191600: 0.665845\n",
      "2022-11-08 11:24:09,776 INFO     Training average negative_sample_loss at step 191600: 0.340383\n",
      "2022-11-08 11:24:09,776 INFO     Training average loss at step 191600: 0.503114\n",
      "2022-11-08 11:24:16,209 INFO     Training average positive_sample_loss at step 191700: 0.702051\n",
      "2022-11-08 11:24:16,209 INFO     Training average negative_sample_loss at step 191700: 0.342732\n",
      "2022-11-08 11:24:16,209 INFO     Training average loss at step 191700: 0.522391\n",
      "2022-11-08 11:24:24,192 INFO     Training average positive_sample_loss at step 191800: 0.679938\n",
      "2022-11-08 11:24:24,192 INFO     Training average negative_sample_loss at step 191800: 0.339912\n",
      "2022-11-08 11:24:24,192 INFO     Training average loss at step 191800: 0.509925\n",
      "2022-11-08 11:24:31,648 INFO     Training average positive_sample_loss at step 191900: 0.678793\n",
      "2022-11-08 11:24:31,648 INFO     Training average negative_sample_loss at step 191900: 0.331121\n",
      "2022-11-08 11:24:31,648 INFO     Training average loss at step 191900: 0.504957\n",
      "2022-11-08 11:24:38,123 INFO     Training average positive_sample_loss at step 192000: 0.686926\n",
      "2022-11-08 11:24:38,123 INFO     Training average negative_sample_loss at step 192000: 0.338639\n",
      "2022-11-08 11:24:38,123 INFO     Training average loss at step 192000: 0.512782\n",
      "2022-11-08 11:24:44,588 INFO     Training average positive_sample_loss at step 192100: 0.685515\n",
      "2022-11-08 11:24:44,588 INFO     Training average negative_sample_loss at step 192100: 0.335043\n",
      "2022-11-08 11:24:44,588 INFO     Training average loss at step 192100: 0.510279\n",
      "2022-11-08 11:24:51,032 INFO     Training average positive_sample_loss at step 192200: 0.675772\n",
      "2022-11-08 11:24:51,032 INFO     Training average negative_sample_loss at step 192200: 0.338909\n",
      "2022-11-08 11:24:51,032 INFO     Training average loss at step 192200: 0.507341\n",
      "2022-11-08 11:24:57,552 INFO     Training average positive_sample_loss at step 192300: 0.702534\n",
      "2022-11-08 11:24:57,552 INFO     Training average negative_sample_loss at step 192300: 0.338958\n",
      "2022-11-08 11:24:57,552 INFO     Training average loss at step 192300: 0.520746\n",
      "2022-11-08 11:25:04,028 INFO     Training average positive_sample_loss at step 192400: 0.673672\n",
      "2022-11-08 11:25:04,028 INFO     Training average negative_sample_loss at step 192400: 0.331227\n",
      "2022-11-08 11:25:04,028 INFO     Training average loss at step 192400: 0.502450\n",
      "2022-11-08 11:25:10,597 INFO     Training average positive_sample_loss at step 192500: 0.653515\n",
      "2022-11-08 11:25:10,597 INFO     Training average negative_sample_loss at step 192500: 0.332282\n",
      "2022-11-08 11:25:10,598 INFO     Training average loss at step 192500: 0.492898\n",
      "2022-11-08 11:25:17,086 INFO     Training average positive_sample_loss at step 192600: 0.676932\n",
      "2022-11-08 11:25:17,086 INFO     Training average negative_sample_loss at step 192600: 0.329357\n",
      "2022-11-08 11:25:17,086 INFO     Training average loss at step 192600: 0.503144\n",
      "2022-11-08 11:25:23,610 INFO     Training average positive_sample_loss at step 192700: 0.683098\n",
      "2022-11-08 11:25:23,610 INFO     Training average negative_sample_loss at step 192700: 0.339665\n",
      "2022-11-08 11:25:23,610 INFO     Training average loss at step 192700: 0.511381\n",
      "2022-11-08 11:25:30,121 INFO     Training average positive_sample_loss at step 192800: 0.689972\n",
      "2022-11-08 11:25:30,121 INFO     Training average negative_sample_loss at step 192800: 0.338364\n",
      "2022-11-08 11:25:30,121 INFO     Training average loss at step 192800: 0.514168\n",
      "2022-11-08 11:25:36,624 INFO     Training average positive_sample_loss at step 192900: 0.702540\n",
      "2022-11-08 11:25:36,624 INFO     Training average negative_sample_loss at step 192900: 0.335676\n",
      "2022-11-08 11:25:36,624 INFO     Training average loss at step 192900: 0.519108\n",
      "2022-11-08 11:25:43,069 INFO     Training average positive_sample_loss at step 193000: 0.672454\n",
      "2022-11-08 11:25:43,069 INFO     Training average negative_sample_loss at step 193000: 0.335555\n",
      "2022-11-08 11:25:43,069 INFO     Training average loss at step 193000: 0.504005\n",
      "2022-11-08 11:25:49,602 INFO     Training average positive_sample_loss at step 193100: 0.679107\n",
      "2022-11-08 11:25:49,602 INFO     Training average negative_sample_loss at step 193100: 0.334571\n",
      "2022-11-08 11:25:49,602 INFO     Training average loss at step 193100: 0.506839\n",
      "2022-11-08 11:25:56,036 INFO     Training average positive_sample_loss at step 193200: 0.678447\n",
      "2022-11-08 11:25:56,037 INFO     Training average negative_sample_loss at step 193200: 0.327326\n",
      "2022-11-08 11:25:56,037 INFO     Training average loss at step 193200: 0.502886\n",
      "2022-11-08 11:26:02,299 INFO     Training average positive_sample_loss at step 193300: 0.680772\n",
      "2022-11-08 11:26:02,299 INFO     Training average negative_sample_loss at step 193300: 0.331245\n",
      "2022-11-08 11:26:02,299 INFO     Training average loss at step 193300: 0.506008\n",
      "2022-11-08 11:26:07,606 INFO     Training average positive_sample_loss at step 193400: 0.636294\n",
      "2022-11-08 11:26:07,606 INFO     Training average negative_sample_loss at step 193400: 0.327283\n",
      "2022-11-08 11:26:07,606 INFO     Training average loss at step 193400: 0.481788\n",
      "2022-11-08 11:26:14,014 INFO     Training average positive_sample_loss at step 193500: 0.669970\n",
      "2022-11-08 11:26:14,014 INFO     Training average negative_sample_loss at step 193500: 0.329998\n",
      "2022-11-08 11:26:14,014 INFO     Training average loss at step 193500: 0.499984\n",
      "2022-11-08 11:26:20,427 INFO     Training average positive_sample_loss at step 193600: 0.713341\n",
      "2022-11-08 11:26:20,428 INFO     Training average negative_sample_loss at step 193600: 0.331520\n",
      "2022-11-08 11:26:20,428 INFO     Training average loss at step 193600: 0.522431\n",
      "2022-11-08 11:26:26,853 INFO     Training average positive_sample_loss at step 193700: 0.661364\n",
      "2022-11-08 11:26:26,853 INFO     Training average negative_sample_loss at step 193700: 0.336370\n",
      "2022-11-08 11:26:26,853 INFO     Training average loss at step 193700: 0.498867\n",
      "2022-11-08 11:26:33,260 INFO     Training average positive_sample_loss at step 193800: 0.671119\n",
      "2022-11-08 11:26:33,260 INFO     Training average negative_sample_loss at step 193800: 0.336507\n",
      "2022-11-08 11:26:33,261 INFO     Training average loss at step 193800: 0.503813\n",
      "2022-11-08 11:26:42,032 INFO     Training average positive_sample_loss at step 193900: 0.682245\n",
      "2022-11-08 11:26:42,032 INFO     Training average negative_sample_loss at step 193900: 0.332508\n",
      "2022-11-08 11:26:42,032 INFO     Training average loss at step 193900: 0.507377\n",
      "2022-11-08 11:26:51,934 INFO     Training average positive_sample_loss at step 194000: 0.714005\n",
      "2022-11-08 11:26:51,934 INFO     Training average negative_sample_loss at step 194000: 0.327595\n",
      "2022-11-08 11:26:51,934 INFO     Training average loss at step 194000: 0.520800\n",
      "2022-11-08 11:27:01,753 INFO     Training average positive_sample_loss at step 194100: 0.657523\n",
      "2022-11-08 11:27:01,753 INFO     Training average negative_sample_loss at step 194100: 0.328000\n",
      "2022-11-08 11:27:01,753 INFO     Training average loss at step 194100: 0.492762\n",
      "2022-11-08 11:27:11,564 INFO     Training average positive_sample_loss at step 194200: 0.697892\n",
      "2022-11-08 11:27:11,564 INFO     Training average negative_sample_loss at step 194200: 0.330781\n",
      "2022-11-08 11:27:11,564 INFO     Training average loss at step 194200: 0.514337\n",
      "2022-11-08 11:27:21,377 INFO     Training average positive_sample_loss at step 194300: 0.673716\n",
      "2022-11-08 11:27:21,377 INFO     Training average negative_sample_loss at step 194300: 0.335368\n",
      "2022-11-08 11:27:21,377 INFO     Training average loss at step 194300: 0.504542\n",
      "2022-11-08 11:27:31,193 INFO     Training average positive_sample_loss at step 194400: 0.678976\n",
      "2022-11-08 11:27:31,193 INFO     Training average negative_sample_loss at step 194400: 0.338765\n",
      "2022-11-08 11:27:31,193 INFO     Training average loss at step 194400: 0.508871\n",
      "2022-11-08 11:27:41,001 INFO     Training average positive_sample_loss at step 194500: 0.670058\n",
      "2022-11-08 11:27:41,001 INFO     Training average negative_sample_loss at step 194500: 0.332010\n",
      "2022-11-08 11:27:41,001 INFO     Training average loss at step 194500: 0.501034\n",
      "2022-11-08 11:27:50,822 INFO     Training average positive_sample_loss at step 194600: 0.680728\n",
      "2022-11-08 11:27:50,823 INFO     Training average negative_sample_loss at step 194600: 0.331675\n",
      "2022-11-08 11:27:50,823 INFO     Training average loss at step 194600: 0.506201\n",
      "2022-11-08 11:28:00,651 INFO     Training average positive_sample_loss at step 194700: 0.680106\n",
      "2022-11-08 11:28:00,651 INFO     Training average negative_sample_loss at step 194700: 0.326366\n",
      "2022-11-08 11:28:00,651 INFO     Training average loss at step 194700: 0.503236\n",
      "2022-11-08 11:28:10,465 INFO     Training average positive_sample_loss at step 194800: 0.688722\n",
      "2022-11-08 11:28:10,465 INFO     Training average negative_sample_loss at step 194800: 0.329932\n",
      "2022-11-08 11:28:10,465 INFO     Training average loss at step 194800: 0.509327\n",
      "2022-11-08 11:28:20,274 INFO     Training average positive_sample_loss at step 194900: 0.700964\n",
      "2022-11-08 11:28:20,274 INFO     Training average negative_sample_loss at step 194900: 0.328750\n",
      "2022-11-08 11:28:20,274 INFO     Training average loss at step 194900: 0.514857\n",
      "2022-11-08 11:28:30,089 INFO     Training average positive_sample_loss at step 195000: 0.690676\n",
      "2022-11-08 11:28:30,089 INFO     Training average negative_sample_loss at step 195000: 0.330650\n",
      "2022-11-08 11:28:30,089 INFO     Training average loss at step 195000: 0.510663\n",
      "2022-11-08 11:28:39,902 INFO     Training average positive_sample_loss at step 195100: 0.648821\n",
      "2022-11-08 11:28:39,902 INFO     Training average negative_sample_loss at step 195100: 0.335754\n",
      "2022-11-08 11:28:39,902 INFO     Training average loss at step 195100: 0.492287\n",
      "2022-11-08 11:28:49,733 INFO     Training average positive_sample_loss at step 195200: 0.644952\n",
      "2022-11-08 11:28:49,733 INFO     Training average negative_sample_loss at step 195200: 0.331310\n",
      "2022-11-08 11:28:49,733 INFO     Training average loss at step 195200: 0.488131\n",
      "2022-11-08 11:28:59,732 INFO     Training average positive_sample_loss at step 195300: 0.680468\n",
      "2022-11-08 11:28:59,732 INFO     Training average negative_sample_loss at step 195300: 0.328291\n",
      "2022-11-08 11:28:59,732 INFO     Training average loss at step 195300: 0.504379\n",
      "2022-11-08 11:29:09,684 INFO     Training average positive_sample_loss at step 195400: 0.667137\n",
      "2022-11-08 11:29:09,684 INFO     Training average negative_sample_loss at step 195400: 0.330958\n",
      "2022-11-08 11:29:09,684 INFO     Training average loss at step 195400: 0.499048\n",
      "2022-11-08 11:29:19,652 INFO     Training average positive_sample_loss at step 195500: 0.670070\n",
      "2022-11-08 11:29:19,653 INFO     Training average negative_sample_loss at step 195500: 0.328439\n",
      "2022-11-08 11:29:19,653 INFO     Training average loss at step 195500: 0.499254\n",
      "2022-11-08 11:29:29,594 INFO     Training average positive_sample_loss at step 195600: 0.661109\n",
      "2022-11-08 11:29:29,594 INFO     Training average negative_sample_loss at step 195600: 0.330421\n",
      "2022-11-08 11:29:29,594 INFO     Training average loss at step 195600: 0.495765\n",
      "2022-11-08 11:29:39,519 INFO     Training average positive_sample_loss at step 195700: 0.692867\n",
      "2022-11-08 11:29:39,519 INFO     Training average negative_sample_loss at step 195700: 0.329449\n",
      "2022-11-08 11:29:39,520 INFO     Training average loss at step 195700: 0.511158\n",
      "2022-11-08 11:29:49,532 INFO     Training average positive_sample_loss at step 195800: 0.668863\n",
      "2022-11-08 11:29:49,532 INFO     Training average negative_sample_loss at step 195800: 0.336073\n",
      "2022-11-08 11:29:49,532 INFO     Training average loss at step 195800: 0.502468\n",
      "2022-11-08 11:29:59,495 INFO     Training average positive_sample_loss at step 195900: 0.666456\n",
      "2022-11-08 11:29:59,496 INFO     Training average negative_sample_loss at step 195900: 0.333088\n",
      "2022-11-08 11:29:59,496 INFO     Training average loss at step 195900: 0.499772\n",
      "2022-11-08 11:30:09,462 INFO     Training average positive_sample_loss at step 196000: 0.693859\n",
      "2022-11-08 11:30:09,462 INFO     Training average negative_sample_loss at step 196000: 0.328140\n",
      "2022-11-08 11:30:09,462 INFO     Training average loss at step 196000: 0.511000\n",
      "2022-11-08 11:30:19,386 INFO     Training average positive_sample_loss at step 196100: 0.679445\n",
      "2022-11-08 11:30:19,386 INFO     Training average negative_sample_loss at step 196100: 0.327705\n",
      "2022-11-08 11:30:19,386 INFO     Training average loss at step 196100: 0.503575\n",
      "2022-11-08 11:30:29,344 INFO     Training average positive_sample_loss at step 196200: 0.662657\n",
      "2022-11-08 11:30:29,344 INFO     Training average negative_sample_loss at step 196200: 0.330605\n",
      "2022-11-08 11:30:29,344 INFO     Training average loss at step 196200: 0.496631\n",
      "2022-11-08 11:30:39,310 INFO     Training average positive_sample_loss at step 196300: 0.653898\n",
      "2022-11-08 11:30:39,310 INFO     Training average negative_sample_loss at step 196300: 0.325773\n",
      "2022-11-08 11:30:39,310 INFO     Training average loss at step 196300: 0.489835\n",
      "2022-11-08 11:30:49,925 INFO     Training average positive_sample_loss at step 196400: 0.650652\n",
      "2022-11-08 11:30:49,925 INFO     Training average negative_sample_loss at step 196400: 0.336829\n",
      "2022-11-08 11:30:49,925 INFO     Training average loss at step 196400: 0.493740\n",
      "2022-11-08 11:31:00,983 INFO     Training average positive_sample_loss at step 196500: 0.669339\n",
      "2022-11-08 11:31:00,983 INFO     Training average negative_sample_loss at step 196500: 0.327830\n",
      "2022-11-08 11:31:00,983 INFO     Training average loss at step 196500: 0.498584\n",
      "2022-11-08 11:31:11,580 INFO     Training average positive_sample_loss at step 196600: 0.671501\n",
      "2022-11-08 11:31:11,581 INFO     Training average negative_sample_loss at step 196600: 0.331059\n",
      "2022-11-08 11:31:11,581 INFO     Training average loss at step 196600: 0.501280\n",
      "2022-11-08 11:31:21,499 INFO     Training average positive_sample_loss at step 196700: 0.664172\n",
      "2022-11-08 11:31:21,499 INFO     Training average negative_sample_loss at step 196700: 0.327125\n",
      "2022-11-08 11:31:21,499 INFO     Training average loss at step 196700: 0.495649\n",
      "2022-11-08 11:31:31,473 INFO     Training average positive_sample_loss at step 196800: 0.670071\n",
      "2022-11-08 11:31:31,473 INFO     Training average negative_sample_loss at step 196800: 0.330388\n",
      "2022-11-08 11:31:31,473 INFO     Training average loss at step 196800: 0.500230\n",
      "2022-11-08 11:31:41,570 INFO     Training average positive_sample_loss at step 196900: 0.664592\n",
      "2022-11-08 11:31:41,571 INFO     Training average negative_sample_loss at step 196900: 0.329089\n",
      "2022-11-08 11:31:41,571 INFO     Training average loss at step 196900: 0.496840\n",
      "2022-11-08 11:31:51,494 INFO     Training average positive_sample_loss at step 197000: 0.662190\n",
      "2022-11-08 11:31:51,494 INFO     Training average negative_sample_loss at step 197000: 0.334565\n",
      "2022-11-08 11:31:51,494 INFO     Training average loss at step 197000: 0.498378\n",
      "2022-11-08 11:32:01,406 INFO     Training average positive_sample_loss at step 197100: 0.635647\n",
      "2022-11-08 11:32:01,406 INFO     Training average negative_sample_loss at step 197100: 0.326225\n",
      "2022-11-08 11:32:01,406 INFO     Training average loss at step 197100: 0.480936\n",
      "2022-11-08 11:32:11,373 INFO     Training average positive_sample_loss at step 197200: 0.663285\n",
      "2022-11-08 11:32:11,373 INFO     Training average negative_sample_loss at step 197200: 0.326531\n",
      "2022-11-08 11:32:11,373 INFO     Training average loss at step 197200: 0.494908\n",
      "2022-11-08 11:32:21,281 INFO     Training average positive_sample_loss at step 197300: 0.684946\n",
      "2022-11-08 11:32:21,281 INFO     Training average negative_sample_loss at step 197300: 0.326537\n",
      "2022-11-08 11:32:21,281 INFO     Training average loss at step 197300: 0.505742\n",
      "2022-11-08 11:32:31,215 INFO     Training average positive_sample_loss at step 197400: 0.647376\n",
      "2022-11-08 11:32:31,215 INFO     Training average negative_sample_loss at step 197400: 0.331315\n",
      "2022-11-08 11:32:31,215 INFO     Training average loss at step 197400: 0.489345\n",
      "2022-11-08 11:32:41,147 INFO     Training average positive_sample_loss at step 197500: 0.652112\n",
      "2022-11-08 11:32:41,147 INFO     Training average negative_sample_loss at step 197500: 0.328074\n",
      "2022-11-08 11:32:41,147 INFO     Training average loss at step 197500: 0.490093\n",
      "2022-11-08 11:32:51,071 INFO     Training average positive_sample_loss at step 197600: 0.684331\n",
      "2022-11-08 11:32:51,071 INFO     Training average negative_sample_loss at step 197600: 0.329005\n",
      "2022-11-08 11:32:51,071 INFO     Training average loss at step 197600: 0.506668\n",
      "2022-11-08 11:33:00,957 INFO     Training average positive_sample_loss at step 197700: 0.642110\n",
      "2022-11-08 11:33:00,957 INFO     Training average negative_sample_loss at step 197700: 0.332879\n",
      "2022-11-08 11:33:00,957 INFO     Training average loss at step 197700: 0.487495\n",
      "2022-11-08 11:33:10,854 INFO     Training average positive_sample_loss at step 197800: 0.676025\n",
      "2022-11-08 11:33:10,854 INFO     Training average negative_sample_loss at step 197800: 0.330027\n",
      "2022-11-08 11:33:10,854 INFO     Training average loss at step 197800: 0.503026\n",
      "2022-11-08 11:33:20,782 INFO     Training average positive_sample_loss at step 197900: 0.665233\n",
      "2022-11-08 11:33:20,783 INFO     Training average negative_sample_loss at step 197900: 0.330485\n",
      "2022-11-08 11:33:20,783 INFO     Training average loss at step 197900: 0.497859\n",
      "2022-11-08 11:33:30,712 INFO     Training average positive_sample_loss at step 198000: 0.680352\n",
      "2022-11-08 11:33:30,712 INFO     Training average negative_sample_loss at step 198000: 0.326672\n",
      "2022-11-08 11:33:30,712 INFO     Training average loss at step 198000: 0.503512\n",
      "2022-11-08 11:33:40,634 INFO     Training average positive_sample_loss at step 198100: 0.659776\n",
      "2022-11-08 11:33:40,634 INFO     Training average negative_sample_loss at step 198100: 0.335044\n",
      "2022-11-08 11:33:40,634 INFO     Training average loss at step 198100: 0.497410\n",
      "2022-11-08 11:33:50,530 INFO     Training average positive_sample_loss at step 198200: 0.675597\n",
      "2022-11-08 11:33:50,530 INFO     Training average negative_sample_loss at step 198200: 0.325698\n",
      "2022-11-08 11:33:50,530 INFO     Training average loss at step 198200: 0.500648\n",
      "2022-11-08 11:34:00,403 INFO     Training average positive_sample_loss at step 198300: 0.665948\n",
      "2022-11-08 11:34:00,403 INFO     Training average negative_sample_loss at step 198300: 0.328290\n",
      "2022-11-08 11:34:00,403 INFO     Training average loss at step 198300: 0.497119\n",
      "2022-11-08 11:34:10,477 INFO     Training average positive_sample_loss at step 198400: 0.633529\n",
      "2022-11-08 11:34:10,477 INFO     Training average negative_sample_loss at step 198400: 0.330936\n",
      "2022-11-08 11:34:10,477 INFO     Training average loss at step 198400: 0.482233\n",
      "2022-11-08 11:34:20,571 INFO     Training average positive_sample_loss at step 198500: 0.668624\n",
      "2022-11-08 11:34:20,571 INFO     Training average negative_sample_loss at step 198500: 0.333056\n",
      "2022-11-08 11:34:20,571 INFO     Training average loss at step 198500: 0.500840\n",
      "2022-11-08 11:34:30,601 INFO     Training average positive_sample_loss at step 198600: 0.651572\n",
      "2022-11-08 11:34:30,601 INFO     Training average negative_sample_loss at step 198600: 0.327922\n",
      "2022-11-08 11:34:30,601 INFO     Training average loss at step 198600: 0.489747\n",
      "2022-11-08 11:34:40,492 INFO     Training average positive_sample_loss at step 198700: 0.691898\n",
      "2022-11-08 11:34:40,492 INFO     Training average negative_sample_loss at step 198700: 0.326587\n",
      "2022-11-08 11:34:40,492 INFO     Training average loss at step 198700: 0.509243\n",
      "2022-11-08 11:34:50,361 INFO     Training average positive_sample_loss at step 198800: 0.633700\n",
      "2022-11-08 11:34:50,361 INFO     Training average negative_sample_loss at step 198800: 0.328222\n",
      "2022-11-08 11:34:50,361 INFO     Training average loss at step 198800: 0.480961\n",
      "2022-11-08 11:34:59,713 INFO     Training average positive_sample_loss at step 198900: 0.665970\n",
      "2022-11-08 11:34:59,713 INFO     Training average negative_sample_loss at step 198900: 0.330928\n",
      "2022-11-08 11:34:59,713 INFO     Training average loss at step 198900: 0.498449\n",
      "2022-11-08 11:35:09,706 INFO     Training average positive_sample_loss at step 199000: 0.670727\n",
      "2022-11-08 11:35:09,706 INFO     Training average negative_sample_loss at step 199000: 0.325773\n",
      "2022-11-08 11:35:09,706 INFO     Training average loss at step 199000: 0.498250\n",
      "2022-11-08 11:35:19,635 INFO     Training average positive_sample_loss at step 199100: 0.685077\n",
      "2022-11-08 11:35:19,636 INFO     Training average negative_sample_loss at step 199100: 0.320244\n",
      "2022-11-08 11:35:19,636 INFO     Training average loss at step 199100: 0.502661\n",
      "2022-11-08 11:35:29,533 INFO     Training average positive_sample_loss at step 199200: 0.658896\n",
      "2022-11-08 11:35:29,533 INFO     Training average negative_sample_loss at step 199200: 0.318752\n",
      "2022-11-08 11:35:29,533 INFO     Training average loss at step 199200: 0.488824\n",
      "2022-11-08 11:35:39,523 INFO     Training average positive_sample_loss at step 199300: 0.641937\n",
      "2022-11-08 11:35:39,523 INFO     Training average negative_sample_loss at step 199300: 0.326556\n",
      "2022-11-08 11:35:39,523 INFO     Training average loss at step 199300: 0.484246\n",
      "2022-11-08 11:35:48,816 INFO     Training average positive_sample_loss at step 199400: 0.700420\n",
      "2022-11-08 11:35:48,816 INFO     Training average negative_sample_loss at step 199400: 0.323137\n",
      "2022-11-08 11:35:48,816 INFO     Training average loss at step 199400: 0.511778\n",
      "2022-11-08 11:35:58,731 INFO     Training average positive_sample_loss at step 199500: 0.667465\n",
      "2022-11-08 11:35:58,731 INFO     Training average negative_sample_loss at step 199500: 0.323852\n",
      "2022-11-08 11:35:58,731 INFO     Training average loss at step 199500: 0.495659\n",
      "2022-11-08 11:36:08,661 INFO     Training average positive_sample_loss at step 199600: 0.680506\n",
      "2022-11-08 11:36:08,661 INFO     Training average negative_sample_loss at step 199600: 0.327871\n",
      "2022-11-08 11:36:08,661 INFO     Training average loss at step 199600: 0.504188\n",
      "2022-11-08 11:36:18,574 INFO     Training average positive_sample_loss at step 199700: 0.679722\n",
      "2022-11-08 11:36:18,574 INFO     Training average negative_sample_loss at step 199700: 0.326474\n",
      "2022-11-08 11:36:18,574 INFO     Training average loss at step 199700: 0.503098\n",
      "2022-11-08 11:36:28,493 INFO     Training average positive_sample_loss at step 199800: 0.682232\n",
      "2022-11-08 11:36:28,493 INFO     Training average negative_sample_loss at step 199800: 0.321502\n",
      "2022-11-08 11:36:28,493 INFO     Training average loss at step 199800: 0.501867\n",
      "2022-11-08 11:36:38,435 INFO     Training average positive_sample_loss at step 199900: 0.687087\n",
      "2022-11-08 11:36:38,435 INFO     Training average negative_sample_loss at step 199900: 0.329767\n",
      "2022-11-08 11:36:38,435 INFO     Training average loss at step 199900: 0.508427\n",
      "2022-11-08 11:36:51,419 INFO     Training average positive_sample_loss at step 200000: 0.680424\n",
      "2022-11-08 11:36:51,419 INFO     Training average negative_sample_loss at step 200000: 0.327867\n",
      "2022-11-08 11:36:51,419 INFO     Training average loss at step 200000: 0.504145\n",
      "2022-11-08 11:37:02,284 INFO     Training average positive_sample_loss at step 200100: 0.669404\n",
      "2022-11-08 11:37:02,285 INFO     Training average negative_sample_loss at step 200100: 0.329341\n",
      "2022-11-08 11:37:02,285 INFO     Training average loss at step 200100: 0.499372\n",
      "2022-11-08 11:37:12,247 INFO     Training average positive_sample_loss at step 200200: 0.668552\n",
      "2022-11-08 11:37:12,247 INFO     Training average negative_sample_loss at step 200200: 0.324481\n",
      "2022-11-08 11:37:12,247 INFO     Training average loss at step 200200: 0.496517\n",
      "2022-11-08 11:37:22,188 INFO     Training average positive_sample_loss at step 200300: 0.663496\n",
      "2022-11-08 11:37:22,188 INFO     Training average negative_sample_loss at step 200300: 0.321254\n",
      "2022-11-08 11:37:22,188 INFO     Training average loss at step 200300: 0.492375\n",
      "2022-11-08 11:37:32,098 INFO     Training average positive_sample_loss at step 200400: 0.667617\n",
      "2022-11-08 11:37:32,099 INFO     Training average negative_sample_loss at step 200400: 0.326661\n",
      "2022-11-08 11:37:32,099 INFO     Training average loss at step 200400: 0.497139\n",
      "2022-11-08 11:37:41,982 INFO     Training average positive_sample_loss at step 200500: 0.668065\n",
      "2022-11-08 11:37:41,982 INFO     Training average negative_sample_loss at step 200500: 0.324525\n",
      "2022-11-08 11:37:41,982 INFO     Training average loss at step 200500: 0.496295\n",
      "2022-11-08 11:37:51,925 INFO     Training average positive_sample_loss at step 200600: 0.629121\n",
      "2022-11-08 11:37:51,925 INFO     Training average negative_sample_loss at step 200600: 0.324307\n",
      "2022-11-08 11:37:51,925 INFO     Training average loss at step 200600: 0.476714\n",
      "2022-11-08 11:38:01,818 INFO     Training average positive_sample_loss at step 200700: 0.653815\n",
      "2022-11-08 11:38:01,818 INFO     Training average negative_sample_loss at step 200700: 0.327936\n",
      "2022-11-08 11:38:01,818 INFO     Training average loss at step 200700: 0.490876\n",
      "2022-11-08 11:38:11,718 INFO     Training average positive_sample_loss at step 200800: 0.671510\n",
      "2022-11-08 11:38:11,718 INFO     Training average negative_sample_loss at step 200800: 0.321771\n",
      "2022-11-08 11:38:11,718 INFO     Training average loss at step 200800: 0.496641\n",
      "2022-11-08 11:38:21,842 INFO     Training average positive_sample_loss at step 200900: 0.670684\n",
      "2022-11-08 11:38:21,842 INFO     Training average negative_sample_loss at step 200900: 0.321235\n",
      "2022-11-08 11:38:21,842 INFO     Training average loss at step 200900: 0.495959\n",
      "2022-11-08 11:38:31,839 INFO     Training average positive_sample_loss at step 201000: 0.666579\n",
      "2022-11-08 11:38:31,839 INFO     Training average negative_sample_loss at step 201000: 0.319774\n",
      "2022-11-08 11:38:31,840 INFO     Training average loss at step 201000: 0.493177\n",
      "2022-11-08 11:38:42,202 INFO     Training average positive_sample_loss at step 201100: 0.665203\n",
      "2022-11-08 11:38:42,202 INFO     Training average negative_sample_loss at step 201100: 0.318664\n",
      "2022-11-08 11:38:42,202 INFO     Training average loss at step 201100: 0.491933\n",
      "2022-11-08 11:38:53,155 INFO     Training average positive_sample_loss at step 201200: 0.636736\n",
      "2022-11-08 11:38:53,155 INFO     Training average negative_sample_loss at step 201200: 0.321661\n",
      "2022-11-08 11:38:53,155 INFO     Training average loss at step 201200: 0.479199\n",
      "2022-11-08 11:39:03,806 INFO     Training average positive_sample_loss at step 201300: 0.662765\n",
      "2022-11-08 11:39:03,807 INFO     Training average negative_sample_loss at step 201300: 0.326069\n",
      "2022-11-08 11:39:03,807 INFO     Training average loss at step 201300: 0.494417\n",
      "2022-11-08 11:39:13,749 INFO     Training average positive_sample_loss at step 201400: 0.665097\n",
      "2022-11-08 11:39:13,749 INFO     Training average negative_sample_loss at step 201400: 0.325150\n",
      "2022-11-08 11:39:13,749 INFO     Training average loss at step 201400: 0.495123\n",
      "2022-11-08 11:39:23,714 INFO     Training average positive_sample_loss at step 201500: 0.654742\n",
      "2022-11-08 11:39:23,714 INFO     Training average negative_sample_loss at step 201500: 0.323378\n",
      "2022-11-08 11:39:23,714 INFO     Training average loss at step 201500: 0.489060\n",
      "2022-11-08 11:39:33,716 INFO     Training average positive_sample_loss at step 201600: 0.688663\n",
      "2022-11-08 11:39:33,716 INFO     Training average negative_sample_loss at step 201600: 0.325599\n",
      "2022-11-08 11:39:33,716 INFO     Training average loss at step 201600: 0.507131\n",
      "2022-11-08 11:39:43,688 INFO     Training average positive_sample_loss at step 201700: 0.673316\n",
      "2022-11-08 11:39:43,688 INFO     Training average negative_sample_loss at step 201700: 0.316460\n",
      "2022-11-08 11:39:43,688 INFO     Training average loss at step 201700: 0.494888\n",
      "2022-11-08 11:39:53,614 INFO     Training average positive_sample_loss at step 201800: 0.669628\n",
      "2022-11-08 11:39:53,614 INFO     Training average negative_sample_loss at step 201800: 0.326128\n",
      "2022-11-08 11:39:53,614 INFO     Training average loss at step 201800: 0.497878\n",
      "2022-11-08 11:40:03,561 INFO     Training average positive_sample_loss at step 201900: 0.647806\n",
      "2022-11-08 11:40:03,561 INFO     Training average negative_sample_loss at step 201900: 0.326459\n",
      "2022-11-08 11:40:03,562 INFO     Training average loss at step 201900: 0.487133\n",
      "2022-11-08 11:40:13,527 INFO     Training average positive_sample_loss at step 202000: 0.658112\n",
      "2022-11-08 11:40:13,527 INFO     Training average negative_sample_loss at step 202000: 0.324620\n",
      "2022-11-08 11:40:13,527 INFO     Training average loss at step 202000: 0.491366\n",
      "2022-11-08 11:40:23,470 INFO     Training average positive_sample_loss at step 202100: 0.648905\n",
      "2022-11-08 11:40:23,470 INFO     Training average negative_sample_loss at step 202100: 0.321042\n",
      "2022-11-08 11:40:23,471 INFO     Training average loss at step 202100: 0.484974\n",
      "2022-11-08 11:40:33,468 INFO     Training average positive_sample_loss at step 202200: 0.662468\n",
      "2022-11-08 11:40:33,468 INFO     Training average negative_sample_loss at step 202200: 0.326518\n",
      "2022-11-08 11:40:33,468 INFO     Training average loss at step 202200: 0.494493\n",
      "2022-11-08 11:40:43,441 INFO     Training average positive_sample_loss at step 202300: 0.655064\n",
      "2022-11-08 11:40:43,441 INFO     Training average negative_sample_loss at step 202300: 0.322313\n",
      "2022-11-08 11:40:43,441 INFO     Training average loss at step 202300: 0.488689\n",
      "2022-11-08 11:40:53,397 INFO     Training average positive_sample_loss at step 202400: 0.645289\n",
      "2022-11-08 11:40:53,398 INFO     Training average negative_sample_loss at step 202400: 0.322284\n",
      "2022-11-08 11:40:53,398 INFO     Training average loss at step 202400: 0.483786\n",
      "2022-11-08 11:41:03,367 INFO     Training average positive_sample_loss at step 202500: 0.635454\n",
      "2022-11-08 11:41:03,367 INFO     Training average negative_sample_loss at step 202500: 0.327005\n",
      "2022-11-08 11:41:03,367 INFO     Training average loss at step 202500: 0.481229\n",
      "2022-11-08 11:41:13,381 INFO     Training average positive_sample_loss at step 202600: 0.651839\n",
      "2022-11-08 11:41:13,381 INFO     Training average negative_sample_loss at step 202600: 0.319687\n",
      "2022-11-08 11:41:13,381 INFO     Training average loss at step 202600: 0.485763\n",
      "2022-11-08 11:41:23,356 INFO     Training average positive_sample_loss at step 202700: 0.654841\n",
      "2022-11-08 11:41:23,356 INFO     Training average negative_sample_loss at step 202700: 0.323814\n",
      "2022-11-08 11:41:23,356 INFO     Training average loss at step 202700: 0.489327\n",
      "2022-11-08 11:41:33,325 INFO     Training average positive_sample_loss at step 202800: 0.675436\n",
      "2022-11-08 11:41:33,326 INFO     Training average negative_sample_loss at step 202800: 0.319941\n",
      "2022-11-08 11:41:33,326 INFO     Training average loss at step 202800: 0.497688\n",
      "2022-11-08 11:41:43,189 INFO     Training average positive_sample_loss at step 202900: 0.645957\n",
      "2022-11-08 11:41:43,189 INFO     Training average negative_sample_loss at step 202900: 0.322329\n",
      "2022-11-08 11:41:43,189 INFO     Training average loss at step 202900: 0.484143\n",
      "2022-11-08 11:41:53,034 INFO     Training average positive_sample_loss at step 203000: 0.644238\n",
      "2022-11-08 11:41:53,035 INFO     Training average negative_sample_loss at step 203000: 0.319406\n",
      "2022-11-08 11:41:53,035 INFO     Training average loss at step 203000: 0.481822\n",
      "2022-11-08 11:42:02,883 INFO     Training average positive_sample_loss at step 203100: 0.672571\n",
      "2022-11-08 11:42:02,883 INFO     Training average negative_sample_loss at step 203100: 0.327698\n",
      "2022-11-08 11:42:02,883 INFO     Training average loss at step 203100: 0.500134\n",
      "2022-11-08 11:42:12,739 INFO     Training average positive_sample_loss at step 203200: 0.638023\n",
      "2022-11-08 11:42:12,739 INFO     Training average negative_sample_loss at step 203200: 0.323936\n",
      "2022-11-08 11:42:12,739 INFO     Training average loss at step 203200: 0.480979\n",
      "2022-11-08 11:42:22,644 INFO     Training average positive_sample_loss at step 203300: 0.649946\n",
      "2022-11-08 11:42:22,644 INFO     Training average negative_sample_loss at step 203300: 0.319741\n",
      "2022-11-08 11:42:22,644 INFO     Training average loss at step 203300: 0.484844\n",
      "2022-11-08 11:42:32,644 INFO     Training average positive_sample_loss at step 203400: 0.650173\n",
      "2022-11-08 11:42:32,644 INFO     Training average negative_sample_loss at step 203400: 0.323351\n",
      "2022-11-08 11:42:32,645 INFO     Training average loss at step 203400: 0.486762\n",
      "2022-11-08 11:42:42,575 INFO     Training average positive_sample_loss at step 203500: 0.640020\n",
      "2022-11-08 11:42:42,575 INFO     Training average negative_sample_loss at step 203500: 0.319822\n",
      "2022-11-08 11:42:42,575 INFO     Training average loss at step 203500: 0.479921\n",
      "2022-11-08 11:42:52,423 INFO     Training average positive_sample_loss at step 203600: 0.672089\n",
      "2022-11-08 11:42:52,423 INFO     Training average negative_sample_loss at step 203600: 0.317445\n",
      "2022-11-08 11:42:52,423 INFO     Training average loss at step 203600: 0.494767\n",
      "2022-11-08 11:43:02,321 INFO     Training average positive_sample_loss at step 203700: 0.659525\n",
      "2022-11-08 11:43:02,321 INFO     Training average negative_sample_loss at step 203700: 0.320104\n",
      "2022-11-08 11:43:02,321 INFO     Training average loss at step 203700: 0.489815\n",
      "2022-11-08 11:43:12,172 INFO     Training average positive_sample_loss at step 203800: 0.651065\n",
      "2022-11-08 11:43:12,172 INFO     Training average negative_sample_loss at step 203800: 0.323536\n",
      "2022-11-08 11:43:12,172 INFO     Training average loss at step 203800: 0.487300\n",
      "2022-11-08 11:43:22,026 INFO     Training average positive_sample_loss at step 203900: 0.650124\n",
      "2022-11-08 11:43:22,026 INFO     Training average negative_sample_loss at step 203900: 0.324340\n",
      "2022-11-08 11:43:22,026 INFO     Training average loss at step 203900: 0.487232\n",
      "2022-11-08 11:43:31,900 INFO     Training average positive_sample_loss at step 204000: 0.659621\n",
      "2022-11-08 11:43:31,900 INFO     Training average negative_sample_loss at step 204000: 0.323287\n",
      "2022-11-08 11:43:31,900 INFO     Training average loss at step 204000: 0.491454\n",
      "2022-11-08 11:43:41,741 INFO     Training average positive_sample_loss at step 204100: 0.637407\n",
      "2022-11-08 11:43:41,741 INFO     Training average negative_sample_loss at step 204100: 0.334075\n",
      "2022-11-08 11:43:41,741 INFO     Training average loss at step 204100: 0.485741\n",
      "2022-11-08 11:43:51,594 INFO     Training average positive_sample_loss at step 204200: 0.646390\n",
      "2022-11-08 11:43:51,594 INFO     Training average negative_sample_loss at step 204200: 0.318308\n",
      "2022-11-08 11:43:51,594 INFO     Training average loss at step 204200: 0.482349\n",
      "2022-11-08 11:44:00,728 INFO     Training average positive_sample_loss at step 204300: 0.675242\n",
      "2022-11-08 11:44:00,728 INFO     Training average negative_sample_loss at step 204300: 0.320925\n",
      "2022-11-08 11:44:00,728 INFO     Training average loss at step 204300: 0.498083\n",
      "2022-11-08 11:44:10,574 INFO     Training average positive_sample_loss at step 204400: 0.663969\n",
      "2022-11-08 11:44:10,574 INFO     Training average negative_sample_loss at step 204400: 0.314797\n",
      "2022-11-08 11:44:10,574 INFO     Training average loss at step 204400: 0.489383\n",
      "2022-11-08 11:44:20,412 INFO     Training average positive_sample_loss at step 204500: 0.665386\n",
      "2022-11-08 11:44:20,412 INFO     Training average negative_sample_loss at step 204500: 0.322081\n",
      "2022-11-08 11:44:20,412 INFO     Training average loss at step 204500: 0.493733\n",
      "2022-11-08 11:44:30,258 INFO     Training average positive_sample_loss at step 204600: 0.666385\n",
      "2022-11-08 11:44:30,258 INFO     Training average negative_sample_loss at step 204600: 0.320560\n",
      "2022-11-08 11:44:30,258 INFO     Training average loss at step 204600: 0.493473\n",
      "2022-11-08 11:44:40,101 INFO     Training average positive_sample_loss at step 204700: 0.628957\n",
      "2022-11-08 11:44:40,101 INFO     Training average negative_sample_loss at step 204700: 0.325808\n",
      "2022-11-08 11:44:40,101 INFO     Training average loss at step 204700: 0.477382\n",
      "2022-11-08 11:44:49,330 INFO     Training average positive_sample_loss at step 204800: 0.620909\n",
      "2022-11-08 11:44:49,331 INFO     Training average negative_sample_loss at step 204800: 0.323721\n",
      "2022-11-08 11:44:49,331 INFO     Training average loss at step 204800: 0.472315\n",
      "2022-11-08 11:44:58,865 INFO     Training average positive_sample_loss at step 204900: 0.673969\n",
      "2022-11-08 11:44:58,865 INFO     Training average negative_sample_loss at step 204900: 0.320757\n",
      "2022-11-08 11:44:58,865 INFO     Training average loss at step 204900: 0.497363\n",
      "2022-11-08 11:45:08,396 INFO     Training average positive_sample_loss at step 205000: 0.636703\n",
      "2022-11-08 11:45:08,396 INFO     Training average negative_sample_loss at step 205000: 0.321110\n",
      "2022-11-08 11:45:08,396 INFO     Training average loss at step 205000: 0.478907\n",
      "2022-11-08 11:45:17,921 INFO     Training average positive_sample_loss at step 205100: 0.681226\n",
      "2022-11-08 11:45:17,921 INFO     Training average negative_sample_loss at step 205100: 0.319012\n",
      "2022-11-08 11:45:17,921 INFO     Training average loss at step 205100: 0.500119\n",
      "2022-11-08 11:45:27,448 INFO     Training average positive_sample_loss at step 205200: 0.657222\n",
      "2022-11-08 11:45:27,448 INFO     Training average negative_sample_loss at step 205200: 0.323561\n",
      "2022-11-08 11:45:27,448 INFO     Training average loss at step 205200: 0.490392\n",
      "2022-11-08 11:45:36,973 INFO     Training average positive_sample_loss at step 205300: 0.666954\n",
      "2022-11-08 11:45:36,973 INFO     Training average negative_sample_loss at step 205300: 0.316802\n",
      "2022-11-08 11:45:36,973 INFO     Training average loss at step 205300: 0.491878\n",
      "2022-11-08 11:45:46,496 INFO     Training average positive_sample_loss at step 205400: 0.629850\n",
      "2022-11-08 11:45:46,496 INFO     Training average negative_sample_loss at step 205400: 0.325749\n",
      "2022-11-08 11:45:46,496 INFO     Training average loss at step 205400: 0.477800\n",
      "2022-11-08 11:45:56,030 INFO     Training average positive_sample_loss at step 205500: 0.623435\n",
      "2022-11-08 11:45:56,030 INFO     Training average negative_sample_loss at step 205500: 0.321565\n",
      "2022-11-08 11:45:56,030 INFO     Training average loss at step 205500: 0.472500\n",
      "2022-11-08 11:46:05,556 INFO     Training average positive_sample_loss at step 205600: 0.636489\n",
      "2022-11-08 11:46:05,556 INFO     Training average negative_sample_loss at step 205600: 0.319366\n",
      "2022-11-08 11:46:05,556 INFO     Training average loss at step 205600: 0.477928\n",
      "2022-11-08 11:46:16,290 INFO     Training average positive_sample_loss at step 205700: 0.668397\n",
      "2022-11-08 11:46:16,290 INFO     Training average negative_sample_loss at step 205700: 0.317353\n",
      "2022-11-08 11:46:16,290 INFO     Training average loss at step 205700: 0.492875\n",
      "2022-11-08 11:46:25,816 INFO     Training average positive_sample_loss at step 205800: 0.653469\n",
      "2022-11-08 11:46:25,816 INFO     Training average negative_sample_loss at step 205800: 0.324170\n",
      "2022-11-08 11:46:25,816 INFO     Training average loss at step 205800: 0.488819\n",
      "2022-11-08 11:46:35,610 INFO     Training average positive_sample_loss at step 205900: 0.650777\n",
      "2022-11-08 11:46:35,610 INFO     Training average negative_sample_loss at step 205900: 0.323301\n",
      "2022-11-08 11:46:35,610 INFO     Training average loss at step 205900: 0.487039\n",
      "2022-11-08 11:46:45,795 INFO     Training average positive_sample_loss at step 206000: 0.657704\n",
      "2022-11-08 11:46:45,795 INFO     Training average negative_sample_loss at step 206000: 0.321958\n",
      "2022-11-08 11:46:45,795 INFO     Training average loss at step 206000: 0.489831\n",
      "2022-11-08 11:46:55,320 INFO     Training average positive_sample_loss at step 206100: 0.644778\n",
      "2022-11-08 11:46:55,320 INFO     Training average negative_sample_loss at step 206100: 0.319031\n",
      "2022-11-08 11:46:55,320 INFO     Training average loss at step 206100: 0.481905\n",
      "2022-11-08 11:47:04,848 INFO     Training average positive_sample_loss at step 206200: 0.629737\n",
      "2022-11-08 11:47:04,848 INFO     Training average negative_sample_loss at step 206200: 0.325224\n",
      "2022-11-08 11:47:04,848 INFO     Training average loss at step 206200: 0.477481\n",
      "2022-11-08 11:47:14,372 INFO     Training average positive_sample_loss at step 206300: 0.656940\n",
      "2022-11-08 11:47:14,372 INFO     Training average negative_sample_loss at step 206300: 0.316101\n",
      "2022-11-08 11:47:14,372 INFO     Training average loss at step 206300: 0.486520\n",
      "2022-11-08 11:47:23,902 INFO     Training average positive_sample_loss at step 206400: 0.664530\n",
      "2022-11-08 11:47:23,902 INFO     Training average negative_sample_loss at step 206400: 0.320371\n",
      "2022-11-08 11:47:23,902 INFO     Training average loss at step 206400: 0.492450\n",
      "2022-11-08 11:47:33,427 INFO     Training average positive_sample_loss at step 206500: 0.647091\n",
      "2022-11-08 11:47:33,428 INFO     Training average negative_sample_loss at step 206500: 0.321748\n",
      "2022-11-08 11:47:33,428 INFO     Training average loss at step 206500: 0.484419\n",
      "2022-11-08 11:47:42,949 INFO     Training average positive_sample_loss at step 206600: 0.632234\n",
      "2022-11-08 11:47:42,949 INFO     Training average negative_sample_loss at step 206600: 0.316982\n",
      "2022-11-08 11:47:42,949 INFO     Training average loss at step 206600: 0.474608\n",
      "2022-11-08 11:47:52,476 INFO     Training average positive_sample_loss at step 206700: 0.640050\n",
      "2022-11-08 11:47:52,476 INFO     Training average negative_sample_loss at step 206700: 0.327016\n",
      "2022-11-08 11:47:52,476 INFO     Training average loss at step 206700: 0.483533\n",
      "2022-11-08 11:48:02,003 INFO     Training average positive_sample_loss at step 206800: 0.619402\n",
      "2022-11-08 11:48:02,003 INFO     Training average negative_sample_loss at step 206800: 0.313621\n",
      "2022-11-08 11:48:02,003 INFO     Training average loss at step 206800: 0.466512\n",
      "2022-11-08 11:48:11,528 INFO     Training average positive_sample_loss at step 206900: 0.623320\n",
      "2022-11-08 11:48:11,528 INFO     Training average negative_sample_loss at step 206900: 0.323298\n",
      "2022-11-08 11:48:11,528 INFO     Training average loss at step 206900: 0.473309\n",
      "2022-11-08 11:48:21,058 INFO     Training average positive_sample_loss at step 207000: 0.679094\n",
      "2022-11-08 11:48:21,058 INFO     Training average negative_sample_loss at step 207000: 0.323410\n",
      "2022-11-08 11:48:21,058 INFO     Training average loss at step 207000: 0.501252\n",
      "2022-11-08 11:48:30,581 INFO     Training average positive_sample_loss at step 207100: 0.665796\n",
      "2022-11-08 11:48:30,581 INFO     Training average negative_sample_loss at step 207100: 0.315287\n",
      "2022-11-08 11:48:30,581 INFO     Training average loss at step 207100: 0.490542\n",
      "2022-11-08 11:48:40,107 INFO     Training average positive_sample_loss at step 207200: 0.668099\n",
      "2022-11-08 11:48:40,107 INFO     Training average negative_sample_loss at step 207200: 0.320513\n",
      "2022-11-08 11:48:40,107 INFO     Training average loss at step 207200: 0.494306\n",
      "2022-11-08 11:48:49,634 INFO     Training average positive_sample_loss at step 207300: 0.664124\n",
      "2022-11-08 11:48:49,635 INFO     Training average negative_sample_loss at step 207300: 0.313254\n",
      "2022-11-08 11:48:49,635 INFO     Training average loss at step 207300: 0.488689\n",
      "2022-11-08 11:48:59,159 INFO     Training average positive_sample_loss at step 207400: 0.659166\n",
      "2022-11-08 11:48:59,159 INFO     Training average negative_sample_loss at step 207400: 0.321591\n",
      "2022-11-08 11:48:59,159 INFO     Training average loss at step 207400: 0.490378\n",
      "2022-11-08 11:49:08,687 INFO     Training average positive_sample_loss at step 207500: 0.634130\n",
      "2022-11-08 11:49:08,687 INFO     Training average negative_sample_loss at step 207500: 0.314958\n",
      "2022-11-08 11:49:08,687 INFO     Training average loss at step 207500: 0.474544\n",
      "2022-11-08 11:49:18,217 INFO     Training average positive_sample_loss at step 207600: 0.624027\n",
      "2022-11-08 11:49:18,217 INFO     Training average negative_sample_loss at step 207600: 0.314408\n",
      "2022-11-08 11:49:18,217 INFO     Training average loss at step 207600: 0.469217\n",
      "2022-11-08 11:49:27,739 INFO     Training average positive_sample_loss at step 207700: 0.647975\n",
      "2022-11-08 11:49:27,739 INFO     Training average negative_sample_loss at step 207700: 0.320452\n",
      "2022-11-08 11:49:27,739 INFO     Training average loss at step 207700: 0.484214\n",
      "2022-11-08 11:49:37,265 INFO     Training average positive_sample_loss at step 207800: 0.654608\n",
      "2022-11-08 11:49:37,265 INFO     Training average negative_sample_loss at step 207800: 0.316052\n",
      "2022-11-08 11:49:37,265 INFO     Training average loss at step 207800: 0.485330\n",
      "2022-11-08 11:49:46,793 INFO     Training average positive_sample_loss at step 207900: 0.657821\n",
      "2022-11-08 11:49:46,793 INFO     Training average negative_sample_loss at step 207900: 0.315232\n",
      "2022-11-08 11:49:46,793 INFO     Training average loss at step 207900: 0.486527\n",
      "2022-11-08 11:49:56,317 INFO     Training average positive_sample_loss at step 208000: 0.650496\n",
      "2022-11-08 11:49:56,317 INFO     Training average negative_sample_loss at step 208000: 0.318145\n",
      "2022-11-08 11:49:56,317 INFO     Training average loss at step 208000: 0.484320\n",
      "2022-11-08 11:50:06,001 INFO     Training average positive_sample_loss at step 208100: 0.632754\n",
      "2022-11-08 11:50:06,001 INFO     Training average negative_sample_loss at step 208100: 0.319006\n",
      "2022-11-08 11:50:06,001 INFO     Training average loss at step 208100: 0.475880\n",
      "2022-11-08 11:50:15,779 INFO     Training average positive_sample_loss at step 208200: 0.644710\n",
      "2022-11-08 11:50:15,779 INFO     Training average negative_sample_loss at step 208200: 0.329174\n",
      "2022-11-08 11:50:15,779 INFO     Training average loss at step 208200: 0.486942\n",
      "2022-11-08 11:50:25,310 INFO     Training average positive_sample_loss at step 208300: 0.637962\n",
      "2022-11-08 11:50:25,310 INFO     Training average negative_sample_loss at step 208300: 0.320007\n",
      "2022-11-08 11:50:25,310 INFO     Training average loss at step 208300: 0.478985\n",
      "2022-11-08 11:50:34,837 INFO     Training average positive_sample_loss at step 208400: 0.654106\n",
      "2022-11-08 11:50:34,837 INFO     Training average negative_sample_loss at step 208400: 0.314098\n",
      "2022-11-08 11:50:34,837 INFO     Training average loss at step 208400: 0.484102\n",
      "2022-11-08 11:50:44,366 INFO     Training average positive_sample_loss at step 208500: 0.654374\n",
      "2022-11-08 11:50:44,366 INFO     Training average negative_sample_loss at step 208500: 0.319333\n",
      "2022-11-08 11:50:44,366 INFO     Training average loss at step 208500: 0.486853\n",
      "2022-11-08 11:50:53,893 INFO     Training average positive_sample_loss at step 208600: 0.647994\n",
      "2022-11-08 11:50:53,893 INFO     Training average negative_sample_loss at step 208600: 0.316819\n",
      "2022-11-08 11:50:53,893 INFO     Training average loss at step 208600: 0.482407\n",
      "2022-11-08 11:51:03,420 INFO     Training average positive_sample_loss at step 208700: 0.659213\n",
      "2022-11-08 11:51:03,420 INFO     Training average negative_sample_loss at step 208700: 0.323453\n",
      "2022-11-08 11:51:03,420 INFO     Training average loss at step 208700: 0.491333\n",
      "2022-11-08 11:51:12,944 INFO     Training average positive_sample_loss at step 208800: 0.661755\n",
      "2022-11-08 11:51:12,944 INFO     Training average negative_sample_loss at step 208800: 0.314984\n",
      "2022-11-08 11:51:12,944 INFO     Training average loss at step 208800: 0.488370\n",
      "2022-11-08 11:51:22,469 INFO     Training average positive_sample_loss at step 208900: 0.652848\n",
      "2022-11-08 11:51:22,469 INFO     Training average negative_sample_loss at step 208900: 0.306652\n",
      "2022-11-08 11:51:22,469 INFO     Training average loss at step 208900: 0.479750\n",
      "2022-11-08 11:51:31,995 INFO     Training average positive_sample_loss at step 209000: 0.653784\n",
      "2022-11-08 11:51:31,996 INFO     Training average negative_sample_loss at step 209000: 0.317921\n",
      "2022-11-08 11:51:31,996 INFO     Training average loss at step 209000: 0.485853\n",
      "2022-11-08 11:51:41,525 INFO     Training average positive_sample_loss at step 209100: 0.636373\n",
      "2022-11-08 11:51:41,525 INFO     Training average negative_sample_loss at step 209100: 0.320557\n",
      "2022-11-08 11:51:41,525 INFO     Training average loss at step 209100: 0.478465\n",
      "2022-11-08 11:51:51,051 INFO     Training average positive_sample_loss at step 209200: 0.644812\n",
      "2022-11-08 11:51:51,051 INFO     Training average negative_sample_loss at step 209200: 0.320183\n",
      "2022-11-08 11:51:51,051 INFO     Training average loss at step 209200: 0.482497\n",
      "2022-11-08 11:52:00,579 INFO     Training average positive_sample_loss at step 209300: 0.624368\n",
      "2022-11-08 11:52:00,579 INFO     Training average negative_sample_loss at step 209300: 0.318127\n",
      "2022-11-08 11:52:00,579 INFO     Training average loss at step 209300: 0.471248\n",
      "2022-11-08 11:52:10,102 INFO     Training average positive_sample_loss at step 209400: 0.647197\n",
      "2022-11-08 11:52:10,102 INFO     Training average negative_sample_loss at step 209400: 0.317934\n",
      "2022-11-08 11:52:10,102 INFO     Training average loss at step 209400: 0.482565\n",
      "2022-11-08 11:52:19,630 INFO     Training average positive_sample_loss at step 209500: 0.634510\n",
      "2022-11-08 11:52:19,630 INFO     Training average negative_sample_loss at step 209500: 0.322531\n",
      "2022-11-08 11:52:19,631 INFO     Training average loss at step 209500: 0.478521\n",
      "2022-11-08 11:52:29,163 INFO     Training average positive_sample_loss at step 209600: 0.633896\n",
      "2022-11-08 11:52:29,163 INFO     Training average negative_sample_loss at step 209600: 0.315445\n",
      "2022-11-08 11:52:29,163 INFO     Training average loss at step 209600: 0.474671\n",
      "2022-11-08 11:52:38,690 INFO     Training average positive_sample_loss at step 209700: 0.646591\n",
      "2022-11-08 11:52:38,691 INFO     Training average negative_sample_loss at step 209700: 0.319716\n",
      "2022-11-08 11:52:38,691 INFO     Training average loss at step 209700: 0.483153\n",
      "2022-11-08 11:52:47,547 INFO     Training average positive_sample_loss at step 209800: 0.657888\n",
      "2022-11-08 11:52:47,547 INFO     Training average negative_sample_loss at step 209800: 0.314124\n",
      "2022-11-08 11:52:47,547 INFO     Training average loss at step 209800: 0.486006\n",
      "2022-11-08 11:52:57,072 INFO     Training average positive_sample_loss at step 209900: 0.645719\n",
      "2022-11-08 11:52:57,072 INFO     Training average negative_sample_loss at step 209900: 0.316689\n",
      "2022-11-08 11:52:57,072 INFO     Training average loss at step 209900: 0.481204\n",
      "2022-11-08 11:53:09,263 INFO     Training average positive_sample_loss at step 210000: 0.658653\n",
      "2022-11-08 11:53:09,263 INFO     Training average negative_sample_loss at step 210000: 0.312889\n",
      "2022-11-08 11:53:09,263 INFO     Training average loss at step 210000: 0.485771\n",
      "2022-11-08 11:53:18,789 INFO     Training average positive_sample_loss at step 210100: 0.638549\n",
      "2022-11-08 11:53:18,790 INFO     Training average negative_sample_loss at step 210100: 0.315017\n",
      "2022-11-08 11:53:18,790 INFO     Training average loss at step 210100: 0.476783\n",
      "2022-11-08 11:53:28,315 INFO     Training average positive_sample_loss at step 210200: 0.637569\n",
      "2022-11-08 11:53:28,315 INFO     Training average negative_sample_loss at step 210200: 0.313879\n",
      "2022-11-08 11:53:28,315 INFO     Training average loss at step 210200: 0.475724\n",
      "2022-11-08 11:53:38,083 INFO     Training average positive_sample_loss at step 210300: 0.655179\n",
      "2022-11-08 11:53:38,083 INFO     Training average negative_sample_loss at step 210300: 0.313002\n",
      "2022-11-08 11:53:38,083 INFO     Training average loss at step 210300: 0.484091\n",
      "2022-11-08 11:53:47,987 INFO     Training average positive_sample_loss at step 210400: 0.653314\n",
      "2022-11-08 11:53:47,987 INFO     Training average negative_sample_loss at step 210400: 0.308777\n",
      "2022-11-08 11:53:47,987 INFO     Training average loss at step 210400: 0.481046\n",
      "2022-11-08 11:53:57,517 INFO     Training average positive_sample_loss at step 210500: 0.635136\n",
      "2022-11-08 11:53:57,517 INFO     Training average negative_sample_loss at step 210500: 0.313848\n",
      "2022-11-08 11:53:57,517 INFO     Training average loss at step 210500: 0.474492\n",
      "2022-11-08 11:54:07,863 INFO     Training average positive_sample_loss at step 210600: 0.650839\n",
      "2022-11-08 11:54:07,863 INFO     Training average negative_sample_loss at step 210600: 0.319664\n",
      "2022-11-08 11:54:07,863 INFO     Training average loss at step 210600: 0.485252\n",
      "2022-11-08 11:54:17,397 INFO     Training average positive_sample_loss at step 210700: 0.639654\n",
      "2022-11-08 11:54:17,397 INFO     Training average negative_sample_loss at step 210700: 0.310034\n",
      "2022-11-08 11:54:17,397 INFO     Training average loss at step 210700: 0.474844\n",
      "2022-11-08 11:54:26,926 INFO     Training average positive_sample_loss at step 210800: 0.644235\n",
      "2022-11-08 11:54:26,926 INFO     Training average negative_sample_loss at step 210800: 0.311949\n",
      "2022-11-08 11:54:26,926 INFO     Training average loss at step 210800: 0.478092\n",
      "2022-11-08 11:54:36,459 INFO     Training average positive_sample_loss at step 210900: 0.661698\n",
      "2022-11-08 11:54:36,459 INFO     Training average negative_sample_loss at step 210900: 0.313967\n",
      "2022-11-08 11:54:36,459 INFO     Training average loss at step 210900: 0.487832\n",
      "2022-11-08 11:54:45,982 INFO     Training average positive_sample_loss at step 211000: 0.608409\n",
      "2022-11-08 11:54:45,982 INFO     Training average negative_sample_loss at step 211000: 0.310280\n",
      "2022-11-08 11:54:45,982 INFO     Training average loss at step 211000: 0.459344\n",
      "2022-11-08 11:54:55,508 INFO     Training average positive_sample_loss at step 211100: 0.644180\n",
      "2022-11-08 11:54:55,509 INFO     Training average negative_sample_loss at step 211100: 0.313472\n",
      "2022-11-08 11:54:55,509 INFO     Training average loss at step 211100: 0.478826\n",
      "2022-11-08 11:55:05,036 INFO     Training average positive_sample_loss at step 211200: 0.616035\n",
      "2022-11-08 11:55:05,036 INFO     Training average negative_sample_loss at step 211200: 0.319053\n",
      "2022-11-08 11:55:05,036 INFO     Training average loss at step 211200: 0.467544\n",
      "2022-11-08 11:55:14,567 INFO     Training average positive_sample_loss at step 211300: 0.645866\n",
      "2022-11-08 11:55:14,567 INFO     Training average negative_sample_loss at step 211300: 0.314086\n",
      "2022-11-08 11:55:14,567 INFO     Training average loss at step 211300: 0.479976\n",
      "2022-11-08 11:55:24,096 INFO     Training average positive_sample_loss at step 211400: 0.642337\n",
      "2022-11-08 11:55:24,096 INFO     Training average negative_sample_loss at step 211400: 0.317463\n",
      "2022-11-08 11:55:24,096 INFO     Training average loss at step 211400: 0.479900\n",
      "2022-11-08 11:55:33,629 INFO     Training average positive_sample_loss at step 211500: 0.617099\n",
      "2022-11-08 11:55:33,629 INFO     Training average negative_sample_loss at step 211500: 0.324234\n",
      "2022-11-08 11:55:33,629 INFO     Training average loss at step 211500: 0.470667\n",
      "2022-11-08 11:55:43,154 INFO     Training average positive_sample_loss at step 211600: 0.666709\n",
      "2022-11-08 11:55:43,154 INFO     Training average negative_sample_loss at step 211600: 0.315754\n",
      "2022-11-08 11:55:43,154 INFO     Training average loss at step 211600: 0.491232\n",
      "2022-11-08 11:55:52,684 INFO     Training average positive_sample_loss at step 211700: 0.612272\n",
      "2022-11-08 11:55:52,684 INFO     Training average negative_sample_loss at step 211700: 0.317080\n",
      "2022-11-08 11:55:52,684 INFO     Training average loss at step 211700: 0.464676\n",
      "2022-11-08 11:56:02,214 INFO     Training average positive_sample_loss at step 211800: 0.632491\n",
      "2022-11-08 11:56:02,214 INFO     Training average negative_sample_loss at step 211800: 0.310331\n",
      "2022-11-08 11:56:02,214 INFO     Training average loss at step 211800: 0.471411\n",
      "2022-11-08 11:56:11,744 INFO     Training average positive_sample_loss at step 211900: 0.647203\n",
      "2022-11-08 11:56:11,744 INFO     Training average negative_sample_loss at step 211900: 0.315973\n",
      "2022-11-08 11:56:11,744 INFO     Training average loss at step 211900: 0.481588\n",
      "2022-11-08 11:56:21,274 INFO     Training average positive_sample_loss at step 212000: 0.645378\n",
      "2022-11-08 11:56:21,274 INFO     Training average negative_sample_loss at step 212000: 0.311621\n",
      "2022-11-08 11:56:21,274 INFO     Training average loss at step 212000: 0.478500\n",
      "2022-11-08 11:56:30,798 INFO     Training average positive_sample_loss at step 212100: 0.633798\n",
      "2022-11-08 11:56:30,798 INFO     Training average negative_sample_loss at step 212100: 0.313180\n",
      "2022-11-08 11:56:30,798 INFO     Training average loss at step 212100: 0.473489\n",
      "2022-11-08 11:56:40,324 INFO     Training average positive_sample_loss at step 212200: 0.633160\n",
      "2022-11-08 11:56:40,324 INFO     Training average negative_sample_loss at step 212200: 0.311063\n",
      "2022-11-08 11:56:40,324 INFO     Training average loss at step 212200: 0.472111\n",
      "2022-11-08 11:56:49,854 INFO     Training average positive_sample_loss at step 212300: 0.651835\n",
      "2022-11-08 11:56:49,855 INFO     Training average negative_sample_loss at step 212300: 0.317606\n",
      "2022-11-08 11:56:49,855 INFO     Training average loss at step 212300: 0.484720\n",
      "2022-11-08 11:56:59,382 INFO     Training average positive_sample_loss at step 212400: 0.602803\n",
      "2022-11-08 11:56:59,382 INFO     Training average negative_sample_loss at step 212400: 0.314801\n",
      "2022-11-08 11:56:59,382 INFO     Training average loss at step 212400: 0.458802\n",
      "2022-11-08 11:57:08,913 INFO     Training average positive_sample_loss at step 212500: 0.614442\n",
      "2022-11-08 11:57:08,913 INFO     Training average negative_sample_loss at step 212500: 0.310580\n",
      "2022-11-08 11:57:08,913 INFO     Training average loss at step 212500: 0.462511\n",
      "2022-11-08 11:57:18,440 INFO     Training average positive_sample_loss at step 212600: 0.623990\n",
      "2022-11-08 11:57:18,440 INFO     Training average negative_sample_loss at step 212600: 0.311562\n",
      "2022-11-08 11:57:18,440 INFO     Training average loss at step 212600: 0.467776\n",
      "2022-11-08 11:57:27,965 INFO     Training average positive_sample_loss at step 212700: 0.662217\n",
      "2022-11-08 11:57:27,965 INFO     Training average negative_sample_loss at step 212700: 0.311234\n",
      "2022-11-08 11:57:27,965 INFO     Training average loss at step 212700: 0.486725\n",
      "2022-11-08 11:57:37,498 INFO     Training average positive_sample_loss at step 212800: 0.620871\n",
      "2022-11-08 11:57:37,498 INFO     Training average negative_sample_loss at step 212800: 0.313547\n",
      "2022-11-08 11:57:37,498 INFO     Training average loss at step 212800: 0.467209\n",
      "2022-11-08 11:57:47,024 INFO     Training average positive_sample_loss at step 212900: 0.618882\n",
      "2022-11-08 11:57:47,024 INFO     Training average negative_sample_loss at step 212900: 0.314567\n",
      "2022-11-08 11:57:47,024 INFO     Training average loss at step 212900: 0.466724\n",
      "2022-11-08 11:57:56,553 INFO     Training average positive_sample_loss at step 213000: 0.633836\n",
      "2022-11-08 11:57:56,553 INFO     Training average negative_sample_loss at step 213000: 0.310836\n",
      "2022-11-08 11:57:56,553 INFO     Training average loss at step 213000: 0.472336\n",
      "2022-11-08 11:58:06,084 INFO     Training average positive_sample_loss at step 213100: 0.660571\n",
      "2022-11-08 11:58:06,084 INFO     Training average negative_sample_loss at step 213100: 0.312610\n",
      "2022-11-08 11:58:06,084 INFO     Training average loss at step 213100: 0.486591\n",
      "2022-11-08 11:58:15,612 INFO     Training average positive_sample_loss at step 213200: 0.647242\n",
      "2022-11-08 11:58:15,612 INFO     Training average negative_sample_loss at step 213200: 0.318698\n",
      "2022-11-08 11:58:15,612 INFO     Training average loss at step 213200: 0.482970\n",
      "2022-11-08 11:58:25,141 INFO     Training average positive_sample_loss at step 213300: 0.615475\n",
      "2022-11-08 11:58:25,141 INFO     Training average negative_sample_loss at step 213300: 0.311796\n",
      "2022-11-08 11:58:25,141 INFO     Training average loss at step 213300: 0.463635\n",
      "2022-11-08 11:58:34,673 INFO     Training average positive_sample_loss at step 213400: 0.648792\n",
      "2022-11-08 11:58:34,673 INFO     Training average negative_sample_loss at step 213400: 0.309408\n",
      "2022-11-08 11:58:34,673 INFO     Training average loss at step 213400: 0.479100\n",
      "2022-11-08 11:58:44,202 INFO     Training average positive_sample_loss at step 213500: 0.625988\n",
      "2022-11-08 11:58:44,202 INFO     Training average negative_sample_loss at step 213500: 0.314812\n",
      "2022-11-08 11:58:44,202 INFO     Training average loss at step 213500: 0.470400\n",
      "2022-11-08 11:58:53,734 INFO     Training average positive_sample_loss at step 213600: 0.616448\n",
      "2022-11-08 11:58:53,734 INFO     Training average negative_sample_loss at step 213600: 0.314726\n",
      "2022-11-08 11:58:53,734 INFO     Training average loss at step 213600: 0.465587\n",
      "2022-11-08 11:59:03,263 INFO     Training average positive_sample_loss at step 213700: 0.620072\n",
      "2022-11-08 11:59:03,263 INFO     Training average negative_sample_loss at step 213700: 0.310408\n",
      "2022-11-08 11:59:03,263 INFO     Training average loss at step 213700: 0.465240\n",
      "2022-11-08 11:59:12,794 INFO     Training average positive_sample_loss at step 213800: 0.643323\n",
      "2022-11-08 11:59:12,794 INFO     Training average negative_sample_loss at step 213800: 0.309561\n",
      "2022-11-08 11:59:12,794 INFO     Training average loss at step 213800: 0.476442\n",
      "2022-11-08 11:59:22,322 INFO     Training average positive_sample_loss at step 213900: 0.635004\n",
      "2022-11-08 11:59:22,322 INFO     Training average negative_sample_loss at step 213900: 0.312236\n",
      "2022-11-08 11:59:22,322 INFO     Training average loss at step 213900: 0.473620\n",
      "2022-11-08 11:59:31,855 INFO     Training average positive_sample_loss at step 214000: 0.641110\n",
      "2022-11-08 11:59:31,855 INFO     Training average negative_sample_loss at step 214000: 0.313665\n",
      "2022-11-08 11:59:31,855 INFO     Training average loss at step 214000: 0.477388\n",
      "2022-11-08 11:59:41,384 INFO     Training average positive_sample_loss at step 214100: 0.635681\n",
      "2022-11-08 11:59:41,385 INFO     Training average negative_sample_loss at step 214100: 0.309499\n",
      "2022-11-08 11:59:41,385 INFO     Training average loss at step 214100: 0.472590\n",
      "2022-11-08 11:59:50,912 INFO     Training average positive_sample_loss at step 214200: 0.635237\n",
      "2022-11-08 11:59:50,912 INFO     Training average negative_sample_loss at step 214200: 0.313440\n",
      "2022-11-08 11:59:50,912 INFO     Training average loss at step 214200: 0.474338\n",
      "2022-11-08 12:00:00,442 INFO     Training average positive_sample_loss at step 214300: 0.620767\n",
      "2022-11-08 12:00:00,442 INFO     Training average negative_sample_loss at step 214300: 0.314487\n",
      "2022-11-08 12:00:00,442 INFO     Training average loss at step 214300: 0.467627\n",
      "2022-11-08 12:00:09,968 INFO     Training average positive_sample_loss at step 214400: 0.673004\n",
      "2022-11-08 12:00:09,968 INFO     Training average negative_sample_loss at step 214400: 0.311263\n",
      "2022-11-08 12:00:09,968 INFO     Training average loss at step 214400: 0.492134\n",
      "2022-11-08 12:00:19,501 INFO     Training average positive_sample_loss at step 214500: 0.633010\n",
      "2022-11-08 12:00:19,501 INFO     Training average negative_sample_loss at step 214500: 0.317483\n",
      "2022-11-08 12:00:19,501 INFO     Training average loss at step 214500: 0.475246\n",
      "2022-11-08 12:00:29,031 INFO     Training average positive_sample_loss at step 214600: 0.652684\n",
      "2022-11-08 12:00:29,031 INFO     Training average negative_sample_loss at step 214600: 0.313845\n",
      "2022-11-08 12:00:29,031 INFO     Training average loss at step 214600: 0.483265\n",
      "2022-11-08 12:00:38,562 INFO     Training average positive_sample_loss at step 214700: 0.626182\n",
      "2022-11-08 12:00:38,562 INFO     Training average negative_sample_loss at step 214700: 0.312560\n",
      "2022-11-08 12:00:38,562 INFO     Training average loss at step 214700: 0.469371\n",
      "2022-11-08 12:00:48,089 INFO     Training average positive_sample_loss at step 214800: 0.615776\n",
      "2022-11-08 12:00:48,089 INFO     Training average negative_sample_loss at step 214800: 0.309847\n",
      "2022-11-08 12:00:48,089 INFO     Training average loss at step 214800: 0.462811\n",
      "2022-11-08 12:00:57,615 INFO     Training average positive_sample_loss at step 214900: 0.634384\n",
      "2022-11-08 12:00:57,615 INFO     Training average negative_sample_loss at step 214900: 0.312218\n",
      "2022-11-08 12:00:57,615 INFO     Training average loss at step 214900: 0.473301\n",
      "2022-11-08 12:01:08,451 INFO     Training average positive_sample_loss at step 215000: 0.625694\n",
      "2022-11-08 12:01:08,451 INFO     Training average negative_sample_loss at step 215000: 0.313085\n",
      "2022-11-08 12:01:08,451 INFO     Training average loss at step 215000: 0.469389\n",
      "2022-11-08 12:01:18,589 INFO     Training average positive_sample_loss at step 215100: 0.627452\n",
      "2022-11-08 12:01:18,589 INFO     Training average negative_sample_loss at step 215100: 0.313951\n",
      "2022-11-08 12:01:18,589 INFO     Training average loss at step 215100: 0.470701\n",
      "2022-11-08 12:01:27,416 INFO     Training average positive_sample_loss at step 215200: 0.612546\n",
      "2022-11-08 12:01:27,416 INFO     Training average negative_sample_loss at step 215200: 0.305540\n",
      "2022-11-08 12:01:27,416 INFO     Training average loss at step 215200: 0.459043\n",
      "2022-11-08 12:01:37,453 INFO     Training average positive_sample_loss at step 215300: 0.641996\n",
      "2022-11-08 12:01:37,453 INFO     Training average negative_sample_loss at step 215300: 0.309393\n",
      "2022-11-08 12:01:37,453 INFO     Training average loss at step 215300: 0.475694\n",
      "2022-11-08 12:01:46,985 INFO     Training average positive_sample_loss at step 215400: 0.621035\n",
      "2022-11-08 12:01:46,985 INFO     Training average negative_sample_loss at step 215400: 0.312612\n",
      "2022-11-08 12:01:46,985 INFO     Training average loss at step 215400: 0.466824\n",
      "2022-11-08 12:01:56,518 INFO     Training average positive_sample_loss at step 215500: 0.628143\n",
      "2022-11-08 12:01:56,519 INFO     Training average negative_sample_loss at step 215500: 0.311745\n",
      "2022-11-08 12:01:56,519 INFO     Training average loss at step 215500: 0.469944\n",
      "2022-11-08 12:02:06,052 INFO     Training average positive_sample_loss at step 215600: 0.631195\n",
      "2022-11-08 12:02:06,052 INFO     Training average negative_sample_loss at step 215600: 0.313167\n",
      "2022-11-08 12:02:06,052 INFO     Training average loss at step 215600: 0.472181\n",
      "2022-11-08 12:02:14,919 INFO     Training average positive_sample_loss at step 215700: 0.635002\n",
      "2022-11-08 12:02:14,919 INFO     Training average negative_sample_loss at step 215700: 0.314950\n",
      "2022-11-08 12:02:14,919 INFO     Training average loss at step 215700: 0.474976\n",
      "2022-11-08 12:02:24,454 INFO     Training average positive_sample_loss at step 215800: 0.647661\n",
      "2022-11-08 12:02:24,454 INFO     Training average negative_sample_loss at step 215800: 0.306646\n",
      "2022-11-08 12:02:24,454 INFO     Training average loss at step 215800: 0.477154\n",
      "2022-11-08 12:02:33,980 INFO     Training average positive_sample_loss at step 215900: 0.598094\n",
      "2022-11-08 12:02:33,981 INFO     Training average negative_sample_loss at step 215900: 0.314013\n",
      "2022-11-08 12:02:33,981 INFO     Training average loss at step 215900: 0.456053\n",
      "2022-11-08 12:02:43,505 INFO     Training average positive_sample_loss at step 216000: 0.633319\n",
      "2022-11-08 12:02:43,506 INFO     Training average negative_sample_loss at step 216000: 0.308977\n",
      "2022-11-08 12:02:43,506 INFO     Training average loss at step 216000: 0.471148\n",
      "2022-11-08 12:02:53,035 INFO     Training average positive_sample_loss at step 216100: 0.615535\n",
      "2022-11-08 12:02:53,035 INFO     Training average negative_sample_loss at step 216100: 0.310706\n",
      "2022-11-08 12:02:53,035 INFO     Training average loss at step 216100: 0.463121\n",
      "2022-11-08 12:03:02,566 INFO     Training average positive_sample_loss at step 216200: 0.643819\n",
      "2022-11-08 12:03:02,567 INFO     Training average negative_sample_loss at step 216200: 0.304171\n",
      "2022-11-08 12:03:02,567 INFO     Training average loss at step 216200: 0.473995\n",
      "2022-11-08 12:03:12,095 INFO     Training average positive_sample_loss at step 216300: 0.620955\n",
      "2022-11-08 12:03:12,095 INFO     Training average negative_sample_loss at step 216300: 0.312427\n",
      "2022-11-08 12:03:12,095 INFO     Training average loss at step 216300: 0.466691\n",
      "2022-11-08 12:03:21,628 INFO     Training average positive_sample_loss at step 216400: 0.601436\n",
      "2022-11-08 12:03:21,629 INFO     Training average negative_sample_loss at step 216400: 0.309167\n",
      "2022-11-08 12:03:21,629 INFO     Training average loss at step 216400: 0.455302\n",
      "2022-11-08 12:03:31,155 INFO     Training average positive_sample_loss at step 216500: 0.624667\n",
      "2022-11-08 12:03:31,155 INFO     Training average negative_sample_loss at step 216500: 0.304820\n",
      "2022-11-08 12:03:31,155 INFO     Training average loss at step 216500: 0.464743\n",
      "2022-11-08 12:03:40,685 INFO     Training average positive_sample_loss at step 216600: 0.615137\n",
      "2022-11-08 12:03:40,685 INFO     Training average negative_sample_loss at step 216600: 0.306675\n",
      "2022-11-08 12:03:40,685 INFO     Training average loss at step 216600: 0.460906\n",
      "2022-11-08 12:03:50,216 INFO     Training average positive_sample_loss at step 216700: 0.632270\n",
      "2022-11-08 12:03:50,216 INFO     Training average negative_sample_loss at step 216700: 0.312553\n",
      "2022-11-08 12:03:50,216 INFO     Training average loss at step 216700: 0.472411\n",
      "2022-11-08 12:03:59,745 INFO     Training average positive_sample_loss at step 216800: 0.622322\n",
      "2022-11-08 12:03:59,745 INFO     Training average negative_sample_loss at step 216800: 0.308312\n",
      "2022-11-08 12:03:59,745 INFO     Training average loss at step 216800: 0.465317\n",
      "2022-11-08 12:04:09,278 INFO     Training average positive_sample_loss at step 216900: 0.614404\n",
      "2022-11-08 12:04:09,278 INFO     Training average negative_sample_loss at step 216900: 0.315042\n",
      "2022-11-08 12:04:09,278 INFO     Training average loss at step 216900: 0.464723\n",
      "2022-11-08 12:04:18,806 INFO     Training average positive_sample_loss at step 217000: 0.629376\n",
      "2022-11-08 12:04:18,806 INFO     Training average negative_sample_loss at step 217000: 0.311335\n",
      "2022-11-08 12:04:18,806 INFO     Training average loss at step 217000: 0.470356\n",
      "2022-11-08 12:04:28,334 INFO     Training average positive_sample_loss at step 217100: 0.621661\n",
      "2022-11-08 12:04:28,334 INFO     Training average negative_sample_loss at step 217100: 0.309039\n",
      "2022-11-08 12:04:28,334 INFO     Training average loss at step 217100: 0.465350\n",
      "2022-11-08 12:04:37,867 INFO     Training average positive_sample_loss at step 217200: 0.633708\n",
      "2022-11-08 12:04:37,867 INFO     Training average negative_sample_loss at step 217200: 0.308093\n",
      "2022-11-08 12:04:37,867 INFO     Training average loss at step 217200: 0.470901\n",
      "2022-11-08 12:04:47,397 INFO     Training average positive_sample_loss at step 217300: 0.644405\n",
      "2022-11-08 12:04:47,397 INFO     Training average negative_sample_loss at step 217300: 0.304479\n",
      "2022-11-08 12:04:47,397 INFO     Training average loss at step 217300: 0.474442\n",
      "2022-11-08 12:04:56,927 INFO     Training average positive_sample_loss at step 217400: 0.605199\n",
      "2022-11-08 12:04:56,927 INFO     Training average negative_sample_loss at step 217400: 0.308269\n",
      "2022-11-08 12:04:56,927 INFO     Training average loss at step 217400: 0.456734\n",
      "2022-11-08 12:05:06,464 INFO     Training average positive_sample_loss at step 217500: 0.600834\n",
      "2022-11-08 12:05:06,464 INFO     Training average negative_sample_loss at step 217500: 0.309008\n",
      "2022-11-08 12:05:06,464 INFO     Training average loss at step 217500: 0.454921\n",
      "2022-11-08 12:05:15,990 INFO     Training average positive_sample_loss at step 217600: 0.635629\n",
      "2022-11-08 12:05:15,990 INFO     Training average negative_sample_loss at step 217600: 0.309235\n",
      "2022-11-08 12:05:15,990 INFO     Training average loss at step 217600: 0.472432\n",
      "2022-11-08 12:05:25,520 INFO     Training average positive_sample_loss at step 217700: 0.604104\n",
      "2022-11-08 12:05:25,520 INFO     Training average negative_sample_loss at step 217700: 0.306601\n",
      "2022-11-08 12:05:25,520 INFO     Training average loss at step 217700: 0.455353\n",
      "2022-11-08 12:05:35,049 INFO     Training average positive_sample_loss at step 217800: 0.612235\n",
      "2022-11-08 12:05:35,050 INFO     Training average negative_sample_loss at step 217800: 0.311996\n",
      "2022-11-08 12:05:35,050 INFO     Training average loss at step 217800: 0.462115\n",
      "2022-11-08 12:05:44,580 INFO     Training average positive_sample_loss at step 217900: 0.610475\n",
      "2022-11-08 12:05:44,580 INFO     Training average negative_sample_loss at step 217900: 0.315434\n",
      "2022-11-08 12:05:44,580 INFO     Training average loss at step 217900: 0.462954\n",
      "2022-11-08 12:05:54,113 INFO     Training average positive_sample_loss at step 218000: 0.623130\n",
      "2022-11-08 12:05:54,113 INFO     Training average negative_sample_loss at step 218000: 0.311182\n",
      "2022-11-08 12:05:54,113 INFO     Training average loss at step 218000: 0.467156\n",
      "2022-11-08 12:06:03,642 INFO     Training average positive_sample_loss at step 218100: 0.653450\n",
      "2022-11-08 12:06:03,642 INFO     Training average negative_sample_loss at step 218100: 0.305638\n",
      "2022-11-08 12:06:03,642 INFO     Training average loss at step 218100: 0.479544\n",
      "2022-11-08 12:06:13,167 INFO     Training average positive_sample_loss at step 218200: 0.601050\n",
      "2022-11-08 12:06:13,167 INFO     Training average negative_sample_loss at step 218200: 0.311004\n",
      "2022-11-08 12:06:13,167 INFO     Training average loss at step 218200: 0.456027\n",
      "2022-11-08 12:06:22,699 INFO     Training average positive_sample_loss at step 218300: 0.630679\n",
      "2022-11-08 12:06:22,699 INFO     Training average negative_sample_loss at step 218300: 0.310076\n",
      "2022-11-08 12:06:22,699 INFO     Training average loss at step 218300: 0.470378\n",
      "2022-11-08 12:06:32,229 INFO     Training average positive_sample_loss at step 218400: 0.608771\n",
      "2022-11-08 12:06:32,229 INFO     Training average negative_sample_loss at step 218400: 0.306242\n",
      "2022-11-08 12:06:32,229 INFO     Training average loss at step 218400: 0.457506\n",
      "2022-11-08 12:06:41,758 INFO     Training average positive_sample_loss at step 218500: 0.613818\n",
      "2022-11-08 12:06:41,758 INFO     Training average negative_sample_loss at step 218500: 0.308998\n",
      "2022-11-08 12:06:41,758 INFO     Training average loss at step 218500: 0.461408\n",
      "2022-11-08 12:06:51,292 INFO     Training average positive_sample_loss at step 218600: 0.621955\n",
      "2022-11-08 12:06:51,292 INFO     Training average negative_sample_loss at step 218600: 0.313801\n",
      "2022-11-08 12:06:51,292 INFO     Training average loss at step 218600: 0.467878\n",
      "2022-11-08 12:07:00,819 INFO     Training average positive_sample_loss at step 218700: 0.623564\n",
      "2022-11-08 12:07:00,819 INFO     Training average negative_sample_loss at step 218700: 0.303051\n",
      "2022-11-08 12:07:00,819 INFO     Training average loss at step 218700: 0.463308\n",
      "2022-11-08 12:07:10,346 INFO     Training average positive_sample_loss at step 218800: 0.620586\n",
      "2022-11-08 12:07:10,346 INFO     Training average negative_sample_loss at step 218800: 0.300859\n",
      "2022-11-08 12:07:10,346 INFO     Training average loss at step 218800: 0.460723\n",
      "2022-11-08 12:07:19,879 INFO     Training average positive_sample_loss at step 218900: 0.610010\n",
      "2022-11-08 12:07:19,879 INFO     Training average negative_sample_loss at step 218900: 0.303059\n",
      "2022-11-08 12:07:19,879 INFO     Training average loss at step 218900: 0.456534\n",
      "2022-11-08 12:07:29,409 INFO     Training average positive_sample_loss at step 219000: 0.644817\n",
      "2022-11-08 12:07:29,409 INFO     Training average negative_sample_loss at step 219000: 0.312124\n",
      "2022-11-08 12:07:29,409 INFO     Training average loss at step 219000: 0.478471\n",
      "2022-11-08 12:07:38,939 INFO     Training average positive_sample_loss at step 219100: 0.643489\n",
      "2022-11-08 12:07:38,939 INFO     Training average negative_sample_loss at step 219100: 0.310081\n",
      "2022-11-08 12:07:38,939 INFO     Training average loss at step 219100: 0.476785\n",
      "2022-11-08 12:07:48,468 INFO     Training average positive_sample_loss at step 219200: 0.602829\n",
      "2022-11-08 12:07:48,468 INFO     Training average negative_sample_loss at step 219200: 0.304526\n",
      "2022-11-08 12:07:48,468 INFO     Training average loss at step 219200: 0.453677\n",
      "2022-11-08 12:07:57,994 INFO     Training average positive_sample_loss at step 219300: 0.613669\n",
      "2022-11-08 12:07:57,994 INFO     Training average negative_sample_loss at step 219300: 0.312077\n",
      "2022-11-08 12:07:57,994 INFO     Training average loss at step 219300: 0.462873\n",
      "2022-11-08 12:08:07,527 INFO     Training average positive_sample_loss at step 219400: 0.624871\n",
      "2022-11-08 12:08:07,527 INFO     Training average negative_sample_loss at step 219400: 0.305295\n",
      "2022-11-08 12:08:07,527 INFO     Training average loss at step 219400: 0.465083\n",
      "2022-11-08 12:08:17,058 INFO     Training average positive_sample_loss at step 219500: 0.632554\n",
      "2022-11-08 12:08:17,058 INFO     Training average negative_sample_loss at step 219500: 0.306527\n",
      "2022-11-08 12:08:17,058 INFO     Training average loss at step 219500: 0.469540\n",
      "2022-11-08 12:08:26,676 INFO     Training average positive_sample_loss at step 219600: 0.634237\n",
      "2022-11-08 12:08:26,676 INFO     Training average negative_sample_loss at step 219600: 0.306426\n",
      "2022-11-08 12:08:26,676 INFO     Training average loss at step 219600: 0.470332\n",
      "2022-11-08 12:08:37,788 INFO     Training average positive_sample_loss at step 219700: 0.589922\n",
      "2022-11-08 12:08:37,788 INFO     Training average negative_sample_loss at step 219700: 0.308614\n",
      "2022-11-08 12:08:37,788 INFO     Training average loss at step 219700: 0.449268\n",
      "2022-11-08 12:08:48,166 INFO     Training average positive_sample_loss at step 219800: 0.622694\n",
      "2022-11-08 12:08:48,166 INFO     Training average negative_sample_loss at step 219800: 0.303339\n",
      "2022-11-08 12:08:48,167 INFO     Training average loss at step 219800: 0.463017\n",
      "2022-11-08 12:08:58,227 INFO     Training average positive_sample_loss at step 219900: 0.614291\n",
      "2022-11-08 12:08:58,227 INFO     Training average negative_sample_loss at step 219900: 0.300925\n",
      "2022-11-08 12:08:58,227 INFO     Training average loss at step 219900: 0.457608\n",
      "2022-11-08 12:09:10,539 INFO     Training average positive_sample_loss at step 220000: 0.629102\n",
      "2022-11-08 12:09:10,539 INFO     Training average negative_sample_loss at step 220000: 0.299575\n",
      "2022-11-08 12:09:10,539 INFO     Training average loss at step 220000: 0.464339\n",
      "2022-11-08 12:09:20,069 INFO     Training average positive_sample_loss at step 220100: 0.604274\n",
      "2022-11-08 12:09:20,069 INFO     Training average negative_sample_loss at step 220100: 0.305922\n",
      "2022-11-08 12:09:20,069 INFO     Training average loss at step 220100: 0.455098\n",
      "2022-11-08 12:09:29,597 INFO     Training average positive_sample_loss at step 220200: 0.606518\n",
      "2022-11-08 12:09:29,597 INFO     Training average negative_sample_loss at step 220200: 0.307020\n",
      "2022-11-08 12:09:29,597 INFO     Training average loss at step 220200: 0.456769\n",
      "2022-11-08 12:09:39,127 INFO     Training average positive_sample_loss at step 220300: 0.632192\n",
      "2022-11-08 12:09:39,127 INFO     Training average negative_sample_loss at step 220300: 0.305931\n",
      "2022-11-08 12:09:39,127 INFO     Training average loss at step 220300: 0.469062\n",
      "2022-11-08 12:09:48,657 INFO     Training average positive_sample_loss at step 220400: 0.615056\n",
      "2022-11-08 12:09:48,658 INFO     Training average negative_sample_loss at step 220400: 0.307744\n",
      "2022-11-08 12:09:48,658 INFO     Training average loss at step 220400: 0.461400\n",
      "2022-11-08 12:09:58,182 INFO     Training average positive_sample_loss at step 220500: 0.618826\n",
      "2022-11-08 12:09:58,182 INFO     Training average negative_sample_loss at step 220500: 0.310071\n",
      "2022-11-08 12:09:58,182 INFO     Training average loss at step 220500: 0.464449\n",
      "2022-11-08 12:10:07,712 INFO     Training average positive_sample_loss at step 220600: 0.609739\n",
      "2022-11-08 12:10:07,712 INFO     Training average negative_sample_loss at step 220600: 0.305508\n",
      "2022-11-08 12:10:07,712 INFO     Training average loss at step 220600: 0.457624\n",
      "2022-11-08 12:10:16,575 INFO     Training average positive_sample_loss at step 220700: 0.621548\n",
      "2022-11-08 12:10:16,575 INFO     Training average negative_sample_loss at step 220700: 0.300334\n",
      "2022-11-08 12:10:16,575 INFO     Training average loss at step 220700: 0.460941\n",
      "2022-11-08 12:10:26,109 INFO     Training average positive_sample_loss at step 220800: 0.580570\n",
      "2022-11-08 12:10:26,109 INFO     Training average negative_sample_loss at step 220800: 0.309682\n",
      "2022-11-08 12:10:26,109 INFO     Training average loss at step 220800: 0.445126\n",
      "2022-11-08 12:10:35,640 INFO     Training average positive_sample_loss at step 220900: 0.620060\n",
      "2022-11-08 12:10:35,640 INFO     Training average negative_sample_loss at step 220900: 0.307070\n",
      "2022-11-08 12:10:35,640 INFO     Training average loss at step 220900: 0.463565\n",
      "2022-11-08 12:10:45,174 INFO     Training average positive_sample_loss at step 221000: 0.600930\n",
      "2022-11-08 12:10:45,174 INFO     Training average negative_sample_loss at step 221000: 0.309959\n",
      "2022-11-08 12:10:45,174 INFO     Training average loss at step 221000: 0.455444\n",
      "2022-11-08 12:10:54,607 INFO     Training average positive_sample_loss at step 221100: 0.631861\n",
      "2022-11-08 12:10:54,607 INFO     Training average negative_sample_loss at step 221100: 0.308521\n",
      "2022-11-08 12:10:54,607 INFO     Training average loss at step 221100: 0.470191\n",
      "2022-11-08 12:11:03,546 INFO     Training average positive_sample_loss at step 221200: 0.591516\n",
      "2022-11-08 12:11:03,546 INFO     Training average negative_sample_loss at step 221200: 0.312450\n",
      "2022-11-08 12:11:03,546 INFO     Training average loss at step 221200: 0.451983\n",
      "2022-11-08 12:11:13,083 INFO     Training average positive_sample_loss at step 221300: 0.622397\n",
      "2022-11-08 12:11:13,083 INFO     Training average negative_sample_loss at step 221300: 0.302653\n",
      "2022-11-08 12:11:13,083 INFO     Training average loss at step 221300: 0.462525\n",
      "2022-11-08 12:11:22,618 INFO     Training average positive_sample_loss at step 221400: 0.607396\n",
      "2022-11-08 12:11:22,618 INFO     Training average negative_sample_loss at step 221400: 0.307201\n",
      "2022-11-08 12:11:22,618 INFO     Training average loss at step 221400: 0.457298\n",
      "2022-11-08 12:11:32,152 INFO     Training average positive_sample_loss at step 221500: 0.606302\n",
      "2022-11-08 12:11:32,153 INFO     Training average negative_sample_loss at step 221500: 0.308396\n",
      "2022-11-08 12:11:32,153 INFO     Training average loss at step 221500: 0.457349\n",
      "2022-11-08 12:11:41,687 INFO     Training average positive_sample_loss at step 221600: 0.612425\n",
      "2022-11-08 12:11:41,687 INFO     Training average negative_sample_loss at step 221600: 0.302946\n",
      "2022-11-08 12:11:41,687 INFO     Training average loss at step 221600: 0.457685\n",
      "2022-11-08 12:11:51,219 INFO     Training average positive_sample_loss at step 221700: 0.602684\n",
      "2022-11-08 12:11:51,219 INFO     Training average negative_sample_loss at step 221700: 0.306953\n",
      "2022-11-08 12:11:51,219 INFO     Training average loss at step 221700: 0.454818\n",
      "2022-11-08 12:12:00,752 INFO     Training average positive_sample_loss at step 221800: 0.617269\n",
      "2022-11-08 12:12:00,752 INFO     Training average negative_sample_loss at step 221800: 0.301394\n",
      "2022-11-08 12:12:00,752 INFO     Training average loss at step 221800: 0.459331\n",
      "2022-11-08 12:12:10,289 INFO     Training average positive_sample_loss at step 221900: 0.601285\n",
      "2022-11-08 12:12:10,289 INFO     Training average negative_sample_loss at step 221900: 0.304008\n",
      "2022-11-08 12:12:10,289 INFO     Training average loss at step 221900: 0.452647\n",
      "2022-11-08 12:12:19,825 INFO     Training average positive_sample_loss at step 222000: 0.630601\n",
      "2022-11-08 12:12:19,825 INFO     Training average negative_sample_loss at step 222000: 0.308020\n",
      "2022-11-08 12:12:19,825 INFO     Training average loss at step 222000: 0.469310\n",
      "2022-11-08 12:12:29,363 INFO     Training average positive_sample_loss at step 222100: 0.600322\n",
      "2022-11-08 12:12:29,364 INFO     Training average negative_sample_loss at step 222100: 0.300204\n",
      "2022-11-08 12:12:29,364 INFO     Training average loss at step 222100: 0.450263\n",
      "2022-11-08 12:12:38,895 INFO     Training average positive_sample_loss at step 222200: 0.600895\n",
      "2022-11-08 12:12:38,895 INFO     Training average negative_sample_loss at step 222200: 0.302761\n",
      "2022-11-08 12:12:38,895 INFO     Training average loss at step 222200: 0.451828\n",
      "2022-11-08 12:12:48,423 INFO     Training average positive_sample_loss at step 222300: 0.606548\n",
      "2022-11-08 12:12:48,423 INFO     Training average negative_sample_loss at step 222300: 0.301565\n",
      "2022-11-08 12:12:48,423 INFO     Training average loss at step 222300: 0.454057\n",
      "2022-11-08 12:12:57,960 INFO     Training average positive_sample_loss at step 222400: 0.606706\n",
      "2022-11-08 12:12:57,960 INFO     Training average negative_sample_loss at step 222400: 0.300650\n",
      "2022-11-08 12:12:57,960 INFO     Training average loss at step 222400: 0.453678\n",
      "2022-11-08 12:13:07,497 INFO     Training average positive_sample_loss at step 222500: 0.589136\n",
      "2022-11-08 12:13:07,497 INFO     Training average negative_sample_loss at step 222500: 0.301498\n",
      "2022-11-08 12:13:07,497 INFO     Training average loss at step 222500: 0.445317\n",
      "2022-11-08 12:13:17,032 INFO     Training average positive_sample_loss at step 222600: 0.612786\n",
      "2022-11-08 12:13:17,032 INFO     Training average negative_sample_loss at step 222600: 0.304715\n",
      "2022-11-08 12:13:17,032 INFO     Training average loss at step 222600: 0.458751\n",
      "2022-11-08 12:13:26,563 INFO     Training average positive_sample_loss at step 222700: 0.619734\n",
      "2022-11-08 12:13:26,563 INFO     Training average negative_sample_loss at step 222700: 0.300928\n",
      "2022-11-08 12:13:26,563 INFO     Training average loss at step 222700: 0.460331\n",
      "2022-11-08 12:13:36,100 INFO     Training average positive_sample_loss at step 222800: 0.598770\n",
      "2022-11-08 12:13:36,100 INFO     Training average negative_sample_loss at step 222800: 0.305401\n",
      "2022-11-08 12:13:36,100 INFO     Training average loss at step 222800: 0.452085\n",
      "2022-11-08 12:13:45,640 INFO     Training average positive_sample_loss at step 222900: 0.596845\n",
      "2022-11-08 12:13:45,640 INFO     Training average negative_sample_loss at step 222900: 0.304598\n",
      "2022-11-08 12:13:45,640 INFO     Training average loss at step 222900: 0.450721\n",
      "2022-11-08 12:13:55,175 INFO     Training average positive_sample_loss at step 223000: 0.593144\n",
      "2022-11-08 12:13:55,175 INFO     Training average negative_sample_loss at step 223000: 0.305168\n",
      "2022-11-08 12:13:55,175 INFO     Training average loss at step 223000: 0.449156\n",
      "2022-11-08 12:14:04,711 INFO     Training average positive_sample_loss at step 223100: 0.633104\n",
      "2022-11-08 12:14:04,711 INFO     Training average negative_sample_loss at step 223100: 0.302071\n",
      "2022-11-08 12:14:04,711 INFO     Training average loss at step 223100: 0.467587\n",
      "2022-11-08 12:14:14,245 INFO     Training average positive_sample_loss at step 223200: 0.596425\n",
      "2022-11-08 12:14:14,245 INFO     Training average negative_sample_loss at step 223200: 0.307728\n",
      "2022-11-08 12:14:14,245 INFO     Training average loss at step 223200: 0.452076\n",
      "2022-11-08 12:14:23,776 INFO     Training average positive_sample_loss at step 223300: 0.615060\n",
      "2022-11-08 12:14:23,776 INFO     Training average negative_sample_loss at step 223300: 0.305622\n",
      "2022-11-08 12:14:23,776 INFO     Training average loss at step 223300: 0.460341\n",
      "2022-11-08 12:14:33,311 INFO     Training average positive_sample_loss at step 223400: 0.635127\n",
      "2022-11-08 12:14:33,311 INFO     Training average negative_sample_loss at step 223400: 0.298176\n",
      "2022-11-08 12:14:33,311 INFO     Training average loss at step 223400: 0.466652\n",
      "2022-11-08 12:14:42,847 INFO     Training average positive_sample_loss at step 223500: 0.607170\n",
      "2022-11-08 12:14:42,847 INFO     Training average negative_sample_loss at step 223500: 0.302072\n",
      "2022-11-08 12:14:42,847 INFO     Training average loss at step 223500: 0.454621\n",
      "2022-11-08 12:14:52,381 INFO     Training average positive_sample_loss at step 223600: 0.624434\n",
      "2022-11-08 12:14:52,381 INFO     Training average negative_sample_loss at step 223600: 0.302295\n",
      "2022-11-08 12:14:52,381 INFO     Training average loss at step 223600: 0.463365\n",
      "2022-11-08 12:15:01,920 INFO     Training average positive_sample_loss at step 223700: 0.594755\n",
      "2022-11-08 12:15:01,920 INFO     Training average negative_sample_loss at step 223700: 0.302771\n",
      "2022-11-08 12:15:01,920 INFO     Training average loss at step 223700: 0.448763\n",
      "2022-11-08 12:15:11,453 INFO     Training average positive_sample_loss at step 223800: 0.601214\n",
      "2022-11-08 12:15:11,454 INFO     Training average negative_sample_loss at step 223800: 0.303524\n",
      "2022-11-08 12:15:11,454 INFO     Training average loss at step 223800: 0.452369\n",
      "2022-11-08 12:15:20,987 INFO     Training average positive_sample_loss at step 223900: 0.612901\n",
      "2022-11-08 12:15:20,987 INFO     Training average negative_sample_loss at step 223900: 0.306126\n",
      "2022-11-08 12:15:20,987 INFO     Training average loss at step 223900: 0.459514\n",
      "2022-11-08 12:15:30,520 INFO     Training average positive_sample_loss at step 224000: 0.625403\n",
      "2022-11-08 12:15:30,520 INFO     Training average negative_sample_loss at step 224000: 0.300924\n",
      "2022-11-08 12:15:30,520 INFO     Training average loss at step 224000: 0.463164\n",
      "2022-11-08 12:15:40,059 INFO     Training average positive_sample_loss at step 224100: 0.601594\n",
      "2022-11-08 12:15:40,059 INFO     Training average negative_sample_loss at step 224100: 0.301787\n",
      "2022-11-08 12:15:40,059 INFO     Training average loss at step 224100: 0.451691\n",
      "2022-11-08 12:15:49,594 INFO     Training average positive_sample_loss at step 224200: 0.608682\n",
      "2022-11-08 12:15:49,594 INFO     Training average negative_sample_loss at step 224200: 0.302485\n",
      "2022-11-08 12:15:49,594 INFO     Training average loss at step 224200: 0.455583\n",
      "2022-11-08 12:15:59,732 INFO     Training average positive_sample_loss at step 224300: 0.606799\n",
      "2022-11-08 12:15:59,732 INFO     Training average negative_sample_loss at step 224300: 0.299533\n",
      "2022-11-08 12:15:59,732 INFO     Training average loss at step 224300: 0.453166\n",
      "2022-11-08 12:16:09,820 INFO     Training average positive_sample_loss at step 224400: 0.597594\n",
      "2022-11-08 12:16:09,820 INFO     Training average negative_sample_loss at step 224400: 0.300351\n",
      "2022-11-08 12:16:09,820 INFO     Training average loss at step 224400: 0.448972\n",
      "2022-11-08 12:16:19,935 INFO     Training average positive_sample_loss at step 224500: 0.633502\n",
      "2022-11-08 12:16:19,935 INFO     Training average negative_sample_loss at step 224500: 0.300867\n",
      "2022-11-08 12:16:19,935 INFO     Training average loss at step 224500: 0.467185\n",
      "2022-11-08 12:16:29,744 INFO     Training average positive_sample_loss at step 224600: 0.596248\n",
      "2022-11-08 12:16:29,744 INFO     Training average negative_sample_loss at step 224600: 0.303504\n",
      "2022-11-08 12:16:29,744 INFO     Training average loss at step 224600: 0.449876\n",
      "2022-11-08 12:16:39,279 INFO     Training average positive_sample_loss at step 224700: 0.606194\n",
      "2022-11-08 12:16:39,279 INFO     Training average negative_sample_loss at step 224700: 0.306903\n",
      "2022-11-08 12:16:39,279 INFO     Training average loss at step 224700: 0.456548\n",
      "2022-11-08 12:16:48,811 INFO     Training average positive_sample_loss at step 224800: 0.610222\n",
      "2022-11-08 12:16:48,811 INFO     Training average negative_sample_loss at step 224800: 0.295653\n",
      "2022-11-08 12:16:48,811 INFO     Training average loss at step 224800: 0.452937\n",
      "2022-11-08 12:16:58,343 INFO     Training average positive_sample_loss at step 224900: 0.599734\n",
      "2022-11-08 12:16:58,343 INFO     Training average negative_sample_loss at step 224900: 0.300004\n",
      "2022-11-08 12:16:58,343 INFO     Training average loss at step 224900: 0.449869\n",
      "2022-11-08 12:17:07,872 INFO     Training average positive_sample_loss at step 225000: 0.612566\n",
      "2022-11-08 12:17:07,873 INFO     Training average negative_sample_loss at step 225000: 0.302982\n",
      "2022-11-08 12:17:07,873 INFO     Training average loss at step 225000: 0.457774\n",
      "2022-11-08 12:17:17,403 INFO     Training average positive_sample_loss at step 225100: 0.606890\n",
      "2022-11-08 12:17:17,403 INFO     Training average negative_sample_loss at step 225100: 0.302412\n",
      "2022-11-08 12:17:17,403 INFO     Training average loss at step 225100: 0.454651\n",
      "2022-11-08 12:17:26,939 INFO     Training average positive_sample_loss at step 225200: 0.610640\n",
      "2022-11-08 12:17:26,939 INFO     Training average negative_sample_loss at step 225200: 0.304245\n",
      "2022-11-08 12:17:26,939 INFO     Training average loss at step 225200: 0.457442\n",
      "2022-11-08 12:17:36,475 INFO     Training average positive_sample_loss at step 225300: 0.632537\n",
      "2022-11-08 12:17:36,475 INFO     Training average negative_sample_loss at step 225300: 0.297466\n",
      "2022-11-08 12:17:36,475 INFO     Training average loss at step 225300: 0.465002\n",
      "2022-11-08 12:17:46,005 INFO     Training average positive_sample_loss at step 225400: 0.598680\n",
      "2022-11-08 12:17:46,005 INFO     Training average negative_sample_loss at step 225400: 0.301572\n",
      "2022-11-08 12:17:46,005 INFO     Training average loss at step 225400: 0.450126\n",
      "2022-11-08 12:17:55,533 INFO     Training average positive_sample_loss at step 225500: 0.602060\n",
      "2022-11-08 12:17:55,533 INFO     Training average negative_sample_loss at step 225500: 0.297546\n",
      "2022-11-08 12:17:55,533 INFO     Training average loss at step 225500: 0.449803\n",
      "2022-11-08 12:18:05,067 INFO     Training average positive_sample_loss at step 225600: 0.615560\n",
      "2022-11-08 12:18:05,067 INFO     Training average negative_sample_loss at step 225600: 0.294566\n",
      "2022-11-08 12:18:05,067 INFO     Training average loss at step 225600: 0.455063\n",
      "2022-11-08 12:18:14,599 INFO     Training average positive_sample_loss at step 225700: 0.599425\n",
      "2022-11-08 12:18:14,599 INFO     Training average negative_sample_loss at step 225700: 0.298892\n",
      "2022-11-08 12:18:14,599 INFO     Training average loss at step 225700: 0.449159\n",
      "2022-11-08 12:18:24,130 INFO     Training average positive_sample_loss at step 225800: 0.625082\n",
      "2022-11-08 12:18:24,130 INFO     Training average negative_sample_loss at step 225800: 0.299342\n",
      "2022-11-08 12:18:24,130 INFO     Training average loss at step 225800: 0.462212\n",
      "2022-11-08 12:18:33,663 INFO     Training average positive_sample_loss at step 225900: 0.600899\n",
      "2022-11-08 12:18:33,663 INFO     Training average negative_sample_loss at step 225900: 0.300452\n",
      "2022-11-08 12:18:33,663 INFO     Training average loss at step 225900: 0.450675\n",
      "2022-11-08 12:18:43,192 INFO     Training average positive_sample_loss at step 226000: 0.621489\n",
      "2022-11-08 12:18:43,192 INFO     Training average negative_sample_loss at step 226000: 0.298104\n",
      "2022-11-08 12:18:43,192 INFO     Training average loss at step 226000: 0.459797\n",
      "2022-11-08 12:18:52,722 INFO     Training average positive_sample_loss at step 226100: 0.585226\n",
      "2022-11-08 12:18:52,722 INFO     Training average negative_sample_loss at step 226100: 0.304760\n",
      "2022-11-08 12:18:52,722 INFO     Training average loss at step 226100: 0.444993\n",
      "2022-11-08 12:19:01,565 INFO     Training average positive_sample_loss at step 226200: 0.619588\n",
      "2022-11-08 12:19:01,565 INFO     Training average negative_sample_loss at step 226200: 0.302567\n",
      "2022-11-08 12:19:01,565 INFO     Training average loss at step 226200: 0.461078\n",
      "2022-11-08 12:19:11,090 INFO     Training average positive_sample_loss at step 226300: 0.610451\n",
      "2022-11-08 12:19:11,091 INFO     Training average negative_sample_loss at step 226300: 0.304690\n",
      "2022-11-08 12:19:11,091 INFO     Training average loss at step 226300: 0.457571\n",
      "2022-11-08 12:19:20,618 INFO     Training average positive_sample_loss at step 226400: 0.603214\n",
      "2022-11-08 12:19:20,618 INFO     Training average negative_sample_loss at step 226400: 0.300785\n",
      "2022-11-08 12:19:20,618 INFO     Training average loss at step 226400: 0.451999\n",
      "2022-11-08 12:19:30,152 INFO     Training average positive_sample_loss at step 226500: 0.604365\n",
      "2022-11-08 12:19:30,152 INFO     Training average negative_sample_loss at step 226500: 0.298816\n",
      "2022-11-08 12:19:30,152 INFO     Training average loss at step 226500: 0.451591\n",
      "2022-11-08 12:19:39,261 INFO     Training average positive_sample_loss at step 226600: 0.605911\n",
      "2022-11-08 12:19:39,261 INFO     Training average negative_sample_loss at step 226600: 0.302598\n",
      "2022-11-08 12:19:39,261 INFO     Training average loss at step 226600: 0.454254\n",
      "2022-11-08 12:19:48,512 INFO     Training average positive_sample_loss at step 226700: 0.595485\n",
      "2022-11-08 12:19:48,512 INFO     Training average negative_sample_loss at step 226700: 0.299667\n",
      "2022-11-08 12:19:48,512 INFO     Training average loss at step 226700: 0.447576\n",
      "2022-11-08 12:19:58,040 INFO     Training average positive_sample_loss at step 226800: 0.624278\n",
      "2022-11-08 12:19:58,040 INFO     Training average negative_sample_loss at step 226800: 0.296517\n",
      "2022-11-08 12:19:58,040 INFO     Training average loss at step 226800: 0.460398\n",
      "2022-11-08 12:20:07,565 INFO     Training average positive_sample_loss at step 226900: 0.592784\n",
      "2022-11-08 12:20:07,565 INFO     Training average negative_sample_loss at step 226900: 0.303296\n",
      "2022-11-08 12:20:07,565 INFO     Training average loss at step 226900: 0.448040\n",
      "2022-11-08 12:20:17,088 INFO     Training average positive_sample_loss at step 227000: 0.617014\n",
      "2022-11-08 12:20:17,088 INFO     Training average negative_sample_loss at step 227000: 0.301583\n",
      "2022-11-08 12:20:17,088 INFO     Training average loss at step 227000: 0.459299\n",
      "2022-11-08 12:20:26,617 INFO     Training average positive_sample_loss at step 227100: 0.628863\n",
      "2022-11-08 12:20:26,617 INFO     Training average negative_sample_loss at step 227100: 0.293928\n",
      "2022-11-08 12:20:26,617 INFO     Training average loss at step 227100: 0.461395\n",
      "2022-11-08 12:20:36,144 INFO     Training average positive_sample_loss at step 227200: 0.594650\n",
      "2022-11-08 12:20:36,144 INFO     Training average negative_sample_loss at step 227200: 0.304322\n",
      "2022-11-08 12:20:36,144 INFO     Training average loss at step 227200: 0.449486\n",
      "2022-11-08 12:20:45,671 INFO     Training average positive_sample_loss at step 227300: 0.645556\n",
      "2022-11-08 12:20:45,671 INFO     Training average negative_sample_loss at step 227300: 0.297362\n",
      "2022-11-08 12:20:45,671 INFO     Training average loss at step 227300: 0.471459\n",
      "2022-11-08 12:20:55,197 INFO     Training average positive_sample_loss at step 227400: 0.616017\n",
      "2022-11-08 12:20:55,198 INFO     Training average negative_sample_loss at step 227400: 0.304857\n",
      "2022-11-08 12:20:55,198 INFO     Training average loss at step 227400: 0.460437\n",
      "2022-11-08 12:21:04,720 INFO     Training average positive_sample_loss at step 227500: 0.605837\n",
      "2022-11-08 12:21:04,720 INFO     Training average negative_sample_loss at step 227500: 0.296538\n",
      "2022-11-08 12:21:04,720 INFO     Training average loss at step 227500: 0.451188\n",
      "2022-11-08 12:21:14,250 INFO     Training average positive_sample_loss at step 227600: 0.611601\n",
      "2022-11-08 12:21:14,250 INFO     Training average negative_sample_loss at step 227600: 0.304987\n",
      "2022-11-08 12:21:14,250 INFO     Training average loss at step 227600: 0.458294\n",
      "2022-11-08 12:21:23,780 INFO     Training average positive_sample_loss at step 227700: 0.596092\n",
      "2022-11-08 12:21:23,780 INFO     Training average negative_sample_loss at step 227700: 0.299703\n",
      "2022-11-08 12:21:23,780 INFO     Training average loss at step 227700: 0.447898\n",
      "2022-11-08 12:21:33,305 INFO     Training average positive_sample_loss at step 227800: 0.619293\n",
      "2022-11-08 12:21:33,305 INFO     Training average negative_sample_loss at step 227800: 0.295173\n",
      "2022-11-08 12:21:33,305 INFO     Training average loss at step 227800: 0.457233\n",
      "2022-11-08 12:21:42,832 INFO     Training average positive_sample_loss at step 227900: 0.593510\n",
      "2022-11-08 12:21:42,832 INFO     Training average negative_sample_loss at step 227900: 0.292126\n",
      "2022-11-08 12:21:42,832 INFO     Training average loss at step 227900: 0.442818\n",
      "2022-11-08 12:21:52,358 INFO     Training average positive_sample_loss at step 228000: 0.573884\n",
      "2022-11-08 12:21:52,358 INFO     Training average negative_sample_loss at step 228000: 0.303695\n",
      "2022-11-08 12:21:52,358 INFO     Training average loss at step 228000: 0.438789\n",
      "2022-11-08 12:22:01,883 INFO     Training average positive_sample_loss at step 228100: 0.577854\n",
      "2022-11-08 12:22:01,883 INFO     Training average negative_sample_loss at step 228100: 0.296776\n",
      "2022-11-08 12:22:01,883 INFO     Training average loss at step 228100: 0.437315\n",
      "2022-11-08 12:22:11,409 INFO     Training average positive_sample_loss at step 228200: 0.601452\n",
      "2022-11-08 12:22:11,409 INFO     Training average negative_sample_loss at step 228200: 0.298610\n",
      "2022-11-08 12:22:11,409 INFO     Training average loss at step 228200: 0.450031\n",
      "2022-11-08 12:22:20,938 INFO     Training average positive_sample_loss at step 228300: 0.593335\n",
      "2022-11-08 12:22:20,938 INFO     Training average negative_sample_loss at step 228300: 0.300731\n",
      "2022-11-08 12:22:20,938 INFO     Training average loss at step 228300: 0.447033\n",
      "2022-11-08 12:22:30,470 INFO     Training average positive_sample_loss at step 228400: 0.631351\n",
      "2022-11-08 12:22:30,470 INFO     Training average negative_sample_loss at step 228400: 0.299493\n",
      "2022-11-08 12:22:30,471 INFO     Training average loss at step 228400: 0.465422\n",
      "2022-11-08 12:22:39,999 INFO     Training average positive_sample_loss at step 228500: 0.593141\n",
      "2022-11-08 12:22:39,999 INFO     Training average negative_sample_loss at step 228500: 0.303665\n",
      "2022-11-08 12:22:39,999 INFO     Training average loss at step 228500: 0.448403\n",
      "2022-11-08 12:22:49,522 INFO     Training average positive_sample_loss at step 228600: 0.630495\n",
      "2022-11-08 12:22:49,522 INFO     Training average negative_sample_loss at step 228600: 0.296134\n",
      "2022-11-08 12:22:49,522 INFO     Training average loss at step 228600: 0.463315\n",
      "2022-11-08 12:22:59,046 INFO     Training average positive_sample_loss at step 228700: 0.607200\n",
      "2022-11-08 12:22:59,046 INFO     Training average negative_sample_loss at step 228700: 0.296500\n",
      "2022-11-08 12:22:59,046 INFO     Training average loss at step 228700: 0.451850\n",
      "2022-11-08 12:23:09,210 INFO     Training average positive_sample_loss at step 228800: 0.604107\n",
      "2022-11-08 12:23:09,210 INFO     Training average negative_sample_loss at step 228800: 0.296599\n",
      "2022-11-08 12:23:09,210 INFO     Training average loss at step 228800: 0.450353\n",
      "2022-11-08 12:23:18,738 INFO     Training average positive_sample_loss at step 228900: 0.602319\n",
      "2022-11-08 12:23:18,738 INFO     Training average negative_sample_loss at step 228900: 0.300478\n",
      "2022-11-08 12:23:18,738 INFO     Training average loss at step 228900: 0.451399\n",
      "2022-11-08 12:23:28,832 INFO     Training average positive_sample_loss at step 229000: 0.597581\n",
      "2022-11-08 12:23:28,832 INFO     Training average negative_sample_loss at step 229000: 0.294853\n",
      "2022-11-08 12:23:28,832 INFO     Training average loss at step 229000: 0.446217\n",
      "2022-11-08 12:23:38,649 INFO     Training average positive_sample_loss at step 229100: 0.618177\n",
      "2022-11-08 12:23:38,649 INFO     Training average negative_sample_loss at step 229100: 0.301669\n",
      "2022-11-08 12:23:38,649 INFO     Training average loss at step 229100: 0.459923\n",
      "2022-11-08 12:23:48,536 INFO     Training average positive_sample_loss at step 229200: 0.597034\n",
      "2022-11-08 12:23:48,536 INFO     Training average negative_sample_loss at step 229200: 0.297858\n",
      "2022-11-08 12:23:48,536 INFO     Training average loss at step 229200: 0.447446\n",
      "2022-11-08 12:23:58,406 INFO     Training average positive_sample_loss at step 229300: 0.592214\n",
      "2022-11-08 12:23:58,406 INFO     Training average negative_sample_loss at step 229300: 0.294744\n",
      "2022-11-08 12:23:58,406 INFO     Training average loss at step 229300: 0.443479\n",
      "2022-11-08 12:24:07,932 INFO     Training average positive_sample_loss at step 229400: 0.609156\n",
      "2022-11-08 12:24:07,932 INFO     Training average negative_sample_loss at step 229400: 0.293439\n",
      "2022-11-08 12:24:07,932 INFO     Training average loss at step 229400: 0.451297\n",
      "2022-11-08 12:24:17,457 INFO     Training average positive_sample_loss at step 229500: 0.607550\n",
      "2022-11-08 12:24:17,457 INFO     Training average negative_sample_loss at step 229500: 0.299515\n",
      "2022-11-08 12:24:17,457 INFO     Training average loss at step 229500: 0.453533\n",
      "2022-11-08 12:24:26,984 INFO     Training average positive_sample_loss at step 229600: 0.602831\n",
      "2022-11-08 12:24:26,984 INFO     Training average negative_sample_loss at step 229600: 0.297759\n",
      "2022-11-08 12:24:26,984 INFO     Training average loss at step 229600: 0.450295\n",
      "2022-11-08 12:24:36,511 INFO     Training average positive_sample_loss at step 229700: 0.616679\n",
      "2022-11-08 12:24:36,511 INFO     Training average negative_sample_loss at step 229700: 0.294556\n",
      "2022-11-08 12:24:36,511 INFO     Training average loss at step 229700: 0.455618\n",
      "2022-11-08 12:24:46,038 INFO     Training average positive_sample_loss at step 229800: 0.611459\n",
      "2022-11-08 12:24:46,038 INFO     Training average negative_sample_loss at step 229800: 0.298347\n",
      "2022-11-08 12:24:46,038 INFO     Training average loss at step 229800: 0.454903\n",
      "2022-11-08 12:24:55,564 INFO     Training average positive_sample_loss at step 229900: 0.622491\n",
      "2022-11-08 12:24:55,565 INFO     Training average negative_sample_loss at step 229900: 0.297005\n",
      "2022-11-08 12:24:55,565 INFO     Training average loss at step 229900: 0.459748\n",
      "2022-11-08 12:25:07,636 INFO     Training average positive_sample_loss at step 230000: 0.630355\n",
      "2022-11-08 12:25:07,636 INFO     Training average negative_sample_loss at step 230000: 0.291134\n",
      "2022-11-08 12:25:07,637 INFO     Training average loss at step 230000: 0.460745\n",
      "2022-11-08 12:25:17,164 INFO     Training average positive_sample_loss at step 230100: 0.603495\n",
      "2022-11-08 12:25:17,164 INFO     Training average negative_sample_loss at step 230100: 0.292752\n",
      "2022-11-08 12:25:17,164 INFO     Training average loss at step 230100: 0.448124\n",
      "2022-11-08 12:25:26,688 INFO     Training average positive_sample_loss at step 230200: 0.630938\n",
      "2022-11-08 12:25:26,688 INFO     Training average negative_sample_loss at step 230200: 0.298900\n",
      "2022-11-08 12:25:26,688 INFO     Training average loss at step 230200: 0.464919\n",
      "2022-11-08 12:25:36,212 INFO     Training average positive_sample_loss at step 230300: 0.599135\n",
      "2022-11-08 12:25:36,212 INFO     Training average negative_sample_loss at step 230300: 0.294146\n",
      "2022-11-08 12:25:36,213 INFO     Training average loss at step 230300: 0.446640\n",
      "2022-11-08 12:25:45,741 INFO     Training average positive_sample_loss at step 230400: 0.591692\n",
      "2022-11-08 12:25:45,742 INFO     Training average negative_sample_loss at step 230400: 0.291421\n",
      "2022-11-08 12:25:45,742 INFO     Training average loss at step 230400: 0.441556\n",
      "2022-11-08 12:25:55,267 INFO     Training average positive_sample_loss at step 230500: 0.589527\n",
      "2022-11-08 12:25:55,267 INFO     Training average negative_sample_loss at step 230500: 0.293527\n",
      "2022-11-08 12:25:55,267 INFO     Training average loss at step 230500: 0.441527\n",
      "2022-11-08 12:26:04,796 INFO     Training average positive_sample_loss at step 230600: 0.587681\n",
      "2022-11-08 12:26:04,796 INFO     Training average negative_sample_loss at step 230600: 0.296319\n",
      "2022-11-08 12:26:04,796 INFO     Training average loss at step 230600: 0.442000\n",
      "2022-11-08 12:26:14,320 INFO     Training average positive_sample_loss at step 230700: 0.567315\n",
      "2022-11-08 12:26:14,320 INFO     Training average negative_sample_loss at step 230700: 0.291143\n",
      "2022-11-08 12:26:14,320 INFO     Training average loss at step 230700: 0.429229\n",
      "2022-11-08 12:26:23,842 INFO     Training average positive_sample_loss at step 230800: 0.596284\n",
      "2022-11-08 12:26:23,843 INFO     Training average negative_sample_loss at step 230800: 0.297044\n",
      "2022-11-08 12:26:23,843 INFO     Training average loss at step 230800: 0.446664\n",
      "2022-11-08 12:26:33,369 INFO     Training average positive_sample_loss at step 230900: 0.617295\n",
      "2022-11-08 12:26:33,370 INFO     Training average negative_sample_loss at step 230900: 0.291856\n",
      "2022-11-08 12:26:33,370 INFO     Training average loss at step 230900: 0.454575\n",
      "2022-11-08 12:26:42,898 INFO     Training average positive_sample_loss at step 231000: 0.577474\n",
      "2022-11-08 12:26:42,898 INFO     Training average negative_sample_loss at step 231000: 0.293846\n",
      "2022-11-08 12:26:42,898 INFO     Training average loss at step 231000: 0.435660\n",
      "2022-11-08 12:26:52,424 INFO     Training average positive_sample_loss at step 231100: 0.573807\n",
      "2022-11-08 12:26:52,424 INFO     Training average negative_sample_loss at step 231100: 0.292215\n",
      "2022-11-08 12:26:52,424 INFO     Training average loss at step 231100: 0.433011\n",
      "2022-11-08 12:27:01,952 INFO     Training average positive_sample_loss at step 231200: 0.602108\n",
      "2022-11-08 12:27:01,953 INFO     Training average negative_sample_loss at step 231200: 0.294884\n",
      "2022-11-08 12:27:01,953 INFO     Training average loss at step 231200: 0.448496\n",
      "2022-11-08 12:27:11,475 INFO     Training average positive_sample_loss at step 231300: 0.608541\n",
      "2022-11-08 12:27:11,475 INFO     Training average negative_sample_loss at step 231300: 0.296725\n",
      "2022-11-08 12:27:11,475 INFO     Training average loss at step 231300: 0.452633\n",
      "2022-11-08 12:27:21,000 INFO     Training average positive_sample_loss at step 231400: 0.593282\n",
      "2022-11-08 12:27:21,000 INFO     Training average negative_sample_loss at step 231400: 0.294269\n",
      "2022-11-08 12:27:21,000 INFO     Training average loss at step 231400: 0.443776\n",
      "2022-11-08 12:27:30,528 INFO     Training average positive_sample_loss at step 231500: 0.612568\n",
      "2022-11-08 12:27:30,528 INFO     Training average negative_sample_loss at step 231500: 0.296403\n",
      "2022-11-08 12:27:30,528 INFO     Training average loss at step 231500: 0.454486\n",
      "2022-11-08 12:27:39,425 INFO     Training average positive_sample_loss at step 231600: 0.603366\n",
      "2022-11-08 12:27:39,425 INFO     Training average negative_sample_loss at step 231600: 0.292105\n",
      "2022-11-08 12:27:39,425 INFO     Training average loss at step 231600: 0.447736\n",
      "2022-11-08 12:27:48,958 INFO     Training average positive_sample_loss at step 231700: 0.591792\n",
      "2022-11-08 12:27:48,958 INFO     Training average negative_sample_loss at step 231700: 0.293387\n",
      "2022-11-08 12:27:48,958 INFO     Training average loss at step 231700: 0.442590\n",
      "2022-11-08 12:27:58,484 INFO     Training average positive_sample_loss at step 231800: 0.593142\n",
      "2022-11-08 12:27:58,484 INFO     Training average negative_sample_loss at step 231800: 0.297189\n",
      "2022-11-08 12:27:58,484 INFO     Training average loss at step 231800: 0.445166\n",
      "2022-11-08 12:28:08,016 INFO     Training average positive_sample_loss at step 231900: 0.603422\n",
      "2022-11-08 12:28:08,016 INFO     Training average negative_sample_loss at step 231900: 0.291066\n",
      "2022-11-08 12:28:08,016 INFO     Training average loss at step 231900: 0.447244\n",
      "2022-11-08 12:28:17,547 INFO     Training average positive_sample_loss at step 232000: 0.600934\n",
      "2022-11-08 12:28:17,547 INFO     Training average negative_sample_loss at step 232000: 0.297012\n",
      "2022-11-08 12:28:17,547 INFO     Training average loss at step 232000: 0.448973\n",
      "2022-11-08 12:28:26,423 INFO     Training average positive_sample_loss at step 232100: 0.593261\n",
      "2022-11-08 12:28:26,424 INFO     Training average negative_sample_loss at step 232100: 0.291488\n",
      "2022-11-08 12:28:26,424 INFO     Training average loss at step 232100: 0.442375\n",
      "2022-11-08 12:28:35,951 INFO     Training average positive_sample_loss at step 232200: 0.582940\n",
      "2022-11-08 12:28:35,951 INFO     Training average negative_sample_loss at step 232200: 0.300889\n",
      "2022-11-08 12:28:35,951 INFO     Training average loss at step 232200: 0.441915\n",
      "2022-11-08 12:28:45,483 INFO     Training average positive_sample_loss at step 232300: 0.611333\n",
      "2022-11-08 12:28:45,483 INFO     Training average negative_sample_loss at step 232300: 0.298160\n",
      "2022-11-08 12:28:45,483 INFO     Training average loss at step 232300: 0.454746\n",
      "2022-11-08 12:28:55,012 INFO     Training average positive_sample_loss at step 232400: 0.592467\n",
      "2022-11-08 12:28:55,012 INFO     Training average negative_sample_loss at step 232400: 0.298734\n",
      "2022-11-08 12:28:55,012 INFO     Training average loss at step 232400: 0.445600\n",
      "2022-11-08 12:29:04,540 INFO     Training average positive_sample_loss at step 232500: 0.589754\n",
      "2022-11-08 12:29:04,540 INFO     Training average negative_sample_loss at step 232500: 0.295932\n",
      "2022-11-08 12:29:04,540 INFO     Training average loss at step 232500: 0.442843\n",
      "2022-11-08 12:29:14,069 INFO     Training average positive_sample_loss at step 232600: 0.595224\n",
      "2022-11-08 12:29:14,069 INFO     Training average negative_sample_loss at step 232600: 0.294285\n",
      "2022-11-08 12:29:14,069 INFO     Training average loss at step 232600: 0.444754\n",
      "2022-11-08 12:29:23,596 INFO     Training average positive_sample_loss at step 232700: 0.611492\n",
      "2022-11-08 12:29:23,596 INFO     Training average negative_sample_loss at step 232700: 0.292109\n",
      "2022-11-08 12:29:23,596 INFO     Training average loss at step 232700: 0.451801\n",
      "2022-11-08 12:29:33,130 INFO     Training average positive_sample_loss at step 232800: 0.597358\n",
      "2022-11-08 12:29:33,130 INFO     Training average negative_sample_loss at step 232800: 0.294755\n",
      "2022-11-08 12:29:33,130 INFO     Training average loss at step 232800: 0.446057\n",
      "2022-11-08 12:29:42,662 INFO     Training average positive_sample_loss at step 232900: 0.585348\n",
      "2022-11-08 12:29:42,662 INFO     Training average negative_sample_loss at step 232900: 0.293016\n",
      "2022-11-08 12:29:42,662 INFO     Training average loss at step 232900: 0.439182\n",
      "2022-11-08 12:29:52,188 INFO     Training average positive_sample_loss at step 233000: 0.577395\n",
      "2022-11-08 12:29:52,189 INFO     Training average negative_sample_loss at step 233000: 0.301795\n",
      "2022-11-08 12:29:52,189 INFO     Training average loss at step 233000: 0.439595\n",
      "2022-11-08 12:30:01,717 INFO     Training average positive_sample_loss at step 233100: 0.590618\n",
      "2022-11-08 12:30:01,718 INFO     Training average negative_sample_loss at step 233100: 0.292218\n",
      "2022-11-08 12:30:01,718 INFO     Training average loss at step 233100: 0.441418\n",
      "2022-11-08 12:30:11,247 INFO     Training average positive_sample_loss at step 233200: 0.582024\n",
      "2022-11-08 12:30:11,247 INFO     Training average negative_sample_loss at step 233200: 0.303039\n",
      "2022-11-08 12:30:11,247 INFO     Training average loss at step 233200: 0.442532\n",
      "2022-11-08 12:30:20,773 INFO     Training average positive_sample_loss at step 233300: 0.593874\n",
      "2022-11-08 12:30:20,773 INFO     Training average negative_sample_loss at step 233300: 0.289178\n",
      "2022-11-08 12:30:20,773 INFO     Training average loss at step 233300: 0.441526\n",
      "2022-11-08 12:30:30,301 INFO     Training average positive_sample_loss at step 233400: 0.597532\n",
      "2022-11-08 12:30:30,301 INFO     Training average negative_sample_loss at step 233400: 0.292137\n",
      "2022-11-08 12:30:30,301 INFO     Training average loss at step 233400: 0.444834\n",
      "2022-11-08 12:30:40,924 INFO     Training average positive_sample_loss at step 233500: 0.601439\n",
      "2022-11-08 12:30:40,924 INFO     Training average negative_sample_loss at step 233500: 0.293450\n",
      "2022-11-08 12:30:40,924 INFO     Training average loss at step 233500: 0.447444\n",
      "2022-11-08 12:30:50,920 INFO     Training average positive_sample_loss at step 233600: 0.603070\n",
      "2022-11-08 12:30:50,920 INFO     Training average negative_sample_loss at step 233600: 0.290428\n",
      "2022-11-08 12:30:50,920 INFO     Training average loss at step 233600: 0.446749\n",
      "2022-11-08 12:31:00,454 INFO     Training average positive_sample_loss at step 233700: 0.612545\n",
      "2022-11-08 12:31:00,455 INFO     Training average negative_sample_loss at step 233700: 0.291496\n",
      "2022-11-08 12:31:00,455 INFO     Training average loss at step 233700: 0.452020\n",
      "2022-11-08 12:31:10,354 INFO     Training average positive_sample_loss at step 233800: 0.589070\n",
      "2022-11-08 12:31:10,354 INFO     Training average negative_sample_loss at step 233800: 0.295330\n",
      "2022-11-08 12:31:10,354 INFO     Training average loss at step 233800: 0.442200\n",
      "2022-11-08 12:31:19,879 INFO     Training average positive_sample_loss at step 233900: 0.613441\n",
      "2022-11-08 12:31:19,879 INFO     Training average negative_sample_loss at step 233900: 0.298266\n",
      "2022-11-08 12:31:19,879 INFO     Training average loss at step 233900: 0.455854\n",
      "2022-11-08 12:31:29,719 INFO     Training average positive_sample_loss at step 234000: 0.589219\n",
      "2022-11-08 12:31:29,719 INFO     Training average negative_sample_loss at step 234000: 0.291026\n",
      "2022-11-08 12:31:29,719 INFO     Training average loss at step 234000: 0.440123\n",
      "2022-11-08 12:31:39,248 INFO     Training average positive_sample_loss at step 234100: 0.587217\n",
      "2022-11-08 12:31:39,248 INFO     Training average negative_sample_loss at step 234100: 0.298198\n",
      "2022-11-08 12:31:39,248 INFO     Training average loss at step 234100: 0.442708\n",
      "2022-11-08 12:31:48,777 INFO     Training average positive_sample_loss at step 234200: 0.606935\n",
      "2022-11-08 12:31:48,777 INFO     Training average negative_sample_loss at step 234200: 0.289151\n",
      "2022-11-08 12:31:48,777 INFO     Training average loss at step 234200: 0.448043\n",
      "2022-11-08 12:31:58,307 INFO     Training average positive_sample_loss at step 234300: 0.592402\n",
      "2022-11-08 12:31:58,307 INFO     Training average negative_sample_loss at step 234300: 0.293925\n",
      "2022-11-08 12:31:58,307 INFO     Training average loss at step 234300: 0.443164\n",
      "2022-11-08 12:32:07,835 INFO     Training average positive_sample_loss at step 234400: 0.593673\n",
      "2022-11-08 12:32:07,835 INFO     Training average negative_sample_loss at step 234400: 0.292711\n",
      "2022-11-08 12:32:07,835 INFO     Training average loss at step 234400: 0.443192\n",
      "2022-11-08 12:32:17,365 INFO     Training average positive_sample_loss at step 234500: 0.571677\n",
      "2022-11-08 12:32:17,365 INFO     Training average negative_sample_loss at step 234500: 0.291212\n",
      "2022-11-08 12:32:17,365 INFO     Training average loss at step 234500: 0.431444\n",
      "2022-11-08 12:32:26,892 INFO     Training average positive_sample_loss at step 234600: 0.594567\n",
      "2022-11-08 12:32:26,892 INFO     Training average negative_sample_loss at step 234600: 0.291805\n",
      "2022-11-08 12:32:26,892 INFO     Training average loss at step 234600: 0.443186\n",
      "2022-11-08 12:32:36,423 INFO     Training average positive_sample_loss at step 234700: 0.573636\n",
      "2022-11-08 12:32:36,423 INFO     Training average negative_sample_loss at step 234700: 0.292945\n",
      "2022-11-08 12:32:36,423 INFO     Training average loss at step 234700: 0.433291\n",
      "2022-11-08 12:32:45,952 INFO     Training average positive_sample_loss at step 234800: 0.579715\n",
      "2022-11-08 12:32:45,952 INFO     Training average negative_sample_loss at step 234800: 0.292439\n",
      "2022-11-08 12:32:45,952 INFO     Training average loss at step 234800: 0.436077\n",
      "2022-11-08 12:32:55,477 INFO     Training average positive_sample_loss at step 234900: 0.596501\n",
      "2022-11-08 12:32:55,478 INFO     Training average negative_sample_loss at step 234900: 0.292450\n",
      "2022-11-08 12:32:55,478 INFO     Training average loss at step 234900: 0.444475\n",
      "2022-11-08 12:33:05,014 INFO     Training average positive_sample_loss at step 235000: 0.608991\n",
      "2022-11-08 12:33:05,014 INFO     Training average negative_sample_loss at step 235000: 0.296505\n",
      "2022-11-08 12:33:05,014 INFO     Training average loss at step 235000: 0.452748\n",
      "2022-11-08 12:33:14,541 INFO     Training average positive_sample_loss at step 235100: 0.588974\n",
      "2022-11-08 12:33:14,541 INFO     Training average negative_sample_loss at step 235100: 0.290932\n",
      "2022-11-08 12:33:14,541 INFO     Training average loss at step 235100: 0.439953\n",
      "2022-11-08 12:33:24,071 INFO     Training average positive_sample_loss at step 235200: 0.579871\n",
      "2022-11-08 12:33:24,071 INFO     Training average negative_sample_loss at step 235200: 0.290840\n",
      "2022-11-08 12:33:24,071 INFO     Training average loss at step 235200: 0.435355\n",
      "2022-11-08 12:33:33,604 INFO     Training average positive_sample_loss at step 235300: 0.559737\n",
      "2022-11-08 12:33:33,604 INFO     Training average negative_sample_loss at step 235300: 0.292768\n",
      "2022-11-08 12:33:33,605 INFO     Training average loss at step 235300: 0.426252\n",
      "2022-11-08 12:33:43,133 INFO     Training average positive_sample_loss at step 235400: 0.577581\n",
      "2022-11-08 12:33:43,133 INFO     Training average negative_sample_loss at step 235400: 0.291286\n",
      "2022-11-08 12:33:43,134 INFO     Training average loss at step 235400: 0.434434\n",
      "2022-11-08 12:33:52,659 INFO     Training average positive_sample_loss at step 235500: 0.575531\n",
      "2022-11-08 12:33:52,660 INFO     Training average negative_sample_loss at step 235500: 0.286435\n",
      "2022-11-08 12:33:52,660 INFO     Training average loss at step 235500: 0.430983\n",
      "2022-11-08 12:34:02,190 INFO     Training average positive_sample_loss at step 235600: 0.591592\n",
      "2022-11-08 12:34:02,190 INFO     Training average negative_sample_loss at step 235600: 0.292018\n",
      "2022-11-08 12:34:02,190 INFO     Training average loss at step 235600: 0.441805\n",
      "2022-11-08 12:34:11,719 INFO     Training average positive_sample_loss at step 235700: 0.584285\n",
      "2022-11-08 12:34:11,720 INFO     Training average negative_sample_loss at step 235700: 0.296195\n",
      "2022-11-08 12:34:11,720 INFO     Training average loss at step 235700: 0.440240\n",
      "2022-11-08 12:34:21,249 INFO     Training average positive_sample_loss at step 235800: 0.628205\n",
      "2022-11-08 12:34:21,249 INFO     Training average negative_sample_loss at step 235800: 0.293399\n",
      "2022-11-08 12:34:21,249 INFO     Training average loss at step 235800: 0.460802\n",
      "2022-11-08 12:34:30,778 INFO     Training average positive_sample_loss at step 235900: 0.573917\n",
      "2022-11-08 12:34:30,778 INFO     Training average negative_sample_loss at step 235900: 0.289775\n",
      "2022-11-08 12:34:30,778 INFO     Training average loss at step 235900: 0.431846\n",
      "2022-11-08 12:34:40,309 INFO     Training average positive_sample_loss at step 236000: 0.563953\n",
      "2022-11-08 12:34:40,309 INFO     Training average negative_sample_loss at step 236000: 0.294947\n",
      "2022-11-08 12:34:40,309 INFO     Training average loss at step 236000: 0.429450\n",
      "2022-11-08 12:34:49,841 INFO     Training average positive_sample_loss at step 236100: 0.580710\n",
      "2022-11-08 12:34:49,841 INFO     Training average negative_sample_loss at step 236100: 0.292972\n",
      "2022-11-08 12:34:49,841 INFO     Training average loss at step 236100: 0.436841\n",
      "2022-11-08 12:34:59,374 INFO     Training average positive_sample_loss at step 236200: 0.596821\n",
      "2022-11-08 12:34:59,374 INFO     Training average negative_sample_loss at step 236200: 0.290878\n",
      "2022-11-08 12:34:59,374 INFO     Training average loss at step 236200: 0.443849\n",
      "2022-11-08 12:35:08,903 INFO     Training average positive_sample_loss at step 236300: 0.582188\n",
      "2022-11-08 12:35:08,903 INFO     Training average negative_sample_loss at step 236300: 0.288202\n",
      "2022-11-08 12:35:08,903 INFO     Training average loss at step 236300: 0.435195\n",
      "2022-11-08 12:35:18,431 INFO     Training average positive_sample_loss at step 236400: 0.578545\n",
      "2022-11-08 12:35:18,432 INFO     Training average negative_sample_loss at step 236400: 0.288940\n",
      "2022-11-08 12:35:18,432 INFO     Training average loss at step 236400: 0.433743\n",
      "2022-11-08 12:35:27,963 INFO     Training average positive_sample_loss at step 236500: 0.608401\n",
      "2022-11-08 12:35:27,963 INFO     Training average negative_sample_loss at step 236500: 0.289627\n",
      "2022-11-08 12:35:27,963 INFO     Training average loss at step 236500: 0.449014\n",
      "2022-11-08 12:35:37,491 INFO     Training average positive_sample_loss at step 236600: 0.559008\n",
      "2022-11-08 12:35:37,491 INFO     Training average negative_sample_loss at step 236600: 0.292034\n",
      "2022-11-08 12:35:37,491 INFO     Training average loss at step 236600: 0.425521\n",
      "2022-11-08 12:35:47,024 INFO     Training average positive_sample_loss at step 236700: 0.604094\n",
      "2022-11-08 12:35:47,024 INFO     Training average negative_sample_loss at step 236700: 0.291241\n",
      "2022-11-08 12:35:47,024 INFO     Training average loss at step 236700: 0.447668\n",
      "2022-11-08 12:35:56,551 INFO     Training average positive_sample_loss at step 236800: 0.558666\n",
      "2022-11-08 12:35:56,551 INFO     Training average negative_sample_loss at step 236800: 0.290469\n",
      "2022-11-08 12:35:56,551 INFO     Training average loss at step 236800: 0.424568\n",
      "2022-11-08 12:36:06,081 INFO     Training average positive_sample_loss at step 236900: 0.568153\n",
      "2022-11-08 12:36:06,081 INFO     Training average negative_sample_loss at step 236900: 0.288830\n",
      "2022-11-08 12:36:06,081 INFO     Training average loss at step 236900: 0.428491\n",
      "2022-11-08 12:36:15,609 INFO     Training average positive_sample_loss at step 237000: 0.582288\n",
      "2022-11-08 12:36:15,609 INFO     Training average negative_sample_loss at step 237000: 0.290180\n",
      "2022-11-08 12:36:15,609 INFO     Training average loss at step 237000: 0.436234\n",
      "2022-11-08 12:36:24,492 INFO     Training average positive_sample_loss at step 237100: 0.569821\n",
      "2022-11-08 12:36:24,492 INFO     Training average negative_sample_loss at step 237100: 0.294501\n",
      "2022-11-08 12:36:24,492 INFO     Training average loss at step 237100: 0.432161\n",
      "2022-11-08 12:36:34,026 INFO     Training average positive_sample_loss at step 237200: 0.591441\n",
      "2022-11-08 12:36:34,026 INFO     Training average negative_sample_loss at step 237200: 0.289982\n",
      "2022-11-08 12:36:34,026 INFO     Training average loss at step 237200: 0.440711\n",
      "2022-11-08 12:36:43,557 INFO     Training average positive_sample_loss at step 237300: 0.582223\n",
      "2022-11-08 12:36:43,557 INFO     Training average negative_sample_loss at step 237300: 0.285484\n",
      "2022-11-08 12:36:43,557 INFO     Training average loss at step 237300: 0.433854\n",
      "2022-11-08 12:36:53,091 INFO     Training average positive_sample_loss at step 237400: 0.591332\n",
      "2022-11-08 12:36:53,091 INFO     Training average negative_sample_loss at step 237400: 0.292930\n",
      "2022-11-08 12:36:53,091 INFO     Training average loss at step 237400: 0.442131\n",
      "2022-11-08 12:37:05,357 INFO     Training average positive_sample_loss at step 237500: 0.528695\n",
      "2022-11-08 12:37:05,357 INFO     Training average negative_sample_loss at step 237500: 0.291418\n",
      "2022-11-08 12:37:05,357 INFO     Training average loss at step 237500: 0.410057\n",
      "2022-11-08 12:37:14,885 INFO     Training average positive_sample_loss at step 237600: 0.418738\n",
      "2022-11-08 12:37:14,885 INFO     Training average negative_sample_loss at step 237600: 0.290761\n",
      "2022-11-08 12:37:14,885 INFO     Training average loss at step 237600: 0.354749\n",
      "2022-11-08 12:37:24,417 INFO     Training average positive_sample_loss at step 237700: 0.424943\n",
      "2022-11-08 12:37:24,417 INFO     Training average negative_sample_loss at step 237700: 0.286952\n",
      "2022-11-08 12:37:24,417 INFO     Training average loss at step 237700: 0.355948\n",
      "2022-11-08 12:37:33,948 INFO     Training average positive_sample_loss at step 237800: 0.419080\n",
      "2022-11-08 12:37:33,948 INFO     Training average negative_sample_loss at step 237800: 0.277287\n",
      "2022-11-08 12:37:33,948 INFO     Training average loss at step 237800: 0.348183\n",
      "2022-11-08 12:37:43,472 INFO     Training average positive_sample_loss at step 237900: 0.424196\n",
      "2022-11-08 12:37:43,472 INFO     Training average negative_sample_loss at step 237900: 0.277874\n",
      "2022-11-08 12:37:43,472 INFO     Training average loss at step 237900: 0.351035\n",
      "2022-11-08 12:37:53,002 INFO     Training average positive_sample_loss at step 238000: 0.426863\n",
      "2022-11-08 12:37:53,002 INFO     Training average negative_sample_loss at step 238000: 0.284977\n",
      "2022-11-08 12:37:53,002 INFO     Training average loss at step 238000: 0.355920\n",
      "2022-11-08 12:38:02,533 INFO     Training average positive_sample_loss at step 238100: 0.408259\n",
      "2022-11-08 12:38:02,533 INFO     Training average negative_sample_loss at step 238100: 0.278386\n",
      "2022-11-08 12:38:02,533 INFO     Training average loss at step 238100: 0.343323\n",
      "2022-11-08 12:38:12,062 INFO     Training average positive_sample_loss at step 238200: 0.429652\n",
      "2022-11-08 12:38:12,062 INFO     Training average negative_sample_loss at step 238200: 0.267841\n",
      "2022-11-08 12:38:12,062 INFO     Training average loss at step 238200: 0.348747\n",
      "2022-11-08 12:38:21,592 INFO     Training average positive_sample_loss at step 238300: 0.439067\n",
      "2022-11-08 12:38:21,592 INFO     Training average negative_sample_loss at step 238300: 0.274576\n",
      "2022-11-08 12:38:21,592 INFO     Training average loss at step 238300: 0.356822\n",
      "2022-11-08 12:38:31,124 INFO     Training average positive_sample_loss at step 238400: 0.426847\n",
      "2022-11-08 12:38:31,124 INFO     Training average negative_sample_loss at step 238400: 0.273078\n",
      "2022-11-08 12:38:31,124 INFO     Training average loss at step 238400: 0.349963\n",
      "2022-11-08 12:38:40,654 INFO     Training average positive_sample_loss at step 238500: 0.420213\n",
      "2022-11-08 12:38:40,654 INFO     Training average negative_sample_loss at step 238500: 0.274242\n",
      "2022-11-08 12:38:40,654 INFO     Training average loss at step 238500: 0.347227\n",
      "2022-11-08 12:38:50,183 INFO     Training average positive_sample_loss at step 238600: 0.405609\n",
      "2022-11-08 12:38:50,184 INFO     Training average negative_sample_loss at step 238600: 0.277025\n",
      "2022-11-08 12:38:50,184 INFO     Training average loss at step 238600: 0.341317\n",
      "2022-11-08 12:38:59,712 INFO     Training average positive_sample_loss at step 238700: 0.445652\n",
      "2022-11-08 12:38:59,713 INFO     Training average negative_sample_loss at step 238700: 0.269605\n",
      "2022-11-08 12:38:59,713 INFO     Training average loss at step 238700: 0.357628\n",
      "2022-11-08 12:39:09,243 INFO     Training average positive_sample_loss at step 238800: 0.436148\n",
      "2022-11-08 12:39:09,243 INFO     Training average negative_sample_loss at step 238800: 0.269244\n",
      "2022-11-08 12:39:09,243 INFO     Training average loss at step 238800: 0.352696\n",
      "2022-11-08 12:39:18,768 INFO     Training average positive_sample_loss at step 238900: 0.420517\n",
      "2022-11-08 12:39:18,768 INFO     Training average negative_sample_loss at step 238900: 0.265604\n",
      "2022-11-08 12:39:18,768 INFO     Training average loss at step 238900: 0.343061\n",
      "2022-11-08 12:39:28,297 INFO     Training average positive_sample_loss at step 239000: 0.418132\n",
      "2022-11-08 12:39:28,297 INFO     Training average negative_sample_loss at step 239000: 0.269626\n",
      "2022-11-08 12:39:28,297 INFO     Training average loss at step 239000: 0.343879\n",
      "2022-11-08 12:39:37,826 INFO     Training average positive_sample_loss at step 239100: 0.425106\n",
      "2022-11-08 12:39:37,826 INFO     Training average negative_sample_loss at step 239100: 0.266531\n",
      "2022-11-08 12:39:37,826 INFO     Training average loss at step 239100: 0.345819\n",
      "2022-11-08 12:39:47,353 INFO     Training average positive_sample_loss at step 239200: 0.418622\n",
      "2022-11-08 12:39:47,353 INFO     Training average negative_sample_loss at step 239200: 0.270704\n",
      "2022-11-08 12:39:47,353 INFO     Training average loss at step 239200: 0.344663\n",
      "2022-11-08 12:39:56,884 INFO     Training average positive_sample_loss at step 239300: 0.420799\n",
      "2022-11-08 12:39:56,884 INFO     Training average negative_sample_loss at step 239300: 0.271639\n",
      "2022-11-08 12:39:56,884 INFO     Training average loss at step 239300: 0.346219\n",
      "2022-11-08 12:40:06,418 INFO     Training average positive_sample_loss at step 239400: 0.415394\n",
      "2022-11-08 12:40:06,418 INFO     Training average negative_sample_loss at step 239400: 0.271216\n",
      "2022-11-08 12:40:06,418 INFO     Training average loss at step 239400: 0.343305\n",
      "2022-11-08 12:40:15,943 INFO     Training average positive_sample_loss at step 239500: 0.416152\n",
      "2022-11-08 12:40:15,943 INFO     Training average negative_sample_loss at step 239500: 0.264239\n",
      "2022-11-08 12:40:15,943 INFO     Training average loss at step 239500: 0.340196\n",
      "2022-11-08 12:40:25,476 INFO     Training average positive_sample_loss at step 239600: 0.416431\n",
      "2022-11-08 12:40:25,476 INFO     Training average negative_sample_loss at step 239600: 0.269466\n",
      "2022-11-08 12:40:25,476 INFO     Training average loss at step 239600: 0.342948\n",
      "2022-11-08 12:40:35,006 INFO     Training average positive_sample_loss at step 239700: 0.431873\n",
      "2022-11-08 12:40:35,006 INFO     Training average negative_sample_loss at step 239700: 0.265521\n",
      "2022-11-08 12:40:35,006 INFO     Training average loss at step 239700: 0.348697\n",
      "2022-11-08 12:40:44,536 INFO     Training average positive_sample_loss at step 239800: 0.429096\n",
      "2022-11-08 12:40:44,536 INFO     Training average negative_sample_loss at step 239800: 0.271078\n",
      "2022-11-08 12:40:44,536 INFO     Training average loss at step 239800: 0.350087\n",
      "2022-11-08 12:40:54,067 INFO     Training average positive_sample_loss at step 239900: 0.430720\n",
      "2022-11-08 12:40:54,067 INFO     Training average negative_sample_loss at step 239900: 0.262202\n",
      "2022-11-08 12:40:54,067 INFO     Training average loss at step 239900: 0.346461\n",
      "2022-11-08 12:41:06,405 INFO     Training average positive_sample_loss at step 240000: 0.434879\n",
      "2022-11-08 12:41:06,405 INFO     Training average negative_sample_loss at step 240000: 0.268872\n",
      "2022-11-08 12:41:06,405 INFO     Training average loss at step 240000: 0.351875\n",
      "2022-11-08 12:41:15,930 INFO     Training average positive_sample_loss at step 240100: 0.430447\n",
      "2022-11-08 12:41:15,930 INFO     Training average negative_sample_loss at step 240100: 0.272162\n",
      "2022-11-08 12:41:15,930 INFO     Training average loss at step 240100: 0.351305\n",
      "2022-11-08 12:41:25,460 INFO     Training average positive_sample_loss at step 240200: 0.419953\n",
      "2022-11-08 12:41:25,460 INFO     Training average negative_sample_loss at step 240200: 0.267509\n",
      "2022-11-08 12:41:25,460 INFO     Training average loss at step 240200: 0.343731\n",
      "2022-11-08 12:41:33,480 INFO     Training average positive_sample_loss at step 240300: 0.432628\n",
      "2022-11-08 12:41:33,480 INFO     Training average negative_sample_loss at step 240300: 0.264088\n",
      "2022-11-08 12:41:33,480 INFO     Training average loss at step 240300: 0.348358\n",
      "2022-11-08 12:41:43,013 INFO     Training average positive_sample_loss at step 240400: 0.428931\n",
      "2022-11-08 12:41:43,013 INFO     Training average negative_sample_loss at step 240400: 0.266272\n",
      "2022-11-08 12:41:43,013 INFO     Training average loss at step 240400: 0.347601\n",
      "2022-11-08 12:41:52,551 INFO     Training average positive_sample_loss at step 240500: 0.438651\n",
      "2022-11-08 12:41:52,551 INFO     Training average negative_sample_loss at step 240500: 0.265314\n",
      "2022-11-08 12:41:52,551 INFO     Training average loss at step 240500: 0.351983\n",
      "2022-11-08 12:42:02,093 INFO     Training average positive_sample_loss at step 240600: 0.426341\n",
      "2022-11-08 12:42:02,093 INFO     Training average negative_sample_loss at step 240600: 0.271595\n",
      "2022-11-08 12:42:02,093 INFO     Training average loss at step 240600: 0.348968\n",
      "2022-11-08 12:42:11,626 INFO     Training average positive_sample_loss at step 240700: 0.425073\n",
      "2022-11-08 12:42:11,626 INFO     Training average negative_sample_loss at step 240700: 0.264535\n",
      "2022-11-08 12:42:11,626 INFO     Training average loss at step 240700: 0.344804\n",
      "2022-11-08 12:42:21,159 INFO     Training average positive_sample_loss at step 240800: 0.422795\n",
      "2022-11-08 12:42:21,159 INFO     Training average negative_sample_loss at step 240800: 0.267442\n",
      "2022-11-08 12:42:21,159 INFO     Training average loss at step 240800: 0.345119\n",
      "2022-11-08 12:42:30,689 INFO     Training average positive_sample_loss at step 240900: 0.438671\n",
      "2022-11-08 12:42:30,689 INFO     Training average negative_sample_loss at step 240900: 0.263520\n",
      "2022-11-08 12:42:30,689 INFO     Training average loss at step 240900: 0.351096\n",
      "2022-11-08 12:42:40,224 INFO     Training average positive_sample_loss at step 241000: 0.428169\n",
      "2022-11-08 12:42:40,224 INFO     Training average negative_sample_loss at step 241000: 0.272610\n",
      "2022-11-08 12:42:40,224 INFO     Training average loss at step 241000: 0.350390\n",
      "2022-11-08 12:42:49,762 INFO     Training average positive_sample_loss at step 241100: 0.425210\n",
      "2022-11-08 12:42:49,762 INFO     Training average negative_sample_loss at step 241100: 0.264144\n",
      "2022-11-08 12:42:49,762 INFO     Training average loss at step 241100: 0.344677\n",
      "2022-11-08 12:42:59,298 INFO     Training average positive_sample_loss at step 241200: 0.444331\n",
      "2022-11-08 12:42:59,298 INFO     Training average negative_sample_loss at step 241200: 0.268310\n",
      "2022-11-08 12:42:59,298 INFO     Training average loss at step 241200: 0.356320\n",
      "2022-11-08 12:43:08,830 INFO     Training average positive_sample_loss at step 241300: 0.432117\n",
      "2022-11-08 12:43:08,830 INFO     Training average negative_sample_loss at step 241300: 0.265569\n",
      "2022-11-08 12:43:08,830 INFO     Training average loss at step 241300: 0.348843\n",
      "2022-11-08 12:43:18,362 INFO     Training average positive_sample_loss at step 241400: 0.435436\n",
      "2022-11-08 12:43:18,362 INFO     Training average negative_sample_loss at step 241400: 0.259918\n",
      "2022-11-08 12:43:18,362 INFO     Training average loss at step 241400: 0.347677\n",
      "2022-11-08 12:43:27,895 INFO     Training average positive_sample_loss at step 241500: 0.426745\n",
      "2022-11-08 12:43:27,896 INFO     Training average negative_sample_loss at step 241500: 0.264053\n",
      "2022-11-08 12:43:27,896 INFO     Training average loss at step 241500: 0.345399\n",
      "2022-11-08 12:43:37,430 INFO     Training average positive_sample_loss at step 241600: 0.444668\n",
      "2022-11-08 12:43:37,431 INFO     Training average negative_sample_loss at step 241600: 0.264642\n",
      "2022-11-08 12:43:37,431 INFO     Training average loss at step 241600: 0.354655\n",
      "2022-11-08 12:43:46,971 INFO     Training average positive_sample_loss at step 241700: 0.430661\n",
      "2022-11-08 12:43:46,971 INFO     Training average negative_sample_loss at step 241700: 0.262148\n",
      "2022-11-08 12:43:46,971 INFO     Training average loss at step 241700: 0.346404\n",
      "2022-11-08 12:43:56,506 INFO     Training average positive_sample_loss at step 241800: 0.426420\n",
      "2022-11-08 12:43:56,506 INFO     Training average negative_sample_loss at step 241800: 0.256953\n",
      "2022-11-08 12:43:56,506 INFO     Training average loss at step 241800: 0.341686\n",
      "2022-11-08 12:44:06,038 INFO     Training average positive_sample_loss at step 241900: 0.450621\n",
      "2022-11-08 12:44:06,038 INFO     Training average negative_sample_loss at step 241900: 0.260743\n",
      "2022-11-08 12:44:06,038 INFO     Training average loss at step 241900: 0.355682\n",
      "2022-11-08 12:44:15,570 INFO     Training average positive_sample_loss at step 242000: 0.446622\n",
      "2022-11-08 12:44:15,570 INFO     Training average negative_sample_loss at step 242000: 0.263077\n",
      "2022-11-08 12:44:15,570 INFO     Training average loss at step 242000: 0.354849\n",
      "2022-11-08 12:44:25,105 INFO     Training average positive_sample_loss at step 242100: 0.436632\n",
      "2022-11-08 12:44:25,105 INFO     Training average negative_sample_loss at step 242100: 0.260717\n",
      "2022-11-08 12:44:25,105 INFO     Training average loss at step 242100: 0.348674\n",
      "2022-11-08 12:44:34,640 INFO     Training average positive_sample_loss at step 242200: 0.444384\n",
      "2022-11-08 12:44:34,640 INFO     Training average negative_sample_loss at step 242200: 0.260094\n",
      "2022-11-08 12:44:34,640 INFO     Training average loss at step 242200: 0.352239\n",
      "2022-11-08 12:44:44,177 INFO     Training average positive_sample_loss at step 242300: 0.437594\n",
      "2022-11-08 12:44:44,177 INFO     Training average negative_sample_loss at step 242300: 0.259434\n",
      "2022-11-08 12:44:44,177 INFO     Training average loss at step 242300: 0.348514\n",
      "2022-11-08 12:44:53,708 INFO     Training average positive_sample_loss at step 242400: 0.454471\n",
      "2022-11-08 12:44:53,708 INFO     Training average negative_sample_loss at step 242400: 0.263656\n",
      "2022-11-08 12:44:53,708 INFO     Training average loss at step 242400: 0.359064\n",
      "2022-11-08 12:45:03,240 INFO     Training average positive_sample_loss at step 242500: 0.449949\n",
      "2022-11-08 12:45:03,240 INFO     Training average negative_sample_loss at step 242500: 0.263052\n",
      "2022-11-08 12:45:03,240 INFO     Training average loss at step 242500: 0.356500\n",
      "2022-11-08 12:45:12,112 INFO     Training average positive_sample_loss at step 242600: 0.438586\n",
      "2022-11-08 12:45:12,112 INFO     Training average negative_sample_loss at step 242600: 0.263517\n",
      "2022-11-08 12:45:12,112 INFO     Training average loss at step 242600: 0.351052\n",
      "2022-11-08 12:45:21,646 INFO     Training average positive_sample_loss at step 242700: 0.435961\n",
      "2022-11-08 12:45:21,646 INFO     Training average negative_sample_loss at step 242700: 0.263075\n",
      "2022-11-08 12:45:21,646 INFO     Training average loss at step 242700: 0.349518\n",
      "2022-11-08 12:45:31,182 INFO     Training average positive_sample_loss at step 242800: 0.438429\n",
      "2022-11-08 12:45:31,182 INFO     Training average negative_sample_loss at step 242800: 0.264780\n",
      "2022-11-08 12:45:31,182 INFO     Training average loss at step 242800: 0.351604\n",
      "2022-11-08 12:45:40,716 INFO     Training average positive_sample_loss at step 242900: 0.439259\n",
      "2022-11-08 12:45:40,717 INFO     Training average negative_sample_loss at step 242900: 0.265894\n",
      "2022-11-08 12:45:40,717 INFO     Training average loss at step 242900: 0.352577\n",
      "2022-11-08 12:45:49,516 INFO     Training average positive_sample_loss at step 243000: 0.442014\n",
      "2022-11-08 12:45:49,517 INFO     Training average negative_sample_loss at step 243000: 0.264292\n",
      "2022-11-08 12:45:49,517 INFO     Training average loss at step 243000: 0.353153\n",
      "2022-11-08 12:45:59,043 INFO     Training average positive_sample_loss at step 243100: 0.443110\n",
      "2022-11-08 12:45:59,043 INFO     Training average negative_sample_loss at step 243100: 0.263201\n",
      "2022-11-08 12:45:59,043 INFO     Training average loss at step 243100: 0.353156\n",
      "2022-11-08 12:46:08,572 INFO     Training average positive_sample_loss at step 243200: 0.432852\n",
      "2022-11-08 12:46:08,572 INFO     Training average negative_sample_loss at step 243200: 0.261039\n",
      "2022-11-08 12:46:08,572 INFO     Training average loss at step 243200: 0.346945\n",
      "2022-11-08 12:46:18,101 INFO     Training average positive_sample_loss at step 243300: 0.438850\n",
      "2022-11-08 12:46:18,101 INFO     Training average negative_sample_loss at step 243300: 0.260488\n",
      "2022-11-08 12:46:18,101 INFO     Training average loss at step 243300: 0.349669\n",
      "2022-11-08 12:46:27,628 INFO     Training average positive_sample_loss at step 243400: 0.452636\n",
      "2022-11-08 12:46:27,628 INFO     Training average negative_sample_loss at step 243400: 0.261310\n",
      "2022-11-08 12:46:27,628 INFO     Training average loss at step 243400: 0.356973\n",
      "2022-11-08 12:46:37,155 INFO     Training average positive_sample_loss at step 243500: 0.452115\n",
      "2022-11-08 12:46:37,155 INFO     Training average negative_sample_loss at step 243500: 0.262349\n",
      "2022-11-08 12:46:37,155 INFO     Training average loss at step 243500: 0.357232\n",
      "2022-11-08 12:46:46,683 INFO     Training average positive_sample_loss at step 243600: 0.432377\n",
      "2022-11-08 12:46:46,683 INFO     Training average negative_sample_loss at step 243600: 0.255066\n",
      "2022-11-08 12:46:46,683 INFO     Training average loss at step 243600: 0.343722\n",
      "2022-11-08 12:46:56,210 INFO     Training average positive_sample_loss at step 243700: 0.459330\n",
      "2022-11-08 12:46:56,210 INFO     Training average negative_sample_loss at step 243700: 0.265190\n",
      "2022-11-08 12:46:56,210 INFO     Training average loss at step 243700: 0.362260\n",
      "2022-11-08 12:47:05,740 INFO     Training average positive_sample_loss at step 243800: 0.425489\n",
      "2022-11-08 12:47:05,740 INFO     Training average negative_sample_loss at step 243800: 0.264103\n",
      "2022-11-08 12:47:05,740 INFO     Training average loss at step 243800: 0.344796\n",
      "2022-11-08 12:47:15,268 INFO     Training average positive_sample_loss at step 243900: 0.426382\n",
      "2022-11-08 12:47:15,268 INFO     Training average negative_sample_loss at step 243900: 0.260296\n",
      "2022-11-08 12:47:15,268 INFO     Training average loss at step 243900: 0.343339\n",
      "2022-11-08 12:47:24,796 INFO     Training average positive_sample_loss at step 244000: 0.427141\n",
      "2022-11-08 12:47:24,796 INFO     Training average negative_sample_loss at step 244000: 0.263362\n",
      "2022-11-08 12:47:24,796 INFO     Training average loss at step 244000: 0.345252\n",
      "2022-11-08 12:47:34,328 INFO     Training average positive_sample_loss at step 244100: 0.444340\n",
      "2022-11-08 12:47:34,328 INFO     Training average negative_sample_loss at step 244100: 0.261402\n",
      "2022-11-08 12:47:34,328 INFO     Training average loss at step 244100: 0.352871\n",
      "2022-11-08 12:47:43,856 INFO     Training average positive_sample_loss at step 244200: 0.429025\n",
      "2022-11-08 12:47:43,856 INFO     Training average negative_sample_loss at step 244200: 0.260377\n",
      "2022-11-08 12:47:43,856 INFO     Training average loss at step 244200: 0.344701\n",
      "2022-11-08 12:47:53,384 INFO     Training average positive_sample_loss at step 244300: 0.436199\n",
      "2022-11-08 12:47:53,384 INFO     Training average negative_sample_loss at step 244300: 0.260763\n",
      "2022-11-08 12:47:53,384 INFO     Training average loss at step 244300: 0.348481\n",
      "2022-11-08 12:48:02,916 INFO     Training average positive_sample_loss at step 244400: 0.427514\n",
      "2022-11-08 12:48:02,916 INFO     Training average negative_sample_loss at step 244400: 0.260599\n",
      "2022-11-08 12:48:02,917 INFO     Training average loss at step 244400: 0.344057\n",
      "2022-11-08 12:48:12,447 INFO     Training average positive_sample_loss at step 244500: 0.454770\n",
      "2022-11-08 12:48:12,447 INFO     Training average negative_sample_loss at step 244500: 0.258673\n",
      "2022-11-08 12:48:12,447 INFO     Training average loss at step 244500: 0.356722\n",
      "2022-11-08 12:48:21,975 INFO     Training average positive_sample_loss at step 244600: 0.430267\n",
      "2022-11-08 12:48:21,975 INFO     Training average negative_sample_loss at step 244600: 0.262107\n",
      "2022-11-08 12:48:21,975 INFO     Training average loss at step 244600: 0.346187\n",
      "2022-11-08 12:48:31,501 INFO     Training average positive_sample_loss at step 244700: 0.441852\n",
      "2022-11-08 12:48:31,501 INFO     Training average negative_sample_loss at step 244700: 0.257678\n",
      "2022-11-08 12:48:31,501 INFO     Training average loss at step 244700: 0.349765\n",
      "2022-11-08 12:48:41,036 INFO     Training average positive_sample_loss at step 244800: 0.433865\n",
      "2022-11-08 12:48:41,036 INFO     Training average negative_sample_loss at step 244800: 0.263883\n",
      "2022-11-08 12:48:41,036 INFO     Training average loss at step 244800: 0.348874\n",
      "2022-11-08 12:48:50,566 INFO     Training average positive_sample_loss at step 244900: 0.446339\n",
      "2022-11-08 12:48:50,566 INFO     Training average negative_sample_loss at step 244900: 0.257751\n",
      "2022-11-08 12:48:50,566 INFO     Training average loss at step 244900: 0.352045\n",
      "2022-11-08 12:49:00,095 INFO     Training average positive_sample_loss at step 245000: 0.429496\n",
      "2022-11-08 12:49:00,095 INFO     Training average negative_sample_loss at step 245000: 0.258365\n",
      "2022-11-08 12:49:00,095 INFO     Training average loss at step 245000: 0.343930\n",
      "2022-11-08 12:49:09,624 INFO     Training average positive_sample_loss at step 245100: 0.432910\n",
      "2022-11-08 12:49:09,625 INFO     Training average negative_sample_loss at step 245100: 0.264799\n",
      "2022-11-08 12:49:09,625 INFO     Training average loss at step 245100: 0.348854\n",
      "2022-11-08 12:49:19,149 INFO     Training average positive_sample_loss at step 245200: 0.445453\n",
      "2022-11-08 12:49:19,149 INFO     Training average negative_sample_loss at step 245200: 0.264976\n",
      "2022-11-08 12:49:19,149 INFO     Training average loss at step 245200: 0.355215\n",
      "2022-11-08 12:49:28,676 INFO     Training average positive_sample_loss at step 245300: 0.434408\n",
      "2022-11-08 12:49:28,676 INFO     Training average negative_sample_loss at step 245300: 0.262557\n",
      "2022-11-08 12:49:28,677 INFO     Training average loss at step 245300: 0.348482\n",
      "2022-11-08 12:49:38,209 INFO     Training average positive_sample_loss at step 245400: 0.427432\n",
      "2022-11-08 12:49:38,209 INFO     Training average negative_sample_loss at step 245400: 0.257947\n",
      "2022-11-08 12:49:38,209 INFO     Training average loss at step 245400: 0.342689\n",
      "2022-11-08 12:49:47,736 INFO     Training average positive_sample_loss at step 245500: 0.451982\n",
      "2022-11-08 12:49:47,736 INFO     Training average negative_sample_loss at step 245500: 0.261280\n",
      "2022-11-08 12:49:47,736 INFO     Training average loss at step 245500: 0.356631\n",
      "2022-11-08 12:49:57,263 INFO     Training average positive_sample_loss at step 245600: 0.435463\n",
      "2022-11-08 12:49:57,263 INFO     Training average negative_sample_loss at step 245600: 0.261015\n",
      "2022-11-08 12:49:57,263 INFO     Training average loss at step 245600: 0.348239\n",
      "2022-11-08 12:50:06,794 INFO     Training average positive_sample_loss at step 245700: 0.442171\n",
      "2022-11-08 12:50:06,794 INFO     Training average negative_sample_loss at step 245700: 0.259706\n",
      "2022-11-08 12:50:06,794 INFO     Training average loss at step 245700: 0.350939\n",
      "2022-11-08 12:50:16,320 INFO     Training average positive_sample_loss at step 245800: 0.452238\n",
      "2022-11-08 12:50:16,320 INFO     Training average negative_sample_loss at step 245800: 0.264272\n",
      "2022-11-08 12:50:16,320 INFO     Training average loss at step 245800: 0.358255\n",
      "2022-11-08 12:50:25,849 INFO     Training average positive_sample_loss at step 245900: 0.444361\n",
      "2022-11-08 12:50:25,849 INFO     Training average negative_sample_loss at step 245900: 0.263013\n",
      "2022-11-08 12:50:25,849 INFO     Training average loss at step 245900: 0.353687\n",
      "2022-11-08 12:50:35,379 INFO     Training average positive_sample_loss at step 246000: 0.427134\n",
      "2022-11-08 12:50:35,379 INFO     Training average negative_sample_loss at step 246000: 0.261306\n",
      "2022-11-08 12:50:35,379 INFO     Training average loss at step 246000: 0.344220\n",
      "2022-11-08 12:50:44,909 INFO     Training average positive_sample_loss at step 246100: 0.443917\n",
      "2022-11-08 12:50:44,909 INFO     Training average negative_sample_loss at step 246100: 0.259245\n",
      "2022-11-08 12:50:44,909 INFO     Training average loss at step 246100: 0.351581\n",
      "2022-11-08 12:50:54,440 INFO     Training average positive_sample_loss at step 246200: 0.431379\n",
      "2022-11-08 12:50:54,440 INFO     Training average negative_sample_loss at step 246200: 0.254593\n",
      "2022-11-08 12:50:54,440 INFO     Training average loss at step 246200: 0.342986\n",
      "2022-11-08 12:51:03,972 INFO     Training average positive_sample_loss at step 246300: 0.455207\n",
      "2022-11-08 12:51:03,972 INFO     Training average negative_sample_loss at step 246300: 0.259788\n",
      "2022-11-08 12:51:03,972 INFO     Training average loss at step 246300: 0.357498\n",
      "2022-11-08 12:51:13,501 INFO     Training average positive_sample_loss at step 246400: 0.455283\n",
      "2022-11-08 12:51:13,501 INFO     Training average negative_sample_loss at step 246400: 0.256606\n",
      "2022-11-08 12:51:13,501 INFO     Training average loss at step 246400: 0.355944\n",
      "2022-11-08 12:51:23,033 INFO     Training average positive_sample_loss at step 246500: 0.454689\n",
      "2022-11-08 12:51:23,033 INFO     Training average negative_sample_loss at step 246500: 0.260950\n",
      "2022-11-08 12:51:23,033 INFO     Training average loss at step 246500: 0.357819\n",
      "2022-11-08 12:51:31,964 INFO     Training average positive_sample_loss at step 246600: 0.444565\n",
      "2022-11-08 12:51:31,964 INFO     Training average negative_sample_loss at step 246600: 0.259045\n",
      "2022-11-08 12:51:31,964 INFO     Training average loss at step 246600: 0.351805\n",
      "2022-11-08 12:51:40,509 INFO     Training average positive_sample_loss at step 246700: 0.436506\n",
      "2022-11-08 12:51:40,509 INFO     Training average negative_sample_loss at step 246700: 0.257607\n",
      "2022-11-08 12:51:40,509 INFO     Training average loss at step 246700: 0.347057\n",
      "2022-11-08 12:51:50,044 INFO     Training average positive_sample_loss at step 246800: 0.432139\n",
      "2022-11-08 12:51:50,044 INFO     Training average negative_sample_loss at step 246800: 0.267668\n",
      "2022-11-08 12:51:50,044 INFO     Training average loss at step 246800: 0.349903\n",
      "2022-11-08 12:51:59,579 INFO     Training average positive_sample_loss at step 246900: 0.435964\n",
      "2022-11-08 12:51:59,579 INFO     Training average negative_sample_loss at step 246900: 0.256476\n",
      "2022-11-08 12:51:59,579 INFO     Training average loss at step 246900: 0.346220\n",
      "2022-11-08 12:52:09,115 INFO     Training average positive_sample_loss at step 247000: 0.434375\n",
      "2022-11-08 12:52:09,115 INFO     Training average negative_sample_loss at step 247000: 0.262515\n",
      "2022-11-08 12:52:09,115 INFO     Training average loss at step 247000: 0.348445\n",
      "2022-11-08 12:52:18,647 INFO     Training average positive_sample_loss at step 247100: 0.457062\n",
      "2022-11-08 12:52:18,647 INFO     Training average negative_sample_loss at step 247100: 0.259342\n",
      "2022-11-08 12:52:18,647 INFO     Training average loss at step 247100: 0.358202\n",
      "2022-11-08 12:52:28,177 INFO     Training average positive_sample_loss at step 247200: 0.435822\n",
      "2022-11-08 12:52:28,178 INFO     Training average negative_sample_loss at step 247200: 0.251808\n",
      "2022-11-08 12:52:28,178 INFO     Training average loss at step 247200: 0.343815\n",
      "2022-11-08 12:52:37,712 INFO     Training average positive_sample_loss at step 247300: 0.444626\n",
      "2022-11-08 12:52:37,712 INFO     Training average negative_sample_loss at step 247300: 0.262970\n",
      "2022-11-08 12:52:37,712 INFO     Training average loss at step 247300: 0.353798\n",
      "2022-11-08 12:52:47,247 INFO     Training average positive_sample_loss at step 247400: 0.443354\n",
      "2022-11-08 12:52:47,248 INFO     Training average negative_sample_loss at step 247400: 0.261600\n",
      "2022-11-08 12:52:47,248 INFO     Training average loss at step 247400: 0.352477\n",
      "2022-11-08 12:52:56,783 INFO     Training average positive_sample_loss at step 247500: 0.433640\n",
      "2022-11-08 12:52:56,783 INFO     Training average negative_sample_loss at step 247500: 0.260378\n",
      "2022-11-08 12:52:56,783 INFO     Training average loss at step 247500: 0.347009\n",
      "2022-11-08 12:53:06,319 INFO     Training average positive_sample_loss at step 247600: 0.444985\n",
      "2022-11-08 12:53:06,319 INFO     Training average negative_sample_loss at step 247600: 0.259981\n",
      "2022-11-08 12:53:06,319 INFO     Training average loss at step 247600: 0.352483\n",
      "2022-11-08 12:53:18,874 INFO     Training average positive_sample_loss at step 247700: 0.425928\n",
      "2022-11-08 12:53:18,875 INFO     Training average negative_sample_loss at step 247700: 0.262368\n",
      "2022-11-08 12:53:18,875 INFO     Training average loss at step 247700: 0.344148\n",
      "2022-11-08 12:53:28,406 INFO     Training average positive_sample_loss at step 247800: 0.424830\n",
      "2022-11-08 12:53:28,407 INFO     Training average negative_sample_loss at step 247800: 0.256938\n",
      "2022-11-08 12:53:28,407 INFO     Training average loss at step 247800: 0.340884\n",
      "2022-11-08 12:53:37,934 INFO     Training average positive_sample_loss at step 247900: 0.429621\n",
      "2022-11-08 12:53:37,934 INFO     Training average negative_sample_loss at step 247900: 0.255165\n",
      "2022-11-08 12:53:37,934 INFO     Training average loss at step 247900: 0.342393\n",
      "2022-11-08 12:53:46,882 INFO     Training average positive_sample_loss at step 248000: 0.443442\n",
      "2022-11-08 12:53:46,883 INFO     Training average negative_sample_loss at step 248000: 0.259598\n",
      "2022-11-08 12:53:46,883 INFO     Training average loss at step 248000: 0.351520\n",
      "2022-11-08 12:53:56,339 INFO     Training average positive_sample_loss at step 248100: 0.446938\n",
      "2022-11-08 12:53:56,339 INFO     Training average negative_sample_loss at step 248100: 0.263842\n",
      "2022-11-08 12:53:56,339 INFO     Training average loss at step 248100: 0.355390\n",
      "2022-11-08 12:54:05,874 INFO     Training average positive_sample_loss at step 248200: 0.448622\n",
      "2022-11-08 12:54:05,874 INFO     Training average negative_sample_loss at step 248200: 0.257542\n",
      "2022-11-08 12:54:05,874 INFO     Training average loss at step 248200: 0.353082\n",
      "2022-11-08 12:54:15,411 INFO     Training average positive_sample_loss at step 248300: 0.450596\n",
      "2022-11-08 12:54:15,411 INFO     Training average negative_sample_loss at step 248300: 0.252063\n",
      "2022-11-08 12:54:15,411 INFO     Training average loss at step 248300: 0.351330\n",
      "2022-11-08 12:54:24,945 INFO     Training average positive_sample_loss at step 248400: 0.446644\n",
      "2022-11-08 12:54:24,945 INFO     Training average negative_sample_loss at step 248400: 0.262661\n",
      "2022-11-08 12:54:24,945 INFO     Training average loss at step 248400: 0.354652\n",
      "2022-11-08 12:54:33,779 INFO     Training average positive_sample_loss at step 248500: 0.436742\n",
      "2022-11-08 12:54:33,780 INFO     Training average negative_sample_loss at step 248500: 0.261903\n",
      "2022-11-08 12:54:33,780 INFO     Training average loss at step 248500: 0.349322\n",
      "2022-11-08 12:54:43,305 INFO     Training average positive_sample_loss at step 248600: 0.439078\n",
      "2022-11-08 12:54:43,305 INFO     Training average negative_sample_loss at step 248600: 0.260752\n",
      "2022-11-08 12:54:43,305 INFO     Training average loss at step 248600: 0.349915\n",
      "2022-11-08 12:54:52,835 INFO     Training average positive_sample_loss at step 248700: 0.440771\n",
      "2022-11-08 12:54:52,835 INFO     Training average negative_sample_loss at step 248700: 0.257739\n",
      "2022-11-08 12:54:52,835 INFO     Training average loss at step 248700: 0.349255\n",
      "2022-11-08 12:55:02,366 INFO     Training average positive_sample_loss at step 248800: 0.431060\n",
      "2022-11-08 12:55:02,366 INFO     Training average negative_sample_loss at step 248800: 0.258076\n",
      "2022-11-08 12:55:02,366 INFO     Training average loss at step 248800: 0.344568\n",
      "2022-11-08 12:55:11,897 INFO     Training average positive_sample_loss at step 248900: 0.455154\n",
      "2022-11-08 12:55:11,897 INFO     Training average negative_sample_loss at step 248900: 0.258081\n",
      "2022-11-08 12:55:11,897 INFO     Training average loss at step 248900: 0.356618\n",
      "2022-11-08 12:55:21,426 INFO     Training average positive_sample_loss at step 249000: 0.457476\n",
      "2022-11-08 12:55:21,426 INFO     Training average negative_sample_loss at step 249000: 0.255821\n",
      "2022-11-08 12:55:21,426 INFO     Training average loss at step 249000: 0.356648\n",
      "2022-11-08 12:55:30,952 INFO     Training average positive_sample_loss at step 249100: 0.446839\n",
      "2022-11-08 12:55:30,952 INFO     Training average negative_sample_loss at step 249100: 0.253405\n",
      "2022-11-08 12:55:30,952 INFO     Training average loss at step 249100: 0.350122\n",
      "2022-11-08 12:55:40,480 INFO     Training average positive_sample_loss at step 249200: 0.462827\n",
      "2022-11-08 12:55:40,480 INFO     Training average negative_sample_loss at step 249200: 0.256670\n",
      "2022-11-08 12:55:40,480 INFO     Training average loss at step 249200: 0.359748\n",
      "2022-11-08 12:55:50,010 INFO     Training average positive_sample_loss at step 249300: 0.457079\n",
      "2022-11-08 12:55:50,010 INFO     Training average negative_sample_loss at step 249300: 0.254930\n",
      "2022-11-08 12:55:50,010 INFO     Training average loss at step 249300: 0.356005\n",
      "2022-11-08 12:55:59,540 INFO     Training average positive_sample_loss at step 249400: 0.448154\n",
      "2022-11-08 12:55:59,540 INFO     Training average negative_sample_loss at step 249400: 0.260241\n",
      "2022-11-08 12:55:59,540 INFO     Training average loss at step 249400: 0.354198\n",
      "2022-11-08 12:56:09,071 INFO     Training average positive_sample_loss at step 249500: 0.436232\n",
      "2022-11-08 12:56:09,071 INFO     Training average negative_sample_loss at step 249500: 0.255794\n",
      "2022-11-08 12:56:09,071 INFO     Training average loss at step 249500: 0.346013\n",
      "2022-11-08 12:56:18,597 INFO     Training average positive_sample_loss at step 249600: 0.470939\n",
      "2022-11-08 12:56:18,597 INFO     Training average negative_sample_loss at step 249600: 0.261621\n",
      "2022-11-08 12:56:18,597 INFO     Training average loss at step 249600: 0.366280\n",
      "2022-11-08 12:56:28,125 INFO     Training average positive_sample_loss at step 249700: 0.449010\n",
      "2022-11-08 12:56:28,125 INFO     Training average negative_sample_loss at step 249700: 0.259366\n",
      "2022-11-08 12:56:28,125 INFO     Training average loss at step 249700: 0.354188\n",
      "2022-11-08 12:56:37,656 INFO     Training average positive_sample_loss at step 249800: 0.443837\n",
      "2022-11-08 12:56:37,656 INFO     Training average negative_sample_loss at step 249800: 0.255475\n",
      "2022-11-08 12:56:37,656 INFO     Training average loss at step 249800: 0.349656\n",
      "2022-11-08 12:56:47,185 INFO     Training average positive_sample_loss at step 249900: 0.430566\n",
      "2022-11-08 12:56:47,185 INFO     Training average negative_sample_loss at step 249900: 0.258690\n",
      "2022-11-08 12:56:47,185 INFO     Training average loss at step 249900: 0.344628\n",
      "2022-11-08 12:56:59,522 INFO     Training average positive_sample_loss at step 250000: 0.445731\n",
      "2022-11-08 12:56:59,522 INFO     Training average negative_sample_loss at step 250000: 0.264708\n",
      "2022-11-08 12:56:59,522 INFO     Training average loss at step 250000: 0.355220\n",
      "2022-11-08 12:57:09,048 INFO     Training average positive_sample_loss at step 250100: 0.443666\n",
      "2022-11-08 12:57:09,048 INFO     Training average negative_sample_loss at step 250100: 0.255131\n",
      "2022-11-08 12:57:09,048 INFO     Training average loss at step 250100: 0.349399\n",
      "2022-11-08 12:57:18,579 INFO     Training average positive_sample_loss at step 250200: 0.428435\n",
      "2022-11-08 12:57:18,579 INFO     Training average negative_sample_loss at step 250200: 0.253919\n",
      "2022-11-08 12:57:18,579 INFO     Training average loss at step 250200: 0.341177\n",
      "2022-11-08 12:57:28,108 INFO     Training average positive_sample_loss at step 250300: 0.440646\n",
      "2022-11-08 12:57:28,109 INFO     Training average negative_sample_loss at step 250300: 0.258564\n",
      "2022-11-08 12:57:28,109 INFO     Training average loss at step 250300: 0.349605\n",
      "2022-11-08 12:57:37,638 INFO     Training average positive_sample_loss at step 250400: 0.428244\n",
      "2022-11-08 12:57:37,638 INFO     Training average negative_sample_loss at step 250400: 0.257154\n",
      "2022-11-08 12:57:37,638 INFO     Training average loss at step 250400: 0.342699\n",
      "2022-11-08 12:57:47,168 INFO     Training average positive_sample_loss at step 250500: 0.440127\n",
      "2022-11-08 12:57:47,168 INFO     Training average negative_sample_loss at step 250500: 0.258697\n",
      "2022-11-08 12:57:47,168 INFO     Training average loss at step 250500: 0.349412\n",
      "2022-11-08 12:57:56,696 INFO     Training average positive_sample_loss at step 250600: 0.438950\n",
      "2022-11-08 12:57:56,696 INFO     Training average negative_sample_loss at step 250600: 0.266566\n",
      "2022-11-08 12:57:56,696 INFO     Training average loss at step 250600: 0.352758\n",
      "2022-11-08 12:58:06,226 INFO     Training average positive_sample_loss at step 250700: 0.449031\n",
      "2022-11-08 12:58:06,226 INFO     Training average negative_sample_loss at step 250700: 0.258987\n",
      "2022-11-08 12:58:06,226 INFO     Training average loss at step 250700: 0.354009\n",
      "2022-11-08 12:58:15,754 INFO     Training average positive_sample_loss at step 250800: 0.462368\n",
      "2022-11-08 12:58:15,754 INFO     Training average negative_sample_loss at step 250800: 0.251091\n",
      "2022-11-08 12:58:15,754 INFO     Training average loss at step 250800: 0.356729\n",
      "2022-11-08 12:58:25,284 INFO     Training average positive_sample_loss at step 250900: 0.434785\n",
      "2022-11-08 12:58:25,284 INFO     Training average negative_sample_loss at step 250900: 0.260469\n",
      "2022-11-08 12:58:25,284 INFO     Training average loss at step 250900: 0.347627\n",
      "2022-11-08 12:58:34,814 INFO     Training average positive_sample_loss at step 251000: 0.457862\n",
      "2022-11-08 12:58:34,814 INFO     Training average negative_sample_loss at step 251000: 0.264314\n",
      "2022-11-08 12:58:34,814 INFO     Training average loss at step 251000: 0.361088\n",
      "2022-11-08 12:58:44,348 INFO     Training average positive_sample_loss at step 251100: 0.464483\n",
      "2022-11-08 12:58:44,348 INFO     Training average negative_sample_loss at step 251100: 0.252859\n",
      "2022-11-08 12:58:44,348 INFO     Training average loss at step 251100: 0.358671\n",
      "2022-11-08 12:58:53,878 INFO     Training average positive_sample_loss at step 251200: 0.447406\n",
      "2022-11-08 12:58:53,878 INFO     Training average negative_sample_loss at step 251200: 0.257245\n",
      "2022-11-08 12:58:53,878 INFO     Training average loss at step 251200: 0.352325\n",
      "2022-11-08 12:59:03,409 INFO     Training average positive_sample_loss at step 251300: 0.440749\n",
      "2022-11-08 12:59:03,409 INFO     Training average negative_sample_loss at step 251300: 0.256736\n",
      "2022-11-08 12:59:03,409 INFO     Training average loss at step 251300: 0.348743\n",
      "2022-11-08 12:59:12,937 INFO     Training average positive_sample_loss at step 251400: 0.443587\n",
      "2022-11-08 12:59:12,937 INFO     Training average negative_sample_loss at step 251400: 0.254739\n",
      "2022-11-08 12:59:12,937 INFO     Training average loss at step 251400: 0.349163\n",
      "2022-11-08 12:59:22,467 INFO     Training average positive_sample_loss at step 251500: 0.432584\n",
      "2022-11-08 12:59:22,467 INFO     Training average negative_sample_loss at step 251500: 0.259371\n",
      "2022-11-08 12:59:22,467 INFO     Training average loss at step 251500: 0.345978\n",
      "2022-11-08 12:59:31,997 INFO     Training average positive_sample_loss at step 251600: 0.437878\n",
      "2022-11-08 12:59:31,997 INFO     Training average negative_sample_loss at step 251600: 0.253206\n",
      "2022-11-08 12:59:31,997 INFO     Training average loss at step 251600: 0.345542\n",
      "2022-11-08 12:59:41,523 INFO     Training average positive_sample_loss at step 251700: 0.432905\n",
      "2022-11-08 12:59:41,523 INFO     Training average negative_sample_loss at step 251700: 0.256192\n",
      "2022-11-08 12:59:41,523 INFO     Training average loss at step 251700: 0.344548\n",
      "2022-11-08 12:59:51,056 INFO     Training average positive_sample_loss at step 251800: 0.441647\n",
      "2022-11-08 12:59:51,056 INFO     Training average negative_sample_loss at step 251800: 0.252598\n",
      "2022-11-08 12:59:51,056 INFO     Training average loss at step 251800: 0.347122\n",
      "2022-11-08 13:00:00,585 INFO     Training average positive_sample_loss at step 251900: 0.459767\n",
      "2022-11-08 13:00:00,585 INFO     Training average negative_sample_loss at step 251900: 0.252557\n",
      "2022-11-08 13:00:00,585 INFO     Training average loss at step 251900: 0.356162\n",
      "2022-11-08 13:00:10,112 INFO     Training average positive_sample_loss at step 252000: 0.446467\n",
      "2022-11-08 13:00:10,112 INFO     Training average negative_sample_loss at step 252000: 0.260484\n",
      "2022-11-08 13:00:10,112 INFO     Training average loss at step 252000: 0.353476\n",
      "2022-11-08 13:00:19,644 INFO     Training average positive_sample_loss at step 252100: 0.447628\n",
      "2022-11-08 13:00:19,644 INFO     Training average negative_sample_loss at step 252100: 0.258328\n",
      "2022-11-08 13:00:19,644 INFO     Training average loss at step 252100: 0.352978\n",
      "2022-11-08 13:00:29,170 INFO     Training average positive_sample_loss at step 252200: 0.449751\n",
      "2022-11-08 13:00:29,170 INFO     Training average negative_sample_loss at step 252200: 0.254659\n",
      "2022-11-08 13:00:29,170 INFO     Training average loss at step 252200: 0.352205\n",
      "2022-11-08 13:00:39,217 INFO     Training average positive_sample_loss at step 252300: 0.422603\n",
      "2022-11-08 13:00:39,218 INFO     Training average negative_sample_loss at step 252300: 0.258917\n",
      "2022-11-08 13:00:39,218 INFO     Training average loss at step 252300: 0.340760\n",
      "2022-11-08 13:00:50,873 INFO     Training average positive_sample_loss at step 252400: 0.456417\n",
      "2022-11-08 13:00:50,873 INFO     Training average negative_sample_loss at step 252400: 0.263902\n",
      "2022-11-08 13:00:50,873 INFO     Training average loss at step 252400: 0.360160\n",
      "2022-11-08 13:01:00,403 INFO     Training average positive_sample_loss at step 252500: 0.457014\n",
      "2022-11-08 13:01:00,403 INFO     Training average negative_sample_loss at step 252500: 0.259666\n",
      "2022-11-08 13:01:00,403 INFO     Training average loss at step 252500: 0.358340\n",
      "2022-11-08 13:01:09,933 INFO     Training average positive_sample_loss at step 252600: 0.452182\n",
      "2022-11-08 13:01:09,933 INFO     Training average negative_sample_loss at step 252600: 0.253476\n",
      "2022-11-08 13:01:09,933 INFO     Training average loss at step 252600: 0.352829\n",
      "2022-11-08 13:01:19,464 INFO     Training average positive_sample_loss at step 252700: 0.463978\n",
      "2022-11-08 13:01:19,464 INFO     Training average negative_sample_loss at step 252700: 0.256200\n",
      "2022-11-08 13:01:19,464 INFO     Training average loss at step 252700: 0.360089\n",
      "2022-11-08 13:01:28,992 INFO     Training average positive_sample_loss at step 252800: 0.449729\n",
      "2022-11-08 13:01:28,992 INFO     Training average negative_sample_loss at step 252800: 0.262020\n",
      "2022-11-08 13:01:28,992 INFO     Training average loss at step 252800: 0.355874\n",
      "2022-11-08 13:01:38,524 INFO     Training average positive_sample_loss at step 252900: 0.454214\n",
      "2022-11-08 13:01:38,524 INFO     Training average negative_sample_loss at step 252900: 0.257065\n",
      "2022-11-08 13:01:38,525 INFO     Training average loss at step 252900: 0.355640\n",
      "2022-11-08 13:01:48,056 INFO     Training average positive_sample_loss at step 253000: 0.443523\n",
      "2022-11-08 13:01:48,056 INFO     Training average negative_sample_loss at step 253000: 0.261156\n",
      "2022-11-08 13:01:48,056 INFO     Training average loss at step 253000: 0.352339\n",
      "2022-11-08 13:01:57,586 INFO     Training average positive_sample_loss at step 253100: 0.451421\n",
      "2022-11-08 13:01:57,586 INFO     Training average negative_sample_loss at step 253100: 0.256057\n",
      "2022-11-08 13:01:57,586 INFO     Training average loss at step 253100: 0.353739\n",
      "2022-11-08 13:02:07,117 INFO     Training average positive_sample_loss at step 253200: 0.441730\n",
      "2022-11-08 13:02:07,117 INFO     Training average negative_sample_loss at step 253200: 0.261791\n",
      "2022-11-08 13:02:07,117 INFO     Training average loss at step 253200: 0.351760\n",
      "2022-11-08 13:02:16,648 INFO     Training average positive_sample_loss at step 253300: 0.439994\n",
      "2022-11-08 13:02:16,648 INFO     Training average negative_sample_loss at step 253300: 0.259759\n",
      "2022-11-08 13:02:16,648 INFO     Training average loss at step 253300: 0.349876\n",
      "2022-11-08 13:02:26,176 INFO     Training average positive_sample_loss at step 253400: 0.439273\n",
      "2022-11-08 13:02:26,176 INFO     Training average negative_sample_loss at step 253400: 0.255012\n",
      "2022-11-08 13:02:26,177 INFO     Training average loss at step 253400: 0.347143\n",
      "2022-11-08 13:02:35,061 INFO     Training average positive_sample_loss at step 253500: 0.429176\n",
      "2022-11-08 13:02:35,061 INFO     Training average negative_sample_loss at step 253500: 0.257287\n",
      "2022-11-08 13:02:35,061 INFO     Training average loss at step 253500: 0.343231\n",
      "2022-11-08 13:02:44,597 INFO     Training average positive_sample_loss at step 253600: 0.435568\n",
      "2022-11-08 13:02:44,597 INFO     Training average negative_sample_loss at step 253600: 0.255985\n",
      "2022-11-08 13:02:44,597 INFO     Training average loss at step 253600: 0.345776\n",
      "2022-11-08 13:02:54,130 INFO     Training average positive_sample_loss at step 253700: 0.463595\n",
      "2022-11-08 13:02:54,130 INFO     Training average negative_sample_loss at step 253700: 0.253796\n",
      "2022-11-08 13:02:54,130 INFO     Training average loss at step 253700: 0.358696\n",
      "2022-11-08 13:03:03,666 INFO     Training average positive_sample_loss at step 253800: 0.455409\n",
      "2022-11-08 13:03:03,666 INFO     Training average negative_sample_loss at step 253800: 0.249188\n",
      "2022-11-08 13:03:03,666 INFO     Training average loss at step 253800: 0.352299\n",
      "2022-11-08 13:03:13,198 INFO     Training average positive_sample_loss at step 253900: 0.460350\n",
      "2022-11-08 13:03:13,198 INFO     Training average negative_sample_loss at step 253900: 0.258204\n",
      "2022-11-08 13:03:13,198 INFO     Training average loss at step 253900: 0.359277\n",
      "2022-11-08 13:03:22,020 INFO     Training average positive_sample_loss at step 254000: 0.443563\n",
      "2022-11-08 13:03:22,020 INFO     Training average negative_sample_loss at step 254000: 0.256413\n",
      "2022-11-08 13:03:22,020 INFO     Training average loss at step 254000: 0.349988\n",
      "2022-11-08 13:03:31,549 INFO     Training average positive_sample_loss at step 254100: 0.444317\n",
      "2022-11-08 13:03:31,549 INFO     Training average negative_sample_loss at step 254100: 0.264957\n",
      "2022-11-08 13:03:31,549 INFO     Training average loss at step 254100: 0.354637\n",
      "2022-11-08 13:03:41,083 INFO     Training average positive_sample_loss at step 254200: 0.435845\n",
      "2022-11-08 13:03:41,083 INFO     Training average negative_sample_loss at step 254200: 0.262904\n",
      "2022-11-08 13:03:41,083 INFO     Training average loss at step 254200: 0.349375\n",
      "2022-11-08 13:03:50,611 INFO     Training average positive_sample_loss at step 254300: 0.453130\n",
      "2022-11-08 13:03:50,611 INFO     Training average negative_sample_loss at step 254300: 0.254993\n",
      "2022-11-08 13:03:50,611 INFO     Training average loss at step 254300: 0.354061\n",
      "2022-11-08 13:04:00,139 INFO     Training average positive_sample_loss at step 254400: 0.451872\n",
      "2022-11-08 13:04:00,139 INFO     Training average negative_sample_loss at step 254400: 0.257870\n",
      "2022-11-08 13:04:00,139 INFO     Training average loss at step 254400: 0.354871\n",
      "2022-11-08 13:04:09,673 INFO     Training average positive_sample_loss at step 254500: 0.448099\n",
      "2022-11-08 13:04:09,673 INFO     Training average negative_sample_loss at step 254500: 0.251202\n",
      "2022-11-08 13:04:09,673 INFO     Training average loss at step 254500: 0.349650\n",
      "2022-11-08 13:04:19,203 INFO     Training average positive_sample_loss at step 254600: 0.440038\n",
      "2022-11-08 13:04:19,203 INFO     Training average negative_sample_loss at step 254600: 0.255109\n",
      "2022-11-08 13:04:19,203 INFO     Training average loss at step 254600: 0.347574\n",
      "2022-11-08 13:04:28,730 INFO     Training average positive_sample_loss at step 254700: 0.438583\n",
      "2022-11-08 13:04:28,731 INFO     Training average negative_sample_loss at step 254700: 0.254903\n",
      "2022-11-08 13:04:28,731 INFO     Training average loss at step 254700: 0.346743\n",
      "2022-11-08 13:04:38,263 INFO     Training average positive_sample_loss at step 254800: 0.448974\n",
      "2022-11-08 13:04:38,263 INFO     Training average negative_sample_loss at step 254800: 0.252751\n",
      "2022-11-08 13:04:38,263 INFO     Training average loss at step 254800: 0.350863\n",
      "2022-11-08 13:04:47,789 INFO     Training average positive_sample_loss at step 254900: 0.447659\n",
      "2022-11-08 13:04:47,789 INFO     Training average negative_sample_loss at step 254900: 0.258235\n",
      "2022-11-08 13:04:47,789 INFO     Training average loss at step 254900: 0.352947\n",
      "2022-11-08 13:04:57,317 INFO     Training average positive_sample_loss at step 255000: 0.443643\n",
      "2022-11-08 13:04:57,317 INFO     Training average negative_sample_loss at step 255000: 0.262743\n",
      "2022-11-08 13:04:57,318 INFO     Training average loss at step 255000: 0.353193\n",
      "2022-11-08 13:05:06,853 INFO     Training average positive_sample_loss at step 255100: 0.409115\n",
      "2022-11-08 13:05:06,853 INFO     Training average negative_sample_loss at step 255100: 0.257127\n",
      "2022-11-08 13:05:06,853 INFO     Training average loss at step 255100: 0.333121\n",
      "2022-11-08 13:05:16,380 INFO     Training average positive_sample_loss at step 255200: 0.441128\n",
      "2022-11-08 13:05:16,380 INFO     Training average negative_sample_loss at step 255200: 0.254195\n",
      "2022-11-08 13:05:16,380 INFO     Training average loss at step 255200: 0.347661\n",
      "2022-11-08 13:05:25,911 INFO     Training average positive_sample_loss at step 255300: 0.451745\n",
      "2022-11-08 13:05:25,911 INFO     Training average negative_sample_loss at step 255300: 0.252519\n",
      "2022-11-08 13:05:25,911 INFO     Training average loss at step 255300: 0.352132\n",
      "2022-11-08 13:05:35,442 INFO     Training average positive_sample_loss at step 255400: 0.470060\n",
      "2022-11-08 13:05:35,442 INFO     Training average negative_sample_loss at step 255400: 0.256250\n",
      "2022-11-08 13:05:35,442 INFO     Training average loss at step 255400: 0.363155\n",
      "2022-11-08 13:05:44,971 INFO     Training average positive_sample_loss at step 255500: 0.434194\n",
      "2022-11-08 13:05:44,971 INFO     Training average negative_sample_loss at step 255500: 0.263271\n",
      "2022-11-08 13:05:44,971 INFO     Training average loss at step 255500: 0.348733\n",
      "2022-11-08 13:05:54,500 INFO     Training average positive_sample_loss at step 255600: 0.427948\n",
      "2022-11-08 13:05:54,500 INFO     Training average negative_sample_loss at step 255600: 0.266662\n",
      "2022-11-08 13:05:54,500 INFO     Training average loss at step 255600: 0.347305\n",
      "2022-11-08 13:06:04,031 INFO     Training average positive_sample_loss at step 255700: 0.450827\n",
      "2022-11-08 13:06:04,032 INFO     Training average negative_sample_loss at step 255700: 0.257649\n",
      "2022-11-08 13:06:04,032 INFO     Training average loss at step 255700: 0.354238\n",
      "2022-11-08 13:06:13,559 INFO     Training average positive_sample_loss at step 255800: 0.433667\n",
      "2022-11-08 13:06:13,560 INFO     Training average negative_sample_loss at step 255800: 0.259895\n",
      "2022-11-08 13:06:13,560 INFO     Training average loss at step 255800: 0.346781\n",
      "2022-11-08 13:06:23,091 INFO     Training average positive_sample_loss at step 255900: 0.452387\n",
      "2022-11-08 13:06:23,091 INFO     Training average negative_sample_loss at step 255900: 0.254406\n",
      "2022-11-08 13:06:23,091 INFO     Training average loss at step 255900: 0.353397\n",
      "2022-11-08 13:06:32,617 INFO     Training average positive_sample_loss at step 256000: 0.446401\n",
      "2022-11-08 13:06:32,618 INFO     Training average negative_sample_loss at step 256000: 0.257592\n",
      "2022-11-08 13:06:32,618 INFO     Training average loss at step 256000: 0.351996\n",
      "2022-11-08 13:06:42,147 INFO     Training average positive_sample_loss at step 256100: 0.466500\n",
      "2022-11-08 13:06:42,147 INFO     Training average negative_sample_loss at step 256100: 0.253784\n",
      "2022-11-08 13:06:42,147 INFO     Training average loss at step 256100: 0.360142\n",
      "2022-11-08 13:06:51,676 INFO     Training average positive_sample_loss at step 256200: 0.437356\n",
      "2022-11-08 13:06:51,676 INFO     Training average negative_sample_loss at step 256200: 0.259726\n",
      "2022-11-08 13:06:51,677 INFO     Training average loss at step 256200: 0.348541\n",
      "2022-11-08 13:07:01,205 INFO     Training average positive_sample_loss at step 256300: 0.433335\n",
      "2022-11-08 13:07:01,205 INFO     Training average negative_sample_loss at step 256300: 0.255210\n",
      "2022-11-08 13:07:01,205 INFO     Training average loss at step 256300: 0.344273\n",
      "2022-11-08 13:07:10,739 INFO     Training average positive_sample_loss at step 256400: 0.448798\n",
      "2022-11-08 13:07:10,739 INFO     Training average negative_sample_loss at step 256400: 0.256014\n",
      "2022-11-08 13:07:10,739 INFO     Training average loss at step 256400: 0.352406\n",
      "2022-11-08 13:07:20,272 INFO     Training average positive_sample_loss at step 256500: 0.456735\n",
      "2022-11-08 13:07:20,272 INFO     Training average negative_sample_loss at step 256500: 0.251905\n",
      "2022-11-08 13:07:20,272 INFO     Training average loss at step 256500: 0.354320\n",
      "2022-11-08 13:07:29,802 INFO     Training average positive_sample_loss at step 256600: 0.464510\n",
      "2022-11-08 13:07:29,802 INFO     Training average negative_sample_loss at step 256600: 0.255360\n",
      "2022-11-08 13:07:29,802 INFO     Training average loss at step 256600: 0.359935\n",
      "2022-11-08 13:07:39,337 INFO     Training average positive_sample_loss at step 256700: 0.443891\n",
      "2022-11-08 13:07:39,337 INFO     Training average negative_sample_loss at step 256700: 0.252371\n",
      "2022-11-08 13:07:39,337 INFO     Training average loss at step 256700: 0.348131\n",
      "2022-11-08 13:07:48,866 INFO     Training average positive_sample_loss at step 256800: 0.438416\n",
      "2022-11-08 13:07:48,867 INFO     Training average negative_sample_loss at step 256800: 0.252539\n",
      "2022-11-08 13:07:48,867 INFO     Training average loss at step 256800: 0.345477\n",
      "2022-11-08 13:07:58,818 INFO     Training average positive_sample_loss at step 256900: 0.448180\n",
      "2022-11-08 13:07:58,818 INFO     Training average negative_sample_loss at step 256900: 0.259905\n",
      "2022-11-08 13:07:58,818 INFO     Training average loss at step 256900: 0.354043\n",
      "2022-11-08 13:08:08,639 INFO     Training average positive_sample_loss at step 257000: 0.437610\n",
      "2022-11-08 13:08:08,639 INFO     Training average negative_sample_loss at step 257000: 0.254366\n",
      "2022-11-08 13:08:08,639 INFO     Training average loss at step 257000: 0.345988\n",
      "2022-11-08 13:08:20,248 INFO     Training average positive_sample_loss at step 257100: 0.437813\n",
      "2022-11-08 13:08:20,248 INFO     Training average negative_sample_loss at step 257100: 0.251804\n",
      "2022-11-08 13:08:20,248 INFO     Training average loss at step 257100: 0.344809\n",
      "2022-11-08 13:08:29,778 INFO     Training average positive_sample_loss at step 257200: 0.453095\n",
      "2022-11-08 13:08:29,778 INFO     Training average negative_sample_loss at step 257200: 0.258228\n",
      "2022-11-08 13:08:29,778 INFO     Training average loss at step 257200: 0.355662\n",
      "2022-11-08 13:08:39,310 INFO     Training average positive_sample_loss at step 257300: 0.437321\n",
      "2022-11-08 13:08:39,310 INFO     Training average negative_sample_loss at step 257300: 0.254474\n",
      "2022-11-08 13:08:39,310 INFO     Training average loss at step 257300: 0.345897\n",
      "2022-11-08 13:08:48,842 INFO     Training average positive_sample_loss at step 257400: 0.456969\n",
      "2022-11-08 13:08:48,843 INFO     Training average negative_sample_loss at step 257400: 0.249544\n",
      "2022-11-08 13:08:48,843 INFO     Training average loss at step 257400: 0.353256\n",
      "2022-11-08 13:08:58,375 INFO     Training average positive_sample_loss at step 257500: 0.445562\n",
      "2022-11-08 13:08:58,375 INFO     Training average negative_sample_loss at step 257500: 0.259729\n",
      "2022-11-08 13:08:58,375 INFO     Training average loss at step 257500: 0.352646\n",
      "2022-11-08 13:09:07,905 INFO     Training average positive_sample_loss at step 257600: 0.447872\n",
      "2022-11-08 13:09:07,905 INFO     Training average negative_sample_loss at step 257600: 0.249199\n",
      "2022-11-08 13:09:07,905 INFO     Training average loss at step 257600: 0.348535\n",
      "2022-11-08 13:09:17,435 INFO     Training average positive_sample_loss at step 257700: 0.446640\n",
      "2022-11-08 13:09:17,436 INFO     Training average negative_sample_loss at step 257700: 0.261293\n",
      "2022-11-08 13:09:17,436 INFO     Training average loss at step 257700: 0.353967\n",
      "2022-11-08 13:09:26,967 INFO     Training average positive_sample_loss at step 257800: 0.442342\n",
      "2022-11-08 13:09:26,967 INFO     Training average negative_sample_loss at step 257800: 0.251312\n",
      "2022-11-08 13:09:26,967 INFO     Training average loss at step 257800: 0.346827\n",
      "2022-11-08 13:09:36,496 INFO     Training average positive_sample_loss at step 257900: 0.450758\n",
      "2022-11-08 13:09:36,497 INFO     Training average negative_sample_loss at step 257900: 0.254699\n",
      "2022-11-08 13:09:36,497 INFO     Training average loss at step 257900: 0.352729\n",
      "2022-11-08 13:09:46,028 INFO     Training average positive_sample_loss at step 258000: 0.444149\n",
      "2022-11-08 13:09:46,028 INFO     Training average negative_sample_loss at step 258000: 0.257835\n",
      "2022-11-08 13:09:46,028 INFO     Training average loss at step 258000: 0.350992\n",
      "2022-11-08 13:09:55,556 INFO     Training average positive_sample_loss at step 258100: 0.455430\n",
      "2022-11-08 13:09:55,556 INFO     Training average negative_sample_loss at step 258100: 0.255499\n",
      "2022-11-08 13:09:55,556 INFO     Training average loss at step 258100: 0.355465\n",
      "2022-11-08 13:10:05,090 INFO     Training average positive_sample_loss at step 258200: 0.467090\n",
      "2022-11-08 13:10:05,090 INFO     Training average negative_sample_loss at step 258200: 0.255093\n",
      "2022-11-08 13:10:05,090 INFO     Training average loss at step 258200: 0.361091\n",
      "2022-11-08 13:10:14,620 INFO     Training average positive_sample_loss at step 258300: 0.438262\n",
      "2022-11-08 13:10:14,620 INFO     Training average negative_sample_loss at step 258300: 0.251425\n",
      "2022-11-08 13:10:14,621 INFO     Training average loss at step 258300: 0.344843\n",
      "2022-11-08 13:10:24,148 INFO     Training average positive_sample_loss at step 258400: 0.441803\n",
      "2022-11-08 13:10:24,148 INFO     Training average negative_sample_loss at step 258400: 0.255466\n",
      "2022-11-08 13:10:24,148 INFO     Training average loss at step 258400: 0.348634\n",
      "2022-11-08 13:10:33,680 INFO     Training average positive_sample_loss at step 258500: 0.444899\n",
      "2022-11-08 13:10:33,680 INFO     Training average negative_sample_loss at step 258500: 0.253908\n",
      "2022-11-08 13:10:33,680 INFO     Training average loss at step 258500: 0.349404\n",
      "2022-11-08 13:10:43,212 INFO     Training average positive_sample_loss at step 258600: 0.453142\n",
      "2022-11-08 13:10:43,212 INFO     Training average negative_sample_loss at step 258600: 0.262239\n",
      "2022-11-08 13:10:43,212 INFO     Training average loss at step 258600: 0.357691\n",
      "2022-11-08 13:10:52,739 INFO     Training average positive_sample_loss at step 258700: 0.435902\n",
      "2022-11-08 13:10:52,739 INFO     Training average negative_sample_loss at step 258700: 0.258993\n",
      "2022-11-08 13:10:52,739 INFO     Training average loss at step 258700: 0.347448\n",
      "2022-11-08 13:11:02,274 INFO     Training average positive_sample_loss at step 258800: 0.443787\n",
      "2022-11-08 13:11:02,274 INFO     Training average negative_sample_loss at step 258800: 0.253227\n",
      "2022-11-08 13:11:02,274 INFO     Training average loss at step 258800: 0.348507\n",
      "2022-11-08 13:11:11,634 INFO     Training average positive_sample_loss at step 258900: 0.446124\n",
      "2022-11-08 13:11:11,634 INFO     Training average negative_sample_loss at step 258900: 0.256843\n",
      "2022-11-08 13:11:11,634 INFO     Training average loss at step 258900: 0.351483\n",
      "2022-11-08 13:11:20,652 INFO     Training average positive_sample_loss at step 259000: 0.445869\n",
      "2022-11-08 13:11:20,652 INFO     Training average negative_sample_loss at step 259000: 0.258232\n",
      "2022-11-08 13:11:20,652 INFO     Training average loss at step 259000: 0.352051\n",
      "2022-11-08 13:11:30,185 INFO     Training average positive_sample_loss at step 259100: 0.442148\n",
      "2022-11-08 13:11:30,185 INFO     Training average negative_sample_loss at step 259100: 0.252589\n",
      "2022-11-08 13:11:30,185 INFO     Training average loss at step 259100: 0.347369\n",
      "2022-11-08 13:11:39,721 INFO     Training average positive_sample_loss at step 259200: 0.443612\n",
      "2022-11-08 13:11:39,721 INFO     Training average negative_sample_loss at step 259200: 0.253191\n",
      "2022-11-08 13:11:39,721 INFO     Training average loss at step 259200: 0.348402\n",
      "2022-11-08 13:11:49,252 INFO     Training average positive_sample_loss at step 259300: 0.443434\n",
      "2022-11-08 13:11:49,253 INFO     Training average negative_sample_loss at step 259300: 0.248624\n",
      "2022-11-08 13:11:49,253 INFO     Training average loss at step 259300: 0.346029\n",
      "2022-11-08 13:11:58,420 INFO     Training average positive_sample_loss at step 259400: 0.440699\n",
      "2022-11-08 13:11:58,420 INFO     Training average negative_sample_loss at step 259400: 0.256081\n",
      "2022-11-08 13:11:58,420 INFO     Training average loss at step 259400: 0.348390\n",
      "2022-11-08 13:12:07,652 INFO     Training average positive_sample_loss at step 259500: 0.465138\n",
      "2022-11-08 13:12:07,652 INFO     Training average negative_sample_loss at step 259500: 0.252386\n",
      "2022-11-08 13:12:07,652 INFO     Training average loss at step 259500: 0.358762\n",
      "2022-11-08 13:12:17,181 INFO     Training average positive_sample_loss at step 259600: 0.476886\n",
      "2022-11-08 13:12:17,181 INFO     Training average negative_sample_loss at step 259600: 0.251466\n",
      "2022-11-08 13:12:17,181 INFO     Training average loss at step 259600: 0.364176\n",
      "2022-11-08 13:12:26,709 INFO     Training average positive_sample_loss at step 259700: 0.442552\n",
      "2022-11-08 13:12:26,709 INFO     Training average negative_sample_loss at step 259700: 0.249864\n",
      "2022-11-08 13:12:26,709 INFO     Training average loss at step 259700: 0.346208\n",
      "2022-11-08 13:12:36,238 INFO     Training average positive_sample_loss at step 259800: 0.445600\n",
      "2022-11-08 13:12:36,238 INFO     Training average negative_sample_loss at step 259800: 0.252561\n",
      "2022-11-08 13:12:36,238 INFO     Training average loss at step 259800: 0.349081\n",
      "2022-11-08 13:12:45,766 INFO     Training average positive_sample_loss at step 259900: 0.442082\n",
      "2022-11-08 13:12:45,766 INFO     Training average negative_sample_loss at step 259900: 0.254348\n",
      "2022-11-08 13:12:45,766 INFO     Training average loss at step 259900: 0.348215\n",
      "2022-11-08 13:12:58,131 INFO     Training average positive_sample_loss at step 260000: 0.456961\n",
      "2022-11-08 13:12:58,131 INFO     Training average negative_sample_loss at step 260000: 0.251883\n",
      "2022-11-08 13:12:58,131 INFO     Training average loss at step 260000: 0.354422\n",
      "2022-11-08 13:13:07,660 INFO     Training average positive_sample_loss at step 260100: 0.460242\n",
      "2022-11-08 13:13:07,660 INFO     Training average negative_sample_loss at step 260100: 0.250539\n",
      "2022-11-08 13:13:07,660 INFO     Training average loss at step 260100: 0.355391\n",
      "2022-11-08 13:13:17,190 INFO     Training average positive_sample_loss at step 260200: 0.433167\n",
      "2022-11-08 13:13:17,190 INFO     Training average negative_sample_loss at step 260200: 0.259208\n",
      "2022-11-08 13:13:17,190 INFO     Training average loss at step 260200: 0.346188\n",
      "2022-11-08 13:13:26,718 INFO     Training average positive_sample_loss at step 260300: 0.451459\n",
      "2022-11-08 13:13:26,718 INFO     Training average negative_sample_loss at step 260300: 0.253153\n",
      "2022-11-08 13:13:26,718 INFO     Training average loss at step 260300: 0.352306\n",
      "2022-11-08 13:13:36,245 INFO     Training average positive_sample_loss at step 260400: 0.437993\n",
      "2022-11-08 13:13:36,245 INFO     Training average negative_sample_loss at step 260400: 0.256615\n",
      "2022-11-08 13:13:36,245 INFO     Training average loss at step 260400: 0.347304\n",
      "2022-11-08 13:13:45,775 INFO     Training average positive_sample_loss at step 260500: 0.439495\n",
      "2022-11-08 13:13:45,775 INFO     Training average negative_sample_loss at step 260500: 0.257216\n",
      "2022-11-08 13:13:45,775 INFO     Training average loss at step 260500: 0.348356\n",
      "2022-11-08 13:13:55,306 INFO     Training average positive_sample_loss at step 260600: 0.431620\n",
      "2022-11-08 13:13:55,306 INFO     Training average negative_sample_loss at step 260600: 0.253273\n",
      "2022-11-08 13:13:55,306 INFO     Training average loss at step 260600: 0.342446\n",
      "2022-11-08 13:14:04,836 INFO     Training average positive_sample_loss at step 260700: 0.449805\n",
      "2022-11-08 13:14:04,836 INFO     Training average negative_sample_loss at step 260700: 0.253505\n",
      "2022-11-08 13:14:04,836 INFO     Training average loss at step 260700: 0.351655\n",
      "2022-11-08 13:14:14,363 INFO     Training average positive_sample_loss at step 260800: 0.443575\n",
      "2022-11-08 13:14:14,363 INFO     Training average negative_sample_loss at step 260800: 0.252572\n",
      "2022-11-08 13:14:14,363 INFO     Training average loss at step 260800: 0.348073\n",
      "2022-11-08 13:14:23,890 INFO     Training average positive_sample_loss at step 260900: 0.433317\n",
      "2022-11-08 13:14:23,890 INFO     Training average negative_sample_loss at step 260900: 0.250068\n",
      "2022-11-08 13:14:23,890 INFO     Training average loss at step 260900: 0.341692\n",
      "2022-11-08 13:14:33,415 INFO     Training average positive_sample_loss at step 261000: 0.449320\n",
      "2022-11-08 13:14:33,415 INFO     Training average negative_sample_loss at step 261000: 0.250196\n",
      "2022-11-08 13:14:33,415 INFO     Training average loss at step 261000: 0.349758\n",
      "2022-11-08 13:14:42,948 INFO     Training average positive_sample_loss at step 261100: 0.446689\n",
      "2022-11-08 13:14:42,948 INFO     Training average negative_sample_loss at step 261100: 0.255214\n",
      "2022-11-08 13:14:42,948 INFO     Training average loss at step 261100: 0.350952\n",
      "2022-11-08 13:14:52,478 INFO     Training average positive_sample_loss at step 261200: 0.449955\n",
      "2022-11-08 13:14:52,478 INFO     Training average negative_sample_loss at step 261200: 0.253932\n",
      "2022-11-08 13:14:52,478 INFO     Training average loss at step 261200: 0.351943\n",
      "2022-11-08 13:15:02,010 INFO     Training average positive_sample_loss at step 261300: 0.451733\n",
      "2022-11-08 13:15:02,010 INFO     Training average negative_sample_loss at step 261300: 0.250456\n",
      "2022-11-08 13:15:02,010 INFO     Training average loss at step 261300: 0.351095\n",
      "2022-11-08 13:15:11,537 INFO     Training average positive_sample_loss at step 261400: 0.446135\n",
      "2022-11-08 13:15:11,537 INFO     Training average negative_sample_loss at step 261400: 0.257152\n",
      "2022-11-08 13:15:11,537 INFO     Training average loss at step 261400: 0.351644\n",
      "2022-11-08 13:15:21,065 INFO     Training average positive_sample_loss at step 261500: 0.448174\n",
      "2022-11-08 13:15:21,065 INFO     Training average negative_sample_loss at step 261500: 0.247927\n",
      "2022-11-08 13:15:21,065 INFO     Training average loss at step 261500: 0.348051\n",
      "2022-11-08 13:15:30,995 INFO     Training average positive_sample_loss at step 261600: 0.429595\n",
      "2022-11-08 13:15:30,995 INFO     Training average negative_sample_loss at step 261600: 0.257838\n",
      "2022-11-08 13:15:30,995 INFO     Training average loss at step 261600: 0.343717\n",
      "2022-11-08 13:15:40,768 INFO     Training average positive_sample_loss at step 261700: 0.426276\n",
      "2022-11-08 13:15:40,768 INFO     Training average negative_sample_loss at step 261700: 0.254763\n",
      "2022-11-08 13:15:40,768 INFO     Training average loss at step 261700: 0.340520\n",
      "2022-11-08 13:15:52,188 INFO     Training average positive_sample_loss at step 261800: 0.447853\n",
      "2022-11-08 13:15:52,188 INFO     Training average negative_sample_loss at step 261800: 0.253270\n",
      "2022-11-08 13:15:52,188 INFO     Training average loss at step 261800: 0.350562\n",
      "2022-11-08 13:16:01,716 INFO     Training average positive_sample_loss at step 261900: 0.435380\n",
      "2022-11-08 13:16:01,716 INFO     Training average negative_sample_loss at step 261900: 0.253159\n",
      "2022-11-08 13:16:01,716 INFO     Training average loss at step 261900: 0.344270\n",
      "2022-11-08 13:16:11,243 INFO     Training average positive_sample_loss at step 262000: 0.447104\n",
      "2022-11-08 13:16:11,243 INFO     Training average negative_sample_loss at step 262000: 0.250242\n",
      "2022-11-08 13:16:11,243 INFO     Training average loss at step 262000: 0.348673\n",
      "2022-11-08 13:16:20,771 INFO     Training average positive_sample_loss at step 262100: 0.437675\n",
      "2022-11-08 13:16:20,771 INFO     Training average negative_sample_loss at step 262100: 0.248037\n",
      "2022-11-08 13:16:20,771 INFO     Training average loss at step 262100: 0.342856\n",
      "2022-11-08 13:16:30,301 INFO     Training average positive_sample_loss at step 262200: 0.442342\n",
      "2022-11-08 13:16:30,301 INFO     Training average negative_sample_loss at step 262200: 0.257963\n",
      "2022-11-08 13:16:30,301 INFO     Training average loss at step 262200: 0.350153\n",
      "2022-11-08 13:16:39,829 INFO     Training average positive_sample_loss at step 262300: 0.439240\n",
      "2022-11-08 13:16:39,829 INFO     Training average negative_sample_loss at step 262300: 0.254116\n",
      "2022-11-08 13:16:39,829 INFO     Training average loss at step 262300: 0.346678\n",
      "2022-11-08 13:16:49,360 INFO     Training average positive_sample_loss at step 262400: 0.437463\n",
      "2022-11-08 13:16:49,360 INFO     Training average negative_sample_loss at step 262400: 0.252018\n",
      "2022-11-08 13:16:49,360 INFO     Training average loss at step 262400: 0.344741\n",
      "2022-11-08 13:16:58,887 INFO     Training average positive_sample_loss at step 262500: 0.466630\n",
      "2022-11-08 13:16:58,887 INFO     Training average negative_sample_loss at step 262500: 0.249535\n",
      "2022-11-08 13:16:58,887 INFO     Training average loss at step 262500: 0.358083\n",
      "2022-11-08 13:17:08,420 INFO     Training average positive_sample_loss at step 262600: 0.442024\n",
      "2022-11-08 13:17:08,421 INFO     Training average negative_sample_loss at step 262600: 0.253288\n",
      "2022-11-08 13:17:08,421 INFO     Training average loss at step 262600: 0.347656\n",
      "2022-11-08 13:17:17,951 INFO     Training average positive_sample_loss at step 262700: 0.434815\n",
      "2022-11-08 13:17:17,952 INFO     Training average negative_sample_loss at step 262700: 0.251344\n",
      "2022-11-08 13:17:17,952 INFO     Training average loss at step 262700: 0.343079\n",
      "2022-11-08 13:17:27,479 INFO     Training average positive_sample_loss at step 262800: 0.453083\n",
      "2022-11-08 13:17:27,479 INFO     Training average negative_sample_loss at step 262800: 0.252415\n",
      "2022-11-08 13:17:27,479 INFO     Training average loss at step 262800: 0.352749\n",
      "2022-11-08 13:17:37,009 INFO     Training average positive_sample_loss at step 262900: 0.451434\n",
      "2022-11-08 13:17:37,009 INFO     Training average negative_sample_loss at step 262900: 0.254374\n",
      "2022-11-08 13:17:37,009 INFO     Training average loss at step 262900: 0.352904\n",
      "2022-11-08 13:17:46,538 INFO     Training average positive_sample_loss at step 263000: 0.431166\n",
      "2022-11-08 13:17:46,538 INFO     Training average negative_sample_loss at step 263000: 0.255133\n",
      "2022-11-08 13:17:46,538 INFO     Training average loss at step 263000: 0.343150\n",
      "2022-11-08 13:17:56,065 INFO     Training average positive_sample_loss at step 263100: 0.457578\n",
      "2022-11-08 13:17:56,065 INFO     Training average negative_sample_loss at step 263100: 0.250902\n",
      "2022-11-08 13:17:56,065 INFO     Training average loss at step 263100: 0.354240\n",
      "2022-11-08 13:18:05,593 INFO     Training average positive_sample_loss at step 263200: 0.444831\n",
      "2022-11-08 13:18:05,593 INFO     Training average negative_sample_loss at step 263200: 0.253788\n",
      "2022-11-08 13:18:05,593 INFO     Training average loss at step 263200: 0.349309\n",
      "2022-11-08 13:18:15,123 INFO     Training average positive_sample_loss at step 263300: 0.444395\n",
      "2022-11-08 13:18:15,123 INFO     Training average negative_sample_loss at step 263300: 0.251852\n",
      "2022-11-08 13:18:15,123 INFO     Training average loss at step 263300: 0.348123\n",
      "2022-11-08 13:18:24,653 INFO     Training average positive_sample_loss at step 263400: 0.443191\n",
      "2022-11-08 13:18:24,653 INFO     Training average negative_sample_loss at step 263400: 0.248260\n",
      "2022-11-08 13:18:24,653 INFO     Training average loss at step 263400: 0.345726\n",
      "2022-11-08 13:18:34,184 INFO     Training average positive_sample_loss at step 263500: 0.451009\n",
      "2022-11-08 13:18:34,184 INFO     Training average negative_sample_loss at step 263500: 0.249631\n",
      "2022-11-08 13:18:34,184 INFO     Training average loss at step 263500: 0.350320\n",
      "2022-11-08 13:18:43,712 INFO     Training average positive_sample_loss at step 263600: 0.474456\n",
      "2022-11-08 13:18:43,712 INFO     Training average negative_sample_loss at step 263600: 0.250775\n",
      "2022-11-08 13:18:43,712 INFO     Training average loss at step 263600: 0.362615\n",
      "2022-11-08 13:18:53,239 INFO     Training average positive_sample_loss at step 263700: 0.434096\n",
      "2022-11-08 13:18:53,240 INFO     Training average negative_sample_loss at step 263700: 0.255484\n",
      "2022-11-08 13:18:53,240 INFO     Training average loss at step 263700: 0.344790\n",
      "2022-11-08 13:19:02,772 INFO     Training average positive_sample_loss at step 263800: 0.427765\n",
      "2022-11-08 13:19:02,772 INFO     Training average negative_sample_loss at step 263800: 0.251518\n",
      "2022-11-08 13:19:02,772 INFO     Training average loss at step 263800: 0.339641\n",
      "2022-11-08 13:19:12,301 INFO     Training average positive_sample_loss at step 263900: 0.449391\n",
      "2022-11-08 13:19:12,301 INFO     Training average negative_sample_loss at step 263900: 0.250835\n",
      "2022-11-08 13:19:12,301 INFO     Training average loss at step 263900: 0.350113\n",
      "2022-11-08 13:19:21,830 INFO     Training average positive_sample_loss at step 264000: 0.450571\n",
      "2022-11-08 13:19:21,830 INFO     Training average negative_sample_loss at step 264000: 0.251494\n",
      "2022-11-08 13:19:21,830 INFO     Training average loss at step 264000: 0.351033\n",
      "2022-11-08 13:19:31,358 INFO     Training average positive_sample_loss at step 264100: 0.457478\n",
      "2022-11-08 13:19:31,358 INFO     Training average negative_sample_loss at step 264100: 0.251908\n",
      "2022-11-08 13:19:31,358 INFO     Training average loss at step 264100: 0.354693\n",
      "2022-11-08 13:19:40,886 INFO     Training average positive_sample_loss at step 264200: 0.447868\n",
      "2022-11-08 13:19:40,886 INFO     Training average negative_sample_loss at step 264200: 0.249762\n",
      "2022-11-08 13:19:40,886 INFO     Training average loss at step 264200: 0.348815\n",
      "2022-11-08 13:19:50,418 INFO     Training average positive_sample_loss at step 264300: 0.437881\n",
      "2022-11-08 13:19:50,418 INFO     Training average negative_sample_loss at step 264300: 0.248216\n",
      "2022-11-08 13:19:50,418 INFO     Training average loss at step 264300: 0.343049\n",
      "2022-11-08 13:19:59,287 INFO     Training average positive_sample_loss at step 264400: 0.456518\n",
      "2022-11-08 13:19:59,287 INFO     Training average negative_sample_loss at step 264400: 0.257888\n",
      "2022-11-08 13:19:59,287 INFO     Training average loss at step 264400: 0.357203\n",
      "2022-11-08 13:20:08,823 INFO     Training average positive_sample_loss at step 264500: 0.463730\n",
      "2022-11-08 13:20:08,823 INFO     Training average negative_sample_loss at step 264500: 0.252678\n",
      "2022-11-08 13:20:08,823 INFO     Training average loss at step 264500: 0.358204\n",
      "2022-11-08 13:20:18,357 INFO     Training average positive_sample_loss at step 264600: 0.448859\n",
      "2022-11-08 13:20:18,357 INFO     Training average negative_sample_loss at step 264600: 0.249218\n",
      "2022-11-08 13:20:18,357 INFO     Training average loss at step 264600: 0.349039\n",
      "2022-11-08 13:20:27,888 INFO     Training average positive_sample_loss at step 264700: 0.454621\n",
      "2022-11-08 13:20:27,888 INFO     Training average negative_sample_loss at step 264700: 0.255074\n",
      "2022-11-08 13:20:27,888 INFO     Training average loss at step 264700: 0.354847\n",
      "2022-11-08 13:20:37,420 INFO     Training average positive_sample_loss at step 264800: 0.444420\n",
      "2022-11-08 13:20:37,421 INFO     Training average negative_sample_loss at step 264800: 0.249631\n",
      "2022-11-08 13:20:37,421 INFO     Training average loss at step 264800: 0.347026\n",
      "2022-11-08 13:20:46,290 INFO     Training average positive_sample_loss at step 264900: 0.462429\n",
      "2022-11-08 13:20:46,290 INFO     Training average negative_sample_loss at step 264900: 0.248417\n",
      "2022-11-08 13:20:46,290 INFO     Training average loss at step 264900: 0.355423\n",
      "2022-11-08 13:20:55,816 INFO     Training average positive_sample_loss at step 265000: 0.459876\n",
      "2022-11-08 13:20:55,816 INFO     Training average negative_sample_loss at step 265000: 0.253826\n",
      "2022-11-08 13:20:55,817 INFO     Training average loss at step 265000: 0.356851\n",
      "2022-11-08 13:21:05,347 INFO     Training average positive_sample_loss at step 265100: 0.451226\n",
      "2022-11-08 13:21:05,347 INFO     Training average negative_sample_loss at step 265100: 0.255529\n",
      "2022-11-08 13:21:05,347 INFO     Training average loss at step 265100: 0.353377\n",
      "2022-11-08 13:21:14,876 INFO     Training average positive_sample_loss at step 265200: 0.419855\n",
      "2022-11-08 13:21:14,876 INFO     Training average negative_sample_loss at step 265200: 0.250829\n",
      "2022-11-08 13:21:14,876 INFO     Training average loss at step 265200: 0.335342\n",
      "2022-11-08 13:21:24,402 INFO     Training average positive_sample_loss at step 265300: 0.425125\n",
      "2022-11-08 13:21:24,403 INFO     Training average negative_sample_loss at step 265300: 0.251825\n",
      "2022-11-08 13:21:24,403 INFO     Training average loss at step 265300: 0.338475\n",
      "2022-11-08 13:21:33,933 INFO     Training average positive_sample_loss at step 265400: 0.445847\n",
      "2022-11-08 13:21:33,933 INFO     Training average negative_sample_loss at step 265400: 0.252131\n",
      "2022-11-08 13:21:33,933 INFO     Training average loss at step 265400: 0.348989\n",
      "2022-11-08 13:21:43,460 INFO     Training average positive_sample_loss at step 265500: 0.432492\n",
      "2022-11-08 13:21:43,461 INFO     Training average negative_sample_loss at step 265500: 0.252969\n",
      "2022-11-08 13:21:43,461 INFO     Training average loss at step 265500: 0.342730\n",
      "2022-11-08 13:21:52,992 INFO     Training average positive_sample_loss at step 265600: 0.440174\n",
      "2022-11-08 13:21:52,992 INFO     Training average negative_sample_loss at step 265600: 0.252436\n",
      "2022-11-08 13:21:52,992 INFO     Training average loss at step 265600: 0.346305\n",
      "2022-11-08 13:22:02,521 INFO     Training average positive_sample_loss at step 265700: 0.437395\n",
      "2022-11-08 13:22:02,521 INFO     Training average negative_sample_loss at step 265700: 0.252772\n",
      "2022-11-08 13:22:02,521 INFO     Training average loss at step 265700: 0.345084\n",
      "2022-11-08 13:22:12,050 INFO     Training average positive_sample_loss at step 265800: 0.447584\n",
      "2022-11-08 13:22:12,050 INFO     Training average negative_sample_loss at step 265800: 0.244506\n",
      "2022-11-08 13:22:12,050 INFO     Training average loss at step 265800: 0.346045\n",
      "2022-11-08 13:22:21,578 INFO     Training average positive_sample_loss at step 265900: 0.438248\n",
      "2022-11-08 13:22:21,578 INFO     Training average negative_sample_loss at step 265900: 0.244937\n",
      "2022-11-08 13:22:21,578 INFO     Training average loss at step 265900: 0.341592\n",
      "2022-11-08 13:22:31,107 INFO     Training average positive_sample_loss at step 266000: 0.436143\n",
      "2022-11-08 13:22:31,107 INFO     Training average negative_sample_loss at step 266000: 0.253136\n",
      "2022-11-08 13:22:31,107 INFO     Training average loss at step 266000: 0.344639\n",
      "2022-11-08 13:22:40,638 INFO     Training average positive_sample_loss at step 266100: 0.445639\n",
      "2022-11-08 13:22:40,638 INFO     Training average negative_sample_loss at step 266100: 0.254101\n",
      "2022-11-08 13:22:40,638 INFO     Training average loss at step 266100: 0.349870\n",
      "2022-11-08 13:22:50,167 INFO     Training average positive_sample_loss at step 266200: 0.453912\n",
      "2022-11-08 13:22:50,167 INFO     Training average negative_sample_loss at step 266200: 0.251210\n",
      "2022-11-08 13:22:50,167 INFO     Training average loss at step 266200: 0.352561\n",
      "2022-11-08 13:23:00,245 INFO     Training average positive_sample_loss at step 266300: 0.454876\n",
      "2022-11-08 13:23:00,245 INFO     Training average negative_sample_loss at step 266300: 0.246869\n",
      "2022-11-08 13:23:00,245 INFO     Training average loss at step 266300: 0.350872\n",
      "2022-11-08 13:23:10,098 INFO     Training average positive_sample_loss at step 266400: 0.443483\n",
      "2022-11-08 13:23:10,098 INFO     Training average negative_sample_loss at step 266400: 0.249956\n",
      "2022-11-08 13:23:10,098 INFO     Training average loss at step 266400: 0.346719\n",
      "2022-11-08 13:23:21,486 INFO     Training average positive_sample_loss at step 266500: 0.452738\n",
      "2022-11-08 13:23:21,486 INFO     Training average negative_sample_loss at step 266500: 0.250541\n",
      "2022-11-08 13:23:21,486 INFO     Training average loss at step 266500: 0.351640\n",
      "2022-11-08 13:23:31,016 INFO     Training average positive_sample_loss at step 266600: 0.446069\n",
      "2022-11-08 13:23:31,017 INFO     Training average negative_sample_loss at step 266600: 0.253158\n",
      "2022-11-08 13:23:31,017 INFO     Training average loss at step 266600: 0.349614\n",
      "2022-11-08 13:23:40,547 INFO     Training average positive_sample_loss at step 266700: 0.444992\n",
      "2022-11-08 13:23:40,547 INFO     Training average negative_sample_loss at step 266700: 0.250046\n",
      "2022-11-08 13:23:40,547 INFO     Training average loss at step 266700: 0.347519\n",
      "2022-11-08 13:23:50,076 INFO     Training average positive_sample_loss at step 266800: 0.452171\n",
      "2022-11-08 13:23:50,076 INFO     Training average negative_sample_loss at step 266800: 0.248321\n",
      "2022-11-08 13:23:50,076 INFO     Training average loss at step 266800: 0.350246\n",
      "2022-11-08 13:23:59,604 INFO     Training average positive_sample_loss at step 266900: 0.437046\n",
      "2022-11-08 13:23:59,605 INFO     Training average negative_sample_loss at step 266900: 0.245928\n",
      "2022-11-08 13:23:59,605 INFO     Training average loss at step 266900: 0.341487\n",
      "2022-11-08 13:24:09,135 INFO     Training average positive_sample_loss at step 267000: 0.432449\n",
      "2022-11-08 13:24:09,135 INFO     Training average negative_sample_loss at step 267000: 0.251366\n",
      "2022-11-08 13:24:09,135 INFO     Training average loss at step 267000: 0.341908\n",
      "2022-11-08 13:24:18,665 INFO     Training average positive_sample_loss at step 267100: 0.437395\n",
      "2022-11-08 13:24:18,665 INFO     Training average negative_sample_loss at step 267100: 0.249965\n",
      "2022-11-08 13:24:18,665 INFO     Training average loss at step 267100: 0.343680\n",
      "2022-11-08 13:24:28,194 INFO     Training average positive_sample_loss at step 267200: 0.451640\n",
      "2022-11-08 13:24:28,194 INFO     Training average negative_sample_loss at step 267200: 0.250005\n",
      "2022-11-08 13:24:28,194 INFO     Training average loss at step 267200: 0.350823\n",
      "2022-11-08 13:24:37,722 INFO     Training average positive_sample_loss at step 267300: 0.442469\n",
      "2022-11-08 13:24:37,722 INFO     Training average negative_sample_loss at step 267300: 0.255839\n",
      "2022-11-08 13:24:37,722 INFO     Training average loss at step 267300: 0.349154\n",
      "2022-11-08 13:24:47,252 INFO     Training average positive_sample_loss at step 267400: 0.463345\n",
      "2022-11-08 13:24:47,252 INFO     Training average negative_sample_loss at step 267400: 0.251899\n",
      "2022-11-08 13:24:47,252 INFO     Training average loss at step 267400: 0.357622\n",
      "2022-11-08 13:24:56,782 INFO     Training average positive_sample_loss at step 267500: 0.419853\n",
      "2022-11-08 13:24:56,782 INFO     Training average negative_sample_loss at step 267500: 0.252250\n",
      "2022-11-08 13:24:56,782 INFO     Training average loss at step 267500: 0.336052\n",
      "2022-11-08 13:25:06,313 INFO     Training average positive_sample_loss at step 267600: 0.438260\n",
      "2022-11-08 13:25:06,313 INFO     Training average negative_sample_loss at step 267600: 0.242585\n",
      "2022-11-08 13:25:06,313 INFO     Training average loss at step 267600: 0.340423\n",
      "2022-11-08 13:25:15,842 INFO     Training average positive_sample_loss at step 267700: 0.444571\n",
      "2022-11-08 13:25:15,842 INFO     Training average negative_sample_loss at step 267700: 0.248235\n",
      "2022-11-08 13:25:15,842 INFO     Training average loss at step 267700: 0.346403\n",
      "2022-11-08 13:25:25,376 INFO     Training average positive_sample_loss at step 267800: 0.454815\n",
      "2022-11-08 13:25:25,376 INFO     Training average negative_sample_loss at step 267800: 0.250093\n",
      "2022-11-08 13:25:25,376 INFO     Training average loss at step 267800: 0.352454\n",
      "2022-11-08 13:25:34,907 INFO     Training average positive_sample_loss at step 267900: 0.437173\n",
      "2022-11-08 13:25:34,907 INFO     Training average negative_sample_loss at step 267900: 0.249527\n",
      "2022-11-08 13:25:34,907 INFO     Training average loss at step 267900: 0.343350\n",
      "2022-11-08 13:25:44,437 INFO     Training average positive_sample_loss at step 268000: 0.468154\n",
      "2022-11-08 13:25:44,437 INFO     Training average negative_sample_loss at step 268000: 0.244660\n",
      "2022-11-08 13:25:44,437 INFO     Training average loss at step 268000: 0.356407\n",
      "2022-11-08 13:25:53,964 INFO     Training average positive_sample_loss at step 268100: 0.423496\n",
      "2022-11-08 13:25:53,964 INFO     Training average negative_sample_loss at step 268100: 0.247151\n",
      "2022-11-08 13:25:53,965 INFO     Training average loss at step 268100: 0.335323\n",
      "2022-11-08 13:26:03,496 INFO     Training average positive_sample_loss at step 268200: 0.441655\n",
      "2022-11-08 13:26:03,496 INFO     Training average negative_sample_loss at step 268200: 0.250947\n",
      "2022-11-08 13:26:03,496 INFO     Training average loss at step 268200: 0.346301\n",
      "2022-11-08 13:26:13,024 INFO     Training average positive_sample_loss at step 268300: 0.442238\n",
      "2022-11-08 13:26:13,025 INFO     Training average negative_sample_loss at step 268300: 0.248970\n",
      "2022-11-08 13:26:13,025 INFO     Training average loss at step 268300: 0.345604\n",
      "2022-11-08 13:26:22,550 INFO     Training average positive_sample_loss at step 268400: 0.465940\n",
      "2022-11-08 13:26:22,550 INFO     Training average negative_sample_loss at step 268400: 0.247540\n",
      "2022-11-08 13:26:22,550 INFO     Training average loss at step 268400: 0.356740\n",
      "2022-11-08 13:26:32,081 INFO     Training average positive_sample_loss at step 268500: 0.451384\n",
      "2022-11-08 13:26:32,081 INFO     Training average negative_sample_loss at step 268500: 0.246171\n",
      "2022-11-08 13:26:32,081 INFO     Training average loss at step 268500: 0.348778\n",
      "2022-11-08 13:26:41,610 INFO     Training average positive_sample_loss at step 268600: 0.441880\n",
      "2022-11-08 13:26:41,610 INFO     Training average negative_sample_loss at step 268600: 0.252023\n",
      "2022-11-08 13:26:41,610 INFO     Training average loss at step 268600: 0.346952\n",
      "2022-11-08 13:26:51,137 INFO     Training average positive_sample_loss at step 268700: 0.439677\n",
      "2022-11-08 13:26:51,137 INFO     Training average negative_sample_loss at step 268700: 0.250890\n",
      "2022-11-08 13:26:51,138 INFO     Training average loss at step 268700: 0.345284\n",
      "2022-11-08 13:27:00,670 INFO     Training average positive_sample_loss at step 268800: 0.430023\n",
      "2022-11-08 13:27:00,670 INFO     Training average negative_sample_loss at step 268800: 0.245713\n",
      "2022-11-08 13:27:00,670 INFO     Training average loss at step 268800: 0.337868\n",
      "2022-11-08 13:27:10,201 INFO     Training average positive_sample_loss at step 268900: 0.444789\n",
      "2022-11-08 13:27:10,201 INFO     Training average negative_sample_loss at step 268900: 0.253971\n",
      "2022-11-08 13:27:10,201 INFO     Training average loss at step 268900: 0.349380\n",
      "2022-11-08 13:27:19,733 INFO     Training average positive_sample_loss at step 269000: 0.460563\n",
      "2022-11-08 13:27:19,733 INFO     Training average negative_sample_loss at step 269000: 0.252545\n",
      "2022-11-08 13:27:19,733 INFO     Training average loss at step 269000: 0.356554\n",
      "2022-11-08 13:27:29,263 INFO     Training average positive_sample_loss at step 269100: 0.461610\n",
      "2022-11-08 13:27:29,263 INFO     Training average negative_sample_loss at step 269100: 0.246704\n",
      "2022-11-08 13:27:29,263 INFO     Training average loss at step 269100: 0.354157\n",
      "2022-11-08 13:27:38,794 INFO     Training average positive_sample_loss at step 269200: 0.442877\n",
      "2022-11-08 13:27:38,794 INFO     Training average negative_sample_loss at step 269200: 0.250151\n",
      "2022-11-08 13:27:38,794 INFO     Training average loss at step 269200: 0.346514\n",
      "2022-11-08 13:27:48,325 INFO     Training average positive_sample_loss at step 269300: 0.448389\n",
      "2022-11-08 13:27:48,325 INFO     Training average negative_sample_loss at step 269300: 0.247400\n",
      "2022-11-08 13:27:48,325 INFO     Training average loss at step 269300: 0.347895\n",
      "2022-11-08 13:27:57,854 INFO     Training average positive_sample_loss at step 269400: 0.454955\n",
      "2022-11-08 13:27:57,854 INFO     Training average negative_sample_loss at step 269400: 0.250140\n",
      "2022-11-08 13:27:57,854 INFO     Training average loss at step 269400: 0.352548\n",
      "2022-11-08 13:28:07,387 INFO     Training average positive_sample_loss at step 269500: 0.449065\n",
      "2022-11-08 13:28:07,387 INFO     Training average negative_sample_loss at step 269500: 0.244183\n",
      "2022-11-08 13:28:07,388 INFO     Training average loss at step 269500: 0.346624\n",
      "2022-11-08 13:28:16,919 INFO     Training average positive_sample_loss at step 269600: 0.427108\n",
      "2022-11-08 13:28:16,919 INFO     Training average negative_sample_loss at step 269600: 0.251387\n",
      "2022-11-08 13:28:16,919 INFO     Training average loss at step 269600: 0.339247\n",
      "2022-11-08 13:28:26,452 INFO     Training average positive_sample_loss at step 269700: 0.448038\n",
      "2022-11-08 13:28:26,452 INFO     Training average negative_sample_loss at step 269700: 0.247825\n",
      "2022-11-08 13:28:26,452 INFO     Training average loss at step 269700: 0.347932\n",
      "2022-11-08 13:28:35,983 INFO     Training average positive_sample_loss at step 269800: 0.441696\n",
      "2022-11-08 13:28:35,983 INFO     Training average negative_sample_loss at step 269800: 0.246651\n",
      "2022-11-08 13:28:35,983 INFO     Training average loss at step 269800: 0.344174\n",
      "2022-11-08 13:28:44,867 INFO     Training average positive_sample_loss at step 269900: 0.441541\n",
      "2022-11-08 13:28:44,867 INFO     Training average negative_sample_loss at step 269900: 0.249758\n",
      "2022-11-08 13:28:44,868 INFO     Training average loss at step 269900: 0.345649\n",
      "2022-11-08 13:28:56,978 INFO     Training average positive_sample_loss at step 270000: 0.444285\n",
      "2022-11-08 13:28:56,978 INFO     Training average negative_sample_loss at step 270000: 0.249699\n",
      "2022-11-08 13:28:56,978 INFO     Training average loss at step 270000: 0.346992\n",
      "2022-11-08 13:29:06,516 INFO     Training average positive_sample_loss at step 270100: 0.445182\n",
      "2022-11-08 13:29:06,516 INFO     Training average negative_sample_loss at step 270100: 0.249080\n",
      "2022-11-08 13:29:06,516 INFO     Training average loss at step 270100: 0.347131\n",
      "2022-11-08 13:29:16,050 INFO     Training average positive_sample_loss at step 270200: 0.444634\n",
      "2022-11-08 13:29:16,050 INFO     Training average negative_sample_loss at step 270200: 0.247786\n",
      "2022-11-08 13:29:16,050 INFO     Training average loss at step 270200: 0.346210\n",
      "2022-11-08 13:29:24,875 INFO     Training average positive_sample_loss at step 270300: 0.431944\n",
      "2022-11-08 13:29:24,875 INFO     Training average negative_sample_loss at step 270300: 0.246542\n",
      "2022-11-08 13:29:24,875 INFO     Training average loss at step 270300: 0.339243\n",
      "2022-11-08 13:29:34,404 INFO     Training average positive_sample_loss at step 270400: 0.470489\n",
      "2022-11-08 13:29:34,404 INFO     Training average negative_sample_loss at step 270400: 0.241767\n",
      "2022-11-08 13:29:34,404 INFO     Training average loss at step 270400: 0.356128\n",
      "2022-11-08 13:29:43,933 INFO     Training average positive_sample_loss at step 270500: 0.456846\n",
      "2022-11-08 13:29:43,933 INFO     Training average negative_sample_loss at step 270500: 0.252549\n",
      "2022-11-08 13:29:43,933 INFO     Training average loss at step 270500: 0.354698\n",
      "2022-11-08 13:29:53,458 INFO     Training average positive_sample_loss at step 270600: 0.441200\n",
      "2022-11-08 13:29:53,458 INFO     Training average negative_sample_loss at step 270600: 0.242279\n",
      "2022-11-08 13:29:53,458 INFO     Training average loss at step 270600: 0.341739\n",
      "2022-11-08 13:30:02,990 INFO     Training average positive_sample_loss at step 270700: 0.441775\n",
      "2022-11-08 13:30:02,990 INFO     Training average negative_sample_loss at step 270700: 0.245038\n",
      "2022-11-08 13:30:02,990 INFO     Training average loss at step 270700: 0.343407\n",
      "2022-11-08 13:30:12,517 INFO     Training average positive_sample_loss at step 270800: 0.438016\n",
      "2022-11-08 13:30:12,517 INFO     Training average negative_sample_loss at step 270800: 0.252496\n",
      "2022-11-08 13:30:12,517 INFO     Training average loss at step 270800: 0.345256\n",
      "2022-11-08 13:30:22,558 INFO     Training average positive_sample_loss at step 270900: 0.441147\n",
      "2022-11-08 13:30:22,559 INFO     Training average negative_sample_loss at step 270900: 0.252977\n",
      "2022-11-08 13:30:22,559 INFO     Training average loss at step 270900: 0.347062\n",
      "2022-11-08 13:30:32,087 INFO     Training average positive_sample_loss at step 271000: 0.449894\n",
      "2022-11-08 13:30:32,087 INFO     Training average negative_sample_loss at step 271000: 0.250297\n",
      "2022-11-08 13:30:32,087 INFO     Training average loss at step 271000: 0.350095\n",
      "2022-11-08 13:30:42,156 INFO     Training average positive_sample_loss at step 271100: 0.431708\n",
      "2022-11-08 13:30:42,156 INFO     Training average negative_sample_loss at step 271100: 0.254560\n",
      "2022-11-08 13:30:42,156 INFO     Training average loss at step 271100: 0.343134\n",
      "2022-11-08 13:30:52,626 INFO     Training average positive_sample_loss at step 271200: 0.445071\n",
      "2022-11-08 13:30:52,626 INFO     Training average negative_sample_loss at step 271200: 0.242210\n",
      "2022-11-08 13:30:52,626 INFO     Training average loss at step 271200: 0.343640\n",
      "2022-11-08 13:31:02,158 INFO     Training average positive_sample_loss at step 271300: 0.411592\n",
      "2022-11-08 13:31:02,158 INFO     Training average negative_sample_loss at step 271300: 0.248553\n",
      "2022-11-08 13:31:02,158 INFO     Training average loss at step 271300: 0.330073\n",
      "2022-11-08 13:31:11,688 INFO     Training average positive_sample_loss at step 271400: 0.432817\n",
      "2022-11-08 13:31:11,688 INFO     Training average negative_sample_loss at step 271400: 0.247462\n",
      "2022-11-08 13:31:11,688 INFO     Training average loss at step 271400: 0.340139\n",
      "2022-11-08 13:31:21,213 INFO     Training average positive_sample_loss at step 271500: 0.439792\n",
      "2022-11-08 13:31:21,213 INFO     Training average negative_sample_loss at step 271500: 0.250125\n",
      "2022-11-08 13:31:21,213 INFO     Training average loss at step 271500: 0.344958\n",
      "2022-11-08 13:31:30,740 INFO     Training average positive_sample_loss at step 271600: 0.447468\n",
      "2022-11-08 13:31:30,740 INFO     Training average negative_sample_loss at step 271600: 0.257087\n",
      "2022-11-08 13:31:30,740 INFO     Training average loss at step 271600: 0.352277\n",
      "2022-11-08 13:31:40,269 INFO     Training average positive_sample_loss at step 271700: 0.469053\n",
      "2022-11-08 13:31:40,269 INFO     Training average negative_sample_loss at step 271700: 0.243878\n",
      "2022-11-08 13:31:40,269 INFO     Training average loss at step 271700: 0.356466\n",
      "2022-11-08 13:31:49,798 INFO     Training average positive_sample_loss at step 271800: 0.447941\n",
      "2022-11-08 13:31:49,798 INFO     Training average negative_sample_loss at step 271800: 0.250068\n",
      "2022-11-08 13:31:49,798 INFO     Training average loss at step 271800: 0.349005\n",
      "2022-11-08 13:31:59,329 INFO     Training average positive_sample_loss at step 271900: 0.466137\n",
      "2022-11-08 13:31:59,330 INFO     Training average negative_sample_loss at step 271900: 0.243809\n",
      "2022-11-08 13:31:59,330 INFO     Training average loss at step 271900: 0.354973\n",
      "2022-11-08 13:32:08,857 INFO     Training average positive_sample_loss at step 272000: 0.450877\n",
      "2022-11-08 13:32:08,858 INFO     Training average negative_sample_loss at step 272000: 0.246868\n",
      "2022-11-08 13:32:08,858 INFO     Training average loss at step 272000: 0.348872\n",
      "2022-11-08 13:32:18,382 INFO     Training average positive_sample_loss at step 272100: 0.435117\n",
      "2022-11-08 13:32:18,382 INFO     Training average negative_sample_loss at step 272100: 0.247656\n",
      "2022-11-08 13:32:18,382 INFO     Training average loss at step 272100: 0.341387\n",
      "2022-11-08 13:32:27,912 INFO     Training average positive_sample_loss at step 272200: 0.450948\n",
      "2022-11-08 13:32:27,912 INFO     Training average negative_sample_loss at step 272200: 0.249910\n",
      "2022-11-08 13:32:27,912 INFO     Training average loss at step 272200: 0.350429\n",
      "2022-11-08 13:32:37,440 INFO     Training average positive_sample_loss at step 272300: 0.446593\n",
      "2022-11-08 13:32:37,440 INFO     Training average negative_sample_loss at step 272300: 0.247930\n",
      "2022-11-08 13:32:37,440 INFO     Training average loss at step 272300: 0.347261\n",
      "2022-11-08 13:32:46,969 INFO     Training average positive_sample_loss at step 272400: 0.435254\n",
      "2022-11-08 13:32:46,969 INFO     Training average negative_sample_loss at step 272400: 0.243286\n",
      "2022-11-08 13:32:46,969 INFO     Training average loss at step 272400: 0.339270\n",
      "2022-11-08 13:32:56,498 INFO     Training average positive_sample_loss at step 272500: 0.452348\n",
      "2022-11-08 13:32:56,498 INFO     Training average negative_sample_loss at step 272500: 0.248549\n",
      "2022-11-08 13:32:56,498 INFO     Training average loss at step 272500: 0.350448\n",
      "2022-11-08 13:33:06,025 INFO     Training average positive_sample_loss at step 272600: 0.427834\n",
      "2022-11-08 13:33:06,026 INFO     Training average negative_sample_loss at step 272600: 0.252566\n",
      "2022-11-08 13:33:06,026 INFO     Training average loss at step 272600: 0.340200\n",
      "2022-11-08 13:33:15,552 INFO     Training average positive_sample_loss at step 272700: 0.455709\n",
      "2022-11-08 13:33:15,552 INFO     Training average negative_sample_loss at step 272700: 0.245905\n",
      "2022-11-08 13:33:15,552 INFO     Training average loss at step 272700: 0.350807\n",
      "2022-11-08 13:33:25,083 INFO     Training average positive_sample_loss at step 272800: 0.450074\n",
      "2022-11-08 13:33:25,084 INFO     Training average negative_sample_loss at step 272800: 0.246175\n",
      "2022-11-08 13:33:25,084 INFO     Training average loss at step 272800: 0.348124\n",
      "2022-11-08 13:33:34,612 INFO     Training average positive_sample_loss at step 272900: 0.428914\n",
      "2022-11-08 13:33:34,612 INFO     Training average negative_sample_loss at step 272900: 0.251248\n",
      "2022-11-08 13:33:34,612 INFO     Training average loss at step 272900: 0.340081\n",
      "2022-11-08 13:33:44,144 INFO     Training average positive_sample_loss at step 273000: 0.437290\n",
      "2022-11-08 13:33:44,144 INFO     Training average negative_sample_loss at step 273000: 0.247787\n",
      "2022-11-08 13:33:44,144 INFO     Training average loss at step 273000: 0.342539\n",
      "2022-11-08 13:33:53,673 INFO     Training average positive_sample_loss at step 273100: 0.430314\n",
      "2022-11-08 13:33:53,673 INFO     Training average negative_sample_loss at step 273100: 0.242028\n",
      "2022-11-08 13:33:53,673 INFO     Training average loss at step 273100: 0.336171\n",
      "2022-11-08 13:34:03,202 INFO     Training average positive_sample_loss at step 273200: 0.428366\n",
      "2022-11-08 13:34:03,202 INFO     Training average negative_sample_loss at step 273200: 0.246565\n",
      "2022-11-08 13:34:03,202 INFO     Training average loss at step 273200: 0.337465\n",
      "2022-11-08 13:34:12,730 INFO     Training average positive_sample_loss at step 273300: 0.447147\n",
      "2022-11-08 13:34:12,730 INFO     Training average negative_sample_loss at step 273300: 0.243233\n",
      "2022-11-08 13:34:12,730 INFO     Training average loss at step 273300: 0.345190\n",
      "2022-11-08 13:34:22,261 INFO     Training average positive_sample_loss at step 273400: 0.459808\n",
      "2022-11-08 13:34:22,261 INFO     Training average negative_sample_loss at step 273400: 0.247547\n",
      "2022-11-08 13:34:22,261 INFO     Training average loss at step 273400: 0.353677\n",
      "2022-11-08 13:34:31,790 INFO     Training average positive_sample_loss at step 273500: 0.419364\n",
      "2022-11-08 13:34:31,790 INFO     Training average negative_sample_loss at step 273500: 0.251223\n",
      "2022-11-08 13:34:31,790 INFO     Training average loss at step 273500: 0.335293\n",
      "2022-11-08 13:34:41,319 INFO     Training average positive_sample_loss at step 273600: 0.444751\n",
      "2022-11-08 13:34:41,319 INFO     Training average negative_sample_loss at step 273600: 0.248858\n",
      "2022-11-08 13:34:41,319 INFO     Training average loss at step 273600: 0.346804\n",
      "2022-11-08 13:34:50,846 INFO     Training average positive_sample_loss at step 273700: 0.421220\n",
      "2022-11-08 13:34:50,846 INFO     Training average negative_sample_loss at step 273700: 0.249709\n",
      "2022-11-08 13:34:50,846 INFO     Training average loss at step 273700: 0.335465\n",
      "2022-11-08 13:35:00,374 INFO     Training average positive_sample_loss at step 273800: 0.440791\n",
      "2022-11-08 13:35:00,374 INFO     Training average negative_sample_loss at step 273800: 0.246581\n",
      "2022-11-08 13:35:00,374 INFO     Training average loss at step 273800: 0.343686\n",
      "2022-11-08 13:35:09,905 INFO     Training average positive_sample_loss at step 273900: 0.434167\n",
      "2022-11-08 13:35:09,905 INFO     Training average negative_sample_loss at step 273900: 0.252695\n",
      "2022-11-08 13:35:09,905 INFO     Training average loss at step 273900: 0.343431\n",
      "2022-11-08 13:35:19,435 INFO     Training average positive_sample_loss at step 274000: 0.434650\n",
      "2022-11-08 13:35:19,435 INFO     Training average negative_sample_loss at step 274000: 0.251449\n",
      "2022-11-08 13:35:19,435 INFO     Training average loss at step 274000: 0.343049\n",
      "2022-11-08 13:35:28,966 INFO     Training average positive_sample_loss at step 274100: 0.429688\n",
      "2022-11-08 13:35:28,966 INFO     Training average negative_sample_loss at step 274100: 0.244927\n",
      "2022-11-08 13:35:28,966 INFO     Training average loss at step 274100: 0.337308\n",
      "2022-11-08 13:35:38,494 INFO     Training average positive_sample_loss at step 274200: 0.442831\n",
      "2022-11-08 13:35:38,494 INFO     Training average negative_sample_loss at step 274200: 0.246770\n",
      "2022-11-08 13:35:38,494 INFO     Training average loss at step 274200: 0.344800\n",
      "2022-11-08 13:35:48,026 INFO     Training average positive_sample_loss at step 274300: 0.421572\n",
      "2022-11-08 13:35:48,026 INFO     Training average negative_sample_loss at step 274300: 0.245603\n",
      "2022-11-08 13:35:48,026 INFO     Training average loss at step 274300: 0.333587\n",
      "2022-11-08 13:35:57,555 INFO     Training average positive_sample_loss at step 274400: 0.461362\n",
      "2022-11-08 13:35:57,555 INFO     Training average negative_sample_loss at step 274400: 0.239150\n",
      "2022-11-08 13:35:57,555 INFO     Training average loss at step 274400: 0.350256\n",
      "2022-11-08 13:36:07,085 INFO     Training average positive_sample_loss at step 274500: 0.428199\n",
      "2022-11-08 13:36:07,085 INFO     Training average negative_sample_loss at step 274500: 0.245081\n",
      "2022-11-08 13:36:07,085 INFO     Training average loss at step 274500: 0.336640\n",
      "2022-11-08 13:36:16,615 INFO     Training average positive_sample_loss at step 274600: 0.435650\n",
      "2022-11-08 13:36:16,615 INFO     Training average negative_sample_loss at step 274600: 0.251195\n",
      "2022-11-08 13:36:16,615 INFO     Training average loss at step 274600: 0.343423\n",
      "2022-11-08 13:36:26,145 INFO     Training average positive_sample_loss at step 274700: 0.430820\n",
      "2022-11-08 13:36:26,145 INFO     Training average negative_sample_loss at step 274700: 0.248123\n",
      "2022-11-08 13:36:26,145 INFO     Training average loss at step 274700: 0.339472\n",
      "2022-11-08 13:36:35,670 INFO     Training average positive_sample_loss at step 274800: 0.451905\n",
      "2022-11-08 13:36:35,670 INFO     Training average negative_sample_loss at step 274800: 0.249364\n",
      "2022-11-08 13:36:35,670 INFO     Training average loss at step 274800: 0.350635\n",
      "2022-11-08 13:36:45,200 INFO     Training average positive_sample_loss at step 274900: 0.432720\n",
      "2022-11-08 13:36:45,200 INFO     Training average negative_sample_loss at step 274900: 0.244002\n",
      "2022-11-08 13:36:45,200 INFO     Training average loss at step 274900: 0.338361\n",
      "2022-11-08 13:36:54,729 INFO     Training average positive_sample_loss at step 275000: 0.432350\n",
      "2022-11-08 13:36:54,729 INFO     Training average negative_sample_loss at step 275000: 0.243961\n",
      "2022-11-08 13:36:54,729 INFO     Training average loss at step 275000: 0.338156\n",
      "2022-11-08 13:37:04,258 INFO     Training average positive_sample_loss at step 275100: 0.448108\n",
      "2022-11-08 13:37:04,258 INFO     Training average negative_sample_loss at step 275100: 0.243691\n",
      "2022-11-08 13:37:04,258 INFO     Training average loss at step 275100: 0.345900\n",
      "2022-11-08 13:37:13,791 INFO     Training average positive_sample_loss at step 275200: 0.437097\n",
      "2022-11-08 13:37:13,791 INFO     Training average negative_sample_loss at step 275200: 0.243154\n",
      "2022-11-08 13:37:13,791 INFO     Training average loss at step 275200: 0.340126\n",
      "2022-11-08 13:37:22,645 INFO     Training average positive_sample_loss at step 275300: 0.478708\n",
      "2022-11-08 13:37:22,645 INFO     Training average negative_sample_loss at step 275300: 0.244469\n",
      "2022-11-08 13:37:22,645 INFO     Training average loss at step 275300: 0.361589\n",
      "2022-11-08 13:37:32,169 INFO     Training average positive_sample_loss at step 275400: 0.429764\n",
      "2022-11-08 13:37:32,169 INFO     Training average negative_sample_loss at step 275400: 0.249077\n",
      "2022-11-08 13:37:32,169 INFO     Training average loss at step 275400: 0.339421\n",
      "2022-11-08 13:37:42,201 INFO     Training average positive_sample_loss at step 275500: 0.440430\n",
      "2022-11-08 13:37:42,201 INFO     Training average negative_sample_loss at step 275500: 0.247335\n",
      "2022-11-08 13:37:42,201 INFO     Training average loss at step 275500: 0.343883\n",
      "2022-11-08 13:37:52,328 INFO     Training average positive_sample_loss at step 275600: 0.435036\n",
      "2022-11-08 13:37:52,328 INFO     Training average negative_sample_loss at step 275600: 0.242556\n",
      "2022-11-08 13:37:52,328 INFO     Training average loss at step 275600: 0.338796\n",
      "2022-11-08 13:38:01,855 INFO     Training average positive_sample_loss at step 275700: 0.440897\n",
      "2022-11-08 13:38:01,855 INFO     Training average negative_sample_loss at step 275700: 0.250744\n",
      "2022-11-08 13:38:01,855 INFO     Training average loss at step 275700: 0.345820\n",
      "2022-11-08 13:38:10,758 INFO     Training average positive_sample_loss at step 275800: 0.439404\n",
      "2022-11-08 13:38:10,758 INFO     Training average negative_sample_loss at step 275800: 0.244797\n",
      "2022-11-08 13:38:10,758 INFO     Training average loss at step 275800: 0.342100\n",
      "2022-11-08 13:38:21,400 INFO     Training average positive_sample_loss at step 275900: 0.447012\n",
      "2022-11-08 13:38:21,400 INFO     Training average negative_sample_loss at step 275900: 0.244493\n",
      "2022-11-08 13:38:21,400 INFO     Training average loss at step 275900: 0.345753\n",
      "2022-11-08 13:38:30,930 INFO     Training average positive_sample_loss at step 276000: 0.432123\n",
      "2022-11-08 13:38:30,930 INFO     Training average negative_sample_loss at step 276000: 0.249465\n",
      "2022-11-08 13:38:30,930 INFO     Training average loss at step 276000: 0.340794\n",
      "2022-11-08 13:38:40,460 INFO     Training average positive_sample_loss at step 276100: 0.435417\n",
      "2022-11-08 13:38:40,461 INFO     Training average negative_sample_loss at step 276100: 0.240839\n",
      "2022-11-08 13:38:40,461 INFO     Training average loss at step 276100: 0.338128\n",
      "2022-11-08 13:38:49,991 INFO     Training average positive_sample_loss at step 276200: 0.441541\n",
      "2022-11-08 13:38:49,991 INFO     Training average negative_sample_loss at step 276200: 0.250680\n",
      "2022-11-08 13:38:49,991 INFO     Training average loss at step 276200: 0.346111\n",
      "2022-11-08 13:38:59,518 INFO     Training average positive_sample_loss at step 276300: 0.451542\n",
      "2022-11-08 13:38:59,518 INFO     Training average negative_sample_loss at step 276300: 0.240547\n",
      "2022-11-08 13:38:59,518 INFO     Training average loss at step 276300: 0.346045\n",
      "2022-11-08 13:39:09,046 INFO     Training average positive_sample_loss at step 276400: 0.443679\n",
      "2022-11-08 13:39:09,046 INFO     Training average negative_sample_loss at step 276400: 0.246533\n",
      "2022-11-08 13:39:09,046 INFO     Training average loss at step 276400: 0.345106\n",
      "2022-11-08 13:39:18,571 INFO     Training average positive_sample_loss at step 276500: 0.445106\n",
      "2022-11-08 13:39:18,572 INFO     Training average negative_sample_loss at step 276500: 0.240723\n",
      "2022-11-08 13:39:18,572 INFO     Training average loss at step 276500: 0.342914\n",
      "2022-11-08 13:39:28,100 INFO     Training average positive_sample_loss at step 276600: 0.451382\n",
      "2022-11-08 13:39:28,100 INFO     Training average negative_sample_loss at step 276600: 0.244291\n",
      "2022-11-08 13:39:28,100 INFO     Training average loss at step 276600: 0.347837\n",
      "2022-11-08 13:39:37,629 INFO     Training average positive_sample_loss at step 276700: 0.426698\n",
      "2022-11-08 13:39:37,629 INFO     Training average negative_sample_loss at step 276700: 0.246918\n",
      "2022-11-08 13:39:37,630 INFO     Training average loss at step 276700: 0.336808\n",
      "2022-11-08 13:39:47,160 INFO     Training average positive_sample_loss at step 276800: 0.429063\n",
      "2022-11-08 13:39:47,161 INFO     Training average negative_sample_loss at step 276800: 0.241839\n",
      "2022-11-08 13:39:47,161 INFO     Training average loss at step 276800: 0.335451\n",
      "2022-11-08 13:39:56,689 INFO     Training average positive_sample_loss at step 276900: 0.415904\n",
      "2022-11-08 13:39:56,689 INFO     Training average negative_sample_loss at step 276900: 0.243770\n",
      "2022-11-08 13:39:56,689 INFO     Training average loss at step 276900: 0.329837\n",
      "2022-11-08 13:40:06,216 INFO     Training average positive_sample_loss at step 277000: 0.424570\n",
      "2022-11-08 13:40:06,216 INFO     Training average negative_sample_loss at step 277000: 0.254963\n",
      "2022-11-08 13:40:06,216 INFO     Training average loss at step 277000: 0.339766\n",
      "2022-11-08 13:40:15,748 INFO     Training average positive_sample_loss at step 277100: 0.420780\n",
      "2022-11-08 13:40:15,748 INFO     Training average negative_sample_loss at step 277100: 0.247774\n",
      "2022-11-08 13:40:15,748 INFO     Training average loss at step 277100: 0.334277\n",
      "2022-11-08 13:40:25,277 INFO     Training average positive_sample_loss at step 277200: 0.429807\n",
      "2022-11-08 13:40:25,277 INFO     Training average negative_sample_loss at step 277200: 0.245524\n",
      "2022-11-08 13:40:25,277 INFO     Training average loss at step 277200: 0.337666\n",
      "2022-11-08 13:40:34,806 INFO     Training average positive_sample_loss at step 277300: 0.439443\n",
      "2022-11-08 13:40:34,807 INFO     Training average negative_sample_loss at step 277300: 0.244129\n",
      "2022-11-08 13:40:34,807 INFO     Training average loss at step 277300: 0.341786\n",
      "2022-11-08 13:40:44,337 INFO     Training average positive_sample_loss at step 277400: 0.430654\n",
      "2022-11-08 13:40:44,337 INFO     Training average negative_sample_loss at step 277400: 0.241140\n",
      "2022-11-08 13:40:44,337 INFO     Training average loss at step 277400: 0.335897\n",
      "2022-11-08 13:40:53,862 INFO     Training average positive_sample_loss at step 277500: 0.434021\n",
      "2022-11-08 13:40:53,862 INFO     Training average negative_sample_loss at step 277500: 0.247004\n",
      "2022-11-08 13:40:53,862 INFO     Training average loss at step 277500: 0.340512\n",
      "2022-11-08 13:41:03,389 INFO     Training average positive_sample_loss at step 277600: 0.454832\n",
      "2022-11-08 13:41:03,390 INFO     Training average negative_sample_loss at step 277600: 0.244292\n",
      "2022-11-08 13:41:03,390 INFO     Training average loss at step 277600: 0.349562\n",
      "2022-11-08 13:41:12,921 INFO     Training average positive_sample_loss at step 277700: 0.432946\n",
      "2022-11-08 13:41:12,921 INFO     Training average negative_sample_loss at step 277700: 0.247036\n",
      "2022-11-08 13:41:12,921 INFO     Training average loss at step 277700: 0.339991\n",
      "2022-11-08 13:41:22,449 INFO     Training average positive_sample_loss at step 277800: 0.448383\n",
      "2022-11-08 13:41:22,449 INFO     Training average negative_sample_loss at step 277800: 0.242796\n",
      "2022-11-08 13:41:22,449 INFO     Training average loss at step 277800: 0.345589\n",
      "2022-11-08 13:41:31,977 INFO     Training average positive_sample_loss at step 277900: 0.455296\n",
      "2022-11-08 13:41:31,977 INFO     Training average negative_sample_loss at step 277900: 0.238613\n",
      "2022-11-08 13:41:31,978 INFO     Training average loss at step 277900: 0.346955\n",
      "2022-11-08 13:41:41,506 INFO     Training average positive_sample_loss at step 278000: 0.424490\n",
      "2022-11-08 13:41:41,506 INFO     Training average negative_sample_loss at step 278000: 0.239844\n",
      "2022-11-08 13:41:41,506 INFO     Training average loss at step 278000: 0.332167\n",
      "2022-11-08 13:41:51,033 INFO     Training average positive_sample_loss at step 278100: 0.410972\n",
      "2022-11-08 13:41:51,033 INFO     Training average negative_sample_loss at step 278100: 0.242039\n",
      "2022-11-08 13:41:51,033 INFO     Training average loss at step 278100: 0.326505\n",
      "2022-11-08 13:42:00,631 INFO     Training average positive_sample_loss at step 278200: 0.450875\n",
      "2022-11-08 13:42:00,631 INFO     Training average negative_sample_loss at step 278200: 0.244059\n",
      "2022-11-08 13:42:00,631 INFO     Training average loss at step 278200: 0.347467\n",
      "2022-11-08 13:42:10,417 INFO     Training average positive_sample_loss at step 278300: 0.440478\n",
      "2022-11-08 13:42:10,417 INFO     Training average negative_sample_loss at step 278300: 0.248924\n",
      "2022-11-08 13:42:10,417 INFO     Training average loss at step 278300: 0.344701\n",
      "2022-11-08 13:42:20,197 INFO     Training average positive_sample_loss at step 278400: 0.416625\n",
      "2022-11-08 13:42:20,197 INFO     Training average negative_sample_loss at step 278400: 0.235011\n",
      "2022-11-08 13:42:20,197 INFO     Training average loss at step 278400: 0.325818\n",
      "2022-11-08 13:42:29,980 INFO     Training average positive_sample_loss at step 278500: 0.432726\n",
      "2022-11-08 13:42:29,980 INFO     Training average negative_sample_loss at step 278500: 0.249652\n",
      "2022-11-08 13:42:29,980 INFO     Training average loss at step 278500: 0.341189\n",
      "2022-11-08 13:42:39,578 INFO     Training average positive_sample_loss at step 278600: 0.435495\n",
      "2022-11-08 13:42:39,578 INFO     Training average negative_sample_loss at step 278600: 0.251196\n",
      "2022-11-08 13:42:39,578 INFO     Training average loss at step 278600: 0.343346\n",
      "2022-11-08 13:42:49,109 INFO     Training average positive_sample_loss at step 278700: 0.425661\n",
      "2022-11-08 13:42:49,110 INFO     Training average negative_sample_loss at step 278700: 0.244468\n",
      "2022-11-08 13:42:49,110 INFO     Training average loss at step 278700: 0.335064\n",
      "2022-11-08 13:42:58,637 INFO     Training average positive_sample_loss at step 278800: 0.449487\n",
      "2022-11-08 13:42:58,637 INFO     Training average negative_sample_loss at step 278800: 0.247752\n",
      "2022-11-08 13:42:58,637 INFO     Training average loss at step 278800: 0.348619\n",
      "2022-11-08 13:43:08,169 INFO     Training average positive_sample_loss at step 278900: 0.455771\n",
      "2022-11-08 13:43:08,169 INFO     Training average negative_sample_loss at step 278900: 0.239569\n",
      "2022-11-08 13:43:08,169 INFO     Training average loss at step 278900: 0.347670\n",
      "2022-11-08 13:43:17,701 INFO     Training average positive_sample_loss at step 279000: 0.443641\n",
      "2022-11-08 13:43:17,701 INFO     Training average negative_sample_loss at step 279000: 0.248939\n",
      "2022-11-08 13:43:17,701 INFO     Training average loss at step 279000: 0.346290\n",
      "2022-11-08 13:43:27,228 INFO     Training average positive_sample_loss at step 279100: 0.424799\n",
      "2022-11-08 13:43:27,228 INFO     Training average negative_sample_loss at step 279100: 0.244795\n",
      "2022-11-08 13:43:27,228 INFO     Training average loss at step 279100: 0.334797\n",
      "2022-11-08 13:43:36,764 INFO     Training average positive_sample_loss at step 279200: 0.421690\n",
      "2022-11-08 13:43:36,764 INFO     Training average negative_sample_loss at step 279200: 0.246919\n",
      "2022-11-08 13:43:36,764 INFO     Training average loss at step 279200: 0.334305\n",
      "2022-11-08 13:43:46,294 INFO     Training average positive_sample_loss at step 279300: 0.410429\n",
      "2022-11-08 13:43:46,294 INFO     Training average negative_sample_loss at step 279300: 0.251207\n",
      "2022-11-08 13:43:46,294 INFO     Training average loss at step 279300: 0.330818\n",
      "2022-11-08 13:43:55,822 INFO     Training average positive_sample_loss at step 279400: 0.432254\n",
      "2022-11-08 13:43:55,822 INFO     Training average negative_sample_loss at step 279400: 0.243441\n",
      "2022-11-08 13:43:55,822 INFO     Training average loss at step 279400: 0.337848\n",
      "2022-11-08 13:44:05,358 INFO     Training average positive_sample_loss at step 279500: 0.430928\n",
      "2022-11-08 13:44:05,358 INFO     Training average negative_sample_loss at step 279500: 0.239112\n",
      "2022-11-08 13:44:05,358 INFO     Training average loss at step 279500: 0.335020\n",
      "2022-11-08 13:44:14,889 INFO     Training average positive_sample_loss at step 279600: 0.423276\n",
      "2022-11-08 13:44:14,889 INFO     Training average negative_sample_loss at step 279600: 0.246954\n",
      "2022-11-08 13:44:14,889 INFO     Training average loss at step 279600: 0.335115\n",
      "2022-11-08 13:44:24,416 INFO     Training average positive_sample_loss at step 279700: 0.425456\n",
      "2022-11-08 13:44:24,416 INFO     Training average negative_sample_loss at step 279700: 0.240219\n",
      "2022-11-08 13:44:24,416 INFO     Training average loss at step 279700: 0.332837\n",
      "2022-11-08 13:44:33,951 INFO     Training average positive_sample_loss at step 279800: 0.437812\n",
      "2022-11-08 13:44:33,951 INFO     Training average negative_sample_loss at step 279800: 0.240301\n",
      "2022-11-08 13:44:33,951 INFO     Training average loss at step 279800: 0.339057\n",
      "2022-11-08 13:44:43,479 INFO     Training average positive_sample_loss at step 279900: 0.440954\n",
      "2022-11-08 13:44:43,479 INFO     Training average negative_sample_loss at step 279900: 0.246211\n",
      "2022-11-08 13:44:43,479 INFO     Training average loss at step 279900: 0.343582\n",
      "2022-11-08 13:44:55,635 INFO     Training average positive_sample_loss at step 280000: 0.439838\n",
      "2022-11-08 13:44:55,635 INFO     Training average negative_sample_loss at step 280000: 0.249396\n",
      "2022-11-08 13:44:55,635 INFO     Training average loss at step 280000: 0.344617\n",
      "2022-11-08 13:45:05,168 INFO     Training average positive_sample_loss at step 280100: 0.438149\n",
      "2022-11-08 13:45:05,169 INFO     Training average negative_sample_loss at step 280100: 0.244743\n",
      "2022-11-08 13:45:05,169 INFO     Training average loss at step 280100: 0.341446\n",
      "2022-11-08 13:45:15,165 INFO     Training average positive_sample_loss at step 280200: 0.423572\n",
      "2022-11-08 13:45:15,165 INFO     Training average negative_sample_loss at step 280200: 0.247208\n",
      "2022-11-08 13:45:15,165 INFO     Training average loss at step 280200: 0.335390\n",
      "2022-11-08 13:45:25,314 INFO     Training average positive_sample_loss at step 280300: 0.448418\n",
      "2022-11-08 13:45:25,315 INFO     Training average negative_sample_loss at step 280300: 0.243632\n",
      "2022-11-08 13:45:25,315 INFO     Training average loss at step 280300: 0.346025\n",
      "2022-11-08 13:45:34,847 INFO     Training average positive_sample_loss at step 280400: 0.431224\n",
      "2022-11-08 13:45:34,847 INFO     Training average negative_sample_loss at step 280400: 0.248322\n",
      "2022-11-08 13:45:34,847 INFO     Training average loss at step 280400: 0.339773\n",
      "2022-11-08 13:45:44,376 INFO     Training average positive_sample_loss at step 280500: 0.442891\n",
      "2022-11-08 13:45:44,376 INFO     Training average negative_sample_loss at step 280500: 0.244491\n",
      "2022-11-08 13:45:44,376 INFO     Training average loss at step 280500: 0.343691\n",
      "2022-11-08 13:45:54,957 INFO     Training average positive_sample_loss at step 280600: 0.437056\n",
      "2022-11-08 13:45:54,957 INFO     Training average negative_sample_loss at step 280600: 0.241889\n",
      "2022-11-08 13:45:54,957 INFO     Training average loss at step 280600: 0.339473\n",
      "2022-11-08 13:46:03,814 INFO     Training average positive_sample_loss at step 280700: 0.433290\n",
      "2022-11-08 13:46:03,814 INFO     Training average negative_sample_loss at step 280700: 0.239788\n",
      "2022-11-08 13:46:03,814 INFO     Training average loss at step 280700: 0.336539\n",
      "2022-11-08 13:46:13,327 INFO     Training average positive_sample_loss at step 280800: 0.437562\n",
      "2022-11-08 13:46:13,327 INFO     Training average negative_sample_loss at step 280800: 0.243324\n",
      "2022-11-08 13:46:13,327 INFO     Training average loss at step 280800: 0.340443\n",
      "2022-11-08 13:46:22,857 INFO     Training average positive_sample_loss at step 280900: 0.432982\n",
      "2022-11-08 13:46:22,857 INFO     Training average negative_sample_loss at step 280900: 0.244207\n",
      "2022-11-08 13:46:22,857 INFO     Training average loss at step 280900: 0.338595\n",
      "2022-11-08 13:46:32,488 INFO     Training average positive_sample_loss at step 281000: 0.434310\n",
      "2022-11-08 13:46:32,488 INFO     Training average negative_sample_loss at step 281000: 0.244121\n",
      "2022-11-08 13:46:32,489 INFO     Training average loss at step 281000: 0.339215\n",
      "2022-11-08 13:46:42,273 INFO     Training average positive_sample_loss at step 281100: 0.440632\n",
      "2022-11-08 13:46:42,273 INFO     Training average negative_sample_loss at step 281100: 0.241433\n",
      "2022-11-08 13:46:42,273 INFO     Training average loss at step 281100: 0.341033\n",
      "2022-11-08 13:46:51,403 INFO     Training average positive_sample_loss at step 281200: 0.433073\n",
      "2022-11-08 13:46:51,403 INFO     Training average negative_sample_loss at step 281200: 0.248120\n",
      "2022-11-08 13:46:51,403 INFO     Training average loss at step 281200: 0.340596\n",
      "2022-11-08 13:47:01,188 INFO     Training average positive_sample_loss at step 281300: 0.434269\n",
      "2022-11-08 13:47:01,188 INFO     Training average negative_sample_loss at step 281300: 0.244692\n",
      "2022-11-08 13:47:01,188 INFO     Training average loss at step 281300: 0.339481\n",
      "2022-11-08 13:47:10,765 INFO     Training average positive_sample_loss at step 281400: 0.460245\n",
      "2022-11-08 13:47:10,766 INFO     Training average negative_sample_loss at step 281400: 0.243490\n",
      "2022-11-08 13:47:10,766 INFO     Training average loss at step 281400: 0.351867\n",
      "2022-11-08 13:47:20,296 INFO     Training average positive_sample_loss at step 281500: 0.432218\n",
      "2022-11-08 13:47:20,296 INFO     Training average negative_sample_loss at step 281500: 0.243644\n",
      "2022-11-08 13:47:20,296 INFO     Training average loss at step 281500: 0.337931\n",
      "2022-11-08 13:47:29,825 INFO     Training average positive_sample_loss at step 281600: 0.449457\n",
      "2022-11-08 13:47:29,825 INFO     Training average negative_sample_loss at step 281600: 0.246665\n",
      "2022-11-08 13:47:29,825 INFO     Training average loss at step 281600: 0.348061\n",
      "2022-11-08 13:47:39,357 INFO     Training average positive_sample_loss at step 281700: 0.423292\n",
      "2022-11-08 13:47:39,357 INFO     Training average negative_sample_loss at step 281700: 0.253436\n",
      "2022-11-08 13:47:39,357 INFO     Training average loss at step 281700: 0.338364\n",
      "2022-11-08 13:47:48,885 INFO     Training average positive_sample_loss at step 281800: 0.443372\n",
      "2022-11-08 13:47:48,885 INFO     Training average negative_sample_loss at step 281800: 0.241773\n",
      "2022-11-08 13:47:48,885 INFO     Training average loss at step 281800: 0.342572\n",
      "2022-11-08 13:47:58,415 INFO     Training average positive_sample_loss at step 281900: 0.438144\n",
      "2022-11-08 13:47:58,415 INFO     Training average negative_sample_loss at step 281900: 0.239200\n",
      "2022-11-08 13:47:58,415 INFO     Training average loss at step 281900: 0.338672\n",
      "2022-11-08 13:48:07,947 INFO     Training average positive_sample_loss at step 282000: 0.427329\n",
      "2022-11-08 13:48:07,947 INFO     Training average negative_sample_loss at step 282000: 0.241393\n",
      "2022-11-08 13:48:07,947 INFO     Training average loss at step 282000: 0.334361\n",
      "2022-11-08 13:48:17,473 INFO     Training average positive_sample_loss at step 282100: 0.436729\n",
      "2022-11-08 13:48:17,473 INFO     Training average negative_sample_loss at step 282100: 0.243003\n",
      "2022-11-08 13:48:17,473 INFO     Training average loss at step 282100: 0.339866\n",
      "2022-11-08 13:48:27,004 INFO     Training average positive_sample_loss at step 282200: 0.418179\n",
      "2022-11-08 13:48:27,004 INFO     Training average negative_sample_loss at step 282200: 0.243887\n",
      "2022-11-08 13:48:27,004 INFO     Training average loss at step 282200: 0.331033\n",
      "2022-11-08 13:48:36,533 INFO     Training average positive_sample_loss at step 282300: 0.436793\n",
      "2022-11-08 13:48:36,533 INFO     Training average negative_sample_loss at step 282300: 0.244430\n",
      "2022-11-08 13:48:36,533 INFO     Training average loss at step 282300: 0.340611\n",
      "2022-11-08 13:48:46,060 INFO     Training average positive_sample_loss at step 282400: 0.438461\n",
      "2022-11-08 13:48:46,060 INFO     Training average negative_sample_loss at step 282400: 0.240136\n",
      "2022-11-08 13:48:46,060 INFO     Training average loss at step 282400: 0.339299\n",
      "2022-11-08 13:48:55,591 INFO     Training average positive_sample_loss at step 282500: 0.447566\n",
      "2022-11-08 13:48:55,592 INFO     Training average negative_sample_loss at step 282500: 0.240440\n",
      "2022-11-08 13:48:55,592 INFO     Training average loss at step 282500: 0.344003\n",
      "2022-11-08 13:49:05,119 INFO     Training average positive_sample_loss at step 282600: 0.428432\n",
      "2022-11-08 13:49:05,120 INFO     Training average negative_sample_loss at step 282600: 0.246313\n",
      "2022-11-08 13:49:05,120 INFO     Training average loss at step 282600: 0.337373\n",
      "2022-11-08 13:49:14,650 INFO     Training average positive_sample_loss at step 282700: 0.436266\n",
      "2022-11-08 13:49:14,650 INFO     Training average negative_sample_loss at step 282700: 0.237854\n",
      "2022-11-08 13:49:14,650 INFO     Training average loss at step 282700: 0.337060\n",
      "2022-11-08 13:49:24,180 INFO     Training average positive_sample_loss at step 282800: 0.423173\n",
      "2022-11-08 13:49:24,180 INFO     Training average negative_sample_loss at step 282800: 0.246864\n",
      "2022-11-08 13:49:24,180 INFO     Training average loss at step 282800: 0.335018\n",
      "2022-11-08 13:49:33,705 INFO     Training average positive_sample_loss at step 282900: 0.416153\n",
      "2022-11-08 13:49:33,705 INFO     Training average negative_sample_loss at step 282900: 0.243317\n",
      "2022-11-08 13:49:33,705 INFO     Training average loss at step 282900: 0.329735\n",
      "2022-11-08 13:49:43,234 INFO     Training average positive_sample_loss at step 283000: 0.437864\n",
      "2022-11-08 13:49:43,234 INFO     Training average negative_sample_loss at step 283000: 0.240449\n",
      "2022-11-08 13:49:43,234 INFO     Training average loss at step 283000: 0.339157\n",
      "2022-11-08 13:49:52,764 INFO     Training average positive_sample_loss at step 283100: 0.450409\n",
      "2022-11-08 13:49:52,764 INFO     Training average negative_sample_loss at step 283100: 0.242609\n",
      "2022-11-08 13:49:52,764 INFO     Training average loss at step 283100: 0.346509\n",
      "2022-11-08 13:50:02,294 INFO     Training average positive_sample_loss at step 283200: 0.438644\n",
      "2022-11-08 13:50:02,295 INFO     Training average negative_sample_loss at step 283200: 0.239516\n",
      "2022-11-08 13:50:02,295 INFO     Training average loss at step 283200: 0.339080\n",
      "2022-11-08 13:50:11,824 INFO     Training average positive_sample_loss at step 283300: 0.446913\n",
      "2022-11-08 13:50:11,824 INFO     Training average negative_sample_loss at step 283300: 0.240506\n",
      "2022-11-08 13:50:11,824 INFO     Training average loss at step 283300: 0.343709\n",
      "2022-11-08 13:50:21,356 INFO     Training average positive_sample_loss at step 283400: 0.437291\n",
      "2022-11-08 13:50:21,356 INFO     Training average negative_sample_loss at step 283400: 0.243579\n",
      "2022-11-08 13:50:21,356 INFO     Training average loss at step 283400: 0.340435\n",
      "2022-11-08 13:50:30,884 INFO     Training average positive_sample_loss at step 283500: 0.439832\n",
      "2022-11-08 13:50:30,884 INFO     Training average negative_sample_loss at step 283500: 0.240729\n",
      "2022-11-08 13:50:30,884 INFO     Training average loss at step 283500: 0.340281\n",
      "2022-11-08 13:50:40,413 INFO     Training average positive_sample_loss at step 283600: 0.439045\n",
      "2022-11-08 13:50:40,413 INFO     Training average negative_sample_loss at step 283600: 0.238975\n",
      "2022-11-08 13:50:40,413 INFO     Training average loss at step 283600: 0.339010\n",
      "2022-11-08 13:50:49,941 INFO     Training average positive_sample_loss at step 283700: 0.445866\n",
      "2022-11-08 13:50:49,941 INFO     Training average negative_sample_loss at step 283700: 0.241624\n",
      "2022-11-08 13:50:49,941 INFO     Training average loss at step 283700: 0.343745\n",
      "2022-11-08 13:50:59,470 INFO     Training average positive_sample_loss at step 283800: 0.423011\n",
      "2022-11-08 13:50:59,470 INFO     Training average negative_sample_loss at step 283800: 0.244165\n",
      "2022-11-08 13:50:59,470 INFO     Training average loss at step 283800: 0.333588\n",
      "2022-11-08 13:51:08,999 INFO     Training average positive_sample_loss at step 283900: 0.427295\n",
      "2022-11-08 13:51:08,999 INFO     Training average negative_sample_loss at step 283900: 0.247922\n",
      "2022-11-08 13:51:08,999 INFO     Training average loss at step 283900: 0.337608\n",
      "2022-11-08 13:51:18,529 INFO     Training average positive_sample_loss at step 284000: 0.425062\n",
      "2022-11-08 13:51:18,529 INFO     Training average negative_sample_loss at step 284000: 0.242985\n",
      "2022-11-08 13:51:18,529 INFO     Training average loss at step 284000: 0.334023\n",
      "2022-11-08 13:51:28,056 INFO     Training average positive_sample_loss at step 284100: 0.433408\n",
      "2022-11-08 13:51:28,056 INFO     Training average negative_sample_loss at step 284100: 0.244114\n",
      "2022-11-08 13:51:28,056 INFO     Training average loss at step 284100: 0.338761\n",
      "2022-11-08 13:51:37,589 INFO     Training average positive_sample_loss at step 284200: 0.419385\n",
      "2022-11-08 13:51:37,589 INFO     Training average negative_sample_loss at step 284200: 0.246298\n",
      "2022-11-08 13:51:37,589 INFO     Training average loss at step 284200: 0.332842\n",
      "2022-11-08 13:51:47,121 INFO     Training average positive_sample_loss at step 284300: 0.421498\n",
      "2022-11-08 13:51:47,121 INFO     Training average negative_sample_loss at step 284300: 0.242814\n",
      "2022-11-08 13:51:47,121 INFO     Training average loss at step 284300: 0.332156\n",
      "2022-11-08 13:51:56,651 INFO     Training average positive_sample_loss at step 284400: 0.419947\n",
      "2022-11-08 13:51:56,651 INFO     Training average negative_sample_loss at step 284400: 0.247823\n",
      "2022-11-08 13:51:56,651 INFO     Training average loss at step 284400: 0.333885\n",
      "2022-11-08 13:52:06,182 INFO     Training average positive_sample_loss at step 284500: 0.423400\n",
      "2022-11-08 13:52:06,182 INFO     Training average negative_sample_loss at step 284500: 0.241682\n",
      "2022-11-08 13:52:06,182 INFO     Training average loss at step 284500: 0.332541\n",
      "2022-11-08 13:52:15,707 INFO     Training average positive_sample_loss at step 284600: 0.435307\n",
      "2022-11-08 13:52:15,707 INFO     Training average negative_sample_loss at step 284600: 0.244780\n",
      "2022-11-08 13:52:15,707 INFO     Training average loss at step 284600: 0.340044\n",
      "2022-11-08 13:52:25,238 INFO     Training average positive_sample_loss at step 284700: 0.415072\n",
      "2022-11-08 13:52:25,239 INFO     Training average negative_sample_loss at step 284700: 0.243324\n",
      "2022-11-08 13:52:25,239 INFO     Training average loss at step 284700: 0.329198\n",
      "2022-11-08 13:52:34,766 INFO     Training average positive_sample_loss at step 284800: 0.430235\n",
      "2022-11-08 13:52:34,766 INFO     Training average negative_sample_loss at step 284800: 0.243486\n",
      "2022-11-08 13:52:34,766 INFO     Training average loss at step 284800: 0.336860\n",
      "2022-11-08 13:52:44,680 INFO     Training average positive_sample_loss at step 284900: 0.423367\n",
      "2022-11-08 13:52:44,680 INFO     Training average negative_sample_loss at step 284900: 0.239649\n",
      "2022-11-08 13:52:44,681 INFO     Training average loss at step 284900: 0.331508\n",
      "2022-11-08 13:52:54,876 INFO     Training average positive_sample_loss at step 285000: 0.432244\n",
      "2022-11-08 13:52:54,877 INFO     Training average negative_sample_loss at step 285000: 0.241855\n",
      "2022-11-08 13:52:54,877 INFO     Training average loss at step 285000: 0.337049\n",
      "2022-11-08 13:53:04,405 INFO     Training average positive_sample_loss at step 285100: 0.430170\n",
      "2022-11-08 13:53:04,405 INFO     Training average negative_sample_loss at step 285100: 0.240133\n",
      "2022-11-08 13:53:04,405 INFO     Training average loss at step 285100: 0.335151\n",
      "2022-11-08 13:53:13,932 INFO     Training average positive_sample_loss at step 285200: 0.417616\n",
      "2022-11-08 13:53:13,932 INFO     Training average negative_sample_loss at step 285200: 0.246757\n",
      "2022-11-08 13:53:13,932 INFO     Training average loss at step 285200: 0.332187\n",
      "2022-11-08 13:53:24,527 INFO     Training average positive_sample_loss at step 285300: 0.419141\n",
      "2022-11-08 13:53:24,528 INFO     Training average negative_sample_loss at step 285300: 0.247411\n",
      "2022-11-08 13:53:24,528 INFO     Training average loss at step 285300: 0.333276\n",
      "2022-11-08 13:53:34,057 INFO     Training average positive_sample_loss at step 285400: 0.431302\n",
      "2022-11-08 13:53:34,057 INFO     Training average negative_sample_loss at step 285400: 0.241719\n",
      "2022-11-08 13:53:34,057 INFO     Training average loss at step 285400: 0.336511\n",
      "2022-11-08 13:53:43,589 INFO     Training average positive_sample_loss at step 285500: 0.399426\n",
      "2022-11-08 13:53:43,589 INFO     Training average negative_sample_loss at step 285500: 0.241236\n",
      "2022-11-08 13:53:43,589 INFO     Training average loss at step 285500: 0.320331\n",
      "2022-11-08 13:53:53,119 INFO     Training average positive_sample_loss at step 285600: 0.432050\n",
      "2022-11-08 13:53:53,119 INFO     Training average negative_sample_loss at step 285600: 0.242941\n",
      "2022-11-08 13:53:53,119 INFO     Training average loss at step 285600: 0.337496\n",
      "2022-11-08 13:54:02,652 INFO     Training average positive_sample_loss at step 285700: 0.431840\n",
      "2022-11-08 13:54:02,652 INFO     Training average negative_sample_loss at step 285700: 0.244673\n",
      "2022-11-08 13:54:02,652 INFO     Training average loss at step 285700: 0.338257\n",
      "2022-11-08 13:54:12,179 INFO     Training average positive_sample_loss at step 285800: 0.428008\n",
      "2022-11-08 13:54:12,179 INFO     Training average negative_sample_loss at step 285800: 0.239354\n",
      "2022-11-08 13:54:12,179 INFO     Training average loss at step 285800: 0.333681\n",
      "2022-11-08 13:54:21,705 INFO     Training average positive_sample_loss at step 285900: 0.420441\n",
      "2022-11-08 13:54:21,705 INFO     Training average negative_sample_loss at step 285900: 0.236094\n",
      "2022-11-08 13:54:21,705 INFO     Training average loss at step 285900: 0.328267\n",
      "2022-11-08 13:54:31,234 INFO     Training average positive_sample_loss at step 286000: 0.437259\n",
      "2022-11-08 13:54:31,235 INFO     Training average negative_sample_loss at step 286000: 0.239794\n",
      "2022-11-08 13:54:31,235 INFO     Training average loss at step 286000: 0.338526\n",
      "2022-11-08 13:54:40,764 INFO     Training average positive_sample_loss at step 286100: 0.416505\n",
      "2022-11-08 13:54:40,764 INFO     Training average negative_sample_loss at step 286100: 0.241186\n",
      "2022-11-08 13:54:40,764 INFO     Training average loss at step 286100: 0.328846\n",
      "2022-11-08 13:54:49,624 INFO     Training average positive_sample_loss at step 286200: 0.406080\n",
      "2022-11-08 13:54:49,625 INFO     Training average negative_sample_loss at step 286200: 0.246188\n",
      "2022-11-08 13:54:49,625 INFO     Training average loss at step 286200: 0.326134\n",
      "2022-11-08 13:54:59,149 INFO     Training average positive_sample_loss at step 286300: 0.430430\n",
      "2022-11-08 13:54:59,149 INFO     Training average negative_sample_loss at step 286300: 0.243216\n",
      "2022-11-08 13:54:59,149 INFO     Training average loss at step 286300: 0.336823\n",
      "2022-11-08 13:55:08,678 INFO     Training average positive_sample_loss at step 286400: 0.438161\n",
      "2022-11-08 13:55:08,678 INFO     Training average negative_sample_loss at step 286400: 0.238384\n",
      "2022-11-08 13:55:08,678 INFO     Training average loss at step 286400: 0.338273\n",
      "2022-11-08 13:55:18,209 INFO     Training average positive_sample_loss at step 286500: 0.443828\n",
      "2022-11-08 13:55:18,209 INFO     Training average negative_sample_loss at step 286500: 0.241439\n",
      "2022-11-08 13:55:18,209 INFO     Training average loss at step 286500: 0.342634\n",
      "2022-11-08 13:55:27,737 INFO     Training average positive_sample_loss at step 286600: 0.422149\n",
      "2022-11-08 13:55:27,738 INFO     Training average negative_sample_loss at step 286600: 0.239393\n",
      "2022-11-08 13:55:27,738 INFO     Training average loss at step 286600: 0.330771\n",
      "2022-11-08 13:55:36,595 INFO     Training average positive_sample_loss at step 286700: 0.425995\n",
      "2022-11-08 13:55:36,595 INFO     Training average negative_sample_loss at step 286700: 0.242700\n",
      "2022-11-08 13:55:36,595 INFO     Training average loss at step 286700: 0.334348\n",
      "2022-11-08 13:55:46,109 INFO     Training average positive_sample_loss at step 286800: 0.411400\n",
      "2022-11-08 13:55:46,109 INFO     Training average negative_sample_loss at step 286800: 0.239624\n",
      "2022-11-08 13:55:46,109 INFO     Training average loss at step 286800: 0.325512\n",
      "2022-11-08 13:55:55,637 INFO     Training average positive_sample_loss at step 286900: 0.439218\n",
      "2022-11-08 13:55:55,637 INFO     Training average negative_sample_loss at step 286900: 0.236987\n",
      "2022-11-08 13:55:55,637 INFO     Training average loss at step 286900: 0.338103\n",
      "2022-11-08 13:56:05,167 INFO     Training average positive_sample_loss at step 287000: 0.418413\n",
      "2022-11-08 13:56:05,167 INFO     Training average negative_sample_loss at step 287000: 0.240921\n",
      "2022-11-08 13:56:05,167 INFO     Training average loss at step 287000: 0.329667\n",
      "2022-11-08 13:56:14,696 INFO     Training average positive_sample_loss at step 287100: 0.429141\n",
      "2022-11-08 13:56:14,696 INFO     Training average negative_sample_loss at step 287100: 0.239939\n",
      "2022-11-08 13:56:14,696 INFO     Training average loss at step 287100: 0.334540\n",
      "2022-11-08 13:56:24,223 INFO     Training average positive_sample_loss at step 287200: 0.424040\n",
      "2022-11-08 13:56:24,223 INFO     Training average negative_sample_loss at step 287200: 0.238160\n",
      "2022-11-08 13:56:24,224 INFO     Training average loss at step 287200: 0.331100\n",
      "2022-11-08 13:56:33,746 INFO     Training average positive_sample_loss at step 287300: 0.427643\n",
      "2022-11-08 13:56:33,746 INFO     Training average negative_sample_loss at step 287300: 0.241995\n",
      "2022-11-08 13:56:33,747 INFO     Training average loss at step 287300: 0.334819\n",
      "2022-11-08 13:56:43,276 INFO     Training average positive_sample_loss at step 287400: 0.424719\n",
      "2022-11-08 13:56:43,276 INFO     Training average negative_sample_loss at step 287400: 0.238836\n",
      "2022-11-08 13:56:43,276 INFO     Training average loss at step 287400: 0.331777\n",
      "2022-11-08 13:56:52,803 INFO     Training average positive_sample_loss at step 287500: 0.422257\n",
      "2022-11-08 13:56:52,803 INFO     Training average negative_sample_loss at step 287500: 0.246747\n",
      "2022-11-08 13:56:52,803 INFO     Training average loss at step 287500: 0.334502\n",
      "2022-11-08 13:57:02,333 INFO     Training average positive_sample_loss at step 287600: 0.428305\n",
      "2022-11-08 13:57:02,333 INFO     Training average negative_sample_loss at step 287600: 0.239913\n",
      "2022-11-08 13:57:02,333 INFO     Training average loss at step 287600: 0.334109\n",
      "2022-11-08 13:57:11,862 INFO     Training average positive_sample_loss at step 287700: 0.426447\n",
      "2022-11-08 13:57:11,862 INFO     Training average negative_sample_loss at step 287700: 0.240075\n",
      "2022-11-08 13:57:11,862 INFO     Training average loss at step 287700: 0.333261\n",
      "2022-11-08 13:57:21,389 INFO     Training average positive_sample_loss at step 287800: 0.422273\n",
      "2022-11-08 13:57:21,389 INFO     Training average negative_sample_loss at step 287800: 0.235712\n",
      "2022-11-08 13:57:21,389 INFO     Training average loss at step 287800: 0.328992\n",
      "2022-11-08 13:57:30,916 INFO     Training average positive_sample_loss at step 287900: 0.414644\n",
      "2022-11-08 13:57:30,917 INFO     Training average negative_sample_loss at step 287900: 0.242770\n",
      "2022-11-08 13:57:30,917 INFO     Training average loss at step 287900: 0.328707\n",
      "2022-11-08 13:57:40,445 INFO     Training average positive_sample_loss at step 288000: 0.416846\n",
      "2022-11-08 13:57:40,445 INFO     Training average negative_sample_loss at step 288000: 0.242539\n",
      "2022-11-08 13:57:40,445 INFO     Training average loss at step 288000: 0.329692\n",
      "2022-11-08 13:57:49,976 INFO     Training average positive_sample_loss at step 288100: 0.427284\n",
      "2022-11-08 13:57:49,976 INFO     Training average negative_sample_loss at step 288100: 0.240613\n",
      "2022-11-08 13:57:49,976 INFO     Training average loss at step 288100: 0.333949\n",
      "2022-11-08 13:57:59,504 INFO     Training average positive_sample_loss at step 288200: 0.429087\n",
      "2022-11-08 13:57:59,504 INFO     Training average negative_sample_loss at step 288200: 0.239462\n",
      "2022-11-08 13:57:59,504 INFO     Training average loss at step 288200: 0.334275\n",
      "2022-11-08 13:58:09,033 INFO     Training average positive_sample_loss at step 288300: 0.446675\n",
      "2022-11-08 13:58:09,033 INFO     Training average negative_sample_loss at step 288300: 0.241530\n",
      "2022-11-08 13:58:09,033 INFO     Training average loss at step 288300: 0.344103\n",
      "2022-11-08 13:58:18,559 INFO     Training average positive_sample_loss at step 288400: 0.423163\n",
      "2022-11-08 13:58:18,559 INFO     Training average negative_sample_loss at step 288400: 0.243242\n",
      "2022-11-08 13:58:18,559 INFO     Training average loss at step 288400: 0.333203\n",
      "2022-11-08 13:58:28,090 INFO     Training average positive_sample_loss at step 288500: 0.428603\n",
      "2022-11-08 13:58:28,091 INFO     Training average negative_sample_loss at step 288500: 0.238846\n",
      "2022-11-08 13:58:28,091 INFO     Training average loss at step 288500: 0.333725\n",
      "2022-11-08 13:58:37,622 INFO     Training average positive_sample_loss at step 288600: 0.410487\n",
      "2022-11-08 13:58:37,622 INFO     Training average negative_sample_loss at step 288600: 0.241544\n",
      "2022-11-08 13:58:37,622 INFO     Training average loss at step 288600: 0.326015\n",
      "2022-11-08 13:58:47,151 INFO     Training average positive_sample_loss at step 288700: 0.425121\n",
      "2022-11-08 13:58:47,151 INFO     Training average negative_sample_loss at step 288700: 0.241679\n",
      "2022-11-08 13:58:47,151 INFO     Training average loss at step 288700: 0.333400\n",
      "2022-11-08 13:58:56,678 INFO     Training average positive_sample_loss at step 288800: 0.424396\n",
      "2022-11-08 13:58:56,678 INFO     Training average negative_sample_loss at step 288800: 0.244232\n",
      "2022-11-08 13:58:56,678 INFO     Training average loss at step 288800: 0.334314\n",
      "2022-11-08 13:59:06,205 INFO     Training average positive_sample_loss at step 288900: 0.436141\n",
      "2022-11-08 13:59:06,205 INFO     Training average negative_sample_loss at step 288900: 0.238593\n",
      "2022-11-08 13:59:06,205 INFO     Training average loss at step 288900: 0.337367\n",
      "2022-11-08 13:59:15,733 INFO     Training average positive_sample_loss at step 289000: 0.421261\n",
      "2022-11-08 13:59:15,733 INFO     Training average negative_sample_loss at step 289000: 0.241289\n",
      "2022-11-08 13:59:15,733 INFO     Training average loss at step 289000: 0.331275\n",
      "2022-11-08 13:59:25,262 INFO     Training average positive_sample_loss at step 289100: 0.436772\n",
      "2022-11-08 13:59:25,262 INFO     Training average negative_sample_loss at step 289100: 0.245377\n",
      "2022-11-08 13:59:25,262 INFO     Training average loss at step 289100: 0.341074\n",
      "2022-11-08 13:59:34,790 INFO     Training average positive_sample_loss at step 289200: 0.414837\n",
      "2022-11-08 13:59:34,790 INFO     Training average negative_sample_loss at step 289200: 0.242359\n",
      "2022-11-08 13:59:34,790 INFO     Training average loss at step 289200: 0.328598\n",
      "2022-11-08 13:59:44,322 INFO     Training average positive_sample_loss at step 289300: 0.433732\n",
      "2022-11-08 13:59:44,322 INFO     Training average negative_sample_loss at step 289300: 0.235284\n",
      "2022-11-08 13:59:44,322 INFO     Training average loss at step 289300: 0.334508\n",
      "2022-11-08 13:59:53,849 INFO     Training average positive_sample_loss at step 289400: 0.427762\n",
      "2022-11-08 13:59:53,849 INFO     Training average negative_sample_loss at step 289400: 0.243183\n",
      "2022-11-08 13:59:53,849 INFO     Training average loss at step 289400: 0.335473\n",
      "2022-11-08 14:00:03,791 INFO     Training average positive_sample_loss at step 289500: 0.417692\n",
      "2022-11-08 14:00:03,791 INFO     Training average negative_sample_loss at step 289500: 0.240711\n",
      "2022-11-08 14:00:03,791 INFO     Training average loss at step 289500: 0.329202\n",
      "2022-11-08 14:00:13,601 INFO     Training average positive_sample_loss at step 289600: 0.415693\n",
      "2022-11-08 14:00:13,601 INFO     Training average negative_sample_loss at step 289600: 0.244157\n",
      "2022-11-08 14:00:13,601 INFO     Training average loss at step 289600: 0.329925\n",
      "2022-11-08 14:00:23,578 INFO     Training average positive_sample_loss at step 289700: 0.430444\n",
      "2022-11-08 14:00:23,578 INFO     Training average negative_sample_loss at step 289700: 0.238427\n",
      "2022-11-08 14:00:23,578 INFO     Training average loss at step 289700: 0.334436\n",
      "2022-11-08 14:00:33,105 INFO     Training average positive_sample_loss at step 289800: 0.415091\n",
      "2022-11-08 14:00:33,105 INFO     Training average negative_sample_loss at step 289800: 0.238129\n",
      "2022-11-08 14:00:33,105 INFO     Training average loss at step 289800: 0.326610\n",
      "2022-11-08 14:00:43,748 INFO     Training average positive_sample_loss at step 289900: 0.411248\n",
      "2022-11-08 14:00:43,749 INFO     Training average negative_sample_loss at step 289900: 0.240394\n",
      "2022-11-08 14:00:43,749 INFO     Training average loss at step 289900: 0.325821\n",
      "2022-11-08 14:00:55,895 INFO     Training average positive_sample_loss at step 290000: 0.422879\n",
      "2022-11-08 14:00:55,895 INFO     Training average negative_sample_loss at step 290000: 0.237151\n",
      "2022-11-08 14:00:55,895 INFO     Training average loss at step 290000: 0.330015\n",
      "2022-11-08 14:01:05,425 INFO     Training average positive_sample_loss at step 290100: 0.420453\n",
      "2022-11-08 14:01:05,425 INFO     Training average negative_sample_loss at step 290100: 0.236999\n",
      "2022-11-08 14:01:05,425 INFO     Training average loss at step 290100: 0.328726\n",
      "2022-11-08 14:01:14,956 INFO     Training average positive_sample_loss at step 290200: 0.427768\n",
      "2022-11-08 14:01:14,956 INFO     Training average negative_sample_loss at step 290200: 0.241475\n",
      "2022-11-08 14:01:14,956 INFO     Training average loss at step 290200: 0.334622\n",
      "2022-11-08 14:01:24,483 INFO     Training average positive_sample_loss at step 290300: 0.418911\n",
      "2022-11-08 14:01:24,483 INFO     Training average negative_sample_loss at step 290300: 0.240603\n",
      "2022-11-08 14:01:24,483 INFO     Training average loss at step 290300: 0.329757\n",
      "2022-11-08 14:01:34,011 INFO     Training average positive_sample_loss at step 290400: 0.407230\n",
      "2022-11-08 14:01:34,011 INFO     Training average negative_sample_loss at step 290400: 0.237007\n",
      "2022-11-08 14:01:34,011 INFO     Training average loss at step 290400: 0.322118\n",
      "2022-11-08 14:01:43,540 INFO     Training average positive_sample_loss at step 290500: 0.413407\n",
      "2022-11-08 14:01:43,540 INFO     Training average negative_sample_loss at step 290500: 0.241608\n",
      "2022-11-08 14:01:43,540 INFO     Training average loss at step 290500: 0.327508\n",
      "2022-11-08 14:01:53,069 INFO     Training average positive_sample_loss at step 290600: 0.426130\n",
      "2022-11-08 14:01:53,070 INFO     Training average negative_sample_loss at step 290600: 0.243909\n",
      "2022-11-08 14:01:53,070 INFO     Training average loss at step 290600: 0.335020\n",
      "2022-11-08 14:02:02,599 INFO     Training average positive_sample_loss at step 290700: 0.430945\n",
      "2022-11-08 14:02:02,599 INFO     Training average negative_sample_loss at step 290700: 0.234052\n",
      "2022-11-08 14:02:02,599 INFO     Training average loss at step 290700: 0.332499\n",
      "2022-11-08 14:02:12,127 INFO     Training average positive_sample_loss at step 290800: 0.426709\n",
      "2022-11-08 14:02:12,128 INFO     Training average negative_sample_loss at step 290800: 0.238529\n",
      "2022-11-08 14:02:12,128 INFO     Training average loss at step 290800: 0.332619\n",
      "2022-11-08 14:02:21,652 INFO     Training average positive_sample_loss at step 290900: 0.418543\n",
      "2022-11-08 14:02:21,652 INFO     Training average negative_sample_loss at step 290900: 0.237323\n",
      "2022-11-08 14:02:21,652 INFO     Training average loss at step 290900: 0.327933\n",
      "2022-11-08 14:02:31,178 INFO     Training average positive_sample_loss at step 291000: 0.419368\n",
      "2022-11-08 14:02:31,178 INFO     Training average negative_sample_loss at step 291000: 0.238297\n",
      "2022-11-08 14:02:31,178 INFO     Training average loss at step 291000: 0.328833\n",
      "2022-11-08 14:02:40,707 INFO     Training average positive_sample_loss at step 291100: 0.427737\n",
      "2022-11-08 14:02:40,707 INFO     Training average negative_sample_loss at step 291100: 0.236181\n",
      "2022-11-08 14:02:40,707 INFO     Training average loss at step 291100: 0.331959\n",
      "2022-11-08 14:02:50,235 INFO     Training average positive_sample_loss at step 291200: 0.434421\n",
      "2022-11-08 14:02:50,235 INFO     Training average negative_sample_loss at step 291200: 0.242169\n",
      "2022-11-08 14:02:50,235 INFO     Training average loss at step 291200: 0.338295\n",
      "2022-11-08 14:02:59,763 INFO     Training average positive_sample_loss at step 291300: 0.429673\n",
      "2022-11-08 14:02:59,763 INFO     Training average negative_sample_loss at step 291300: 0.238993\n",
      "2022-11-08 14:02:59,764 INFO     Training average loss at step 291300: 0.334333\n",
      "2022-11-08 14:03:09,291 INFO     Training average positive_sample_loss at step 291400: 0.419335\n",
      "2022-11-08 14:03:09,291 INFO     Training average negative_sample_loss at step 291400: 0.244229\n",
      "2022-11-08 14:03:09,292 INFO     Training average loss at step 291400: 0.331782\n",
      "2022-11-08 14:03:18,817 INFO     Training average positive_sample_loss at step 291500: 0.424286\n",
      "2022-11-08 14:03:18,817 INFO     Training average negative_sample_loss at step 291500: 0.235568\n",
      "2022-11-08 14:03:18,817 INFO     Training average loss at step 291500: 0.329927\n",
      "2022-11-08 14:03:28,348 INFO     Training average positive_sample_loss at step 291600: 0.416664\n",
      "2022-11-08 14:03:28,348 INFO     Training average negative_sample_loss at step 291600: 0.233897\n",
      "2022-11-08 14:03:28,348 INFO     Training average loss at step 291600: 0.325281\n",
      "2022-11-08 14:03:37,210 INFO     Training average positive_sample_loss at step 291700: 0.429611\n",
      "2022-11-08 14:03:37,210 INFO     Training average negative_sample_loss at step 291700: 0.240831\n",
      "2022-11-08 14:03:37,210 INFO     Training average loss at step 291700: 0.335221\n",
      "2022-11-08 14:03:46,739 INFO     Training average positive_sample_loss at step 291800: 0.432472\n",
      "2022-11-08 14:03:46,740 INFO     Training average negative_sample_loss at step 291800: 0.234741\n",
      "2022-11-08 14:03:46,740 INFO     Training average loss at step 291800: 0.333606\n",
      "2022-11-08 14:03:56,274 INFO     Training average positive_sample_loss at step 291900: 0.438871\n",
      "2022-11-08 14:03:56,274 INFO     Training average negative_sample_loss at step 291900: 0.232311\n",
      "2022-11-08 14:03:56,274 INFO     Training average loss at step 291900: 0.335591\n",
      "2022-11-08 14:04:05,810 INFO     Training average positive_sample_loss at step 292000: 0.430534\n",
      "2022-11-08 14:04:05,810 INFO     Training average negative_sample_loss at step 292000: 0.239420\n",
      "2022-11-08 14:04:05,811 INFO     Training average loss at step 292000: 0.334977\n",
      "2022-11-08 14:04:15,277 INFO     Training average positive_sample_loss at step 292100: 0.441822\n",
      "2022-11-08 14:04:15,277 INFO     Training average negative_sample_loss at step 292100: 0.234103\n",
      "2022-11-08 14:04:15,277 INFO     Training average loss at step 292100: 0.337962\n",
      "2022-11-08 14:04:24,210 INFO     Training average positive_sample_loss at step 292200: 0.416471\n",
      "2022-11-08 14:04:24,210 INFO     Training average negative_sample_loss at step 292200: 0.238207\n",
      "2022-11-08 14:04:24,210 INFO     Training average loss at step 292200: 0.327339\n",
      "2022-11-08 14:04:33,740 INFO     Training average positive_sample_loss at step 292300: 0.417118\n",
      "2022-11-08 14:04:33,740 INFO     Training average negative_sample_loss at step 292300: 0.237764\n",
      "2022-11-08 14:04:33,740 INFO     Training average loss at step 292300: 0.327441\n",
      "2022-11-08 14:04:43,269 INFO     Training average positive_sample_loss at step 292400: 0.420237\n",
      "2022-11-08 14:04:43,269 INFO     Training average negative_sample_loss at step 292400: 0.238982\n",
      "2022-11-08 14:04:43,269 INFO     Training average loss at step 292400: 0.329610\n",
      "2022-11-08 14:04:52,805 INFO     Training average positive_sample_loss at step 292500: 0.436296\n",
      "2022-11-08 14:04:52,806 INFO     Training average negative_sample_loss at step 292500: 0.239906\n",
      "2022-11-08 14:04:52,806 INFO     Training average loss at step 292500: 0.338101\n",
      "2022-11-08 14:05:02,336 INFO     Training average positive_sample_loss at step 292600: 0.430866\n",
      "2022-11-08 14:05:02,336 INFO     Training average negative_sample_loss at step 292600: 0.238707\n",
      "2022-11-08 14:05:02,336 INFO     Training average loss at step 292600: 0.334786\n",
      "2022-11-08 14:05:11,864 INFO     Training average positive_sample_loss at step 292700: 0.433288\n",
      "2022-11-08 14:05:11,864 INFO     Training average negative_sample_loss at step 292700: 0.237882\n",
      "2022-11-08 14:05:11,865 INFO     Training average loss at step 292700: 0.335585\n",
      "2022-11-08 14:05:21,397 INFO     Training average positive_sample_loss at step 292800: 0.420488\n",
      "2022-11-08 14:05:21,397 INFO     Training average negative_sample_loss at step 292800: 0.229211\n",
      "2022-11-08 14:05:21,397 INFO     Training average loss at step 292800: 0.324850\n",
      "2022-11-08 14:05:30,927 INFO     Training average positive_sample_loss at step 292900: 0.431590\n",
      "2022-11-08 14:05:30,927 INFO     Training average negative_sample_loss at step 292900: 0.243834\n",
      "2022-11-08 14:05:30,927 INFO     Training average loss at step 292900: 0.337712\n",
      "2022-11-08 14:05:40,459 INFO     Training average positive_sample_loss at step 293000: 0.414667\n",
      "2022-11-08 14:05:40,459 INFO     Training average negative_sample_loss at step 293000: 0.234669\n",
      "2022-11-08 14:05:40,459 INFO     Training average loss at step 293000: 0.324668\n",
      "2022-11-08 14:05:49,990 INFO     Training average positive_sample_loss at step 293100: 0.430962\n",
      "2022-11-08 14:05:49,990 INFO     Training average negative_sample_loss at step 293100: 0.237575\n",
      "2022-11-08 14:05:49,990 INFO     Training average loss at step 293100: 0.334268\n",
      "2022-11-08 14:05:59,517 INFO     Training average positive_sample_loss at step 293200: 0.408353\n",
      "2022-11-08 14:05:59,517 INFO     Training average negative_sample_loss at step 293200: 0.238787\n",
      "2022-11-08 14:05:59,517 INFO     Training average loss at step 293200: 0.323570\n",
      "2022-11-08 14:06:09,052 INFO     Training average positive_sample_loss at step 293300: 0.420980\n",
      "2022-11-08 14:06:09,052 INFO     Training average negative_sample_loss at step 293300: 0.238317\n",
      "2022-11-08 14:06:09,052 INFO     Training average loss at step 293300: 0.329648\n",
      "2022-11-08 14:06:18,581 INFO     Training average positive_sample_loss at step 293400: 0.407363\n",
      "2022-11-08 14:06:18,581 INFO     Training average negative_sample_loss at step 293400: 0.237095\n",
      "2022-11-08 14:06:18,581 INFO     Training average loss at step 293400: 0.322229\n",
      "2022-11-08 14:06:28,113 INFO     Training average positive_sample_loss at step 293500: 0.421136\n",
      "2022-11-08 14:06:28,113 INFO     Training average negative_sample_loss at step 293500: 0.240789\n",
      "2022-11-08 14:06:28,113 INFO     Training average loss at step 293500: 0.330963\n",
      "2022-11-08 14:06:37,643 INFO     Training average positive_sample_loss at step 293600: 0.427626\n",
      "2022-11-08 14:06:37,643 INFO     Training average negative_sample_loss at step 293600: 0.241399\n",
      "2022-11-08 14:06:37,643 INFO     Training average loss at step 293600: 0.334512\n",
      "2022-11-08 14:06:47,175 INFO     Training average positive_sample_loss at step 293700: 0.419441\n",
      "2022-11-08 14:06:47,175 INFO     Training average negative_sample_loss at step 293700: 0.231816\n",
      "2022-11-08 14:06:47,175 INFO     Training average loss at step 293700: 0.325628\n",
      "2022-11-08 14:06:56,704 INFO     Training average positive_sample_loss at step 293800: 0.415236\n",
      "2022-11-08 14:06:56,704 INFO     Training average negative_sample_loss at step 293800: 0.239553\n",
      "2022-11-08 14:06:56,704 INFO     Training average loss at step 293800: 0.327395\n",
      "2022-11-08 14:07:06,237 INFO     Training average positive_sample_loss at step 293900: 0.428607\n",
      "2022-11-08 14:07:06,237 INFO     Training average negative_sample_loss at step 293900: 0.235264\n",
      "2022-11-08 14:07:06,237 INFO     Training average loss at step 293900: 0.331935\n",
      "2022-11-08 14:07:16,187 INFO     Training average positive_sample_loss at step 294000: 0.414109\n",
      "2022-11-08 14:07:16,187 INFO     Training average negative_sample_loss at step 294000: 0.235768\n",
      "2022-11-08 14:07:16,187 INFO     Training average loss at step 294000: 0.324939\n",
      "2022-11-08 14:07:25,720 INFO     Training average positive_sample_loss at step 294100: 0.408959\n",
      "2022-11-08 14:07:25,720 INFO     Training average negative_sample_loss at step 294100: 0.245222\n",
      "2022-11-08 14:07:25,720 INFO     Training average loss at step 294100: 0.327090\n",
      "2022-11-08 14:07:35,483 INFO     Training average positive_sample_loss at step 294200: 0.429387\n",
      "2022-11-08 14:07:35,483 INFO     Training average negative_sample_loss at step 294200: 0.235838\n",
      "2022-11-08 14:07:35,483 INFO     Training average loss at step 294200: 0.332612\n",
      "2022-11-08 14:07:45,468 INFO     Training average positive_sample_loss at step 294300: 0.410252\n",
      "2022-11-08 14:07:45,468 INFO     Training average negative_sample_loss at step 294300: 0.238536\n",
      "2022-11-08 14:07:45,468 INFO     Training average loss at step 294300: 0.324394\n",
      "2022-11-08 14:07:55,000 INFO     Training average positive_sample_loss at step 294400: 0.425395\n",
      "2022-11-08 14:07:55,000 INFO     Training average negative_sample_loss at step 294400: 0.234807\n",
      "2022-11-08 14:07:55,000 INFO     Training average loss at step 294400: 0.330101\n",
      "2022-11-08 14:08:04,532 INFO     Training average positive_sample_loss at step 294500: 0.392806\n",
      "2022-11-08 14:08:04,532 INFO     Training average negative_sample_loss at step 294500: 0.236196\n",
      "2022-11-08 14:08:04,532 INFO     Training average loss at step 294500: 0.314501\n",
      "2022-11-08 14:08:15,135 INFO     Training average positive_sample_loss at step 294600: 0.407636\n",
      "2022-11-08 14:08:15,135 INFO     Training average negative_sample_loss at step 294600: 0.238719\n",
      "2022-11-08 14:08:15,135 INFO     Training average loss at step 294600: 0.323177\n",
      "2022-11-08 14:08:24,666 INFO     Training average positive_sample_loss at step 294700: 0.421294\n",
      "2022-11-08 14:08:24,666 INFO     Training average negative_sample_loss at step 294700: 0.236397\n",
      "2022-11-08 14:08:24,666 INFO     Training average loss at step 294700: 0.328846\n",
      "2022-11-08 14:08:34,197 INFO     Training average positive_sample_loss at step 294800: 0.426485\n",
      "2022-11-08 14:08:34,197 INFO     Training average negative_sample_loss at step 294800: 0.242405\n",
      "2022-11-08 14:08:34,197 INFO     Training average loss at step 294800: 0.334445\n",
      "2022-11-08 14:08:43,723 INFO     Training average positive_sample_loss at step 294900: 0.429910\n",
      "2022-11-08 14:08:43,723 INFO     Training average negative_sample_loss at step 294900: 0.239756\n",
      "2022-11-08 14:08:43,724 INFO     Training average loss at step 294900: 0.334833\n",
      "2022-11-08 14:08:53,256 INFO     Training average positive_sample_loss at step 295000: 0.426408\n",
      "2022-11-08 14:08:53,256 INFO     Training average negative_sample_loss at step 295000: 0.238580\n",
      "2022-11-08 14:08:53,256 INFO     Training average loss at step 295000: 0.332494\n",
      "2022-11-08 14:09:02,787 INFO     Training average positive_sample_loss at step 295100: 0.404803\n",
      "2022-11-08 14:09:02,787 INFO     Training average negative_sample_loss at step 295100: 0.233679\n",
      "2022-11-08 14:09:02,787 INFO     Training average loss at step 295100: 0.319241\n",
      "2022-11-08 14:09:12,317 INFO     Training average positive_sample_loss at step 295200: 0.407181\n",
      "2022-11-08 14:09:12,317 INFO     Training average negative_sample_loss at step 295200: 0.233945\n",
      "2022-11-08 14:09:12,317 INFO     Training average loss at step 295200: 0.320563\n",
      "2022-11-08 14:09:21,849 INFO     Training average positive_sample_loss at step 295300: 0.412800\n",
      "2022-11-08 14:09:21,849 INFO     Training average negative_sample_loss at step 295300: 0.242098\n",
      "2022-11-08 14:09:21,850 INFO     Training average loss at step 295300: 0.327449\n",
      "2022-11-08 14:09:31,377 INFO     Training average positive_sample_loss at step 295400: 0.418973\n",
      "2022-11-08 14:09:31,377 INFO     Training average negative_sample_loss at step 295400: 0.239926\n",
      "2022-11-08 14:09:31,377 INFO     Training average loss at step 295400: 0.329450\n",
      "2022-11-08 14:09:40,907 INFO     Training average positive_sample_loss at step 295500: 0.429398\n",
      "2022-11-08 14:09:40,907 INFO     Training average negative_sample_loss at step 295500: 0.237447\n",
      "2022-11-08 14:09:40,907 INFO     Training average loss at step 295500: 0.333423\n",
      "2022-11-08 14:09:50,438 INFO     Training average positive_sample_loss at step 295600: 0.420715\n",
      "2022-11-08 14:09:50,438 INFO     Training average negative_sample_loss at step 295600: 0.242287\n",
      "2022-11-08 14:09:50,438 INFO     Training average loss at step 295600: 0.331501\n",
      "2022-11-08 14:09:59,969 INFO     Training average positive_sample_loss at step 295700: 0.411936\n",
      "2022-11-08 14:09:59,969 INFO     Training average negative_sample_loss at step 295700: 0.231537\n",
      "2022-11-08 14:09:59,969 INFO     Training average loss at step 295700: 0.321737\n",
      "2022-11-08 14:10:09,503 INFO     Training average positive_sample_loss at step 295800: 0.390119\n",
      "2022-11-08 14:10:09,503 INFO     Training average negative_sample_loss at step 295800: 0.236676\n",
      "2022-11-08 14:10:09,503 INFO     Training average loss at step 295800: 0.313397\n",
      "2022-11-08 14:10:19,037 INFO     Training average positive_sample_loss at step 295900: 0.425022\n",
      "2022-11-08 14:10:19,037 INFO     Training average negative_sample_loss at step 295900: 0.240732\n",
      "2022-11-08 14:10:19,037 INFO     Training average loss at step 295900: 0.332877\n",
      "2022-11-08 14:10:28,566 INFO     Training average positive_sample_loss at step 296000: 0.416124\n",
      "2022-11-08 14:10:28,567 INFO     Training average negative_sample_loss at step 296000: 0.240791\n",
      "2022-11-08 14:10:28,567 INFO     Training average loss at step 296000: 0.328458\n",
      "2022-11-08 14:10:38,098 INFO     Training average positive_sample_loss at step 296100: 0.412163\n",
      "2022-11-08 14:10:38,098 INFO     Training average negative_sample_loss at step 296100: 0.229555\n",
      "2022-11-08 14:10:38,098 INFO     Training average loss at step 296100: 0.320859\n",
      "2022-11-08 14:10:47,627 INFO     Training average positive_sample_loss at step 296200: 0.400468\n",
      "2022-11-08 14:10:47,628 INFO     Training average negative_sample_loss at step 296200: 0.236558\n",
      "2022-11-08 14:10:47,628 INFO     Training average loss at step 296200: 0.318513\n",
      "2022-11-08 14:10:57,158 INFO     Training average positive_sample_loss at step 296300: 0.425130\n",
      "2022-11-08 14:10:57,158 INFO     Training average negative_sample_loss at step 296300: 0.229910\n",
      "2022-11-08 14:10:57,158 INFO     Training average loss at step 296300: 0.327520\n",
      "2022-11-08 14:11:06,691 INFO     Training average positive_sample_loss at step 296400: 0.421682\n",
      "2022-11-08 14:11:06,691 INFO     Training average negative_sample_loss at step 296400: 0.233071\n",
      "2022-11-08 14:11:06,691 INFO     Training average loss at step 296400: 0.327377\n",
      "2022-11-08 14:11:16,221 INFO     Training average positive_sample_loss at step 296500: 0.408314\n",
      "2022-11-08 14:11:16,221 INFO     Training average negative_sample_loss at step 296500: 0.241682\n",
      "2022-11-08 14:11:16,221 INFO     Training average loss at step 296500: 0.324998\n",
      "2022-11-08 14:11:25,752 INFO     Training average positive_sample_loss at step 296600: 0.427052\n",
      "2022-11-08 14:11:25,752 INFO     Training average negative_sample_loss at step 296600: 0.237744\n",
      "2022-11-08 14:11:25,752 INFO     Training average loss at step 296600: 0.332398\n",
      "2022-11-08 14:11:35,283 INFO     Training average positive_sample_loss at step 296700: 0.430310\n",
      "2022-11-08 14:11:35,283 INFO     Training average negative_sample_loss at step 296700: 0.235804\n",
      "2022-11-08 14:11:35,283 INFO     Training average loss at step 296700: 0.333057\n",
      "2022-11-08 14:11:44,813 INFO     Training average positive_sample_loss at step 296800: 0.415000\n",
      "2022-11-08 14:11:44,813 INFO     Training average negative_sample_loss at step 296800: 0.240973\n",
      "2022-11-08 14:11:44,813 INFO     Training average loss at step 296800: 0.327987\n",
      "2022-11-08 14:11:54,345 INFO     Training average positive_sample_loss at step 296900: 0.399187\n",
      "2022-11-08 14:11:54,345 INFO     Training average negative_sample_loss at step 296900: 0.234676\n",
      "2022-11-08 14:11:54,345 INFO     Training average loss at step 296900: 0.316931\n",
      "2022-11-08 14:12:03,879 INFO     Training average positive_sample_loss at step 297000: 0.401544\n",
      "2022-11-08 14:12:03,879 INFO     Training average negative_sample_loss at step 297000: 0.243323\n",
      "2022-11-08 14:12:03,879 INFO     Training average loss at step 297000: 0.322434\n",
      "2022-11-08 14:12:13,203 INFO     Training average positive_sample_loss at step 297100: 0.412374\n",
      "2022-11-08 14:12:13,203 INFO     Training average negative_sample_loss at step 297100: 0.233396\n",
      "2022-11-08 14:12:13,203 INFO     Training average loss at step 297100: 0.322885\n",
      "2022-11-08 14:12:22,271 INFO     Training average positive_sample_loss at step 297200: 0.394906\n",
      "2022-11-08 14:12:22,271 INFO     Training average negative_sample_loss at step 297200: 0.233411\n",
      "2022-11-08 14:12:22,271 INFO     Training average loss at step 297200: 0.314158\n",
      "2022-11-08 14:12:31,794 INFO     Training average positive_sample_loss at step 297300: 0.411627\n",
      "2022-11-08 14:12:31,794 INFO     Training average negative_sample_loss at step 297300: 0.233470\n",
      "2022-11-08 14:12:31,794 INFO     Training average loss at step 297300: 0.322549\n",
      "2022-11-08 14:12:41,325 INFO     Training average positive_sample_loss at step 297400: 0.423617\n",
      "2022-11-08 14:12:41,325 INFO     Training average negative_sample_loss at step 297400: 0.228535\n",
      "2022-11-08 14:12:41,325 INFO     Training average loss at step 297400: 0.326076\n",
      "2022-11-08 14:12:50,854 INFO     Training average positive_sample_loss at step 297500: 0.418020\n",
      "2022-11-08 14:12:50,854 INFO     Training average negative_sample_loss at step 297500: 0.237256\n",
      "2022-11-08 14:12:50,854 INFO     Training average loss at step 297500: 0.327638\n",
      "2022-11-08 14:12:59,874 INFO     Training average positive_sample_loss at step 297600: 0.424093\n",
      "2022-11-08 14:12:59,875 INFO     Training average negative_sample_loss at step 297600: 0.237082\n",
      "2022-11-08 14:12:59,875 INFO     Training average loss at step 297600: 0.330587\n",
      "2022-11-08 14:13:09,213 INFO     Training average positive_sample_loss at step 297700: 0.427985\n",
      "2022-11-08 14:13:09,214 INFO     Training average negative_sample_loss at step 297700: 0.236448\n",
      "2022-11-08 14:13:09,214 INFO     Training average loss at step 297700: 0.332217\n",
      "2022-11-08 14:13:18,749 INFO     Training average positive_sample_loss at step 297800: 0.411882\n",
      "2022-11-08 14:13:18,749 INFO     Training average negative_sample_loss at step 297800: 0.238196\n",
      "2022-11-08 14:13:18,749 INFO     Training average loss at step 297800: 0.325039\n",
      "2022-11-08 14:13:28,290 INFO     Training average positive_sample_loss at step 297900: 0.407780\n",
      "2022-11-08 14:13:28,291 INFO     Training average negative_sample_loss at step 297900: 0.233327\n",
      "2022-11-08 14:13:28,291 INFO     Training average loss at step 297900: 0.320554\n",
      "2022-11-08 14:13:37,823 INFO     Training average positive_sample_loss at step 298000: 0.398267\n",
      "2022-11-08 14:13:37,823 INFO     Training average negative_sample_loss at step 298000: 0.239328\n",
      "2022-11-08 14:13:37,823 INFO     Training average loss at step 298000: 0.318798\n",
      "2022-11-08 14:13:47,357 INFO     Training average positive_sample_loss at step 298100: 0.422880\n",
      "2022-11-08 14:13:47,358 INFO     Training average negative_sample_loss at step 298100: 0.238812\n",
      "2022-11-08 14:13:47,358 INFO     Training average loss at step 298100: 0.330846\n",
      "2022-11-08 14:13:56,895 INFO     Training average positive_sample_loss at step 298200: 0.403231\n",
      "2022-11-08 14:13:56,895 INFO     Training average negative_sample_loss at step 298200: 0.232140\n",
      "2022-11-08 14:13:56,895 INFO     Training average loss at step 298200: 0.317686\n",
      "2022-11-08 14:14:06,432 INFO     Training average positive_sample_loss at step 298300: 0.417480\n",
      "2022-11-08 14:14:06,432 INFO     Training average negative_sample_loss at step 298300: 0.233599\n",
      "2022-11-08 14:14:06,432 INFO     Training average loss at step 298300: 0.325540\n",
      "2022-11-08 14:14:15,967 INFO     Training average positive_sample_loss at step 298400: 0.422144\n",
      "2022-11-08 14:14:15,967 INFO     Training average negative_sample_loss at step 298400: 0.231661\n",
      "2022-11-08 14:14:15,967 INFO     Training average loss at step 298400: 0.326902\n",
      "2022-11-08 14:14:25,500 INFO     Training average positive_sample_loss at step 298500: 0.399431\n",
      "2022-11-08 14:14:25,500 INFO     Training average negative_sample_loss at step 298500: 0.229679\n",
      "2022-11-08 14:14:25,500 INFO     Training average loss at step 298500: 0.314555\n",
      "2022-11-08 14:14:35,030 INFO     Training average positive_sample_loss at step 298600: 0.410651\n",
      "2022-11-08 14:14:35,031 INFO     Training average negative_sample_loss at step 298600: 0.229364\n",
      "2022-11-08 14:14:35,031 INFO     Training average loss at step 298600: 0.320008\n",
      "2022-11-08 14:14:44,975 INFO     Training average positive_sample_loss at step 298700: 0.409786\n",
      "2022-11-08 14:14:44,975 INFO     Training average negative_sample_loss at step 298700: 0.235776\n",
      "2022-11-08 14:14:44,975 INFO     Training average loss at step 298700: 0.322781\n",
      "2022-11-08 14:14:54,756 INFO     Training average positive_sample_loss at step 298800: 0.428795\n",
      "2022-11-08 14:14:54,756 INFO     Training average negative_sample_loss at step 298800: 0.229109\n",
      "2022-11-08 14:14:54,756 INFO     Training average loss at step 298800: 0.328952\n",
      "2022-11-08 14:15:04,288 INFO     Training average positive_sample_loss at step 298900: 0.417007\n",
      "2022-11-08 14:15:04,288 INFO     Training average negative_sample_loss at step 298900: 0.239977\n",
      "2022-11-08 14:15:04,288 INFO     Training average loss at step 298900: 0.328492\n",
      "2022-11-08 14:15:14,242 INFO     Training average positive_sample_loss at step 299000: 0.417948\n",
      "2022-11-08 14:15:14,243 INFO     Training average negative_sample_loss at step 299000: 0.236799\n",
      "2022-11-08 14:15:14,243 INFO     Training average loss at step 299000: 0.327374\n",
      "2022-11-08 14:15:23,777 INFO     Training average positive_sample_loss at step 299100: 0.427086\n",
      "2022-11-08 14:15:23,778 INFO     Training average negative_sample_loss at step 299100: 0.238367\n",
      "2022-11-08 14:15:23,778 INFO     Training average loss at step 299100: 0.332727\n",
      "2022-11-08 14:15:33,313 INFO     Training average positive_sample_loss at step 299200: 0.437593\n",
      "2022-11-08 14:15:33,313 INFO     Training average negative_sample_loss at step 299200: 0.235691\n",
      "2022-11-08 14:15:33,313 INFO     Training average loss at step 299200: 0.336642\n",
      "2022-11-08 14:15:43,694 INFO     Training average positive_sample_loss at step 299300: 0.407487\n",
      "2022-11-08 14:15:43,694 INFO     Training average negative_sample_loss at step 299300: 0.234904\n",
      "2022-11-08 14:15:43,694 INFO     Training average loss at step 299300: 0.321196\n",
      "2022-11-08 14:15:52,131 INFO     Training average positive_sample_loss at step 299400: 0.437015\n",
      "2022-11-08 14:15:52,131 INFO     Training average negative_sample_loss at step 299400: 0.234327\n",
      "2022-11-08 14:15:52,131 INFO     Training average loss at step 299400: 0.335671\n",
      "2022-11-08 14:16:01,660 INFO     Training average positive_sample_loss at step 299500: 0.416698\n",
      "2022-11-08 14:16:01,660 INFO     Training average negative_sample_loss at step 299500: 0.230511\n",
      "2022-11-08 14:16:01,660 INFO     Training average loss at step 299500: 0.323604\n",
      "2022-11-08 14:16:11,195 INFO     Training average positive_sample_loss at step 299600: 0.409446\n",
      "2022-11-08 14:16:11,195 INFO     Training average negative_sample_loss at step 299600: 0.235095\n",
      "2022-11-08 14:16:11,195 INFO     Training average loss at step 299600: 0.322271\n",
      "2022-11-08 14:16:20,726 INFO     Training average positive_sample_loss at step 299700: 0.400400\n",
      "2022-11-08 14:16:20,726 INFO     Training average negative_sample_loss at step 299700: 0.238998\n",
      "2022-11-08 14:16:20,726 INFO     Training average loss at step 299700: 0.319699\n",
      "2022-11-08 14:16:30,257 INFO     Training average positive_sample_loss at step 299800: 0.412589\n",
      "2022-11-08 14:16:30,258 INFO     Training average negative_sample_loss at step 299800: 0.232803\n",
      "2022-11-08 14:16:30,258 INFO     Training average loss at step 299800: 0.322696\n",
      "2022-11-08 14:16:39,791 INFO     Training average positive_sample_loss at step 299900: 0.401021\n",
      "2022-11-08 14:16:39,792 INFO     Training average negative_sample_loss at step 299900: 0.229550\n",
      "2022-11-08 14:16:39,792 INFO     Training average loss at step 299900: 0.315286\n",
      "2022-11-08 14:16:52,190 INFO     Training average positive_sample_loss at step 300000: 0.410712\n",
      "2022-11-08 14:16:52,190 INFO     Training average negative_sample_loss at step 300000: 0.236055\n",
      "2022-11-08 14:16:52,190 INFO     Training average loss at step 300000: 0.323384\n",
      "2022-11-08 14:17:01,721 INFO     Training average positive_sample_loss at step 300100: 0.408996\n",
      "2022-11-08 14:17:01,721 INFO     Training average negative_sample_loss at step 300100: 0.234637\n",
      "2022-11-08 14:17:01,722 INFO     Training average loss at step 300100: 0.321816\n",
      "2022-11-08 14:17:11,256 INFO     Training average positive_sample_loss at step 300200: 0.408211\n",
      "2022-11-08 14:17:11,256 INFO     Training average negative_sample_loss at step 300200: 0.239699\n",
      "2022-11-08 14:17:11,256 INFO     Training average loss at step 300200: 0.323955\n",
      "2022-11-08 14:17:20,788 INFO     Training average positive_sample_loss at step 300300: 0.400900\n",
      "2022-11-08 14:17:20,788 INFO     Training average negative_sample_loss at step 300300: 0.231498\n",
      "2022-11-08 14:17:20,788 INFO     Training average loss at step 300300: 0.316199\n",
      "2022-11-08 14:17:30,321 INFO     Training average positive_sample_loss at step 300400: 0.403115\n",
      "2022-11-08 14:17:30,321 INFO     Training average negative_sample_loss at step 300400: 0.233277\n",
      "2022-11-08 14:17:30,321 INFO     Training average loss at step 300400: 0.318196\n",
      "2022-11-08 14:17:39,856 INFO     Training average positive_sample_loss at step 300500: 0.413939\n",
      "2022-11-08 14:17:39,856 INFO     Training average negative_sample_loss at step 300500: 0.242297\n",
      "2022-11-08 14:17:39,856 INFO     Training average loss at step 300500: 0.328118\n",
      "2022-11-08 14:17:49,389 INFO     Training average positive_sample_loss at step 300600: 0.396927\n",
      "2022-11-08 14:17:49,389 INFO     Training average negative_sample_loss at step 300600: 0.237628\n",
      "2022-11-08 14:17:49,389 INFO     Training average loss at step 300600: 0.317278\n",
      "2022-11-08 14:17:58,923 INFO     Training average positive_sample_loss at step 300700: 0.422332\n",
      "2022-11-08 14:17:58,923 INFO     Training average negative_sample_loss at step 300700: 0.230894\n",
      "2022-11-08 14:17:58,923 INFO     Training average loss at step 300700: 0.326613\n",
      "2022-11-08 14:18:08,458 INFO     Training average positive_sample_loss at step 300800: 0.422884\n",
      "2022-11-08 14:18:08,459 INFO     Training average negative_sample_loss at step 300800: 0.236798\n",
      "2022-11-08 14:18:08,459 INFO     Training average loss at step 300800: 0.329841\n",
      "2022-11-08 14:18:17,985 INFO     Training average positive_sample_loss at step 300900: 0.412405\n",
      "2022-11-08 14:18:17,985 INFO     Training average negative_sample_loss at step 300900: 0.234762\n",
      "2022-11-08 14:18:17,985 INFO     Training average loss at step 300900: 0.323584\n",
      "2022-11-08 14:18:27,519 INFO     Training average positive_sample_loss at step 301000: 0.405014\n",
      "2022-11-08 14:18:27,520 INFO     Training average negative_sample_loss at step 301000: 0.232491\n",
      "2022-11-08 14:18:27,520 INFO     Training average loss at step 301000: 0.318753\n",
      "2022-11-08 14:18:37,058 INFO     Training average positive_sample_loss at step 301100: 0.401882\n",
      "2022-11-08 14:18:37,058 INFO     Training average negative_sample_loss at step 301100: 0.230621\n",
      "2022-11-08 14:18:37,058 INFO     Training average loss at step 301100: 0.316251\n",
      "2022-11-08 14:18:46,591 INFO     Training average positive_sample_loss at step 301200: 0.393262\n",
      "2022-11-08 14:18:46,591 INFO     Training average negative_sample_loss at step 301200: 0.230814\n",
      "2022-11-08 14:18:46,591 INFO     Training average loss at step 301200: 0.312038\n",
      "2022-11-08 14:18:56,124 INFO     Training average positive_sample_loss at step 301300: 0.426574\n",
      "2022-11-08 14:18:56,124 INFO     Training average negative_sample_loss at step 301300: 0.229212\n",
      "2022-11-08 14:18:56,124 INFO     Training average loss at step 301300: 0.327893\n",
      "2022-11-08 14:19:05,657 INFO     Training average positive_sample_loss at step 301400: 0.405310\n",
      "2022-11-08 14:19:05,657 INFO     Training average negative_sample_loss at step 301400: 0.237032\n",
      "2022-11-08 14:19:05,657 INFO     Training average loss at step 301400: 0.321171\n",
      "2022-11-08 14:19:15,189 INFO     Training average positive_sample_loss at step 301500: 0.404622\n",
      "2022-11-08 14:19:15,189 INFO     Training average negative_sample_loss at step 301500: 0.234111\n",
      "2022-11-08 14:19:15,189 INFO     Training average loss at step 301500: 0.319367\n",
      "2022-11-08 14:19:24,724 INFO     Training average positive_sample_loss at step 301600: 0.392300\n",
      "2022-11-08 14:19:24,724 INFO     Training average negative_sample_loss at step 301600: 0.233898\n",
      "2022-11-08 14:19:24,724 INFO     Training average loss at step 301600: 0.313099\n",
      "2022-11-08 14:19:34,261 INFO     Training average positive_sample_loss at step 301700: 0.394667\n",
      "2022-11-08 14:19:34,261 INFO     Training average negative_sample_loss at step 301700: 0.234880\n",
      "2022-11-08 14:19:34,261 INFO     Training average loss at step 301700: 0.314774\n",
      "2022-11-08 14:19:43,796 INFO     Training average positive_sample_loss at step 301800: 0.430909\n",
      "2022-11-08 14:19:43,796 INFO     Training average negative_sample_loss at step 301800: 0.235831\n",
      "2022-11-08 14:19:43,796 INFO     Training average loss at step 301800: 0.333370\n",
      "2022-11-08 14:19:53,327 INFO     Training average positive_sample_loss at step 301900: 0.390136\n",
      "2022-11-08 14:19:53,327 INFO     Training average negative_sample_loss at step 301900: 0.233126\n",
      "2022-11-08 14:19:53,327 INFO     Training average loss at step 301900: 0.311631\n",
      "2022-11-08 14:20:02,857 INFO     Training average positive_sample_loss at step 302000: 0.415304\n",
      "2022-11-08 14:20:02,858 INFO     Training average negative_sample_loss at step 302000: 0.232493\n",
      "2022-11-08 14:20:02,858 INFO     Training average loss at step 302000: 0.323899\n",
      "2022-11-08 14:20:12,393 INFO     Training average positive_sample_loss at step 302100: 0.402098\n",
      "2022-11-08 14:20:12,393 INFO     Training average negative_sample_loss at step 302100: 0.239023\n",
      "2022-11-08 14:20:12,393 INFO     Training average loss at step 302100: 0.320561\n",
      "2022-11-08 14:20:21,928 INFO     Training average positive_sample_loss at step 302200: 0.407264\n",
      "2022-11-08 14:20:21,928 INFO     Training average negative_sample_loss at step 302200: 0.233516\n",
      "2022-11-08 14:20:21,928 INFO     Training average loss at step 302200: 0.320390\n",
      "2022-11-08 14:20:31,460 INFO     Training average positive_sample_loss at step 302300: 0.416224\n",
      "2022-11-08 14:20:31,460 INFO     Training average negative_sample_loss at step 302300: 0.232169\n",
      "2022-11-08 14:20:31,460 INFO     Training average loss at step 302300: 0.324196\n",
      "2022-11-08 14:20:40,993 INFO     Training average positive_sample_loss at step 302400: 0.411795\n",
      "2022-11-08 14:20:40,993 INFO     Training average negative_sample_loss at step 302400: 0.233712\n",
      "2022-11-08 14:20:40,994 INFO     Training average loss at step 302400: 0.322753\n",
      "2022-11-08 14:20:50,523 INFO     Training average positive_sample_loss at step 302500: 0.400730\n",
      "2022-11-08 14:20:50,523 INFO     Training average negative_sample_loss at step 302500: 0.229740\n",
      "2022-11-08 14:20:50,523 INFO     Training average loss at step 302500: 0.315235\n",
      "2022-11-08 14:20:59,388 INFO     Training average positive_sample_loss at step 302600: 0.413254\n",
      "2022-11-08 14:20:59,388 INFO     Training average negative_sample_loss at step 302600: 0.231208\n",
      "2022-11-08 14:20:59,388 INFO     Training average loss at step 302600: 0.322231\n",
      "2022-11-08 14:21:08,922 INFO     Training average positive_sample_loss at step 302700: 0.403782\n",
      "2022-11-08 14:21:08,922 INFO     Training average negative_sample_loss at step 302700: 0.235150\n",
      "2022-11-08 14:21:08,922 INFO     Training average loss at step 302700: 0.319466\n",
      "2022-11-08 14:21:18,457 INFO     Training average positive_sample_loss at step 302800: 0.397835\n",
      "2022-11-08 14:21:18,457 INFO     Training average negative_sample_loss at step 302800: 0.234094\n",
      "2022-11-08 14:21:18,457 INFO     Training average loss at step 302800: 0.315964\n",
      "2022-11-08 14:21:27,992 INFO     Training average positive_sample_loss at step 302900: 0.400038\n",
      "2022-11-08 14:21:27,993 INFO     Training average negative_sample_loss at step 302900: 0.234511\n",
      "2022-11-08 14:21:27,993 INFO     Training average loss at step 302900: 0.317274\n",
      "2022-11-08 14:21:37,532 INFO     Training average positive_sample_loss at step 303000: 0.422737\n",
      "2022-11-08 14:21:37,532 INFO     Training average negative_sample_loss at step 303000: 0.228877\n",
      "2022-11-08 14:21:37,532 INFO     Training average loss at step 303000: 0.325807\n",
      "2022-11-08 14:21:46,377 INFO     Training average positive_sample_loss at step 303100: 0.417958\n",
      "2022-11-08 14:21:46,377 INFO     Training average negative_sample_loss at step 303100: 0.232752\n",
      "2022-11-08 14:21:46,377 INFO     Training average loss at step 303100: 0.325355\n",
      "2022-11-08 14:21:55,906 INFO     Training average positive_sample_loss at step 303200: 0.397928\n",
      "2022-11-08 14:21:55,907 INFO     Training average negative_sample_loss at step 303200: 0.233685\n",
      "2022-11-08 14:21:55,907 INFO     Training average loss at step 303200: 0.315806\n",
      "2022-11-08 14:22:05,389 INFO     Training average positive_sample_loss at step 303300: 0.406282\n",
      "2022-11-08 14:22:05,390 INFO     Training average negative_sample_loss at step 303300: 0.229735\n",
      "2022-11-08 14:22:05,390 INFO     Training average loss at step 303300: 0.318008\n",
      "2022-11-08 14:22:15,312 INFO     Training average positive_sample_loss at step 303400: 0.408540\n",
      "2022-11-08 14:22:15,313 INFO     Training average negative_sample_loss at step 303400: 0.226664\n",
      "2022-11-08 14:22:15,313 INFO     Training average loss at step 303400: 0.317602\n",
      "2022-11-08 14:22:25,118 INFO     Training average positive_sample_loss at step 303500: 0.406680\n",
      "2022-11-08 14:22:25,118 INFO     Training average negative_sample_loss at step 303500: 0.230682\n",
      "2022-11-08 14:22:25,118 INFO     Training average loss at step 303500: 0.318681\n",
      "2022-11-08 14:22:34,648 INFO     Training average positive_sample_loss at step 303600: 0.408197\n",
      "2022-11-08 14:22:34,648 INFO     Training average negative_sample_loss at step 303600: 0.231930\n",
      "2022-11-08 14:22:34,648 INFO     Training average loss at step 303600: 0.320064\n",
      "2022-11-08 14:22:44,584 INFO     Training average positive_sample_loss at step 303700: 0.409016\n",
      "2022-11-08 14:22:44,585 INFO     Training average negative_sample_loss at step 303700: 0.231361\n",
      "2022-11-08 14:22:44,585 INFO     Training average loss at step 303700: 0.320188\n",
      "2022-11-08 14:22:54,117 INFO     Training average positive_sample_loss at step 303800: 0.410231\n",
      "2022-11-08 14:22:54,117 INFO     Training average negative_sample_loss at step 303800: 0.234012\n",
      "2022-11-08 14:22:54,117 INFO     Training average loss at step 303800: 0.322122\n",
      "2022-11-08 14:23:03,648 INFO     Training average positive_sample_loss at step 303900: 0.417035\n",
      "2022-11-08 14:23:03,648 INFO     Training average negative_sample_loss at step 303900: 0.227059\n",
      "2022-11-08 14:23:03,648 INFO     Training average loss at step 303900: 0.322047\n",
      "2022-11-08 14:23:14,181 INFO     Training average positive_sample_loss at step 304000: 0.413160\n",
      "2022-11-08 14:23:14,181 INFO     Training average negative_sample_loss at step 304000: 0.233937\n",
      "2022-11-08 14:23:14,181 INFO     Training average loss at step 304000: 0.323549\n",
      "2022-11-08 14:23:23,712 INFO     Training average positive_sample_loss at step 304100: 0.406237\n",
      "2022-11-08 14:23:23,712 INFO     Training average negative_sample_loss at step 304100: 0.232698\n",
      "2022-11-08 14:23:23,712 INFO     Training average loss at step 304100: 0.319467\n",
      "2022-11-08 14:23:33,243 INFO     Training average positive_sample_loss at step 304200: 0.398658\n",
      "2022-11-08 14:23:33,243 INFO     Training average negative_sample_loss at step 304200: 0.229027\n",
      "2022-11-08 14:23:33,243 INFO     Training average loss at step 304200: 0.313843\n",
      "2022-11-08 14:23:42,775 INFO     Training average positive_sample_loss at step 304300: 0.416333\n",
      "2022-11-08 14:23:42,775 INFO     Training average negative_sample_loss at step 304300: 0.237951\n",
      "2022-11-08 14:23:42,775 INFO     Training average loss at step 304300: 0.327142\n",
      "2022-11-08 14:23:52,304 INFO     Training average positive_sample_loss at step 304400: 0.410313\n",
      "2022-11-08 14:23:52,304 INFO     Training average negative_sample_loss at step 304400: 0.227886\n",
      "2022-11-08 14:23:52,304 INFO     Training average loss at step 304400: 0.319099\n",
      "2022-11-08 14:24:01,831 INFO     Training average positive_sample_loss at step 304500: 0.420386\n",
      "2022-11-08 14:24:01,831 INFO     Training average negative_sample_loss at step 304500: 0.237479\n",
      "2022-11-08 14:24:01,831 INFO     Training average loss at step 304500: 0.328933\n",
      "2022-11-08 14:24:11,361 INFO     Training average positive_sample_loss at step 304600: 0.387361\n",
      "2022-11-08 14:24:11,361 INFO     Training average negative_sample_loss at step 304600: 0.233921\n",
      "2022-11-08 14:24:11,361 INFO     Training average loss at step 304600: 0.310641\n",
      "2022-11-08 14:24:20,892 INFO     Training average positive_sample_loss at step 304700: 0.397693\n",
      "2022-11-08 14:24:20,892 INFO     Training average negative_sample_loss at step 304700: 0.234714\n",
      "2022-11-08 14:24:20,892 INFO     Training average loss at step 304700: 0.316203\n",
      "2022-11-08 14:24:30,419 INFO     Training average positive_sample_loss at step 304800: 0.408033\n",
      "2022-11-08 14:24:30,419 INFO     Training average negative_sample_loss at step 304800: 0.228104\n",
      "2022-11-08 14:24:30,419 INFO     Training average loss at step 304800: 0.318068\n",
      "2022-11-08 14:24:39,949 INFO     Training average positive_sample_loss at step 304900: 0.388976\n",
      "2022-11-08 14:24:39,949 INFO     Training average negative_sample_loss at step 304900: 0.229614\n",
      "2022-11-08 14:24:39,949 INFO     Training average loss at step 304900: 0.309295\n",
      "2022-11-08 14:24:49,475 INFO     Training average positive_sample_loss at step 305000: 0.387311\n",
      "2022-11-08 14:24:49,475 INFO     Training average negative_sample_loss at step 305000: 0.229798\n",
      "2022-11-08 14:24:49,475 INFO     Training average loss at step 305000: 0.308554\n",
      "2022-11-08 14:24:59,001 INFO     Training average positive_sample_loss at step 305100: 0.425649\n",
      "2022-11-08 14:24:59,001 INFO     Training average negative_sample_loss at step 305100: 0.234583\n",
      "2022-11-08 14:24:59,001 INFO     Training average loss at step 305100: 0.330116\n",
      "2022-11-08 14:25:08,533 INFO     Training average positive_sample_loss at step 305200: 0.396093\n",
      "2022-11-08 14:25:08,533 INFO     Training average negative_sample_loss at step 305200: 0.236418\n",
      "2022-11-08 14:25:08,533 INFO     Training average loss at step 305200: 0.316255\n",
      "2022-11-08 14:25:18,062 INFO     Training average positive_sample_loss at step 305300: 0.397292\n",
      "2022-11-08 14:25:18,062 INFO     Training average negative_sample_loss at step 305300: 0.237983\n",
      "2022-11-08 14:25:18,062 INFO     Training average loss at step 305300: 0.317638\n",
      "2022-11-08 14:25:27,593 INFO     Training average positive_sample_loss at step 305400: 0.403280\n",
      "2022-11-08 14:25:27,593 INFO     Training average negative_sample_loss at step 305400: 0.232145\n",
      "2022-11-08 14:25:27,593 INFO     Training average loss at step 305400: 0.317713\n",
      "2022-11-08 14:25:37,122 INFO     Training average positive_sample_loss at step 305500: 0.403976\n",
      "2022-11-08 14:25:37,122 INFO     Training average negative_sample_loss at step 305500: 0.234901\n",
      "2022-11-08 14:25:37,122 INFO     Training average loss at step 305500: 0.319439\n",
      "2022-11-08 14:25:46,648 INFO     Training average positive_sample_loss at step 305600: 0.421772\n",
      "2022-11-08 14:25:46,648 INFO     Training average negative_sample_loss at step 305600: 0.229774\n",
      "2022-11-08 14:25:46,648 INFO     Training average loss at step 305600: 0.325773\n",
      "2022-11-08 14:25:56,176 INFO     Training average positive_sample_loss at step 305700: 0.401259\n",
      "2022-11-08 14:25:56,176 INFO     Training average negative_sample_loss at step 305700: 0.228856\n",
      "2022-11-08 14:25:56,176 INFO     Training average loss at step 305700: 0.315058\n",
      "2022-11-08 14:26:05,711 INFO     Training average positive_sample_loss at step 305800: 0.398470\n",
      "2022-11-08 14:26:05,711 INFO     Training average negative_sample_loss at step 305800: 0.231164\n",
      "2022-11-08 14:26:05,711 INFO     Training average loss at step 305800: 0.314817\n",
      "2022-11-08 14:26:15,240 INFO     Training average positive_sample_loss at step 305900: 0.403820\n",
      "2022-11-08 14:26:15,240 INFO     Training average negative_sample_loss at step 305900: 0.231108\n",
      "2022-11-08 14:26:15,240 INFO     Training average loss at step 305900: 0.317464\n",
      "2022-11-08 14:26:24,770 INFO     Training average positive_sample_loss at step 306000: 0.400575\n",
      "2022-11-08 14:26:24,770 INFO     Training average negative_sample_loss at step 306000: 0.229167\n",
      "2022-11-08 14:26:24,770 INFO     Training average loss at step 306000: 0.314871\n",
      "2022-11-08 14:26:34,299 INFO     Training average positive_sample_loss at step 306100: 0.402860\n",
      "2022-11-08 14:26:34,299 INFO     Training average negative_sample_loss at step 306100: 0.230888\n",
      "2022-11-08 14:26:34,299 INFO     Training average loss at step 306100: 0.316874\n",
      "2022-11-08 14:26:43,823 INFO     Training average positive_sample_loss at step 306200: 0.401681\n",
      "2022-11-08 14:26:43,824 INFO     Training average negative_sample_loss at step 306200: 0.229358\n",
      "2022-11-08 14:26:43,824 INFO     Training average loss at step 306200: 0.315519\n",
      "2022-11-08 14:26:53,353 INFO     Training average positive_sample_loss at step 306300: 0.410244\n",
      "2022-11-08 14:26:53,353 INFO     Training average negative_sample_loss at step 306300: 0.233240\n",
      "2022-11-08 14:26:53,353 INFO     Training average loss at step 306300: 0.321742\n",
      "2022-11-08 14:27:02,883 INFO     Training average positive_sample_loss at step 306400: 0.383745\n",
      "2022-11-08 14:27:02,883 INFO     Training average negative_sample_loss at step 306400: 0.238033\n",
      "2022-11-08 14:27:02,883 INFO     Training average loss at step 306400: 0.310889\n",
      "2022-11-08 14:27:12,412 INFO     Training average positive_sample_loss at step 306500: 0.413257\n",
      "2022-11-08 14:27:12,412 INFO     Training average negative_sample_loss at step 306500: 0.230671\n",
      "2022-11-08 14:27:12,412 INFO     Training average loss at step 306500: 0.321964\n",
      "2022-11-08 14:27:21,941 INFO     Training average positive_sample_loss at step 306600: 0.406949\n",
      "2022-11-08 14:27:21,941 INFO     Training average negative_sample_loss at step 306600: 0.226288\n",
      "2022-11-08 14:27:21,942 INFO     Training average loss at step 306600: 0.316618\n",
      "2022-11-08 14:27:31,469 INFO     Training average positive_sample_loss at step 306700: 0.377343\n",
      "2022-11-08 14:27:31,469 INFO     Training average negative_sample_loss at step 306700: 0.232056\n",
      "2022-11-08 14:27:31,469 INFO     Training average loss at step 306700: 0.304700\n",
      "2022-11-08 14:27:40,996 INFO     Training average positive_sample_loss at step 306800: 0.412803\n",
      "2022-11-08 14:27:40,996 INFO     Training average negative_sample_loss at step 306800: 0.230919\n",
      "2022-11-08 14:27:40,996 INFO     Training average loss at step 306800: 0.321861\n",
      "2022-11-08 14:27:50,529 INFO     Training average positive_sample_loss at step 306900: 0.411363\n",
      "2022-11-08 14:27:50,529 INFO     Training average negative_sample_loss at step 306900: 0.228030\n",
      "2022-11-08 14:27:50,529 INFO     Training average loss at step 306900: 0.319697\n",
      "2022-11-08 14:28:00,059 INFO     Training average positive_sample_loss at step 307000: 0.414760\n",
      "2022-11-08 14:28:00,059 INFO     Training average negative_sample_loss at step 307000: 0.231500\n",
      "2022-11-08 14:28:00,059 INFO     Training average loss at step 307000: 0.323130\n",
      "2022-11-08 14:28:09,588 INFO     Training average positive_sample_loss at step 307100: 0.396330\n",
      "2022-11-08 14:28:09,588 INFO     Training average negative_sample_loss at step 307100: 0.230972\n",
      "2022-11-08 14:28:09,588 INFO     Training average loss at step 307100: 0.313651\n",
      "2022-11-08 14:28:19,116 INFO     Training average positive_sample_loss at step 307200: 0.399536\n",
      "2022-11-08 14:28:19,116 INFO     Training average negative_sample_loss at step 307200: 0.230103\n",
      "2022-11-08 14:28:19,116 INFO     Training average loss at step 307200: 0.314819\n",
      "2022-11-08 14:28:28,640 INFO     Training average positive_sample_loss at step 307300: 0.384819\n",
      "2022-11-08 14:28:28,640 INFO     Training average negative_sample_loss at step 307300: 0.234885\n",
      "2022-11-08 14:28:28,640 INFO     Training average loss at step 307300: 0.309852\n",
      "2022-11-08 14:28:38,173 INFO     Training average positive_sample_loss at step 307400: 0.403611\n",
      "2022-11-08 14:28:38,173 INFO     Training average negative_sample_loss at step 307400: 0.226074\n",
      "2022-11-08 14:28:38,173 INFO     Training average loss at step 307400: 0.314842\n",
      "2022-11-08 14:28:47,701 INFO     Training average positive_sample_loss at step 307500: 0.388221\n",
      "2022-11-08 14:28:47,701 INFO     Training average negative_sample_loss at step 307500: 0.235875\n",
      "2022-11-08 14:28:47,701 INFO     Training average loss at step 307500: 0.312048\n",
      "2022-11-08 14:28:57,233 INFO     Training average positive_sample_loss at step 307600: 0.415509\n",
      "2022-11-08 14:28:57,233 INFO     Training average negative_sample_loss at step 307600: 0.234810\n",
      "2022-11-08 14:28:57,233 INFO     Training average loss at step 307600: 0.325159\n",
      "2022-11-08 14:29:06,761 INFO     Training average positive_sample_loss at step 307700: 0.392247\n",
      "2022-11-08 14:29:06,761 INFO     Training average negative_sample_loss at step 307700: 0.235844\n",
      "2022-11-08 14:29:06,761 INFO     Training average loss at step 307700: 0.314046\n",
      "2022-11-08 14:29:16,286 INFO     Training average positive_sample_loss at step 307800: 0.392109\n",
      "2022-11-08 14:29:16,286 INFO     Training average negative_sample_loss at step 307800: 0.230271\n",
      "2022-11-08 14:29:16,286 INFO     Training average loss at step 307800: 0.311190\n",
      "2022-11-08 14:29:25,816 INFO     Training average positive_sample_loss at step 307900: 0.386467\n",
      "2022-11-08 14:29:25,816 INFO     Training average negative_sample_loss at step 307900: 0.233785\n",
      "2022-11-08 14:29:25,816 INFO     Training average loss at step 307900: 0.310126\n",
      "2022-11-08 14:29:35,788 INFO     Training average positive_sample_loss at step 308000: 0.434815\n",
      "2022-11-08 14:29:35,788 INFO     Training average negative_sample_loss at step 308000: 0.231886\n",
      "2022-11-08 14:29:35,788 INFO     Training average loss at step 308000: 0.333350\n",
      "2022-11-08 14:29:44,687 INFO     Training average positive_sample_loss at step 308100: 0.415911\n",
      "2022-11-08 14:29:44,687 INFO     Training average negative_sample_loss at step 308100: 0.221955\n",
      "2022-11-08 14:29:44,687 INFO     Training average loss at step 308100: 0.318933\n",
      "2022-11-08 14:29:54,501 INFO     Training average positive_sample_loss at step 308200: 0.408209\n",
      "2022-11-08 14:29:54,501 INFO     Training average negative_sample_loss at step 308200: 0.236814\n",
      "2022-11-08 14:29:54,501 INFO     Training average loss at step 308200: 0.322512\n",
      "2022-11-08 14:30:04,505 INFO     Training average positive_sample_loss at step 308300: 0.396148\n",
      "2022-11-08 14:30:04,505 INFO     Training average negative_sample_loss at step 308300: 0.230014\n",
      "2022-11-08 14:30:04,505 INFO     Training average loss at step 308300: 0.313081\n",
      "2022-11-08 14:30:14,041 INFO     Training average positive_sample_loss at step 308400: 0.390463\n",
      "2022-11-08 14:30:14,042 INFO     Training average negative_sample_loss at step 308400: 0.228511\n",
      "2022-11-08 14:30:14,042 INFO     Training average loss at step 308400: 0.309487\n",
      "2022-11-08 14:30:23,577 INFO     Training average positive_sample_loss at step 308500: 0.406582\n",
      "2022-11-08 14:30:23,577 INFO     Training average negative_sample_loss at step 308500: 0.230396\n",
      "2022-11-08 14:30:23,577 INFO     Training average loss at step 308500: 0.318489\n",
      "2022-11-08 14:30:32,430 INFO     Training average positive_sample_loss at step 308600: 0.419318\n",
      "2022-11-08 14:30:32,430 INFO     Training average negative_sample_loss at step 308600: 0.226224\n",
      "2022-11-08 14:30:32,430 INFO     Training average loss at step 308600: 0.322771\n",
      "2022-11-08 14:30:43,011 INFO     Training average positive_sample_loss at step 308700: 0.417721\n",
      "2022-11-08 14:30:43,011 INFO     Training average negative_sample_loss at step 308700: 0.226258\n",
      "2022-11-08 14:30:43,011 INFO     Training average loss at step 308700: 0.321990\n",
      "2022-11-08 14:30:52,544 INFO     Training average positive_sample_loss at step 308800: 0.403815\n",
      "2022-11-08 14:30:52,544 INFO     Training average negative_sample_loss at step 308800: 0.226338\n",
      "2022-11-08 14:30:52,544 INFO     Training average loss at step 308800: 0.315076\n",
      "2022-11-08 14:31:02,075 INFO     Training average positive_sample_loss at step 308900: 0.403678\n",
      "2022-11-08 14:31:02,075 INFO     Training average negative_sample_loss at step 308900: 0.234697\n",
      "2022-11-08 14:31:02,075 INFO     Training average loss at step 308900: 0.319188\n",
      "2022-11-08 14:31:11,604 INFO     Training average positive_sample_loss at step 309000: 0.411187\n",
      "2022-11-08 14:31:11,604 INFO     Training average negative_sample_loss at step 309000: 0.235518\n",
      "2022-11-08 14:31:11,604 INFO     Training average loss at step 309000: 0.323352\n",
      "2022-11-08 14:31:21,138 INFO     Training average positive_sample_loss at step 309100: 0.398544\n",
      "2022-11-08 14:31:21,138 INFO     Training average negative_sample_loss at step 309100: 0.231012\n",
      "2022-11-08 14:31:21,138 INFO     Training average loss at step 309100: 0.314778\n",
      "2022-11-08 14:31:30,670 INFO     Training average positive_sample_loss at step 309200: 0.378095\n",
      "2022-11-08 14:31:30,670 INFO     Training average negative_sample_loss at step 309200: 0.233570\n",
      "2022-11-08 14:31:30,670 INFO     Training average loss at step 309200: 0.305832\n",
      "2022-11-08 14:31:40,203 INFO     Training average positive_sample_loss at step 309300: 0.408875\n",
      "2022-11-08 14:31:40,204 INFO     Training average negative_sample_loss at step 309300: 0.229852\n",
      "2022-11-08 14:31:40,204 INFO     Training average loss at step 309300: 0.319364\n",
      "2022-11-08 14:31:49,743 INFO     Training average positive_sample_loss at step 309400: 0.388156\n",
      "2022-11-08 14:31:49,744 INFO     Training average negative_sample_loss at step 309400: 0.226103\n",
      "2022-11-08 14:31:49,744 INFO     Training average loss at step 309400: 0.307129\n",
      "2022-11-08 14:31:59,272 INFO     Training average positive_sample_loss at step 309500: 0.411704\n",
      "2022-11-08 14:31:59,273 INFO     Training average negative_sample_loss at step 309500: 0.228574\n",
      "2022-11-08 14:31:59,273 INFO     Training average loss at step 309500: 0.320139\n",
      "2022-11-08 14:32:08,803 INFO     Training average positive_sample_loss at step 309600: 0.395303\n",
      "2022-11-08 14:32:08,804 INFO     Training average negative_sample_loss at step 309600: 0.235627\n",
      "2022-11-08 14:32:08,804 INFO     Training average loss at step 309600: 0.315465\n",
      "2022-11-08 14:32:18,339 INFO     Training average positive_sample_loss at step 309700: 0.415792\n",
      "2022-11-08 14:32:18,340 INFO     Training average negative_sample_loss at step 309700: 0.234874\n",
      "2022-11-08 14:32:18,340 INFO     Training average loss at step 309700: 0.325333\n",
      "2022-11-08 14:32:27,871 INFO     Training average positive_sample_loss at step 309800: 0.404913\n",
      "2022-11-08 14:32:27,871 INFO     Training average negative_sample_loss at step 309800: 0.235865\n",
      "2022-11-08 14:32:27,871 INFO     Training average loss at step 309800: 0.320389\n",
      "2022-11-08 14:32:37,525 INFO     Training average positive_sample_loss at step 309900: 0.401415\n",
      "2022-11-08 14:32:37,525 INFO     Training average negative_sample_loss at step 309900: 0.224660\n",
      "2022-11-08 14:32:37,525 INFO     Training average loss at step 309900: 0.313037\n",
      "2022-11-08 14:32:49,970 INFO     Training average positive_sample_loss at step 310000: 0.420825\n",
      "2022-11-08 14:32:49,970 INFO     Training average negative_sample_loss at step 310000: 0.228574\n",
      "2022-11-08 14:32:49,970 INFO     Training average loss at step 310000: 0.324699\n",
      "2022-11-08 14:32:59,751 INFO     Training average positive_sample_loss at step 310100: 0.406568\n",
      "2022-11-08 14:32:59,751 INFO     Training average negative_sample_loss at step 310100: 0.230144\n",
      "2022-11-08 14:32:59,751 INFO     Training average loss at step 310100: 0.318356\n",
      "2022-11-08 14:33:09,497 INFO     Training average positive_sample_loss at step 310200: 0.401223\n",
      "2022-11-08 14:33:09,497 INFO     Training average negative_sample_loss at step 310200: 0.229544\n",
      "2022-11-08 14:33:09,497 INFO     Training average loss at step 310200: 0.315384\n",
      "2022-11-08 14:33:19,027 INFO     Training average positive_sample_loss at step 310300: 0.397441\n",
      "2022-11-08 14:33:19,027 INFO     Training average negative_sample_loss at step 310300: 0.230091\n",
      "2022-11-08 14:33:19,027 INFO     Training average loss at step 310300: 0.313766\n",
      "2022-11-08 14:33:28,558 INFO     Training average positive_sample_loss at step 310400: 0.403318\n",
      "2022-11-08 14:33:28,558 INFO     Training average negative_sample_loss at step 310400: 0.232902\n",
      "2022-11-08 14:33:28,558 INFO     Training average loss at step 310400: 0.318110\n",
      "2022-11-08 14:33:38,094 INFO     Training average positive_sample_loss at step 310500: 0.395102\n",
      "2022-11-08 14:33:38,094 INFO     Training average negative_sample_loss at step 310500: 0.225798\n",
      "2022-11-08 14:33:38,094 INFO     Training average loss at step 310500: 0.310450\n",
      "2022-11-08 14:33:47,628 INFO     Training average positive_sample_loss at step 310600: 0.387737\n",
      "2022-11-08 14:33:47,628 INFO     Training average negative_sample_loss at step 310600: 0.229766\n",
      "2022-11-08 14:33:47,628 INFO     Training average loss at step 310600: 0.308751\n",
      "2022-11-08 14:33:57,162 INFO     Training average positive_sample_loss at step 310700: 0.380312\n",
      "2022-11-08 14:33:57,162 INFO     Training average negative_sample_loss at step 310700: 0.225450\n",
      "2022-11-08 14:33:57,162 INFO     Training average loss at step 310700: 0.302881\n",
      "2022-11-08 14:34:06,695 INFO     Training average positive_sample_loss at step 310800: 0.395139\n",
      "2022-11-08 14:34:06,695 INFO     Training average negative_sample_loss at step 310800: 0.228288\n",
      "2022-11-08 14:34:06,695 INFO     Training average loss at step 310800: 0.311714\n",
      "2022-11-08 14:34:16,227 INFO     Training average positive_sample_loss at step 310900: 0.378275\n",
      "2022-11-08 14:34:16,227 INFO     Training average negative_sample_loss at step 310900: 0.231411\n",
      "2022-11-08 14:34:16,227 INFO     Training average loss at step 310900: 0.304843\n",
      "2022-11-08 14:34:25,758 INFO     Training average positive_sample_loss at step 311000: 0.412683\n",
      "2022-11-08 14:34:25,758 INFO     Training average negative_sample_loss at step 311000: 0.227784\n",
      "2022-11-08 14:34:25,759 INFO     Training average loss at step 311000: 0.320234\n",
      "2022-11-08 14:34:35,293 INFO     Training average positive_sample_loss at step 311100: 0.407695\n",
      "2022-11-08 14:34:35,293 INFO     Training average negative_sample_loss at step 311100: 0.233430\n",
      "2022-11-08 14:34:35,293 INFO     Training average loss at step 311100: 0.320562\n",
      "2022-11-08 14:34:44,824 INFO     Training average positive_sample_loss at step 311200: 0.404998\n",
      "2022-11-08 14:34:44,824 INFO     Training average negative_sample_loss at step 311200: 0.229269\n",
      "2022-11-08 14:34:44,824 INFO     Training average loss at step 311200: 0.317134\n",
      "2022-11-08 14:34:54,357 INFO     Training average positive_sample_loss at step 311300: 0.403997\n",
      "2022-11-08 14:34:54,358 INFO     Training average negative_sample_loss at step 311300: 0.227931\n",
      "2022-11-08 14:34:54,358 INFO     Training average loss at step 311300: 0.315964\n",
      "2022-11-08 14:35:03,893 INFO     Training average positive_sample_loss at step 311400: 0.408821\n",
      "2022-11-08 14:35:03,893 INFO     Training average negative_sample_loss at step 311400: 0.227449\n",
      "2022-11-08 14:35:03,893 INFO     Training average loss at step 311400: 0.318135\n",
      "2022-11-08 14:35:13,426 INFO     Training average positive_sample_loss at step 311500: 0.403408\n",
      "2022-11-08 14:35:13,426 INFO     Training average negative_sample_loss at step 311500: 0.225290\n",
      "2022-11-08 14:35:13,426 INFO     Training average loss at step 311500: 0.314349\n",
      "2022-11-08 14:35:22,960 INFO     Training average positive_sample_loss at step 311600: 0.374418\n",
      "2022-11-08 14:35:22,960 INFO     Training average negative_sample_loss at step 311600: 0.233418\n",
      "2022-11-08 14:35:22,960 INFO     Training average loss at step 311600: 0.303918\n",
      "2022-11-08 14:35:32,495 INFO     Training average positive_sample_loss at step 311700: 0.417281\n",
      "2022-11-08 14:35:32,495 INFO     Training average negative_sample_loss at step 311700: 0.220590\n",
      "2022-11-08 14:35:32,495 INFO     Training average loss at step 311700: 0.318935\n",
      "2022-11-08 14:35:42,032 INFO     Training average positive_sample_loss at step 311800: 0.384844\n",
      "2022-11-08 14:35:42,032 INFO     Training average negative_sample_loss at step 311800: 0.224909\n",
      "2022-11-08 14:35:42,032 INFO     Training average loss at step 311800: 0.304877\n",
      "2022-11-08 14:35:51,566 INFO     Training average positive_sample_loss at step 311900: 0.399615\n",
      "2022-11-08 14:35:51,566 INFO     Training average negative_sample_loss at step 311900: 0.226250\n",
      "2022-11-08 14:35:51,566 INFO     Training average loss at step 311900: 0.312933\n",
      "2022-11-08 14:36:01,095 INFO     Training average positive_sample_loss at step 312000: 0.386261\n",
      "2022-11-08 14:36:01,095 INFO     Training average negative_sample_loss at step 312000: 0.227440\n",
      "2022-11-08 14:36:01,095 INFO     Training average loss at step 312000: 0.306850\n",
      "2022-11-08 14:36:10,626 INFO     Training average positive_sample_loss at step 312100: 0.399360\n",
      "2022-11-08 14:36:10,627 INFO     Training average negative_sample_loss at step 312100: 0.225508\n",
      "2022-11-08 14:36:10,627 INFO     Training average loss at step 312100: 0.312434\n",
      "2022-11-08 14:36:20,161 INFO     Training average positive_sample_loss at step 312200: 0.396320\n",
      "2022-11-08 14:36:20,161 INFO     Training average negative_sample_loss at step 312200: 0.226483\n",
      "2022-11-08 14:36:20,161 INFO     Training average loss at step 312200: 0.311401\n",
      "2022-11-08 14:36:29,693 INFO     Training average positive_sample_loss at step 312300: 0.395435\n",
      "2022-11-08 14:36:29,693 INFO     Training average negative_sample_loss at step 312300: 0.226306\n",
      "2022-11-08 14:36:29,693 INFO     Training average loss at step 312300: 0.310871\n",
      "2022-11-08 14:36:39,228 INFO     Training average positive_sample_loss at step 312400: 0.379458\n",
      "2022-11-08 14:36:39,228 INFO     Training average negative_sample_loss at step 312400: 0.228893\n",
      "2022-11-08 14:36:39,228 INFO     Training average loss at step 312400: 0.304176\n",
      "2022-11-08 14:36:48,760 INFO     Training average positive_sample_loss at step 312500: 0.410136\n",
      "2022-11-08 14:36:48,760 INFO     Training average negative_sample_loss at step 312500: 0.233156\n",
      "2022-11-08 14:36:48,760 INFO     Training average loss at step 312500: 0.321646\n",
      "2022-11-08 14:36:58,743 INFO     Training average positive_sample_loss at step 312600: 0.395824\n",
      "2022-11-08 14:36:58,743 INFO     Training average negative_sample_loss at step 312600: 0.225447\n",
      "2022-11-08 14:36:58,743 INFO     Training average loss at step 312600: 0.310635\n",
      "2022-11-08 14:37:08,277 INFO     Training average positive_sample_loss at step 312700: 0.379918\n",
      "2022-11-08 14:37:08,278 INFO     Training average negative_sample_loss at step 312700: 0.225451\n",
      "2022-11-08 14:37:08,278 INFO     Training average loss at step 312700: 0.302684\n",
      "2022-11-08 14:37:18,098 INFO     Training average positive_sample_loss at step 312800: 0.396100\n",
      "2022-11-08 14:37:18,098 INFO     Training average negative_sample_loss at step 312800: 0.230311\n",
      "2022-11-08 14:37:18,098 INFO     Training average loss at step 312800: 0.313205\n",
      "2022-11-08 14:37:27,914 INFO     Training average positive_sample_loss at step 312900: 0.412795\n",
      "2022-11-08 14:37:27,914 INFO     Training average negative_sample_loss at step 312900: 0.227017\n",
      "2022-11-08 14:37:27,914 INFO     Training average loss at step 312900: 0.319906\n",
      "2022-11-08 14:37:37,735 INFO     Training average positive_sample_loss at step 313000: 0.391908\n",
      "2022-11-08 14:37:37,735 INFO     Training average negative_sample_loss at step 313000: 0.230597\n",
      "2022-11-08 14:37:37,735 INFO     Training average loss at step 313000: 0.311253\n",
      "2022-11-08 14:37:47,270 INFO     Training average positive_sample_loss at step 313100: 0.403548\n",
      "2022-11-08 14:37:47,270 INFO     Training average negative_sample_loss at step 313100: 0.227634\n",
      "2022-11-08 14:37:47,270 INFO     Training average loss at step 313100: 0.315591\n",
      "2022-11-08 14:37:56,803 INFO     Training average positive_sample_loss at step 313200: 0.385745\n",
      "2022-11-08 14:37:56,804 INFO     Training average negative_sample_loss at step 313200: 0.227917\n",
      "2022-11-08 14:37:56,804 INFO     Training average loss at step 313200: 0.306831\n",
      "2022-11-08 14:38:06,336 INFO     Training average positive_sample_loss at step 313300: 0.413953\n",
      "2022-11-08 14:38:06,336 INFO     Training average negative_sample_loss at step 313300: 0.227796\n",
      "2022-11-08 14:38:06,336 INFO     Training average loss at step 313300: 0.320875\n",
      "2022-11-08 14:38:16,857 INFO     Training average positive_sample_loss at step 313400: 0.394685\n",
      "2022-11-08 14:38:16,857 INFO     Training average negative_sample_loss at step 313400: 0.227712\n",
      "2022-11-08 14:38:16,857 INFO     Training average loss at step 313400: 0.311199\n",
      "2022-11-08 14:38:25,721 INFO     Training average positive_sample_loss at step 313500: 0.388348\n",
      "2022-11-08 14:38:25,721 INFO     Training average negative_sample_loss at step 313500: 0.233378\n",
      "2022-11-08 14:38:25,721 INFO     Training average loss at step 313500: 0.310863\n",
      "2022-11-08 14:38:35,255 INFO     Training average positive_sample_loss at step 313600: 0.395593\n",
      "2022-11-08 14:38:35,256 INFO     Training average negative_sample_loss at step 313600: 0.220994\n",
      "2022-11-08 14:38:35,256 INFO     Training average loss at step 313600: 0.308293\n",
      "2022-11-08 14:38:44,789 INFO     Training average positive_sample_loss at step 313700: 0.394813\n",
      "2022-11-08 14:38:44,789 INFO     Training average negative_sample_loss at step 313700: 0.221144\n",
      "2022-11-08 14:38:44,789 INFO     Training average loss at step 313700: 0.307979\n",
      "2022-11-08 14:38:54,324 INFO     Training average positive_sample_loss at step 313800: 0.393107\n",
      "2022-11-08 14:38:54,324 INFO     Training average negative_sample_loss at step 313800: 0.232594\n",
      "2022-11-08 14:38:54,324 INFO     Training average loss at step 313800: 0.312851\n",
      "2022-11-08 14:39:03,860 INFO     Training average positive_sample_loss at step 313900: 0.396172\n",
      "2022-11-08 14:39:03,860 INFO     Training average negative_sample_loss at step 313900: 0.227229\n",
      "2022-11-08 14:39:03,860 INFO     Training average loss at step 313900: 0.311701\n",
      "2022-11-08 14:39:12,744 INFO     Training average positive_sample_loss at step 314000: 0.387071\n",
      "2022-11-08 14:39:12,744 INFO     Training average negative_sample_loss at step 314000: 0.234226\n",
      "2022-11-08 14:39:12,744 INFO     Training average loss at step 314000: 0.310648\n",
      "2022-11-08 14:39:22,273 INFO     Training average positive_sample_loss at step 314100: 0.403961\n",
      "2022-11-08 14:39:22,273 INFO     Training average negative_sample_loss at step 314100: 0.228694\n",
      "2022-11-08 14:39:22,273 INFO     Training average loss at step 314100: 0.316327\n",
      "2022-11-08 14:39:31,807 INFO     Training average positive_sample_loss at step 314200: 0.404562\n",
      "2022-11-08 14:39:31,807 INFO     Training average negative_sample_loss at step 314200: 0.231394\n",
      "2022-11-08 14:39:31,807 INFO     Training average loss at step 314200: 0.317978\n",
      "2022-11-08 14:39:41,331 INFO     Training average positive_sample_loss at step 314300: 0.392409\n",
      "2022-11-08 14:39:41,332 INFO     Training average negative_sample_loss at step 314300: 0.230485\n",
      "2022-11-08 14:39:41,332 INFO     Training average loss at step 314300: 0.311447\n",
      "2022-11-08 14:39:50,860 INFO     Training average positive_sample_loss at step 314400: 0.379636\n",
      "2022-11-08 14:39:50,860 INFO     Training average negative_sample_loss at step 314400: 0.228231\n",
      "2022-11-08 14:39:50,860 INFO     Training average loss at step 314400: 0.303934\n",
      "2022-11-08 14:40:00,391 INFO     Training average positive_sample_loss at step 314500: 0.378958\n",
      "2022-11-08 14:40:00,391 INFO     Training average negative_sample_loss at step 314500: 0.224026\n",
      "2022-11-08 14:40:00,391 INFO     Training average loss at step 314500: 0.301492\n",
      "2022-11-08 14:40:09,923 INFO     Training average positive_sample_loss at step 314600: 0.403020\n",
      "2022-11-08 14:40:09,923 INFO     Training average negative_sample_loss at step 314600: 0.228668\n",
      "2022-11-08 14:40:09,923 INFO     Training average loss at step 314600: 0.315844\n",
      "2022-11-08 14:40:19,457 INFO     Training average positive_sample_loss at step 314700: 0.399246\n",
      "2022-11-08 14:40:19,457 INFO     Training average negative_sample_loss at step 314700: 0.232217\n",
      "2022-11-08 14:40:19,457 INFO     Training average loss at step 314700: 0.315732\n",
      "2022-11-08 14:40:28,983 INFO     Training average positive_sample_loss at step 314800: 0.402697\n",
      "2022-11-08 14:40:28,983 INFO     Training average negative_sample_loss at step 314800: 0.224729\n",
      "2022-11-08 14:40:28,983 INFO     Training average loss at step 314800: 0.313713\n",
      "2022-11-08 14:40:38,508 INFO     Training average positive_sample_loss at step 314900: 0.385971\n",
      "2022-11-08 14:40:38,508 INFO     Training average negative_sample_loss at step 314900: 0.227732\n",
      "2022-11-08 14:40:38,508 INFO     Training average loss at step 314900: 0.306852\n",
      "2022-11-08 14:40:48,036 INFO     Training average positive_sample_loss at step 315000: 0.409974\n",
      "2022-11-08 14:40:48,036 INFO     Training average negative_sample_loss at step 315000: 0.228676\n",
      "2022-11-08 14:40:48,036 INFO     Training average loss at step 315000: 0.319325\n",
      "2022-11-08 14:40:57,565 INFO     Training average positive_sample_loss at step 315100: 0.370395\n",
      "2022-11-08 14:40:57,565 INFO     Training average negative_sample_loss at step 315100: 0.230089\n",
      "2022-11-08 14:40:57,565 INFO     Training average loss at step 315100: 0.300242\n",
      "2022-11-08 14:41:07,094 INFO     Training average positive_sample_loss at step 315200: 0.406654\n",
      "2022-11-08 14:41:07,095 INFO     Training average negative_sample_loss at step 315200: 0.227282\n",
      "2022-11-08 14:41:07,095 INFO     Training average loss at step 315200: 0.316968\n",
      "2022-11-08 14:41:16,622 INFO     Training average positive_sample_loss at step 315300: 0.388830\n",
      "2022-11-08 14:41:16,622 INFO     Training average negative_sample_loss at step 315300: 0.226235\n",
      "2022-11-08 14:41:16,622 INFO     Training average loss at step 315300: 0.307532\n",
      "2022-11-08 14:41:26,147 INFO     Training average positive_sample_loss at step 315400: 0.398551\n",
      "2022-11-08 14:41:26,147 INFO     Training average negative_sample_loss at step 315400: 0.230113\n",
      "2022-11-08 14:41:26,147 INFO     Training average loss at step 315400: 0.314332\n",
      "2022-11-08 14:41:35,676 INFO     Training average positive_sample_loss at step 315500: 0.410777\n",
      "2022-11-08 14:41:35,676 INFO     Training average negative_sample_loss at step 315500: 0.223067\n",
      "2022-11-08 14:41:35,676 INFO     Training average loss at step 315500: 0.316922\n",
      "2022-11-08 14:41:44,579 INFO     Training average positive_sample_loss at step 315600: 0.383627\n",
      "2022-11-08 14:41:44,579 INFO     Training average negative_sample_loss at step 315600: 0.230690\n",
      "2022-11-08 14:41:44,579 INFO     Training average loss at step 315600: 0.307158\n",
      "2022-11-08 14:41:53,145 INFO     Training average positive_sample_loss at step 315700: 0.385639\n",
      "2022-11-08 14:41:53,145 INFO     Training average negative_sample_loss at step 315700: 0.224688\n",
      "2022-11-08 14:41:53,145 INFO     Training average loss at step 315700: 0.305163\n",
      "2022-11-08 14:42:02,677 INFO     Training average positive_sample_loss at step 315800: 0.396366\n",
      "2022-11-08 14:42:02,678 INFO     Training average negative_sample_loss at step 315800: 0.231558\n",
      "2022-11-08 14:42:02,678 INFO     Training average loss at step 315800: 0.313962\n",
      "2022-11-08 14:42:12,211 INFO     Training average positive_sample_loss at step 315900: 0.403412\n",
      "2022-11-08 14:42:12,211 INFO     Training average negative_sample_loss at step 315900: 0.229653\n",
      "2022-11-08 14:42:12,211 INFO     Training average loss at step 315900: 0.316532\n",
      "2022-11-08 14:42:21,749 INFO     Training average positive_sample_loss at step 316000: 0.392431\n",
      "2022-11-08 14:42:21,749 INFO     Training average negative_sample_loss at step 316000: 0.223112\n",
      "2022-11-08 14:42:21,749 INFO     Training average loss at step 316000: 0.307772\n",
      "2022-11-08 14:42:31,284 INFO     Training average positive_sample_loss at step 316100: 0.393012\n",
      "2022-11-08 14:42:31,284 INFO     Training average negative_sample_loss at step 316100: 0.229652\n",
      "2022-11-08 14:42:31,284 INFO     Training average loss at step 316100: 0.311332\n",
      "2022-11-08 14:42:40,816 INFO     Training average positive_sample_loss at step 316200: 0.409618\n",
      "2022-11-08 14:42:40,817 INFO     Training average negative_sample_loss at step 316200: 0.229652\n",
      "2022-11-08 14:42:40,817 INFO     Training average loss at step 316200: 0.319635\n",
      "2022-11-08 14:42:50,347 INFO     Training average positive_sample_loss at step 316300: 0.380098\n",
      "2022-11-08 14:42:50,347 INFO     Training average negative_sample_loss at step 316300: 0.228280\n",
      "2022-11-08 14:42:50,347 INFO     Training average loss at step 316300: 0.304189\n",
      "2022-11-08 14:42:59,882 INFO     Training average positive_sample_loss at step 316400: 0.401052\n",
      "2022-11-08 14:42:59,882 INFO     Training average negative_sample_loss at step 316400: 0.226430\n",
      "2022-11-08 14:42:59,882 INFO     Training average loss at step 316400: 0.313741\n",
      "2022-11-08 14:43:09,418 INFO     Training average positive_sample_loss at step 316500: 0.401443\n",
      "2022-11-08 14:43:09,418 INFO     Training average negative_sample_loss at step 316500: 0.221837\n",
      "2022-11-08 14:43:09,418 INFO     Training average loss at step 316500: 0.311640\n",
      "2022-11-08 14:43:18,955 INFO     Training average positive_sample_loss at step 316600: 0.392259\n",
      "2022-11-08 14:43:18,955 INFO     Training average negative_sample_loss at step 316600: 0.224667\n",
      "2022-11-08 14:43:18,955 INFO     Training average loss at step 316600: 0.308463\n",
      "2022-11-08 14:43:31,706 INFO     Training average positive_sample_loss at step 316700: 0.306305\n",
      "2022-11-08 14:43:31,706 INFO     Training average negative_sample_loss at step 316700: 0.228169\n",
      "2022-11-08 14:43:31,706 INFO     Training average loss at step 316700: 0.267237\n",
      "2022-11-08 14:43:41,238 INFO     Training average positive_sample_loss at step 316800: 0.284136\n",
      "2022-11-08 14:43:41,238 INFO     Training average negative_sample_loss at step 316800: 0.230190\n",
      "2022-11-08 14:43:41,238 INFO     Training average loss at step 316800: 0.257163\n",
      "2022-11-08 14:43:50,767 INFO     Training average positive_sample_loss at step 316900: 0.277743\n",
      "2022-11-08 14:43:50,767 INFO     Training average negative_sample_loss at step 316900: 0.221120\n",
      "2022-11-08 14:43:50,767 INFO     Training average loss at step 316900: 0.249431\n",
      "2022-11-08 14:44:00,303 INFO     Training average positive_sample_loss at step 317000: 0.277186\n",
      "2022-11-08 14:44:00,303 INFO     Training average negative_sample_loss at step 317000: 0.215275\n",
      "2022-11-08 14:44:00,303 INFO     Training average loss at step 317000: 0.246231\n",
      "2022-11-08 14:44:09,830 INFO     Training average positive_sample_loss at step 317100: 0.282092\n",
      "2022-11-08 14:44:09,830 INFO     Training average negative_sample_loss at step 317100: 0.217226\n",
      "2022-11-08 14:44:09,830 INFO     Training average loss at step 317100: 0.249659\n",
      "2022-11-08 14:44:19,360 INFO     Training average positive_sample_loss at step 317200: 0.268313\n",
      "2022-11-08 14:44:19,360 INFO     Training average negative_sample_loss at step 317200: 0.222555\n",
      "2022-11-08 14:44:19,360 INFO     Training average loss at step 317200: 0.245434\n",
      "2022-11-08 14:44:28,893 INFO     Training average positive_sample_loss at step 317300: 0.287000\n",
      "2022-11-08 14:44:28,893 INFO     Training average negative_sample_loss at step 317300: 0.213527\n",
      "2022-11-08 14:44:28,893 INFO     Training average loss at step 317300: 0.250264\n",
      "2022-11-08 14:44:38,422 INFO     Training average positive_sample_loss at step 317400: 0.286573\n",
      "2022-11-08 14:44:38,422 INFO     Training average negative_sample_loss at step 317400: 0.216299\n",
      "2022-11-08 14:44:38,422 INFO     Training average loss at step 317400: 0.251436\n",
      "2022-11-08 14:44:47,953 INFO     Training average positive_sample_loss at step 317500: 0.279074\n",
      "2022-11-08 14:44:47,953 INFO     Training average negative_sample_loss at step 317500: 0.217430\n",
      "2022-11-08 14:44:47,953 INFO     Training average loss at step 317500: 0.248252\n",
      "2022-11-08 14:44:57,486 INFO     Training average positive_sample_loss at step 317600: 0.292128\n",
      "2022-11-08 14:44:57,486 INFO     Training average negative_sample_loss at step 317600: 0.217687\n",
      "2022-11-08 14:44:57,486 INFO     Training average loss at step 317600: 0.254908\n",
      "2022-11-08 14:45:07,012 INFO     Training average positive_sample_loss at step 317700: 0.280164\n",
      "2022-11-08 14:45:07,012 INFO     Training average negative_sample_loss at step 317700: 0.215505\n",
      "2022-11-08 14:45:07,012 INFO     Training average loss at step 317700: 0.247834\n",
      "2022-11-08 14:45:16,543 INFO     Training average positive_sample_loss at step 317800: 0.295295\n",
      "2022-11-08 14:45:16,543 INFO     Training average negative_sample_loss at step 317800: 0.217541\n",
      "2022-11-08 14:45:16,543 INFO     Training average loss at step 317800: 0.256418\n",
      "2022-11-08 14:45:26,073 INFO     Training average positive_sample_loss at step 317900: 0.279251\n",
      "2022-11-08 14:45:26,073 INFO     Training average negative_sample_loss at step 317900: 0.211932\n",
      "2022-11-08 14:45:26,073 INFO     Training average loss at step 317900: 0.245591\n",
      "2022-11-08 14:45:35,607 INFO     Training average positive_sample_loss at step 318000: 0.287303\n",
      "2022-11-08 14:45:35,607 INFO     Training average negative_sample_loss at step 318000: 0.212203\n",
      "2022-11-08 14:45:35,607 INFO     Training average loss at step 318000: 0.249753\n",
      "2022-11-08 14:45:45,141 INFO     Training average positive_sample_loss at step 318100: 0.294978\n",
      "2022-11-08 14:45:45,141 INFO     Training average negative_sample_loss at step 318100: 0.211976\n",
      "2022-11-08 14:45:45,141 INFO     Training average loss at step 318100: 0.253477\n",
      "2022-11-08 14:45:54,673 INFO     Training average positive_sample_loss at step 318200: 0.277478\n",
      "2022-11-08 14:45:54,673 INFO     Training average negative_sample_loss at step 318200: 0.211790\n",
      "2022-11-08 14:45:54,673 INFO     Training average loss at step 318200: 0.244634\n",
      "2022-11-08 14:46:04,205 INFO     Training average positive_sample_loss at step 318300: 0.283382\n",
      "2022-11-08 14:46:04,205 INFO     Training average negative_sample_loss at step 318300: 0.215326\n",
      "2022-11-08 14:46:04,205 INFO     Training average loss at step 318300: 0.249354\n",
      "2022-11-08 14:46:13,740 INFO     Training average positive_sample_loss at step 318400: 0.288892\n",
      "2022-11-08 14:46:13,741 INFO     Training average negative_sample_loss at step 318400: 0.212946\n",
      "2022-11-08 14:46:13,741 INFO     Training average loss at step 318400: 0.250919\n",
      "2022-11-08 14:46:23,273 INFO     Training average positive_sample_loss at step 318500: 0.285125\n",
      "2022-11-08 14:46:23,273 INFO     Training average negative_sample_loss at step 318500: 0.210207\n",
      "2022-11-08 14:46:23,273 INFO     Training average loss at step 318500: 0.247666\n",
      "2022-11-08 14:46:32,807 INFO     Training average positive_sample_loss at step 318600: 0.290319\n",
      "2022-11-08 14:46:32,807 INFO     Training average negative_sample_loss at step 318600: 0.208678\n",
      "2022-11-08 14:46:32,807 INFO     Training average loss at step 318600: 0.249498\n",
      "2022-11-08 14:46:42,341 INFO     Training average positive_sample_loss at step 318700: 0.295022\n",
      "2022-11-08 14:46:42,341 INFO     Training average negative_sample_loss at step 318700: 0.210654\n",
      "2022-11-08 14:46:42,342 INFO     Training average loss at step 318700: 0.252838\n",
      "2022-11-08 14:46:51,872 INFO     Training average positive_sample_loss at step 318800: 0.286633\n",
      "2022-11-08 14:46:51,872 INFO     Training average negative_sample_loss at step 318800: 0.211081\n",
      "2022-11-08 14:46:51,872 INFO     Training average loss at step 318800: 0.248857\n",
      "2022-11-08 14:47:01,406 INFO     Training average positive_sample_loss at step 318900: 0.286329\n",
      "2022-11-08 14:47:01,406 INFO     Training average negative_sample_loss at step 318900: 0.207886\n",
      "2022-11-08 14:47:01,406 INFO     Training average loss at step 318900: 0.247107\n",
      "2022-11-08 14:47:10,272 INFO     Training average positive_sample_loss at step 319000: 0.284335\n",
      "2022-11-08 14:47:10,272 INFO     Training average negative_sample_loss at step 319000: 0.214961\n",
      "2022-11-08 14:47:10,272 INFO     Training average loss at step 319000: 0.249648\n",
      "2022-11-08 14:47:19,803 INFO     Training average positive_sample_loss at step 319100: 0.293736\n",
      "2022-11-08 14:47:19,803 INFO     Training average negative_sample_loss at step 319100: 0.206441\n",
      "2022-11-08 14:47:19,803 INFO     Training average loss at step 319100: 0.250088\n",
      "2022-11-08 14:47:29,333 INFO     Training average positive_sample_loss at step 319200: 0.296577\n",
      "2022-11-08 14:47:29,333 INFO     Training average negative_sample_loss at step 319200: 0.202174\n",
      "2022-11-08 14:47:29,333 INFO     Training average loss at step 319200: 0.249376\n",
      "2022-11-08 14:47:38,860 INFO     Training average positive_sample_loss at step 319300: 0.294968\n",
      "2022-11-08 14:47:38,860 INFO     Training average negative_sample_loss at step 319300: 0.207830\n",
      "2022-11-08 14:47:38,861 INFO     Training average loss at step 319300: 0.251399\n",
      "2022-11-08 14:47:48,393 INFO     Training average positive_sample_loss at step 319400: 0.284610\n",
      "2022-11-08 14:47:48,393 INFO     Training average negative_sample_loss at step 319400: 0.214369\n",
      "2022-11-08 14:47:48,393 INFO     Training average loss at step 319400: 0.249489\n",
      "2022-11-08 14:47:57,240 INFO     Training average positive_sample_loss at step 319500: 0.298501\n",
      "2022-11-08 14:47:57,241 INFO     Training average negative_sample_loss at step 319500: 0.206755\n",
      "2022-11-08 14:47:57,241 INFO     Training average loss at step 319500: 0.252628\n",
      "2022-11-08 14:48:06,778 INFO     Training average positive_sample_loss at step 319600: 0.284883\n",
      "2022-11-08 14:48:06,778 INFO     Training average negative_sample_loss at step 319600: 0.214126\n",
      "2022-11-08 14:48:06,778 INFO     Training average loss at step 319600: 0.249504\n",
      "2022-11-08 14:48:16,314 INFO     Training average positive_sample_loss at step 319700: 0.285007\n",
      "2022-11-08 14:48:16,314 INFO     Training average negative_sample_loss at step 319700: 0.210336\n",
      "2022-11-08 14:48:16,314 INFO     Training average loss at step 319700: 0.247672\n",
      "2022-11-08 14:48:25,850 INFO     Training average positive_sample_loss at step 319800: 0.284912\n",
      "2022-11-08 14:48:25,850 INFO     Training average negative_sample_loss at step 319800: 0.213103\n",
      "2022-11-08 14:48:25,850 INFO     Training average loss at step 319800: 0.249008\n",
      "2022-11-08 14:48:35,382 INFO     Training average positive_sample_loss at step 319900: 0.289732\n",
      "2022-11-08 14:48:35,382 INFO     Training average negative_sample_loss at step 319900: 0.201145\n",
      "2022-11-08 14:48:35,382 INFO     Training average loss at step 319900: 0.245439\n",
      "2022-11-08 14:48:47,746 INFO     Training average positive_sample_loss at step 320000: 0.287483\n",
      "2022-11-08 14:48:47,747 INFO     Training average negative_sample_loss at step 320000: 0.207913\n",
      "2022-11-08 14:48:47,747 INFO     Training average loss at step 320000: 0.247698\n",
      "2022-11-08 14:48:57,274 INFO     Training average positive_sample_loss at step 320100: 0.298421\n",
      "2022-11-08 14:48:57,274 INFO     Training average negative_sample_loss at step 320100: 0.210161\n",
      "2022-11-08 14:48:57,274 INFO     Training average loss at step 320100: 0.254291\n",
      "2022-11-08 14:49:06,810 INFO     Training average positive_sample_loss at step 320200: 0.296759\n",
      "2022-11-08 14:49:06,810 INFO     Training average negative_sample_loss at step 320200: 0.206484\n",
      "2022-11-08 14:49:06,810 INFO     Training average loss at step 320200: 0.251621\n",
      "2022-11-08 14:49:16,346 INFO     Training average positive_sample_loss at step 320300: 0.281533\n",
      "2022-11-08 14:49:16,346 INFO     Training average negative_sample_loss at step 320300: 0.204042\n",
      "2022-11-08 14:49:16,346 INFO     Training average loss at step 320300: 0.242787\n",
      "2022-11-08 14:49:25,884 INFO     Training average positive_sample_loss at step 320400: 0.300712\n",
      "2022-11-08 14:49:25,884 INFO     Training average negative_sample_loss at step 320400: 0.210411\n",
      "2022-11-08 14:49:25,884 INFO     Training average loss at step 320400: 0.255562\n",
      "2022-11-08 14:49:35,416 INFO     Training average positive_sample_loss at step 320500: 0.304171\n",
      "2022-11-08 14:49:35,416 INFO     Training average negative_sample_loss at step 320500: 0.207338\n",
      "2022-11-08 14:49:35,416 INFO     Training average loss at step 320500: 0.255755\n",
      "2022-11-08 14:49:44,948 INFO     Training average positive_sample_loss at step 320600: 0.294347\n",
      "2022-11-08 14:49:44,949 INFO     Training average negative_sample_loss at step 320600: 0.212230\n",
      "2022-11-08 14:49:44,949 INFO     Training average loss at step 320600: 0.253288\n",
      "2022-11-08 14:49:54,483 INFO     Training average positive_sample_loss at step 320700: 0.293680\n",
      "2022-11-08 14:49:54,483 INFO     Training average negative_sample_loss at step 320700: 0.205297\n",
      "2022-11-08 14:49:54,483 INFO     Training average loss at step 320700: 0.249488\n",
      "2022-11-08 14:50:04,018 INFO     Training average positive_sample_loss at step 320800: 0.291328\n",
      "2022-11-08 14:50:04,018 INFO     Training average negative_sample_loss at step 320800: 0.202663\n",
      "2022-11-08 14:50:04,018 INFO     Training average loss at step 320800: 0.246996\n",
      "2022-11-08 14:50:13,554 INFO     Training average positive_sample_loss at step 320900: 0.296679\n",
      "2022-11-08 14:50:13,554 INFO     Training average negative_sample_loss at step 320900: 0.205832\n",
      "2022-11-08 14:50:13,554 INFO     Training average loss at step 320900: 0.251256\n",
      "2022-11-08 14:50:23,088 INFO     Training average positive_sample_loss at step 321000: 0.292661\n",
      "2022-11-08 14:50:23,088 INFO     Training average negative_sample_loss at step 321000: 0.206015\n",
      "2022-11-08 14:50:23,088 INFO     Training average loss at step 321000: 0.249338\n",
      "2022-11-08 14:50:32,619 INFO     Training average positive_sample_loss at step 321100: 0.288051\n",
      "2022-11-08 14:50:32,619 INFO     Training average negative_sample_loss at step 321100: 0.210906\n",
      "2022-11-08 14:50:32,619 INFO     Training average loss at step 321100: 0.249478\n",
      "2022-11-08 14:50:42,152 INFO     Training average positive_sample_loss at step 321200: 0.309871\n",
      "2022-11-08 14:50:42,152 INFO     Training average negative_sample_loss at step 321200: 0.212182\n",
      "2022-11-08 14:50:42,152 INFO     Training average loss at step 321200: 0.261027\n",
      "2022-11-08 14:50:51,687 INFO     Training average positive_sample_loss at step 321300: 0.306695\n",
      "2022-11-08 14:50:51,687 INFO     Training average negative_sample_loss at step 321300: 0.208061\n",
      "2022-11-08 14:50:51,687 INFO     Training average loss at step 321300: 0.257378\n",
      "2022-11-08 14:51:01,223 INFO     Training average positive_sample_loss at step 321400: 0.285862\n",
      "2022-11-08 14:51:01,223 INFO     Training average negative_sample_loss at step 321400: 0.214127\n",
      "2022-11-08 14:51:01,223 INFO     Training average loss at step 321400: 0.249994\n",
      "2022-11-08 14:51:10,758 INFO     Training average positive_sample_loss at step 321500: 0.292343\n",
      "2022-11-08 14:51:10,758 INFO     Training average negative_sample_loss at step 321500: 0.212017\n",
      "2022-11-08 14:51:10,758 INFO     Training average loss at step 321500: 0.252180\n",
      "2022-11-08 14:51:20,288 INFO     Training average positive_sample_loss at step 321600: 0.297538\n",
      "2022-11-08 14:51:20,289 INFO     Training average negative_sample_loss at step 321600: 0.205817\n",
      "2022-11-08 14:51:20,289 INFO     Training average loss at step 321600: 0.251677\n",
      "2022-11-08 14:51:29,820 INFO     Training average positive_sample_loss at step 321700: 0.299960\n",
      "2022-11-08 14:51:29,820 INFO     Training average negative_sample_loss at step 321700: 0.205706\n",
      "2022-11-08 14:51:29,820 INFO     Training average loss at step 321700: 0.252833\n",
      "2022-11-08 14:51:39,354 INFO     Training average positive_sample_loss at step 321800: 0.288111\n",
      "2022-11-08 14:51:39,355 INFO     Training average negative_sample_loss at step 321800: 0.205986\n",
      "2022-11-08 14:51:39,355 INFO     Training average loss at step 321800: 0.247048\n",
      "2022-11-08 14:51:48,894 INFO     Training average positive_sample_loss at step 321900: 0.302278\n",
      "2022-11-08 14:51:48,894 INFO     Training average negative_sample_loss at step 321900: 0.207309\n",
      "2022-11-08 14:51:48,894 INFO     Training average loss at step 321900: 0.254794\n",
      "2022-11-08 14:51:58,427 INFO     Training average positive_sample_loss at step 322000: 0.297472\n",
      "2022-11-08 14:51:58,427 INFO     Training average negative_sample_loss at step 322000: 0.208988\n",
      "2022-11-08 14:51:58,427 INFO     Training average loss at step 322000: 0.253230\n",
      "2022-11-08 14:52:07,966 INFO     Training average positive_sample_loss at step 322100: 0.304373\n",
      "2022-11-08 14:52:07,966 INFO     Training average negative_sample_loss at step 322100: 0.208502\n",
      "2022-11-08 14:52:07,966 INFO     Training average loss at step 322100: 0.256438\n",
      "2022-11-08 14:52:17,500 INFO     Training average positive_sample_loss at step 322200: 0.305495\n",
      "2022-11-08 14:52:17,500 INFO     Training average negative_sample_loss at step 322200: 0.206954\n",
      "2022-11-08 14:52:17,500 INFO     Training average loss at step 322200: 0.256224\n",
      "2022-11-08 14:52:27,032 INFO     Training average positive_sample_loss at step 322300: 0.300133\n",
      "2022-11-08 14:52:27,032 INFO     Training average negative_sample_loss at step 322300: 0.204477\n",
      "2022-11-08 14:52:27,033 INFO     Training average loss at step 322300: 0.252305\n",
      "2022-11-08 14:52:36,567 INFO     Training average positive_sample_loss at step 322400: 0.301054\n",
      "2022-11-08 14:52:36,568 INFO     Training average negative_sample_loss at step 322400: 0.206079\n",
      "2022-11-08 14:52:36,568 INFO     Training average loss at step 322400: 0.253566\n",
      "2022-11-08 14:52:46,106 INFO     Training average positive_sample_loss at step 322500: 0.298259\n",
      "2022-11-08 14:52:46,106 INFO     Training average negative_sample_loss at step 322500: 0.210561\n",
      "2022-11-08 14:52:46,106 INFO     Training average loss at step 322500: 0.254410\n",
      "2022-11-08 14:52:55,640 INFO     Training average positive_sample_loss at step 322600: 0.301808\n",
      "2022-11-08 14:52:55,640 INFO     Training average negative_sample_loss at step 322600: 0.212868\n",
      "2022-11-08 14:52:55,640 INFO     Training average loss at step 322600: 0.257338\n",
      "2022-11-08 14:53:05,172 INFO     Training average positive_sample_loss at step 322700: 0.295651\n",
      "2022-11-08 14:53:05,172 INFO     Training average negative_sample_loss at step 322700: 0.208147\n",
      "2022-11-08 14:53:05,172 INFO     Training average loss at step 322700: 0.251899\n",
      "2022-11-08 14:53:14,703 INFO     Training average positive_sample_loss at step 322800: 0.293326\n",
      "2022-11-08 14:53:14,703 INFO     Training average negative_sample_loss at step 322800: 0.206302\n",
      "2022-11-08 14:53:14,703 INFO     Training average loss at step 322800: 0.249814\n",
      "2022-11-08 14:53:24,238 INFO     Training average positive_sample_loss at step 322900: 0.294490\n",
      "2022-11-08 14:53:24,238 INFO     Training average negative_sample_loss at step 322900: 0.212076\n",
      "2022-11-08 14:53:24,238 INFO     Training average loss at step 322900: 0.253283\n",
      "2022-11-08 14:53:33,777 INFO     Training average positive_sample_loss at step 323000: 0.299368\n",
      "2022-11-08 14:53:33,777 INFO     Training average negative_sample_loss at step 323000: 0.214689\n",
      "2022-11-08 14:53:33,777 INFO     Training average loss at step 323000: 0.257029\n",
      "2022-11-08 14:53:43,313 INFO     Training average positive_sample_loss at step 323100: 0.297511\n",
      "2022-11-08 14:53:43,314 INFO     Training average negative_sample_loss at step 323100: 0.207697\n",
      "2022-11-08 14:53:43,314 INFO     Training average loss at step 323100: 0.252604\n",
      "2022-11-08 14:53:52,847 INFO     Training average positive_sample_loss at step 323200: 0.309787\n",
      "2022-11-08 14:53:52,847 INFO     Training average negative_sample_loss at step 323200: 0.208578\n",
      "2022-11-08 14:53:52,847 INFO     Training average loss at step 323200: 0.259182\n",
      "2022-11-08 14:54:02,379 INFO     Training average positive_sample_loss at step 323300: 0.299297\n",
      "2022-11-08 14:54:02,379 INFO     Training average negative_sample_loss at step 323300: 0.210620\n",
      "2022-11-08 14:54:02,380 INFO     Training average loss at step 323300: 0.254958\n",
      "2022-11-08 14:54:11,913 INFO     Training average positive_sample_loss at step 323400: 0.297417\n",
      "2022-11-08 14:54:11,913 INFO     Training average negative_sample_loss at step 323400: 0.206120\n",
      "2022-11-08 14:54:11,913 INFO     Training average loss at step 323400: 0.251768\n",
      "2022-11-08 14:54:21,450 INFO     Training average positive_sample_loss at step 323500: 0.288942\n",
      "2022-11-08 14:54:21,450 INFO     Training average negative_sample_loss at step 323500: 0.203263\n",
      "2022-11-08 14:54:21,450 INFO     Training average loss at step 323500: 0.246102\n",
      "2022-11-08 14:54:30,984 INFO     Training average positive_sample_loss at step 323600: 0.290853\n",
      "2022-11-08 14:54:30,984 INFO     Training average negative_sample_loss at step 323600: 0.206524\n",
      "2022-11-08 14:54:30,984 INFO     Training average loss at step 323600: 0.248689\n",
      "2022-11-08 14:54:40,520 INFO     Training average positive_sample_loss at step 323700: 0.281950\n",
      "2022-11-08 14:54:40,520 INFO     Training average negative_sample_loss at step 323700: 0.203637\n",
      "2022-11-08 14:54:40,520 INFO     Training average loss at step 323700: 0.242793\n",
      "2022-11-08 14:54:50,051 INFO     Training average positive_sample_loss at step 323800: 0.290822\n",
      "2022-11-08 14:54:50,051 INFO     Training average negative_sample_loss at step 323800: 0.208038\n",
      "2022-11-08 14:54:50,051 INFO     Training average loss at step 323800: 0.249430\n",
      "2022-11-08 14:54:59,583 INFO     Training average positive_sample_loss at step 323900: 0.293471\n",
      "2022-11-08 14:54:59,583 INFO     Training average negative_sample_loss at step 323900: 0.204442\n",
      "2022-11-08 14:54:59,583 INFO     Training average loss at step 323900: 0.248957\n",
      "2022-11-08 14:55:09,118 INFO     Training average positive_sample_loss at step 324000: 0.289201\n",
      "2022-11-08 14:55:09,118 INFO     Training average negative_sample_loss at step 324000: 0.206600\n",
      "2022-11-08 14:55:09,118 INFO     Training average loss at step 324000: 0.247901\n",
      "2022-11-08 14:55:18,654 INFO     Training average positive_sample_loss at step 324100: 0.307134\n",
      "2022-11-08 14:55:18,654 INFO     Training average negative_sample_loss at step 324100: 0.206687\n",
      "2022-11-08 14:55:18,654 INFO     Training average loss at step 324100: 0.256911\n",
      "2022-11-08 14:55:28,189 INFO     Training average positive_sample_loss at step 324200: 0.297729\n",
      "2022-11-08 14:55:28,189 INFO     Training average negative_sample_loss at step 324200: 0.208349\n",
      "2022-11-08 14:55:28,189 INFO     Training average loss at step 324200: 0.253039\n",
      "2022-11-08 14:55:37,723 INFO     Training average positive_sample_loss at step 324300: 0.299201\n",
      "2022-11-08 14:55:37,723 INFO     Training average negative_sample_loss at step 324300: 0.201413\n",
      "2022-11-08 14:55:37,723 INFO     Training average loss at step 324300: 0.250307\n",
      "2022-11-08 14:55:47,255 INFO     Training average positive_sample_loss at step 324400: 0.282629\n",
      "2022-11-08 14:55:47,255 INFO     Training average negative_sample_loss at step 324400: 0.204317\n",
      "2022-11-08 14:55:47,255 INFO     Training average loss at step 324400: 0.243473\n",
      "2022-11-08 14:55:56,116 INFO     Training average positive_sample_loss at step 324500: 0.300454\n",
      "2022-11-08 14:55:56,116 INFO     Training average negative_sample_loss at step 324500: 0.209235\n",
      "2022-11-08 14:55:56,116 INFO     Training average loss at step 324500: 0.254844\n",
      "2022-11-08 14:56:05,653 INFO     Training average positive_sample_loss at step 324600: 0.298900\n",
      "2022-11-08 14:56:05,654 INFO     Training average negative_sample_loss at step 324600: 0.201189\n",
      "2022-11-08 14:56:05,654 INFO     Training average loss at step 324600: 0.250044\n",
      "2022-11-08 14:56:15,185 INFO     Training average positive_sample_loss at step 324700: 0.307014\n",
      "2022-11-08 14:56:15,185 INFO     Training average negative_sample_loss at step 324700: 0.209992\n",
      "2022-11-08 14:56:15,185 INFO     Training average loss at step 324700: 0.258503\n",
      "2022-11-08 14:56:24,717 INFO     Training average positive_sample_loss at step 324800: 0.305584\n",
      "2022-11-08 14:56:24,718 INFO     Training average negative_sample_loss at step 324800: 0.210584\n",
      "2022-11-08 14:56:24,718 INFO     Training average loss at step 324800: 0.258084\n",
      "2022-11-08 14:56:34,253 INFO     Training average positive_sample_loss at step 324900: 0.301405\n",
      "2022-11-08 14:56:34,253 INFO     Training average negative_sample_loss at step 324900: 0.206990\n",
      "2022-11-08 14:56:34,253 INFO     Training average loss at step 324900: 0.254197\n",
      "2022-11-08 14:56:43,122 INFO     Training average positive_sample_loss at step 325000: 0.291383\n",
      "2022-11-08 14:56:43,122 INFO     Training average negative_sample_loss at step 325000: 0.206904\n",
      "2022-11-08 14:56:43,122 INFO     Training average loss at step 325000: 0.249143\n",
      "2022-11-08 14:56:52,651 INFO     Training average positive_sample_loss at step 325100: 0.295638\n",
      "2022-11-08 14:56:52,651 INFO     Training average negative_sample_loss at step 325100: 0.210152\n",
      "2022-11-08 14:56:52,651 INFO     Training average loss at step 325100: 0.252895\n",
      "2022-11-08 14:57:02,183 INFO     Training average positive_sample_loss at step 325200: 0.301493\n",
      "2022-11-08 14:57:02,184 INFO     Training average negative_sample_loss at step 325200: 0.201946\n",
      "2022-11-08 14:57:02,184 INFO     Training average loss at step 325200: 0.251720\n",
      "2022-11-08 14:57:11,710 INFO     Training average positive_sample_loss at step 325300: 0.306089\n",
      "2022-11-08 14:57:11,710 INFO     Training average negative_sample_loss at step 325300: 0.204166\n",
      "2022-11-08 14:57:11,710 INFO     Training average loss at step 325300: 0.255128\n",
      "2022-11-08 14:57:21,235 INFO     Training average positive_sample_loss at step 325400: 0.304488\n",
      "2022-11-08 14:57:21,235 INFO     Training average negative_sample_loss at step 325400: 0.208951\n",
      "2022-11-08 14:57:21,235 INFO     Training average loss at step 325400: 0.256720\n",
      "2022-11-08 14:57:30,766 INFO     Training average positive_sample_loss at step 325500: 0.308453\n",
      "2022-11-08 14:57:30,766 INFO     Training average negative_sample_loss at step 325500: 0.212783\n",
      "2022-11-08 14:57:30,766 INFO     Training average loss at step 325500: 0.260618\n",
      "2022-11-08 14:57:40,295 INFO     Training average positive_sample_loss at step 325600: 0.304110\n",
      "2022-11-08 14:57:40,295 INFO     Training average negative_sample_loss at step 325600: 0.203406\n",
      "2022-11-08 14:57:40,295 INFO     Training average loss at step 325600: 0.253758\n",
      "2022-11-08 14:57:49,824 INFO     Training average positive_sample_loss at step 325700: 0.294600\n",
      "2022-11-08 14:57:49,824 INFO     Training average negative_sample_loss at step 325700: 0.203282\n",
      "2022-11-08 14:57:49,824 INFO     Training average loss at step 325700: 0.248941\n",
      "2022-11-08 14:57:59,353 INFO     Training average positive_sample_loss at step 325800: 0.294518\n",
      "2022-11-08 14:57:59,353 INFO     Training average negative_sample_loss at step 325800: 0.203848\n",
      "2022-11-08 14:57:59,353 INFO     Training average loss at step 325800: 0.249183\n",
      "2022-11-08 14:58:08,878 INFO     Training average positive_sample_loss at step 325900: 0.295293\n",
      "2022-11-08 14:58:08,878 INFO     Training average negative_sample_loss at step 325900: 0.207307\n",
      "2022-11-08 14:58:08,878 INFO     Training average loss at step 325900: 0.251300\n",
      "2022-11-08 14:58:18,405 INFO     Training average positive_sample_loss at step 326000: 0.296478\n",
      "2022-11-08 14:58:18,405 INFO     Training average negative_sample_loss at step 326000: 0.207987\n",
      "2022-11-08 14:58:18,405 INFO     Training average loss at step 326000: 0.252233\n",
      "2022-11-08 14:58:27,934 INFO     Training average positive_sample_loss at step 326100: 0.307687\n",
      "2022-11-08 14:58:27,934 INFO     Training average negative_sample_loss at step 326100: 0.203814\n",
      "2022-11-08 14:58:27,934 INFO     Training average loss at step 326100: 0.255750\n",
      "2022-11-08 14:58:37,465 INFO     Training average positive_sample_loss at step 326200: 0.305945\n",
      "2022-11-08 14:58:37,466 INFO     Training average negative_sample_loss at step 326200: 0.205110\n",
      "2022-11-08 14:58:37,466 INFO     Training average loss at step 326200: 0.255527\n",
      "2022-11-08 14:58:46,996 INFO     Training average positive_sample_loss at step 326300: 0.297699\n",
      "2022-11-08 14:58:46,997 INFO     Training average negative_sample_loss at step 326300: 0.200269\n",
      "2022-11-08 14:58:46,997 INFO     Training average loss at step 326300: 0.248984\n",
      "2022-11-08 14:58:56,525 INFO     Training average positive_sample_loss at step 326400: 0.297987\n",
      "2022-11-08 14:58:56,525 INFO     Training average negative_sample_loss at step 326400: 0.208985\n",
      "2022-11-08 14:58:56,525 INFO     Training average loss at step 326400: 0.253486\n",
      "2022-11-08 14:59:06,053 INFO     Training average positive_sample_loss at step 326500: 0.311810\n",
      "2022-11-08 14:59:06,053 INFO     Training average negative_sample_loss at step 326500: 0.206656\n",
      "2022-11-08 14:59:06,054 INFO     Training average loss at step 326500: 0.259233\n",
      "2022-11-08 14:59:15,582 INFO     Training average positive_sample_loss at step 326600: 0.300434\n",
      "2022-11-08 14:59:15,582 INFO     Training average negative_sample_loss at step 326600: 0.207557\n",
      "2022-11-08 14:59:15,582 INFO     Training average loss at step 326600: 0.253996\n",
      "2022-11-08 14:59:25,111 INFO     Training average positive_sample_loss at step 326700: 0.298858\n",
      "2022-11-08 14:59:25,111 INFO     Training average negative_sample_loss at step 326700: 0.209521\n",
      "2022-11-08 14:59:25,111 INFO     Training average loss at step 326700: 0.254190\n",
      "2022-11-08 14:59:34,642 INFO     Training average positive_sample_loss at step 326800: 0.300527\n",
      "2022-11-08 14:59:34,642 INFO     Training average negative_sample_loss at step 326800: 0.208470\n",
      "2022-11-08 14:59:34,642 INFO     Training average loss at step 326800: 0.254498\n",
      "2022-11-08 14:59:44,171 INFO     Training average positive_sample_loss at step 326900: 0.299967\n",
      "2022-11-08 14:59:44,171 INFO     Training average negative_sample_loss at step 326900: 0.204744\n",
      "2022-11-08 14:59:44,171 INFO     Training average loss at step 326900: 0.252355\n",
      "2022-11-08 14:59:56,637 INFO     Training average positive_sample_loss at step 327000: 0.294300\n",
      "2022-11-08 14:59:56,637 INFO     Training average negative_sample_loss at step 327000: 0.208109\n",
      "2022-11-08 14:59:56,637 INFO     Training average loss at step 327000: 0.251204\n",
      "2022-11-08 15:00:06,168 INFO     Training average positive_sample_loss at step 327100: 0.301013\n",
      "2022-11-08 15:00:06,168 INFO     Training average negative_sample_loss at step 327100: 0.208937\n",
      "2022-11-08 15:00:06,168 INFO     Training average loss at step 327100: 0.254975\n",
      "2022-11-08 15:00:15,697 INFO     Training average positive_sample_loss at step 327200: 0.317667\n",
      "2022-11-08 15:00:15,697 INFO     Training average negative_sample_loss at step 327200: 0.206452\n",
      "2022-11-08 15:00:15,697 INFO     Training average loss at step 327200: 0.262060\n",
      "2022-11-08 15:00:25,226 INFO     Training average positive_sample_loss at step 327300: 0.319134\n",
      "2022-11-08 15:00:25,226 INFO     Training average negative_sample_loss at step 327300: 0.205958\n",
      "2022-11-08 15:00:25,226 INFO     Training average loss at step 327300: 0.262546\n",
      "2022-11-08 15:00:34,757 INFO     Training average positive_sample_loss at step 327400: 0.308718\n",
      "2022-11-08 15:00:34,757 INFO     Training average negative_sample_loss at step 327400: 0.212313\n",
      "2022-11-08 15:00:34,757 INFO     Training average loss at step 327400: 0.260516\n",
      "2022-11-08 15:00:44,285 INFO     Training average positive_sample_loss at step 327500: 0.294015\n",
      "2022-11-08 15:00:44,286 INFO     Training average negative_sample_loss at step 327500: 0.203901\n",
      "2022-11-08 15:00:44,286 INFO     Training average loss at step 327500: 0.248958\n",
      "2022-11-08 15:00:53,813 INFO     Training average positive_sample_loss at step 327600: 0.306923\n",
      "2022-11-08 15:00:53,813 INFO     Training average negative_sample_loss at step 327600: 0.206695\n",
      "2022-11-08 15:00:53,813 INFO     Training average loss at step 327600: 0.256809\n",
      "2022-11-08 15:01:03,346 INFO     Training average positive_sample_loss at step 327700: 0.298329\n",
      "2022-11-08 15:01:03,346 INFO     Training average negative_sample_loss at step 327700: 0.207148\n",
      "2022-11-08 15:01:03,346 INFO     Training average loss at step 327700: 0.252739\n",
      "2022-11-08 15:01:12,872 INFO     Training average positive_sample_loss at step 327800: 0.299274\n",
      "2022-11-08 15:01:12,872 INFO     Training average negative_sample_loss at step 327800: 0.207252\n",
      "2022-11-08 15:01:12,872 INFO     Training average loss at step 327800: 0.253263\n",
      "2022-11-08 15:01:22,399 INFO     Training average positive_sample_loss at step 327900: 0.292970\n",
      "2022-11-08 15:01:22,399 INFO     Training average negative_sample_loss at step 327900: 0.205598\n",
      "2022-11-08 15:01:22,399 INFO     Training average loss at step 327900: 0.249284\n",
      "2022-11-08 15:01:31,929 INFO     Training average positive_sample_loss at step 328000: 0.305325\n",
      "2022-11-08 15:01:31,930 INFO     Training average negative_sample_loss at step 328000: 0.206031\n",
      "2022-11-08 15:01:31,930 INFO     Training average loss at step 328000: 0.255678\n",
      "2022-11-08 15:01:41,458 INFO     Training average positive_sample_loss at step 328100: 0.288542\n",
      "2022-11-08 15:01:41,458 INFO     Training average negative_sample_loss at step 328100: 0.215417\n",
      "2022-11-08 15:01:41,458 INFO     Training average loss at step 328100: 0.251980\n",
      "2022-11-08 15:01:50,988 INFO     Training average positive_sample_loss at step 328200: 0.303025\n",
      "2022-11-08 15:01:50,988 INFO     Training average negative_sample_loss at step 328200: 0.203663\n",
      "2022-11-08 15:01:50,988 INFO     Training average loss at step 328200: 0.253344\n",
      "2022-11-08 15:02:00,521 INFO     Training average positive_sample_loss at step 328300: 0.292692\n",
      "2022-11-08 15:02:00,521 INFO     Training average negative_sample_loss at step 328300: 0.202205\n",
      "2022-11-08 15:02:00,521 INFO     Training average loss at step 328300: 0.247449\n",
      "2022-11-08 15:02:10,046 INFO     Training average positive_sample_loss at step 328400: 0.301875\n",
      "2022-11-08 15:02:10,046 INFO     Training average negative_sample_loss at step 328400: 0.196817\n",
      "2022-11-08 15:02:10,046 INFO     Training average loss at step 328400: 0.249346\n",
      "2022-11-08 15:02:19,577 INFO     Training average positive_sample_loss at step 328500: 0.305740\n",
      "2022-11-08 15:02:19,577 INFO     Training average negative_sample_loss at step 328500: 0.205107\n",
      "2022-11-08 15:02:19,577 INFO     Training average loss at step 328500: 0.255423\n",
      "2022-11-08 15:02:29,106 INFO     Training average positive_sample_loss at step 328600: 0.295771\n",
      "2022-11-08 15:02:29,106 INFO     Training average negative_sample_loss at step 328600: 0.207054\n",
      "2022-11-08 15:02:29,106 INFO     Training average loss at step 328600: 0.251413\n",
      "2022-11-08 15:02:38,633 INFO     Training average positive_sample_loss at step 328700: 0.311776\n",
      "2022-11-08 15:02:38,633 INFO     Training average negative_sample_loss at step 328700: 0.203310\n",
      "2022-11-08 15:02:38,633 INFO     Training average loss at step 328700: 0.257543\n",
      "2022-11-08 15:02:48,163 INFO     Training average positive_sample_loss at step 328800: 0.298434\n",
      "2022-11-08 15:02:48,164 INFO     Training average negative_sample_loss at step 328800: 0.204780\n",
      "2022-11-08 15:02:48,164 INFO     Training average loss at step 328800: 0.251607\n",
      "2022-11-08 15:02:57,694 INFO     Training average positive_sample_loss at step 328900: 0.301314\n",
      "2022-11-08 15:02:57,694 INFO     Training average negative_sample_loss at step 328900: 0.213176\n",
      "2022-11-08 15:02:57,694 INFO     Training average loss at step 328900: 0.257245\n",
      "2022-11-08 15:03:07,223 INFO     Training average positive_sample_loss at step 329000: 0.312983\n",
      "2022-11-08 15:03:07,223 INFO     Training average negative_sample_loss at step 329000: 0.205427\n",
      "2022-11-08 15:03:07,223 INFO     Training average loss at step 329000: 0.259205\n",
      "2022-11-08 15:03:16,753 INFO     Training average positive_sample_loss at step 329100: 0.303645\n",
      "2022-11-08 15:03:16,753 INFO     Training average negative_sample_loss at step 329100: 0.204119\n",
      "2022-11-08 15:03:16,753 INFO     Training average loss at step 329100: 0.253882\n",
      "2022-11-08 15:03:26,282 INFO     Training average positive_sample_loss at step 329200: 0.315339\n",
      "2022-11-08 15:03:26,282 INFO     Training average negative_sample_loss at step 329200: 0.208033\n",
      "2022-11-08 15:03:26,282 INFO     Training average loss at step 329200: 0.261686\n",
      "2022-11-08 15:03:35,814 INFO     Training average positive_sample_loss at step 329300: 0.305140\n",
      "2022-11-08 15:03:35,814 INFO     Training average negative_sample_loss at step 329300: 0.212475\n",
      "2022-11-08 15:03:35,814 INFO     Training average loss at step 329300: 0.258807\n",
      "2022-11-08 15:03:45,343 INFO     Training average positive_sample_loss at step 329400: 0.317540\n",
      "2022-11-08 15:03:45,343 INFO     Training average negative_sample_loss at step 329400: 0.204787\n",
      "2022-11-08 15:03:45,343 INFO     Training average loss at step 329400: 0.261164\n",
      "2022-11-08 15:03:54,871 INFO     Training average positive_sample_loss at step 329500: 0.306534\n",
      "2022-11-08 15:03:54,871 INFO     Training average negative_sample_loss at step 329500: 0.204036\n",
      "2022-11-08 15:03:54,871 INFO     Training average loss at step 329500: 0.255285\n",
      "2022-11-08 15:04:04,402 INFO     Training average positive_sample_loss at step 329600: 0.309661\n",
      "2022-11-08 15:04:04,402 INFO     Training average negative_sample_loss at step 329600: 0.202553\n",
      "2022-11-08 15:04:04,402 INFO     Training average loss at step 329600: 0.256107\n",
      "2022-11-08 15:04:13,929 INFO     Training average positive_sample_loss at step 329700: 0.303702\n",
      "2022-11-08 15:04:13,929 INFO     Training average negative_sample_loss at step 329700: 0.201775\n",
      "2022-11-08 15:04:13,929 INFO     Training average loss at step 329700: 0.252739\n",
      "2022-11-08 15:04:23,461 INFO     Training average positive_sample_loss at step 329800: 0.301407\n",
      "2022-11-08 15:04:23,461 INFO     Training average negative_sample_loss at step 329800: 0.206086\n",
      "2022-11-08 15:04:23,461 INFO     Training average loss at step 329800: 0.253747\n",
      "2022-11-08 15:04:32,989 INFO     Training average positive_sample_loss at step 329900: 0.295878\n",
      "2022-11-08 15:04:32,989 INFO     Training average negative_sample_loss at step 329900: 0.208688\n",
      "2022-11-08 15:04:32,989 INFO     Training average loss at step 329900: 0.252283\n",
      "2022-11-08 15:04:44,572 INFO     Training average positive_sample_loss at step 330000: 0.292360\n",
      "2022-11-08 15:04:44,572 INFO     Training average negative_sample_loss at step 330000: 0.209921\n",
      "2022-11-08 15:04:44,572 INFO     Training average loss at step 330000: 0.251141\n",
      "2022-11-08 15:04:54,104 INFO     Training average positive_sample_loss at step 330100: 0.298896\n",
      "2022-11-08 15:04:54,104 INFO     Training average negative_sample_loss at step 330100: 0.204091\n",
      "2022-11-08 15:04:54,104 INFO     Training average loss at step 330100: 0.251493\n",
      "2022-11-08 15:05:03,637 INFO     Training average positive_sample_loss at step 330200: 0.300371\n",
      "2022-11-08 15:05:03,637 INFO     Training average negative_sample_loss at step 330200: 0.203449\n",
      "2022-11-08 15:05:03,637 INFO     Training average loss at step 330200: 0.251910\n",
      "2022-11-08 15:05:13,171 INFO     Training average positive_sample_loss at step 330300: 0.309662\n",
      "2022-11-08 15:05:13,171 INFO     Training average negative_sample_loss at step 330300: 0.204368\n",
      "2022-11-08 15:05:13,171 INFO     Training average loss at step 330300: 0.257015\n",
      "2022-11-08 15:05:21,905 INFO     Training average positive_sample_loss at step 330400: 0.312098\n",
      "2022-11-08 15:05:21,905 INFO     Training average negative_sample_loss at step 330400: 0.202553\n",
      "2022-11-08 15:05:21,905 INFO     Training average loss at step 330400: 0.257325\n",
      "2022-11-08 15:05:31,435 INFO     Training average positive_sample_loss at step 330500: 0.302493\n",
      "2022-11-08 15:05:31,435 INFO     Training average negative_sample_loss at step 330500: 0.200736\n",
      "2022-11-08 15:05:31,435 INFO     Training average loss at step 330500: 0.251615\n",
      "2022-11-08 15:05:40,962 INFO     Training average positive_sample_loss at step 330600: 0.303263\n",
      "2022-11-08 15:05:40,962 INFO     Training average negative_sample_loss at step 330600: 0.210267\n",
      "2022-11-08 15:05:40,962 INFO     Training average loss at step 330600: 0.256765\n",
      "2022-11-08 15:05:50,491 INFO     Training average positive_sample_loss at step 330700: 0.298840\n",
      "2022-11-08 15:05:50,491 INFO     Training average negative_sample_loss at step 330700: 0.205353\n",
      "2022-11-08 15:05:50,491 INFO     Training average loss at step 330700: 0.252097\n",
      "2022-11-08 15:06:00,021 INFO     Training average positive_sample_loss at step 330800: 0.299413\n",
      "2022-11-08 15:06:00,021 INFO     Training average negative_sample_loss at step 330800: 0.206969\n",
      "2022-11-08 15:06:00,021 INFO     Training average loss at step 330800: 0.253191\n",
      "2022-11-08 15:06:09,551 INFO     Training average positive_sample_loss at step 330900: 0.323099\n",
      "2022-11-08 15:06:09,551 INFO     Training average negative_sample_loss at step 330900: 0.204017\n",
      "2022-11-08 15:06:09,551 INFO     Training average loss at step 330900: 0.263558\n",
      "2022-11-08 15:06:19,082 INFO     Training average positive_sample_loss at step 331000: 0.310221\n",
      "2022-11-08 15:06:19,082 INFO     Training average negative_sample_loss at step 331000: 0.209346\n",
      "2022-11-08 15:06:19,082 INFO     Training average loss at step 331000: 0.259784\n",
      "2022-11-08 15:06:28,610 INFO     Training average positive_sample_loss at step 331100: 0.308251\n",
      "2022-11-08 15:06:28,610 INFO     Training average negative_sample_loss at step 331100: 0.206632\n",
      "2022-11-08 15:06:28,610 INFO     Training average loss at step 331100: 0.257442\n",
      "2022-11-08 15:06:38,135 INFO     Training average positive_sample_loss at step 331200: 0.295980\n",
      "2022-11-08 15:06:38,135 INFO     Training average negative_sample_loss at step 331200: 0.207276\n",
      "2022-11-08 15:06:38,135 INFO     Training average loss at step 331200: 0.251628\n",
      "2022-11-08 15:06:47,664 INFO     Training average positive_sample_loss at step 331300: 0.300071\n",
      "2022-11-08 15:06:47,664 INFO     Training average negative_sample_loss at step 331300: 0.206627\n",
      "2022-11-08 15:06:47,664 INFO     Training average loss at step 331300: 0.253349\n",
      "2022-11-08 15:06:57,193 INFO     Training average positive_sample_loss at step 331400: 0.289072\n",
      "2022-11-08 15:06:57,193 INFO     Training average negative_sample_loss at step 331400: 0.205494\n",
      "2022-11-08 15:06:57,193 INFO     Training average loss at step 331400: 0.247283\n",
      "2022-11-08 15:07:06,723 INFO     Training average positive_sample_loss at step 331500: 0.309031\n",
      "2022-11-08 15:07:06,723 INFO     Training average negative_sample_loss at step 331500: 0.203254\n",
      "2022-11-08 15:07:06,723 INFO     Training average loss at step 331500: 0.256142\n",
      "2022-11-08 15:07:16,253 INFO     Training average positive_sample_loss at step 331600: 0.296175\n",
      "2022-11-08 15:07:16,253 INFO     Training average negative_sample_loss at step 331600: 0.205872\n",
      "2022-11-08 15:07:16,253 INFO     Training average loss at step 331600: 0.251023\n",
      "2022-11-08 15:07:28,537 INFO     Training average positive_sample_loss at step 331700: 0.293043\n",
      "2022-11-08 15:07:28,537 INFO     Training average negative_sample_loss at step 331700: 0.203058\n",
      "2022-11-08 15:07:28,537 INFO     Training average loss at step 331700: 0.248051\n",
      "2022-11-08 15:07:38,069 INFO     Training average positive_sample_loss at step 331800: 0.314728\n",
      "2022-11-08 15:07:38,069 INFO     Training average negative_sample_loss at step 331800: 0.204102\n",
      "2022-11-08 15:07:38,069 INFO     Training average loss at step 331800: 0.259415\n",
      "2022-11-08 15:07:47,601 INFO     Training average positive_sample_loss at step 331900: 0.301482\n",
      "2022-11-08 15:07:47,601 INFO     Training average negative_sample_loss at step 331900: 0.203739\n",
      "2022-11-08 15:07:47,601 INFO     Training average loss at step 331900: 0.252611\n",
      "2022-11-08 15:07:57,136 INFO     Training average positive_sample_loss at step 332000: 0.301903\n",
      "2022-11-08 15:07:57,136 INFO     Training average negative_sample_loss at step 332000: 0.203344\n",
      "2022-11-08 15:07:57,136 INFO     Training average loss at step 332000: 0.252624\n",
      "2022-11-08 15:08:06,687 INFO     Training average positive_sample_loss at step 332100: 0.300169\n",
      "2022-11-08 15:08:06,688 INFO     Training average negative_sample_loss at step 332100: 0.205335\n",
      "2022-11-08 15:08:06,688 INFO     Training average loss at step 332100: 0.252752\n",
      "2022-11-08 15:08:16,475 INFO     Training average positive_sample_loss at step 332200: 0.312120\n",
      "2022-11-08 15:08:16,475 INFO     Training average negative_sample_loss at step 332200: 0.205019\n",
      "2022-11-08 15:08:16,475 INFO     Training average loss at step 332200: 0.258570\n",
      "2022-11-08 15:08:26,257 INFO     Training average positive_sample_loss at step 332300: 0.303000\n",
      "2022-11-08 15:08:26,257 INFO     Training average negative_sample_loss at step 332300: 0.202809\n",
      "2022-11-08 15:08:26,257 INFO     Training average loss at step 332300: 0.252905\n",
      "2022-11-08 15:08:36,035 INFO     Training average positive_sample_loss at step 332400: 0.300723\n",
      "2022-11-08 15:08:36,035 INFO     Training average negative_sample_loss at step 332400: 0.205664\n",
      "2022-11-08 15:08:36,035 INFO     Training average loss at step 332400: 0.253193\n",
      "2022-11-08 15:08:45,687 INFO     Training average positive_sample_loss at step 332500: 0.305546\n",
      "2022-11-08 15:08:45,687 INFO     Training average negative_sample_loss at step 332500: 0.207942\n",
      "2022-11-08 15:08:45,687 INFO     Training average loss at step 332500: 0.256744\n",
      "2022-11-08 15:08:55,221 INFO     Training average positive_sample_loss at step 332600: 0.301936\n",
      "2022-11-08 15:08:55,221 INFO     Training average negative_sample_loss at step 332600: 0.201915\n",
      "2022-11-08 15:08:55,221 INFO     Training average loss at step 332600: 0.251925\n",
      "2022-11-08 15:09:04,755 INFO     Training average positive_sample_loss at step 332700: 0.299785\n",
      "2022-11-08 15:09:04,755 INFO     Training average negative_sample_loss at step 332700: 0.202636\n",
      "2022-11-08 15:09:04,755 INFO     Training average loss at step 332700: 0.251211\n",
      "2022-11-08 15:09:14,287 INFO     Training average positive_sample_loss at step 332800: 0.295461\n",
      "2022-11-08 15:09:14,287 INFO     Training average negative_sample_loss at step 332800: 0.211678\n",
      "2022-11-08 15:09:14,287 INFO     Training average loss at step 332800: 0.253569\n",
      "2022-11-08 15:09:23,817 INFO     Training average positive_sample_loss at step 332900: 0.320132\n",
      "2022-11-08 15:09:23,817 INFO     Training average negative_sample_loss at step 332900: 0.200504\n",
      "2022-11-08 15:09:23,817 INFO     Training average loss at step 332900: 0.260318\n",
      "2022-11-08 15:09:33,571 INFO     Training average positive_sample_loss at step 333000: 0.324475\n",
      "2022-11-08 15:09:33,571 INFO     Training average negative_sample_loss at step 333000: 0.204852\n",
      "2022-11-08 15:09:33,571 INFO     Training average loss at step 333000: 0.264663\n",
      "2022-11-08 15:09:43,352 INFO     Training average positive_sample_loss at step 333100: 0.314152\n",
      "2022-11-08 15:09:43,352 INFO     Training average negative_sample_loss at step 333100: 0.199812\n",
      "2022-11-08 15:09:43,352 INFO     Training average loss at step 333100: 0.256982\n",
      "2022-11-08 15:09:53,143 INFO     Training average positive_sample_loss at step 333200: 0.304741\n",
      "2022-11-08 15:09:53,143 INFO     Training average negative_sample_loss at step 333200: 0.207830\n",
      "2022-11-08 15:09:53,143 INFO     Training average loss at step 333200: 0.256286\n",
      "2022-11-08 15:10:02,927 INFO     Training average positive_sample_loss at step 333300: 0.304522\n",
      "2022-11-08 15:10:02,927 INFO     Training average negative_sample_loss at step 333300: 0.203085\n",
      "2022-11-08 15:10:02,927 INFO     Training average loss at step 333300: 0.253803\n",
      "2022-11-08 15:10:12,707 INFO     Training average positive_sample_loss at step 333400: 0.299267\n",
      "2022-11-08 15:10:12,707 INFO     Training average negative_sample_loss at step 333400: 0.205352\n",
      "2022-11-08 15:10:12,707 INFO     Training average loss at step 333400: 0.252309\n",
      "2022-11-08 15:10:22,451 INFO     Training average positive_sample_loss at step 333500: 0.303262\n",
      "2022-11-08 15:10:22,451 INFO     Training average negative_sample_loss at step 333500: 0.210785\n",
      "2022-11-08 15:10:22,451 INFO     Training average loss at step 333500: 0.257024\n",
      "2022-11-08 15:10:31,986 INFO     Training average positive_sample_loss at step 333600: 0.284902\n",
      "2022-11-08 15:10:31,986 INFO     Training average negative_sample_loss at step 333600: 0.206497\n",
      "2022-11-08 15:10:31,986 INFO     Training average loss at step 333600: 0.245700\n",
      "2022-11-08 15:10:41,522 INFO     Training average positive_sample_loss at step 333700: 0.300564\n",
      "2022-11-08 15:10:41,522 INFO     Training average negative_sample_loss at step 333700: 0.207595\n",
      "2022-11-08 15:10:41,522 INFO     Training average loss at step 333700: 0.254079\n",
      "2022-11-08 15:10:51,056 INFO     Training average positive_sample_loss at step 333800: 0.315142\n",
      "2022-11-08 15:10:51,056 INFO     Training average negative_sample_loss at step 333800: 0.200428\n",
      "2022-11-08 15:10:51,056 INFO     Training average loss at step 333800: 0.257785\n",
      "2022-11-08 15:11:00,587 INFO     Training average positive_sample_loss at step 333900: 0.291514\n",
      "2022-11-08 15:11:00,588 INFO     Training average negative_sample_loss at step 333900: 0.203896\n",
      "2022-11-08 15:11:00,588 INFO     Training average loss at step 333900: 0.247705\n",
      "2022-11-08 15:11:10,120 INFO     Training average positive_sample_loss at step 334000: 0.306502\n",
      "2022-11-08 15:11:10,120 INFO     Training average negative_sample_loss at step 334000: 0.202299\n",
      "2022-11-08 15:11:10,120 INFO     Training average loss at step 334000: 0.254401\n",
      "2022-11-08 15:11:19,654 INFO     Training average positive_sample_loss at step 334100: 0.300873\n",
      "2022-11-08 15:11:19,654 INFO     Training average negative_sample_loss at step 334100: 0.205315\n",
      "2022-11-08 15:11:19,654 INFO     Training average loss at step 334100: 0.253094\n",
      "2022-11-08 15:11:29,190 INFO     Training average positive_sample_loss at step 334200: 0.313354\n",
      "2022-11-08 15:11:29,190 INFO     Training average negative_sample_loss at step 334200: 0.205808\n",
      "2022-11-08 15:11:29,190 INFO     Training average loss at step 334200: 0.259581\n",
      "2022-11-08 15:11:38,727 INFO     Training average positive_sample_loss at step 334300: 0.316126\n",
      "2022-11-08 15:11:38,728 INFO     Training average negative_sample_loss at step 334300: 0.198997\n",
      "2022-11-08 15:11:38,728 INFO     Training average loss at step 334300: 0.257562\n",
      "2022-11-08 15:11:48,261 INFO     Training average positive_sample_loss at step 334400: 0.302077\n",
      "2022-11-08 15:11:48,261 INFO     Training average negative_sample_loss at step 334400: 0.203145\n",
      "2022-11-08 15:11:48,261 INFO     Training average loss at step 334400: 0.252611\n",
      "2022-11-08 15:11:57,791 INFO     Training average positive_sample_loss at step 334500: 0.313962\n",
      "2022-11-08 15:11:57,791 INFO     Training average negative_sample_loss at step 334500: 0.206782\n",
      "2022-11-08 15:11:57,791 INFO     Training average loss at step 334500: 0.260372\n",
      "2022-11-08 15:12:07,326 INFO     Training average positive_sample_loss at step 334600: 0.309458\n",
      "2022-11-08 15:12:07,326 INFO     Training average negative_sample_loss at step 334600: 0.203440\n",
      "2022-11-08 15:12:07,326 INFO     Training average loss at step 334600: 0.256449\n",
      "2022-11-08 15:12:16,859 INFO     Training average positive_sample_loss at step 334700: 0.298899\n",
      "2022-11-08 15:12:16,859 INFO     Training average negative_sample_loss at step 334700: 0.205182\n",
      "2022-11-08 15:12:16,859 INFO     Training average loss at step 334700: 0.252040\n",
      "2022-11-08 15:12:26,395 INFO     Training average positive_sample_loss at step 334800: 0.306859\n",
      "2022-11-08 15:12:26,395 INFO     Training average negative_sample_loss at step 334800: 0.202453\n",
      "2022-11-08 15:12:26,395 INFO     Training average loss at step 334800: 0.254656\n",
      "2022-11-08 15:12:35,929 INFO     Training average positive_sample_loss at step 334900: 0.292362\n",
      "2022-11-08 15:12:35,929 INFO     Training average negative_sample_loss at step 334900: 0.204365\n",
      "2022-11-08 15:12:35,930 INFO     Training average loss at step 334900: 0.248363\n",
      "2022-11-08 15:12:45,459 INFO     Training average positive_sample_loss at step 335000: 0.294375\n",
      "2022-11-08 15:12:45,459 INFO     Training average negative_sample_loss at step 335000: 0.206152\n",
      "2022-11-08 15:12:45,459 INFO     Training average loss at step 335000: 0.250263\n",
      "2022-11-08 15:12:54,989 INFO     Training average positive_sample_loss at step 335100: 0.301557\n",
      "2022-11-08 15:12:54,989 INFO     Training average negative_sample_loss at step 335100: 0.205767\n",
      "2022-11-08 15:12:54,989 INFO     Training average loss at step 335100: 0.253662\n",
      "2022-11-08 15:13:04,524 INFO     Training average positive_sample_loss at step 335200: 0.303011\n",
      "2022-11-08 15:13:04,524 INFO     Training average negative_sample_loss at step 335200: 0.202108\n",
      "2022-11-08 15:13:04,524 INFO     Training average loss at step 335200: 0.252559\n",
      "2022-11-08 15:13:14,060 INFO     Training average positive_sample_loss at step 335300: 0.304692\n",
      "2022-11-08 15:13:14,060 INFO     Training average negative_sample_loss at step 335300: 0.195467\n",
      "2022-11-08 15:13:14,060 INFO     Training average loss at step 335300: 0.250080\n",
      "2022-11-08 15:13:22,934 INFO     Training average positive_sample_loss at step 335400: 0.304166\n",
      "2022-11-08 15:13:22,934 INFO     Training average negative_sample_loss at step 335400: 0.205295\n",
      "2022-11-08 15:13:22,934 INFO     Training average loss at step 335400: 0.254730\n",
      "2022-11-08 15:13:32,468 INFO     Training average positive_sample_loss at step 335500: 0.315732\n",
      "2022-11-08 15:13:32,468 INFO     Training average negative_sample_loss at step 335500: 0.205283\n",
      "2022-11-08 15:13:32,468 INFO     Training average loss at step 335500: 0.260507\n",
      "2022-11-08 15:13:42,000 INFO     Training average positive_sample_loss at step 335600: 0.321234\n",
      "2022-11-08 15:13:42,000 INFO     Training average negative_sample_loss at step 335600: 0.204761\n",
      "2022-11-08 15:13:42,000 INFO     Training average loss at step 335600: 0.262998\n",
      "2022-11-08 15:13:51,533 INFO     Training average positive_sample_loss at step 335700: 0.300441\n",
      "2022-11-08 15:13:51,533 INFO     Training average negative_sample_loss at step 335700: 0.203791\n",
      "2022-11-08 15:13:51,533 INFO     Training average loss at step 335700: 0.252116\n",
      "2022-11-08 15:14:01,071 INFO     Training average positive_sample_loss at step 335800: 0.297383\n",
      "2022-11-08 15:14:01,072 INFO     Training average negative_sample_loss at step 335800: 0.208571\n",
      "2022-11-08 15:14:01,072 INFO     Training average loss at step 335800: 0.252977\n",
      "2022-11-08 15:14:09,963 INFO     Training average positive_sample_loss at step 335900: 0.299274\n",
      "2022-11-08 15:14:09,963 INFO     Training average negative_sample_loss at step 335900: 0.204121\n",
      "2022-11-08 15:14:09,963 INFO     Training average loss at step 335900: 0.251697\n",
      "2022-11-08 15:14:19,493 INFO     Training average positive_sample_loss at step 336000: 0.315940\n",
      "2022-11-08 15:14:19,493 INFO     Training average negative_sample_loss at step 336000: 0.202395\n",
      "2022-11-08 15:14:19,493 INFO     Training average loss at step 336000: 0.259167\n",
      "2022-11-08 15:14:29,029 INFO     Training average positive_sample_loss at step 336100: 0.299677\n",
      "2022-11-08 15:14:29,030 INFO     Training average negative_sample_loss at step 336100: 0.200232\n",
      "2022-11-08 15:14:29,030 INFO     Training average loss at step 336100: 0.249955\n",
      "2022-11-08 15:14:38,563 INFO     Training average positive_sample_loss at step 336200: 0.311037\n",
      "2022-11-08 15:14:38,563 INFO     Training average negative_sample_loss at step 336200: 0.206068\n",
      "2022-11-08 15:14:38,563 INFO     Training average loss at step 336200: 0.258552\n",
      "2022-11-08 15:14:48,097 INFO     Training average positive_sample_loss at step 336300: 0.300874\n",
      "2022-11-08 15:14:48,097 INFO     Training average negative_sample_loss at step 336300: 0.205972\n",
      "2022-11-08 15:14:48,097 INFO     Training average loss at step 336300: 0.253423\n",
      "2022-11-08 15:15:00,557 INFO     Training average positive_sample_loss at step 336400: 0.294894\n",
      "2022-11-08 15:15:00,558 INFO     Training average negative_sample_loss at step 336400: 0.200495\n",
      "2022-11-08 15:15:00,558 INFO     Training average loss at step 336400: 0.247694\n",
      "2022-11-08 15:15:10,092 INFO     Training average positive_sample_loss at step 336500: 0.301346\n",
      "2022-11-08 15:15:10,092 INFO     Training average negative_sample_loss at step 336500: 0.206719\n",
      "2022-11-08 15:15:10,092 INFO     Training average loss at step 336500: 0.254033\n",
      "2022-11-08 15:15:19,617 INFO     Training average positive_sample_loss at step 336600: 0.304801\n",
      "2022-11-08 15:15:19,618 INFO     Training average negative_sample_loss at step 336600: 0.203908\n",
      "2022-11-08 15:15:19,618 INFO     Training average loss at step 336600: 0.254355\n",
      "2022-11-08 15:15:29,149 INFO     Training average positive_sample_loss at step 336700: 0.294049\n",
      "2022-11-08 15:15:29,149 INFO     Training average negative_sample_loss at step 336700: 0.213113\n",
      "2022-11-08 15:15:29,149 INFO     Training average loss at step 336700: 0.253581\n",
      "2022-11-08 15:15:38,679 INFO     Training average positive_sample_loss at step 336800: 0.298137\n",
      "2022-11-08 15:15:38,679 INFO     Training average negative_sample_loss at step 336800: 0.200618\n",
      "2022-11-08 15:15:38,679 INFO     Training average loss at step 336800: 0.249377\n",
      "2022-11-08 15:15:48,203 INFO     Training average positive_sample_loss at step 336900: 0.306760\n",
      "2022-11-08 15:15:48,204 INFO     Training average negative_sample_loss at step 336900: 0.204558\n",
      "2022-11-08 15:15:48,204 INFO     Training average loss at step 336900: 0.255659\n",
      "2022-11-08 15:15:57,731 INFO     Training average positive_sample_loss at step 337000: 0.310769\n",
      "2022-11-08 15:15:57,731 INFO     Training average negative_sample_loss at step 337000: 0.203458\n",
      "2022-11-08 15:15:57,731 INFO     Training average loss at step 337000: 0.257113\n",
      "2022-11-08 15:16:07,264 INFO     Training average positive_sample_loss at step 337100: 0.308954\n",
      "2022-11-08 15:16:07,264 INFO     Training average negative_sample_loss at step 337100: 0.201799\n",
      "2022-11-08 15:16:07,264 INFO     Training average loss at step 337100: 0.255377\n",
      "2022-11-08 15:16:16,790 INFO     Training average positive_sample_loss at step 337200: 0.313847\n",
      "2022-11-08 15:16:16,790 INFO     Training average negative_sample_loss at step 337200: 0.203560\n",
      "2022-11-08 15:16:16,790 INFO     Training average loss at step 337200: 0.258704\n",
      "2022-11-08 15:16:26,322 INFO     Training average positive_sample_loss at step 337300: 0.312594\n",
      "2022-11-08 15:16:26,322 INFO     Training average negative_sample_loss at step 337300: 0.208113\n",
      "2022-11-08 15:16:26,322 INFO     Training average loss at step 337300: 0.260353\n",
      "2022-11-08 15:16:35,849 INFO     Training average positive_sample_loss at step 337400: 0.312356\n",
      "2022-11-08 15:16:35,849 INFO     Training average negative_sample_loss at step 337400: 0.199311\n",
      "2022-11-08 15:16:35,849 INFO     Training average loss at step 337400: 0.255834\n",
      "2022-11-08 15:16:45,375 INFO     Training average positive_sample_loss at step 337500: 0.309146\n",
      "2022-11-08 15:16:45,375 INFO     Training average negative_sample_loss at step 337500: 0.204173\n",
      "2022-11-08 15:16:45,375 INFO     Training average loss at step 337500: 0.256659\n",
      "2022-11-08 15:16:54,905 INFO     Training average positive_sample_loss at step 337600: 0.306794\n",
      "2022-11-08 15:16:54,905 INFO     Training average negative_sample_loss at step 337600: 0.200143\n",
      "2022-11-08 15:16:54,905 INFO     Training average loss at step 337600: 0.253469\n",
      "2022-11-08 15:17:04,436 INFO     Training average positive_sample_loss at step 337700: 0.306907\n",
      "2022-11-08 15:17:04,436 INFO     Training average negative_sample_loss at step 337700: 0.201307\n",
      "2022-11-08 15:17:04,436 INFO     Training average loss at step 337700: 0.254107\n",
      "2022-11-08 15:17:13,967 INFO     Training average positive_sample_loss at step 337800: 0.307651\n",
      "2022-11-08 15:17:13,967 INFO     Training average negative_sample_loss at step 337800: 0.206078\n",
      "2022-11-08 15:17:13,967 INFO     Training average loss at step 337800: 0.256864\n",
      "2022-11-08 15:17:23,495 INFO     Training average positive_sample_loss at step 337900: 0.300214\n",
      "2022-11-08 15:17:23,495 INFO     Training average negative_sample_loss at step 337900: 0.205696\n",
      "2022-11-08 15:17:23,495 INFO     Training average loss at step 337900: 0.252955\n",
      "2022-11-08 15:17:33,022 INFO     Training average positive_sample_loss at step 338000: 0.308821\n",
      "2022-11-08 15:17:33,022 INFO     Training average negative_sample_loss at step 338000: 0.207867\n",
      "2022-11-08 15:17:33,022 INFO     Training average loss at step 338000: 0.258344\n",
      "2022-11-08 15:17:42,555 INFO     Training average positive_sample_loss at step 338100: 0.317262\n",
      "2022-11-08 15:17:42,555 INFO     Training average negative_sample_loss at step 338100: 0.206975\n",
      "2022-11-08 15:17:42,555 INFO     Training average loss at step 338100: 0.262119\n",
      "2022-11-08 15:17:52,084 INFO     Training average positive_sample_loss at step 338200: 0.314947\n",
      "2022-11-08 15:17:52,084 INFO     Training average negative_sample_loss at step 338200: 0.204635\n",
      "2022-11-08 15:17:52,084 INFO     Training average loss at step 338200: 0.259791\n",
      "2022-11-08 15:18:01,614 INFO     Training average positive_sample_loss at step 338300: 0.312491\n",
      "2022-11-08 15:18:01,614 INFO     Training average negative_sample_loss at step 338300: 0.206839\n",
      "2022-11-08 15:18:01,614 INFO     Training average loss at step 338300: 0.259665\n",
      "2022-11-08 15:18:11,143 INFO     Training average positive_sample_loss at step 338400: 0.307301\n",
      "2022-11-08 15:18:11,143 INFO     Training average negative_sample_loss at step 338400: 0.209155\n",
      "2022-11-08 15:18:11,143 INFO     Training average loss at step 338400: 0.258228\n",
      "2022-11-08 15:18:20,670 INFO     Training average positive_sample_loss at step 338500: 0.311265\n",
      "2022-11-08 15:18:20,670 INFO     Training average negative_sample_loss at step 338500: 0.201992\n",
      "2022-11-08 15:18:20,670 INFO     Training average loss at step 338500: 0.256628\n",
      "2022-11-08 15:18:30,199 INFO     Training average positive_sample_loss at step 338600: 0.296500\n",
      "2022-11-08 15:18:30,199 INFO     Training average negative_sample_loss at step 338600: 0.209194\n",
      "2022-11-08 15:18:30,199 INFO     Training average loss at step 338600: 0.252847\n",
      "2022-11-08 15:18:39,730 INFO     Training average positive_sample_loss at step 338700: 0.299714\n",
      "2022-11-08 15:18:39,730 INFO     Training average negative_sample_loss at step 338700: 0.208001\n",
      "2022-11-08 15:18:39,730 INFO     Training average loss at step 338700: 0.253857\n",
      "2022-11-08 15:18:49,258 INFO     Training average positive_sample_loss at step 338800: 0.307520\n",
      "2022-11-08 15:18:49,258 INFO     Training average negative_sample_loss at step 338800: 0.203996\n",
      "2022-11-08 15:18:49,258 INFO     Training average loss at step 338800: 0.255758\n",
      "2022-11-08 15:18:58,788 INFO     Training average positive_sample_loss at step 338900: 0.306522\n",
      "2022-11-08 15:18:58,789 INFO     Training average negative_sample_loss at step 338900: 0.208026\n",
      "2022-11-08 15:18:58,789 INFO     Training average loss at step 338900: 0.257274\n",
      "2022-11-08 15:19:08,319 INFO     Training average positive_sample_loss at step 339000: 0.305088\n",
      "2022-11-08 15:19:08,319 INFO     Training average negative_sample_loss at step 339000: 0.207113\n",
      "2022-11-08 15:19:08,319 INFO     Training average loss at step 339000: 0.256100\n",
      "2022-11-08 15:19:17,843 INFO     Training average positive_sample_loss at step 339100: 0.308859\n",
      "2022-11-08 15:19:17,843 INFO     Training average negative_sample_loss at step 339100: 0.205494\n",
      "2022-11-08 15:19:17,843 INFO     Training average loss at step 339100: 0.257176\n",
      "2022-11-08 15:19:27,372 INFO     Training average positive_sample_loss at step 339200: 0.303351\n",
      "2022-11-08 15:19:27,372 INFO     Training average negative_sample_loss at step 339200: 0.202820\n",
      "2022-11-08 15:19:27,372 INFO     Training average loss at step 339200: 0.253085\n",
      "2022-11-08 15:19:36,911 INFO     Training average positive_sample_loss at step 339300: 0.307688\n",
      "2022-11-08 15:19:36,911 INFO     Training average negative_sample_loss at step 339300: 0.199756\n",
      "2022-11-08 15:19:36,911 INFO     Training average loss at step 339300: 0.253722\n",
      "2022-11-08 15:19:46,442 INFO     Training average positive_sample_loss at step 339400: 0.302852\n",
      "2022-11-08 15:19:46,442 INFO     Training average negative_sample_loss at step 339400: 0.200585\n",
      "2022-11-08 15:19:46,442 INFO     Training average loss at step 339400: 0.251719\n",
      "2022-11-08 15:19:55,976 INFO     Training average positive_sample_loss at step 339500: 0.312617\n",
      "2022-11-08 15:19:55,976 INFO     Training average negative_sample_loss at step 339500: 0.204754\n",
      "2022-11-08 15:19:55,976 INFO     Training average loss at step 339500: 0.258685\n",
      "2022-11-08 15:20:05,504 INFO     Training average positive_sample_loss at step 339600: 0.308568\n",
      "2022-11-08 15:20:05,505 INFO     Training average negative_sample_loss at step 339600: 0.205629\n",
      "2022-11-08 15:20:05,505 INFO     Training average loss at step 339600: 0.257099\n",
      "2022-11-08 15:20:15,031 INFO     Training average positive_sample_loss at step 339700: 0.306571\n",
      "2022-11-08 15:20:15,032 INFO     Training average negative_sample_loss at step 339700: 0.208920\n",
      "2022-11-08 15:20:15,032 INFO     Training average loss at step 339700: 0.257746\n",
      "2022-11-08 15:20:24,562 INFO     Training average positive_sample_loss at step 339800: 0.311657\n",
      "2022-11-08 15:20:24,562 INFO     Training average negative_sample_loss at step 339800: 0.202584\n",
      "2022-11-08 15:20:24,563 INFO     Training average loss at step 339800: 0.257120\n",
      "2022-11-08 15:20:34,089 INFO     Training average positive_sample_loss at step 339900: 0.317145\n",
      "2022-11-08 15:20:34,089 INFO     Training average negative_sample_loss at step 339900: 0.205852\n",
      "2022-11-08 15:20:34,089 INFO     Training average loss at step 339900: 0.261498\n",
      "2022-11-08 15:20:46,328 INFO     Training average positive_sample_loss at step 340000: 0.306917\n",
      "2022-11-08 15:20:46,328 INFO     Training average negative_sample_loss at step 340000: 0.200064\n",
      "2022-11-08 15:20:46,328 INFO     Training average loss at step 340000: 0.253491\n",
      "2022-11-08 15:20:55,857 INFO     Training average positive_sample_loss at step 340100: 0.305896\n",
      "2022-11-08 15:20:55,857 INFO     Training average negative_sample_loss at step 340100: 0.206449\n",
      "2022-11-08 15:20:55,857 INFO     Training average loss at step 340100: 0.256173\n",
      "2022-11-08 15:21:05,385 INFO     Training average positive_sample_loss at step 340200: 0.298379\n",
      "2022-11-08 15:21:05,386 INFO     Training average negative_sample_loss at step 340200: 0.203401\n",
      "2022-11-08 15:21:05,386 INFO     Training average loss at step 340200: 0.250890\n",
      "2022-11-08 15:21:14,911 INFO     Training average positive_sample_loss at step 340300: 0.295237\n",
      "2022-11-08 15:21:14,911 INFO     Training average negative_sample_loss at step 340300: 0.210587\n",
      "2022-11-08 15:21:14,911 INFO     Training average loss at step 340300: 0.252912\n",
      "2022-11-08 15:21:24,442 INFO     Training average positive_sample_loss at step 340400: 0.300416\n",
      "2022-11-08 15:21:24,442 INFO     Training average negative_sample_loss at step 340400: 0.204454\n",
      "2022-11-08 15:21:24,442 INFO     Training average loss at step 340400: 0.252435\n",
      "2022-11-08 15:21:33,970 INFO     Training average positive_sample_loss at step 340500: 0.310108\n",
      "2022-11-08 15:21:33,970 INFO     Training average negative_sample_loss at step 340500: 0.203482\n",
      "2022-11-08 15:21:33,970 INFO     Training average loss at step 340500: 0.256795\n",
      "2022-11-08 15:21:43,500 INFO     Training average positive_sample_loss at step 340600: 0.288657\n",
      "2022-11-08 15:21:43,501 INFO     Training average negative_sample_loss at step 340600: 0.204157\n",
      "2022-11-08 15:21:43,501 INFO     Training average loss at step 340600: 0.246407\n",
      "2022-11-08 15:21:53,033 INFO     Training average positive_sample_loss at step 340700: 0.300231\n",
      "2022-11-08 15:21:53,033 INFO     Training average negative_sample_loss at step 340700: 0.202276\n",
      "2022-11-08 15:21:53,033 INFO     Training average loss at step 340700: 0.251254\n",
      "2022-11-08 15:22:01,873 INFO     Training average positive_sample_loss at step 340800: 0.317926\n",
      "2022-11-08 15:22:01,873 INFO     Training average negative_sample_loss at step 340800: 0.199754\n",
      "2022-11-08 15:22:01,873 INFO     Training average loss at step 340800: 0.258840\n",
      "2022-11-08 15:22:11,390 INFO     Training average positive_sample_loss at step 340900: 0.293099\n",
      "2022-11-08 15:22:11,391 INFO     Training average negative_sample_loss at step 340900: 0.198080\n",
      "2022-11-08 15:22:11,391 INFO     Training average loss at step 340900: 0.245590\n",
      "2022-11-08 15:22:21,869 INFO     Training average positive_sample_loss at step 341000: 0.295653\n",
      "2022-11-08 15:22:21,870 INFO     Training average negative_sample_loss at step 341000: 0.201203\n",
      "2022-11-08 15:22:21,870 INFO     Training average loss at step 341000: 0.248428\n",
      "2022-11-08 15:22:32,416 INFO     Training average positive_sample_loss at step 341100: 0.302772\n",
      "2022-11-08 15:22:32,416 INFO     Training average negative_sample_loss at step 341100: 0.207924\n",
      "2022-11-08 15:22:32,416 INFO     Training average loss at step 341100: 0.255348\n",
      "2022-11-08 15:22:41,946 INFO     Training average positive_sample_loss at step 341200: 0.311634\n",
      "2022-11-08 15:22:41,946 INFO     Training average negative_sample_loss at step 341200: 0.206853\n",
      "2022-11-08 15:22:41,946 INFO     Training average loss at step 341200: 0.259244\n",
      "2022-11-08 15:22:50,799 INFO     Training average positive_sample_loss at step 341300: 0.303530\n",
      "2022-11-08 15:22:50,799 INFO     Training average negative_sample_loss at step 341300: 0.201835\n",
      "2022-11-08 15:22:50,799 INFO     Training average loss at step 341300: 0.252683\n",
      "2022-11-08 15:23:00,324 INFO     Training average positive_sample_loss at step 341400: 0.308375\n",
      "2022-11-08 15:23:00,324 INFO     Training average negative_sample_loss at step 341400: 0.203847\n",
      "2022-11-08 15:23:00,324 INFO     Training average loss at step 341400: 0.256111\n",
      "2022-11-08 15:23:09,853 INFO     Training average positive_sample_loss at step 341500: 0.303323\n",
      "2022-11-08 15:23:09,854 INFO     Training average negative_sample_loss at step 341500: 0.203468\n",
      "2022-11-08 15:23:09,854 INFO     Training average loss at step 341500: 0.253396\n",
      "2022-11-08 15:23:19,383 INFO     Training average positive_sample_loss at step 341600: 0.312610\n",
      "2022-11-08 15:23:19,383 INFO     Training average negative_sample_loss at step 341600: 0.197574\n",
      "2022-11-08 15:23:19,383 INFO     Training average loss at step 341600: 0.255092\n",
      "2022-11-08 15:23:28,910 INFO     Training average positive_sample_loss at step 341700: 0.305868\n",
      "2022-11-08 15:23:28,910 INFO     Training average negative_sample_loss at step 341700: 0.207564\n",
      "2022-11-08 15:23:28,910 INFO     Training average loss at step 341700: 0.256716\n",
      "2022-11-08 15:23:38,443 INFO     Training average positive_sample_loss at step 341800: 0.292919\n",
      "2022-11-08 15:23:38,443 INFO     Training average negative_sample_loss at step 341800: 0.199403\n",
      "2022-11-08 15:23:38,443 INFO     Training average loss at step 341800: 0.246161\n",
      "2022-11-08 15:23:47,972 INFO     Training average positive_sample_loss at step 341900: 0.298367\n",
      "2022-11-08 15:23:47,972 INFO     Training average negative_sample_loss at step 341900: 0.199427\n",
      "2022-11-08 15:23:47,972 INFO     Training average loss at step 341900: 0.248897\n",
      "2022-11-08 15:23:57,498 INFO     Training average positive_sample_loss at step 342000: 0.296288\n",
      "2022-11-08 15:23:57,498 INFO     Training average negative_sample_loss at step 342000: 0.208331\n",
      "2022-11-08 15:23:57,498 INFO     Training average loss at step 342000: 0.252310\n",
      "2022-11-08 15:24:07,032 INFO     Training average positive_sample_loss at step 342100: 0.303302\n",
      "2022-11-08 15:24:07,032 INFO     Training average negative_sample_loss at step 342100: 0.201956\n",
      "2022-11-08 15:24:07,032 INFO     Training average loss at step 342100: 0.252629\n",
      "2022-11-08 15:24:16,561 INFO     Training average positive_sample_loss at step 342200: 0.301023\n",
      "2022-11-08 15:24:16,561 INFO     Training average negative_sample_loss at step 342200: 0.205604\n",
      "2022-11-08 15:24:16,561 INFO     Training average loss at step 342200: 0.253313\n",
      "2022-11-08 15:24:26,092 INFO     Training average positive_sample_loss at step 342300: 0.303726\n",
      "2022-11-08 15:24:26,092 INFO     Training average negative_sample_loss at step 342300: 0.206896\n",
      "2022-11-08 15:24:26,093 INFO     Training average loss at step 342300: 0.255311\n",
      "2022-11-08 15:24:35,619 INFO     Training average positive_sample_loss at step 342400: 0.302572\n",
      "2022-11-08 15:24:35,619 INFO     Training average negative_sample_loss at step 342400: 0.202323\n",
      "2022-11-08 15:24:35,619 INFO     Training average loss at step 342400: 0.252448\n",
      "2022-11-08 15:24:45,143 INFO     Training average positive_sample_loss at step 342500: 0.314742\n",
      "2022-11-08 15:24:45,143 INFO     Training average negative_sample_loss at step 342500: 0.204903\n",
      "2022-11-08 15:24:45,144 INFO     Training average loss at step 342500: 0.259822\n",
      "2022-11-08 15:24:54,673 INFO     Training average positive_sample_loss at step 342600: 0.316526\n",
      "2022-11-08 15:24:54,673 INFO     Training average negative_sample_loss at step 342600: 0.202305\n",
      "2022-11-08 15:24:54,673 INFO     Training average loss at step 342600: 0.259416\n",
      "2022-11-08 15:25:04,204 INFO     Training average positive_sample_loss at step 342700: 0.303582\n",
      "2022-11-08 15:25:04,204 INFO     Training average negative_sample_loss at step 342700: 0.202472\n",
      "2022-11-08 15:25:04,204 INFO     Training average loss at step 342700: 0.253027\n",
      "2022-11-08 15:25:13,731 INFO     Training average positive_sample_loss at step 342800: 0.302324\n",
      "2022-11-08 15:25:13,731 INFO     Training average negative_sample_loss at step 342800: 0.203375\n",
      "2022-11-08 15:25:13,731 INFO     Training average loss at step 342800: 0.252850\n",
      "2022-11-08 15:25:23,264 INFO     Training average positive_sample_loss at step 342900: 0.304197\n",
      "2022-11-08 15:25:23,264 INFO     Training average negative_sample_loss at step 342900: 0.203270\n",
      "2022-11-08 15:25:23,264 INFO     Training average loss at step 342900: 0.253734\n",
      "2022-11-08 15:25:32,790 INFO     Training average positive_sample_loss at step 343000: 0.297727\n",
      "2022-11-08 15:25:32,790 INFO     Training average negative_sample_loss at step 343000: 0.202884\n",
      "2022-11-08 15:25:32,790 INFO     Training average loss at step 343000: 0.250305\n",
      "2022-11-08 15:25:42,319 INFO     Training average positive_sample_loss at step 343100: 0.304620\n",
      "2022-11-08 15:25:42,319 INFO     Training average negative_sample_loss at step 343100: 0.199991\n",
      "2022-11-08 15:25:42,319 INFO     Training average loss at step 343100: 0.252305\n",
      "2022-11-08 15:25:51,851 INFO     Training average positive_sample_loss at step 343200: 0.306441\n",
      "2022-11-08 15:25:51,852 INFO     Training average negative_sample_loss at step 343200: 0.197671\n",
      "2022-11-08 15:25:51,852 INFO     Training average loss at step 343200: 0.252056\n",
      "2022-11-08 15:26:01,381 INFO     Training average positive_sample_loss at step 343300: 0.309693\n",
      "2022-11-08 15:26:01,382 INFO     Training average negative_sample_loss at step 343300: 0.204905\n",
      "2022-11-08 15:26:01,382 INFO     Training average loss at step 343300: 0.257299\n",
      "2022-11-08 15:26:10,910 INFO     Training average positive_sample_loss at step 343400: 0.287939\n",
      "2022-11-08 15:26:10,910 INFO     Training average negative_sample_loss at step 343400: 0.208084\n",
      "2022-11-08 15:26:10,910 INFO     Training average loss at step 343400: 0.248011\n",
      "2022-11-08 15:26:20,442 INFO     Training average positive_sample_loss at step 343500: 0.323386\n",
      "2022-11-08 15:26:20,442 INFO     Training average negative_sample_loss at step 343500: 0.201956\n",
      "2022-11-08 15:26:20,442 INFO     Training average loss at step 343500: 0.262671\n",
      "2022-11-08 15:26:29,969 INFO     Training average positive_sample_loss at step 343600: 0.314153\n",
      "2022-11-08 15:26:29,969 INFO     Training average negative_sample_loss at step 343600: 0.200106\n",
      "2022-11-08 15:26:29,969 INFO     Training average loss at step 343600: 0.257129\n",
      "2022-11-08 15:26:39,498 INFO     Training average positive_sample_loss at step 343700: 0.309562\n",
      "2022-11-08 15:26:39,498 INFO     Training average negative_sample_loss at step 343700: 0.205521\n",
      "2022-11-08 15:26:39,498 INFO     Training average loss at step 343700: 0.257542\n",
      "2022-11-08 15:26:49,030 INFO     Training average positive_sample_loss at step 343800: 0.314556\n",
      "2022-11-08 15:26:49,030 INFO     Training average negative_sample_loss at step 343800: 0.202441\n",
      "2022-11-08 15:26:49,030 INFO     Training average loss at step 343800: 0.258498\n",
      "2022-11-08 15:26:58,556 INFO     Training average positive_sample_loss at step 343900: 0.318392\n",
      "2022-11-08 15:26:58,556 INFO     Training average negative_sample_loss at step 343900: 0.206919\n",
      "2022-11-08 15:26:58,556 INFO     Training average loss at step 343900: 0.262656\n",
      "2022-11-08 15:27:08,088 INFO     Training average positive_sample_loss at step 344000: 0.305701\n",
      "2022-11-08 15:27:08,088 INFO     Training average negative_sample_loss at step 344000: 0.209687\n",
      "2022-11-08 15:27:08,088 INFO     Training average loss at step 344000: 0.257694\n",
      "2022-11-08 15:27:17,615 INFO     Training average positive_sample_loss at step 344100: 0.307231\n",
      "2022-11-08 15:27:17,615 INFO     Training average negative_sample_loss at step 344100: 0.202439\n",
      "2022-11-08 15:27:17,615 INFO     Training average loss at step 344100: 0.254835\n",
      "2022-11-08 15:27:27,143 INFO     Training average positive_sample_loss at step 344200: 0.304521\n",
      "2022-11-08 15:27:27,143 INFO     Training average negative_sample_loss at step 344200: 0.204812\n",
      "2022-11-08 15:27:27,143 INFO     Training average loss at step 344200: 0.254667\n",
      "2022-11-08 15:27:36,672 INFO     Training average positive_sample_loss at step 344300: 0.301729\n",
      "2022-11-08 15:27:36,672 INFO     Training average negative_sample_loss at step 344300: 0.205083\n",
      "2022-11-08 15:27:36,672 INFO     Training average loss at step 344300: 0.253406\n",
      "2022-11-08 15:27:46,202 INFO     Training average positive_sample_loss at step 344400: 0.307007\n",
      "2022-11-08 15:27:46,202 INFO     Training average negative_sample_loss at step 344400: 0.205470\n",
      "2022-11-08 15:27:46,202 INFO     Training average loss at step 344400: 0.256238\n",
      "2022-11-08 15:27:55,734 INFO     Training average positive_sample_loss at step 344500: 0.302523\n",
      "2022-11-08 15:27:55,734 INFO     Training average negative_sample_loss at step 344500: 0.205804\n",
      "2022-11-08 15:27:55,734 INFO     Training average loss at step 344500: 0.254163\n",
      "2022-11-08 15:28:05,266 INFO     Training average positive_sample_loss at step 344600: 0.322399\n",
      "2022-11-08 15:28:05,266 INFO     Training average negative_sample_loss at step 344600: 0.197916\n",
      "2022-11-08 15:28:05,266 INFO     Training average loss at step 344600: 0.260157\n",
      "2022-11-08 15:28:14,794 INFO     Training average positive_sample_loss at step 344700: 0.308226\n",
      "2022-11-08 15:28:14,794 INFO     Training average negative_sample_loss at step 344700: 0.205650\n",
      "2022-11-08 15:28:14,794 INFO     Training average loss at step 344700: 0.256938\n",
      "2022-11-08 15:28:24,325 INFO     Training average positive_sample_loss at step 344800: 0.304906\n",
      "2022-11-08 15:28:24,325 INFO     Training average negative_sample_loss at step 344800: 0.200849\n",
      "2022-11-08 15:28:24,325 INFO     Training average loss at step 344800: 0.252877\n",
      "2022-11-08 15:28:33,856 INFO     Training average positive_sample_loss at step 344900: 0.309870\n",
      "2022-11-08 15:28:33,856 INFO     Training average negative_sample_loss at step 344900: 0.204296\n",
      "2022-11-08 15:28:33,856 INFO     Training average loss at step 344900: 0.257083\n",
      "2022-11-08 15:28:43,385 INFO     Training average positive_sample_loss at step 345000: 0.305787\n",
      "2022-11-08 15:28:43,385 INFO     Training average negative_sample_loss at step 345000: 0.202614\n",
      "2022-11-08 15:28:43,385 INFO     Training average loss at step 345000: 0.254201\n",
      "2022-11-08 15:28:52,914 INFO     Training average positive_sample_loss at step 345100: 0.305572\n",
      "2022-11-08 15:28:52,914 INFO     Training average negative_sample_loss at step 345100: 0.201178\n",
      "2022-11-08 15:28:52,914 INFO     Training average loss at step 345100: 0.253375\n",
      "2022-11-08 15:29:02,442 INFO     Training average positive_sample_loss at step 345200: 0.305043\n",
      "2022-11-08 15:29:02,442 INFO     Training average negative_sample_loss at step 345200: 0.209007\n",
      "2022-11-08 15:29:02,442 INFO     Training average loss at step 345200: 0.257025\n",
      "2022-11-08 15:29:11,973 INFO     Training average positive_sample_loss at step 345300: 0.306794\n",
      "2022-11-08 15:29:11,973 INFO     Training average negative_sample_loss at step 345300: 0.200300\n",
      "2022-11-08 15:29:11,973 INFO     Training average loss at step 345300: 0.253547\n",
      "2022-11-08 15:29:21,502 INFO     Training average positive_sample_loss at step 345400: 0.313763\n",
      "2022-11-08 15:29:21,502 INFO     Training average negative_sample_loss at step 345400: 0.198457\n",
      "2022-11-08 15:29:21,502 INFO     Training average loss at step 345400: 0.256110\n",
      "2022-11-08 15:29:31,028 INFO     Training average positive_sample_loss at step 345500: 0.303125\n",
      "2022-11-08 15:29:31,028 INFO     Training average negative_sample_loss at step 345500: 0.199369\n",
      "2022-11-08 15:29:31,028 INFO     Training average loss at step 345500: 0.251247\n",
      "2022-11-08 15:29:41,531 INFO     Training average positive_sample_loss at step 345600: 0.303316\n",
      "2022-11-08 15:29:41,531 INFO     Training average negative_sample_loss at step 345600: 0.202540\n",
      "2022-11-08 15:29:41,531 INFO     Training average loss at step 345600: 0.252928\n",
      "2022-11-08 15:29:51,060 INFO     Training average positive_sample_loss at step 345700: 0.301675\n",
      "2022-11-08 15:29:51,060 INFO     Training average negative_sample_loss at step 345700: 0.203592\n",
      "2022-11-08 15:29:51,060 INFO     Training average loss at step 345700: 0.252633\n",
      "2022-11-08 15:30:01,563 INFO     Training average positive_sample_loss at step 345800: 0.313045\n",
      "2022-11-08 15:30:01,563 INFO     Training average negative_sample_loss at step 345800: 0.199241\n",
      "2022-11-08 15:30:01,563 INFO     Training average loss at step 345800: 0.256143\n",
      "2022-11-08 15:30:11,092 INFO     Training average positive_sample_loss at step 345900: 0.312882\n",
      "2022-11-08 15:30:11,092 INFO     Training average negative_sample_loss at step 345900: 0.203193\n",
      "2022-11-08 15:30:11,092 INFO     Training average loss at step 345900: 0.258037\n",
      "2022-11-08 15:30:20,619 INFO     Training average positive_sample_loss at step 346000: 0.314305\n",
      "2022-11-08 15:30:20,619 INFO     Training average negative_sample_loss at step 346000: 0.201134\n",
      "2022-11-08 15:30:20,619 INFO     Training average loss at step 346000: 0.257719\n",
      "2022-11-08 15:30:30,149 INFO     Training average positive_sample_loss at step 346100: 0.316244\n",
      "2022-11-08 15:30:30,149 INFO     Training average negative_sample_loss at step 346100: 0.204947\n",
      "2022-11-08 15:30:30,149 INFO     Training average loss at step 346100: 0.260595\n",
      "2022-11-08 15:30:39,677 INFO     Training average positive_sample_loss at step 346200: 0.298777\n",
      "2022-11-08 15:30:39,677 INFO     Training average negative_sample_loss at step 346200: 0.198612\n",
      "2022-11-08 15:30:39,677 INFO     Training average loss at step 346200: 0.248695\n",
      "2022-11-08 15:30:48,571 INFO     Training average positive_sample_loss at step 346300: 0.297447\n",
      "2022-11-08 15:30:48,571 INFO     Training average negative_sample_loss at step 346300: 0.198077\n",
      "2022-11-08 15:30:48,571 INFO     Training average loss at step 346300: 0.247762\n",
      "2022-11-08 15:30:58,099 INFO     Training average positive_sample_loss at step 346400: 0.313096\n",
      "2022-11-08 15:30:58,099 INFO     Training average negative_sample_loss at step 346400: 0.201022\n",
      "2022-11-08 15:30:58,099 INFO     Training average loss at step 346400: 0.257059\n",
      "2022-11-08 15:31:07,631 INFO     Training average positive_sample_loss at step 346500: 0.312944\n",
      "2022-11-08 15:31:07,631 INFO     Training average negative_sample_loss at step 346500: 0.204383\n",
      "2022-11-08 15:31:07,631 INFO     Training average loss at step 346500: 0.258663\n",
      "2022-11-08 15:31:17,158 INFO     Training average positive_sample_loss at step 346600: 0.288711\n",
      "2022-11-08 15:31:17,158 INFO     Training average negative_sample_loss at step 346600: 0.207464\n",
      "2022-11-08 15:31:17,158 INFO     Training average loss at step 346600: 0.248088\n",
      "2022-11-08 15:31:26,686 INFO     Training average positive_sample_loss at step 346700: 0.307283\n",
      "2022-11-08 15:31:26,686 INFO     Training average negative_sample_loss at step 346700: 0.199616\n",
      "2022-11-08 15:31:26,686 INFO     Training average loss at step 346700: 0.253450\n",
      "2022-11-08 15:31:35,532 INFO     Training average positive_sample_loss at step 346800: 0.294871\n",
      "2022-11-08 15:31:35,532 INFO     Training average negative_sample_loss at step 346800: 0.202015\n",
      "2022-11-08 15:31:35,532 INFO     Training average loss at step 346800: 0.248443\n",
      "2022-11-08 15:31:45,061 INFO     Training average positive_sample_loss at step 346900: 0.313071\n",
      "2022-11-08 15:31:45,061 INFO     Training average negative_sample_loss at step 346900: 0.205972\n",
      "2022-11-08 15:31:45,061 INFO     Training average loss at step 346900: 0.259521\n",
      "2022-11-08 15:31:54,590 INFO     Training average positive_sample_loss at step 347000: 0.297861\n",
      "2022-11-08 15:31:54,590 INFO     Training average negative_sample_loss at step 347000: 0.201677\n",
      "2022-11-08 15:31:54,590 INFO     Training average loss at step 347000: 0.249769\n",
      "2022-11-08 15:32:04,121 INFO     Training average positive_sample_loss at step 347100: 0.317328\n",
      "2022-11-08 15:32:04,121 INFO     Training average negative_sample_loss at step 347100: 0.204052\n",
      "2022-11-08 15:32:04,121 INFO     Training average loss at step 347100: 0.260690\n",
      "2022-11-08 15:32:13,647 INFO     Training average positive_sample_loss at step 347200: 0.289184\n",
      "2022-11-08 15:32:13,647 INFO     Training average negative_sample_loss at step 347200: 0.203571\n",
      "2022-11-08 15:32:13,647 INFO     Training average loss at step 347200: 0.246377\n",
      "2022-11-08 15:32:23,185 INFO     Training average positive_sample_loss at step 347300: 0.299174\n",
      "2022-11-08 15:32:23,185 INFO     Training average negative_sample_loss at step 347300: 0.207582\n",
      "2022-11-08 15:32:23,185 INFO     Training average loss at step 347300: 0.253378\n",
      "2022-11-08 15:32:32,716 INFO     Training average positive_sample_loss at step 347400: 0.299584\n",
      "2022-11-08 15:32:32,717 INFO     Training average negative_sample_loss at step 347400: 0.199907\n",
      "2022-11-08 15:32:32,717 INFO     Training average loss at step 347400: 0.249745\n",
      "2022-11-08 15:32:42,244 INFO     Training average positive_sample_loss at step 347500: 0.316093\n",
      "2022-11-08 15:32:42,244 INFO     Training average negative_sample_loss at step 347500: 0.206478\n",
      "2022-11-08 15:32:42,244 INFO     Training average loss at step 347500: 0.261285\n",
      "2022-11-08 15:32:51,774 INFO     Training average positive_sample_loss at step 347600: 0.309909\n",
      "2022-11-08 15:32:51,774 INFO     Training average negative_sample_loss at step 347600: 0.200403\n",
      "2022-11-08 15:32:51,774 INFO     Training average loss at step 347600: 0.255156\n",
      "2022-11-08 15:33:01,302 INFO     Training average positive_sample_loss at step 347700: 0.300608\n",
      "2022-11-08 15:33:01,302 INFO     Training average negative_sample_loss at step 347700: 0.208449\n",
      "2022-11-08 15:33:01,302 INFO     Training average loss at step 347700: 0.254528\n",
      "2022-11-08 15:33:10,836 INFO     Training average positive_sample_loss at step 347800: 0.298768\n",
      "2022-11-08 15:33:10,836 INFO     Training average negative_sample_loss at step 347800: 0.200251\n",
      "2022-11-08 15:33:10,836 INFO     Training average loss at step 347800: 0.249509\n",
      "2022-11-08 15:33:20,366 INFO     Training average positive_sample_loss at step 347900: 0.295254\n",
      "2022-11-08 15:33:20,366 INFO     Training average negative_sample_loss at step 347900: 0.200319\n",
      "2022-11-08 15:33:20,366 INFO     Training average loss at step 347900: 0.247787\n",
      "2022-11-08 15:33:29,893 INFO     Training average positive_sample_loss at step 348000: 0.304461\n",
      "2022-11-08 15:33:29,893 INFO     Training average negative_sample_loss at step 348000: 0.202782\n",
      "2022-11-08 15:33:29,894 INFO     Training average loss at step 348000: 0.253621\n",
      "2022-11-08 15:33:39,429 INFO     Training average positive_sample_loss at step 348100: 0.303859\n",
      "2022-11-08 15:33:39,429 INFO     Training average negative_sample_loss at step 348100: 0.196394\n",
      "2022-11-08 15:33:39,429 INFO     Training average loss at step 348100: 0.250127\n",
      "2022-11-08 15:33:48,962 INFO     Training average positive_sample_loss at step 348200: 0.288429\n",
      "2022-11-08 15:33:48,962 INFO     Training average negative_sample_loss at step 348200: 0.203974\n",
      "2022-11-08 15:33:48,962 INFO     Training average loss at step 348200: 0.246202\n",
      "2022-11-08 15:33:58,490 INFO     Training average positive_sample_loss at step 348300: 0.305568\n",
      "2022-11-08 15:33:58,490 INFO     Training average negative_sample_loss at step 348300: 0.200856\n",
      "2022-11-08 15:33:58,490 INFO     Training average loss at step 348300: 0.253212\n",
      "2022-11-08 15:34:08,026 INFO     Training average positive_sample_loss at step 348400: 0.307764\n",
      "2022-11-08 15:34:08,026 INFO     Training average negative_sample_loss at step 348400: 0.198209\n",
      "2022-11-08 15:34:08,026 INFO     Training average loss at step 348400: 0.252987\n",
      "2022-11-08 15:34:17,554 INFO     Training average positive_sample_loss at step 348500: 0.300942\n",
      "2022-11-08 15:34:17,554 INFO     Training average negative_sample_loss at step 348500: 0.204539\n",
      "2022-11-08 15:34:17,554 INFO     Training average loss at step 348500: 0.252741\n",
      "2022-11-08 15:34:27,085 INFO     Training average positive_sample_loss at step 348600: 0.327379\n",
      "2022-11-08 15:34:27,085 INFO     Training average negative_sample_loss at step 348600: 0.199406\n",
      "2022-11-08 15:34:27,085 INFO     Training average loss at step 348600: 0.263393\n",
      "2022-11-08 15:34:36,617 INFO     Training average positive_sample_loss at step 348700: 0.304586\n",
      "2022-11-08 15:34:36,617 INFO     Training average negative_sample_loss at step 348700: 0.205261\n",
      "2022-11-08 15:34:36,617 INFO     Training average loss at step 348700: 0.254923\n",
      "2022-11-08 15:34:46,146 INFO     Training average positive_sample_loss at step 348800: 0.312895\n",
      "2022-11-08 15:34:46,146 INFO     Training average negative_sample_loss at step 348800: 0.200513\n",
      "2022-11-08 15:34:46,146 INFO     Training average loss at step 348800: 0.256704\n",
      "2022-11-08 15:34:55,676 INFO     Training average positive_sample_loss at step 348900: 0.306264\n",
      "2022-11-08 15:34:55,676 INFO     Training average negative_sample_loss at step 348900: 0.206987\n",
      "2022-11-08 15:34:55,676 INFO     Training average loss at step 348900: 0.256625\n",
      "2022-11-08 15:35:05,210 INFO     Training average positive_sample_loss at step 349000: 0.319383\n",
      "2022-11-08 15:35:05,211 INFO     Training average negative_sample_loss at step 349000: 0.201493\n",
      "2022-11-08 15:35:05,211 INFO     Training average loss at step 349000: 0.260438\n",
      "2022-11-08 15:35:14,737 INFO     Training average positive_sample_loss at step 349100: 0.315473\n",
      "2022-11-08 15:35:14,737 INFO     Training average negative_sample_loss at step 349100: 0.208501\n",
      "2022-11-08 15:35:14,737 INFO     Training average loss at step 349100: 0.261987\n",
      "2022-11-08 15:35:24,268 INFO     Training average positive_sample_loss at step 349200: 0.296194\n",
      "2022-11-08 15:35:24,268 INFO     Training average negative_sample_loss at step 349200: 0.204735\n",
      "2022-11-08 15:35:24,268 INFO     Training average loss at step 349200: 0.250465\n",
      "2022-11-08 15:35:33,800 INFO     Training average positive_sample_loss at step 349300: 0.330060\n",
      "2022-11-08 15:35:33,800 INFO     Training average negative_sample_loss at step 349300: 0.201914\n",
      "2022-11-08 15:35:33,800 INFO     Training average loss at step 349300: 0.265987\n",
      "2022-11-08 15:35:43,332 INFO     Training average positive_sample_loss at step 349400: 0.315033\n",
      "2022-11-08 15:35:43,332 INFO     Training average negative_sample_loss at step 349400: 0.202427\n",
      "2022-11-08 15:35:43,332 INFO     Training average loss at step 349400: 0.258730\n",
      "2022-11-08 15:35:52,864 INFO     Training average positive_sample_loss at step 349500: 0.302640\n",
      "2022-11-08 15:35:52,864 INFO     Training average negative_sample_loss at step 349500: 0.197279\n",
      "2022-11-08 15:35:52,864 INFO     Training average loss at step 349500: 0.249959\n",
      "2022-11-08 15:36:02,397 INFO     Training average positive_sample_loss at step 349600: 0.305553\n",
      "2022-11-08 15:36:02,397 INFO     Training average negative_sample_loss at step 349600: 0.205518\n",
      "2022-11-08 15:36:02,397 INFO     Training average loss at step 349600: 0.255535\n",
      "2022-11-08 15:36:11,925 INFO     Training average positive_sample_loss at step 349700: 0.297766\n",
      "2022-11-08 15:36:11,925 INFO     Training average negative_sample_loss at step 349700: 0.204088\n",
      "2022-11-08 15:36:11,925 INFO     Training average loss at step 349700: 0.250927\n",
      "2022-11-08 15:36:21,459 INFO     Training average positive_sample_loss at step 349800: 0.294899\n",
      "2022-11-08 15:36:21,459 INFO     Training average negative_sample_loss at step 349800: 0.201077\n",
      "2022-11-08 15:36:21,459 INFO     Training average loss at step 349800: 0.247988\n",
      "2022-11-08 15:36:30,990 INFO     Training average positive_sample_loss at step 349900: 0.315609\n",
      "2022-11-08 15:36:30,990 INFO     Training average negative_sample_loss at step 349900: 0.206465\n",
      "2022-11-08 15:36:30,990 INFO     Training average loss at step 349900: 0.261037\n",
      "2022-11-08 15:36:43,072 INFO     Training average positive_sample_loss at step 350000: 0.308959\n",
      "2022-11-08 15:36:43,072 INFO     Training average negative_sample_loss at step 350000: 0.198274\n",
      "2022-11-08 15:36:43,072 INFO     Training average loss at step 350000: 0.253617\n",
      "2022-11-08 15:36:52,602 INFO     Training average positive_sample_loss at step 350100: 0.309517\n",
      "2022-11-08 15:36:52,602 INFO     Training average negative_sample_loss at step 350100: 0.201260\n",
      "2022-11-08 15:36:52,602 INFO     Training average loss at step 350100: 0.255389\n",
      "2022-11-08 15:37:02,133 INFO     Training average positive_sample_loss at step 350200: 0.315579\n",
      "2022-11-08 15:37:02,133 INFO     Training average negative_sample_loss at step 350200: 0.202082\n",
      "2022-11-08 15:37:02,133 INFO     Training average loss at step 350200: 0.258831\n",
      "2022-11-08 15:37:12,505 INFO     Training average positive_sample_loss at step 350300: 0.289924\n",
      "2022-11-08 15:37:12,505 INFO     Training average negative_sample_loss at step 350300: 0.200424\n",
      "2022-11-08 15:37:12,505 INFO     Training average loss at step 350300: 0.245174\n",
      "2022-11-08 15:37:22,034 INFO     Training average positive_sample_loss at step 350400: 0.309689\n",
      "2022-11-08 15:37:22,035 INFO     Training average negative_sample_loss at step 350400: 0.198680\n",
      "2022-11-08 15:37:22,035 INFO     Training average loss at step 350400: 0.254185\n",
      "2022-11-08 15:37:32,689 INFO     Training average positive_sample_loss at step 350500: 0.314714\n",
      "2022-11-08 15:37:32,689 INFO     Training average negative_sample_loss at step 350500: 0.205084\n",
      "2022-11-08 15:37:32,690 INFO     Training average loss at step 350500: 0.259899\n",
      "2022-11-08 15:37:42,222 INFO     Training average positive_sample_loss at step 350600: 0.295611\n",
      "2022-11-08 15:37:42,222 INFO     Training average negative_sample_loss at step 350600: 0.204665\n",
      "2022-11-08 15:37:42,222 INFO     Training average loss at step 350600: 0.250138\n",
      "2022-11-08 15:37:51,749 INFO     Training average positive_sample_loss at step 350700: 0.300116\n",
      "2022-11-08 15:37:51,749 INFO     Training average negative_sample_loss at step 350700: 0.202417\n",
      "2022-11-08 15:37:51,749 INFO     Training average loss at step 350700: 0.251267\n",
      "2022-11-08 15:38:01,284 INFO     Training average positive_sample_loss at step 350800: 0.289312\n",
      "2022-11-08 15:38:01,284 INFO     Training average negative_sample_loss at step 350800: 0.200766\n",
      "2022-11-08 15:38:01,284 INFO     Training average loss at step 350800: 0.245039\n",
      "2022-11-08 15:38:10,815 INFO     Training average positive_sample_loss at step 350900: 0.308390\n",
      "2022-11-08 15:38:10,815 INFO     Training average negative_sample_loss at step 350900: 0.202205\n",
      "2022-11-08 15:38:10,815 INFO     Training average loss at step 350900: 0.255298\n",
      "2022-11-08 15:38:20,344 INFO     Training average positive_sample_loss at step 351000: 0.303229\n",
      "2022-11-08 15:38:20,344 INFO     Training average negative_sample_loss at step 351000: 0.202721\n",
      "2022-11-08 15:38:20,344 INFO     Training average loss at step 351000: 0.252975\n",
      "2022-11-08 15:38:29,877 INFO     Training average positive_sample_loss at step 351100: 0.323036\n",
      "2022-11-08 15:38:29,877 INFO     Training average negative_sample_loss at step 351100: 0.202834\n",
      "2022-11-08 15:38:29,877 INFO     Training average loss at step 351100: 0.262935\n",
      "2022-11-08 15:38:39,415 INFO     Training average positive_sample_loss at step 351200: 0.300492\n",
      "2022-11-08 15:38:39,415 INFO     Training average negative_sample_loss at step 351200: 0.199506\n",
      "2022-11-08 15:38:39,415 INFO     Training average loss at step 351200: 0.249999\n",
      "2022-11-08 15:38:48,945 INFO     Training average positive_sample_loss at step 351300: 0.304736\n",
      "2022-11-08 15:38:48,945 INFO     Training average negative_sample_loss at step 351300: 0.203226\n",
      "2022-11-08 15:38:48,945 INFO     Training average loss at step 351300: 0.253981\n",
      "2022-11-08 15:38:58,586 INFO     Training average positive_sample_loss at step 351400: 0.307665\n",
      "2022-11-08 15:38:58,586 INFO     Training average negative_sample_loss at step 351400: 0.200122\n",
      "2022-11-08 15:38:58,586 INFO     Training average loss at step 351400: 0.253894\n",
      "2022-11-08 15:39:08,368 INFO     Training average positive_sample_loss at step 351500: 0.310499\n",
      "2022-11-08 15:39:08,368 INFO     Training average negative_sample_loss at step 351500: 0.194502\n",
      "2022-11-08 15:39:08,368 INFO     Training average loss at step 351500: 0.252500\n",
      "2022-11-08 15:39:18,152 INFO     Training average positive_sample_loss at step 351600: 0.293310\n",
      "2022-11-08 15:39:18,152 INFO     Training average negative_sample_loss at step 351600: 0.202703\n",
      "2022-11-08 15:39:18,152 INFO     Training average loss at step 351600: 0.248007\n",
      "2022-11-08 15:39:27,295 INFO     Training average positive_sample_loss at step 351700: 0.294152\n",
      "2022-11-08 15:39:27,295 INFO     Training average negative_sample_loss at step 351700: 0.204616\n",
      "2022-11-08 15:39:27,295 INFO     Training average loss at step 351700: 0.249384\n",
      "2022-11-08 15:39:36,841 INFO     Training average positive_sample_loss at step 351800: 0.308253\n",
      "2022-11-08 15:39:36,841 INFO     Training average negative_sample_loss at step 351800: 0.203426\n",
      "2022-11-08 15:39:36,841 INFO     Training average loss at step 351800: 0.255840\n",
      "2022-11-08 15:39:46,371 INFO     Training average positive_sample_loss at step 351900: 0.317341\n",
      "2022-11-08 15:39:46,371 INFO     Training average negative_sample_loss at step 351900: 0.197436\n",
      "2022-11-08 15:39:46,371 INFO     Training average loss at step 351900: 0.257388\n",
      "2022-11-08 15:39:55,901 INFO     Training average positive_sample_loss at step 352000: 0.301324\n",
      "2022-11-08 15:39:55,901 INFO     Training average negative_sample_loss at step 352000: 0.199609\n",
      "2022-11-08 15:39:55,901 INFO     Training average loss at step 352000: 0.250466\n",
      "2022-11-08 15:40:04,100 INFO     Training average positive_sample_loss at step 352100: 0.298577\n",
      "2022-11-08 15:40:04,100 INFO     Training average negative_sample_loss at step 352100: 0.201607\n",
      "2022-11-08 15:40:04,100 INFO     Training average loss at step 352100: 0.250092\n",
      "2022-11-08 15:40:14,174 INFO     Training average positive_sample_loss at step 352200: 0.307481\n",
      "2022-11-08 15:40:14,174 INFO     Training average negative_sample_loss at step 352200: 0.201096\n",
      "2022-11-08 15:40:14,174 INFO     Training average loss at step 352200: 0.254289\n",
      "2022-11-08 15:40:23,513 INFO     Training average positive_sample_loss at step 352300: 0.302392\n",
      "2022-11-08 15:40:23,513 INFO     Training average negative_sample_loss at step 352300: 0.198600\n",
      "2022-11-08 15:40:23,513 INFO     Training average loss at step 352300: 0.250496\n",
      "2022-11-08 15:40:33,406 INFO     Training average positive_sample_loss at step 352400: 0.303088\n",
      "2022-11-08 15:40:33,407 INFO     Training average negative_sample_loss at step 352400: 0.198206\n",
      "2022-11-08 15:40:33,407 INFO     Training average loss at step 352400: 0.250647\n",
      "2022-11-08 15:40:43,425 INFO     Training average positive_sample_loss at step 352500: 0.290969\n",
      "2022-11-08 15:40:43,425 INFO     Training average negative_sample_loss at step 352500: 0.205006\n",
      "2022-11-08 15:40:43,425 INFO     Training average loss at step 352500: 0.247988\n",
      "2022-11-08 15:40:53,285 INFO     Training average positive_sample_loss at step 352600: 0.309444\n",
      "2022-11-08 15:40:53,285 INFO     Training average negative_sample_loss at step 352600: 0.203270\n",
      "2022-11-08 15:40:53,285 INFO     Training average loss at step 352600: 0.256357\n",
      "2022-11-08 15:41:03,156 INFO     Training average positive_sample_loss at step 352700: 0.302058\n",
      "2022-11-08 15:41:03,156 INFO     Training average negative_sample_loss at step 352700: 0.199041\n",
      "2022-11-08 15:41:03,156 INFO     Training average loss at step 352700: 0.250550\n",
      "2022-11-08 15:41:13,016 INFO     Training average positive_sample_loss at step 352800: 0.287913\n",
      "2022-11-08 15:41:13,016 INFO     Training average negative_sample_loss at step 352800: 0.203795\n",
      "2022-11-08 15:41:13,016 INFO     Training average loss at step 352800: 0.245854\n",
      "2022-11-08 15:41:22,948 INFO     Training average positive_sample_loss at step 352900: 0.309775\n",
      "2022-11-08 15:41:22,948 INFO     Training average negative_sample_loss at step 352900: 0.204987\n",
      "2022-11-08 15:41:22,948 INFO     Training average loss at step 352900: 0.257381\n",
      "2022-11-08 15:41:32,875 INFO     Training average positive_sample_loss at step 353000: 0.304628\n",
      "2022-11-08 15:41:32,875 INFO     Training average negative_sample_loss at step 353000: 0.196661\n",
      "2022-11-08 15:41:32,875 INFO     Training average loss at step 353000: 0.250645\n",
      "2022-11-08 15:41:42,757 INFO     Training average positive_sample_loss at step 353100: 0.297102\n",
      "2022-11-08 15:41:42,758 INFO     Training average negative_sample_loss at step 353100: 0.200536\n",
      "2022-11-08 15:41:42,758 INFO     Training average loss at step 353100: 0.248819\n",
      "2022-11-08 15:41:52,708 INFO     Training average positive_sample_loss at step 353200: 0.307164\n",
      "2022-11-08 15:41:52,708 INFO     Training average negative_sample_loss at step 353200: 0.197783\n",
      "2022-11-08 15:41:52,709 INFO     Training average loss at step 353200: 0.252473\n",
      "2022-11-08 15:42:02,545 INFO     Training average positive_sample_loss at step 353300: 0.300731\n",
      "2022-11-08 15:42:02,545 INFO     Training average negative_sample_loss at step 353300: 0.198348\n",
      "2022-11-08 15:42:02,545 INFO     Training average loss at step 353300: 0.249540\n",
      "2022-11-08 15:42:12,483 INFO     Training average positive_sample_loss at step 353400: 0.296925\n",
      "2022-11-08 15:42:12,483 INFO     Training average negative_sample_loss at step 353400: 0.200860\n",
      "2022-11-08 15:42:12,483 INFO     Training average loss at step 353400: 0.248892\n",
      "2022-11-08 15:42:22,485 INFO     Training average positive_sample_loss at step 353500: 0.294615\n",
      "2022-11-08 15:42:22,485 INFO     Training average negative_sample_loss at step 353500: 0.201028\n",
      "2022-11-08 15:42:22,485 INFO     Training average loss at step 353500: 0.247822\n",
      "2022-11-08 15:42:32,478 INFO     Training average positive_sample_loss at step 353600: 0.296435\n",
      "2022-11-08 15:42:32,478 INFO     Training average negative_sample_loss at step 353600: 0.205819\n",
      "2022-11-08 15:42:32,478 INFO     Training average loss at step 353600: 0.251127\n",
      "2022-11-08 15:42:42,407 INFO     Training average positive_sample_loss at step 353700: 0.299661\n",
      "2022-11-08 15:42:42,407 INFO     Training average negative_sample_loss at step 353700: 0.200779\n",
      "2022-11-08 15:42:42,407 INFO     Training average loss at step 353700: 0.250220\n",
      "2022-11-08 15:42:52,312 INFO     Training average positive_sample_loss at step 353800: 0.309599\n",
      "2022-11-08 15:42:52,312 INFO     Training average negative_sample_loss at step 353800: 0.203141\n",
      "2022-11-08 15:42:52,312 INFO     Training average loss at step 353800: 0.256370\n",
      "2022-11-08 15:43:02,145 INFO     Training average positive_sample_loss at step 353900: 0.298183\n",
      "2022-11-08 15:43:02,145 INFO     Training average negative_sample_loss at step 353900: 0.202260\n",
      "2022-11-08 15:43:02,145 INFO     Training average loss at step 353900: 0.250221\n",
      "2022-11-08 15:43:12,007 INFO     Training average positive_sample_loss at step 354000: 0.304728\n",
      "2022-11-08 15:43:12,007 INFO     Training average negative_sample_loss at step 354000: 0.202228\n",
      "2022-11-08 15:43:12,007 INFO     Training average loss at step 354000: 0.253478\n",
      "2022-11-08 15:43:21,912 INFO     Training average positive_sample_loss at step 354100: 0.297191\n",
      "2022-11-08 15:43:21,912 INFO     Training average negative_sample_loss at step 354100: 0.203993\n",
      "2022-11-08 15:43:21,912 INFO     Training average loss at step 354100: 0.250592\n",
      "2022-11-08 15:43:31,791 INFO     Training average positive_sample_loss at step 354200: 0.291596\n",
      "2022-11-08 15:43:31,791 INFO     Training average negative_sample_loss at step 354200: 0.200165\n",
      "2022-11-08 15:43:31,791 INFO     Training average loss at step 354200: 0.245881\n",
      "2022-11-08 15:43:41,672 INFO     Training average positive_sample_loss at step 354300: 0.305376\n",
      "2022-11-08 15:43:41,672 INFO     Training average negative_sample_loss at step 354300: 0.200453\n",
      "2022-11-08 15:43:41,672 INFO     Training average loss at step 354300: 0.252914\n",
      "2022-11-08 15:43:51,599 INFO     Training average positive_sample_loss at step 354400: 0.305328\n",
      "2022-11-08 15:43:51,599 INFO     Training average negative_sample_loss at step 354400: 0.196294\n",
      "2022-11-08 15:43:51,599 INFO     Training average loss at step 354400: 0.250811\n",
      "2022-11-08 15:44:01,525 INFO     Training average positive_sample_loss at step 354500: 0.305736\n",
      "2022-11-08 15:44:01,525 INFO     Training average negative_sample_loss at step 354500: 0.198568\n",
      "2022-11-08 15:44:01,525 INFO     Training average loss at step 354500: 0.252152\n",
      "2022-11-08 15:44:11,401 INFO     Training average positive_sample_loss at step 354600: 0.304074\n",
      "2022-11-08 15:44:11,401 INFO     Training average negative_sample_loss at step 354600: 0.197415\n",
      "2022-11-08 15:44:11,401 INFO     Training average loss at step 354600: 0.250745\n",
      "2022-11-08 15:44:21,253 INFO     Training average positive_sample_loss at step 354700: 0.300651\n",
      "2022-11-08 15:44:21,253 INFO     Training average negative_sample_loss at step 354700: 0.202101\n",
      "2022-11-08 15:44:21,253 INFO     Training average loss at step 354700: 0.251376\n",
      "2022-11-08 15:44:31,039 INFO     Training average positive_sample_loss at step 354800: 0.287034\n",
      "2022-11-08 15:44:31,039 INFO     Training average negative_sample_loss at step 354800: 0.200149\n",
      "2022-11-08 15:44:31,040 INFO     Training average loss at step 354800: 0.243591\n",
      "2022-11-08 15:44:40,866 INFO     Training average positive_sample_loss at step 354900: 0.314526\n",
      "2022-11-08 15:44:40,866 INFO     Training average negative_sample_loss at step 354900: 0.194686\n",
      "2022-11-08 15:44:40,866 INFO     Training average loss at step 354900: 0.254606\n",
      "2022-11-08 15:44:51,751 INFO     Training average positive_sample_loss at step 355000: 0.314515\n",
      "2022-11-08 15:44:51,751 INFO     Training average negative_sample_loss at step 355000: 0.201224\n",
      "2022-11-08 15:44:51,751 INFO     Training average loss at step 355000: 0.257870\n",
      "2022-11-08 15:45:02,863 INFO     Training average positive_sample_loss at step 355100: 0.313363\n",
      "2022-11-08 15:45:02,863 INFO     Training average negative_sample_loss at step 355100: 0.199590\n",
      "2022-11-08 15:45:02,864 INFO     Training average loss at step 355100: 0.256477\n",
      "2022-11-08 15:45:12,717 INFO     Training average positive_sample_loss at step 355200: 0.295565\n",
      "2022-11-08 15:45:12,717 INFO     Training average negative_sample_loss at step 355200: 0.202287\n",
      "2022-11-08 15:45:12,717 INFO     Training average loss at step 355200: 0.248926\n",
      "2022-11-08 15:45:22,565 INFO     Training average positive_sample_loss at step 355300: 0.298865\n",
      "2022-11-08 15:45:22,565 INFO     Training average negative_sample_loss at step 355300: 0.199933\n",
      "2022-11-08 15:45:22,565 INFO     Training average loss at step 355300: 0.249399\n",
      "2022-11-08 15:45:32,408 INFO     Training average positive_sample_loss at step 355400: 0.297664\n",
      "2022-11-08 15:45:32,408 INFO     Training average negative_sample_loss at step 355400: 0.199318\n",
      "2022-11-08 15:45:32,408 INFO     Training average loss at step 355400: 0.248491\n",
      "2022-11-08 15:45:42,267 INFO     Training average positive_sample_loss at step 355500: 0.307200\n",
      "2022-11-08 15:45:42,267 INFO     Training average negative_sample_loss at step 355500: 0.199651\n",
      "2022-11-08 15:45:42,267 INFO     Training average loss at step 355500: 0.253425\n",
      "2022-11-08 15:45:52,221 INFO     Training average positive_sample_loss at step 355600: 0.301069\n",
      "2022-11-08 15:45:52,221 INFO     Training average negative_sample_loss at step 355600: 0.202299\n",
      "2022-11-08 15:45:52,221 INFO     Training average loss at step 355600: 0.251684\n",
      "2022-11-08 15:46:02,209 INFO     Training average positive_sample_loss at step 355700: 0.304018\n",
      "2022-11-08 15:46:02,209 INFO     Training average negative_sample_loss at step 355700: 0.202762\n",
      "2022-11-08 15:46:02,209 INFO     Training average loss at step 355700: 0.253390\n",
      "2022-11-08 15:46:12,061 INFO     Training average positive_sample_loss at step 355800: 0.303248\n",
      "2022-11-08 15:46:12,062 INFO     Training average negative_sample_loss at step 355800: 0.205317\n",
      "2022-11-08 15:46:12,062 INFO     Training average loss at step 355800: 0.254282\n",
      "2022-11-08 15:46:21,914 INFO     Training average positive_sample_loss at step 355900: 0.309670\n",
      "2022-11-08 15:46:21,914 INFO     Training average negative_sample_loss at step 355900: 0.198068\n",
      "2022-11-08 15:46:21,915 INFO     Training average loss at step 355900: 0.253869\n",
      "2022-11-08 15:46:31,811 INFO     Training average positive_sample_loss at step 356000: 0.308922\n",
      "2022-11-08 15:46:31,812 INFO     Training average negative_sample_loss at step 356000: 0.201704\n",
      "2022-11-08 15:46:31,812 INFO     Training average loss at step 356000: 0.255313\n",
      "2022-11-08 15:46:41,708 INFO     Training average positive_sample_loss at step 356100: 0.290277\n",
      "2022-11-08 15:46:41,708 INFO     Training average negative_sample_loss at step 356100: 0.204210\n",
      "2022-11-08 15:46:41,708 INFO     Training average loss at step 356100: 0.247243\n",
      "2022-11-08 15:46:51,673 INFO     Training average positive_sample_loss at step 356200: 0.306946\n",
      "2022-11-08 15:46:51,673 INFO     Training average negative_sample_loss at step 356200: 0.199536\n",
      "2022-11-08 15:46:51,673 INFO     Training average loss at step 356200: 0.253241\n",
      "2022-11-08 15:47:01,596 INFO     Training average positive_sample_loss at step 356300: 0.316639\n",
      "2022-11-08 15:47:01,596 INFO     Training average negative_sample_loss at step 356300: 0.205342\n",
      "2022-11-08 15:47:01,596 INFO     Training average loss at step 356300: 0.260991\n",
      "2022-11-08 15:47:11,514 INFO     Training average positive_sample_loss at step 356400: 0.306073\n",
      "2022-11-08 15:47:11,514 INFO     Training average negative_sample_loss at step 356400: 0.204171\n",
      "2022-11-08 15:47:11,514 INFO     Training average loss at step 356400: 0.255122\n",
      "2022-11-08 15:47:21,493 INFO     Training average positive_sample_loss at step 356500: 0.306375\n",
      "2022-11-08 15:47:21,493 INFO     Training average negative_sample_loss at step 356500: 0.195308\n",
      "2022-11-08 15:47:21,493 INFO     Training average loss at step 356500: 0.250842\n",
      "2022-11-08 15:47:31,382 INFO     Training average positive_sample_loss at step 356600: 0.307609\n",
      "2022-11-08 15:47:31,383 INFO     Training average negative_sample_loss at step 356600: 0.200162\n",
      "2022-11-08 15:47:31,383 INFO     Training average loss at step 356600: 0.253886\n",
      "2022-11-08 15:47:41,172 INFO     Training average positive_sample_loss at step 356700: 0.302050\n",
      "2022-11-08 15:47:41,172 INFO     Training average negative_sample_loss at step 356700: 0.198195\n",
      "2022-11-08 15:47:41,172 INFO     Training average loss at step 356700: 0.250123\n",
      "2022-11-08 15:47:50,980 INFO     Training average positive_sample_loss at step 356800: 0.313988\n",
      "2022-11-08 15:47:50,980 INFO     Training average negative_sample_loss at step 356800: 0.201235\n",
      "2022-11-08 15:47:50,980 INFO     Training average loss at step 356800: 0.257612\n",
      "2022-11-08 15:48:00,793 INFO     Training average positive_sample_loss at step 356900: 0.292801\n",
      "2022-11-08 15:48:00,793 INFO     Training average negative_sample_loss at step 356900: 0.200425\n",
      "2022-11-08 15:48:00,793 INFO     Training average loss at step 356900: 0.246613\n",
      "2022-11-08 15:48:10,616 INFO     Training average positive_sample_loss at step 357000: 0.303729\n",
      "2022-11-08 15:48:10,617 INFO     Training average negative_sample_loss at step 357000: 0.198836\n",
      "2022-11-08 15:48:10,617 INFO     Training average loss at step 357000: 0.251282\n",
      "2022-11-08 15:48:20,406 INFO     Training average positive_sample_loss at step 357100: 0.307283\n",
      "2022-11-08 15:48:20,406 INFO     Training average negative_sample_loss at step 357100: 0.200148\n",
      "2022-11-08 15:48:20,406 INFO     Training average loss at step 357100: 0.253715\n",
      "2022-11-08 15:48:29,503 INFO     Training average positive_sample_loss at step 357200: 0.304435\n",
      "2022-11-08 15:48:29,504 INFO     Training average negative_sample_loss at step 357200: 0.199003\n",
      "2022-11-08 15:48:29,504 INFO     Training average loss at step 357200: 0.251719\n",
      "2022-11-08 15:48:39,295 INFO     Training average positive_sample_loss at step 357300: 0.315547\n",
      "2022-11-08 15:48:39,296 INFO     Training average negative_sample_loss at step 357300: 0.193647\n",
      "2022-11-08 15:48:39,296 INFO     Training average loss at step 357300: 0.254597\n",
      "2022-11-08 15:48:49,098 INFO     Training average positive_sample_loss at step 357400: 0.292642\n",
      "2022-11-08 15:48:49,098 INFO     Training average negative_sample_loss at step 357400: 0.197995\n",
      "2022-11-08 15:48:49,098 INFO     Training average loss at step 357400: 0.245318\n",
      "2022-11-08 15:48:58,880 INFO     Training average positive_sample_loss at step 357500: 0.293933\n",
      "2022-11-08 15:48:58,880 INFO     Training average negative_sample_loss at step 357500: 0.197428\n",
      "2022-11-08 15:48:58,880 INFO     Training average loss at step 357500: 0.245680\n",
      "2022-11-08 15:49:08,661 INFO     Training average positive_sample_loss at step 357600: 0.296174\n",
      "2022-11-08 15:49:08,662 INFO     Training average negative_sample_loss at step 357600: 0.203020\n",
      "2022-11-08 15:49:08,662 INFO     Training average loss at step 357600: 0.249597\n",
      "2022-11-08 15:49:18,447 INFO     Training average positive_sample_loss at step 357700: 0.293315\n",
      "2022-11-08 15:49:18,447 INFO     Training average negative_sample_loss at step 357700: 0.197999\n",
      "2022-11-08 15:49:18,447 INFO     Training average loss at step 357700: 0.245657\n",
      "2022-11-08 15:49:27,500 INFO     Training average positive_sample_loss at step 357800: 0.307635\n",
      "2022-11-08 15:49:27,500 INFO     Training average negative_sample_loss at step 357800: 0.204180\n",
      "2022-11-08 15:49:27,500 INFO     Training average loss at step 357800: 0.255907\n",
      "2022-11-08 15:49:37,292 INFO     Training average positive_sample_loss at step 357900: 0.295751\n",
      "2022-11-08 15:49:37,292 INFO     Training average negative_sample_loss at step 357900: 0.199118\n",
      "2022-11-08 15:49:37,292 INFO     Training average loss at step 357900: 0.247434\n",
      "2022-11-08 15:49:47,079 INFO     Training average positive_sample_loss at step 358000: 0.302211\n",
      "2022-11-08 15:49:47,079 INFO     Training average negative_sample_loss at step 358000: 0.196690\n",
      "2022-11-08 15:49:47,079 INFO     Training average loss at step 358000: 0.249450\n",
      "2022-11-08 15:49:56,861 INFO     Training average positive_sample_loss at step 358100: 0.298054\n",
      "2022-11-08 15:49:56,861 INFO     Training average negative_sample_loss at step 358100: 0.197345\n",
      "2022-11-08 15:49:56,861 INFO     Training average loss at step 358100: 0.247700\n",
      "2022-11-08 15:50:06,650 INFO     Training average positive_sample_loss at step 358200: 0.300610\n",
      "2022-11-08 15:50:06,650 INFO     Training average negative_sample_loss at step 358200: 0.196847\n",
      "2022-11-08 15:50:06,650 INFO     Training average loss at step 358200: 0.248729\n",
      "2022-11-08 15:50:16,432 INFO     Training average positive_sample_loss at step 358300: 0.300571\n",
      "2022-11-08 15:50:16,433 INFO     Training average negative_sample_loss at step 358300: 0.200580\n",
      "2022-11-08 15:50:16,433 INFO     Training average loss at step 358300: 0.250575\n",
      "2022-11-08 15:50:26,240 INFO     Training average positive_sample_loss at step 358400: 0.293632\n",
      "2022-11-08 15:50:26,240 INFO     Training average negative_sample_loss at step 358400: 0.200308\n",
      "2022-11-08 15:50:26,240 INFO     Training average loss at step 358400: 0.246970\n",
      "2022-11-08 15:50:36,036 INFO     Training average positive_sample_loss at step 358500: 0.298978\n",
      "2022-11-08 15:50:36,036 INFO     Training average negative_sample_loss at step 358500: 0.198098\n",
      "2022-11-08 15:50:36,036 INFO     Training average loss at step 358500: 0.248538\n",
      "2022-11-08 15:50:45,819 INFO     Training average positive_sample_loss at step 358600: 0.307865\n",
      "2022-11-08 15:50:45,819 INFO     Training average negative_sample_loss at step 358600: 0.198659\n",
      "2022-11-08 15:50:45,819 INFO     Training average loss at step 358600: 0.253262\n",
      "2022-11-08 15:50:55,608 INFO     Training average positive_sample_loss at step 358700: 0.301309\n",
      "2022-11-08 15:50:55,608 INFO     Training average negative_sample_loss at step 358700: 0.200636\n",
      "2022-11-08 15:50:55,609 INFO     Training average loss at step 358700: 0.250972\n",
      "2022-11-08 15:51:05,383 INFO     Training average positive_sample_loss at step 358800: 0.306788\n",
      "2022-11-08 15:51:05,383 INFO     Training average negative_sample_loss at step 358800: 0.202016\n",
      "2022-11-08 15:51:05,383 INFO     Training average loss at step 358800: 0.254402\n",
      "2022-11-08 15:51:15,169 INFO     Training average positive_sample_loss at step 358900: 0.301686\n",
      "2022-11-08 15:51:15,169 INFO     Training average negative_sample_loss at step 358900: 0.204456\n",
      "2022-11-08 15:51:15,169 INFO     Training average loss at step 358900: 0.253071\n",
      "2022-11-08 15:51:24,951 INFO     Training average positive_sample_loss at step 359000: 0.289520\n",
      "2022-11-08 15:51:24,951 INFO     Training average negative_sample_loss at step 359000: 0.205642\n",
      "2022-11-08 15:51:24,951 INFO     Training average loss at step 359000: 0.247581\n",
      "2022-11-08 15:51:34,748 INFO     Training average positive_sample_loss at step 359100: 0.300769\n",
      "2022-11-08 15:51:34,748 INFO     Training average negative_sample_loss at step 359100: 0.201221\n",
      "2022-11-08 15:51:34,748 INFO     Training average loss at step 359100: 0.250995\n",
      "2022-11-08 15:51:44,535 INFO     Training average positive_sample_loss at step 359200: 0.292864\n",
      "2022-11-08 15:51:44,535 INFO     Training average negative_sample_loss at step 359200: 0.196514\n",
      "2022-11-08 15:51:44,535 INFO     Training average loss at step 359200: 0.244689\n",
      "2022-11-08 15:51:54,320 INFO     Training average positive_sample_loss at step 359300: 0.304512\n",
      "2022-11-08 15:51:54,320 INFO     Training average negative_sample_loss at step 359300: 0.199277\n",
      "2022-11-08 15:51:54,320 INFO     Training average loss at step 359300: 0.251895\n",
      "2022-11-08 15:52:04,151 INFO     Training average positive_sample_loss at step 359400: 0.309636\n",
      "2022-11-08 15:52:04,151 INFO     Training average negative_sample_loss at step 359400: 0.200255\n",
      "2022-11-08 15:52:04,151 INFO     Training average loss at step 359400: 0.254946\n",
      "2022-11-08 15:52:13,964 INFO     Training average positive_sample_loss at step 359500: 0.284360\n",
      "2022-11-08 15:52:13,964 INFO     Training average negative_sample_loss at step 359500: 0.197049\n",
      "2022-11-08 15:52:13,964 INFO     Training average loss at step 359500: 0.240704\n",
      "2022-11-08 15:52:24,150 INFO     Training average positive_sample_loss at step 359600: 0.312558\n",
      "2022-11-08 15:52:24,150 INFO     Training average negative_sample_loss at step 359600: 0.202552\n",
      "2022-11-08 15:52:24,150 INFO     Training average loss at step 359600: 0.257555\n",
      "2022-11-08 15:52:34,532 INFO     Training average positive_sample_loss at step 359700: 0.316254\n",
      "2022-11-08 15:52:34,532 INFO     Training average negative_sample_loss at step 359700: 0.198135\n",
      "2022-11-08 15:52:34,532 INFO     Training average loss at step 359700: 0.257195\n",
      "2022-11-08 15:52:45,290 INFO     Training average positive_sample_loss at step 359800: 0.296726\n",
      "2022-11-08 15:52:45,291 INFO     Training average negative_sample_loss at step 359800: 0.195569\n",
      "2022-11-08 15:52:45,291 INFO     Training average loss at step 359800: 0.246148\n",
      "2022-11-08 15:52:55,096 INFO     Training average positive_sample_loss at step 359900: 0.293312\n",
      "2022-11-08 15:52:55,097 INFO     Training average negative_sample_loss at step 359900: 0.198995\n",
      "2022-11-08 15:52:55,097 INFO     Training average loss at step 359900: 0.246153\n",
      "2022-11-08 15:53:07,777 INFO     Training average positive_sample_loss at step 360000: 0.308811\n",
      "2022-11-08 15:53:07,777 INFO     Training average negative_sample_loss at step 360000: 0.208319\n",
      "2022-11-08 15:53:07,777 INFO     Training average loss at step 360000: 0.258565\n",
      "2022-11-08 15:53:17,654 INFO     Training average positive_sample_loss at step 360100: 0.307327\n",
      "2022-11-08 15:53:17,655 INFO     Training average negative_sample_loss at step 360100: 0.197462\n",
      "2022-11-08 15:53:17,655 INFO     Training average loss at step 360100: 0.252395\n",
      "2022-11-08 15:53:27,467 INFO     Training average positive_sample_loss at step 360200: 0.296641\n",
      "2022-11-08 15:53:27,468 INFO     Training average negative_sample_loss at step 360200: 0.192950\n",
      "2022-11-08 15:53:27,468 INFO     Training average loss at step 360200: 0.244795\n",
      "2022-11-08 15:53:37,300 INFO     Training average positive_sample_loss at step 360300: 0.296194\n",
      "2022-11-08 15:53:37,300 INFO     Training average negative_sample_loss at step 360300: 0.203657\n",
      "2022-11-08 15:53:37,300 INFO     Training average loss at step 360300: 0.249925\n",
      "2022-11-08 15:53:47,345 INFO     Training average positive_sample_loss at step 360400: 0.288544\n",
      "2022-11-08 15:53:47,346 INFO     Training average negative_sample_loss at step 360400: 0.200657\n",
      "2022-11-08 15:53:47,346 INFO     Training average loss at step 360400: 0.244600\n",
      "2022-11-08 15:53:57,312 INFO     Training average positive_sample_loss at step 360500: 0.301733\n",
      "2022-11-08 15:53:57,312 INFO     Training average negative_sample_loss at step 360500: 0.200966\n",
      "2022-11-08 15:53:57,312 INFO     Training average loss at step 360500: 0.251349\n",
      "2022-11-08 15:54:07,123 INFO     Training average positive_sample_loss at step 360600: 0.315901\n",
      "2022-11-08 15:54:07,123 INFO     Training average negative_sample_loss at step 360600: 0.190713\n",
      "2022-11-08 15:54:07,123 INFO     Training average loss at step 360600: 0.253307\n",
      "2022-11-08 15:54:16,931 INFO     Training average positive_sample_loss at step 360700: 0.298015\n",
      "2022-11-08 15:54:16,931 INFO     Training average negative_sample_loss at step 360700: 0.198148\n",
      "2022-11-08 15:54:16,931 INFO     Training average loss at step 360700: 0.248081\n",
      "2022-11-08 15:54:26,818 INFO     Training average positive_sample_loss at step 360800: 0.309091\n",
      "2022-11-08 15:54:26,818 INFO     Training average negative_sample_loss at step 360800: 0.195490\n",
      "2022-11-08 15:54:26,818 INFO     Training average loss at step 360800: 0.252291\n",
      "2022-11-08 15:54:36,631 INFO     Training average positive_sample_loss at step 360900: 0.303339\n",
      "2022-11-08 15:54:36,631 INFO     Training average negative_sample_loss at step 360900: 0.195081\n",
      "2022-11-08 15:54:36,631 INFO     Training average loss at step 360900: 0.249210\n",
      "2022-11-08 15:54:46,452 INFO     Training average positive_sample_loss at step 361000: 0.302843\n",
      "2022-11-08 15:54:46,452 INFO     Training average negative_sample_loss at step 361000: 0.199232\n",
      "2022-11-08 15:54:46,452 INFO     Training average loss at step 361000: 0.251038\n",
      "2022-11-08 15:54:56,266 INFO     Training average positive_sample_loss at step 361100: 0.307805\n",
      "2022-11-08 15:54:56,266 INFO     Training average negative_sample_loss at step 361100: 0.196801\n",
      "2022-11-08 15:54:56,266 INFO     Training average loss at step 361100: 0.252303\n",
      "2022-11-08 15:55:06,078 INFO     Training average positive_sample_loss at step 361200: 0.290486\n",
      "2022-11-08 15:55:06,078 INFO     Training average negative_sample_loss at step 361200: 0.199510\n",
      "2022-11-08 15:55:06,078 INFO     Training average loss at step 361200: 0.244998\n",
      "2022-11-08 15:55:15,889 INFO     Training average positive_sample_loss at step 361300: 0.300208\n",
      "2022-11-08 15:55:15,889 INFO     Training average negative_sample_loss at step 361300: 0.197066\n",
      "2022-11-08 15:55:15,889 INFO     Training average loss at step 361300: 0.248637\n",
      "2022-11-08 15:55:25,717 INFO     Training average positive_sample_loss at step 361400: 0.305615\n",
      "2022-11-08 15:55:25,717 INFO     Training average negative_sample_loss at step 361400: 0.196280\n",
      "2022-11-08 15:55:25,717 INFO     Training average loss at step 361400: 0.250948\n",
      "2022-11-08 15:55:35,531 INFO     Training average positive_sample_loss at step 361500: 0.298684\n",
      "2022-11-08 15:55:35,531 INFO     Training average negative_sample_loss at step 361500: 0.199474\n",
      "2022-11-08 15:55:35,531 INFO     Training average loss at step 361500: 0.249079\n",
      "2022-11-08 15:55:45,345 INFO     Training average positive_sample_loss at step 361600: 0.316356\n",
      "2022-11-08 15:55:45,345 INFO     Training average negative_sample_loss at step 361600: 0.200631\n",
      "2022-11-08 15:55:45,345 INFO     Training average loss at step 361600: 0.258493\n",
      "2022-11-08 15:55:55,173 INFO     Training average positive_sample_loss at step 361700: 0.310832\n",
      "2022-11-08 15:55:55,173 INFO     Training average negative_sample_loss at step 361700: 0.200157\n",
      "2022-11-08 15:55:55,173 INFO     Training average loss at step 361700: 0.255494\n",
      "2022-11-08 15:56:05,059 INFO     Training average positive_sample_loss at step 361800: 0.299050\n",
      "2022-11-08 15:56:05,059 INFO     Training average negative_sample_loss at step 361800: 0.200219\n",
      "2022-11-08 15:56:05,059 INFO     Training average loss at step 361800: 0.249634\n",
      "2022-11-08 15:56:15,018 INFO     Training average positive_sample_loss at step 361900: 0.302747\n",
      "2022-11-08 15:56:15,018 INFO     Training average negative_sample_loss at step 361900: 0.203323\n",
      "2022-11-08 15:56:15,018 INFO     Training average loss at step 361900: 0.253035\n",
      "2022-11-08 15:56:24,859 INFO     Training average positive_sample_loss at step 362000: 0.312652\n",
      "2022-11-08 15:56:24,860 INFO     Training average negative_sample_loss at step 362000: 0.196010\n",
      "2022-11-08 15:56:24,860 INFO     Training average loss at step 362000: 0.254331\n",
      "2022-11-08 15:56:34,719 INFO     Training average positive_sample_loss at step 362100: 0.296243\n",
      "2022-11-08 15:56:34,719 INFO     Training average negative_sample_loss at step 362100: 0.199575\n",
      "2022-11-08 15:56:34,719 INFO     Training average loss at step 362100: 0.247909\n",
      "2022-11-08 15:56:44,597 INFO     Training average positive_sample_loss at step 362200: 0.294201\n",
      "2022-11-08 15:56:44,597 INFO     Training average negative_sample_loss at step 362200: 0.201947\n",
      "2022-11-08 15:56:44,597 INFO     Training average loss at step 362200: 0.248074\n",
      "2022-11-08 15:56:54,490 INFO     Training average positive_sample_loss at step 362300: 0.312274\n",
      "2022-11-08 15:56:54,490 INFO     Training average negative_sample_loss at step 362300: 0.197936\n",
      "2022-11-08 15:56:54,490 INFO     Training average loss at step 362300: 0.255105\n",
      "2022-11-08 15:57:04,349 INFO     Training average positive_sample_loss at step 362400: 0.316870\n",
      "2022-11-08 15:57:04,349 INFO     Training average negative_sample_loss at step 362400: 0.197019\n",
      "2022-11-08 15:57:04,349 INFO     Training average loss at step 362400: 0.256944\n",
      "2022-11-08 15:57:14,257 INFO     Training average positive_sample_loss at step 362500: 0.303631\n",
      "2022-11-08 15:57:14,257 INFO     Training average negative_sample_loss at step 362500: 0.195946\n",
      "2022-11-08 15:57:14,258 INFO     Training average loss at step 362500: 0.249788\n",
      "2022-11-08 15:57:24,095 INFO     Training average positive_sample_loss at step 362600: 0.305480\n",
      "2022-11-08 15:57:24,095 INFO     Training average negative_sample_loss at step 362600: 0.200002\n",
      "2022-11-08 15:57:24,095 INFO     Training average loss at step 362600: 0.252741\n",
      "2022-11-08 15:57:33,641 INFO     Training average positive_sample_loss at step 362700: 0.294584\n",
      "2022-11-08 15:57:33,641 INFO     Training average negative_sample_loss at step 362700: 0.196691\n",
      "2022-11-08 15:57:33,641 INFO     Training average loss at step 362700: 0.245637\n",
      "2022-11-08 15:57:43,583 INFO     Training average positive_sample_loss at step 362800: 0.305596\n",
      "2022-11-08 15:57:43,583 INFO     Training average negative_sample_loss at step 362800: 0.199092\n",
      "2022-11-08 15:57:43,583 INFO     Training average loss at step 362800: 0.252344\n",
      "2022-11-08 15:57:53,439 INFO     Training average positive_sample_loss at step 362900: 0.298018\n",
      "2022-11-08 15:57:53,439 INFO     Training average negative_sample_loss at step 362900: 0.197000\n",
      "2022-11-08 15:57:53,439 INFO     Training average loss at step 362900: 0.247509\n",
      "2022-11-08 15:58:03,312 INFO     Training average positive_sample_loss at step 363000: 0.289804\n",
      "2022-11-08 15:58:03,313 INFO     Training average negative_sample_loss at step 363000: 0.200720\n",
      "2022-11-08 15:58:03,313 INFO     Training average loss at step 363000: 0.245262\n",
      "2022-11-08 15:58:13,210 INFO     Training average positive_sample_loss at step 363100: 0.309717\n",
      "2022-11-08 15:58:13,210 INFO     Training average negative_sample_loss at step 363100: 0.201700\n",
      "2022-11-08 15:58:13,211 INFO     Training average loss at step 363100: 0.255709\n",
      "2022-11-08 15:58:22,386 INFO     Training average positive_sample_loss at step 363200: 0.294379\n",
      "2022-11-08 15:58:22,386 INFO     Training average negative_sample_loss at step 363200: 0.200944\n",
      "2022-11-08 15:58:22,386 INFO     Training average loss at step 363200: 0.247662\n",
      "2022-11-08 15:58:32,299 INFO     Training average positive_sample_loss at step 363300: 0.305711\n",
      "2022-11-08 15:58:32,299 INFO     Training average negative_sample_loss at step 363300: 0.199440\n",
      "2022-11-08 15:58:32,299 INFO     Training average loss at step 363300: 0.252575\n",
      "2022-11-08 15:58:42,210 INFO     Training average positive_sample_loss at step 363400: 0.322379\n",
      "2022-11-08 15:58:42,210 INFO     Training average negative_sample_loss at step 363400: 0.192356\n",
      "2022-11-08 15:58:42,210 INFO     Training average loss at step 363400: 0.257368\n",
      "2022-11-08 15:58:52,103 INFO     Training average positive_sample_loss at step 363500: 0.289952\n",
      "2022-11-08 15:58:52,104 INFO     Training average negative_sample_loss at step 363500: 0.201236\n",
      "2022-11-08 15:58:52,104 INFO     Training average loss at step 363500: 0.245594\n",
      "2022-11-08 15:59:02,038 INFO     Training average positive_sample_loss at step 363600: 0.305415\n",
      "2022-11-08 15:59:02,038 INFO     Training average negative_sample_loss at step 363600: 0.200573\n",
      "2022-11-08 15:59:02,038 INFO     Training average loss at step 363600: 0.252994\n",
      "2022-11-08 15:59:11,903 INFO     Training average positive_sample_loss at step 363700: 0.307040\n",
      "2022-11-08 15:59:11,903 INFO     Training average negative_sample_loss at step 363700: 0.200557\n",
      "2022-11-08 15:59:11,903 INFO     Training average loss at step 363700: 0.253798\n",
      "2022-11-08 15:59:21,826 INFO     Training average positive_sample_loss at step 363800: 0.298540\n",
      "2022-11-08 15:59:21,826 INFO     Training average negative_sample_loss at step 363800: 0.199900\n",
      "2022-11-08 15:59:21,826 INFO     Training average loss at step 363800: 0.249220\n",
      "2022-11-08 15:59:31,657 INFO     Training average positive_sample_loss at step 363900: 0.292229\n",
      "2022-11-08 15:59:31,657 INFO     Training average negative_sample_loss at step 363900: 0.198435\n",
      "2022-11-08 15:59:31,657 INFO     Training average loss at step 363900: 0.245332\n",
      "2022-11-08 15:59:41,534 INFO     Training average positive_sample_loss at step 364000: 0.316493\n",
      "2022-11-08 15:59:41,534 INFO     Training average negative_sample_loss at step 364000: 0.197873\n",
      "2022-11-08 15:59:41,534 INFO     Training average loss at step 364000: 0.257183\n",
      "2022-11-08 15:59:51,395 INFO     Training average positive_sample_loss at step 364100: 0.302880\n",
      "2022-11-08 15:59:51,395 INFO     Training average negative_sample_loss at step 364100: 0.196433\n",
      "2022-11-08 15:59:51,395 INFO     Training average loss at step 364100: 0.249656\n",
      "2022-11-08 16:00:01,268 INFO     Training average positive_sample_loss at step 364200: 0.295478\n",
      "2022-11-08 16:00:01,268 INFO     Training average negative_sample_loss at step 364200: 0.198236\n",
      "2022-11-08 16:00:01,268 INFO     Training average loss at step 364200: 0.246857\n",
      "2022-11-08 16:00:11,677 INFO     Training average positive_sample_loss at step 364300: 0.299114\n",
      "2022-11-08 16:00:11,677 INFO     Training average negative_sample_loss at step 364300: 0.193493\n",
      "2022-11-08 16:00:11,677 INFO     Training average loss at step 364300: 0.246304\n",
      "2022-11-08 16:00:22,224 INFO     Training average positive_sample_loss at step 364400: 0.296004\n",
      "2022-11-08 16:00:22,224 INFO     Training average negative_sample_loss at step 364400: 0.195501\n",
      "2022-11-08 16:00:22,224 INFO     Training average loss at step 364400: 0.245753\n",
      "2022-11-08 16:00:33,172 INFO     Training average positive_sample_loss at step 364500: 0.301346\n",
      "2022-11-08 16:00:33,173 INFO     Training average negative_sample_loss at step 364500: 0.196914\n",
      "2022-11-08 16:00:33,173 INFO     Training average loss at step 364500: 0.249130\n",
      "2022-11-08 16:00:42,964 INFO     Training average positive_sample_loss at step 364600: 0.310112\n",
      "2022-11-08 16:00:42,964 INFO     Training average negative_sample_loss at step 364600: 0.199320\n",
      "2022-11-08 16:00:42,964 INFO     Training average loss at step 364600: 0.254716\n",
      "2022-11-08 16:00:52,754 INFO     Training average positive_sample_loss at step 364700: 0.280926\n",
      "2022-11-08 16:00:52,754 INFO     Training average negative_sample_loss at step 364700: 0.198976\n",
      "2022-11-08 16:00:52,754 INFO     Training average loss at step 364700: 0.239951\n",
      "2022-11-08 16:01:02,614 INFO     Training average positive_sample_loss at step 364800: 0.308166\n",
      "2022-11-08 16:01:02,614 INFO     Training average negative_sample_loss at step 364800: 0.201613\n",
      "2022-11-08 16:01:02,614 INFO     Training average loss at step 364800: 0.254889\n",
      "2022-11-08 16:01:12,388 INFO     Training average positive_sample_loss at step 364900: 0.299011\n",
      "2022-11-08 16:01:12,388 INFO     Training average negative_sample_loss at step 364900: 0.199027\n",
      "2022-11-08 16:01:12,388 INFO     Training average loss at step 364900: 0.249019\n",
      "2022-11-08 16:01:22,219 INFO     Training average positive_sample_loss at step 365000: 0.299060\n",
      "2022-11-08 16:01:22,219 INFO     Training average negative_sample_loss at step 365000: 0.203533\n",
      "2022-11-08 16:01:22,219 INFO     Training average loss at step 365000: 0.251297\n",
      "2022-11-08 16:01:32,002 INFO     Training average positive_sample_loss at step 365100: 0.293603\n",
      "2022-11-08 16:01:32,002 INFO     Training average negative_sample_loss at step 365100: 0.197415\n",
      "2022-11-08 16:01:32,002 INFO     Training average loss at step 365100: 0.245509\n",
      "2022-11-08 16:01:42,016 INFO     Training average positive_sample_loss at step 365200: 0.296221\n",
      "2022-11-08 16:01:42,017 INFO     Training average negative_sample_loss at step 365200: 0.198683\n",
      "2022-11-08 16:01:42,017 INFO     Training average loss at step 365200: 0.247452\n",
      "2022-11-08 16:01:51,812 INFO     Training average positive_sample_loss at step 365300: 0.296055\n",
      "2022-11-08 16:01:51,812 INFO     Training average negative_sample_loss at step 365300: 0.200493\n",
      "2022-11-08 16:01:51,812 INFO     Training average loss at step 365300: 0.248274\n",
      "2022-11-08 16:02:01,677 INFO     Training average positive_sample_loss at step 365400: 0.291136\n",
      "2022-11-08 16:02:01,677 INFO     Training average negative_sample_loss at step 365400: 0.198353\n",
      "2022-11-08 16:02:01,677 INFO     Training average loss at step 365400: 0.244745\n",
      "2022-11-08 16:02:11,408 INFO     Training average positive_sample_loss at step 365500: 0.307213\n",
      "2022-11-08 16:02:11,408 INFO     Training average negative_sample_loss at step 365500: 0.195169\n",
      "2022-11-08 16:02:11,408 INFO     Training average loss at step 365500: 0.251191\n",
      "2022-11-08 16:02:21,403 INFO     Training average positive_sample_loss at step 365600: 0.293468\n",
      "2022-11-08 16:02:21,403 INFO     Training average negative_sample_loss at step 365600: 0.197650\n",
      "2022-11-08 16:02:21,403 INFO     Training average loss at step 365600: 0.245559\n",
      "2022-11-08 16:02:31,521 INFO     Training average positive_sample_loss at step 365700: 0.299401\n",
      "2022-11-08 16:02:31,521 INFO     Training average negative_sample_loss at step 365700: 0.202068\n",
      "2022-11-08 16:02:31,521 INFO     Training average loss at step 365700: 0.250734\n",
      "2022-11-08 16:02:41,554 INFO     Training average positive_sample_loss at step 365800: 0.300803\n",
      "2022-11-08 16:02:41,554 INFO     Training average negative_sample_loss at step 365800: 0.196295\n",
      "2022-11-08 16:02:41,554 INFO     Training average loss at step 365800: 0.248549\n",
      "2022-11-08 16:02:51,556 INFO     Training average positive_sample_loss at step 365900: 0.309535\n",
      "2022-11-08 16:02:51,556 INFO     Training average negative_sample_loss at step 365900: 0.199754\n",
      "2022-11-08 16:02:51,556 INFO     Training average loss at step 365900: 0.254645\n",
      "2022-11-08 16:03:01,552 INFO     Training average positive_sample_loss at step 366000: 0.308245\n",
      "2022-11-08 16:03:01,553 INFO     Training average negative_sample_loss at step 366000: 0.193646\n",
      "2022-11-08 16:03:01,553 INFO     Training average loss at step 366000: 0.250945\n",
      "2022-11-08 16:03:11,603 INFO     Training average positive_sample_loss at step 366100: 0.297657\n",
      "2022-11-08 16:03:11,603 INFO     Training average negative_sample_loss at step 366100: 0.199036\n",
      "2022-11-08 16:03:11,603 INFO     Training average loss at step 366100: 0.248347\n",
      "2022-11-08 16:03:21,756 INFO     Training average positive_sample_loss at step 366200: 0.287690\n",
      "2022-11-08 16:03:21,757 INFO     Training average negative_sample_loss at step 366200: 0.195499\n",
      "2022-11-08 16:03:21,757 INFO     Training average loss at step 366200: 0.241595\n",
      "2022-11-08 16:03:31,836 INFO     Training average positive_sample_loss at step 366300: 0.302042\n",
      "2022-11-08 16:03:31,836 INFO     Training average negative_sample_loss at step 366300: 0.200292\n",
      "2022-11-08 16:03:31,836 INFO     Training average loss at step 366300: 0.251167\n",
      "2022-11-08 16:03:41,898 INFO     Training average positive_sample_loss at step 366400: 0.287053\n",
      "2022-11-08 16:03:41,898 INFO     Training average negative_sample_loss at step 366400: 0.195066\n",
      "2022-11-08 16:03:41,898 INFO     Training average loss at step 366400: 0.241060\n",
      "2022-11-08 16:03:52,021 INFO     Training average positive_sample_loss at step 366500: 0.304790\n",
      "2022-11-08 16:03:52,022 INFO     Training average negative_sample_loss at step 366500: 0.197555\n",
      "2022-11-08 16:03:52,022 INFO     Training average loss at step 366500: 0.251173\n",
      "2022-11-08 16:04:02,133 INFO     Training average positive_sample_loss at step 366600: 0.283964\n",
      "2022-11-08 16:04:02,133 INFO     Training average negative_sample_loss at step 366600: 0.196742\n",
      "2022-11-08 16:04:02,133 INFO     Training average loss at step 366600: 0.240353\n",
      "2022-11-08 16:04:12,272 INFO     Training average positive_sample_loss at step 366700: 0.285968\n",
      "2022-11-08 16:04:12,272 INFO     Training average negative_sample_loss at step 366700: 0.197677\n",
      "2022-11-08 16:04:12,272 INFO     Training average loss at step 366700: 0.241823\n",
      "2022-11-08 16:04:22,409 INFO     Training average positive_sample_loss at step 366800: 0.312084\n",
      "2022-11-08 16:04:22,409 INFO     Training average negative_sample_loss at step 366800: 0.197886\n",
      "2022-11-08 16:04:22,409 INFO     Training average loss at step 366800: 0.254985\n",
      "2022-11-08 16:04:32,519 INFO     Training average positive_sample_loss at step 366900: 0.308305\n",
      "2022-11-08 16:04:32,520 INFO     Training average negative_sample_loss at step 366900: 0.194112\n",
      "2022-11-08 16:04:32,520 INFO     Training average loss at step 366900: 0.251209\n",
      "2022-11-08 16:04:42,609 INFO     Training average positive_sample_loss at step 367000: 0.291759\n",
      "2022-11-08 16:04:42,609 INFO     Training average negative_sample_loss at step 367000: 0.198347\n",
      "2022-11-08 16:04:42,609 INFO     Training average loss at step 367000: 0.245053\n",
      "2022-11-08 16:04:52,688 INFO     Training average positive_sample_loss at step 367100: 0.297640\n",
      "2022-11-08 16:04:52,688 INFO     Training average negative_sample_loss at step 367100: 0.194289\n",
      "2022-11-08 16:04:52,689 INFO     Training average loss at step 367100: 0.245965\n",
      "2022-11-08 16:05:02,720 INFO     Training average positive_sample_loss at step 367200: 0.294797\n",
      "2022-11-08 16:05:02,721 INFO     Training average negative_sample_loss at step 367200: 0.199465\n",
      "2022-11-08 16:05:02,721 INFO     Training average loss at step 367200: 0.247131\n",
      "2022-11-08 16:05:12,775 INFO     Training average positive_sample_loss at step 367300: 0.299569\n",
      "2022-11-08 16:05:12,775 INFO     Training average negative_sample_loss at step 367300: 0.202718\n",
      "2022-11-08 16:05:12,775 INFO     Training average loss at step 367300: 0.251143\n",
      "2022-11-08 16:05:22,692 INFO     Training average positive_sample_loss at step 367400: 0.288495\n",
      "2022-11-08 16:05:22,693 INFO     Training average negative_sample_loss at step 367400: 0.195391\n",
      "2022-11-08 16:05:22,693 INFO     Training average loss at step 367400: 0.241943\n",
      "2022-11-08 16:05:32,607 INFO     Training average positive_sample_loss at step 367500: 0.305088\n",
      "2022-11-08 16:05:32,607 INFO     Training average negative_sample_loss at step 367500: 0.190379\n",
      "2022-11-08 16:05:32,607 INFO     Training average loss at step 367500: 0.247734\n",
      "2022-11-08 16:05:42,527 INFO     Training average positive_sample_loss at step 367600: 0.306264\n",
      "2022-11-08 16:05:42,527 INFO     Training average negative_sample_loss at step 367600: 0.194919\n",
      "2022-11-08 16:05:42,527 INFO     Training average loss at step 367600: 0.250592\n",
      "2022-11-08 16:05:52,437 INFO     Training average positive_sample_loss at step 367700: 0.300674\n",
      "2022-11-08 16:05:52,437 INFO     Training average negative_sample_loss at step 367700: 0.199853\n",
      "2022-11-08 16:05:52,437 INFO     Training average loss at step 367700: 0.250263\n",
      "2022-11-08 16:06:02,346 INFO     Training average positive_sample_loss at step 367800: 0.300261\n",
      "2022-11-08 16:06:02,346 INFO     Training average negative_sample_loss at step 367800: 0.198756\n",
      "2022-11-08 16:06:02,346 INFO     Training average loss at step 367800: 0.249508\n",
      "2022-11-08 16:06:12,258 INFO     Training average positive_sample_loss at step 367900: 0.295617\n",
      "2022-11-08 16:06:12,258 INFO     Training average negative_sample_loss at step 367900: 0.204945\n",
      "2022-11-08 16:06:12,258 INFO     Training average loss at step 367900: 0.250281\n",
      "2022-11-08 16:06:22,250 INFO     Training average positive_sample_loss at step 368000: 0.307932\n",
      "2022-11-08 16:06:22,251 INFO     Training average negative_sample_loss at step 368000: 0.197282\n",
      "2022-11-08 16:06:22,251 INFO     Training average loss at step 368000: 0.252607\n",
      "2022-11-08 16:06:32,017 INFO     Training average positive_sample_loss at step 368100: 0.303022\n",
      "2022-11-08 16:06:32,018 INFO     Training average negative_sample_loss at step 368100: 0.193126\n",
      "2022-11-08 16:06:32,018 INFO     Training average loss at step 368100: 0.248074\n",
      "2022-11-08 16:06:41,130 INFO     Training average positive_sample_loss at step 368200: 0.310473\n",
      "2022-11-08 16:06:41,130 INFO     Training average negative_sample_loss at step 368200: 0.204293\n",
      "2022-11-08 16:06:41,130 INFO     Training average loss at step 368200: 0.257383\n",
      "2022-11-08 16:06:50,891 INFO     Training average positive_sample_loss at step 368300: 0.307007\n",
      "2022-11-08 16:06:50,891 INFO     Training average negative_sample_loss at step 368300: 0.197122\n",
      "2022-11-08 16:06:50,891 INFO     Training average loss at step 368300: 0.252065\n",
      "2022-11-08 16:07:00,776 INFO     Training average positive_sample_loss at step 368400: 0.302605\n",
      "2022-11-08 16:07:00,777 INFO     Training average negative_sample_loss at step 368400: 0.196132\n",
      "2022-11-08 16:07:00,777 INFO     Training average loss at step 368400: 0.249368\n",
      "2022-11-08 16:07:10,576 INFO     Training average positive_sample_loss at step 368500: 0.291028\n",
      "2022-11-08 16:07:10,576 INFO     Training average negative_sample_loss at step 368500: 0.200211\n",
      "2022-11-08 16:07:10,577 INFO     Training average loss at step 368500: 0.245620\n",
      "2022-11-08 16:07:20,562 INFO     Training average positive_sample_loss at step 368600: 0.288762\n",
      "2022-11-08 16:07:20,562 INFO     Training average negative_sample_loss at step 368600: 0.199646\n",
      "2022-11-08 16:07:20,562 INFO     Training average loss at step 368600: 0.244204\n",
      "2022-11-08 16:07:29,609 INFO     Training average positive_sample_loss at step 368700: 0.305532\n",
      "2022-11-08 16:07:29,609 INFO     Training average negative_sample_loss at step 368700: 0.199685\n",
      "2022-11-08 16:07:29,609 INFO     Training average loss at step 368700: 0.252609\n",
      "2022-11-08 16:07:39,433 INFO     Training average positive_sample_loss at step 368800: 0.297140\n",
      "2022-11-08 16:07:39,434 INFO     Training average negative_sample_loss at step 368800: 0.193339\n",
      "2022-11-08 16:07:39,434 INFO     Training average loss at step 368800: 0.245239\n",
      "2022-11-08 16:07:49,126 INFO     Training average positive_sample_loss at step 368900: 0.300240\n",
      "2022-11-08 16:07:49,126 INFO     Training average negative_sample_loss at step 368900: 0.200382\n",
      "2022-11-08 16:07:49,126 INFO     Training average loss at step 368900: 0.250311\n",
      "2022-11-08 16:07:59,238 INFO     Training average positive_sample_loss at step 369000: 0.294413\n",
      "2022-11-08 16:07:59,238 INFO     Training average negative_sample_loss at step 369000: 0.199337\n",
      "2022-11-08 16:07:59,238 INFO     Training average loss at step 369000: 0.246875\n",
      "2022-11-08 16:08:09,607 INFO     Training average positive_sample_loss at step 369100: 0.299851\n",
      "2022-11-08 16:08:09,607 INFO     Training average negative_sample_loss at step 369100: 0.202523\n",
      "2022-11-08 16:08:09,607 INFO     Training average loss at step 369100: 0.251187\n",
      "2022-11-08 16:08:20,349 INFO     Training average positive_sample_loss at step 369200: 0.289517\n",
      "2022-11-08 16:08:20,349 INFO     Training average negative_sample_loss at step 369200: 0.197854\n",
      "2022-11-08 16:08:20,349 INFO     Training average loss at step 369200: 0.243686\n",
      "2022-11-08 16:08:30,031 INFO     Training average positive_sample_loss at step 369300: 0.294810\n",
      "2022-11-08 16:08:30,031 INFO     Training average negative_sample_loss at step 369300: 0.195487\n",
      "2022-11-08 16:08:30,031 INFO     Training average loss at step 369300: 0.245149\n",
      "2022-11-08 16:08:39,749 INFO     Training average positive_sample_loss at step 369400: 0.288355\n",
      "2022-11-08 16:08:39,749 INFO     Training average negative_sample_loss at step 369400: 0.198900\n",
      "2022-11-08 16:08:39,749 INFO     Training average loss at step 369400: 0.243628\n",
      "2022-11-08 16:08:49,568 INFO     Training average positive_sample_loss at step 369500: 0.306149\n",
      "2022-11-08 16:08:49,569 INFO     Training average negative_sample_loss at step 369500: 0.198788\n",
      "2022-11-08 16:08:49,569 INFO     Training average loss at step 369500: 0.252468\n",
      "2022-11-08 16:08:59,304 INFO     Training average positive_sample_loss at step 369600: 0.304745\n",
      "2022-11-08 16:08:59,304 INFO     Training average negative_sample_loss at step 369600: 0.194449\n",
      "2022-11-08 16:08:59,304 INFO     Training average loss at step 369600: 0.249597\n",
      "2022-11-08 16:09:09,082 INFO     Training average positive_sample_loss at step 369700: 0.301933\n",
      "2022-11-08 16:09:09,082 INFO     Training average negative_sample_loss at step 369700: 0.199069\n",
      "2022-11-08 16:09:09,082 INFO     Training average loss at step 369700: 0.250501\n",
      "2022-11-08 16:09:18,866 INFO     Training average positive_sample_loss at step 369800: 0.296424\n",
      "2022-11-08 16:09:18,866 INFO     Training average negative_sample_loss at step 369800: 0.198774\n",
      "2022-11-08 16:09:18,866 INFO     Training average loss at step 369800: 0.247599\n",
      "2022-11-08 16:09:28,580 INFO     Training average positive_sample_loss at step 369900: 0.293367\n",
      "2022-11-08 16:09:28,580 INFO     Training average negative_sample_loss at step 369900: 0.194431\n",
      "2022-11-08 16:09:28,580 INFO     Training average loss at step 369900: 0.243899\n",
      "2022-11-08 16:09:41,037 INFO     Training average positive_sample_loss at step 370000: 0.287327\n",
      "2022-11-08 16:09:41,037 INFO     Training average negative_sample_loss at step 370000: 0.199277\n",
      "2022-11-08 16:09:41,037 INFO     Training average loss at step 370000: 0.243302\n",
      "2022-11-08 16:09:50,819 INFO     Training average positive_sample_loss at step 370100: 0.284526\n",
      "2022-11-08 16:09:50,819 INFO     Training average negative_sample_loss at step 370100: 0.198346\n",
      "2022-11-08 16:09:50,819 INFO     Training average loss at step 370100: 0.241436\n",
      "2022-11-08 16:10:00,668 INFO     Training average positive_sample_loss at step 370200: 0.308072\n",
      "2022-11-08 16:10:00,668 INFO     Training average negative_sample_loss at step 370200: 0.192272\n",
      "2022-11-08 16:10:00,668 INFO     Training average loss at step 370200: 0.250172\n",
      "2022-11-08 16:10:10,419 INFO     Training average positive_sample_loss at step 370300: 0.286799\n",
      "2022-11-08 16:10:10,419 INFO     Training average negative_sample_loss at step 370300: 0.194013\n",
      "2022-11-08 16:10:10,419 INFO     Training average loss at step 370300: 0.240406\n",
      "2022-11-08 16:10:20,247 INFO     Training average positive_sample_loss at step 370400: 0.299014\n",
      "2022-11-08 16:10:20,248 INFO     Training average negative_sample_loss at step 370400: 0.199417\n",
      "2022-11-08 16:10:20,248 INFO     Training average loss at step 370400: 0.249216\n",
      "2022-11-08 16:10:30,077 INFO     Training average positive_sample_loss at step 370500: 0.298585\n",
      "2022-11-08 16:10:30,078 INFO     Training average negative_sample_loss at step 370500: 0.194851\n",
      "2022-11-08 16:10:30,078 INFO     Training average loss at step 370500: 0.246718\n",
      "2022-11-08 16:10:39,751 INFO     Training average positive_sample_loss at step 370600: 0.289971\n",
      "2022-11-08 16:10:39,751 INFO     Training average negative_sample_loss at step 370600: 0.196434\n",
      "2022-11-08 16:10:39,751 INFO     Training average loss at step 370600: 0.243202\n",
      "2022-11-08 16:10:49,534 INFO     Training average positive_sample_loss at step 370700: 0.296014\n",
      "2022-11-08 16:10:49,534 INFO     Training average negative_sample_loss at step 370700: 0.195919\n",
      "2022-11-08 16:10:49,534 INFO     Training average loss at step 370700: 0.245966\n",
      "2022-11-08 16:10:59,260 INFO     Training average positive_sample_loss at step 370800: 0.293571\n",
      "2022-11-08 16:10:59,260 INFO     Training average negative_sample_loss at step 370800: 0.195551\n",
      "2022-11-08 16:10:59,260 INFO     Training average loss at step 370800: 0.244561\n",
      "2022-11-08 16:11:08,959 INFO     Training average positive_sample_loss at step 370900: 0.303892\n",
      "2022-11-08 16:11:08,959 INFO     Training average negative_sample_loss at step 370900: 0.196031\n",
      "2022-11-08 16:11:08,959 INFO     Training average loss at step 370900: 0.249962\n",
      "2022-11-08 16:11:18,759 INFO     Training average positive_sample_loss at step 371000: 0.287212\n",
      "2022-11-08 16:11:18,759 INFO     Training average negative_sample_loss at step 371000: 0.196059\n",
      "2022-11-08 16:11:18,759 INFO     Training average loss at step 371000: 0.241636\n",
      "2022-11-08 16:11:28,474 INFO     Training average positive_sample_loss at step 371100: 0.299794\n",
      "2022-11-08 16:11:28,474 INFO     Training average negative_sample_loss at step 371100: 0.194133\n",
      "2022-11-08 16:11:28,474 INFO     Training average loss at step 371100: 0.246963\n",
      "2022-11-08 16:11:38,182 INFO     Training average positive_sample_loss at step 371200: 0.293548\n",
      "2022-11-08 16:11:38,182 INFO     Training average negative_sample_loss at step 371200: 0.196088\n",
      "2022-11-08 16:11:38,182 INFO     Training average loss at step 371200: 0.244818\n",
      "2022-11-08 16:11:47,969 INFO     Training average positive_sample_loss at step 371300: 0.285748\n",
      "2022-11-08 16:11:47,969 INFO     Training average negative_sample_loss at step 371300: 0.192709\n",
      "2022-11-08 16:11:47,969 INFO     Training average loss at step 371300: 0.239228\n",
      "2022-11-08 16:11:57,729 INFO     Training average positive_sample_loss at step 371400: 0.285719\n",
      "2022-11-08 16:11:57,729 INFO     Training average negative_sample_loss at step 371400: 0.197080\n",
      "2022-11-08 16:11:57,729 INFO     Training average loss at step 371400: 0.241399\n",
      "2022-11-08 16:12:07,551 INFO     Training average positive_sample_loss at step 371500: 0.300261\n",
      "2022-11-08 16:12:07,551 INFO     Training average negative_sample_loss at step 371500: 0.201083\n",
      "2022-11-08 16:12:07,552 INFO     Training average loss at step 371500: 0.250672\n",
      "2022-11-08 16:12:17,340 INFO     Training average positive_sample_loss at step 371600: 0.306160\n",
      "2022-11-08 16:12:17,340 INFO     Training average negative_sample_loss at step 371600: 0.199119\n",
      "2022-11-08 16:12:17,340 INFO     Training average loss at step 371600: 0.252640\n",
      "2022-11-08 16:12:27,106 INFO     Training average positive_sample_loss at step 371700: 0.285596\n",
      "2022-11-08 16:12:27,107 INFO     Training average negative_sample_loss at step 371700: 0.196946\n",
      "2022-11-08 16:12:27,107 INFO     Training average loss at step 371700: 0.241271\n",
      "2022-11-08 16:12:36,804 INFO     Training average positive_sample_loss at step 371800: 0.300446\n",
      "2022-11-08 16:12:36,804 INFO     Training average negative_sample_loss at step 371800: 0.196055\n",
      "2022-11-08 16:12:36,804 INFO     Training average loss at step 371800: 0.248250\n",
      "2022-11-08 16:12:46,534 INFO     Training average positive_sample_loss at step 371900: 0.297953\n",
      "2022-11-08 16:12:46,534 INFO     Training average negative_sample_loss at step 371900: 0.198547\n",
      "2022-11-08 16:12:46,534 INFO     Training average loss at step 371900: 0.248250\n",
      "2022-11-08 16:12:56,333 INFO     Training average positive_sample_loss at step 372000: 0.286524\n",
      "2022-11-08 16:12:56,333 INFO     Training average negative_sample_loss at step 372000: 0.196155\n",
      "2022-11-08 16:12:56,333 INFO     Training average loss at step 372000: 0.241340\n",
      "2022-11-08 16:13:06,133 INFO     Training average positive_sample_loss at step 372100: 0.308822\n",
      "2022-11-08 16:13:06,134 INFO     Training average negative_sample_loss at step 372100: 0.193767\n",
      "2022-11-08 16:13:06,134 INFO     Training average loss at step 372100: 0.251295\n",
      "2022-11-08 16:13:15,894 INFO     Training average positive_sample_loss at step 372200: 0.300323\n",
      "2022-11-08 16:13:15,894 INFO     Training average negative_sample_loss at step 372200: 0.199251\n",
      "2022-11-08 16:13:15,894 INFO     Training average loss at step 372200: 0.249787\n",
      "2022-11-08 16:13:25,699 INFO     Training average positive_sample_loss at step 372300: 0.291762\n",
      "2022-11-08 16:13:25,699 INFO     Training average negative_sample_loss at step 372300: 0.198705\n",
      "2022-11-08 16:13:25,699 INFO     Training average loss at step 372300: 0.245233\n",
      "2022-11-08 16:13:35,477 INFO     Training average positive_sample_loss at step 372400: 0.302456\n",
      "2022-11-08 16:13:35,477 INFO     Training average negative_sample_loss at step 372400: 0.192816\n",
      "2022-11-08 16:13:35,477 INFO     Training average loss at step 372400: 0.247636\n",
      "2022-11-08 16:13:45,249 INFO     Training average positive_sample_loss at step 372500: 0.297360\n",
      "2022-11-08 16:13:45,249 INFO     Training average negative_sample_loss at step 372500: 0.194956\n",
      "2022-11-08 16:13:45,249 INFO     Training average loss at step 372500: 0.246158\n",
      "2022-11-08 16:13:55,039 INFO     Training average positive_sample_loss at step 372600: 0.309842\n",
      "2022-11-08 16:13:55,039 INFO     Training average negative_sample_loss at step 372600: 0.195638\n",
      "2022-11-08 16:13:55,039 INFO     Training average loss at step 372600: 0.252740\n",
      "2022-11-08 16:14:04,758 INFO     Training average positive_sample_loss at step 372700: 0.296837\n",
      "2022-11-08 16:14:04,758 INFO     Training average negative_sample_loss at step 372700: 0.197351\n",
      "2022-11-08 16:14:04,758 INFO     Training average loss at step 372700: 0.247094\n",
      "2022-11-08 16:14:14,517 INFO     Training average positive_sample_loss at step 372800: 0.292515\n",
      "2022-11-08 16:14:14,517 INFO     Training average negative_sample_loss at step 372800: 0.194368\n",
      "2022-11-08 16:14:14,517 INFO     Training average loss at step 372800: 0.243442\n",
      "2022-11-08 16:14:24,312 INFO     Training average positive_sample_loss at step 372900: 0.288306\n",
      "2022-11-08 16:14:24,312 INFO     Training average negative_sample_loss at step 372900: 0.191663\n",
      "2022-11-08 16:14:24,312 INFO     Training average loss at step 372900: 0.239985\n",
      "2022-11-08 16:14:34,134 INFO     Training average positive_sample_loss at step 373000: 0.297662\n",
      "2022-11-08 16:14:34,134 INFO     Training average negative_sample_loss at step 373000: 0.193159\n",
      "2022-11-08 16:14:34,134 INFO     Training average loss at step 373000: 0.245411\n",
      "2022-11-08 16:14:43,917 INFO     Training average positive_sample_loss at step 373100: 0.295915\n",
      "2022-11-08 16:14:43,917 INFO     Training average negative_sample_loss at step 373100: 0.198007\n",
      "2022-11-08 16:14:43,917 INFO     Training average loss at step 373100: 0.246961\n",
      "2022-11-08 16:14:53,644 INFO     Training average positive_sample_loss at step 373200: 0.295104\n",
      "2022-11-08 16:14:53,645 INFO     Training average negative_sample_loss at step 373200: 0.195269\n",
      "2022-11-08 16:14:53,645 INFO     Training average loss at step 373200: 0.245186\n",
      "2022-11-08 16:15:03,359 INFO     Training average positive_sample_loss at step 373300: 0.294114\n",
      "2022-11-08 16:15:03,359 INFO     Training average negative_sample_loss at step 373300: 0.194962\n",
      "2022-11-08 16:15:03,359 INFO     Training average loss at step 373300: 0.244538\n",
      "2022-11-08 16:15:13,084 INFO     Training average positive_sample_loss at step 373400: 0.293341\n",
      "2022-11-08 16:15:13,084 INFO     Training average negative_sample_loss at step 373400: 0.193647\n",
      "2022-11-08 16:15:13,084 INFO     Training average loss at step 373400: 0.243494\n",
      "2022-11-08 16:15:22,808 INFO     Training average positive_sample_loss at step 373500: 0.309756\n",
      "2022-11-08 16:15:22,808 INFO     Training average negative_sample_loss at step 373500: 0.199311\n",
      "2022-11-08 16:15:22,808 INFO     Training average loss at step 373500: 0.254534\n",
      "2022-11-08 16:15:31,900 INFO     Training average positive_sample_loss at step 373600: 0.300643\n",
      "2022-11-08 16:15:31,900 INFO     Training average negative_sample_loss at step 373600: 0.201336\n",
      "2022-11-08 16:15:31,900 INFO     Training average loss at step 373600: 0.250990\n",
      "2022-11-08 16:15:42,103 INFO     Training average positive_sample_loss at step 373700: 0.285650\n",
      "2022-11-08 16:15:42,103 INFO     Training average negative_sample_loss at step 373700: 0.190407\n",
      "2022-11-08 16:15:42,103 INFO     Training average loss at step 373700: 0.238028\n",
      "2022-11-08 16:15:52,406 INFO     Training average positive_sample_loss at step 373800: 0.302680\n",
      "2022-11-08 16:15:52,407 INFO     Training average negative_sample_loss at step 373800: 0.194038\n",
      "2022-11-08 16:15:52,407 INFO     Training average loss at step 373800: 0.248359\n",
      "2022-11-08 16:16:03,479 INFO     Training average positive_sample_loss at step 373900: 0.301494\n",
      "2022-11-08 16:16:03,479 INFO     Training average negative_sample_loss at step 373900: 0.196211\n",
      "2022-11-08 16:16:03,479 INFO     Training average loss at step 373900: 0.248853\n",
      "2022-11-08 16:16:13,262 INFO     Training average positive_sample_loss at step 374000: 0.277866\n",
      "2022-11-08 16:16:13,262 INFO     Training average negative_sample_loss at step 374000: 0.197803\n",
      "2022-11-08 16:16:13,262 INFO     Training average loss at step 374000: 0.237835\n",
      "2022-11-08 16:16:22,316 INFO     Training average positive_sample_loss at step 374100: 0.301840\n",
      "2022-11-08 16:16:22,316 INFO     Training average negative_sample_loss at step 374100: 0.191599\n",
      "2022-11-08 16:16:22,316 INFO     Training average loss at step 374100: 0.246720\n",
      "2022-11-08 16:16:32,056 INFO     Training average positive_sample_loss at step 374200: 0.270691\n",
      "2022-11-08 16:16:32,056 INFO     Training average negative_sample_loss at step 374200: 0.194221\n",
      "2022-11-08 16:16:32,056 INFO     Training average loss at step 374200: 0.232456\n",
      "2022-11-08 16:16:41,767 INFO     Training average positive_sample_loss at step 374300: 0.303390\n",
      "2022-11-08 16:16:41,767 INFO     Training average negative_sample_loss at step 374300: 0.199423\n",
      "2022-11-08 16:16:41,767 INFO     Training average loss at step 374300: 0.251407\n",
      "2022-11-08 16:16:51,504 INFO     Training average positive_sample_loss at step 374400: 0.279329\n",
      "2022-11-08 16:16:51,504 INFO     Training average negative_sample_loss at step 374400: 0.196039\n",
      "2022-11-08 16:16:51,504 INFO     Training average loss at step 374400: 0.237684\n",
      "2022-11-08 16:17:01,232 INFO     Training average positive_sample_loss at step 374500: 0.293157\n",
      "2022-11-08 16:17:01,232 INFO     Training average negative_sample_loss at step 374500: 0.197965\n",
      "2022-11-08 16:17:01,232 INFO     Training average loss at step 374500: 0.245561\n",
      "2022-11-08 16:17:11,011 INFO     Training average positive_sample_loss at step 374600: 0.302390\n",
      "2022-11-08 16:17:11,012 INFO     Training average negative_sample_loss at step 374600: 0.197263\n",
      "2022-11-08 16:17:11,012 INFO     Training average loss at step 374600: 0.249826\n",
      "2022-11-08 16:17:20,771 INFO     Training average positive_sample_loss at step 374700: 0.297538\n",
      "2022-11-08 16:17:20,772 INFO     Training average negative_sample_loss at step 374700: 0.196239\n",
      "2022-11-08 16:17:20,772 INFO     Training average loss at step 374700: 0.246889\n",
      "2022-11-08 16:17:30,514 INFO     Training average positive_sample_loss at step 374800: 0.287471\n",
      "2022-11-08 16:17:30,514 INFO     Training average negative_sample_loss at step 374800: 0.200567\n",
      "2022-11-08 16:17:30,514 INFO     Training average loss at step 374800: 0.244019\n",
      "2022-11-08 16:17:40,280 INFO     Training average positive_sample_loss at step 374900: 0.302130\n",
      "2022-11-08 16:17:40,280 INFO     Training average negative_sample_loss at step 374900: 0.192485\n",
      "2022-11-08 16:17:40,280 INFO     Training average loss at step 374900: 0.247308\n",
      "2022-11-08 16:17:50,035 INFO     Training average positive_sample_loss at step 375000: 0.292328\n",
      "2022-11-08 16:17:50,035 INFO     Training average negative_sample_loss at step 375000: 0.194571\n",
      "2022-11-08 16:17:50,035 INFO     Training average loss at step 375000: 0.243449\n",
      "2022-11-08 16:18:00,116 INFO     Training average positive_sample_loss at step 375100: 0.276664\n",
      "2022-11-08 16:18:00,116 INFO     Training average negative_sample_loss at step 375100: 0.197161\n",
      "2022-11-08 16:18:00,116 INFO     Training average loss at step 375100: 0.236912\n",
      "2022-11-08 16:18:10,069 INFO     Training average positive_sample_loss at step 375200: 0.290714\n",
      "2022-11-08 16:18:10,069 INFO     Training average negative_sample_loss at step 375200: 0.199793\n",
      "2022-11-08 16:18:10,069 INFO     Training average loss at step 375200: 0.245253\n",
      "2022-11-08 16:18:19,949 INFO     Training average positive_sample_loss at step 375300: 0.289163\n",
      "2022-11-08 16:18:19,949 INFO     Training average negative_sample_loss at step 375300: 0.192851\n",
      "2022-11-08 16:18:19,949 INFO     Training average loss at step 375300: 0.241007\n",
      "2022-11-08 16:18:29,834 INFO     Training average positive_sample_loss at step 375400: 0.272612\n",
      "2022-11-08 16:18:29,834 INFO     Training average negative_sample_loss at step 375400: 0.198499\n",
      "2022-11-08 16:18:29,834 INFO     Training average loss at step 375400: 0.235555\n",
      "2022-11-08 16:18:39,727 INFO     Training average positive_sample_loss at step 375500: 0.290282\n",
      "2022-11-08 16:18:39,728 INFO     Training average negative_sample_loss at step 375500: 0.192372\n",
      "2022-11-08 16:18:39,728 INFO     Training average loss at step 375500: 0.241327\n",
      "2022-11-08 16:18:49,614 INFO     Training average positive_sample_loss at step 375600: 0.296056\n",
      "2022-11-08 16:18:49,614 INFO     Training average negative_sample_loss at step 375600: 0.194741\n",
      "2022-11-08 16:18:49,614 INFO     Training average loss at step 375600: 0.245398\n",
      "2022-11-08 16:18:59,497 INFO     Training average positive_sample_loss at step 375700: 0.300428\n",
      "2022-11-08 16:18:59,498 INFO     Training average negative_sample_loss at step 375700: 0.188618\n",
      "2022-11-08 16:18:59,498 INFO     Training average loss at step 375700: 0.244523\n",
      "2022-11-08 16:19:09,339 INFO     Training average positive_sample_loss at step 375800: 0.301878\n",
      "2022-11-08 16:19:09,339 INFO     Training average negative_sample_loss at step 375800: 0.194590\n",
      "2022-11-08 16:19:09,339 INFO     Training average loss at step 375800: 0.248234\n",
      "2022-11-08 16:19:19,090 INFO     Training average positive_sample_loss at step 375900: 0.287173\n",
      "2022-11-08 16:19:19,091 INFO     Training average negative_sample_loss at step 375900: 0.195698\n",
      "2022-11-08 16:19:19,091 INFO     Training average loss at step 375900: 0.241436\n",
      "2022-11-08 16:19:28,882 INFO     Training average positive_sample_loss at step 376000: 0.302403\n",
      "2022-11-08 16:19:28,883 INFO     Training average negative_sample_loss at step 376000: 0.194918\n",
      "2022-11-08 16:19:28,883 INFO     Training average loss at step 376000: 0.248661\n",
      "2022-11-08 16:19:38,729 INFO     Training average positive_sample_loss at step 376100: 0.289109\n",
      "2022-11-08 16:19:38,729 INFO     Training average negative_sample_loss at step 376100: 0.193066\n",
      "2022-11-08 16:19:38,729 INFO     Training average loss at step 376100: 0.241087\n",
      "2022-11-08 16:19:48,598 INFO     Training average positive_sample_loss at step 376200: 0.295944\n",
      "2022-11-08 16:19:48,598 INFO     Training average negative_sample_loss at step 376200: 0.192669\n",
      "2022-11-08 16:19:48,598 INFO     Training average loss at step 376200: 0.244306\n",
      "2022-11-08 16:19:58,390 INFO     Training average positive_sample_loss at step 376300: 0.293364\n",
      "2022-11-08 16:19:58,390 INFO     Training average negative_sample_loss at step 376300: 0.196575\n",
      "2022-11-08 16:19:58,390 INFO     Training average loss at step 376300: 0.244969\n",
      "2022-11-08 16:20:08,077 INFO     Training average positive_sample_loss at step 376400: 0.288011\n",
      "2022-11-08 16:20:08,077 INFO     Training average negative_sample_loss at step 376400: 0.191405\n",
      "2022-11-08 16:20:08,077 INFO     Training average loss at step 376400: 0.239708\n",
      "2022-11-08 16:20:17,763 INFO     Training average positive_sample_loss at step 376500: 0.271497\n",
      "2022-11-08 16:20:17,763 INFO     Training average negative_sample_loss at step 376500: 0.194254\n",
      "2022-11-08 16:20:17,763 INFO     Training average loss at step 376500: 0.232876\n",
      "2022-11-08 16:20:27,431 INFO     Training average positive_sample_loss at step 376600: 0.298715\n",
      "2022-11-08 16:20:27,431 INFO     Training average negative_sample_loss at step 376600: 0.195080\n",
      "2022-11-08 16:20:27,431 INFO     Training average loss at step 376600: 0.246898\n",
      "2022-11-08 16:20:37,105 INFO     Training average positive_sample_loss at step 376700: 0.300086\n",
      "2022-11-08 16:20:37,106 INFO     Training average negative_sample_loss at step 376700: 0.197673\n",
      "2022-11-08 16:20:37,106 INFO     Training average loss at step 376700: 0.248879\n",
      "2022-11-08 16:20:46,931 INFO     Training average positive_sample_loss at step 376800: 0.280986\n",
      "2022-11-08 16:20:46,931 INFO     Training average negative_sample_loss at step 376800: 0.194021\n",
      "2022-11-08 16:20:46,931 INFO     Training average loss at step 376800: 0.237503\n",
      "2022-11-08 16:20:56,641 INFO     Training average positive_sample_loss at step 376900: 0.304992\n",
      "2022-11-08 16:20:56,641 INFO     Training average negative_sample_loss at step 376900: 0.190422\n",
      "2022-11-08 16:20:56,641 INFO     Training average loss at step 376900: 0.247707\n",
      "2022-11-08 16:21:06,309 INFO     Training average positive_sample_loss at step 377000: 0.296701\n",
      "2022-11-08 16:21:06,309 INFO     Training average negative_sample_loss at step 377000: 0.195696\n",
      "2022-11-08 16:21:06,309 INFO     Training average loss at step 377000: 0.246198\n",
      "2022-11-08 16:21:15,976 INFO     Training average positive_sample_loss at step 377100: 0.297977\n",
      "2022-11-08 16:21:15,976 INFO     Training average negative_sample_loss at step 377100: 0.195213\n",
      "2022-11-08 16:21:15,976 INFO     Training average loss at step 377100: 0.246595\n",
      "2022-11-08 16:21:25,644 INFO     Training average positive_sample_loss at step 377200: 0.283994\n",
      "2022-11-08 16:21:25,644 INFO     Training average negative_sample_loss at step 377200: 0.203109\n",
      "2022-11-08 16:21:25,644 INFO     Training average loss at step 377200: 0.243551\n",
      "2022-11-08 16:21:35,313 INFO     Training average positive_sample_loss at step 377300: 0.314684\n",
      "2022-11-08 16:21:35,313 INFO     Training average negative_sample_loss at step 377300: 0.196038\n",
      "2022-11-08 16:21:35,314 INFO     Training average loss at step 377300: 0.255361\n",
      "2022-11-08 16:21:44,978 INFO     Training average positive_sample_loss at step 377400: 0.291819\n",
      "2022-11-08 16:21:44,978 INFO     Training average negative_sample_loss at step 377400: 0.192513\n",
      "2022-11-08 16:21:44,978 INFO     Training average loss at step 377400: 0.242166\n",
      "2022-11-08 16:21:54,642 INFO     Training average positive_sample_loss at step 377500: 0.300306\n",
      "2022-11-08 16:21:54,642 INFO     Training average negative_sample_loss at step 377500: 0.195046\n",
      "2022-11-08 16:21:54,642 INFO     Training average loss at step 377500: 0.247676\n",
      "2022-11-08 16:22:04,311 INFO     Training average positive_sample_loss at step 377600: 0.292058\n",
      "2022-11-08 16:22:04,311 INFO     Training average negative_sample_loss at step 377600: 0.195263\n",
      "2022-11-08 16:22:04,311 INFO     Training average loss at step 377600: 0.243661\n",
      "2022-11-08 16:22:13,979 INFO     Training average positive_sample_loss at step 377700: 0.297347\n",
      "2022-11-08 16:22:13,979 INFO     Training average negative_sample_loss at step 377700: 0.196774\n",
      "2022-11-08 16:22:13,979 INFO     Training average loss at step 377700: 0.247060\n",
      "2022-11-08 16:22:23,708 INFO     Training average positive_sample_loss at step 377800: 0.287046\n",
      "2022-11-08 16:22:23,708 INFO     Training average negative_sample_loss at step 377800: 0.191940\n",
      "2022-11-08 16:22:23,708 INFO     Training average loss at step 377800: 0.239493\n",
      "2022-11-08 16:22:33,462 INFO     Training average positive_sample_loss at step 377900: 0.292268\n",
      "2022-11-08 16:22:33,462 INFO     Training average negative_sample_loss at step 377900: 0.193653\n",
      "2022-11-08 16:22:33,462 INFO     Training average loss at step 377900: 0.242960\n",
      "2022-11-08 16:22:43,242 INFO     Training average positive_sample_loss at step 378000: 0.285325\n",
      "2022-11-08 16:22:43,242 INFO     Training average negative_sample_loss at step 378000: 0.197757\n",
      "2022-11-08 16:22:43,242 INFO     Training average loss at step 378000: 0.241541\n",
      "2022-11-08 16:22:52,979 INFO     Training average positive_sample_loss at step 378100: 0.294079\n",
      "2022-11-08 16:22:52,980 INFO     Training average negative_sample_loss at step 378100: 0.192172\n",
      "2022-11-08 16:22:52,980 INFO     Training average loss at step 378100: 0.243125\n",
      "2022-11-08 16:23:03,215 INFO     Training average positive_sample_loss at step 378200: 0.293234\n",
      "2022-11-08 16:23:03,216 INFO     Training average negative_sample_loss at step 378200: 0.189855\n",
      "2022-11-08 16:23:03,216 INFO     Training average loss at step 378200: 0.241545\n",
      "2022-11-08 16:23:12,965 INFO     Training average positive_sample_loss at step 378300: 0.295514\n",
      "2022-11-08 16:23:12,965 INFO     Training average negative_sample_loss at step 378300: 0.192463\n",
      "2022-11-08 16:23:12,965 INFO     Training average loss at step 378300: 0.243988\n",
      "2022-11-08 16:23:22,891 INFO     Training average positive_sample_loss at step 378400: 0.278921\n",
      "2022-11-08 16:23:22,891 INFO     Training average negative_sample_loss at step 378400: 0.202043\n",
      "2022-11-08 16:23:22,891 INFO     Training average loss at step 378400: 0.240482\n",
      "2022-11-08 16:23:33,169 INFO     Training average positive_sample_loss at step 378500: 0.286155\n",
      "2022-11-08 16:23:33,169 INFO     Training average negative_sample_loss at step 378500: 0.195655\n",
      "2022-11-08 16:23:33,169 INFO     Training average loss at step 378500: 0.240905\n",
      "2022-11-08 16:23:43,942 INFO     Training average positive_sample_loss at step 378600: 0.283829\n",
      "2022-11-08 16:23:43,942 INFO     Training average negative_sample_loss at step 378600: 0.195241\n",
      "2022-11-08 16:23:43,942 INFO     Training average loss at step 378600: 0.239535\n",
      "2022-11-08 16:23:53,614 INFO     Training average positive_sample_loss at step 378700: 0.284678\n",
      "2022-11-08 16:23:53,614 INFO     Training average negative_sample_loss at step 378700: 0.198703\n",
      "2022-11-08 16:23:53,614 INFO     Training average loss at step 378700: 0.241691\n",
      "2022-11-08 16:24:03,308 INFO     Training average positive_sample_loss at step 378800: 0.296366\n",
      "2022-11-08 16:24:03,308 INFO     Training average negative_sample_loss at step 378800: 0.194881\n",
      "2022-11-08 16:24:03,308 INFO     Training average loss at step 378800: 0.245624\n",
      "2022-11-08 16:24:13,072 INFO     Training average positive_sample_loss at step 378900: 0.286220\n",
      "2022-11-08 16:24:13,072 INFO     Training average negative_sample_loss at step 378900: 0.192965\n",
      "2022-11-08 16:24:13,072 INFO     Training average loss at step 378900: 0.239593\n",
      "2022-11-08 16:24:22,802 INFO     Training average positive_sample_loss at step 379000: 0.291525\n",
      "2022-11-08 16:24:22,802 INFO     Training average negative_sample_loss at step 379000: 0.202348\n",
      "2022-11-08 16:24:22,802 INFO     Training average loss at step 379000: 0.246937\n",
      "2022-11-08 16:24:32,136 INFO     Training average positive_sample_loss at step 379100: 0.296574\n",
      "2022-11-08 16:24:32,137 INFO     Training average negative_sample_loss at step 379100: 0.194361\n",
      "2022-11-08 16:24:32,137 INFO     Training average loss at step 379100: 0.245468\n",
      "2022-11-08 16:24:41,876 INFO     Training average positive_sample_loss at step 379200: 0.276925\n",
      "2022-11-08 16:24:41,876 INFO     Training average negative_sample_loss at step 379200: 0.196004\n",
      "2022-11-08 16:24:41,876 INFO     Training average loss at step 379200: 0.236465\n",
      "2022-11-08 16:24:51,606 INFO     Training average positive_sample_loss at step 379300: 0.287968\n",
      "2022-11-08 16:24:51,606 INFO     Training average negative_sample_loss at step 379300: 0.193488\n",
      "2022-11-08 16:24:51,606 INFO     Training average loss at step 379300: 0.240728\n",
      "2022-11-08 16:25:01,361 INFO     Training average positive_sample_loss at step 379400: 0.295139\n",
      "2022-11-08 16:25:01,361 INFO     Training average negative_sample_loss at step 379400: 0.192853\n",
      "2022-11-08 16:25:01,361 INFO     Training average loss at step 379400: 0.243996\n",
      "2022-11-08 16:25:11,199 INFO     Training average positive_sample_loss at step 379500: 0.296764\n",
      "2022-11-08 16:25:11,199 INFO     Training average negative_sample_loss at step 379500: 0.192308\n",
      "2022-11-08 16:25:11,199 INFO     Training average loss at step 379500: 0.244536\n",
      "2022-11-08 16:25:20,321 INFO     Training average positive_sample_loss at step 379600: 0.291271\n",
      "2022-11-08 16:25:20,321 INFO     Training average negative_sample_loss at step 379600: 0.193915\n",
      "2022-11-08 16:25:20,321 INFO     Training average loss at step 379600: 0.242593\n",
      "2022-11-08 16:25:30,069 INFO     Training average positive_sample_loss at step 379700: 0.291107\n",
      "2022-11-08 16:25:30,069 INFO     Training average negative_sample_loss at step 379700: 0.194793\n",
      "2022-11-08 16:25:30,069 INFO     Training average loss at step 379700: 0.242950\n",
      "2022-11-08 16:25:39,817 INFO     Training average positive_sample_loss at step 379800: 0.282778\n",
      "2022-11-08 16:25:39,818 INFO     Training average negative_sample_loss at step 379800: 0.194200\n",
      "2022-11-08 16:25:39,818 INFO     Training average loss at step 379800: 0.238489\n",
      "2022-11-08 16:25:49,636 INFO     Training average positive_sample_loss at step 379900: 0.288665\n",
      "2022-11-08 16:25:49,636 INFO     Training average negative_sample_loss at step 379900: 0.196697\n",
      "2022-11-08 16:25:49,636 INFO     Training average loss at step 379900: 0.242681\n",
      "2022-11-08 16:26:02,133 INFO     Training average positive_sample_loss at step 380000: 0.284947\n",
      "2022-11-08 16:26:02,134 INFO     Training average negative_sample_loss at step 380000: 0.191677\n",
      "2022-11-08 16:26:02,134 INFO     Training average loss at step 380000: 0.238312\n",
      "2022-11-08 16:26:11,966 INFO     Training average positive_sample_loss at step 380100: 0.287602\n",
      "2022-11-08 16:26:11,966 INFO     Training average negative_sample_loss at step 380100: 0.191194\n",
      "2022-11-08 16:26:11,967 INFO     Training average loss at step 380100: 0.239398\n",
      "2022-11-08 16:26:21,766 INFO     Training average positive_sample_loss at step 380200: 0.288429\n",
      "2022-11-08 16:26:21,766 INFO     Training average negative_sample_loss at step 380200: 0.196019\n",
      "2022-11-08 16:26:21,766 INFO     Training average loss at step 380200: 0.242224\n",
      "2022-11-08 16:26:31,564 INFO     Training average positive_sample_loss at step 380300: 0.296210\n",
      "2022-11-08 16:26:31,564 INFO     Training average negative_sample_loss at step 380300: 0.195827\n",
      "2022-11-08 16:26:31,564 INFO     Training average loss at step 380300: 0.246019\n",
      "2022-11-08 16:26:41,335 INFO     Training average positive_sample_loss at step 380400: 0.289842\n",
      "2022-11-08 16:26:41,335 INFO     Training average negative_sample_loss at step 380400: 0.191768\n",
      "2022-11-08 16:26:41,335 INFO     Training average loss at step 380400: 0.240805\n",
      "2022-11-08 16:26:51,137 INFO     Training average positive_sample_loss at step 380500: 0.296190\n",
      "2022-11-08 16:26:51,137 INFO     Training average negative_sample_loss at step 380500: 0.193800\n",
      "2022-11-08 16:26:51,137 INFO     Training average loss at step 380500: 0.244995\n",
      "2022-11-08 16:27:00,961 INFO     Training average positive_sample_loss at step 380600: 0.280735\n",
      "2022-11-08 16:27:00,961 INFO     Training average negative_sample_loss at step 380600: 0.191649\n",
      "2022-11-08 16:27:00,961 INFO     Training average loss at step 380600: 0.236192\n",
      "2022-11-08 16:27:10,708 INFO     Training average positive_sample_loss at step 380700: 0.294668\n",
      "2022-11-08 16:27:10,708 INFO     Training average negative_sample_loss at step 380700: 0.196043\n",
      "2022-11-08 16:27:10,708 INFO     Training average loss at step 380700: 0.245355\n",
      "2022-11-08 16:27:20,449 INFO     Training average positive_sample_loss at step 380800: 0.293256\n",
      "2022-11-08 16:27:20,449 INFO     Training average negative_sample_loss at step 380800: 0.186928\n",
      "2022-11-08 16:27:20,449 INFO     Training average loss at step 380800: 0.240092\n",
      "2022-11-08 16:27:30,188 INFO     Training average positive_sample_loss at step 380900: 0.295371\n",
      "2022-11-08 16:27:30,188 INFO     Training average negative_sample_loss at step 380900: 0.192800\n",
      "2022-11-08 16:27:30,188 INFO     Training average loss at step 380900: 0.244085\n",
      "2022-11-08 16:27:39,977 INFO     Training average positive_sample_loss at step 381000: 0.298910\n",
      "2022-11-08 16:27:39,977 INFO     Training average negative_sample_loss at step 381000: 0.190801\n",
      "2022-11-08 16:27:39,977 INFO     Training average loss at step 381000: 0.244856\n",
      "2022-11-08 16:27:49,728 INFO     Training average positive_sample_loss at step 381100: 0.287081\n",
      "2022-11-08 16:27:49,728 INFO     Training average negative_sample_loss at step 381100: 0.194376\n",
      "2022-11-08 16:27:49,728 INFO     Training average loss at step 381100: 0.240728\n",
      "2022-11-08 16:27:59,562 INFO     Training average positive_sample_loss at step 381200: 0.276922\n",
      "2022-11-08 16:27:59,562 INFO     Training average negative_sample_loss at step 381200: 0.196993\n",
      "2022-11-08 16:27:59,562 INFO     Training average loss at step 381200: 0.236957\n",
      "2022-11-08 16:28:09,321 INFO     Training average positive_sample_loss at step 381300: 0.280705\n",
      "2022-11-08 16:28:09,321 INFO     Training average negative_sample_loss at step 381300: 0.190509\n",
      "2022-11-08 16:28:09,321 INFO     Training average loss at step 381300: 0.235607\n",
      "2022-11-08 16:28:19,066 INFO     Training average positive_sample_loss at step 381400: 0.283221\n",
      "2022-11-08 16:28:19,066 INFO     Training average negative_sample_loss at step 381400: 0.195710\n",
      "2022-11-08 16:28:19,066 INFO     Training average loss at step 381400: 0.239466\n",
      "2022-11-08 16:28:28,830 INFO     Training average positive_sample_loss at step 381500: 0.297916\n",
      "2022-11-08 16:28:28,830 INFO     Training average negative_sample_loss at step 381500: 0.190495\n",
      "2022-11-08 16:28:28,830 INFO     Training average loss at step 381500: 0.244205\n",
      "2022-11-08 16:28:38,524 INFO     Training average positive_sample_loss at step 381600: 0.275535\n",
      "2022-11-08 16:28:38,525 INFO     Training average negative_sample_loss at step 381600: 0.196279\n",
      "2022-11-08 16:28:38,525 INFO     Training average loss at step 381600: 0.235907\n",
      "2022-11-08 16:28:48,195 INFO     Training average positive_sample_loss at step 381700: 0.297025\n",
      "2022-11-08 16:28:48,196 INFO     Training average negative_sample_loss at step 381700: 0.191871\n",
      "2022-11-08 16:28:48,196 INFO     Training average loss at step 381700: 0.244448\n",
      "2022-11-08 16:28:57,962 INFO     Training average positive_sample_loss at step 381800: 0.284188\n",
      "2022-11-08 16:28:57,962 INFO     Training average negative_sample_loss at step 381800: 0.189019\n",
      "2022-11-08 16:28:57,962 INFO     Training average loss at step 381800: 0.236603\n",
      "2022-11-08 16:29:07,739 INFO     Training average positive_sample_loss at step 381900: 0.295367\n",
      "2022-11-08 16:29:07,739 INFO     Training average negative_sample_loss at step 381900: 0.191896\n",
      "2022-11-08 16:29:07,739 INFO     Training average loss at step 381900: 0.243631\n",
      "2022-11-08 16:29:17,485 INFO     Training average positive_sample_loss at step 382000: 0.275842\n",
      "2022-11-08 16:29:17,486 INFO     Training average negative_sample_loss at step 382000: 0.192691\n",
      "2022-11-08 16:29:17,486 INFO     Training average loss at step 382000: 0.234266\n",
      "2022-11-08 16:29:27,203 INFO     Training average positive_sample_loss at step 382100: 0.291109\n",
      "2022-11-08 16:29:27,203 INFO     Training average negative_sample_loss at step 382100: 0.195269\n",
      "2022-11-08 16:29:27,203 INFO     Training average loss at step 382100: 0.243189\n",
      "2022-11-08 16:29:36,962 INFO     Training average positive_sample_loss at step 382200: 0.302233\n",
      "2022-11-08 16:29:36,962 INFO     Training average negative_sample_loss at step 382200: 0.186474\n",
      "2022-11-08 16:29:36,962 INFO     Training average loss at step 382200: 0.244354\n",
      "2022-11-08 16:29:46,800 INFO     Training average positive_sample_loss at step 382300: 0.299413\n",
      "2022-11-08 16:29:46,800 INFO     Training average negative_sample_loss at step 382300: 0.190327\n",
      "2022-11-08 16:29:46,800 INFO     Training average loss at step 382300: 0.244870\n",
      "2022-11-08 16:29:56,583 INFO     Training average positive_sample_loss at step 382400: 0.291261\n",
      "2022-11-08 16:29:56,583 INFO     Training average negative_sample_loss at step 382400: 0.194447\n",
      "2022-11-08 16:29:56,583 INFO     Training average loss at step 382400: 0.242854\n",
      "2022-11-08 16:30:06,364 INFO     Training average positive_sample_loss at step 382500: 0.289411\n",
      "2022-11-08 16:30:06,364 INFO     Training average negative_sample_loss at step 382500: 0.189804\n",
      "2022-11-08 16:30:06,364 INFO     Training average loss at step 382500: 0.239608\n",
      "2022-11-08 16:30:16,170 INFO     Training average positive_sample_loss at step 382600: 0.298562\n",
      "2022-11-08 16:30:16,170 INFO     Training average negative_sample_loss at step 382600: 0.194882\n",
      "2022-11-08 16:30:16,170 INFO     Training average loss at step 382600: 0.246722\n",
      "2022-11-08 16:30:26,179 INFO     Training average positive_sample_loss at step 382700: 0.301816\n",
      "2022-11-08 16:30:26,179 INFO     Training average negative_sample_loss at step 382700: 0.195191\n",
      "2022-11-08 16:30:26,179 INFO     Training average loss at step 382700: 0.248504\n",
      "2022-11-08 16:30:35,921 INFO     Training average positive_sample_loss at step 382800: 0.298404\n",
      "2022-11-08 16:30:35,921 INFO     Training average negative_sample_loss at step 382800: 0.196468\n",
      "2022-11-08 16:30:35,921 INFO     Training average loss at step 382800: 0.247436\n",
      "2022-11-08 16:30:46,184 INFO     Training average positive_sample_loss at step 382900: 0.297043\n",
      "2022-11-08 16:30:46,185 INFO     Training average negative_sample_loss at step 382900: 0.194337\n",
      "2022-11-08 16:30:46,185 INFO     Training average loss at step 382900: 0.245690\n",
      "2022-11-08 16:30:56,341 INFO     Training average positive_sample_loss at step 383000: 0.288296\n",
      "2022-11-08 16:30:56,341 INFO     Training average negative_sample_loss at step 383000: 0.199130\n",
      "2022-11-08 16:30:56,341 INFO     Training average loss at step 383000: 0.243713\n",
      "2022-11-08 16:31:06,117 INFO     Training average positive_sample_loss at step 383100: 0.280046\n",
      "2022-11-08 16:31:06,117 INFO     Training average negative_sample_loss at step 383100: 0.195012\n",
      "2022-11-08 16:31:06,117 INFO     Training average loss at step 383100: 0.237529\n",
      "2022-11-08 16:31:16,352 INFO     Training average positive_sample_loss at step 383200: 0.293678\n",
      "2022-11-08 16:31:16,353 INFO     Training average negative_sample_loss at step 383200: 0.192717\n",
      "2022-11-08 16:31:16,353 INFO     Training average loss at step 383200: 0.243197\n",
      "2022-11-08 16:31:27,262 INFO     Training average positive_sample_loss at step 383300: 0.291130\n",
      "2022-11-08 16:31:27,262 INFO     Training average negative_sample_loss at step 383300: 0.191394\n",
      "2022-11-08 16:31:27,262 INFO     Training average loss at step 383300: 0.241262\n",
      "2022-11-08 16:31:37,024 INFO     Training average positive_sample_loss at step 383400: 0.291363\n",
      "2022-11-08 16:31:37,024 INFO     Training average negative_sample_loss at step 383400: 0.194346\n",
      "2022-11-08 16:31:37,025 INFO     Training average loss at step 383400: 0.242854\n",
      "2022-11-08 16:31:46,756 INFO     Training average positive_sample_loss at step 383500: 0.287329\n",
      "2022-11-08 16:31:46,756 INFO     Training average negative_sample_loss at step 383500: 0.188303\n",
      "2022-11-08 16:31:46,756 INFO     Training average loss at step 383500: 0.237816\n",
      "2022-11-08 16:31:56,529 INFO     Training average positive_sample_loss at step 383600: 0.286974\n",
      "2022-11-08 16:31:56,529 INFO     Training average negative_sample_loss at step 383600: 0.192531\n",
      "2022-11-08 16:31:56,529 INFO     Training average loss at step 383600: 0.239752\n",
      "2022-11-08 16:32:06,340 INFO     Training average positive_sample_loss at step 383700: 0.287379\n",
      "2022-11-08 16:32:06,340 INFO     Training average negative_sample_loss at step 383700: 0.191003\n",
      "2022-11-08 16:32:06,340 INFO     Training average loss at step 383700: 0.239191\n",
      "2022-11-08 16:32:16,125 INFO     Training average positive_sample_loss at step 383800: 0.284010\n",
      "2022-11-08 16:32:16,125 INFO     Training average negative_sample_loss at step 383800: 0.193369\n",
      "2022-11-08 16:32:16,125 INFO     Training average loss at step 383800: 0.238690\n",
      "2022-11-08 16:32:25,928 INFO     Training average positive_sample_loss at step 383900: 0.294452\n",
      "2022-11-08 16:32:25,928 INFO     Training average negative_sample_loss at step 383900: 0.197247\n",
      "2022-11-08 16:32:25,928 INFO     Training average loss at step 383900: 0.245849\n",
      "2022-11-08 16:32:35,704 INFO     Training average positive_sample_loss at step 384000: 0.286388\n",
      "2022-11-08 16:32:35,704 INFO     Training average negative_sample_loss at step 384000: 0.192185\n",
      "2022-11-08 16:32:35,704 INFO     Training average loss at step 384000: 0.239286\n",
      "2022-11-08 16:32:45,480 INFO     Training average positive_sample_loss at step 384100: 0.287277\n",
      "2022-11-08 16:32:45,480 INFO     Training average negative_sample_loss at step 384100: 0.192851\n",
      "2022-11-08 16:32:45,480 INFO     Training average loss at step 384100: 0.240064\n",
      "2022-11-08 16:32:55,283 INFO     Training average positive_sample_loss at step 384200: 0.287032\n",
      "2022-11-08 16:32:55,283 INFO     Training average negative_sample_loss at step 384200: 0.194134\n",
      "2022-11-08 16:32:55,283 INFO     Training average loss at step 384200: 0.240583\n",
      "2022-11-08 16:33:05,095 INFO     Training average positive_sample_loss at step 384300: 0.288834\n",
      "2022-11-08 16:33:05,095 INFO     Training average negative_sample_loss at step 384300: 0.195404\n",
      "2022-11-08 16:33:05,096 INFO     Training average loss at step 384300: 0.242119\n",
      "2022-11-08 16:33:15,033 INFO     Training average positive_sample_loss at step 384400: 0.299578\n",
      "2022-11-08 16:33:15,034 INFO     Training average negative_sample_loss at step 384400: 0.194220\n",
      "2022-11-08 16:33:15,034 INFO     Training average loss at step 384400: 0.246899\n",
      "2022-11-08 16:33:24,312 INFO     Training average positive_sample_loss at step 384500: 0.281030\n",
      "2022-11-08 16:33:24,312 INFO     Training average negative_sample_loss at step 384500: 0.195220\n",
      "2022-11-08 16:33:24,312 INFO     Training average loss at step 384500: 0.238125\n",
      "2022-11-08 16:33:34,172 INFO     Training average positive_sample_loss at step 384600: 0.281594\n",
      "2022-11-08 16:33:34,173 INFO     Training average negative_sample_loss at step 384600: 0.188078\n",
      "2022-11-08 16:33:34,173 INFO     Training average loss at step 384600: 0.234836\n",
      "2022-11-08 16:33:43,907 INFO     Training average positive_sample_loss at step 384700: 0.281498\n",
      "2022-11-08 16:33:43,907 INFO     Training average negative_sample_loss at step 384700: 0.192389\n",
      "2022-11-08 16:33:43,907 INFO     Training average loss at step 384700: 0.236944\n",
      "2022-11-08 16:33:53,699 INFO     Training average positive_sample_loss at step 384800: 0.289373\n",
      "2022-11-08 16:33:53,699 INFO     Training average negative_sample_loss at step 384800: 0.193791\n",
      "2022-11-08 16:33:53,699 INFO     Training average loss at step 384800: 0.241582\n",
      "2022-11-08 16:34:03,462 INFO     Training average positive_sample_loss at step 384900: 0.290281\n",
      "2022-11-08 16:34:03,462 INFO     Training average negative_sample_loss at step 384900: 0.196865\n",
      "2022-11-08 16:34:03,462 INFO     Training average loss at step 384900: 0.243573\n",
      "2022-11-08 16:34:13,209 INFO     Training average positive_sample_loss at step 385000: 0.278445\n",
      "2022-11-08 16:34:13,210 INFO     Training average negative_sample_loss at step 385000: 0.196399\n",
      "2022-11-08 16:34:13,210 INFO     Training average loss at step 385000: 0.237422\n",
      "2022-11-08 16:34:22,278 INFO     Training average positive_sample_loss at step 385100: 0.290238\n",
      "2022-11-08 16:34:22,278 INFO     Training average negative_sample_loss at step 385100: 0.194262\n",
      "2022-11-08 16:34:22,278 INFO     Training average loss at step 385100: 0.242250\n",
      "2022-11-08 16:34:32,040 INFO     Training average positive_sample_loss at step 385200: 0.298217\n",
      "2022-11-08 16:34:32,040 INFO     Training average negative_sample_loss at step 385200: 0.194907\n",
      "2022-11-08 16:34:32,040 INFO     Training average loss at step 385200: 0.246562\n",
      "2022-11-08 16:34:41,818 INFO     Training average positive_sample_loss at step 385300: 0.285249\n",
      "2022-11-08 16:34:41,818 INFO     Training average negative_sample_loss at step 385300: 0.191104\n",
      "2022-11-08 16:34:41,818 INFO     Training average loss at step 385300: 0.238176\n",
      "2022-11-08 16:34:51,579 INFO     Training average positive_sample_loss at step 385400: 0.289569\n",
      "2022-11-08 16:34:51,579 INFO     Training average negative_sample_loss at step 385400: 0.191273\n",
      "2022-11-08 16:34:51,579 INFO     Training average loss at step 385400: 0.240421\n",
      "2022-11-08 16:35:01,374 INFO     Training average positive_sample_loss at step 385500: 0.289364\n",
      "2022-11-08 16:35:01,375 INFO     Training average negative_sample_loss at step 385500: 0.196012\n",
      "2022-11-08 16:35:01,375 INFO     Training average loss at step 385500: 0.242688\n",
      "2022-11-08 16:35:11,118 INFO     Training average positive_sample_loss at step 385600: 0.282055\n",
      "2022-11-08 16:35:11,118 INFO     Training average negative_sample_loss at step 385600: 0.192093\n",
      "2022-11-08 16:35:11,118 INFO     Training average loss at step 385600: 0.237074\n",
      "2022-11-08 16:35:20,929 INFO     Training average positive_sample_loss at step 385700: 0.283261\n",
      "2022-11-08 16:35:20,929 INFO     Training average negative_sample_loss at step 385700: 0.191707\n",
      "2022-11-08 16:35:20,929 INFO     Training average loss at step 385700: 0.237484\n",
      "2022-11-08 16:35:30,895 INFO     Training average positive_sample_loss at step 385800: 0.290618\n",
      "2022-11-08 16:35:30,895 INFO     Training average negative_sample_loss at step 385800: 0.189885\n",
      "2022-11-08 16:35:30,895 INFO     Training average loss at step 385800: 0.240252\n",
      "2022-11-08 16:35:40,709 INFO     Training average positive_sample_loss at step 385900: 0.291656\n",
      "2022-11-08 16:35:40,709 INFO     Training average negative_sample_loss at step 385900: 0.191718\n",
      "2022-11-08 16:35:40,709 INFO     Training average loss at step 385900: 0.241687\n",
      "2022-11-08 16:35:50,466 INFO     Training average positive_sample_loss at step 386000: 0.291724\n",
      "2022-11-08 16:35:50,466 INFO     Training average negative_sample_loss at step 386000: 0.195330\n",
      "2022-11-08 16:35:50,466 INFO     Training average loss at step 386000: 0.243527\n",
      "2022-11-08 16:36:00,225 INFO     Training average positive_sample_loss at step 386100: 0.286145\n",
      "2022-11-08 16:36:00,225 INFO     Training average negative_sample_loss at step 386100: 0.193359\n",
      "2022-11-08 16:36:00,225 INFO     Training average loss at step 386100: 0.239752\n",
      "2022-11-08 16:36:10,038 INFO     Training average positive_sample_loss at step 386200: 0.294512\n",
      "2022-11-08 16:36:10,038 INFO     Training average negative_sample_loss at step 386200: 0.187944\n",
      "2022-11-08 16:36:10,038 INFO     Training average loss at step 386200: 0.241228\n",
      "2022-11-08 16:36:19,753 INFO     Training average positive_sample_loss at step 386300: 0.279147\n",
      "2022-11-08 16:36:19,753 INFO     Training average negative_sample_loss at step 386300: 0.193241\n",
      "2022-11-08 16:36:19,753 INFO     Training average loss at step 386300: 0.236194\n",
      "2022-11-08 16:36:29,468 INFO     Training average positive_sample_loss at step 386400: 0.272766\n",
      "2022-11-08 16:36:29,468 INFO     Training average negative_sample_loss at step 386400: 0.197457\n",
      "2022-11-08 16:36:29,468 INFO     Training average loss at step 386400: 0.235111\n",
      "2022-11-08 16:36:39,274 INFO     Training average positive_sample_loss at step 386500: 0.275655\n",
      "2022-11-08 16:36:39,274 INFO     Training average negative_sample_loss at step 386500: 0.191064\n",
      "2022-11-08 16:36:39,274 INFO     Training average loss at step 386500: 0.233359\n",
      "2022-11-08 16:36:49,046 INFO     Training average positive_sample_loss at step 386600: 0.286705\n",
      "2022-11-08 16:36:49,046 INFO     Training average negative_sample_loss at step 386600: 0.191144\n",
      "2022-11-08 16:36:49,046 INFO     Training average loss at step 386600: 0.238925\n",
      "2022-11-08 16:36:58,844 INFO     Training average positive_sample_loss at step 386700: 0.286476\n",
      "2022-11-08 16:36:58,844 INFO     Training average negative_sample_loss at step 386700: 0.192835\n",
      "2022-11-08 16:36:58,844 INFO     Training average loss at step 386700: 0.239656\n",
      "2022-11-08 16:37:08,592 INFO     Training average positive_sample_loss at step 386800: 0.295682\n",
      "2022-11-08 16:37:08,592 INFO     Training average negative_sample_loss at step 386800: 0.192471\n",
      "2022-11-08 16:37:08,592 INFO     Training average loss at step 386800: 0.244077\n",
      "2022-11-08 16:37:18,363 INFO     Training average positive_sample_loss at step 386900: 0.286674\n",
      "2022-11-08 16:37:18,363 INFO     Training average negative_sample_loss at step 386900: 0.191211\n",
      "2022-11-08 16:37:18,363 INFO     Training average loss at step 386900: 0.238943\n",
      "2022-11-08 16:37:28,196 INFO     Training average positive_sample_loss at step 387000: 0.278500\n",
      "2022-11-08 16:37:28,196 INFO     Training average negative_sample_loss at step 387000: 0.195925\n",
      "2022-11-08 16:37:28,196 INFO     Training average loss at step 387000: 0.237213\n",
      "2022-11-08 16:37:37,926 INFO     Training average positive_sample_loss at step 387100: 0.293956\n",
      "2022-11-08 16:37:37,926 INFO     Training average negative_sample_loss at step 387100: 0.199309\n",
      "2022-11-08 16:37:37,926 INFO     Training average loss at step 387100: 0.246633\n",
      "2022-11-08 16:37:47,625 INFO     Training average positive_sample_loss at step 387200: 0.286333\n",
      "2022-11-08 16:37:47,625 INFO     Training average negative_sample_loss at step 387200: 0.194162\n",
      "2022-11-08 16:37:47,625 INFO     Training average loss at step 387200: 0.240247\n",
      "2022-11-08 16:37:57,345 INFO     Training average positive_sample_loss at step 387300: 0.295648\n",
      "2022-11-08 16:37:57,345 INFO     Training average negative_sample_loss at step 387300: 0.193983\n",
      "2022-11-08 16:37:57,345 INFO     Training average loss at step 387300: 0.244815\n",
      "2022-11-08 16:38:07,078 INFO     Training average positive_sample_loss at step 387400: 0.298142\n",
      "2022-11-08 16:38:07,078 INFO     Training average negative_sample_loss at step 387400: 0.195431\n",
      "2022-11-08 16:38:07,078 INFO     Training average loss at step 387400: 0.246787\n",
      "2022-11-08 16:38:16,834 INFO     Training average positive_sample_loss at step 387500: 0.275142\n",
      "2022-11-08 16:38:16,835 INFO     Training average negative_sample_loss at step 387500: 0.195444\n",
      "2022-11-08 16:38:16,835 INFO     Training average loss at step 387500: 0.235293\n",
      "2022-11-08 16:38:26,931 INFO     Training average positive_sample_loss at step 387600: 0.286026\n",
      "2022-11-08 16:38:26,931 INFO     Training average negative_sample_loss at step 387600: 0.196026\n",
      "2022-11-08 16:38:26,931 INFO     Training average loss at step 387600: 0.241026\n",
      "2022-11-08 16:38:37,020 INFO     Training average positive_sample_loss at step 387700: 0.281902\n",
      "2022-11-08 16:38:37,020 INFO     Training average negative_sample_loss at step 387700: 0.192719\n",
      "2022-11-08 16:38:37,020 INFO     Training average loss at step 387700: 0.237310\n",
      "2022-11-08 16:38:46,780 INFO     Training average positive_sample_loss at step 387800: 0.280700\n",
      "2022-11-08 16:38:46,780 INFO     Training average negative_sample_loss at step 387800: 0.192013\n",
      "2022-11-08 16:38:46,780 INFO     Training average loss at step 387800: 0.236356\n",
      "2022-11-08 16:38:57,064 INFO     Training average positive_sample_loss at step 387900: 0.291569\n",
      "2022-11-08 16:38:57,064 INFO     Training average negative_sample_loss at step 387900: 0.196281\n",
      "2022-11-08 16:38:57,064 INFO     Training average loss at step 387900: 0.243925\n",
      "2022-11-08 16:39:07,971 INFO     Training average positive_sample_loss at step 388000: 0.283160\n",
      "2022-11-08 16:39:07,971 INFO     Training average negative_sample_loss at step 388000: 0.189504\n",
      "2022-11-08 16:39:07,971 INFO     Training average loss at step 388000: 0.236332\n",
      "2022-11-08 16:39:17,752 INFO     Training average positive_sample_loss at step 388100: 0.290904\n",
      "2022-11-08 16:39:17,752 INFO     Training average negative_sample_loss at step 388100: 0.192428\n",
      "2022-11-08 16:39:17,752 INFO     Training average loss at step 388100: 0.241666\n",
      "2022-11-08 16:39:27,527 INFO     Training average positive_sample_loss at step 388200: 0.284831\n",
      "2022-11-08 16:39:27,527 INFO     Training average negative_sample_loss at step 388200: 0.189937\n",
      "2022-11-08 16:39:27,527 INFO     Training average loss at step 388200: 0.237384\n",
      "2022-11-08 16:39:37,306 INFO     Training average positive_sample_loss at step 388300: 0.281483\n",
      "2022-11-08 16:39:37,306 INFO     Training average negative_sample_loss at step 388300: 0.194263\n",
      "2022-11-08 16:39:37,306 INFO     Training average loss at step 388300: 0.237873\n",
      "2022-11-08 16:39:47,112 INFO     Training average positive_sample_loss at step 388400: 0.285613\n",
      "2022-11-08 16:39:47,112 INFO     Training average negative_sample_loss at step 388400: 0.194836\n",
      "2022-11-08 16:39:47,112 INFO     Training average loss at step 388400: 0.240224\n",
      "2022-11-08 16:39:56,896 INFO     Training average positive_sample_loss at step 388500: 0.284036\n",
      "2022-11-08 16:39:56,897 INFO     Training average negative_sample_loss at step 388500: 0.193202\n",
      "2022-11-08 16:39:56,897 INFO     Training average loss at step 388500: 0.238619\n",
      "2022-11-08 16:40:06,640 INFO     Training average positive_sample_loss at step 388600: 0.303457\n",
      "2022-11-08 16:40:06,640 INFO     Training average negative_sample_loss at step 388600: 0.188733\n",
      "2022-11-08 16:40:06,640 INFO     Training average loss at step 388600: 0.246095\n",
      "2022-11-08 16:40:16,391 INFO     Training average positive_sample_loss at step 388700: 0.292937\n",
      "2022-11-08 16:40:16,391 INFO     Training average negative_sample_loss at step 388700: 0.190732\n",
      "2022-11-08 16:40:16,391 INFO     Training average loss at step 388700: 0.241835\n",
      "2022-11-08 16:40:26,142 INFO     Training average positive_sample_loss at step 388800: 0.285159\n",
      "2022-11-08 16:40:26,142 INFO     Training average negative_sample_loss at step 388800: 0.193270\n",
      "2022-11-08 16:40:26,142 INFO     Training average loss at step 388800: 0.239214\n",
      "2022-11-08 16:40:35,882 INFO     Training average positive_sample_loss at step 388900: 0.272041\n",
      "2022-11-08 16:40:35,882 INFO     Training average negative_sample_loss at step 388900: 0.193334\n",
      "2022-11-08 16:40:35,882 INFO     Training average loss at step 388900: 0.232687\n",
      "2022-11-08 16:40:45,604 INFO     Training average positive_sample_loss at step 389000: 0.289348\n",
      "2022-11-08 16:40:45,604 INFO     Training average negative_sample_loss at step 389000: 0.190926\n",
      "2022-11-08 16:40:45,604 INFO     Training average loss at step 389000: 0.240137\n",
      "2022-11-08 16:40:55,319 INFO     Training average positive_sample_loss at step 389100: 0.282230\n",
      "2022-11-08 16:40:55,319 INFO     Training average negative_sample_loss at step 389100: 0.193214\n",
      "2022-11-08 16:40:55,319 INFO     Training average loss at step 389100: 0.237722\n",
      "2022-11-08 16:41:05,020 INFO     Training average positive_sample_loss at step 389200: 0.286907\n",
      "2022-11-08 16:41:05,020 INFO     Training average negative_sample_loss at step 389200: 0.191787\n",
      "2022-11-08 16:41:05,020 INFO     Training average loss at step 389200: 0.239347\n",
      "2022-11-08 16:41:14,789 INFO     Training average positive_sample_loss at step 389300: 0.286118\n",
      "2022-11-08 16:41:14,790 INFO     Training average negative_sample_loss at step 389300: 0.187697\n",
      "2022-11-08 16:41:14,790 INFO     Training average loss at step 389300: 0.236908\n",
      "2022-11-08 16:41:24,523 INFO     Training average positive_sample_loss at step 389400: 0.285243\n",
      "2022-11-08 16:41:24,523 INFO     Training average negative_sample_loss at step 389400: 0.191170\n",
      "2022-11-08 16:41:24,523 INFO     Training average loss at step 389400: 0.238207\n",
      "2022-11-08 16:41:34,230 INFO     Training average positive_sample_loss at step 389500: 0.289534\n",
      "2022-11-08 16:41:34,230 INFO     Training average negative_sample_loss at step 389500: 0.189226\n",
      "2022-11-08 16:41:34,230 INFO     Training average loss at step 389500: 0.239380\n",
      "2022-11-08 16:41:43,945 INFO     Training average positive_sample_loss at step 389600: 0.268015\n",
      "2022-11-08 16:41:43,945 INFO     Training average negative_sample_loss at step 389600: 0.192239\n",
      "2022-11-08 16:41:43,945 INFO     Training average loss at step 389600: 0.230127\n",
      "2022-11-08 16:41:53,676 INFO     Training average positive_sample_loss at step 389700: 0.295358\n",
      "2022-11-08 16:41:53,676 INFO     Training average negative_sample_loss at step 389700: 0.193681\n",
      "2022-11-08 16:41:53,676 INFO     Training average loss at step 389700: 0.244520\n",
      "2022-11-08 16:42:03,416 INFO     Training average positive_sample_loss at step 389800: 0.282582\n",
      "2022-11-08 16:42:03,417 INFO     Training average negative_sample_loss at step 389800: 0.197486\n",
      "2022-11-08 16:42:03,417 INFO     Training average loss at step 389800: 0.240034\n",
      "2022-11-08 16:42:13,116 INFO     Training average positive_sample_loss at step 389900: 0.290085\n",
      "2022-11-08 16:42:13,116 INFO     Training average negative_sample_loss at step 389900: 0.192058\n",
      "2022-11-08 16:42:13,116 INFO     Training average loss at step 389900: 0.241071\n",
      "2022-11-08 16:42:24,758 INFO     Training average positive_sample_loss at step 390000: 0.278618\n",
      "2022-11-08 16:42:24,758 INFO     Training average negative_sample_loss at step 390000: 0.195929\n",
      "2022-11-08 16:42:24,758 INFO     Training average loss at step 390000: 0.237274\n",
      "2022-11-08 16:42:34,509 INFO     Training average positive_sample_loss at step 390100: 0.274394\n",
      "2022-11-08 16:42:34,509 INFO     Training average negative_sample_loss at step 390100: 0.192117\n",
      "2022-11-08 16:42:34,509 INFO     Training average loss at step 390100: 0.233255\n",
      "2022-11-08 16:42:44,253 INFO     Training average positive_sample_loss at step 390200: 0.283655\n",
      "2022-11-08 16:42:44,253 INFO     Training average negative_sample_loss at step 390200: 0.193185\n",
      "2022-11-08 16:42:44,253 INFO     Training average loss at step 390200: 0.238420\n",
      "2022-11-08 16:42:54,002 INFO     Training average positive_sample_loss at step 390300: 0.282008\n",
      "2022-11-08 16:42:54,002 INFO     Training average negative_sample_loss at step 390300: 0.193892\n",
      "2022-11-08 16:42:54,002 INFO     Training average loss at step 390300: 0.237950\n",
      "2022-11-08 16:43:03,736 INFO     Training average positive_sample_loss at step 390400: 0.282460\n",
      "2022-11-08 16:43:03,736 INFO     Training average negative_sample_loss at step 390400: 0.194754\n",
      "2022-11-08 16:43:03,736 INFO     Training average loss at step 390400: 0.238607\n",
      "2022-11-08 16:43:12,758 INFO     Training average positive_sample_loss at step 390500: 0.284847\n",
      "2022-11-08 16:43:12,759 INFO     Training average negative_sample_loss at step 390500: 0.192697\n",
      "2022-11-08 16:43:12,759 INFO     Training average loss at step 390500: 0.238772\n",
      "2022-11-08 16:43:22,519 INFO     Training average positive_sample_loss at step 390600: 0.274982\n",
      "2022-11-08 16:43:22,519 INFO     Training average negative_sample_loss at step 390600: 0.197104\n",
      "2022-11-08 16:43:22,519 INFO     Training average loss at step 390600: 0.236043\n",
      "2022-11-08 16:43:32,355 INFO     Training average positive_sample_loss at step 390700: 0.276039\n",
      "2022-11-08 16:43:32,355 INFO     Training average negative_sample_loss at step 390700: 0.190162\n",
      "2022-11-08 16:43:32,355 INFO     Training average loss at step 390700: 0.233100\n",
      "2022-11-08 16:43:42,219 INFO     Training average positive_sample_loss at step 390800: 0.282542\n",
      "2022-11-08 16:43:42,220 INFO     Training average negative_sample_loss at step 390800: 0.190261\n",
      "2022-11-08 16:43:42,220 INFO     Training average loss at step 390800: 0.236402\n",
      "2022-11-08 16:43:52,089 INFO     Training average positive_sample_loss at step 390900: 0.273932\n",
      "2022-11-08 16:43:52,089 INFO     Training average negative_sample_loss at step 390900: 0.193435\n",
      "2022-11-08 16:43:52,089 INFO     Training average loss at step 390900: 0.233683\n",
      "2022-11-08 16:44:00,266 INFO     Training average positive_sample_loss at step 391000: 0.291478\n",
      "2022-11-08 16:44:00,266 INFO     Training average negative_sample_loss at step 391000: 0.193517\n",
      "2022-11-08 16:44:00,266 INFO     Training average loss at step 391000: 0.242497\n",
      "2022-11-08 16:44:10,067 INFO     Training average positive_sample_loss at step 391100: 0.269745\n",
      "2022-11-08 16:44:10,067 INFO     Training average negative_sample_loss at step 391100: 0.193666\n",
      "2022-11-08 16:44:10,067 INFO     Training average loss at step 391100: 0.231705\n",
      "2022-11-08 16:44:20,054 INFO     Training average positive_sample_loss at step 391200: 0.295175\n",
      "2022-11-08 16:44:20,054 INFO     Training average negative_sample_loss at step 391200: 0.192684\n",
      "2022-11-08 16:44:20,054 INFO     Training average loss at step 391200: 0.243930\n",
      "2022-11-08 16:44:29,842 INFO     Training average positive_sample_loss at step 391300: 0.285768\n",
      "2022-11-08 16:44:29,842 INFO     Training average negative_sample_loss at step 391300: 0.193263\n",
      "2022-11-08 16:44:29,842 INFO     Training average loss at step 391300: 0.239515\n",
      "2022-11-08 16:44:39,657 INFO     Training average positive_sample_loss at step 391400: 0.289969\n",
      "2022-11-08 16:44:39,657 INFO     Training average negative_sample_loss at step 391400: 0.186913\n",
      "2022-11-08 16:44:39,657 INFO     Training average loss at step 391400: 0.238441\n",
      "2022-11-08 16:44:49,371 INFO     Training average positive_sample_loss at step 391500: 0.286679\n",
      "2022-11-08 16:44:49,371 INFO     Training average negative_sample_loss at step 391500: 0.191705\n",
      "2022-11-08 16:44:49,371 INFO     Training average loss at step 391500: 0.239192\n",
      "2022-11-08 16:44:59,125 INFO     Training average positive_sample_loss at step 391600: 0.280742\n",
      "2022-11-08 16:44:59,125 INFO     Training average negative_sample_loss at step 391600: 0.192510\n",
      "2022-11-08 16:44:59,125 INFO     Training average loss at step 391600: 0.236626\n",
      "2022-11-08 16:45:08,881 INFO     Training average positive_sample_loss at step 391700: 0.280027\n",
      "2022-11-08 16:45:08,882 INFO     Training average negative_sample_loss at step 391700: 0.188926\n",
      "2022-11-08 16:45:08,882 INFO     Training average loss at step 391700: 0.234477\n",
      "2022-11-08 16:45:18,659 INFO     Training average positive_sample_loss at step 391800: 0.285566\n",
      "2022-11-08 16:45:18,659 INFO     Training average negative_sample_loss at step 391800: 0.186339\n",
      "2022-11-08 16:45:18,660 INFO     Training average loss at step 391800: 0.235952\n",
      "2022-11-08 16:45:28,557 INFO     Training average positive_sample_loss at step 391900: 0.276734\n",
      "2022-11-08 16:45:28,557 INFO     Training average negative_sample_loss at step 391900: 0.195398\n",
      "2022-11-08 16:45:28,557 INFO     Training average loss at step 391900: 0.236066\n",
      "2022-11-08 16:45:38,305 INFO     Training average positive_sample_loss at step 392000: 0.291086\n",
      "2022-11-08 16:45:38,305 INFO     Training average negative_sample_loss at step 392000: 0.188324\n",
      "2022-11-08 16:45:38,305 INFO     Training average loss at step 392000: 0.239705\n",
      "2022-11-08 16:45:48,108 INFO     Training average positive_sample_loss at step 392100: 0.286467\n",
      "2022-11-08 16:45:48,108 INFO     Training average negative_sample_loss at step 392100: 0.187460\n",
      "2022-11-08 16:45:48,108 INFO     Training average loss at step 392100: 0.236963\n",
      "2022-11-08 16:45:57,860 INFO     Training average positive_sample_loss at step 392200: 0.281636\n",
      "2022-11-08 16:45:57,860 INFO     Training average negative_sample_loss at step 392200: 0.194796\n",
      "2022-11-08 16:45:57,860 INFO     Training average loss at step 392200: 0.238216\n",
      "2022-11-08 16:46:08,226 INFO     Training average positive_sample_loss at step 392300: 0.279638\n",
      "2022-11-08 16:46:08,226 INFO     Training average negative_sample_loss at step 392300: 0.194421\n",
      "2022-11-08 16:46:08,226 INFO     Training average loss at step 392300: 0.237029\n",
      "2022-11-08 16:46:18,761 INFO     Training average positive_sample_loss at step 392400: 0.280986\n",
      "2022-11-08 16:46:18,762 INFO     Training average negative_sample_loss at step 392400: 0.190549\n",
      "2022-11-08 16:46:18,762 INFO     Training average loss at step 392400: 0.235767\n",
      "2022-11-08 16:46:28,465 INFO     Training average positive_sample_loss at step 392500: 0.272969\n",
      "2022-11-08 16:46:28,465 INFO     Training average negative_sample_loss at step 392500: 0.194837\n",
      "2022-11-08 16:46:28,465 INFO     Training average loss at step 392500: 0.233903\n",
      "2022-11-08 16:46:38,168 INFO     Training average positive_sample_loss at step 392600: 0.285881\n",
      "2022-11-08 16:46:38,168 INFO     Training average negative_sample_loss at step 392600: 0.191003\n",
      "2022-11-08 16:46:38,168 INFO     Training average loss at step 392600: 0.238442\n",
      "2022-11-08 16:46:48,937 INFO     Training average positive_sample_loss at step 392700: 0.287980\n",
      "2022-11-08 16:46:48,937 INFO     Training average negative_sample_loss at step 392700: 0.194949\n",
      "2022-11-08 16:46:48,937 INFO     Training average loss at step 392700: 0.241465\n",
      "2022-11-08 16:46:58,636 INFO     Training average positive_sample_loss at step 392800: 0.298647\n",
      "2022-11-08 16:46:58,636 INFO     Training average negative_sample_loss at step 392800: 0.188243\n",
      "2022-11-08 16:46:58,636 INFO     Training average loss at step 392800: 0.243445\n",
      "2022-11-08 16:47:08,310 INFO     Training average positive_sample_loss at step 392900: 0.274410\n",
      "2022-11-08 16:47:08,310 INFO     Training average negative_sample_loss at step 392900: 0.192186\n",
      "2022-11-08 16:47:08,310 INFO     Training average loss at step 392900: 0.233298\n",
      "2022-11-08 16:47:18,116 INFO     Training average positive_sample_loss at step 393000: 0.283022\n",
      "2022-11-08 16:47:18,116 INFO     Training average negative_sample_loss at step 393000: 0.195949\n",
      "2022-11-08 16:47:18,116 INFO     Training average loss at step 393000: 0.239486\n",
      "2022-11-08 16:47:27,852 INFO     Training average positive_sample_loss at step 393100: 0.281726\n",
      "2022-11-08 16:47:27,852 INFO     Training average negative_sample_loss at step 393100: 0.194788\n",
      "2022-11-08 16:47:27,852 INFO     Training average loss at step 393100: 0.238257\n",
      "2022-11-08 16:47:37,794 INFO     Training average positive_sample_loss at step 393200: 0.279998\n",
      "2022-11-08 16:47:37,794 INFO     Training average negative_sample_loss at step 393200: 0.191932\n",
      "2022-11-08 16:47:37,794 INFO     Training average loss at step 393200: 0.235965\n",
      "2022-11-08 16:47:47,594 INFO     Training average positive_sample_loss at step 393300: 0.294265\n",
      "2022-11-08 16:47:47,595 INFO     Training average negative_sample_loss at step 393300: 0.190035\n",
      "2022-11-08 16:47:47,595 INFO     Training average loss at step 393300: 0.242150\n",
      "2022-11-08 16:47:57,474 INFO     Training average positive_sample_loss at step 393400: 0.266645\n",
      "2022-11-08 16:47:57,474 INFO     Training average negative_sample_loss at step 393400: 0.190411\n",
      "2022-11-08 16:47:57,475 INFO     Training average loss at step 393400: 0.228528\n",
      "2022-11-08 16:48:07,408 INFO     Training average positive_sample_loss at step 393500: 0.279924\n",
      "2022-11-08 16:48:07,408 INFO     Training average negative_sample_loss at step 393500: 0.191705\n",
      "2022-11-08 16:48:07,408 INFO     Training average loss at step 393500: 0.235814\n",
      "2022-11-08 16:48:17,243 INFO     Training average positive_sample_loss at step 393600: 0.288554\n",
      "2022-11-08 16:48:17,243 INFO     Training average negative_sample_loss at step 393600: 0.188988\n",
      "2022-11-08 16:48:17,243 INFO     Training average loss at step 393600: 0.238771\n",
      "2022-11-08 16:48:27,037 INFO     Training average positive_sample_loss at step 393700: 0.278342\n",
      "2022-11-08 16:48:27,037 INFO     Training average negative_sample_loss at step 393700: 0.186225\n",
      "2022-11-08 16:48:27,037 INFO     Training average loss at step 393700: 0.232284\n",
      "2022-11-08 16:48:36,888 INFO     Training average positive_sample_loss at step 393800: 0.286684\n",
      "2022-11-08 16:48:36,888 INFO     Training average negative_sample_loss at step 393800: 0.196835\n",
      "2022-11-08 16:48:36,888 INFO     Training average loss at step 393800: 0.241759\n",
      "2022-11-08 16:48:46,758 INFO     Training average positive_sample_loss at step 393900: 0.294298\n",
      "2022-11-08 16:48:46,758 INFO     Training average negative_sample_loss at step 393900: 0.195366\n",
      "2022-11-08 16:48:46,758 INFO     Training average loss at step 393900: 0.244832\n",
      "2022-11-08 16:48:56,644 INFO     Training average positive_sample_loss at step 394000: 0.284978\n",
      "2022-11-08 16:48:56,644 INFO     Training average negative_sample_loss at step 394000: 0.192289\n",
      "2022-11-08 16:48:56,644 INFO     Training average loss at step 394000: 0.238634\n",
      "2022-11-08 16:49:06,490 INFO     Training average positive_sample_loss at step 394100: 0.282046\n",
      "2022-11-08 16:49:06,490 INFO     Training average negative_sample_loss at step 394100: 0.188755\n",
      "2022-11-08 16:49:06,490 INFO     Training average loss at step 394100: 0.235401\n",
      "2022-11-08 16:49:16,311 INFO     Training average positive_sample_loss at step 394200: 0.279319\n",
      "2022-11-08 16:49:16,311 INFO     Training average negative_sample_loss at step 394200: 0.189899\n",
      "2022-11-08 16:49:16,312 INFO     Training average loss at step 394200: 0.234609\n",
      "2022-11-08 16:49:26,182 INFO     Training average positive_sample_loss at step 394300: 0.288022\n",
      "2022-11-08 16:49:26,182 INFO     Training average negative_sample_loss at step 394300: 0.192875\n",
      "2022-11-08 16:49:26,182 INFO     Training average loss at step 394300: 0.240449\n",
      "2022-11-08 16:49:36,005 INFO     Training average positive_sample_loss at step 394400: 0.276177\n",
      "2022-11-08 16:49:36,005 INFO     Training average negative_sample_loss at step 394400: 0.193908\n",
      "2022-11-08 16:49:36,005 INFO     Training average loss at step 394400: 0.235043\n",
      "2022-11-08 16:49:45,863 INFO     Training average positive_sample_loss at step 394500: 0.287976\n",
      "2022-11-08 16:49:45,864 INFO     Training average negative_sample_loss at step 394500: 0.187902\n",
      "2022-11-08 16:49:45,864 INFO     Training average loss at step 394500: 0.237939\n",
      "2022-11-08 16:49:55,652 INFO     Training average positive_sample_loss at step 394600: 0.288126\n",
      "2022-11-08 16:49:55,652 INFO     Training average negative_sample_loss at step 394600: 0.192529\n",
      "2022-11-08 16:49:55,652 INFO     Training average loss at step 394600: 0.240328\n",
      "2022-11-08 16:50:05,460 INFO     Training average positive_sample_loss at step 394700: 0.290992\n",
      "2022-11-08 16:50:05,460 INFO     Training average negative_sample_loss at step 394700: 0.191925\n",
      "2022-11-08 16:50:05,460 INFO     Training average loss at step 394700: 0.241458\n",
      "2022-11-08 16:50:15,254 INFO     Training average positive_sample_loss at step 394800: 0.283728\n",
      "2022-11-08 16:50:15,255 INFO     Training average negative_sample_loss at step 394800: 0.187272\n",
      "2022-11-08 16:50:15,255 INFO     Training average loss at step 394800: 0.235500\n",
      "2022-11-08 16:50:24,948 INFO     Training average positive_sample_loss at step 394900: 0.296523\n",
      "2022-11-08 16:50:24,948 INFO     Training average negative_sample_loss at step 394900: 0.189918\n",
      "2022-11-08 16:50:24,948 INFO     Training average loss at step 394900: 0.243221\n",
      "2022-11-08 16:50:34,660 INFO     Training average positive_sample_loss at step 395000: 0.288934\n",
      "2022-11-08 16:50:34,660 INFO     Training average negative_sample_loss at step 395000: 0.188940\n",
      "2022-11-08 16:50:34,661 INFO     Training average loss at step 395000: 0.238937\n",
      "2022-11-08 16:50:44,383 INFO     Training average positive_sample_loss at step 395100: 0.284970\n",
      "2022-11-08 16:50:44,383 INFO     Training average negative_sample_loss at step 395100: 0.193765\n",
      "2022-11-08 16:50:44,383 INFO     Training average loss at step 395100: 0.239367\n",
      "2022-11-08 16:50:54,178 INFO     Training average positive_sample_loss at step 395200: 0.280679\n",
      "2022-11-08 16:50:54,178 INFO     Training average negative_sample_loss at step 395200: 0.195361\n",
      "2022-11-08 16:50:54,178 INFO     Training average loss at step 395200: 0.238020\n",
      "2022-11-08 16:51:03,991 INFO     Training average positive_sample_loss at step 395300: 0.279088\n",
      "2022-11-08 16:51:03,992 INFO     Training average negative_sample_loss at step 395300: 0.193226\n",
      "2022-11-08 16:51:03,992 INFO     Training average loss at step 395300: 0.236157\n",
      "2022-11-08 16:51:13,672 INFO     Training average positive_sample_loss at step 395400: 0.278770\n",
      "2022-11-08 16:51:13,672 INFO     Training average negative_sample_loss at step 395400: 0.188932\n",
      "2022-11-08 16:51:13,672 INFO     Training average loss at step 395400: 0.233851\n",
      "2022-11-08 16:51:22,709 INFO     Training average positive_sample_loss at step 395500: 0.279259\n",
      "2022-11-08 16:51:22,709 INFO     Training average negative_sample_loss at step 395500: 0.192864\n",
      "2022-11-08 16:51:22,709 INFO     Training average loss at step 395500: 0.236062\n",
      "2022-11-08 16:51:32,450 INFO     Training average positive_sample_loss at step 395600: 0.277675\n",
      "2022-11-08 16:51:32,450 INFO     Training average negative_sample_loss at step 395600: 0.193483\n",
      "2022-11-08 16:51:32,450 INFO     Training average loss at step 395600: 0.235579\n",
      "2022-11-08 16:51:42,192 INFO     Training average positive_sample_loss at step 395700: 0.287036\n",
      "2022-11-08 16:51:42,192 INFO     Training average negative_sample_loss at step 395700: 0.188984\n",
      "2022-11-08 16:51:42,192 INFO     Training average loss at step 395700: 0.238010\n",
      "2022-11-08 16:51:55,286 INFO     Training average positive_sample_loss at step 395800: 0.266140\n",
      "2022-11-08 16:51:55,286 INFO     Training average negative_sample_loss at step 395800: 0.190490\n",
      "2022-11-08 16:51:55,286 INFO     Training average loss at step 395800: 0.228315\n",
      "2022-11-08 16:52:04,900 INFO     Training average positive_sample_loss at step 395900: 0.196366\n",
      "2022-11-08 16:52:04,900 INFO     Training average negative_sample_loss at step 395900: 0.186909\n",
      "2022-11-08 16:52:04,900 INFO     Training average loss at step 395900: 0.191638\n",
      "2022-11-08 16:52:14,236 INFO     Training average positive_sample_loss at step 396000: 0.200158\n",
      "2022-11-08 16:52:14,236 INFO     Training average negative_sample_loss at step 396000: 0.188822\n",
      "2022-11-08 16:52:14,236 INFO     Training average loss at step 396000: 0.194490\n",
      "2022-11-08 16:52:23,958 INFO     Training average positive_sample_loss at step 396100: 0.205022\n",
      "2022-11-08 16:52:23,958 INFO     Training average negative_sample_loss at step 396100: 0.186670\n",
      "2022-11-08 16:52:23,958 INFO     Training average loss at step 396100: 0.195846\n",
      "2022-11-08 16:52:33,689 INFO     Training average positive_sample_loss at step 396200: 0.197602\n",
      "2022-11-08 16:52:33,689 INFO     Training average negative_sample_loss at step 396200: 0.181555\n",
      "2022-11-08 16:52:33,689 INFO     Training average loss at step 396200: 0.189578\n",
      "2022-11-08 16:52:43,385 INFO     Training average positive_sample_loss at step 396300: 0.201488\n",
      "2022-11-08 16:52:43,385 INFO     Training average negative_sample_loss at step 396300: 0.183415\n",
      "2022-11-08 16:52:43,385 INFO     Training average loss at step 396300: 0.192451\n",
      "2022-11-08 16:52:53,071 INFO     Training average positive_sample_loss at step 396400: 0.202105\n",
      "2022-11-08 16:52:53,071 INFO     Training average negative_sample_loss at step 396400: 0.179197\n",
      "2022-11-08 16:52:53,071 INFO     Training average loss at step 396400: 0.190651\n",
      "2022-11-08 16:53:02,843 INFO     Training average positive_sample_loss at step 396500: 0.200148\n",
      "2022-11-08 16:53:02,843 INFO     Training average negative_sample_loss at step 396500: 0.182040\n",
      "2022-11-08 16:53:02,843 INFO     Training average loss at step 396500: 0.191094\n",
      "2022-11-08 16:53:12,556 INFO     Training average positive_sample_loss at step 396600: 0.214720\n",
      "2022-11-08 16:53:12,556 INFO     Training average negative_sample_loss at step 396600: 0.176040\n",
      "2022-11-08 16:53:12,556 INFO     Training average loss at step 396600: 0.195380\n",
      "2022-11-08 16:53:22,259 INFO     Training average positive_sample_loss at step 396700: 0.209415\n",
      "2022-11-08 16:53:22,259 INFO     Training average negative_sample_loss at step 396700: 0.175964\n",
      "2022-11-08 16:53:22,259 INFO     Training average loss at step 396700: 0.192690\n",
      "2022-11-08 16:53:32,095 INFO     Training average positive_sample_loss at step 396800: 0.197769\n",
      "2022-11-08 16:53:32,095 INFO     Training average negative_sample_loss at step 396800: 0.180939\n",
      "2022-11-08 16:53:32,095 INFO     Training average loss at step 396800: 0.189354\n",
      "2022-11-08 16:53:41,886 INFO     Training average positive_sample_loss at step 396900: 0.201091\n",
      "2022-11-08 16:53:41,886 INFO     Training average negative_sample_loss at step 396900: 0.177408\n",
      "2022-11-08 16:53:41,887 INFO     Training average loss at step 396900: 0.189249\n",
      "2022-11-08 16:53:51,836 INFO     Training average positive_sample_loss at step 397000: 0.209711\n",
      "2022-11-08 16:53:51,836 INFO     Training average negative_sample_loss at step 397000: 0.177518\n",
      "2022-11-08 16:53:51,836 INFO     Training average loss at step 397000: 0.193615\n",
      "2022-11-08 16:54:01,539 INFO     Training average positive_sample_loss at step 397100: 0.206641\n",
      "2022-11-08 16:54:01,539 INFO     Training average negative_sample_loss at step 397100: 0.181914\n",
      "2022-11-08 16:54:01,539 INFO     Training average loss at step 397100: 0.194278\n",
      "2022-11-08 16:54:11,284 INFO     Training average positive_sample_loss at step 397200: 0.212867\n",
      "2022-11-08 16:54:11,284 INFO     Training average negative_sample_loss at step 397200: 0.181514\n",
      "2022-11-08 16:54:11,284 INFO     Training average loss at step 397200: 0.197191\n",
      "2022-11-08 16:54:21,091 INFO     Training average positive_sample_loss at step 397300: 0.207881\n",
      "2022-11-08 16:54:21,092 INFO     Training average negative_sample_loss at step 397300: 0.180098\n",
      "2022-11-08 16:54:21,092 INFO     Training average loss at step 397300: 0.193990\n",
      "2022-11-08 16:54:30,898 INFO     Training average positive_sample_loss at step 397400: 0.202290\n",
      "2022-11-08 16:54:30,898 INFO     Training average negative_sample_loss at step 397400: 0.179972\n",
      "2022-11-08 16:54:30,898 INFO     Training average loss at step 397400: 0.191131\n",
      "2022-11-08 16:54:40,594 INFO     Training average positive_sample_loss at step 397500: 0.213182\n",
      "2022-11-08 16:54:40,594 INFO     Training average negative_sample_loss at step 397500: 0.176085\n",
      "2022-11-08 16:54:40,594 INFO     Training average loss at step 397500: 0.194633\n",
      "2022-11-08 16:54:50,421 INFO     Training average positive_sample_loss at step 397600: 0.214600\n",
      "2022-11-08 16:54:50,421 INFO     Training average negative_sample_loss at step 397600: 0.178585\n",
      "2022-11-08 16:54:50,421 INFO     Training average loss at step 397600: 0.196593\n",
      "2022-11-08 16:55:00,267 INFO     Training average positive_sample_loss at step 397700: 0.212115\n",
      "2022-11-08 16:55:00,267 INFO     Training average negative_sample_loss at step 397700: 0.179862\n",
      "2022-11-08 16:55:00,267 INFO     Training average loss at step 397700: 0.195988\n",
      "2022-11-08 16:55:10,021 INFO     Training average positive_sample_loss at step 397800: 0.205533\n",
      "2022-11-08 16:55:10,021 INFO     Training average negative_sample_loss at step 397800: 0.176449\n",
      "2022-11-08 16:55:10,021 INFO     Training average loss at step 397800: 0.190991\n",
      "2022-11-08 16:55:19,742 INFO     Training average positive_sample_loss at step 397900: 0.217272\n",
      "2022-11-08 16:55:19,742 INFO     Training average negative_sample_loss at step 397900: 0.176045\n",
      "2022-11-08 16:55:19,742 INFO     Training average loss at step 397900: 0.196659\n",
      "2022-11-08 16:55:29,498 INFO     Training average positive_sample_loss at step 398000: 0.206292\n",
      "2022-11-08 16:55:29,498 INFO     Training average negative_sample_loss at step 398000: 0.176535\n",
      "2022-11-08 16:55:29,498 INFO     Training average loss at step 398000: 0.191413\n",
      "2022-11-08 16:55:39,250 INFO     Training average positive_sample_loss at step 398100: 0.211335\n",
      "2022-11-08 16:55:39,250 INFO     Training average negative_sample_loss at step 398100: 0.179420\n",
      "2022-11-08 16:55:39,250 INFO     Training average loss at step 398100: 0.195378\n",
      "2022-11-08 16:55:49,003 INFO     Training average positive_sample_loss at step 398200: 0.203808\n",
      "2022-11-08 16:55:49,003 INFO     Training average negative_sample_loss at step 398200: 0.177550\n",
      "2022-11-08 16:55:49,003 INFO     Training average loss at step 398200: 0.190679\n",
      "2022-11-08 16:55:58,759 INFO     Training average positive_sample_loss at step 398300: 0.211359\n",
      "2022-11-08 16:55:58,759 INFO     Training average negative_sample_loss at step 398300: 0.174901\n",
      "2022-11-08 16:55:58,759 INFO     Training average loss at step 398300: 0.193130\n",
      "2022-11-08 16:56:08,528 INFO     Training average positive_sample_loss at step 398400: 0.212718\n",
      "2022-11-08 16:56:08,528 INFO     Training average negative_sample_loss at step 398400: 0.174795\n",
      "2022-11-08 16:56:08,528 INFO     Training average loss at step 398400: 0.193756\n",
      "2022-11-08 16:56:18,239 INFO     Training average positive_sample_loss at step 398500: 0.212159\n",
      "2022-11-08 16:56:18,239 INFO     Training average negative_sample_loss at step 398500: 0.176833\n",
      "2022-11-08 16:56:18,239 INFO     Training average loss at step 398500: 0.194496\n",
      "2022-11-08 16:56:27,909 INFO     Training average positive_sample_loss at step 398600: 0.222944\n",
      "2022-11-08 16:56:27,909 INFO     Training average negative_sample_loss at step 398600: 0.177276\n",
      "2022-11-08 16:56:27,909 INFO     Training average loss at step 398600: 0.200110\n",
      "2022-11-08 16:56:37,619 INFO     Training average positive_sample_loss at step 398700: 0.214066\n",
      "2022-11-08 16:56:37,619 INFO     Training average negative_sample_loss at step 398700: 0.180728\n",
      "2022-11-08 16:56:37,619 INFO     Training average loss at step 398700: 0.197397\n",
      "2022-11-08 16:56:47,380 INFO     Training average positive_sample_loss at step 398800: 0.207522\n",
      "2022-11-08 16:56:47,380 INFO     Training average negative_sample_loss at step 398800: 0.177952\n",
      "2022-11-08 16:56:47,380 INFO     Training average loss at step 398800: 0.192737\n",
      "2022-11-08 16:56:57,112 INFO     Training average positive_sample_loss at step 398900: 0.213183\n",
      "2022-11-08 16:56:57,112 INFO     Training average negative_sample_loss at step 398900: 0.178063\n",
      "2022-11-08 16:56:57,112 INFO     Training average loss at step 398900: 0.195623\n",
      "2022-11-08 16:57:06,860 INFO     Training average positive_sample_loss at step 399000: 0.211441\n",
      "2022-11-08 16:57:06,860 INFO     Training average negative_sample_loss at step 399000: 0.179395\n",
      "2022-11-08 16:57:06,860 INFO     Training average loss at step 399000: 0.195418\n",
      "2022-11-08 16:57:16,606 INFO     Training average positive_sample_loss at step 399100: 0.210132\n",
      "2022-11-08 16:57:16,606 INFO     Training average negative_sample_loss at step 399100: 0.176057\n",
      "2022-11-08 16:57:16,606 INFO     Training average loss at step 399100: 0.193095\n",
      "2022-11-08 16:57:26,355 INFO     Training average positive_sample_loss at step 399200: 0.210230\n",
      "2022-11-08 16:57:26,355 INFO     Training average negative_sample_loss at step 399200: 0.176603\n",
      "2022-11-08 16:57:26,355 INFO     Training average loss at step 399200: 0.193417\n",
      "2022-11-08 16:57:36,106 INFO     Training average positive_sample_loss at step 399300: 0.209881\n",
      "2022-11-08 16:57:36,106 INFO     Training average negative_sample_loss at step 399300: 0.178703\n",
      "2022-11-08 16:57:36,106 INFO     Training average loss at step 399300: 0.194292\n",
      "2022-11-08 16:57:45,858 INFO     Training average positive_sample_loss at step 399400: 0.223588\n",
      "2022-11-08 16:57:45,858 INFO     Training average negative_sample_loss at step 399400: 0.178308\n",
      "2022-11-08 16:57:45,858 INFO     Training average loss at step 399400: 0.200948\n",
      "2022-11-08 16:57:55,615 INFO     Training average positive_sample_loss at step 399500: 0.225522\n",
      "2022-11-08 16:57:55,615 INFO     Training average negative_sample_loss at step 399500: 0.175889\n",
      "2022-11-08 16:57:55,615 INFO     Training average loss at step 399500: 0.200706\n",
      "2022-11-08 16:58:05,378 INFO     Training average positive_sample_loss at step 399600: 0.206727\n",
      "2022-11-08 16:58:05,378 INFO     Training average negative_sample_loss at step 399600: 0.175795\n",
      "2022-11-08 16:58:05,378 INFO     Training average loss at step 399600: 0.191261\n",
      "2022-11-08 16:58:15,149 INFO     Training average positive_sample_loss at step 399700: 0.212080\n",
      "2022-11-08 16:58:15,149 INFO     Training average negative_sample_loss at step 399700: 0.179212\n",
      "2022-11-08 16:58:15,149 INFO     Training average loss at step 399700: 0.195646\n",
      "2022-11-08 16:58:24,927 INFO     Training average positive_sample_loss at step 399800: 0.212087\n",
      "2022-11-08 16:58:24,927 INFO     Training average negative_sample_loss at step 399800: 0.180839\n",
      "2022-11-08 16:58:24,927 INFO     Training average loss at step 399800: 0.196463\n",
      "2022-11-08 16:58:34,658 INFO     Training average positive_sample_loss at step 399900: 0.219519\n",
      "2022-11-08 16:58:34,658 INFO     Training average negative_sample_loss at step 399900: 0.176681\n",
      "2022-11-08 16:58:34,658 INFO     Training average loss at step 399900: 0.198100\n",
      "2022-11-08 16:58:47,328 INFO     Training average positive_sample_loss at step 400000: 0.221988\n",
      "2022-11-08 16:58:47,328 INFO     Training average negative_sample_loss at step 400000: 0.177700\n",
      "2022-11-08 16:58:47,328 INFO     Training average loss at step 400000: 0.199844\n",
      "2022-11-08 16:58:57,082 INFO     Training average positive_sample_loss at step 400100: 0.215198\n",
      "2022-11-08 16:58:57,082 INFO     Training average negative_sample_loss at step 400100: 0.181674\n",
      "2022-11-08 16:58:57,083 INFO     Training average loss at step 400100: 0.198436\n",
      "2022-11-08 16:59:06,832 INFO     Training average positive_sample_loss at step 400200: 0.214518\n",
      "2022-11-08 16:59:06,832 INFO     Training average negative_sample_loss at step 400200: 0.173216\n",
      "2022-11-08 16:59:06,832 INFO     Training average loss at step 400200: 0.193867\n",
      "2022-11-08 16:59:16,584 INFO     Training average positive_sample_loss at step 400300: 0.215421\n",
      "2022-11-08 16:59:16,584 INFO     Training average negative_sample_loss at step 400300: 0.177661\n",
      "2022-11-08 16:59:16,584 INFO     Training average loss at step 400300: 0.196541\n",
      "2022-11-08 16:59:26,336 INFO     Training average positive_sample_loss at step 400400: 0.216540\n",
      "2022-11-08 16:59:26,336 INFO     Training average negative_sample_loss at step 400400: 0.177142\n",
      "2022-11-08 16:59:26,336 INFO     Training average loss at step 400400: 0.196841\n",
      "2022-11-08 16:59:36,087 INFO     Training average positive_sample_loss at step 400500: 0.218841\n",
      "2022-11-08 16:59:36,087 INFO     Training average negative_sample_loss at step 400500: 0.174380\n",
      "2022-11-08 16:59:36,087 INFO     Training average loss at step 400500: 0.196611\n",
      "2022-11-08 16:59:45,844 INFO     Training average positive_sample_loss at step 400600: 0.220577\n",
      "2022-11-08 16:59:45,845 INFO     Training average negative_sample_loss at step 400600: 0.181082\n",
      "2022-11-08 16:59:45,845 INFO     Training average loss at step 400600: 0.200829\n",
      "2022-11-08 16:59:55,580 INFO     Training average positive_sample_loss at step 400700: 0.221924\n",
      "2022-11-08 16:59:55,580 INFO     Training average negative_sample_loss at step 400700: 0.175343\n",
      "2022-11-08 16:59:55,581 INFO     Training average loss at step 400700: 0.198633\n",
      "2022-11-08 17:00:05,318 INFO     Training average positive_sample_loss at step 400800: 0.217740\n",
      "2022-11-08 17:00:05,318 INFO     Training average negative_sample_loss at step 400800: 0.179410\n",
      "2022-11-08 17:00:05,318 INFO     Training average loss at step 400800: 0.198575\n",
      "2022-11-08 17:00:14,552 INFO     Training average positive_sample_loss at step 400900: 0.218763\n",
      "2022-11-08 17:00:14,552 INFO     Training average negative_sample_loss at step 400900: 0.176293\n",
      "2022-11-08 17:00:14,552 INFO     Training average loss at step 400900: 0.197528\n",
      "2022-11-08 17:00:24,322 INFO     Training average positive_sample_loss at step 401000: 0.212225\n",
      "2022-11-08 17:00:24,322 INFO     Training average negative_sample_loss at step 401000: 0.173164\n",
      "2022-11-08 17:00:24,322 INFO     Training average loss at step 401000: 0.192695\n",
      "2022-11-08 17:00:34,075 INFO     Training average positive_sample_loss at step 401100: 0.203603\n",
      "2022-11-08 17:00:34,075 INFO     Training average negative_sample_loss at step 401100: 0.175402\n",
      "2022-11-08 17:00:34,075 INFO     Training average loss at step 401100: 0.189503\n",
      "2022-11-08 17:00:43,832 INFO     Training average positive_sample_loss at step 401200: 0.221933\n",
      "2022-11-08 17:00:43,832 INFO     Training average negative_sample_loss at step 401200: 0.178455\n",
      "2022-11-08 17:00:43,832 INFO     Training average loss at step 401200: 0.200194\n",
      "2022-11-08 17:00:53,564 INFO     Training average positive_sample_loss at step 401300: 0.215561\n",
      "2022-11-08 17:00:53,564 INFO     Training average negative_sample_loss at step 401300: 0.174717\n",
      "2022-11-08 17:00:53,564 INFO     Training average loss at step 401300: 0.195139\n",
      "2022-11-08 17:01:02,515 INFO     Training average positive_sample_loss at step 401400: 0.207652\n",
      "2022-11-08 17:01:02,515 INFO     Training average negative_sample_loss at step 401400: 0.175359\n",
      "2022-11-08 17:01:02,515 INFO     Training average loss at step 401400: 0.191505\n",
      "2022-11-08 17:01:12,208 INFO     Training average positive_sample_loss at step 401500: 0.222076\n",
      "2022-11-08 17:01:12,208 INFO     Training average negative_sample_loss at step 401500: 0.173727\n",
      "2022-11-08 17:01:12,208 INFO     Training average loss at step 401500: 0.197902\n",
      "2022-11-08 17:01:21,964 INFO     Training average positive_sample_loss at step 401600: 0.207109\n",
      "2022-11-08 17:01:21,964 INFO     Training average negative_sample_loss at step 401600: 0.175449\n",
      "2022-11-08 17:01:21,964 INFO     Training average loss at step 401600: 0.191279\n",
      "2022-11-08 17:01:31,729 INFO     Training average positive_sample_loss at step 401700: 0.220774\n",
      "2022-11-08 17:01:31,729 INFO     Training average negative_sample_loss at step 401700: 0.178554\n",
      "2022-11-08 17:01:31,729 INFO     Training average loss at step 401700: 0.199664\n",
      "2022-11-08 17:01:41,477 INFO     Training average positive_sample_loss at step 401800: 0.225984\n",
      "2022-11-08 17:01:41,477 INFO     Training average negative_sample_loss at step 401800: 0.175397\n",
      "2022-11-08 17:01:41,477 INFO     Training average loss at step 401800: 0.200691\n",
      "2022-11-08 17:01:51,225 INFO     Training average positive_sample_loss at step 401900: 0.216205\n",
      "2022-11-08 17:01:51,225 INFO     Training average negative_sample_loss at step 401900: 0.174109\n",
      "2022-11-08 17:01:51,225 INFO     Training average loss at step 401900: 0.195157\n",
      "2022-11-08 17:02:00,979 INFO     Training average positive_sample_loss at step 402000: 0.223261\n",
      "2022-11-08 17:02:00,979 INFO     Training average negative_sample_loss at step 402000: 0.170568\n",
      "2022-11-08 17:02:00,979 INFO     Training average loss at step 402000: 0.196915\n",
      "2022-11-08 17:02:10,752 INFO     Training average positive_sample_loss at step 402100: 0.218284\n",
      "2022-11-08 17:02:10,752 INFO     Training average negative_sample_loss at step 402100: 0.179480\n",
      "2022-11-08 17:02:10,752 INFO     Training average loss at step 402100: 0.198882\n",
      "2022-11-08 17:02:20,512 INFO     Training average positive_sample_loss at step 402200: 0.214367\n",
      "2022-11-08 17:02:20,512 INFO     Training average negative_sample_loss at step 402200: 0.178229\n",
      "2022-11-08 17:02:20,512 INFO     Training average loss at step 402200: 0.196298\n",
      "2022-11-08 17:02:30,268 INFO     Training average positive_sample_loss at step 402300: 0.217597\n",
      "2022-11-08 17:02:30,268 INFO     Training average negative_sample_loss at step 402300: 0.178453\n",
      "2022-11-08 17:02:30,268 INFO     Training average loss at step 402300: 0.198025\n",
      "2022-11-08 17:02:40,059 INFO     Training average positive_sample_loss at step 402400: 0.212136\n",
      "2022-11-08 17:02:40,059 INFO     Training average negative_sample_loss at step 402400: 0.179048\n",
      "2022-11-08 17:02:40,059 INFO     Training average loss at step 402400: 0.195592\n",
      "2022-11-08 17:02:49,894 INFO     Training average positive_sample_loss at step 402500: 0.217653\n",
      "2022-11-08 17:02:49,894 INFO     Training average negative_sample_loss at step 402500: 0.176593\n",
      "2022-11-08 17:02:49,894 INFO     Training average loss at step 402500: 0.197123\n",
      "2022-11-08 17:02:59,668 INFO     Training average positive_sample_loss at step 402600: 0.220295\n",
      "2022-11-08 17:02:59,668 INFO     Training average negative_sample_loss at step 402600: 0.177342\n",
      "2022-11-08 17:02:59,668 INFO     Training average loss at step 402600: 0.198819\n",
      "2022-11-08 17:03:09,386 INFO     Training average positive_sample_loss at step 402700: 0.215046\n",
      "2022-11-08 17:03:09,386 INFO     Training average negative_sample_loss at step 402700: 0.174787\n",
      "2022-11-08 17:03:09,386 INFO     Training average loss at step 402700: 0.194917\n",
      "2022-11-08 17:03:19,090 INFO     Training average positive_sample_loss at step 402800: 0.214607\n",
      "2022-11-08 17:03:19,090 INFO     Training average negative_sample_loss at step 402800: 0.176828\n",
      "2022-11-08 17:03:19,090 INFO     Training average loss at step 402800: 0.195717\n",
      "2022-11-08 17:03:28,757 INFO     Training average positive_sample_loss at step 402900: 0.210633\n",
      "2022-11-08 17:03:28,758 INFO     Training average negative_sample_loss at step 402900: 0.175088\n",
      "2022-11-08 17:03:28,758 INFO     Training average loss at step 402900: 0.192861\n",
      "2022-11-08 17:03:38,536 INFO     Training average positive_sample_loss at step 403000: 0.207349\n",
      "2022-11-08 17:03:38,536 INFO     Training average negative_sample_loss at step 403000: 0.176508\n",
      "2022-11-08 17:03:38,536 INFO     Training average loss at step 403000: 0.191928\n",
      "2022-11-08 17:03:48,322 INFO     Training average positive_sample_loss at step 403100: 0.207300\n",
      "2022-11-08 17:03:48,322 INFO     Training average negative_sample_loss at step 403100: 0.177011\n",
      "2022-11-08 17:03:48,322 INFO     Training average loss at step 403100: 0.192156\n",
      "2022-11-08 17:03:58,070 INFO     Training average positive_sample_loss at step 403200: 0.219441\n",
      "2022-11-08 17:03:58,070 INFO     Training average negative_sample_loss at step 403200: 0.177892\n",
      "2022-11-08 17:03:58,070 INFO     Training average loss at step 403200: 0.198667\n",
      "2022-11-08 17:04:07,815 INFO     Training average positive_sample_loss at step 403300: 0.213996\n",
      "2022-11-08 17:04:07,815 INFO     Training average negative_sample_loss at step 403300: 0.176182\n",
      "2022-11-08 17:04:07,815 INFO     Training average loss at step 403300: 0.195089\n",
      "2022-11-08 17:04:17,499 INFO     Training average positive_sample_loss at step 403400: 0.215580\n",
      "2022-11-08 17:04:17,499 INFO     Training average negative_sample_loss at step 403400: 0.176146\n",
      "2022-11-08 17:04:17,499 INFO     Training average loss at step 403400: 0.195863\n",
      "2022-11-08 17:04:27,227 INFO     Training average positive_sample_loss at step 403500: 0.227770\n",
      "2022-11-08 17:04:27,227 INFO     Training average negative_sample_loss at step 403500: 0.183933\n",
      "2022-11-08 17:04:27,227 INFO     Training average loss at step 403500: 0.205852\n",
      "2022-11-08 17:04:37,035 INFO     Training average positive_sample_loss at step 403600: 0.224067\n",
      "2022-11-08 17:04:37,035 INFO     Training average negative_sample_loss at step 403600: 0.178737\n",
      "2022-11-08 17:04:37,035 INFO     Training average loss at step 403600: 0.201402\n",
      "2022-11-08 17:04:46,721 INFO     Training average positive_sample_loss at step 403700: 0.227605\n",
      "2022-11-08 17:04:46,721 INFO     Training average negative_sample_loss at step 403700: 0.169789\n",
      "2022-11-08 17:04:46,721 INFO     Training average loss at step 403700: 0.198697\n",
      "2022-11-08 17:04:56,482 INFO     Training average positive_sample_loss at step 403800: 0.212303\n",
      "2022-11-08 17:04:56,482 INFO     Training average negative_sample_loss at step 403800: 0.176066\n",
      "2022-11-08 17:04:56,482 INFO     Training average loss at step 403800: 0.194185\n",
      "2022-11-08 17:05:06,301 INFO     Training average positive_sample_loss at step 403900: 0.219676\n",
      "2022-11-08 17:05:06,302 INFO     Training average negative_sample_loss at step 403900: 0.171548\n",
      "2022-11-08 17:05:06,302 INFO     Training average loss at step 403900: 0.195612\n",
      "2022-11-08 17:05:16,026 INFO     Training average positive_sample_loss at step 404000: 0.230525\n",
      "2022-11-08 17:05:16,026 INFO     Training average negative_sample_loss at step 404000: 0.175362\n",
      "2022-11-08 17:05:16,026 INFO     Training average loss at step 404000: 0.202943\n",
      "2022-11-08 17:05:25,827 INFO     Training average positive_sample_loss at step 404100: 0.227945\n",
      "2022-11-08 17:05:25,827 INFO     Training average negative_sample_loss at step 404100: 0.181034\n",
      "2022-11-08 17:05:25,827 INFO     Training average loss at step 404100: 0.204489\n",
      "2022-11-08 17:05:35,624 INFO     Training average positive_sample_loss at step 404200: 0.211175\n",
      "2022-11-08 17:05:35,624 INFO     Training average negative_sample_loss at step 404200: 0.173028\n",
      "2022-11-08 17:05:35,624 INFO     Training average loss at step 404200: 0.192102\n",
      "2022-11-08 17:05:45,326 INFO     Training average positive_sample_loss at step 404300: 0.221500\n",
      "2022-11-08 17:05:45,326 INFO     Training average negative_sample_loss at step 404300: 0.173226\n",
      "2022-11-08 17:05:45,326 INFO     Training average loss at step 404300: 0.197363\n",
      "2022-11-08 17:05:55,076 INFO     Training average positive_sample_loss at step 404400: 0.219637\n",
      "2022-11-08 17:05:55,076 INFO     Training average negative_sample_loss at step 404400: 0.173826\n",
      "2022-11-08 17:05:55,076 INFO     Training average loss at step 404400: 0.196731\n",
      "2022-11-08 17:06:04,779 INFO     Training average positive_sample_loss at step 404500: 0.212964\n",
      "2022-11-08 17:06:04,779 INFO     Training average negative_sample_loss at step 404500: 0.176038\n",
      "2022-11-08 17:06:04,779 INFO     Training average loss at step 404500: 0.194501\n",
      "2022-11-08 17:06:14,494 INFO     Training average positive_sample_loss at step 404600: 0.218006\n",
      "2022-11-08 17:06:14,494 INFO     Training average negative_sample_loss at step 404600: 0.177590\n",
      "2022-11-08 17:06:14,494 INFO     Training average loss at step 404600: 0.197798\n",
      "2022-11-08 17:06:24,179 INFO     Training average positive_sample_loss at step 404700: 0.213453\n",
      "2022-11-08 17:06:24,179 INFO     Training average negative_sample_loss at step 404700: 0.177632\n",
      "2022-11-08 17:06:24,179 INFO     Training average loss at step 404700: 0.195543\n",
      "2022-11-08 17:06:33,958 INFO     Training average positive_sample_loss at step 404800: 0.219690\n",
      "2022-11-08 17:06:33,958 INFO     Training average negative_sample_loss at step 404800: 0.171933\n",
      "2022-11-08 17:06:33,958 INFO     Training average loss at step 404800: 0.195811\n",
      "2022-11-08 17:06:42,099 INFO     Training average positive_sample_loss at step 404900: 0.214916\n",
      "2022-11-08 17:06:42,100 INFO     Training average negative_sample_loss at step 404900: 0.171273\n",
      "2022-11-08 17:06:42,100 INFO     Training average loss at step 404900: 0.193095\n",
      "2022-11-08 17:06:51,809 INFO     Training average positive_sample_loss at step 405000: 0.216187\n",
      "2022-11-08 17:06:51,809 INFO     Training average negative_sample_loss at step 405000: 0.174973\n",
      "2022-11-08 17:06:51,809 INFO     Training average loss at step 405000: 0.195580\n",
      "2022-11-08 17:07:01,505 INFO     Training average positive_sample_loss at step 405100: 0.218919\n",
      "2022-11-08 17:07:01,505 INFO     Training average negative_sample_loss at step 405100: 0.175660\n",
      "2022-11-08 17:07:01,505 INFO     Training average loss at step 405100: 0.197289\n",
      "2022-11-08 17:07:11,265 INFO     Training average positive_sample_loss at step 405200: 0.221886\n",
      "2022-11-08 17:07:11,265 INFO     Training average negative_sample_loss at step 405200: 0.180804\n",
      "2022-11-08 17:07:11,265 INFO     Training average loss at step 405200: 0.201345\n",
      "2022-11-08 17:07:21,076 INFO     Training average positive_sample_loss at step 405300: 0.220897\n",
      "2022-11-08 17:07:21,076 INFO     Training average negative_sample_loss at step 405300: 0.172665\n",
      "2022-11-08 17:07:21,076 INFO     Training average loss at step 405300: 0.196781\n",
      "2022-11-08 17:07:30,903 INFO     Training average positive_sample_loss at step 405400: 0.213306\n",
      "2022-11-08 17:07:30,903 INFO     Training average negative_sample_loss at step 405400: 0.179132\n",
      "2022-11-08 17:07:30,903 INFO     Training average loss at step 405400: 0.196219\n",
      "2022-11-08 17:07:40,599 INFO     Training average positive_sample_loss at step 405500: 0.216134\n",
      "2022-11-08 17:07:40,599 INFO     Training average negative_sample_loss at step 405500: 0.172369\n",
      "2022-11-08 17:07:40,599 INFO     Training average loss at step 405500: 0.194252\n",
      "2022-11-08 17:07:50,301 INFO     Training average positive_sample_loss at step 405600: 0.219019\n",
      "2022-11-08 17:07:50,301 INFO     Training average negative_sample_loss at step 405600: 0.174461\n",
      "2022-11-08 17:07:50,301 INFO     Training average loss at step 405600: 0.196740\n",
      "2022-11-08 17:07:59,992 INFO     Training average positive_sample_loss at step 405700: 0.228332\n",
      "2022-11-08 17:07:59,992 INFO     Training average negative_sample_loss at step 405700: 0.175817\n",
      "2022-11-08 17:07:59,992 INFO     Training average loss at step 405700: 0.202075\n",
      "2022-11-08 17:08:09,664 INFO     Training average positive_sample_loss at step 405800: 0.219287\n",
      "2022-11-08 17:08:09,664 INFO     Training average negative_sample_loss at step 405800: 0.174406\n",
      "2022-11-08 17:08:09,664 INFO     Training average loss at step 405800: 0.196846\n",
      "2022-11-08 17:08:20,502 INFO     Training average positive_sample_loss at step 405900: 0.223541\n",
      "2022-11-08 17:08:20,502 INFO     Training average negative_sample_loss at step 405900: 0.176654\n",
      "2022-11-08 17:08:20,502 INFO     Training average loss at step 405900: 0.200097\n",
      "2022-11-08 17:08:31,536 INFO     Training average positive_sample_loss at step 406000: 0.221796\n",
      "2022-11-08 17:08:31,536 INFO     Training average negative_sample_loss at step 406000: 0.176263\n",
      "2022-11-08 17:08:31,536 INFO     Training average loss at step 406000: 0.199029\n",
      "2022-11-08 17:08:41,308 INFO     Training average positive_sample_loss at step 406100: 0.211562\n",
      "2022-11-08 17:08:41,308 INFO     Training average negative_sample_loss at step 406100: 0.174503\n",
      "2022-11-08 17:08:41,308 INFO     Training average loss at step 406100: 0.193033\n",
      "2022-11-08 17:08:51,069 INFO     Training average positive_sample_loss at step 406200: 0.217622\n",
      "2022-11-08 17:08:51,069 INFO     Training average negative_sample_loss at step 406200: 0.174616\n",
      "2022-11-08 17:08:51,069 INFO     Training average loss at step 406200: 0.196119\n",
      "2022-11-08 17:09:00,971 INFO     Training average positive_sample_loss at step 406300: 0.217732\n",
      "2022-11-08 17:09:00,971 INFO     Training average negative_sample_loss at step 406300: 0.176115\n",
      "2022-11-08 17:09:00,971 INFO     Training average loss at step 406300: 0.196923\n",
      "2022-11-08 17:09:10,136 INFO     Training average positive_sample_loss at step 406400: 0.215549\n",
      "2022-11-08 17:09:10,136 INFO     Training average negative_sample_loss at step 406400: 0.172653\n",
      "2022-11-08 17:09:10,136 INFO     Training average loss at step 406400: 0.194101\n",
      "2022-11-08 17:09:20,028 INFO     Training average positive_sample_loss at step 406500: 0.223686\n",
      "2022-11-08 17:09:20,028 INFO     Training average negative_sample_loss at step 406500: 0.175682\n",
      "2022-11-08 17:09:20,028 INFO     Training average loss at step 406500: 0.199684\n",
      "2022-11-08 17:09:30,089 INFO     Training average positive_sample_loss at step 406600: 0.221504\n",
      "2022-11-08 17:09:30,089 INFO     Training average negative_sample_loss at step 406600: 0.175192\n",
      "2022-11-08 17:09:30,089 INFO     Training average loss at step 406600: 0.198348\n",
      "2022-11-08 17:09:40,153 INFO     Training average positive_sample_loss at step 406700: 0.224564\n",
      "2022-11-08 17:09:40,153 INFO     Training average negative_sample_loss at step 406700: 0.176443\n",
      "2022-11-08 17:09:40,153 INFO     Training average loss at step 406700: 0.200503\n",
      "2022-11-08 17:09:50,009 INFO     Training average positive_sample_loss at step 406800: 0.218447\n",
      "2022-11-08 17:09:50,009 INFO     Training average negative_sample_loss at step 406800: 0.171772\n",
      "2022-11-08 17:09:50,009 INFO     Training average loss at step 406800: 0.195109\n",
      "2022-11-08 17:09:59,800 INFO     Training average positive_sample_loss at step 406900: 0.212745\n",
      "2022-11-08 17:09:59,800 INFO     Training average negative_sample_loss at step 406900: 0.177081\n",
      "2022-11-08 17:09:59,800 INFO     Training average loss at step 406900: 0.194913\n",
      "2022-11-08 17:10:09,059 INFO     Training average positive_sample_loss at step 407000: 0.219118\n",
      "2022-11-08 17:10:09,059 INFO     Training average negative_sample_loss at step 407000: 0.178220\n",
      "2022-11-08 17:10:09,059 INFO     Training average loss at step 407000: 0.198669\n",
      "2022-11-08 17:10:18,831 INFO     Training average positive_sample_loss at step 407100: 0.218010\n",
      "2022-11-08 17:10:18,831 INFO     Training average negative_sample_loss at step 407100: 0.175992\n",
      "2022-11-08 17:10:18,831 INFO     Training average loss at step 407100: 0.197001\n",
      "2022-11-08 17:10:28,720 INFO     Training average positive_sample_loss at step 407200: 0.220385\n",
      "2022-11-08 17:10:28,721 INFO     Training average negative_sample_loss at step 407200: 0.173998\n",
      "2022-11-08 17:10:28,721 INFO     Training average loss at step 407200: 0.197191\n",
      "2022-11-08 17:10:38,561 INFO     Training average positive_sample_loss at step 407300: 0.222018\n",
      "2022-11-08 17:10:38,561 INFO     Training average negative_sample_loss at step 407300: 0.175622\n",
      "2022-11-08 17:10:38,561 INFO     Training average loss at step 407300: 0.198820\n",
      "2022-11-08 17:10:48,460 INFO     Training average positive_sample_loss at step 407400: 0.228164\n",
      "2022-11-08 17:10:48,461 INFO     Training average negative_sample_loss at step 407400: 0.174774\n",
      "2022-11-08 17:10:48,461 INFO     Training average loss at step 407400: 0.201469\n",
      "2022-11-08 17:10:58,364 INFO     Training average positive_sample_loss at step 407500: 0.216927\n",
      "2022-11-08 17:10:58,365 INFO     Training average negative_sample_loss at step 407500: 0.180280\n",
      "2022-11-08 17:10:58,365 INFO     Training average loss at step 407500: 0.198603\n",
      "2022-11-08 17:11:08,214 INFO     Training average positive_sample_loss at step 407600: 0.221900\n",
      "2022-11-08 17:11:08,214 INFO     Training average negative_sample_loss at step 407600: 0.176094\n",
      "2022-11-08 17:11:08,214 INFO     Training average loss at step 407600: 0.198997\n",
      "2022-11-08 17:11:18,047 INFO     Training average positive_sample_loss at step 407700: 0.225544\n",
      "2022-11-08 17:11:18,047 INFO     Training average negative_sample_loss at step 407700: 0.176208\n",
      "2022-11-08 17:11:18,047 INFO     Training average loss at step 407700: 0.200876\n",
      "2022-11-08 17:11:27,843 INFO     Training average positive_sample_loss at step 407800: 0.229009\n",
      "2022-11-08 17:11:27,843 INFO     Training average negative_sample_loss at step 407800: 0.178376\n",
      "2022-11-08 17:11:27,843 INFO     Training average loss at step 407800: 0.203692\n",
      "2022-11-08 17:11:37,545 INFO     Training average positive_sample_loss at step 407900: 0.216645\n",
      "2022-11-08 17:11:37,545 INFO     Training average negative_sample_loss at step 407900: 0.170771\n",
      "2022-11-08 17:11:37,545 INFO     Training average loss at step 407900: 0.193708\n",
      "2022-11-08 17:11:47,341 INFO     Training average positive_sample_loss at step 408000: 0.214372\n",
      "2022-11-08 17:11:47,342 INFO     Training average negative_sample_loss at step 408000: 0.173560\n",
      "2022-11-08 17:11:47,342 INFO     Training average loss at step 408000: 0.193966\n",
      "2022-11-08 17:11:57,191 INFO     Training average positive_sample_loss at step 408100: 0.223453\n",
      "2022-11-08 17:11:57,191 INFO     Training average negative_sample_loss at step 408100: 0.176696\n",
      "2022-11-08 17:11:57,191 INFO     Training average loss at step 408100: 0.200075\n",
      "2022-11-08 17:12:06,951 INFO     Training average positive_sample_loss at step 408200: 0.225101\n",
      "2022-11-08 17:12:06,951 INFO     Training average negative_sample_loss at step 408200: 0.170723\n",
      "2022-11-08 17:12:06,951 INFO     Training average loss at step 408200: 0.197912\n",
      "2022-11-08 17:12:16,672 INFO     Training average positive_sample_loss at step 408300: 0.225417\n",
      "2022-11-08 17:12:16,672 INFO     Training average negative_sample_loss at step 408300: 0.176665\n",
      "2022-11-08 17:12:16,672 INFO     Training average loss at step 408300: 0.201041\n",
      "2022-11-08 17:12:26,410 INFO     Training average positive_sample_loss at step 408400: 0.218351\n",
      "2022-11-08 17:12:26,411 INFO     Training average negative_sample_loss at step 408400: 0.171775\n",
      "2022-11-08 17:12:26,411 INFO     Training average loss at step 408400: 0.195063\n",
      "2022-11-08 17:12:36,114 INFO     Training average positive_sample_loss at step 408500: 0.217055\n",
      "2022-11-08 17:12:36,114 INFO     Training average negative_sample_loss at step 408500: 0.172650\n",
      "2022-11-08 17:12:36,114 INFO     Training average loss at step 408500: 0.194853\n",
      "2022-11-08 17:12:45,848 INFO     Training average positive_sample_loss at step 408600: 0.220560\n",
      "2022-11-08 17:12:45,848 INFO     Training average negative_sample_loss at step 408600: 0.175630\n",
      "2022-11-08 17:12:45,848 INFO     Training average loss at step 408600: 0.198095\n",
      "2022-11-08 17:12:55,810 INFO     Training average positive_sample_loss at step 408700: 0.220276\n",
      "2022-11-08 17:12:55,810 INFO     Training average negative_sample_loss at step 408700: 0.177309\n",
      "2022-11-08 17:12:55,810 INFO     Training average loss at step 408700: 0.198793\n",
      "2022-11-08 17:13:05,664 INFO     Training average positive_sample_loss at step 408800: 0.214833\n",
      "2022-11-08 17:13:05,665 INFO     Training average negative_sample_loss at step 408800: 0.173410\n",
      "2022-11-08 17:13:05,665 INFO     Training average loss at step 408800: 0.194121\n",
      "2022-11-08 17:13:15,403 INFO     Training average positive_sample_loss at step 408900: 0.215427\n",
      "2022-11-08 17:13:15,403 INFO     Training average negative_sample_loss at step 408900: 0.173204\n",
      "2022-11-08 17:13:15,403 INFO     Training average loss at step 408900: 0.194316\n",
      "2022-11-08 17:13:25,088 INFO     Training average positive_sample_loss at step 409000: 0.225788\n",
      "2022-11-08 17:13:25,088 INFO     Training average negative_sample_loss at step 409000: 0.171616\n",
      "2022-11-08 17:13:25,088 INFO     Training average loss at step 409000: 0.198702\n",
      "2022-11-08 17:13:34,830 INFO     Training average positive_sample_loss at step 409100: 0.225383\n",
      "2022-11-08 17:13:34,830 INFO     Training average negative_sample_loss at step 409100: 0.175340\n",
      "2022-11-08 17:13:34,830 INFO     Training average loss at step 409100: 0.200362\n",
      "2022-11-08 17:13:44,608 INFO     Training average positive_sample_loss at step 409200: 0.220692\n",
      "2022-11-08 17:13:44,608 INFO     Training average negative_sample_loss at step 409200: 0.180742\n",
      "2022-11-08 17:13:44,608 INFO     Training average loss at step 409200: 0.200717\n",
      "2022-11-08 17:13:54,299 INFO     Training average positive_sample_loss at step 409300: 0.237984\n",
      "2022-11-08 17:13:54,299 INFO     Training average negative_sample_loss at step 409300: 0.173116\n",
      "2022-11-08 17:13:54,299 INFO     Training average loss at step 409300: 0.205550\n",
      "2022-11-08 17:14:04,013 INFO     Training average positive_sample_loss at step 409400: 0.224967\n",
      "2022-11-08 17:14:04,013 INFO     Training average negative_sample_loss at step 409400: 0.175921\n",
      "2022-11-08 17:14:04,013 INFO     Training average loss at step 409400: 0.200444\n",
      "2022-11-08 17:14:13,678 INFO     Training average positive_sample_loss at step 409500: 0.224653\n",
      "2022-11-08 17:14:13,678 INFO     Training average negative_sample_loss at step 409500: 0.177468\n",
      "2022-11-08 17:14:13,678 INFO     Training average loss at step 409500: 0.201060\n",
      "2022-11-08 17:14:23,384 INFO     Training average positive_sample_loss at step 409600: 0.209951\n",
      "2022-11-08 17:14:23,384 INFO     Training average negative_sample_loss at step 409600: 0.177026\n",
      "2022-11-08 17:14:23,384 INFO     Training average loss at step 409600: 0.193488\n",
      "2022-11-08 17:14:33,047 INFO     Training average positive_sample_loss at step 409700: 0.225901\n",
      "2022-11-08 17:14:33,047 INFO     Training average negative_sample_loss at step 409700: 0.173759\n",
      "2022-11-08 17:14:33,047 INFO     Training average loss at step 409700: 0.199830\n",
      "2022-11-08 17:14:42,744 INFO     Training average positive_sample_loss at step 409800: 0.221413\n",
      "2022-11-08 17:14:42,744 INFO     Training average negative_sample_loss at step 409800: 0.174900\n",
      "2022-11-08 17:14:42,744 INFO     Training average loss at step 409800: 0.198157\n",
      "2022-11-08 17:14:52,459 INFO     Training average positive_sample_loss at step 409900: 0.233546\n",
      "2022-11-08 17:14:52,459 INFO     Training average negative_sample_loss at step 409900: 0.175518\n",
      "2022-11-08 17:14:52,459 INFO     Training average loss at step 409900: 0.204532\n",
      "2022-11-08 17:15:05,080 INFO     Training average positive_sample_loss at step 410000: 0.218757\n",
      "2022-11-08 17:15:05,080 INFO     Training average negative_sample_loss at step 410000: 0.173739\n",
      "2022-11-08 17:15:05,080 INFO     Training average loss at step 410000: 0.196248\n",
      "2022-11-08 17:15:14,889 INFO     Training average positive_sample_loss at step 410100: 0.222737\n",
      "2022-11-08 17:15:14,889 INFO     Training average negative_sample_loss at step 410100: 0.176411\n",
      "2022-11-08 17:15:14,889 INFO     Training average loss at step 410100: 0.199574\n",
      "2022-11-08 17:15:24,653 INFO     Training average positive_sample_loss at step 410200: 0.221696\n",
      "2022-11-08 17:15:24,653 INFO     Training average negative_sample_loss at step 410200: 0.177344\n",
      "2022-11-08 17:15:24,653 INFO     Training average loss at step 410200: 0.199520\n",
      "2022-11-08 17:15:34,613 INFO     Training average positive_sample_loss at step 410300: 0.229866\n",
      "2022-11-08 17:15:34,613 INFO     Training average negative_sample_loss at step 410300: 0.175201\n",
      "2022-11-08 17:15:34,613 INFO     Training average loss at step 410300: 0.202534\n",
      "2022-11-08 17:15:44,572 INFO     Training average positive_sample_loss at step 410400: 0.224956\n",
      "2022-11-08 17:15:44,572 INFO     Training average negative_sample_loss at step 410400: 0.176504\n",
      "2022-11-08 17:15:44,572 INFO     Training average loss at step 410400: 0.200730\n",
      "2022-11-08 17:15:54,355 INFO     Training average positive_sample_loss at step 410500: 0.219336\n",
      "2022-11-08 17:15:54,355 INFO     Training average negative_sample_loss at step 410500: 0.176347\n",
      "2022-11-08 17:15:54,355 INFO     Training average loss at step 410500: 0.197842\n",
      "2022-11-08 17:16:06,823 INFO     Training average positive_sample_loss at step 410600: 0.217523\n",
      "2022-11-08 17:16:06,823 INFO     Training average negative_sample_loss at step 410600: 0.175954\n",
      "2022-11-08 17:16:06,823 INFO     Training average loss at step 410600: 0.196738\n",
      "2022-11-08 17:16:16,553 INFO     Training average positive_sample_loss at step 410700: 0.226136\n",
      "2022-11-08 17:16:16,553 INFO     Training average negative_sample_loss at step 410700: 0.173838\n",
      "2022-11-08 17:16:16,553 INFO     Training average loss at step 410700: 0.199987\n",
      "2022-11-08 17:16:26,219 INFO     Training average positive_sample_loss at step 410800: 0.216177\n",
      "2022-11-08 17:16:26,219 INFO     Training average negative_sample_loss at step 410800: 0.173842\n",
      "2022-11-08 17:16:26,219 INFO     Training average loss at step 410800: 0.195009\n",
      "2022-11-08 17:16:35,998 INFO     Training average positive_sample_loss at step 410900: 0.216874\n",
      "2022-11-08 17:16:35,998 INFO     Training average negative_sample_loss at step 410900: 0.174629\n",
      "2022-11-08 17:16:35,998 INFO     Training average loss at step 410900: 0.195751\n",
      "2022-11-08 17:16:45,816 INFO     Training average positive_sample_loss at step 411000: 0.218757\n",
      "2022-11-08 17:16:45,816 INFO     Training average negative_sample_loss at step 411000: 0.171957\n",
      "2022-11-08 17:16:45,816 INFO     Training average loss at step 411000: 0.195357\n",
      "2022-11-08 17:16:55,585 INFO     Training average positive_sample_loss at step 411100: 0.229930\n",
      "2022-11-08 17:16:55,585 INFO     Training average negative_sample_loss at step 411100: 0.177884\n",
      "2022-11-08 17:16:55,585 INFO     Training average loss at step 411100: 0.203907\n",
      "2022-11-08 17:17:05,342 INFO     Training average positive_sample_loss at step 411200: 0.235465\n",
      "2022-11-08 17:17:05,343 INFO     Training average negative_sample_loss at step 411200: 0.176141\n",
      "2022-11-08 17:17:05,343 INFO     Training average loss at step 411200: 0.205803\n",
      "2022-11-08 17:17:15,096 INFO     Training average positive_sample_loss at step 411300: 0.224804\n",
      "2022-11-08 17:17:15,096 INFO     Training average negative_sample_loss at step 411300: 0.171744\n",
      "2022-11-08 17:17:15,096 INFO     Training average loss at step 411300: 0.198274\n",
      "2022-11-08 17:17:24,771 INFO     Training average positive_sample_loss at step 411400: 0.222083\n",
      "2022-11-08 17:17:24,771 INFO     Training average negative_sample_loss at step 411400: 0.176136\n",
      "2022-11-08 17:17:24,771 INFO     Training average loss at step 411400: 0.199109\n",
      "2022-11-08 17:17:34,448 INFO     Training average positive_sample_loss at step 411500: 0.218997\n",
      "2022-11-08 17:17:34,448 INFO     Training average negative_sample_loss at step 411500: 0.179792\n",
      "2022-11-08 17:17:34,448 INFO     Training average loss at step 411500: 0.199394\n",
      "2022-11-08 17:17:44,179 INFO     Training average positive_sample_loss at step 411600: 0.220765\n",
      "2022-11-08 17:17:44,179 INFO     Training average negative_sample_loss at step 411600: 0.176022\n",
      "2022-11-08 17:17:44,179 INFO     Training average loss at step 411600: 0.198394\n",
      "2022-11-08 17:17:53,940 INFO     Training average positive_sample_loss at step 411700: 0.228338\n",
      "2022-11-08 17:17:53,940 INFO     Training average negative_sample_loss at step 411700: 0.172506\n",
      "2022-11-08 17:17:53,940 INFO     Training average loss at step 411700: 0.200422\n",
      "2022-11-08 17:18:03,070 INFO     Training average positive_sample_loss at step 411800: 0.225052\n",
      "2022-11-08 17:18:03,070 INFO     Training average negative_sample_loss at step 411800: 0.175807\n",
      "2022-11-08 17:18:03,070 INFO     Training average loss at step 411800: 0.200429\n",
      "2022-11-08 17:18:12,838 INFO     Training average positive_sample_loss at step 411900: 0.235089\n",
      "2022-11-08 17:18:12,838 INFO     Training average negative_sample_loss at step 411900: 0.175275\n",
      "2022-11-08 17:18:12,839 INFO     Training average loss at step 411900: 0.205182\n",
      "2022-11-08 17:18:22,552 INFO     Training average positive_sample_loss at step 412000: 0.225506\n",
      "2022-11-08 17:18:22,552 INFO     Training average negative_sample_loss at step 412000: 0.172897\n",
      "2022-11-08 17:18:22,552 INFO     Training average loss at step 412000: 0.199201\n",
      "2022-11-08 17:18:32,220 INFO     Training average positive_sample_loss at step 412100: 0.226728\n",
      "2022-11-08 17:18:32,220 INFO     Training average negative_sample_loss at step 412100: 0.174895\n",
      "2022-11-08 17:18:32,220 INFO     Training average loss at step 412100: 0.200812\n",
      "2022-11-08 17:18:41,888 INFO     Training average positive_sample_loss at step 412200: 0.229433\n",
      "2022-11-08 17:18:41,888 INFO     Training average negative_sample_loss at step 412200: 0.180854\n",
      "2022-11-08 17:18:41,888 INFO     Training average loss at step 412200: 0.205144\n",
      "2022-11-08 17:18:51,655 INFO     Training average positive_sample_loss at step 412300: 0.217199\n",
      "2022-11-08 17:18:51,656 INFO     Training average negative_sample_loss at step 412300: 0.178415\n",
      "2022-11-08 17:18:51,656 INFO     Training average loss at step 412300: 0.197807\n",
      "2022-11-08 17:19:00,781 INFO     Training average positive_sample_loss at step 412400: 0.226600\n",
      "2022-11-08 17:19:00,781 INFO     Training average negative_sample_loss at step 412400: 0.180200\n",
      "2022-11-08 17:19:00,781 INFO     Training average loss at step 412400: 0.203400\n",
      "2022-11-08 17:19:10,494 INFO     Training average positive_sample_loss at step 412500: 0.222853\n",
      "2022-11-08 17:19:10,494 INFO     Training average negative_sample_loss at step 412500: 0.183824\n",
      "2022-11-08 17:19:10,494 INFO     Training average loss at step 412500: 0.203338\n",
      "2022-11-08 17:19:20,212 INFO     Training average positive_sample_loss at step 412600: 0.223200\n",
      "2022-11-08 17:19:20,212 INFO     Training average negative_sample_loss at step 412600: 0.171745\n",
      "2022-11-08 17:19:20,212 INFO     Training average loss at step 412600: 0.197473\n",
      "2022-11-08 17:19:29,929 INFO     Training average positive_sample_loss at step 412700: 0.222998\n",
      "2022-11-08 17:19:29,929 INFO     Training average negative_sample_loss at step 412700: 0.174411\n",
      "2022-11-08 17:19:29,929 INFO     Training average loss at step 412700: 0.198705\n",
      "2022-11-08 17:19:39,714 INFO     Training average positive_sample_loss at step 412800: 0.228088\n",
      "2022-11-08 17:19:39,714 INFO     Training average negative_sample_loss at step 412800: 0.176787\n",
      "2022-11-08 17:19:39,714 INFO     Training average loss at step 412800: 0.202438\n",
      "2022-11-08 17:19:49,578 INFO     Training average positive_sample_loss at step 412900: 0.226126\n",
      "2022-11-08 17:19:49,578 INFO     Training average negative_sample_loss at step 412900: 0.177349\n",
      "2022-11-08 17:19:49,578 INFO     Training average loss at step 412900: 0.201737\n",
      "2022-11-08 17:19:59,389 INFO     Training average positive_sample_loss at step 413000: 0.227250\n",
      "2022-11-08 17:19:59,389 INFO     Training average negative_sample_loss at step 413000: 0.174763\n",
      "2022-11-08 17:19:59,389 INFO     Training average loss at step 413000: 0.201006\n",
      "2022-11-08 17:20:09,203 INFO     Training average positive_sample_loss at step 413100: 0.220506\n",
      "2022-11-08 17:20:09,203 INFO     Training average negative_sample_loss at step 413100: 0.172213\n",
      "2022-11-08 17:20:09,203 INFO     Training average loss at step 413100: 0.196360\n",
      "2022-11-08 17:20:19,089 INFO     Training average positive_sample_loss at step 413200: 0.233813\n",
      "2022-11-08 17:20:19,089 INFO     Training average negative_sample_loss at step 413200: 0.173996\n",
      "2022-11-08 17:20:19,089 INFO     Training average loss at step 413200: 0.203905\n",
      "2022-11-08 17:20:29,179 INFO     Training average positive_sample_loss at step 413300: 0.221247\n",
      "2022-11-08 17:20:29,180 INFO     Training average negative_sample_loss at step 413300: 0.171606\n",
      "2022-11-08 17:20:29,180 INFO     Training average loss at step 413300: 0.196426\n",
      "2022-11-08 17:20:39,133 INFO     Training average positive_sample_loss at step 413400: 0.222812\n",
      "2022-11-08 17:20:39,133 INFO     Training average negative_sample_loss at step 413400: 0.173588\n",
      "2022-11-08 17:20:39,133 INFO     Training average loss at step 413400: 0.198200\n",
      "2022-11-08 17:20:48,933 INFO     Training average positive_sample_loss at step 413500: 0.239004\n",
      "2022-11-08 17:20:48,933 INFO     Training average negative_sample_loss at step 413500: 0.178001\n",
      "2022-11-08 17:20:48,933 INFO     Training average loss at step 413500: 0.208502\n",
      "2022-11-08 17:20:58,663 INFO     Training average positive_sample_loss at step 413600: 0.228340\n",
      "2022-11-08 17:20:58,664 INFO     Training average negative_sample_loss at step 413600: 0.174615\n",
      "2022-11-08 17:20:58,664 INFO     Training average loss at step 413600: 0.201477\n",
      "2022-11-08 17:21:08,514 INFO     Training average positive_sample_loss at step 413700: 0.227489\n",
      "2022-11-08 17:21:08,515 INFO     Training average negative_sample_loss at step 413700: 0.177315\n",
      "2022-11-08 17:21:08,515 INFO     Training average loss at step 413700: 0.202402\n",
      "2022-11-08 17:21:18,301 INFO     Training average positive_sample_loss at step 413800: 0.229392\n",
      "2022-11-08 17:21:18,301 INFO     Training average negative_sample_loss at step 413800: 0.167339\n",
      "2022-11-08 17:21:18,301 INFO     Training average loss at step 413800: 0.198366\n",
      "2022-11-08 17:21:28,185 INFO     Training average positive_sample_loss at step 413900: 0.222685\n",
      "2022-11-08 17:21:28,185 INFO     Training average negative_sample_loss at step 413900: 0.173065\n",
      "2022-11-08 17:21:28,186 INFO     Training average loss at step 413900: 0.197875\n",
      "2022-11-08 17:21:37,925 INFO     Training average positive_sample_loss at step 414000: 0.228993\n",
      "2022-11-08 17:21:37,925 INFO     Training average negative_sample_loss at step 414000: 0.176122\n",
      "2022-11-08 17:21:37,925 INFO     Training average loss at step 414000: 0.202557\n",
      "2022-11-08 17:21:47,730 INFO     Training average positive_sample_loss at step 414100: 0.230083\n",
      "2022-11-08 17:21:47,730 INFO     Training average negative_sample_loss at step 414100: 0.174693\n",
      "2022-11-08 17:21:47,730 INFO     Training average loss at step 414100: 0.202388\n",
      "2022-11-08 17:21:57,481 INFO     Training average positive_sample_loss at step 414200: 0.229917\n",
      "2022-11-08 17:21:57,481 INFO     Training average negative_sample_loss at step 414200: 0.172135\n",
      "2022-11-08 17:21:57,481 INFO     Training average loss at step 414200: 0.201026\n",
      "2022-11-08 17:22:07,288 INFO     Training average positive_sample_loss at step 414300: 0.219395\n",
      "2022-11-08 17:22:07,288 INFO     Training average negative_sample_loss at step 414300: 0.174027\n",
      "2022-11-08 17:22:07,288 INFO     Training average loss at step 414300: 0.196711\n",
      "2022-11-08 17:22:17,079 INFO     Training average positive_sample_loss at step 414400: 0.215563\n",
      "2022-11-08 17:22:17,080 INFO     Training average negative_sample_loss at step 414400: 0.174031\n",
      "2022-11-08 17:22:17,080 INFO     Training average loss at step 414400: 0.194797\n",
      "2022-11-08 17:22:26,965 INFO     Training average positive_sample_loss at step 414500: 0.226224\n",
      "2022-11-08 17:22:26,965 INFO     Training average negative_sample_loss at step 414500: 0.173742\n",
      "2022-11-08 17:22:26,965 INFO     Training average loss at step 414500: 0.199983\n",
      "2022-11-08 17:22:36,868 INFO     Training average positive_sample_loss at step 414600: 0.214173\n",
      "2022-11-08 17:22:36,868 INFO     Training average negative_sample_loss at step 414600: 0.177640\n",
      "2022-11-08 17:22:36,868 INFO     Training average loss at step 414600: 0.195907\n",
      "2022-11-08 17:22:46,713 INFO     Training average positive_sample_loss at step 414700: 0.223012\n",
      "2022-11-08 17:22:46,713 INFO     Training average negative_sample_loss at step 414700: 0.177030\n",
      "2022-11-08 17:22:46,713 INFO     Training average loss at step 414700: 0.200021\n",
      "2022-11-08 17:22:56,488 INFO     Training average positive_sample_loss at step 414800: 0.228950\n",
      "2022-11-08 17:22:56,488 INFO     Training average negative_sample_loss at step 414800: 0.179679\n",
      "2022-11-08 17:22:56,488 INFO     Training average loss at step 414800: 0.204314\n",
      "2022-11-08 17:23:06,330 INFO     Training average positive_sample_loss at step 414900: 0.230676\n",
      "2022-11-08 17:23:06,330 INFO     Training average negative_sample_loss at step 414900: 0.173881\n",
      "2022-11-08 17:23:06,330 INFO     Training average loss at step 414900: 0.202279\n",
      "2022-11-08 17:23:16,120 INFO     Training average positive_sample_loss at step 415000: 0.227132\n",
      "2022-11-08 17:23:16,120 INFO     Training average negative_sample_loss at step 415000: 0.176502\n",
      "2022-11-08 17:23:16,120 INFO     Training average loss at step 415000: 0.201817\n",
      "2022-11-08 17:23:25,879 INFO     Training average positive_sample_loss at step 415100: 0.219174\n",
      "2022-11-08 17:23:25,879 INFO     Training average negative_sample_loss at step 415100: 0.178624\n",
      "2022-11-08 17:23:25,879 INFO     Training average loss at step 415100: 0.198899\n",
      "2022-11-08 17:23:35,756 INFO     Training average positive_sample_loss at step 415200: 0.223948\n",
      "2022-11-08 17:23:35,756 INFO     Training average negative_sample_loss at step 415200: 0.176670\n",
      "2022-11-08 17:23:35,756 INFO     Training average loss at step 415200: 0.200309\n",
      "2022-11-08 17:23:48,505 INFO     Training average positive_sample_loss at step 415300: 0.234887\n",
      "2022-11-08 17:23:48,506 INFO     Training average negative_sample_loss at step 415300: 0.178409\n",
      "2022-11-08 17:23:48,506 INFO     Training average loss at step 415300: 0.206648\n",
      "2022-11-08 17:23:58,235 INFO     Training average positive_sample_loss at step 415400: 0.226941\n",
      "2022-11-08 17:23:58,235 INFO     Training average negative_sample_loss at step 415400: 0.176735\n",
      "2022-11-08 17:23:58,235 INFO     Training average loss at step 415400: 0.201838\n",
      "2022-11-08 17:24:07,993 INFO     Training average positive_sample_loss at step 415500: 0.229354\n",
      "2022-11-08 17:24:07,993 INFO     Training average negative_sample_loss at step 415500: 0.177084\n",
      "2022-11-08 17:24:07,993 INFO     Training average loss at step 415500: 0.203219\n",
      "2022-11-08 17:24:17,702 INFO     Training average positive_sample_loss at step 415600: 0.231451\n",
      "2022-11-08 17:24:17,703 INFO     Training average negative_sample_loss at step 415600: 0.176017\n",
      "2022-11-08 17:24:17,703 INFO     Training average loss at step 415600: 0.203734\n",
      "2022-11-08 17:24:27,388 INFO     Training average positive_sample_loss at step 415700: 0.236077\n",
      "2022-11-08 17:24:27,388 INFO     Training average negative_sample_loss at step 415700: 0.175189\n",
      "2022-11-08 17:24:27,388 INFO     Training average loss at step 415700: 0.205633\n",
      "2022-11-08 17:24:37,185 INFO     Training average positive_sample_loss at step 415800: 0.215901\n",
      "2022-11-08 17:24:37,185 INFO     Training average negative_sample_loss at step 415800: 0.178985\n",
      "2022-11-08 17:24:37,185 INFO     Training average loss at step 415800: 0.197443\n",
      "2022-11-08 17:24:46,897 INFO     Training average positive_sample_loss at step 415900: 0.235896\n",
      "2022-11-08 17:24:46,897 INFO     Training average negative_sample_loss at step 415900: 0.170261\n",
      "2022-11-08 17:24:46,897 INFO     Training average loss at step 415900: 0.203078\n",
      "2022-11-08 17:24:56,620 INFO     Training average positive_sample_loss at step 416000: 0.218568\n",
      "2022-11-08 17:24:56,620 INFO     Training average negative_sample_loss at step 416000: 0.174623\n",
      "2022-11-08 17:24:56,620 INFO     Training average loss at step 416000: 0.196595\n",
      "2022-11-08 17:25:06,433 INFO     Training average positive_sample_loss at step 416100: 0.236733\n",
      "2022-11-08 17:25:06,433 INFO     Training average negative_sample_loss at step 416100: 0.173625\n",
      "2022-11-08 17:25:06,434 INFO     Training average loss at step 416100: 0.205179\n",
      "2022-11-08 17:25:16,129 INFO     Training average positive_sample_loss at step 416200: 0.221736\n",
      "2022-11-08 17:25:16,129 INFO     Training average negative_sample_loss at step 416200: 0.172371\n",
      "2022-11-08 17:25:16,129 INFO     Training average loss at step 416200: 0.197053\n",
      "2022-11-08 17:25:25,826 INFO     Training average positive_sample_loss at step 416300: 0.224730\n",
      "2022-11-08 17:25:25,827 INFO     Training average negative_sample_loss at step 416300: 0.177506\n",
      "2022-11-08 17:25:25,827 INFO     Training average loss at step 416300: 0.201118\n",
      "2022-11-08 17:25:35,548 INFO     Training average positive_sample_loss at step 416400: 0.223738\n",
      "2022-11-08 17:25:35,548 INFO     Training average negative_sample_loss at step 416400: 0.173789\n",
      "2022-11-08 17:25:35,548 INFO     Training average loss at step 416400: 0.198764\n",
      "2022-11-08 17:25:45,233 INFO     Training average positive_sample_loss at step 416500: 0.220805\n",
      "2022-11-08 17:25:45,233 INFO     Training average negative_sample_loss at step 416500: 0.173366\n",
      "2022-11-08 17:25:45,233 INFO     Training average loss at step 416500: 0.197085\n",
      "2022-11-08 17:25:54,972 INFO     Training average positive_sample_loss at step 416600: 0.229188\n",
      "2022-11-08 17:25:54,973 INFO     Training average negative_sample_loss at step 416600: 0.179219\n",
      "2022-11-08 17:25:54,973 INFO     Training average loss at step 416600: 0.204204\n",
      "2022-11-08 17:26:04,656 INFO     Training average positive_sample_loss at step 416700: 0.223580\n",
      "2022-11-08 17:26:04,656 INFO     Training average negative_sample_loss at step 416700: 0.173883\n",
      "2022-11-08 17:26:04,656 INFO     Training average loss at step 416700: 0.198731\n",
      "2022-11-08 17:26:14,433 INFO     Training average positive_sample_loss at step 416800: 0.223566\n",
      "2022-11-08 17:26:14,433 INFO     Training average negative_sample_loss at step 416800: 0.173894\n",
      "2022-11-08 17:26:14,433 INFO     Training average loss at step 416800: 0.198730\n",
      "2022-11-08 17:26:24,211 INFO     Training average positive_sample_loss at step 416900: 0.229633\n",
      "2022-11-08 17:26:24,211 INFO     Training average negative_sample_loss at step 416900: 0.172566\n",
      "2022-11-08 17:26:24,211 INFO     Training average loss at step 416900: 0.201100\n",
      "2022-11-08 17:26:33,874 INFO     Training average positive_sample_loss at step 417000: 0.230868\n",
      "2022-11-08 17:26:33,874 INFO     Training average negative_sample_loss at step 417000: 0.175469\n",
      "2022-11-08 17:26:33,874 INFO     Training average loss at step 417000: 0.203169\n",
      "2022-11-08 17:26:43,545 INFO     Training average positive_sample_loss at step 417100: 0.223518\n",
      "2022-11-08 17:26:43,545 INFO     Training average negative_sample_loss at step 417100: 0.172814\n",
      "2022-11-08 17:26:43,545 INFO     Training average loss at step 417100: 0.198166\n",
      "2022-11-08 17:26:53,233 INFO     Training average positive_sample_loss at step 417200: 0.222759\n",
      "2022-11-08 17:26:53,233 INFO     Training average negative_sample_loss at step 417200: 0.174650\n",
      "2022-11-08 17:26:53,233 INFO     Training average loss at step 417200: 0.198704\n",
      "2022-11-08 17:27:02,200 INFO     Training average positive_sample_loss at step 417300: 0.216703\n",
      "2022-11-08 17:27:02,200 INFO     Training average negative_sample_loss at step 417300: 0.172467\n",
      "2022-11-08 17:27:02,200 INFO     Training average loss at step 417300: 0.194585\n",
      "2022-11-08 17:27:11,863 INFO     Training average positive_sample_loss at step 417400: 0.227659\n",
      "2022-11-08 17:27:11,863 INFO     Training average negative_sample_loss at step 417400: 0.175041\n",
      "2022-11-08 17:27:11,863 INFO     Training average loss at step 417400: 0.201350\n",
      "2022-11-08 17:27:21,527 INFO     Training average positive_sample_loss at step 417500: 0.217656\n",
      "2022-11-08 17:27:21,527 INFO     Training average negative_sample_loss at step 417500: 0.179758\n",
      "2022-11-08 17:27:21,527 INFO     Training average loss at step 417500: 0.198707\n",
      "2022-11-08 17:27:31,230 INFO     Training average positive_sample_loss at step 417600: 0.222847\n",
      "2022-11-08 17:27:31,230 INFO     Training average negative_sample_loss at step 417600: 0.175638\n",
      "2022-11-08 17:27:31,230 INFO     Training average loss at step 417600: 0.199243\n",
      "2022-11-08 17:27:40,948 INFO     Training average positive_sample_loss at step 417700: 0.219795\n",
      "2022-11-08 17:27:40,948 INFO     Training average negative_sample_loss at step 417700: 0.175399\n",
      "2022-11-08 17:27:40,948 INFO     Training average loss at step 417700: 0.197597\n",
      "2022-11-08 17:27:50,719 INFO     Training average positive_sample_loss at step 417800: 0.227953\n",
      "2022-11-08 17:27:50,719 INFO     Training average negative_sample_loss at step 417800: 0.172502\n",
      "2022-11-08 17:27:50,719 INFO     Training average loss at step 417800: 0.200228\n",
      "2022-11-08 17:27:59,733 INFO     Training average positive_sample_loss at step 417900: 0.217735\n",
      "2022-11-08 17:27:59,733 INFO     Training average negative_sample_loss at step 417900: 0.175047\n",
      "2022-11-08 17:27:59,733 INFO     Training average loss at step 417900: 0.196391\n",
      "2022-11-08 17:28:09,425 INFO     Training average positive_sample_loss at step 418000: 0.224855\n",
      "2022-11-08 17:28:09,425 INFO     Training average negative_sample_loss at step 418000: 0.172839\n",
      "2022-11-08 17:28:09,425 INFO     Training average loss at step 418000: 0.198847\n",
      "2022-11-08 17:28:19,088 INFO     Training average positive_sample_loss at step 418100: 0.217114\n",
      "2022-11-08 17:28:19,088 INFO     Training average negative_sample_loss at step 418100: 0.176952\n",
      "2022-11-08 17:28:19,088 INFO     Training average loss at step 418100: 0.197033\n",
      "2022-11-08 17:28:28,773 INFO     Training average positive_sample_loss at step 418200: 0.225800\n",
      "2022-11-08 17:28:28,773 INFO     Training average negative_sample_loss at step 418200: 0.171525\n",
      "2022-11-08 17:28:28,773 INFO     Training average loss at step 418200: 0.198662\n",
      "2022-11-08 17:28:38,440 INFO     Training average positive_sample_loss at step 418300: 0.221768\n",
      "2022-11-08 17:28:38,440 INFO     Training average negative_sample_loss at step 418300: 0.177885\n",
      "2022-11-08 17:28:38,440 INFO     Training average loss at step 418300: 0.199827\n",
      "2022-11-08 17:28:48,106 INFO     Training average positive_sample_loss at step 418400: 0.234326\n",
      "2022-11-08 17:28:48,106 INFO     Training average negative_sample_loss at step 418400: 0.178331\n",
      "2022-11-08 17:28:48,106 INFO     Training average loss at step 418400: 0.206329\n",
      "2022-11-08 17:28:57,773 INFO     Training average positive_sample_loss at step 418500: 0.214802\n",
      "2022-11-08 17:28:57,773 INFO     Training average negative_sample_loss at step 418500: 0.176273\n",
      "2022-11-08 17:28:57,773 INFO     Training average loss at step 418500: 0.195538\n",
      "2022-11-08 17:29:07,434 INFO     Training average positive_sample_loss at step 418600: 0.219728\n",
      "2022-11-08 17:29:07,434 INFO     Training average negative_sample_loss at step 418600: 0.171731\n",
      "2022-11-08 17:29:07,434 INFO     Training average loss at step 418600: 0.195729\n",
      "2022-11-08 17:29:17,097 INFO     Training average positive_sample_loss at step 418700: 0.223745\n",
      "2022-11-08 17:29:17,097 INFO     Training average negative_sample_loss at step 418700: 0.175840\n",
      "2022-11-08 17:29:17,097 INFO     Training average loss at step 418700: 0.199792\n",
      "2022-11-08 17:29:26,761 INFO     Training average positive_sample_loss at step 418800: 0.217840\n",
      "2022-11-08 17:29:26,761 INFO     Training average negative_sample_loss at step 418800: 0.173872\n",
      "2022-11-08 17:29:26,761 INFO     Training average loss at step 418800: 0.195856\n",
      "2022-11-08 17:29:36,425 INFO     Training average positive_sample_loss at step 418900: 0.227493\n",
      "2022-11-08 17:29:36,425 INFO     Training average negative_sample_loss at step 418900: 0.174760\n",
      "2022-11-08 17:29:36,425 INFO     Training average loss at step 418900: 0.201127\n",
      "2022-11-08 17:29:46,107 INFO     Training average positive_sample_loss at step 419000: 0.235996\n",
      "2022-11-08 17:29:46,107 INFO     Training average negative_sample_loss at step 419000: 0.177581\n",
      "2022-11-08 17:29:46,107 INFO     Training average loss at step 419000: 0.206789\n",
      "2022-11-08 17:29:55,771 INFO     Training average positive_sample_loss at step 419100: 0.220097\n",
      "2022-11-08 17:29:55,771 INFO     Training average negative_sample_loss at step 419100: 0.178267\n",
      "2022-11-08 17:29:55,771 INFO     Training average loss at step 419100: 0.199182\n",
      "2022-11-08 17:30:05,433 INFO     Training average positive_sample_loss at step 419200: 0.227289\n",
      "2022-11-08 17:30:05,433 INFO     Training average negative_sample_loss at step 419200: 0.176308\n",
      "2022-11-08 17:30:05,433 INFO     Training average loss at step 419200: 0.201798\n",
      "2022-11-08 17:30:15,098 INFO     Training average positive_sample_loss at step 419300: 0.223700\n",
      "2022-11-08 17:30:15,098 INFO     Training average negative_sample_loss at step 419300: 0.172878\n",
      "2022-11-08 17:30:15,098 INFO     Training average loss at step 419300: 0.198289\n",
      "2022-11-08 17:30:24,764 INFO     Training average positive_sample_loss at step 419400: 0.228610\n",
      "2022-11-08 17:30:24,765 INFO     Training average negative_sample_loss at step 419400: 0.172000\n",
      "2022-11-08 17:30:24,765 INFO     Training average loss at step 419400: 0.200305\n",
      "2022-11-08 17:30:34,428 INFO     Training average positive_sample_loss at step 419500: 0.223224\n",
      "2022-11-08 17:30:34,428 INFO     Training average negative_sample_loss at step 419500: 0.177589\n",
      "2022-11-08 17:30:34,428 INFO     Training average loss at step 419500: 0.200407\n",
      "2022-11-08 17:30:44,169 INFO     Training average positive_sample_loss at step 419600: 0.218486\n",
      "2022-11-08 17:30:44,169 INFO     Training average negative_sample_loss at step 419600: 0.172037\n",
      "2022-11-08 17:30:44,169 INFO     Training average loss at step 419600: 0.195261\n",
      "2022-11-08 17:30:53,851 INFO     Training average positive_sample_loss at step 419700: 0.217147\n",
      "2022-11-08 17:30:53,851 INFO     Training average negative_sample_loss at step 419700: 0.176078\n",
      "2022-11-08 17:30:53,851 INFO     Training average loss at step 419700: 0.196612\n",
      "2022-11-08 17:31:03,513 INFO     Training average positive_sample_loss at step 419800: 0.227412\n",
      "2022-11-08 17:31:03,513 INFO     Training average negative_sample_loss at step 419800: 0.172559\n",
      "2022-11-08 17:31:03,513 INFO     Training average loss at step 419800: 0.199986\n",
      "2022-11-08 17:31:13,235 INFO     Training average positive_sample_loss at step 419900: 0.225199\n",
      "2022-11-08 17:31:13,235 INFO     Training average negative_sample_loss at step 419900: 0.176517\n",
      "2022-11-08 17:31:13,235 INFO     Training average loss at step 419900: 0.200858\n",
      "2022-11-08 17:31:28,591 INFO     Training average positive_sample_loss at step 420000: 0.227132\n",
      "2022-11-08 17:31:28,591 INFO     Training average negative_sample_loss at step 420000: 0.172211\n",
      "2022-11-08 17:31:28,591 INFO     Training average loss at step 420000: 0.199672\n",
      "2022-11-08 17:31:38,255 INFO     Training average positive_sample_loss at step 420100: 0.226126\n",
      "2022-11-08 17:31:38,255 INFO     Training average negative_sample_loss at step 420100: 0.171674\n",
      "2022-11-08 17:31:38,255 INFO     Training average loss at step 420100: 0.198900\n",
      "2022-11-08 17:31:47,949 INFO     Training average positive_sample_loss at step 420200: 0.224919\n",
      "2022-11-08 17:31:47,950 INFO     Training average negative_sample_loss at step 420200: 0.170089\n",
      "2022-11-08 17:31:47,950 INFO     Training average loss at step 420200: 0.197504\n",
      "2022-11-08 17:31:57,664 INFO     Training average positive_sample_loss at step 420300: 0.224399\n",
      "2022-11-08 17:31:57,664 INFO     Training average negative_sample_loss at step 420300: 0.170732\n",
      "2022-11-08 17:31:57,664 INFO     Training average loss at step 420300: 0.197566\n",
      "2022-11-08 17:32:07,343 INFO     Training average positive_sample_loss at step 420400: 0.219291\n",
      "2022-11-08 17:32:07,343 INFO     Training average negative_sample_loss at step 420400: 0.173523\n",
      "2022-11-08 17:32:07,343 INFO     Training average loss at step 420400: 0.196407\n",
      "2022-11-08 17:32:17,088 INFO     Training average positive_sample_loss at step 420500: 0.225255\n",
      "2022-11-08 17:32:17,088 INFO     Training average negative_sample_loss at step 420500: 0.175532\n",
      "2022-11-08 17:32:17,088 INFO     Training average loss at step 420500: 0.200393\n",
      "2022-11-08 17:32:26,775 INFO     Training average positive_sample_loss at step 420600: 0.223198\n",
      "2022-11-08 17:32:26,775 INFO     Training average negative_sample_loss at step 420600: 0.174015\n",
      "2022-11-08 17:32:26,775 INFO     Training average loss at step 420600: 0.198607\n",
      "2022-11-08 17:32:36,436 INFO     Training average positive_sample_loss at step 420700: 0.224662\n",
      "2022-11-08 17:32:36,436 INFO     Training average negative_sample_loss at step 420700: 0.176853\n",
      "2022-11-08 17:32:36,436 INFO     Training average loss at step 420700: 0.200757\n",
      "2022-11-08 17:32:46,141 INFO     Training average positive_sample_loss at step 420800: 0.231894\n",
      "2022-11-08 17:32:46,141 INFO     Training average negative_sample_loss at step 420800: 0.177128\n",
      "2022-11-08 17:32:46,141 INFO     Training average loss at step 420800: 0.204511\n",
      "2022-11-08 17:32:55,827 INFO     Training average positive_sample_loss at step 420900: 0.229659\n",
      "2022-11-08 17:32:55,828 INFO     Training average negative_sample_loss at step 420900: 0.173376\n",
      "2022-11-08 17:32:55,828 INFO     Training average loss at step 420900: 0.201518\n",
      "2022-11-08 17:33:05,514 INFO     Training average positive_sample_loss at step 421000: 0.225848\n",
      "2022-11-08 17:33:05,514 INFO     Training average negative_sample_loss at step 421000: 0.173604\n",
      "2022-11-08 17:33:05,514 INFO     Training average loss at step 421000: 0.199726\n",
      "2022-11-08 17:33:15,248 INFO     Training average positive_sample_loss at step 421100: 0.231359\n",
      "2022-11-08 17:33:15,248 INFO     Training average negative_sample_loss at step 421100: 0.173182\n",
      "2022-11-08 17:33:15,248 INFO     Training average loss at step 421100: 0.202270\n",
      "2022-11-08 17:33:24,979 INFO     Training average positive_sample_loss at step 421200: 0.221397\n",
      "2022-11-08 17:33:24,980 INFO     Training average negative_sample_loss at step 421200: 0.173105\n",
      "2022-11-08 17:33:24,980 INFO     Training average loss at step 421200: 0.197251\n",
      "2022-11-08 17:33:34,680 INFO     Training average positive_sample_loss at step 421300: 0.235130\n",
      "2022-11-08 17:33:34,680 INFO     Training average negative_sample_loss at step 421300: 0.175648\n",
      "2022-11-08 17:33:34,680 INFO     Training average loss at step 421300: 0.205389\n",
      "2022-11-08 17:33:44,380 INFO     Training average positive_sample_loss at step 421400: 0.220767\n",
      "2022-11-08 17:33:44,380 INFO     Training average negative_sample_loss at step 421400: 0.175952\n",
      "2022-11-08 17:33:44,380 INFO     Training average loss at step 421400: 0.198360\n",
      "2022-11-08 17:33:54,069 INFO     Training average positive_sample_loss at step 421500: 0.225466\n",
      "2022-11-08 17:33:54,069 INFO     Training average negative_sample_loss at step 421500: 0.172096\n",
      "2022-11-08 17:33:54,069 INFO     Training average loss at step 421500: 0.198781\n",
      "2022-11-08 17:34:03,784 INFO     Training average positive_sample_loss at step 421600: 0.233855\n",
      "2022-11-08 17:34:03,784 INFO     Training average negative_sample_loss at step 421600: 0.173577\n",
      "2022-11-08 17:34:03,784 INFO     Training average loss at step 421600: 0.203716\n",
      "2022-11-08 17:34:13,618 INFO     Training average positive_sample_loss at step 421700: 0.224485\n",
      "2022-11-08 17:34:13,618 INFO     Training average negative_sample_loss at step 421700: 0.180578\n",
      "2022-11-08 17:34:13,618 INFO     Training average loss at step 421700: 0.202532\n",
      "2022-11-08 17:34:23,380 INFO     Training average positive_sample_loss at step 421800: 0.224341\n",
      "2022-11-08 17:34:23,380 INFO     Training average negative_sample_loss at step 421800: 0.172688\n",
      "2022-11-08 17:34:23,380 INFO     Training average loss at step 421800: 0.198514\n",
      "2022-11-08 17:34:33,255 INFO     Training average positive_sample_loss at step 421900: 0.218045\n",
      "2022-11-08 17:34:33,255 INFO     Training average negative_sample_loss at step 421900: 0.172126\n",
      "2022-11-08 17:34:33,255 INFO     Training average loss at step 421900: 0.195085\n",
      "2022-11-08 17:34:43,140 INFO     Training average positive_sample_loss at step 422000: 0.226747\n",
      "2022-11-08 17:34:43,140 INFO     Training average negative_sample_loss at step 422000: 0.179246\n",
      "2022-11-08 17:34:43,140 INFO     Training average loss at step 422000: 0.202997\n",
      "2022-11-08 17:34:52,828 INFO     Training average positive_sample_loss at step 422100: 0.231826\n",
      "2022-11-08 17:34:52,828 INFO     Training average negative_sample_loss at step 422100: 0.167374\n",
      "2022-11-08 17:34:52,828 INFO     Training average loss at step 422100: 0.199600\n",
      "2022-11-08 17:35:02,516 INFO     Training average positive_sample_loss at step 422200: 0.229246\n",
      "2022-11-08 17:35:02,516 INFO     Training average negative_sample_loss at step 422200: 0.178131\n",
      "2022-11-08 17:35:02,516 INFO     Training average loss at step 422200: 0.203688\n",
      "2022-11-08 17:35:12,237 INFO     Training average positive_sample_loss at step 422300: 0.219264\n",
      "2022-11-08 17:35:12,237 INFO     Training average negative_sample_loss at step 422300: 0.176110\n",
      "2022-11-08 17:35:12,237 INFO     Training average loss at step 422300: 0.197687\n",
      "2022-11-08 17:35:21,937 INFO     Training average positive_sample_loss at step 422400: 0.223827\n",
      "2022-11-08 17:35:21,937 INFO     Training average negative_sample_loss at step 422400: 0.178804\n",
      "2022-11-08 17:35:21,937 INFO     Training average loss at step 422400: 0.201315\n",
      "2022-11-08 17:35:31,612 INFO     Training average positive_sample_loss at step 422500: 0.223492\n",
      "2022-11-08 17:35:31,612 INFO     Training average negative_sample_loss at step 422500: 0.174697\n",
      "2022-11-08 17:35:31,612 INFO     Training average loss at step 422500: 0.199095\n",
      "2022-11-08 17:35:41,333 INFO     Training average positive_sample_loss at step 422600: 0.229772\n",
      "2022-11-08 17:35:41,333 INFO     Training average negative_sample_loss at step 422600: 0.177357\n",
      "2022-11-08 17:35:41,333 INFO     Training average loss at step 422600: 0.203564\n",
      "2022-11-08 17:35:50,462 INFO     Training average positive_sample_loss at step 422700: 0.220635\n",
      "2022-11-08 17:35:50,462 INFO     Training average negative_sample_loss at step 422700: 0.177633\n",
      "2022-11-08 17:35:50,462 INFO     Training average loss at step 422700: 0.199134\n",
      "2022-11-08 17:36:00,057 INFO     Training average positive_sample_loss at step 422800: 0.222935\n",
      "2022-11-08 17:36:00,057 INFO     Training average negative_sample_loss at step 422800: 0.174172\n",
      "2022-11-08 17:36:00,057 INFO     Training average loss at step 422800: 0.198553\n",
      "2022-11-08 17:36:09,761 INFO     Training average positive_sample_loss at step 422900: 0.217432\n",
      "2022-11-08 17:36:09,761 INFO     Training average negative_sample_loss at step 422900: 0.170671\n",
      "2022-11-08 17:36:09,761 INFO     Training average loss at step 422900: 0.194052\n",
      "2022-11-08 17:36:19,486 INFO     Training average positive_sample_loss at step 423000: 0.227883\n",
      "2022-11-08 17:36:19,486 INFO     Training average negative_sample_loss at step 423000: 0.172438\n",
      "2022-11-08 17:36:19,486 INFO     Training average loss at step 423000: 0.200160\n",
      "2022-11-08 17:36:29,213 INFO     Training average positive_sample_loss at step 423100: 0.229941\n",
      "2022-11-08 17:36:29,213 INFO     Training average negative_sample_loss at step 423100: 0.173305\n",
      "2022-11-08 17:36:29,213 INFO     Training average loss at step 423100: 0.201623\n",
      "2022-11-08 17:36:38,891 INFO     Training average positive_sample_loss at step 423200: 0.234747\n",
      "2022-11-08 17:36:38,892 INFO     Training average negative_sample_loss at step 423200: 0.176370\n",
      "2022-11-08 17:36:38,892 INFO     Training average loss at step 423200: 0.205558\n",
      "2022-11-08 17:36:47,890 INFO     Training average positive_sample_loss at step 423300: 0.227535\n",
      "2022-11-08 17:36:47,890 INFO     Training average negative_sample_loss at step 423300: 0.176466\n",
      "2022-11-08 17:36:47,890 INFO     Training average loss at step 423300: 0.202001\n",
      "2022-11-08 17:36:57,553 INFO     Training average positive_sample_loss at step 423400: 0.217263\n",
      "2022-11-08 17:36:57,553 INFO     Training average negative_sample_loss at step 423400: 0.172035\n",
      "2022-11-08 17:36:57,554 INFO     Training average loss at step 423400: 0.194649\n",
      "2022-11-08 17:37:07,215 INFO     Training average positive_sample_loss at step 423500: 0.225912\n",
      "2022-11-08 17:37:07,215 INFO     Training average negative_sample_loss at step 423500: 0.174400\n",
      "2022-11-08 17:37:07,215 INFO     Training average loss at step 423500: 0.200156\n",
      "2022-11-08 17:37:16,878 INFO     Training average positive_sample_loss at step 423600: 0.222518\n",
      "2022-11-08 17:37:16,878 INFO     Training average negative_sample_loss at step 423600: 0.177258\n",
      "2022-11-08 17:37:16,878 INFO     Training average loss at step 423600: 0.199888\n",
      "2022-11-08 17:37:26,537 INFO     Training average positive_sample_loss at step 423700: 0.230267\n",
      "2022-11-08 17:37:26,537 INFO     Training average negative_sample_loss at step 423700: 0.170419\n",
      "2022-11-08 17:37:26,537 INFO     Training average loss at step 423700: 0.200343\n",
      "2022-11-08 17:37:36,197 INFO     Training average positive_sample_loss at step 423800: 0.223503\n",
      "2022-11-08 17:37:36,197 INFO     Training average negative_sample_loss at step 423800: 0.172855\n",
      "2022-11-08 17:37:36,197 INFO     Training average loss at step 423800: 0.198179\n",
      "2022-11-08 17:37:45,859 INFO     Training average positive_sample_loss at step 423900: 0.219957\n",
      "2022-11-08 17:37:45,859 INFO     Training average negative_sample_loss at step 423900: 0.173663\n",
      "2022-11-08 17:37:45,859 INFO     Training average loss at step 423900: 0.196810\n",
      "2022-11-08 17:37:55,519 INFO     Training average positive_sample_loss at step 424000: 0.227066\n",
      "2022-11-08 17:37:55,519 INFO     Training average negative_sample_loss at step 424000: 0.171891\n",
      "2022-11-08 17:37:55,519 INFO     Training average loss at step 424000: 0.199479\n",
      "2022-11-08 17:38:05,183 INFO     Training average positive_sample_loss at step 424100: 0.225196\n",
      "2022-11-08 17:38:05,183 INFO     Training average negative_sample_loss at step 424100: 0.175331\n",
      "2022-11-08 17:38:05,183 INFO     Training average loss at step 424100: 0.200264\n",
      "2022-11-08 17:38:14,848 INFO     Training average positive_sample_loss at step 424200: 0.224777\n",
      "2022-11-08 17:38:14,848 INFO     Training average negative_sample_loss at step 424200: 0.174556\n",
      "2022-11-08 17:38:14,848 INFO     Training average loss at step 424200: 0.199667\n",
      "2022-11-08 17:38:24,505 INFO     Training average positive_sample_loss at step 424300: 0.214854\n",
      "2022-11-08 17:38:24,505 INFO     Training average negative_sample_loss at step 424300: 0.172847\n",
      "2022-11-08 17:38:24,505 INFO     Training average loss at step 424300: 0.193850\n",
      "2022-11-08 17:38:34,171 INFO     Training average positive_sample_loss at step 424400: 0.229047\n",
      "2022-11-08 17:38:34,171 INFO     Training average negative_sample_loss at step 424400: 0.176263\n",
      "2022-11-08 17:38:34,171 INFO     Training average loss at step 424400: 0.202655\n",
      "2022-11-08 17:38:43,832 INFO     Training average positive_sample_loss at step 424500: 0.223059\n",
      "2022-11-08 17:38:43,833 INFO     Training average negative_sample_loss at step 424500: 0.175389\n",
      "2022-11-08 17:38:43,833 INFO     Training average loss at step 424500: 0.199224\n",
      "2022-11-08 17:38:54,005 INFO     Training average positive_sample_loss at step 424600: 0.229575\n",
      "2022-11-08 17:38:54,005 INFO     Training average negative_sample_loss at step 424600: 0.173546\n",
      "2022-11-08 17:38:54,005 INFO     Training average loss at step 424600: 0.201560\n",
      "2022-11-08 17:39:05,460 INFO     Training average positive_sample_loss at step 424700: 0.229824\n",
      "2022-11-08 17:39:05,460 INFO     Training average negative_sample_loss at step 424700: 0.175172\n",
      "2022-11-08 17:39:05,460 INFO     Training average loss at step 424700: 0.202498\n",
      "2022-11-08 17:39:15,124 INFO     Training average positive_sample_loss at step 424800: 0.231189\n",
      "2022-11-08 17:39:15,124 INFO     Training average negative_sample_loss at step 424800: 0.174930\n",
      "2022-11-08 17:39:15,124 INFO     Training average loss at step 424800: 0.203060\n",
      "2022-11-08 17:39:24,785 INFO     Training average positive_sample_loss at step 424900: 0.238675\n",
      "2022-11-08 17:39:24,785 INFO     Training average negative_sample_loss at step 424900: 0.176420\n",
      "2022-11-08 17:39:24,785 INFO     Training average loss at step 424900: 0.207548\n",
      "2022-11-08 17:39:34,448 INFO     Training average positive_sample_loss at step 425000: 0.229706\n",
      "2022-11-08 17:39:34,448 INFO     Training average negative_sample_loss at step 425000: 0.177212\n",
      "2022-11-08 17:39:34,448 INFO     Training average loss at step 425000: 0.203459\n",
      "2022-11-08 17:39:44,105 INFO     Training average positive_sample_loss at step 425100: 0.221640\n",
      "2022-11-08 17:39:44,105 INFO     Training average negative_sample_loss at step 425100: 0.172519\n",
      "2022-11-08 17:39:44,105 INFO     Training average loss at step 425100: 0.197079\n",
      "2022-11-08 17:39:53,765 INFO     Training average positive_sample_loss at step 425200: 0.225150\n",
      "2022-11-08 17:39:53,765 INFO     Training average negative_sample_loss at step 425200: 0.173026\n",
      "2022-11-08 17:39:53,765 INFO     Training average loss at step 425200: 0.199088\n",
      "2022-11-08 17:40:03,428 INFO     Training average positive_sample_loss at step 425300: 0.223110\n",
      "2022-11-08 17:40:03,429 INFO     Training average negative_sample_loss at step 425300: 0.176595\n",
      "2022-11-08 17:40:03,429 INFO     Training average loss at step 425300: 0.199853\n",
      "2022-11-08 17:40:13,092 INFO     Training average positive_sample_loss at step 425400: 0.241404\n",
      "2022-11-08 17:40:13,092 INFO     Training average negative_sample_loss at step 425400: 0.171426\n",
      "2022-11-08 17:40:13,092 INFO     Training average loss at step 425400: 0.206415\n",
      "2022-11-08 17:40:22,755 INFO     Training average positive_sample_loss at step 425500: 0.232329\n",
      "2022-11-08 17:40:22,755 INFO     Training average negative_sample_loss at step 425500: 0.172871\n",
      "2022-11-08 17:40:22,755 INFO     Training average loss at step 425500: 0.202600\n",
      "2022-11-08 17:40:32,417 INFO     Training average positive_sample_loss at step 425600: 0.218459\n",
      "2022-11-08 17:40:32,417 INFO     Training average negative_sample_loss at step 425600: 0.175661\n",
      "2022-11-08 17:40:32,417 INFO     Training average loss at step 425600: 0.197060\n",
      "2022-11-08 17:40:42,076 INFO     Training average positive_sample_loss at step 425700: 0.226728\n",
      "2022-11-08 17:40:42,076 INFO     Training average negative_sample_loss at step 425700: 0.174799\n",
      "2022-11-08 17:40:42,076 INFO     Training average loss at step 425700: 0.200764\n",
      "2022-11-08 17:40:51,740 INFO     Training average positive_sample_loss at step 425800: 0.221162\n",
      "2022-11-08 17:40:51,740 INFO     Training average negative_sample_loss at step 425800: 0.172039\n",
      "2022-11-08 17:40:51,740 INFO     Training average loss at step 425800: 0.196600\n",
      "2022-11-08 17:41:01,401 INFO     Training average positive_sample_loss at step 425900: 0.225439\n",
      "2022-11-08 17:41:01,401 INFO     Training average negative_sample_loss at step 425900: 0.176525\n",
      "2022-11-08 17:41:01,401 INFO     Training average loss at step 425900: 0.200982\n",
      "2022-11-08 17:41:11,063 INFO     Training average positive_sample_loss at step 426000: 0.232985\n",
      "2022-11-08 17:41:11,063 INFO     Training average negative_sample_loss at step 426000: 0.176749\n",
      "2022-11-08 17:41:11,063 INFO     Training average loss at step 426000: 0.204867\n",
      "2022-11-08 17:41:20,728 INFO     Training average positive_sample_loss at step 426100: 0.224696\n",
      "2022-11-08 17:41:20,728 INFO     Training average negative_sample_loss at step 426100: 0.172885\n",
      "2022-11-08 17:41:20,728 INFO     Training average loss at step 426100: 0.198790\n",
      "2022-11-08 17:41:30,388 INFO     Training average positive_sample_loss at step 426200: 0.231355\n",
      "2022-11-08 17:41:30,388 INFO     Training average negative_sample_loss at step 426200: 0.173220\n",
      "2022-11-08 17:41:30,388 INFO     Training average loss at step 426200: 0.202287\n",
      "2022-11-08 17:41:40,046 INFO     Training average positive_sample_loss at step 426300: 0.220999\n",
      "2022-11-08 17:41:40,046 INFO     Training average negative_sample_loss at step 426300: 0.176023\n",
      "2022-11-08 17:41:40,046 INFO     Training average loss at step 426300: 0.198511\n",
      "2022-11-08 17:41:49,708 INFO     Training average positive_sample_loss at step 426400: 0.229858\n",
      "2022-11-08 17:41:49,708 INFO     Training average negative_sample_loss at step 426400: 0.174235\n",
      "2022-11-08 17:41:49,708 INFO     Training average loss at step 426400: 0.202046\n",
      "2022-11-08 17:41:59,370 INFO     Training average positive_sample_loss at step 426500: 0.226123\n",
      "2022-11-08 17:41:59,370 INFO     Training average negative_sample_loss at step 426500: 0.173631\n",
      "2022-11-08 17:41:59,370 INFO     Training average loss at step 426500: 0.199877\n",
      "2022-11-08 17:42:09,032 INFO     Training average positive_sample_loss at step 426600: 0.231607\n",
      "2022-11-08 17:42:09,032 INFO     Training average negative_sample_loss at step 426600: 0.171030\n",
      "2022-11-08 17:42:09,032 INFO     Training average loss at step 426600: 0.201319\n",
      "2022-11-08 17:42:18,795 INFO     Training average positive_sample_loss at step 426700: 0.235782\n",
      "2022-11-08 17:42:18,795 INFO     Training average negative_sample_loss at step 426700: 0.170100\n",
      "2022-11-08 17:42:18,795 INFO     Training average loss at step 426700: 0.202941\n",
      "2022-11-08 17:42:28,648 INFO     Training average positive_sample_loss at step 426800: 0.226531\n",
      "2022-11-08 17:42:28,648 INFO     Training average negative_sample_loss at step 426800: 0.173542\n",
      "2022-11-08 17:42:28,648 INFO     Training average loss at step 426800: 0.200036\n",
      "2022-11-08 17:42:38,363 INFO     Training average positive_sample_loss at step 426900: 0.229346\n",
      "2022-11-08 17:42:38,363 INFO     Training average negative_sample_loss at step 426900: 0.175756\n",
      "2022-11-08 17:42:38,363 INFO     Training average loss at step 426900: 0.202551\n",
      "2022-11-08 17:42:48,076 INFO     Training average positive_sample_loss at step 427000: 0.225131\n",
      "2022-11-08 17:42:48,076 INFO     Training average negative_sample_loss at step 427000: 0.177171\n",
      "2022-11-08 17:42:48,076 INFO     Training average loss at step 427000: 0.201151\n",
      "2022-11-08 17:42:57,831 INFO     Training average positive_sample_loss at step 427100: 0.229293\n",
      "2022-11-08 17:42:57,831 INFO     Training average negative_sample_loss at step 427100: 0.170251\n",
      "2022-11-08 17:42:57,831 INFO     Training average loss at step 427100: 0.199772\n",
      "2022-11-08 17:43:07,565 INFO     Training average positive_sample_loss at step 427200: 0.227269\n",
      "2022-11-08 17:43:07,566 INFO     Training average negative_sample_loss at step 427200: 0.173338\n",
      "2022-11-08 17:43:07,566 INFO     Training average loss at step 427200: 0.200304\n",
      "2022-11-08 17:43:17,316 INFO     Training average positive_sample_loss at step 427300: 0.220806\n",
      "2022-11-08 17:43:17,317 INFO     Training average negative_sample_loss at step 427300: 0.174200\n",
      "2022-11-08 17:43:17,317 INFO     Training average loss at step 427300: 0.197503\n",
      "2022-11-08 17:43:27,065 INFO     Training average positive_sample_loss at step 427400: 0.227115\n",
      "2022-11-08 17:43:27,065 INFO     Training average negative_sample_loss at step 427400: 0.171268\n",
      "2022-11-08 17:43:27,065 INFO     Training average loss at step 427400: 0.199192\n",
      "2022-11-08 17:43:36,819 INFO     Training average positive_sample_loss at step 427500: 0.232498\n",
      "2022-11-08 17:43:36,819 INFO     Training average negative_sample_loss at step 427500: 0.169140\n",
      "2022-11-08 17:43:36,819 INFO     Training average loss at step 427500: 0.200819\n",
      "2022-11-08 17:43:46,560 INFO     Training average positive_sample_loss at step 427600: 0.207900\n",
      "2022-11-08 17:43:46,560 INFO     Training average negative_sample_loss at step 427600: 0.173274\n",
      "2022-11-08 17:43:46,560 INFO     Training average loss at step 427600: 0.190587\n",
      "2022-11-08 17:43:56,307 INFO     Training average positive_sample_loss at step 427700: 0.222987\n",
      "2022-11-08 17:43:56,307 INFO     Training average negative_sample_loss at step 427700: 0.173587\n",
      "2022-11-08 17:43:56,307 INFO     Training average loss at step 427700: 0.198287\n",
      "2022-11-08 17:44:06,073 INFO     Training average positive_sample_loss at step 427800: 0.237076\n",
      "2022-11-08 17:44:06,073 INFO     Training average negative_sample_loss at step 427800: 0.173557\n",
      "2022-11-08 17:44:06,073 INFO     Training average loss at step 427800: 0.205316\n",
      "2022-11-08 17:44:15,855 INFO     Training average positive_sample_loss at step 427900: 0.227400\n",
      "2022-11-08 17:44:15,855 INFO     Training average negative_sample_loss at step 427900: 0.177385\n",
      "2022-11-08 17:44:15,855 INFO     Training average loss at step 427900: 0.202393\n",
      "2022-11-08 17:44:25,610 INFO     Training average positive_sample_loss at step 428000: 0.219105\n",
      "2022-11-08 17:44:25,610 INFO     Training average negative_sample_loss at step 428000: 0.171008\n",
      "2022-11-08 17:44:25,610 INFO     Training average loss at step 428000: 0.195056\n",
      "2022-11-08 17:44:35,341 INFO     Training average positive_sample_loss at step 428100: 0.228393\n",
      "2022-11-08 17:44:35,341 INFO     Training average negative_sample_loss at step 428100: 0.182540\n",
      "2022-11-08 17:44:35,341 INFO     Training average loss at step 428100: 0.205466\n",
      "2022-11-08 17:44:44,456 INFO     Training average positive_sample_loss at step 428200: 0.229446\n",
      "2022-11-08 17:44:44,456 INFO     Training average negative_sample_loss at step 428200: 0.171890\n",
      "2022-11-08 17:44:44,456 INFO     Training average loss at step 428200: 0.200668\n",
      "2022-11-08 17:44:54,196 INFO     Training average positive_sample_loss at step 428300: 0.213299\n",
      "2022-11-08 17:44:54,196 INFO     Training average negative_sample_loss at step 428300: 0.174587\n",
      "2022-11-08 17:44:54,196 INFO     Training average loss at step 428300: 0.193943\n",
      "2022-11-08 17:45:03,937 INFO     Training average positive_sample_loss at step 428400: 0.225561\n",
      "2022-11-08 17:45:03,937 INFO     Training average negative_sample_loss at step 428400: 0.174370\n",
      "2022-11-08 17:45:03,937 INFO     Training average loss at step 428400: 0.199965\n",
      "2022-11-08 17:45:13,688 INFO     Training average positive_sample_loss at step 428500: 0.231071\n",
      "2022-11-08 17:45:13,688 INFO     Training average negative_sample_loss at step 428500: 0.176028\n",
      "2022-11-08 17:45:13,688 INFO     Training average loss at step 428500: 0.203549\n",
      "2022-11-08 17:45:23,492 INFO     Training average positive_sample_loss at step 428600: 0.222572\n",
      "2022-11-08 17:45:23,492 INFO     Training average negative_sample_loss at step 428600: 0.177718\n",
      "2022-11-08 17:45:23,492 INFO     Training average loss at step 428600: 0.200145\n",
      "2022-11-08 17:45:33,259 INFO     Training average positive_sample_loss at step 428700: 0.221171\n",
      "2022-11-08 17:45:33,259 INFO     Training average negative_sample_loss at step 428700: 0.174568\n",
      "2022-11-08 17:45:33,259 INFO     Training average loss at step 428700: 0.197870\n",
      "2022-11-08 17:45:42,359 INFO     Training average positive_sample_loss at step 428800: 0.223923\n",
      "2022-11-08 17:45:42,359 INFO     Training average negative_sample_loss at step 428800: 0.173376\n",
      "2022-11-08 17:45:42,359 INFO     Training average loss at step 428800: 0.198649\n",
      "2022-11-08 17:45:52,118 INFO     Training average positive_sample_loss at step 428900: 0.227060\n",
      "2022-11-08 17:45:52,118 INFO     Training average negative_sample_loss at step 428900: 0.172125\n",
      "2022-11-08 17:45:52,118 INFO     Training average loss at step 428900: 0.199593\n",
      "2022-11-08 17:46:01,792 INFO     Training average positive_sample_loss at step 429000: 0.229345\n",
      "2022-11-08 17:46:01,792 INFO     Training average negative_sample_loss at step 429000: 0.174067\n",
      "2022-11-08 17:46:01,792 INFO     Training average loss at step 429000: 0.201706\n",
      "2022-11-08 17:46:11,470 INFO     Training average positive_sample_loss at step 429100: 0.222189\n",
      "2022-11-08 17:46:11,470 INFO     Training average negative_sample_loss at step 429100: 0.171204\n",
      "2022-11-08 17:46:11,470 INFO     Training average loss at step 429100: 0.196697\n",
      "2022-11-08 17:46:22,406 INFO     Training average positive_sample_loss at step 429200: 0.221774\n",
      "2022-11-08 17:46:22,406 INFO     Training average negative_sample_loss at step 429200: 0.173921\n",
      "2022-11-08 17:46:22,406 INFO     Training average loss at step 429200: 0.197848\n",
      "2022-11-08 17:46:32,089 INFO     Training average positive_sample_loss at step 429300: 0.225414\n",
      "2022-11-08 17:46:32,090 INFO     Training average negative_sample_loss at step 429300: 0.173826\n",
      "2022-11-08 17:46:32,090 INFO     Training average loss at step 429300: 0.199620\n",
      "2022-11-08 17:46:42,655 INFO     Training average positive_sample_loss at step 429400: 0.223402\n",
      "2022-11-08 17:46:42,655 INFO     Training average negative_sample_loss at step 429400: 0.177889\n",
      "2022-11-08 17:46:42,655 INFO     Training average loss at step 429400: 0.200646\n",
      "2022-11-08 17:46:52,331 INFO     Training average positive_sample_loss at step 429500: 0.226636\n",
      "2022-11-08 17:46:52,331 INFO     Training average negative_sample_loss at step 429500: 0.175911\n",
      "2022-11-08 17:46:52,331 INFO     Training average loss at step 429500: 0.201274\n",
      "2022-11-08 17:47:02,005 INFO     Training average positive_sample_loss at step 429600: 0.228768\n",
      "2022-11-08 17:47:02,005 INFO     Training average negative_sample_loss at step 429600: 0.174877\n",
      "2022-11-08 17:47:02,005 INFO     Training average loss at step 429600: 0.201822\n",
      "2022-11-08 17:47:11,680 INFO     Training average positive_sample_loss at step 429700: 0.219145\n",
      "2022-11-08 17:47:11,680 INFO     Training average negative_sample_loss at step 429700: 0.173591\n",
      "2022-11-08 17:47:11,680 INFO     Training average loss at step 429700: 0.196368\n",
      "2022-11-08 17:47:21,358 INFO     Training average positive_sample_loss at step 429800: 0.228108\n",
      "2022-11-08 17:47:21,358 INFO     Training average negative_sample_loss at step 429800: 0.172898\n",
      "2022-11-08 17:47:21,358 INFO     Training average loss at step 429800: 0.200503\n",
      "2022-11-08 17:47:31,031 INFO     Training average positive_sample_loss at step 429900: 0.220667\n",
      "2022-11-08 17:47:31,032 INFO     Training average negative_sample_loss at step 429900: 0.176413\n",
      "2022-11-08 17:47:31,032 INFO     Training average loss at step 429900: 0.198540\n",
      "2022-11-08 17:47:43,491 INFO     Training average positive_sample_loss at step 430000: 0.231072\n",
      "2022-11-08 17:47:43,491 INFO     Training average negative_sample_loss at step 430000: 0.168852\n",
      "2022-11-08 17:47:43,491 INFO     Training average loss at step 430000: 0.199962\n",
      "2022-11-08 17:47:53,164 INFO     Training average positive_sample_loss at step 430100: 0.225620\n",
      "2022-11-08 17:47:53,164 INFO     Training average negative_sample_loss at step 430100: 0.173884\n",
      "2022-11-08 17:47:53,164 INFO     Training average loss at step 430100: 0.199752\n",
      "2022-11-08 17:48:02,837 INFO     Training average positive_sample_loss at step 430200: 0.212553\n",
      "2022-11-08 17:48:02,837 INFO     Training average negative_sample_loss at step 430200: 0.169981\n",
      "2022-11-08 17:48:02,837 INFO     Training average loss at step 430200: 0.191267\n",
      "2022-11-08 17:48:12,514 INFO     Training average positive_sample_loss at step 430300: 0.223596\n",
      "2022-11-08 17:48:12,514 INFO     Training average negative_sample_loss at step 430300: 0.174068\n",
      "2022-11-08 17:48:12,514 INFO     Training average loss at step 430300: 0.198832\n",
      "2022-11-08 17:48:22,260 INFO     Training average positive_sample_loss at step 430400: 0.220105\n",
      "2022-11-08 17:48:22,261 INFO     Training average negative_sample_loss at step 430400: 0.180927\n",
      "2022-11-08 17:48:22,261 INFO     Training average loss at step 430400: 0.200516\n",
      "2022-11-08 17:48:32,012 INFO     Training average positive_sample_loss at step 430500: 0.218873\n",
      "2022-11-08 17:48:32,012 INFO     Training average negative_sample_loss at step 430500: 0.175352\n",
      "2022-11-08 17:48:32,012 INFO     Training average loss at step 430500: 0.197112\n",
      "2022-11-08 17:48:41,695 INFO     Training average positive_sample_loss at step 430600: 0.227240\n",
      "2022-11-08 17:48:41,695 INFO     Training average negative_sample_loss at step 430600: 0.173223\n",
      "2022-11-08 17:48:41,695 INFO     Training average loss at step 430600: 0.200231\n",
      "2022-11-08 17:48:51,401 INFO     Training average positive_sample_loss at step 430700: 0.223205\n",
      "2022-11-08 17:48:51,401 INFO     Training average negative_sample_loss at step 430700: 0.175730\n",
      "2022-11-08 17:48:51,401 INFO     Training average loss at step 430700: 0.199468\n",
      "2022-11-08 17:49:01,085 INFO     Training average positive_sample_loss at step 430800: 0.227606\n",
      "2022-11-08 17:49:01,085 INFO     Training average negative_sample_loss at step 430800: 0.175716\n",
      "2022-11-08 17:49:01,085 INFO     Training average loss at step 430800: 0.201661\n",
      "2022-11-08 17:49:10,873 INFO     Training average positive_sample_loss at step 430900: 0.223731\n",
      "2022-11-08 17:49:10,873 INFO     Training average negative_sample_loss at step 430900: 0.168042\n",
      "2022-11-08 17:49:10,873 INFO     Training average loss at step 430900: 0.195887\n",
      "2022-11-08 17:49:20,848 INFO     Training average positive_sample_loss at step 431000: 0.225102\n",
      "2022-11-08 17:49:20,848 INFO     Training average negative_sample_loss at step 431000: 0.168256\n",
      "2022-11-08 17:49:20,848 INFO     Training average loss at step 431000: 0.196679\n",
      "2022-11-08 17:49:30,760 INFO     Training average positive_sample_loss at step 431100: 0.236869\n",
      "2022-11-08 17:49:30,760 INFO     Training average negative_sample_loss at step 431100: 0.170605\n",
      "2022-11-08 17:49:30,760 INFO     Training average loss at step 431100: 0.203737\n",
      "2022-11-08 17:49:40,693 INFO     Training average positive_sample_loss at step 431200: 0.228445\n",
      "2022-11-08 17:49:40,693 INFO     Training average negative_sample_loss at step 431200: 0.167565\n",
      "2022-11-08 17:49:40,693 INFO     Training average loss at step 431200: 0.198005\n",
      "2022-11-08 17:49:50,625 INFO     Training average positive_sample_loss at step 431300: 0.222404\n",
      "2022-11-08 17:49:50,625 INFO     Training average negative_sample_loss at step 431300: 0.175169\n",
      "2022-11-08 17:49:50,625 INFO     Training average loss at step 431300: 0.198786\n",
      "2022-11-08 17:50:00,551 INFO     Training average positive_sample_loss at step 431400: 0.220330\n",
      "2022-11-08 17:50:00,551 INFO     Training average negative_sample_loss at step 431400: 0.173209\n",
      "2022-11-08 17:50:00,551 INFO     Training average loss at step 431400: 0.196769\n",
      "2022-11-08 17:50:10,430 INFO     Training average positive_sample_loss at step 431500: 0.227286\n",
      "2022-11-08 17:50:10,430 INFO     Training average negative_sample_loss at step 431500: 0.175092\n",
      "2022-11-08 17:50:10,430 INFO     Training average loss at step 431500: 0.201189\n",
      "2022-11-08 17:50:20,211 INFO     Training average positive_sample_loss at step 431600: 0.226196\n",
      "2022-11-08 17:50:20,211 INFO     Training average negative_sample_loss at step 431600: 0.177104\n",
      "2022-11-08 17:50:20,211 INFO     Training average loss at step 431600: 0.201650\n",
      "2022-11-08 17:50:30,058 INFO     Training average positive_sample_loss at step 431700: 0.223420\n",
      "2022-11-08 17:50:30,058 INFO     Training average negative_sample_loss at step 431700: 0.169734\n",
      "2022-11-08 17:50:30,058 INFO     Training average loss at step 431700: 0.196577\n",
      "2022-11-08 17:50:39,909 INFO     Training average positive_sample_loss at step 431800: 0.235633\n",
      "2022-11-08 17:50:39,909 INFO     Training average negative_sample_loss at step 431800: 0.171137\n",
      "2022-11-08 17:50:39,909 INFO     Training average loss at step 431800: 0.203385\n",
      "2022-11-08 17:50:49,701 INFO     Training average positive_sample_loss at step 431900: 0.232681\n",
      "2022-11-08 17:50:49,701 INFO     Training average negative_sample_loss at step 431900: 0.172514\n",
      "2022-11-08 17:50:49,701 INFO     Training average loss at step 431900: 0.202598\n",
      "2022-11-08 17:50:59,432 INFO     Training average positive_sample_loss at step 432000: 0.226939\n",
      "2022-11-08 17:50:59,432 INFO     Training average negative_sample_loss at step 432000: 0.173791\n",
      "2022-11-08 17:50:59,432 INFO     Training average loss at step 432000: 0.200365\n",
      "2022-11-08 17:51:09,169 INFO     Training average positive_sample_loss at step 432100: 0.223994\n",
      "2022-11-08 17:51:09,169 INFO     Training average negative_sample_loss at step 432100: 0.176852\n",
      "2022-11-08 17:51:09,169 INFO     Training average loss at step 432100: 0.200423\n",
      "2022-11-08 17:51:18,913 INFO     Training average positive_sample_loss at step 432200: 0.227422\n",
      "2022-11-08 17:51:18,913 INFO     Training average negative_sample_loss at step 432200: 0.177168\n",
      "2022-11-08 17:51:18,913 INFO     Training average loss at step 432200: 0.202295\n",
      "2022-11-08 17:51:28,665 INFO     Training average positive_sample_loss at step 432300: 0.219040\n",
      "2022-11-08 17:51:28,666 INFO     Training average negative_sample_loss at step 432300: 0.170714\n",
      "2022-11-08 17:51:28,666 INFO     Training average loss at step 432300: 0.194877\n",
      "2022-11-08 17:51:38,423 INFO     Training average positive_sample_loss at step 432400: 0.221353\n",
      "2022-11-08 17:51:38,423 INFO     Training average negative_sample_loss at step 432400: 0.175351\n",
      "2022-11-08 17:51:38,424 INFO     Training average loss at step 432400: 0.198352\n",
      "2022-11-08 17:51:48,192 INFO     Training average positive_sample_loss at step 432500: 0.223536\n",
      "2022-11-08 17:51:48,192 INFO     Training average negative_sample_loss at step 432500: 0.173946\n",
      "2022-11-08 17:51:48,192 INFO     Training average loss at step 432500: 0.198741\n",
      "2022-11-08 17:51:57,957 INFO     Training average positive_sample_loss at step 432600: 0.220743\n",
      "2022-11-08 17:51:57,957 INFO     Training average negative_sample_loss at step 432600: 0.169576\n",
      "2022-11-08 17:51:57,957 INFO     Training average loss at step 432600: 0.195160\n",
      "2022-11-08 17:52:07,758 INFO     Training average positive_sample_loss at step 432700: 0.216400\n",
      "2022-11-08 17:52:07,758 INFO     Training average negative_sample_loss at step 432700: 0.175968\n",
      "2022-11-08 17:52:07,758 INFO     Training average loss at step 432700: 0.196184\n",
      "2022-11-08 17:52:17,502 INFO     Training average positive_sample_loss at step 432800: 0.225784\n",
      "2022-11-08 17:52:17,502 INFO     Training average negative_sample_loss at step 432800: 0.174062\n",
      "2022-11-08 17:52:17,502 INFO     Training average loss at step 432800: 0.199923\n",
      "2022-11-08 17:52:27,212 INFO     Training average positive_sample_loss at step 432900: 0.222254\n",
      "2022-11-08 17:52:27,212 INFO     Training average negative_sample_loss at step 432900: 0.174273\n",
      "2022-11-08 17:52:27,212 INFO     Training average loss at step 432900: 0.198263\n",
      "2022-11-08 17:52:36,873 INFO     Training average positive_sample_loss at step 433000: 0.223962\n",
      "2022-11-08 17:52:36,873 INFO     Training average negative_sample_loss at step 433000: 0.175914\n",
      "2022-11-08 17:52:36,873 INFO     Training average loss at step 433000: 0.199938\n",
      "2022-11-08 17:52:46,535 INFO     Training average positive_sample_loss at step 433100: 0.214576\n",
      "2022-11-08 17:52:46,535 INFO     Training average negative_sample_loss at step 433100: 0.177681\n",
      "2022-11-08 17:52:46,535 INFO     Training average loss at step 433100: 0.196129\n",
      "2022-11-08 17:52:56,197 INFO     Training average positive_sample_loss at step 433200: 0.221896\n",
      "2022-11-08 17:52:56,197 INFO     Training average negative_sample_loss at step 433200: 0.171739\n",
      "2022-11-08 17:52:56,197 INFO     Training average loss at step 433200: 0.196818\n",
      "2022-11-08 17:53:05,859 INFO     Training average positive_sample_loss at step 433300: 0.225667\n",
      "2022-11-08 17:53:05,859 INFO     Training average negative_sample_loss at step 433300: 0.171558\n",
      "2022-11-08 17:53:05,859 INFO     Training average loss at step 433300: 0.198613\n",
      "2022-11-08 17:53:15,521 INFO     Training average positive_sample_loss at step 433400: 0.223042\n",
      "2022-11-08 17:53:15,521 INFO     Training average negative_sample_loss at step 433400: 0.173900\n",
      "2022-11-08 17:53:15,521 INFO     Training average loss at step 433400: 0.198471\n",
      "2022-11-08 17:53:25,180 INFO     Training average positive_sample_loss at step 433500: 0.225202\n",
      "2022-11-08 17:53:25,180 INFO     Training average negative_sample_loss at step 433500: 0.173252\n",
      "2022-11-08 17:53:25,180 INFO     Training average loss at step 433500: 0.199227\n",
      "2022-11-08 17:53:34,847 INFO     Training average positive_sample_loss at step 433600: 0.228222\n",
      "2022-11-08 17:53:34,847 INFO     Training average negative_sample_loss at step 433600: 0.173101\n",
      "2022-11-08 17:53:34,847 INFO     Training average loss at step 433600: 0.200662\n",
      "2022-11-08 17:53:43,831 INFO     Training average positive_sample_loss at step 433700: 0.230435\n",
      "2022-11-08 17:53:43,831 INFO     Training average negative_sample_loss at step 433700: 0.168548\n",
      "2022-11-08 17:53:43,831 INFO     Training average loss at step 433700: 0.199491\n",
      "2022-11-08 17:53:53,493 INFO     Training average positive_sample_loss at step 433800: 0.214931\n",
      "2022-11-08 17:53:53,493 INFO     Training average negative_sample_loss at step 433800: 0.174597\n",
      "2022-11-08 17:53:53,493 INFO     Training average loss at step 433800: 0.194764\n",
      "2022-11-08 17:54:04,482 INFO     Training average positive_sample_loss at step 433900: 0.222124\n",
      "2022-11-08 17:54:04,482 INFO     Training average negative_sample_loss at step 433900: 0.168974\n",
      "2022-11-08 17:54:04,482 INFO     Training average loss at step 433900: 0.195549\n",
      "2022-11-08 17:54:14,145 INFO     Training average positive_sample_loss at step 434000: 0.235032\n",
      "2022-11-08 17:54:14,146 INFO     Training average negative_sample_loss at step 434000: 0.174454\n",
      "2022-11-08 17:54:14,146 INFO     Training average loss at step 434000: 0.204743\n",
      "2022-11-08 17:54:24,670 INFO     Training average positive_sample_loss at step 434100: 0.231705\n",
      "2022-11-08 17:54:24,670 INFO     Training average negative_sample_loss at step 434100: 0.171295\n",
      "2022-11-08 17:54:24,670 INFO     Training average loss at step 434100: 0.201500\n",
      "2022-11-08 17:54:33,646 INFO     Training average positive_sample_loss at step 434200: 0.226356\n",
      "2022-11-08 17:54:33,646 INFO     Training average negative_sample_loss at step 434200: 0.174113\n",
      "2022-11-08 17:54:33,646 INFO     Training average loss at step 434200: 0.200234\n",
      "2022-11-08 17:54:43,400 INFO     Training average positive_sample_loss at step 434300: 0.234552\n",
      "2022-11-08 17:54:43,400 INFO     Training average negative_sample_loss at step 434300: 0.166201\n",
      "2022-11-08 17:54:43,400 INFO     Training average loss at step 434300: 0.200376\n",
      "2022-11-08 17:54:53,199 INFO     Training average positive_sample_loss at step 434400: 0.235035\n",
      "2022-11-08 17:54:53,199 INFO     Training average negative_sample_loss at step 434400: 0.171954\n",
      "2022-11-08 17:54:53,199 INFO     Training average loss at step 434400: 0.203494\n",
      "2022-11-08 17:55:03,025 INFO     Training average positive_sample_loss at step 434500: 0.228811\n",
      "2022-11-08 17:55:03,025 INFO     Training average negative_sample_loss at step 434500: 0.171937\n",
      "2022-11-08 17:55:03,025 INFO     Training average loss at step 434500: 0.200374\n",
      "2022-11-08 17:55:12,860 INFO     Training average positive_sample_loss at step 434600: 0.229700\n",
      "2022-11-08 17:55:12,860 INFO     Training average negative_sample_loss at step 434600: 0.171879\n",
      "2022-11-08 17:55:12,860 INFO     Training average loss at step 434600: 0.200789\n",
      "2022-11-08 17:55:22,654 INFO     Training average positive_sample_loss at step 434700: 0.229087\n",
      "2022-11-08 17:55:22,654 INFO     Training average negative_sample_loss at step 434700: 0.178605\n",
      "2022-11-08 17:55:22,654 INFO     Training average loss at step 434700: 0.203846\n",
      "2022-11-08 17:55:32,457 INFO     Training average positive_sample_loss at step 434800: 0.231772\n",
      "2022-11-08 17:55:32,457 INFO     Training average negative_sample_loss at step 434800: 0.172806\n",
      "2022-11-08 17:55:32,457 INFO     Training average loss at step 434800: 0.202289\n",
      "2022-11-08 17:55:42,177 INFO     Training average positive_sample_loss at step 434900: 0.215349\n",
      "2022-11-08 17:55:42,177 INFO     Training average negative_sample_loss at step 434900: 0.171013\n",
      "2022-11-08 17:55:42,177 INFO     Training average loss at step 434900: 0.193181\n",
      "2022-11-08 17:55:52,018 INFO     Training average positive_sample_loss at step 435000: 0.220734\n",
      "2022-11-08 17:55:52,018 INFO     Training average negative_sample_loss at step 435000: 0.173914\n",
      "2022-11-08 17:55:52,018 INFO     Training average loss at step 435000: 0.197324\n",
      "2022-11-08 17:56:01,744 INFO     Training average positive_sample_loss at step 435100: 0.220436\n",
      "2022-11-08 17:56:01,744 INFO     Training average negative_sample_loss at step 435100: 0.174748\n",
      "2022-11-08 17:56:01,744 INFO     Training average loss at step 435100: 0.197592\n",
      "2022-11-08 17:56:11,579 INFO     Training average positive_sample_loss at step 435200: 0.230389\n",
      "2022-11-08 17:56:11,579 INFO     Training average negative_sample_loss at step 435200: 0.176331\n",
      "2022-11-08 17:56:11,580 INFO     Training average loss at step 435200: 0.203360\n",
      "2022-11-08 17:56:21,277 INFO     Training average positive_sample_loss at step 435300: 0.223764\n",
      "2022-11-08 17:56:21,278 INFO     Training average negative_sample_loss at step 435300: 0.169229\n",
      "2022-11-08 17:56:21,278 INFO     Training average loss at step 435300: 0.196496\n",
      "2022-11-08 17:56:31,168 INFO     Training average positive_sample_loss at step 435400: 0.222892\n",
      "2022-11-08 17:56:31,168 INFO     Training average negative_sample_loss at step 435400: 0.175071\n",
      "2022-11-08 17:56:31,168 INFO     Training average loss at step 435400: 0.198982\n",
      "2022-11-08 17:56:40,970 INFO     Training average positive_sample_loss at step 435500: 0.231023\n",
      "2022-11-08 17:56:40,970 INFO     Training average negative_sample_loss at step 435500: 0.173123\n",
      "2022-11-08 17:56:40,970 INFO     Training average loss at step 435500: 0.202073\n",
      "2022-11-08 17:56:50,751 INFO     Training average positive_sample_loss at step 435600: 0.217763\n",
      "2022-11-08 17:56:50,751 INFO     Training average negative_sample_loss at step 435600: 0.173948\n",
      "2022-11-08 17:56:50,751 INFO     Training average loss at step 435600: 0.195856\n",
      "2022-11-08 17:57:00,846 INFO     Training average positive_sample_loss at step 435700: 0.230270\n",
      "2022-11-08 17:57:00,846 INFO     Training average negative_sample_loss at step 435700: 0.178609\n",
      "2022-11-08 17:57:00,846 INFO     Training average loss at step 435700: 0.204439\n",
      "2022-11-08 17:57:10,621 INFO     Training average positive_sample_loss at step 435800: 0.228209\n",
      "2022-11-08 17:57:10,622 INFO     Training average negative_sample_loss at step 435800: 0.172537\n",
      "2022-11-08 17:57:10,622 INFO     Training average loss at step 435800: 0.200373\n",
      "2022-11-08 17:57:20,537 INFO     Training average positive_sample_loss at step 435900: 0.227053\n",
      "2022-11-08 17:57:20,537 INFO     Training average negative_sample_loss at step 435900: 0.170245\n",
      "2022-11-08 17:57:20,537 INFO     Training average loss at step 435900: 0.198649\n",
      "2022-11-08 17:57:30,412 INFO     Training average positive_sample_loss at step 436000: 0.218351\n",
      "2022-11-08 17:57:30,412 INFO     Training average negative_sample_loss at step 436000: 0.172608\n",
      "2022-11-08 17:57:30,412 INFO     Training average loss at step 436000: 0.195480\n",
      "2022-11-08 17:57:40,250 INFO     Training average positive_sample_loss at step 436100: 0.224480\n",
      "2022-11-08 17:57:40,250 INFO     Training average negative_sample_loss at step 436100: 0.171031\n",
      "2022-11-08 17:57:40,250 INFO     Training average loss at step 436100: 0.197756\n",
      "2022-11-08 17:57:50,071 INFO     Training average positive_sample_loss at step 436200: 0.231935\n",
      "2022-11-08 17:57:50,071 INFO     Training average negative_sample_loss at step 436200: 0.172884\n",
      "2022-11-08 17:57:50,071 INFO     Training average loss at step 436200: 0.202410\n",
      "2022-11-08 17:57:59,885 INFO     Training average positive_sample_loss at step 436300: 0.227484\n",
      "2022-11-08 17:57:59,885 INFO     Training average negative_sample_loss at step 436300: 0.175297\n",
      "2022-11-08 17:57:59,885 INFO     Training average loss at step 436300: 0.201390\n",
      "2022-11-08 17:58:09,663 INFO     Training average positive_sample_loss at step 436400: 0.234959\n",
      "2022-11-08 17:58:09,663 INFO     Training average negative_sample_loss at step 436400: 0.176903\n",
      "2022-11-08 17:58:09,663 INFO     Training average loss at step 436400: 0.205931\n",
      "2022-11-08 17:58:19,508 INFO     Training average positive_sample_loss at step 436500: 0.232754\n",
      "2022-11-08 17:58:19,508 INFO     Training average negative_sample_loss at step 436500: 0.173781\n",
      "2022-11-08 17:58:19,508 INFO     Training average loss at step 436500: 0.203268\n",
      "2022-11-08 17:58:29,256 INFO     Training average positive_sample_loss at step 436600: 0.225855\n",
      "2022-11-08 17:58:29,256 INFO     Training average negative_sample_loss at step 436600: 0.171183\n",
      "2022-11-08 17:58:29,256 INFO     Training average loss at step 436600: 0.198519\n",
      "2022-11-08 17:58:39,054 INFO     Training average positive_sample_loss at step 436700: 0.219049\n",
      "2022-11-08 17:58:39,054 INFO     Training average negative_sample_loss at step 436700: 0.177307\n",
      "2022-11-08 17:58:39,054 INFO     Training average loss at step 436700: 0.198178\n",
      "2022-11-08 17:58:48,845 INFO     Training average positive_sample_loss at step 436800: 0.214970\n",
      "2022-11-08 17:58:48,846 INFO     Training average negative_sample_loss at step 436800: 0.174406\n",
      "2022-11-08 17:58:48,846 INFO     Training average loss at step 436800: 0.194688\n",
      "2022-11-08 17:58:58,591 INFO     Training average positive_sample_loss at step 436900: 0.222735\n",
      "2022-11-08 17:58:58,591 INFO     Training average negative_sample_loss at step 436900: 0.167130\n",
      "2022-11-08 17:58:58,591 INFO     Training average loss at step 436900: 0.194933\n",
      "2022-11-08 17:59:08,349 INFO     Training average positive_sample_loss at step 437000: 0.222557\n",
      "2022-11-08 17:59:08,349 INFO     Training average negative_sample_loss at step 437000: 0.171402\n",
      "2022-11-08 17:59:08,349 INFO     Training average loss at step 437000: 0.196980\n",
      "2022-11-08 17:59:18,105 INFO     Training average positive_sample_loss at step 437100: 0.228284\n",
      "2022-11-08 17:59:18,105 INFO     Training average negative_sample_loss at step 437100: 0.174661\n",
      "2022-11-08 17:59:18,105 INFO     Training average loss at step 437100: 0.201473\n",
      "2022-11-08 17:59:27,864 INFO     Training average positive_sample_loss at step 437200: 0.222916\n",
      "2022-11-08 17:59:27,864 INFO     Training average negative_sample_loss at step 437200: 0.170602\n",
      "2022-11-08 17:59:27,864 INFO     Training average loss at step 437200: 0.196759\n",
      "2022-11-08 17:59:37,625 INFO     Training average positive_sample_loss at step 437300: 0.228951\n",
      "2022-11-08 17:59:37,625 INFO     Training average negative_sample_loss at step 437300: 0.170156\n",
      "2022-11-08 17:59:37,625 INFO     Training average loss at step 437300: 0.199553\n",
      "2022-11-08 17:59:47,380 INFO     Training average positive_sample_loss at step 437400: 0.226519\n",
      "2022-11-08 17:59:47,380 INFO     Training average negative_sample_loss at step 437400: 0.169805\n",
      "2022-11-08 17:59:47,380 INFO     Training average loss at step 437400: 0.198162\n",
      "2022-11-08 17:59:57,133 INFO     Training average positive_sample_loss at step 437500: 0.230866\n",
      "2022-11-08 17:59:57,133 INFO     Training average negative_sample_loss at step 437500: 0.173189\n",
      "2022-11-08 17:59:57,133 INFO     Training average loss at step 437500: 0.202027\n",
      "2022-11-08 18:00:06,899 INFO     Training average positive_sample_loss at step 437600: 0.226988\n",
      "2022-11-08 18:00:06,899 INFO     Training average negative_sample_loss at step 437600: 0.175703\n",
      "2022-11-08 18:00:06,899 INFO     Training average loss at step 437600: 0.201346\n",
      "2022-11-08 18:00:16,803 INFO     Training average positive_sample_loss at step 437700: 0.223256\n",
      "2022-11-08 18:00:16,803 INFO     Training average negative_sample_loss at step 437700: 0.168109\n",
      "2022-11-08 18:00:16,803 INFO     Training average loss at step 437700: 0.195683\n",
      "2022-11-08 18:00:26,543 INFO     Training average positive_sample_loss at step 437800: 0.221729\n",
      "2022-11-08 18:00:26,543 INFO     Training average negative_sample_loss at step 437800: 0.173690\n",
      "2022-11-08 18:00:26,543 INFO     Training average loss at step 437800: 0.197710\n",
      "2022-11-08 18:00:36,269 INFO     Training average positive_sample_loss at step 437900: 0.222016\n",
      "2022-11-08 18:00:36,269 INFO     Training average negative_sample_loss at step 437900: 0.173900\n",
      "2022-11-08 18:00:36,270 INFO     Training average loss at step 437900: 0.197958\n",
      "2022-11-08 18:00:45,995 INFO     Training average positive_sample_loss at step 438000: 0.219420\n",
      "2022-11-08 18:00:45,995 INFO     Training average negative_sample_loss at step 438000: 0.171605\n",
      "2022-11-08 18:00:45,995 INFO     Training average loss at step 438000: 0.195513\n",
      "2022-11-08 18:00:55,721 INFO     Training average positive_sample_loss at step 438100: 0.225580\n",
      "2022-11-08 18:00:55,721 INFO     Training average negative_sample_loss at step 438100: 0.171848\n",
      "2022-11-08 18:00:55,721 INFO     Training average loss at step 438100: 0.198714\n",
      "2022-11-08 18:01:05,452 INFO     Training average positive_sample_loss at step 438200: 0.230726\n",
      "2022-11-08 18:01:05,452 INFO     Training average negative_sample_loss at step 438200: 0.168923\n",
      "2022-11-08 18:01:05,452 INFO     Training average loss at step 438200: 0.199824\n",
      "2022-11-08 18:01:15,181 INFO     Training average positive_sample_loss at step 438300: 0.228667\n",
      "2022-11-08 18:01:15,181 INFO     Training average negative_sample_loss at step 438300: 0.179106\n",
      "2022-11-08 18:01:15,181 INFO     Training average loss at step 438300: 0.203887\n",
      "2022-11-08 18:01:24,912 INFO     Training average positive_sample_loss at step 438400: 0.221172\n",
      "2022-11-08 18:01:24,912 INFO     Training average negative_sample_loss at step 438400: 0.170126\n",
      "2022-11-08 18:01:24,912 INFO     Training average loss at step 438400: 0.195649\n",
      "2022-11-08 18:01:34,646 INFO     Training average positive_sample_loss at step 438500: 0.228768\n",
      "2022-11-08 18:01:34,647 INFO     Training average negative_sample_loss at step 438500: 0.167892\n",
      "2022-11-08 18:01:34,647 INFO     Training average loss at step 438500: 0.198330\n",
      "2022-11-08 18:01:45,638 INFO     Training average positive_sample_loss at step 438600: 0.222870\n",
      "2022-11-08 18:01:45,638 INFO     Training average negative_sample_loss at step 438600: 0.175450\n",
      "2022-11-08 18:01:45,638 INFO     Training average loss at step 438600: 0.199160\n",
      "2022-11-08 18:01:56,291 INFO     Training average positive_sample_loss at step 438700: 0.229256\n",
      "2022-11-08 18:01:56,292 INFO     Training average negative_sample_loss at step 438700: 0.168578\n",
      "2022-11-08 18:01:56,292 INFO     Training average loss at step 438700: 0.198917\n",
      "2022-11-08 18:02:06,021 INFO     Training average positive_sample_loss at step 438800: 0.226198\n",
      "2022-11-08 18:02:06,021 INFO     Training average negative_sample_loss at step 438800: 0.171681\n",
      "2022-11-08 18:02:06,021 INFO     Training average loss at step 438800: 0.198940\n",
      "2022-11-08 18:02:15,740 INFO     Training average positive_sample_loss at step 438900: 0.223990\n",
      "2022-11-08 18:02:15,740 INFO     Training average negative_sample_loss at step 438900: 0.178947\n",
      "2022-11-08 18:02:15,740 INFO     Training average loss at step 438900: 0.201468\n",
      "2022-11-08 18:02:25,277 INFO     Training average positive_sample_loss at step 439000: 0.218755\n",
      "2022-11-08 18:02:25,277 INFO     Training average negative_sample_loss at step 439000: 0.169526\n",
      "2022-11-08 18:02:25,277 INFO     Training average loss at step 439000: 0.194140\n",
      "2022-11-08 18:02:34,116 INFO     Training average positive_sample_loss at step 439100: 0.224464\n",
      "2022-11-08 18:02:34,116 INFO     Training average negative_sample_loss at step 439100: 0.173265\n",
      "2022-11-08 18:02:34,116 INFO     Training average loss at step 439100: 0.198864\n",
      "2022-11-08 18:02:43,639 INFO     Training average positive_sample_loss at step 439200: 0.224790\n",
      "2022-11-08 18:02:43,639 INFO     Training average negative_sample_loss at step 439200: 0.176282\n",
      "2022-11-08 18:02:43,639 INFO     Training average loss at step 439200: 0.200536\n",
      "2022-11-08 18:02:53,168 INFO     Training average positive_sample_loss at step 439300: 0.214839\n",
      "2022-11-08 18:02:53,168 INFO     Training average negative_sample_loss at step 439300: 0.171267\n",
      "2022-11-08 18:02:53,168 INFO     Training average loss at step 439300: 0.193053\n",
      "2022-11-08 18:03:02,694 INFO     Training average positive_sample_loss at step 439400: 0.224042\n",
      "2022-11-08 18:03:02,694 INFO     Training average negative_sample_loss at step 439400: 0.175705\n",
      "2022-11-08 18:03:02,694 INFO     Training average loss at step 439400: 0.199874\n",
      "2022-11-08 18:03:12,220 INFO     Training average positive_sample_loss at step 439500: 0.222897\n",
      "2022-11-08 18:03:12,220 INFO     Training average negative_sample_loss at step 439500: 0.170266\n",
      "2022-11-08 18:03:12,220 INFO     Training average loss at step 439500: 0.196582\n",
      "2022-11-08 18:03:21,747 INFO     Training average positive_sample_loss at step 439600: 0.232570\n",
      "2022-11-08 18:03:21,747 INFO     Training average negative_sample_loss at step 439600: 0.172432\n",
      "2022-11-08 18:03:21,747 INFO     Training average loss at step 439600: 0.202501\n",
      "2022-11-08 18:03:30,586 INFO     Training average positive_sample_loss at step 439700: 0.219139\n",
      "2022-11-08 18:03:30,587 INFO     Training average negative_sample_loss at step 439700: 0.171152\n",
      "2022-11-08 18:03:30,587 INFO     Training average loss at step 439700: 0.195146\n",
      "2022-11-08 18:03:40,118 INFO     Training average positive_sample_loss at step 439800: 0.227708\n",
      "2022-11-08 18:03:40,118 INFO     Training average negative_sample_loss at step 439800: 0.170001\n",
      "2022-11-08 18:03:40,118 INFO     Training average loss at step 439800: 0.198855\n",
      "2022-11-08 18:03:49,653 INFO     Training average positive_sample_loss at step 439900: 0.217671\n",
      "2022-11-08 18:03:49,653 INFO     Training average negative_sample_loss at step 439900: 0.169157\n",
      "2022-11-08 18:03:49,653 INFO     Training average loss at step 439900: 0.193414\n",
      "2022-11-08 18:04:01,948 INFO     Training average positive_sample_loss at step 440000: 0.222484\n",
      "2022-11-08 18:04:01,948 INFO     Training average negative_sample_loss at step 440000: 0.175114\n",
      "2022-11-08 18:04:01,948 INFO     Training average loss at step 440000: 0.198799\n",
      "2022-11-08 18:04:11,474 INFO     Training average positive_sample_loss at step 440100: 0.219816\n",
      "2022-11-08 18:04:11,474 INFO     Training average negative_sample_loss at step 440100: 0.175529\n",
      "2022-11-08 18:04:11,474 INFO     Training average loss at step 440100: 0.197673\n",
      "2022-11-08 18:04:21,007 INFO     Training average positive_sample_loss at step 440200: 0.226554\n",
      "2022-11-08 18:04:21,007 INFO     Training average negative_sample_loss at step 440200: 0.173087\n",
      "2022-11-08 18:04:21,007 INFO     Training average loss at step 440200: 0.199821\n",
      "2022-11-08 18:04:30,537 INFO     Training average positive_sample_loss at step 440300: 0.224892\n",
      "2022-11-08 18:04:30,537 INFO     Training average negative_sample_loss at step 440300: 0.168226\n",
      "2022-11-08 18:04:30,538 INFO     Training average loss at step 440300: 0.196559\n",
      "2022-11-08 18:04:40,069 INFO     Training average positive_sample_loss at step 440400: 0.214547\n",
      "2022-11-08 18:04:40,069 INFO     Training average negative_sample_loss at step 440400: 0.176567\n",
      "2022-11-08 18:04:40,069 INFO     Training average loss at step 440400: 0.195557\n",
      "2022-11-08 18:04:49,597 INFO     Training average positive_sample_loss at step 440500: 0.232053\n",
      "2022-11-08 18:04:49,597 INFO     Training average negative_sample_loss at step 440500: 0.173856\n",
      "2022-11-08 18:04:49,597 INFO     Training average loss at step 440500: 0.202955\n",
      "2022-11-08 18:04:59,124 INFO     Training average positive_sample_loss at step 440600: 0.223988\n",
      "2022-11-08 18:04:59,125 INFO     Training average negative_sample_loss at step 440600: 0.165707\n",
      "2022-11-08 18:04:59,125 INFO     Training average loss at step 440600: 0.194847\n",
      "2022-11-08 18:05:08,656 INFO     Training average positive_sample_loss at step 440700: 0.218650\n",
      "2022-11-08 18:05:08,656 INFO     Training average negative_sample_loss at step 440700: 0.175567\n",
      "2022-11-08 18:05:08,656 INFO     Training average loss at step 440700: 0.197109\n",
      "2022-11-08 18:05:18,188 INFO     Training average positive_sample_loss at step 440800: 0.219819\n",
      "2022-11-08 18:05:18,188 INFO     Training average negative_sample_loss at step 440800: 0.170720\n",
      "2022-11-08 18:05:18,188 INFO     Training average loss at step 440800: 0.195270\n",
      "2022-11-08 18:05:27,719 INFO     Training average positive_sample_loss at step 440900: 0.228085\n",
      "2022-11-08 18:05:27,719 INFO     Training average negative_sample_loss at step 440900: 0.170519\n",
      "2022-11-08 18:05:27,719 INFO     Training average loss at step 440900: 0.199302\n",
      "2022-11-08 18:05:37,247 INFO     Training average positive_sample_loss at step 441000: 0.224020\n",
      "2022-11-08 18:05:37,247 INFO     Training average negative_sample_loss at step 441000: 0.168021\n",
      "2022-11-08 18:05:37,247 INFO     Training average loss at step 441000: 0.196021\n",
      "2022-11-08 18:05:46,774 INFO     Training average positive_sample_loss at step 441100: 0.227289\n",
      "2022-11-08 18:05:46,774 INFO     Training average negative_sample_loss at step 441100: 0.172147\n",
      "2022-11-08 18:05:46,774 INFO     Training average loss at step 441100: 0.199718\n",
      "2022-11-08 18:05:56,305 INFO     Training average positive_sample_loss at step 441200: 0.231055\n",
      "2022-11-08 18:05:56,305 INFO     Training average negative_sample_loss at step 441200: 0.168969\n",
      "2022-11-08 18:05:56,305 INFO     Training average loss at step 441200: 0.200012\n",
      "2022-11-08 18:06:05,837 INFO     Training average positive_sample_loss at step 441300: 0.221478\n",
      "2022-11-08 18:06:05,837 INFO     Training average negative_sample_loss at step 441300: 0.171877\n",
      "2022-11-08 18:06:05,837 INFO     Training average loss at step 441300: 0.196677\n",
      "2022-11-08 18:06:15,371 INFO     Training average positive_sample_loss at step 441400: 0.229200\n",
      "2022-11-08 18:06:15,371 INFO     Training average negative_sample_loss at step 441400: 0.174264\n",
      "2022-11-08 18:06:15,372 INFO     Training average loss at step 441400: 0.201732\n",
      "2022-11-08 18:06:24,903 INFO     Training average positive_sample_loss at step 441500: 0.219731\n",
      "2022-11-08 18:06:24,903 INFO     Training average negative_sample_loss at step 441500: 0.171647\n",
      "2022-11-08 18:06:24,903 INFO     Training average loss at step 441500: 0.195689\n",
      "2022-11-08 18:06:34,435 INFO     Training average positive_sample_loss at step 441600: 0.217662\n",
      "2022-11-08 18:06:34,435 INFO     Training average negative_sample_loss at step 441600: 0.173220\n",
      "2022-11-08 18:06:34,435 INFO     Training average loss at step 441600: 0.195441\n",
      "2022-11-08 18:06:43,961 INFO     Training average positive_sample_loss at step 441700: 0.236269\n",
      "2022-11-08 18:06:43,961 INFO     Training average negative_sample_loss at step 441700: 0.166356\n",
      "2022-11-08 18:06:43,961 INFO     Training average loss at step 441700: 0.201313\n",
      "2022-11-08 18:06:53,490 INFO     Training average positive_sample_loss at step 441800: 0.224679\n",
      "2022-11-08 18:06:53,490 INFO     Training average negative_sample_loss at step 441800: 0.174848\n",
      "2022-11-08 18:06:53,490 INFO     Training average loss at step 441800: 0.199763\n",
      "2022-11-08 18:07:03,020 INFO     Training average positive_sample_loss at step 441900: 0.231314\n",
      "2022-11-08 18:07:03,020 INFO     Training average negative_sample_loss at step 441900: 0.168718\n",
      "2022-11-08 18:07:03,020 INFO     Training average loss at step 441900: 0.200016\n",
      "2022-11-08 18:07:12,553 INFO     Training average positive_sample_loss at step 442000: 0.224683\n",
      "2022-11-08 18:07:12,553 INFO     Training average negative_sample_loss at step 442000: 0.176970\n",
      "2022-11-08 18:07:12,553 INFO     Training average loss at step 442000: 0.200826\n",
      "2022-11-08 18:07:22,082 INFO     Training average positive_sample_loss at step 442100: 0.226390\n",
      "2022-11-08 18:07:22,082 INFO     Training average negative_sample_loss at step 442100: 0.168449\n",
      "2022-11-08 18:07:22,082 INFO     Training average loss at step 442100: 0.197420\n",
      "2022-11-08 18:07:31,607 INFO     Training average positive_sample_loss at step 442200: 0.218935\n",
      "2022-11-08 18:07:31,608 INFO     Training average negative_sample_loss at step 442200: 0.167292\n",
      "2022-11-08 18:07:31,608 INFO     Training average loss at step 442200: 0.193113\n",
      "2022-11-08 18:07:41,139 INFO     Training average positive_sample_loss at step 442300: 0.227506\n",
      "2022-11-08 18:07:41,139 INFO     Training average negative_sample_loss at step 442300: 0.173167\n",
      "2022-11-08 18:07:41,139 INFO     Training average loss at step 442300: 0.200336\n",
      "2022-11-08 18:07:50,668 INFO     Training average positive_sample_loss at step 442400: 0.223111\n",
      "2022-11-08 18:07:50,668 INFO     Training average negative_sample_loss at step 442400: 0.168979\n",
      "2022-11-08 18:07:50,668 INFO     Training average loss at step 442400: 0.196045\n",
      "2022-11-08 18:08:00,198 INFO     Training average positive_sample_loss at step 442500: 0.221677\n",
      "2022-11-08 18:08:00,198 INFO     Training average negative_sample_loss at step 442500: 0.171785\n",
      "2022-11-08 18:08:00,198 INFO     Training average loss at step 442500: 0.196731\n",
      "2022-11-08 18:08:09,729 INFO     Training average positive_sample_loss at step 442600: 0.237459\n",
      "2022-11-08 18:08:09,729 INFO     Training average negative_sample_loss at step 442600: 0.172704\n",
      "2022-11-08 18:08:09,729 INFO     Training average loss at step 442600: 0.205081\n",
      "2022-11-08 18:08:19,256 INFO     Training average positive_sample_loss at step 442700: 0.227673\n",
      "2022-11-08 18:08:19,256 INFO     Training average negative_sample_loss at step 442700: 0.167793\n",
      "2022-11-08 18:08:19,256 INFO     Training average loss at step 442700: 0.197733\n",
      "2022-11-08 18:08:28,782 INFO     Training average positive_sample_loss at step 442800: 0.222653\n",
      "2022-11-08 18:08:28,782 INFO     Training average negative_sample_loss at step 442800: 0.175277\n",
      "2022-11-08 18:08:28,782 INFO     Training average loss at step 442800: 0.198965\n",
      "2022-11-08 18:08:38,311 INFO     Training average positive_sample_loss at step 442900: 0.222248\n",
      "2022-11-08 18:08:38,312 INFO     Training average negative_sample_loss at step 442900: 0.171340\n",
      "2022-11-08 18:08:38,312 INFO     Training average loss at step 442900: 0.196794\n",
      "2022-11-08 18:08:47,839 INFO     Training average positive_sample_loss at step 443000: 0.220336\n",
      "2022-11-08 18:08:47,839 INFO     Training average negative_sample_loss at step 443000: 0.174363\n",
      "2022-11-08 18:08:47,839 INFO     Training average loss at step 443000: 0.197349\n",
      "2022-11-08 18:08:57,368 INFO     Training average positive_sample_loss at step 443100: 0.219663\n",
      "2022-11-08 18:08:57,368 INFO     Training average negative_sample_loss at step 443100: 0.168613\n",
      "2022-11-08 18:08:57,368 INFO     Training average loss at step 443100: 0.194138\n",
      "2022-11-08 18:09:07,357 INFO     Training average positive_sample_loss at step 443200: 0.224303\n",
      "2022-11-08 18:09:07,357 INFO     Training average negative_sample_loss at step 443200: 0.176833\n",
      "2022-11-08 18:09:07,357 INFO     Training average loss at step 443200: 0.200568\n",
      "2022-11-08 18:09:18,019 INFO     Training average positive_sample_loss at step 443300: 0.224641\n",
      "2022-11-08 18:09:18,019 INFO     Training average negative_sample_loss at step 443300: 0.176693\n",
      "2022-11-08 18:09:18,019 INFO     Training average loss at step 443300: 0.200667\n",
      "2022-11-08 18:09:28,186 INFO     Training average positive_sample_loss at step 443400: 0.215617\n",
      "2022-11-08 18:09:28,186 INFO     Training average negative_sample_loss at step 443400: 0.177100\n",
      "2022-11-08 18:09:28,186 INFO     Training average loss at step 443400: 0.196358\n",
      "2022-11-08 18:09:37,715 INFO     Training average positive_sample_loss at step 443500: 0.232963\n",
      "2022-11-08 18:09:37,715 INFO     Training average negative_sample_loss at step 443500: 0.179110\n",
      "2022-11-08 18:09:37,715 INFO     Training average loss at step 443500: 0.206037\n",
      "2022-11-08 18:09:47,237 INFO     Training average positive_sample_loss at step 443600: 0.218751\n",
      "2022-11-08 18:09:47,237 INFO     Training average negative_sample_loss at step 443600: 0.170459\n",
      "2022-11-08 18:09:47,237 INFO     Training average loss at step 443600: 0.194605\n",
      "2022-11-08 18:09:56,766 INFO     Training average positive_sample_loss at step 443700: 0.221895\n",
      "2022-11-08 18:09:56,766 INFO     Training average negative_sample_loss at step 443700: 0.173317\n",
      "2022-11-08 18:09:56,766 INFO     Training average loss at step 443700: 0.197606\n",
      "2022-11-08 18:10:06,296 INFO     Training average positive_sample_loss at step 443800: 0.224602\n",
      "2022-11-08 18:10:06,296 INFO     Training average negative_sample_loss at step 443800: 0.171151\n",
      "2022-11-08 18:10:06,296 INFO     Training average loss at step 443800: 0.197876\n",
      "2022-11-08 18:10:15,824 INFO     Training average positive_sample_loss at step 443900: 0.228142\n",
      "2022-11-08 18:10:15,824 INFO     Training average negative_sample_loss at step 443900: 0.172176\n",
      "2022-11-08 18:10:15,824 INFO     Training average loss at step 443900: 0.200159\n",
      "2022-11-08 18:10:25,353 INFO     Training average positive_sample_loss at step 444000: 0.224973\n",
      "2022-11-08 18:10:25,353 INFO     Training average negative_sample_loss at step 444000: 0.175155\n",
      "2022-11-08 18:10:25,353 INFO     Training average loss at step 444000: 0.200064\n",
      "2022-11-08 18:10:34,882 INFO     Training average positive_sample_loss at step 444100: 0.222824\n",
      "2022-11-08 18:10:34,882 INFO     Training average negative_sample_loss at step 444100: 0.169501\n",
      "2022-11-08 18:10:34,882 INFO     Training average loss at step 444100: 0.196162\n",
      "2022-11-08 18:10:44,409 INFO     Training average positive_sample_loss at step 444200: 0.219293\n",
      "2022-11-08 18:10:44,409 INFO     Training average negative_sample_loss at step 444200: 0.169334\n",
      "2022-11-08 18:10:44,409 INFO     Training average loss at step 444200: 0.194314\n",
      "2022-11-08 18:10:53,937 INFO     Training average positive_sample_loss at step 444300: 0.218788\n",
      "2022-11-08 18:10:53,937 INFO     Training average negative_sample_loss at step 444300: 0.173199\n",
      "2022-11-08 18:10:53,937 INFO     Training average loss at step 444300: 0.195993\n",
      "2022-11-08 18:11:03,465 INFO     Training average positive_sample_loss at step 444400: 0.214098\n",
      "2022-11-08 18:11:03,465 INFO     Training average negative_sample_loss at step 444400: 0.170737\n",
      "2022-11-08 18:11:03,465 INFO     Training average loss at step 444400: 0.192418\n",
      "2022-11-08 18:11:12,994 INFO     Training average positive_sample_loss at step 444500: 0.224664\n",
      "2022-11-08 18:11:12,994 INFO     Training average negative_sample_loss at step 444500: 0.172512\n",
      "2022-11-08 18:11:12,994 INFO     Training average loss at step 444500: 0.198588\n",
      "2022-11-08 18:11:21,842 INFO     Training average positive_sample_loss at step 444600: 0.217064\n",
      "2022-11-08 18:11:21,842 INFO     Training average negative_sample_loss at step 444600: 0.174255\n",
      "2022-11-08 18:11:21,842 INFO     Training average loss at step 444600: 0.195660\n",
      "2022-11-08 18:11:31,375 INFO     Training average positive_sample_loss at step 444700: 0.236575\n",
      "2022-11-08 18:11:31,375 INFO     Training average negative_sample_loss at step 444700: 0.172512\n",
      "2022-11-08 18:11:31,375 INFO     Training average loss at step 444700: 0.204544\n",
      "2022-11-08 18:11:40,907 INFO     Training average positive_sample_loss at step 444800: 0.232002\n",
      "2022-11-08 18:11:40,907 INFO     Training average negative_sample_loss at step 444800: 0.167268\n",
      "2022-11-08 18:11:40,907 INFO     Training average loss at step 444800: 0.199635\n",
      "2022-11-08 18:11:50,434 INFO     Training average positive_sample_loss at step 444900: 0.229529\n",
      "2022-11-08 18:11:50,434 INFO     Training average negative_sample_loss at step 444900: 0.171012\n",
      "2022-11-08 18:11:50,434 INFO     Training average loss at step 444900: 0.200271\n",
      "2022-11-08 18:11:59,962 INFO     Training average positive_sample_loss at step 445000: 0.222151\n",
      "2022-11-08 18:11:59,962 INFO     Training average negative_sample_loss at step 445000: 0.177070\n",
      "2022-11-08 18:11:59,962 INFO     Training average loss at step 445000: 0.199610\n",
      "2022-11-08 18:12:08,807 INFO     Training average positive_sample_loss at step 445100: 0.221511\n",
      "2022-11-08 18:12:08,807 INFO     Training average negative_sample_loss at step 445100: 0.174510\n",
      "2022-11-08 18:12:08,807 INFO     Training average loss at step 445100: 0.198011\n",
      "2022-11-08 18:12:18,330 INFO     Training average positive_sample_loss at step 445200: 0.234004\n",
      "2022-11-08 18:12:18,330 INFO     Training average negative_sample_loss at step 445200: 0.172858\n",
      "2022-11-08 18:12:18,330 INFO     Training average loss at step 445200: 0.203431\n",
      "2022-11-08 18:12:27,853 INFO     Training average positive_sample_loss at step 445300: 0.219705\n",
      "2022-11-08 18:12:27,853 INFO     Training average negative_sample_loss at step 445300: 0.170288\n",
      "2022-11-08 18:12:27,853 INFO     Training average loss at step 445300: 0.194997\n",
      "2022-11-08 18:12:37,377 INFO     Training average positive_sample_loss at step 445400: 0.219860\n",
      "2022-11-08 18:12:37,377 INFO     Training average negative_sample_loss at step 445400: 0.172056\n",
      "2022-11-08 18:12:37,377 INFO     Training average loss at step 445400: 0.195958\n",
      "2022-11-08 18:12:46,899 INFO     Training average positive_sample_loss at step 445500: 0.231061\n",
      "2022-11-08 18:12:46,899 INFO     Training average negative_sample_loss at step 445500: 0.173361\n",
      "2022-11-08 18:12:46,899 INFO     Training average loss at step 445500: 0.202211\n",
      "2022-11-08 18:12:56,421 INFO     Training average positive_sample_loss at step 445600: 0.224315\n",
      "2022-11-08 18:12:56,421 INFO     Training average negative_sample_loss at step 445600: 0.168725\n",
      "2022-11-08 18:12:56,421 INFO     Training average loss at step 445600: 0.196520\n",
      "2022-11-08 18:13:05,947 INFO     Training average positive_sample_loss at step 445700: 0.220606\n",
      "2022-11-08 18:13:05,947 INFO     Training average negative_sample_loss at step 445700: 0.171324\n",
      "2022-11-08 18:13:05,947 INFO     Training average loss at step 445700: 0.195965\n",
      "2022-11-08 18:13:15,476 INFO     Training average positive_sample_loss at step 445800: 0.219314\n",
      "2022-11-08 18:13:15,476 INFO     Training average negative_sample_loss at step 445800: 0.174385\n",
      "2022-11-08 18:13:15,476 INFO     Training average loss at step 445800: 0.196849\n",
      "2022-11-08 18:13:24,998 INFO     Training average positive_sample_loss at step 445900: 0.238038\n",
      "2022-11-08 18:13:24,998 INFO     Training average negative_sample_loss at step 445900: 0.172151\n",
      "2022-11-08 18:13:24,998 INFO     Training average loss at step 445900: 0.205095\n",
      "2022-11-08 18:13:34,523 INFO     Training average positive_sample_loss at step 446000: 0.219748\n",
      "2022-11-08 18:13:34,524 INFO     Training average negative_sample_loss at step 446000: 0.169558\n",
      "2022-11-08 18:13:34,524 INFO     Training average loss at step 446000: 0.194653\n",
      "2022-11-08 18:13:44,049 INFO     Training average positive_sample_loss at step 446100: 0.220813\n",
      "2022-11-08 18:13:44,049 INFO     Training average negative_sample_loss at step 446100: 0.176066\n",
      "2022-11-08 18:13:44,049 INFO     Training average loss at step 446100: 0.198440\n",
      "2022-11-08 18:13:53,571 INFO     Training average positive_sample_loss at step 446200: 0.221149\n",
      "2022-11-08 18:13:53,572 INFO     Training average negative_sample_loss at step 446200: 0.170673\n",
      "2022-11-08 18:13:53,572 INFO     Training average loss at step 446200: 0.195911\n",
      "2022-11-08 18:14:03,101 INFO     Training average positive_sample_loss at step 446300: 0.221723\n",
      "2022-11-08 18:14:03,101 INFO     Training average negative_sample_loss at step 446300: 0.170184\n",
      "2022-11-08 18:14:03,101 INFO     Training average loss at step 446300: 0.195953\n",
      "2022-11-08 18:14:12,626 INFO     Training average positive_sample_loss at step 446400: 0.221517\n",
      "2022-11-08 18:14:12,626 INFO     Training average negative_sample_loss at step 446400: 0.171283\n",
      "2022-11-08 18:14:12,626 INFO     Training average loss at step 446400: 0.196400\n",
      "2022-11-08 18:14:22,148 INFO     Training average positive_sample_loss at step 446500: 0.225260\n",
      "2022-11-08 18:14:22,148 INFO     Training average negative_sample_loss at step 446500: 0.166366\n",
      "2022-11-08 18:14:22,148 INFO     Training average loss at step 446500: 0.195813\n",
      "2022-11-08 18:14:31,677 INFO     Training average positive_sample_loss at step 446600: 0.224739\n",
      "2022-11-08 18:14:31,677 INFO     Training average negative_sample_loss at step 446600: 0.171065\n",
      "2022-11-08 18:14:31,677 INFO     Training average loss at step 446600: 0.197902\n",
      "2022-11-08 18:14:41,203 INFO     Training average positive_sample_loss at step 446700: 0.218315\n",
      "2022-11-08 18:14:41,203 INFO     Training average negative_sample_loss at step 446700: 0.173591\n",
      "2022-11-08 18:14:41,203 INFO     Training average loss at step 446700: 0.195953\n",
      "2022-11-08 18:14:50,725 INFO     Training average positive_sample_loss at step 446800: 0.226141\n",
      "2022-11-08 18:14:50,725 INFO     Training average negative_sample_loss at step 446800: 0.169356\n",
      "2022-11-08 18:14:50,725 INFO     Training average loss at step 446800: 0.197749\n",
      "2022-11-08 18:15:00,253 INFO     Training average positive_sample_loss at step 446900: 0.224578\n",
      "2022-11-08 18:15:00,253 INFO     Training average negative_sample_loss at step 446900: 0.176593\n",
      "2022-11-08 18:15:00,253 INFO     Training average loss at step 446900: 0.200585\n",
      "2022-11-08 18:15:09,776 INFO     Training average positive_sample_loss at step 447000: 0.221533\n",
      "2022-11-08 18:15:09,776 INFO     Training average negative_sample_loss at step 447000: 0.172146\n",
      "2022-11-08 18:15:09,776 INFO     Training average loss at step 447000: 0.196839\n",
      "2022-11-08 18:15:19,300 INFO     Training average positive_sample_loss at step 447100: 0.218914\n",
      "2022-11-08 18:15:19,300 INFO     Training average negative_sample_loss at step 447100: 0.172394\n",
      "2022-11-08 18:15:19,300 INFO     Training average loss at step 447100: 0.195654\n",
      "2022-11-08 18:15:28,830 INFO     Training average positive_sample_loss at step 447200: 0.224930\n",
      "2022-11-08 18:15:28,830 INFO     Training average negative_sample_loss at step 447200: 0.175407\n",
      "2022-11-08 18:15:28,830 INFO     Training average loss at step 447200: 0.200169\n",
      "2022-11-08 18:15:38,355 INFO     Training average positive_sample_loss at step 447300: 0.225005\n",
      "2022-11-08 18:15:38,355 INFO     Training average negative_sample_loss at step 447300: 0.174587\n",
      "2022-11-08 18:15:38,355 INFO     Training average loss at step 447300: 0.199796\n",
      "2022-11-08 18:15:47,879 INFO     Training average positive_sample_loss at step 447400: 0.209556\n",
      "2022-11-08 18:15:47,879 INFO     Training average negative_sample_loss at step 447400: 0.171144\n",
      "2022-11-08 18:15:47,879 INFO     Training average loss at step 447400: 0.190350\n",
      "2022-11-08 18:15:57,410 INFO     Training average positive_sample_loss at step 447500: 0.234459\n",
      "2022-11-08 18:15:57,410 INFO     Training average negative_sample_loss at step 447500: 0.170013\n",
      "2022-11-08 18:15:57,410 INFO     Training average loss at step 447500: 0.202236\n",
      "2022-11-08 18:16:06,933 INFO     Training average positive_sample_loss at step 447600: 0.220426\n",
      "2022-11-08 18:16:06,933 INFO     Training average negative_sample_loss at step 447600: 0.169800\n",
      "2022-11-08 18:16:06,933 INFO     Training average loss at step 447600: 0.195113\n",
      "2022-11-08 18:16:16,458 INFO     Training average positive_sample_loss at step 447700: 0.217433\n",
      "2022-11-08 18:16:16,458 INFO     Training average negative_sample_loss at step 447700: 0.172005\n",
      "2022-11-08 18:16:16,458 INFO     Training average loss at step 447700: 0.194719\n",
      "2022-11-08 18:16:25,983 INFO     Training average positive_sample_loss at step 447800: 0.221558\n",
      "2022-11-08 18:16:25,983 INFO     Training average negative_sample_loss at step 447800: 0.172427\n",
      "2022-11-08 18:16:25,983 INFO     Training average loss at step 447800: 0.196993\n",
      "2022-11-08 18:16:37,048 INFO     Training average positive_sample_loss at step 447900: 0.229497\n",
      "2022-11-08 18:16:37,048 INFO     Training average negative_sample_loss at step 447900: 0.173909\n",
      "2022-11-08 18:16:37,048 INFO     Training average loss at step 447900: 0.201703\n",
      "2022-11-08 18:16:46,871 INFO     Training average positive_sample_loss at step 448000: 0.219562\n",
      "2022-11-08 18:16:46,871 INFO     Training average negative_sample_loss at step 448000: 0.169532\n",
      "2022-11-08 18:16:46,871 INFO     Training average loss at step 448000: 0.194547\n",
      "2022-11-08 18:16:57,075 INFO     Training average positive_sample_loss at step 448100: 0.230467\n",
      "2022-11-08 18:16:57,075 INFO     Training average negative_sample_loss at step 448100: 0.170708\n",
      "2022-11-08 18:16:57,075 INFO     Training average loss at step 448100: 0.200588\n",
      "2022-11-08 18:17:06,598 INFO     Training average positive_sample_loss at step 448200: 0.227860\n",
      "2022-11-08 18:17:06,598 INFO     Training average negative_sample_loss at step 448200: 0.163557\n",
      "2022-11-08 18:17:06,598 INFO     Training average loss at step 448200: 0.195708\n",
      "2022-11-08 18:17:16,122 INFO     Training average positive_sample_loss at step 448300: 0.214390\n",
      "2022-11-08 18:17:16,122 INFO     Training average negative_sample_loss at step 448300: 0.172687\n",
      "2022-11-08 18:17:16,122 INFO     Training average loss at step 448300: 0.193539\n",
      "2022-11-08 18:17:25,646 INFO     Training average positive_sample_loss at step 448400: 0.217252\n",
      "2022-11-08 18:17:25,646 INFO     Training average negative_sample_loss at step 448400: 0.170729\n",
      "2022-11-08 18:17:25,646 INFO     Training average loss at step 448400: 0.193990\n",
      "2022-11-08 18:17:35,167 INFO     Training average positive_sample_loss at step 448500: 0.222297\n",
      "2022-11-08 18:17:35,167 INFO     Training average negative_sample_loss at step 448500: 0.168304\n",
      "2022-11-08 18:17:35,167 INFO     Training average loss at step 448500: 0.195300\n",
      "2022-11-08 18:17:44,689 INFO     Training average positive_sample_loss at step 448600: 0.214102\n",
      "2022-11-08 18:17:44,689 INFO     Training average negative_sample_loss at step 448600: 0.171144\n",
      "2022-11-08 18:17:44,689 INFO     Training average loss at step 448600: 0.192623\n",
      "2022-11-08 18:17:54,216 INFO     Training average positive_sample_loss at step 448700: 0.227184\n",
      "2022-11-08 18:17:54,216 INFO     Training average negative_sample_loss at step 448700: 0.174625\n",
      "2022-11-08 18:17:54,216 INFO     Training average loss at step 448700: 0.200905\n",
      "2022-11-08 18:18:03,741 INFO     Training average positive_sample_loss at step 448800: 0.218703\n",
      "2022-11-08 18:18:03,742 INFO     Training average negative_sample_loss at step 448800: 0.170594\n",
      "2022-11-08 18:18:03,742 INFO     Training average loss at step 448800: 0.194648\n",
      "2022-11-08 18:18:13,264 INFO     Training average positive_sample_loss at step 448900: 0.225897\n",
      "2022-11-08 18:18:13,264 INFO     Training average negative_sample_loss at step 448900: 0.175526\n",
      "2022-11-08 18:18:13,264 INFO     Training average loss at step 448900: 0.200711\n",
      "2022-11-08 18:18:22,788 INFO     Training average positive_sample_loss at step 449000: 0.224588\n",
      "2022-11-08 18:18:22,788 INFO     Training average negative_sample_loss at step 449000: 0.172813\n",
      "2022-11-08 18:18:22,788 INFO     Training average loss at step 449000: 0.198701\n",
      "2022-11-08 18:18:32,315 INFO     Training average positive_sample_loss at step 449100: 0.228838\n",
      "2022-11-08 18:18:32,315 INFO     Training average negative_sample_loss at step 449100: 0.172544\n",
      "2022-11-08 18:18:32,315 INFO     Training average loss at step 449100: 0.200691\n",
      "2022-11-08 18:18:41,840 INFO     Training average positive_sample_loss at step 449200: 0.216506\n",
      "2022-11-08 18:18:41,840 INFO     Training average negative_sample_loss at step 449200: 0.167687\n",
      "2022-11-08 18:18:41,840 INFO     Training average loss at step 449200: 0.192096\n",
      "2022-11-08 18:18:51,363 INFO     Training average positive_sample_loss at step 449300: 0.215196\n",
      "2022-11-08 18:18:51,363 INFO     Training average negative_sample_loss at step 449300: 0.167293\n",
      "2022-11-08 18:18:51,363 INFO     Training average loss at step 449300: 0.191244\n",
      "2022-11-08 18:19:00,889 INFO     Training average positive_sample_loss at step 449400: 0.228922\n",
      "2022-11-08 18:19:00,889 INFO     Training average negative_sample_loss at step 449400: 0.173025\n",
      "2022-11-08 18:19:00,889 INFO     Training average loss at step 449400: 0.200974\n",
      "2022-11-08 18:19:10,412 INFO     Training average positive_sample_loss at step 449500: 0.225140\n",
      "2022-11-08 18:19:10,412 INFO     Training average negative_sample_loss at step 449500: 0.174258\n",
      "2022-11-08 18:19:10,412 INFO     Training average loss at step 449500: 0.199699\n",
      "2022-11-08 18:19:19,935 INFO     Training average positive_sample_loss at step 449600: 0.224156\n",
      "2022-11-08 18:19:19,935 INFO     Training average negative_sample_loss at step 449600: 0.173268\n",
      "2022-11-08 18:19:19,935 INFO     Training average loss at step 449600: 0.198712\n",
      "2022-11-08 18:19:29,464 INFO     Training average positive_sample_loss at step 449700: 0.222491\n",
      "2022-11-08 18:19:29,464 INFO     Training average negative_sample_loss at step 449700: 0.172480\n",
      "2022-11-08 18:19:29,464 INFO     Training average loss at step 449700: 0.197486\n",
      "2022-11-08 18:19:38,987 INFO     Training average positive_sample_loss at step 449800: 0.224110\n",
      "2022-11-08 18:19:38,987 INFO     Training average negative_sample_loss at step 449800: 0.170207\n",
      "2022-11-08 18:19:38,987 INFO     Training average loss at step 449800: 0.197158\n",
      "2022-11-08 18:19:48,511 INFO     Training average positive_sample_loss at step 449900: 0.211181\n",
      "2022-11-08 18:19:48,511 INFO     Training average negative_sample_loss at step 449900: 0.172336\n",
      "2022-11-08 18:19:48,511 INFO     Training average loss at step 449900: 0.191759\n",
      "2022-11-08 18:20:00,514 INFO     Training average positive_sample_loss at step 450000: 0.218838\n",
      "2022-11-08 18:20:00,514 INFO     Training average negative_sample_loss at step 450000: 0.174577\n",
      "2022-11-08 18:20:00,514 INFO     Training average loss at step 450000: 0.196708\n",
      "2022-11-08 18:20:10,037 INFO     Training average positive_sample_loss at step 450100: 0.217180\n",
      "2022-11-08 18:20:10,037 INFO     Training average negative_sample_loss at step 450100: 0.173631\n",
      "2022-11-08 18:20:10,037 INFO     Training average loss at step 450100: 0.195405\n",
      "2022-11-08 18:20:19,566 INFO     Training average positive_sample_loss at step 450200: 0.224136\n",
      "2022-11-08 18:20:19,566 INFO     Training average negative_sample_loss at step 450200: 0.168222\n",
      "2022-11-08 18:20:19,566 INFO     Training average loss at step 450200: 0.196179\n",
      "2022-11-08 18:20:29,101 INFO     Training average positive_sample_loss at step 450300: 0.227325\n",
      "2022-11-08 18:20:29,101 INFO     Training average negative_sample_loss at step 450300: 0.169396\n",
      "2022-11-08 18:20:29,101 INFO     Training average loss at step 450300: 0.198360\n",
      "2022-11-08 18:20:38,632 INFO     Training average positive_sample_loss at step 450400: 0.218937\n",
      "2022-11-08 18:20:38,632 INFO     Training average negative_sample_loss at step 450400: 0.177015\n",
      "2022-11-08 18:20:38,632 INFO     Training average loss at step 450400: 0.197976\n",
      "2022-11-08 18:20:48,159 INFO     Training average positive_sample_loss at step 450500: 0.221130\n",
      "2022-11-08 18:20:48,159 INFO     Training average negative_sample_loss at step 450500: 0.168487\n",
      "2022-11-08 18:20:48,159 INFO     Training average loss at step 450500: 0.194808\n",
      "2022-11-08 18:20:57,020 INFO     Training average positive_sample_loss at step 450600: 0.220000\n",
      "2022-11-08 18:20:57,020 INFO     Training average negative_sample_loss at step 450600: 0.168261\n",
      "2022-11-08 18:20:57,020 INFO     Training average loss at step 450600: 0.194130\n",
      "2022-11-08 18:21:06,550 INFO     Training average positive_sample_loss at step 450700: 0.229058\n",
      "2022-11-08 18:21:06,550 INFO     Training average negative_sample_loss at step 450700: 0.173938\n",
      "2022-11-08 18:21:06,550 INFO     Training average loss at step 450700: 0.201498\n",
      "2022-11-08 18:21:16,078 INFO     Training average positive_sample_loss at step 450800: 0.222947\n",
      "2022-11-08 18:21:16,078 INFO     Training average negative_sample_loss at step 450800: 0.165780\n",
      "2022-11-08 18:21:16,078 INFO     Training average loss at step 450800: 0.194363\n",
      "2022-11-08 18:21:25,605 INFO     Training average positive_sample_loss at step 450900: 0.228790\n",
      "2022-11-08 18:21:25,605 INFO     Training average negative_sample_loss at step 450900: 0.171903\n",
      "2022-11-08 18:21:25,605 INFO     Training average loss at step 450900: 0.200347\n",
      "2022-11-08 18:21:35,133 INFO     Training average positive_sample_loss at step 451000: 0.218378\n",
      "2022-11-08 18:21:35,133 INFO     Training average negative_sample_loss at step 451000: 0.163664\n",
      "2022-11-08 18:21:35,133 INFO     Training average loss at step 451000: 0.191021\n",
      "2022-11-08 18:21:44,658 INFO     Training average positive_sample_loss at step 451100: 0.219676\n",
      "2022-11-08 18:21:44,658 INFO     Training average negative_sample_loss at step 451100: 0.174133\n",
      "2022-11-08 18:21:44,658 INFO     Training average loss at step 451100: 0.196905\n",
      "2022-11-08 18:21:54,189 INFO     Training average positive_sample_loss at step 451200: 0.212558\n",
      "2022-11-08 18:21:54,189 INFO     Training average negative_sample_loss at step 451200: 0.169059\n",
      "2022-11-08 18:21:54,189 INFO     Training average loss at step 451200: 0.190809\n",
      "2022-11-08 18:22:03,717 INFO     Training average positive_sample_loss at step 451300: 0.232640\n",
      "2022-11-08 18:22:03,717 INFO     Training average negative_sample_loss at step 451300: 0.171030\n",
      "2022-11-08 18:22:03,717 INFO     Training average loss at step 451300: 0.201835\n",
      "2022-11-08 18:22:13,241 INFO     Training average positive_sample_loss at step 451400: 0.220977\n",
      "2022-11-08 18:22:13,241 INFO     Training average negative_sample_loss at step 451400: 0.165912\n",
      "2022-11-08 18:22:13,241 INFO     Training average loss at step 451400: 0.193444\n",
      "2022-11-08 18:22:22,770 INFO     Training average positive_sample_loss at step 451500: 0.226811\n",
      "2022-11-08 18:22:22,770 INFO     Training average negative_sample_loss at step 451500: 0.170930\n",
      "2022-11-08 18:22:22,770 INFO     Training average loss at step 451500: 0.198870\n",
      "2022-11-08 18:22:32,297 INFO     Training average positive_sample_loss at step 451600: 0.224766\n",
      "2022-11-08 18:22:32,298 INFO     Training average negative_sample_loss at step 451600: 0.169527\n",
      "2022-11-08 18:22:32,298 INFO     Training average loss at step 451600: 0.197147\n",
      "2022-11-08 18:22:41,823 INFO     Training average positive_sample_loss at step 451700: 0.215999\n",
      "2022-11-08 18:22:41,823 INFO     Training average negative_sample_loss at step 451700: 0.165021\n",
      "2022-11-08 18:22:41,823 INFO     Training average loss at step 451700: 0.190510\n",
      "2022-11-08 18:22:51,353 INFO     Training average positive_sample_loss at step 451800: 0.229533\n",
      "2022-11-08 18:22:51,353 INFO     Training average negative_sample_loss at step 451800: 0.172703\n",
      "2022-11-08 18:22:51,353 INFO     Training average loss at step 451800: 0.201118\n",
      "2022-11-08 18:23:00,880 INFO     Training average positive_sample_loss at step 451900: 0.214578\n",
      "2022-11-08 18:23:00,880 INFO     Training average negative_sample_loss at step 451900: 0.172523\n",
      "2022-11-08 18:23:00,880 INFO     Training average loss at step 451900: 0.193551\n",
      "2022-11-08 18:23:10,405 INFO     Training average positive_sample_loss at step 452000: 0.225573\n",
      "2022-11-08 18:23:10,406 INFO     Training average negative_sample_loss at step 452000: 0.168314\n",
      "2022-11-08 18:23:10,406 INFO     Training average loss at step 452000: 0.196943\n",
      "2022-11-08 18:23:19,934 INFO     Training average positive_sample_loss at step 452100: 0.223245\n",
      "2022-11-08 18:23:19,935 INFO     Training average negative_sample_loss at step 452100: 0.174620\n",
      "2022-11-08 18:23:19,935 INFO     Training average loss at step 452100: 0.198933\n",
      "2022-11-08 18:23:29,463 INFO     Training average positive_sample_loss at step 452200: 0.228963\n",
      "2022-11-08 18:23:29,463 INFO     Training average negative_sample_loss at step 452200: 0.170197\n",
      "2022-11-08 18:23:29,463 INFO     Training average loss at step 452200: 0.199580\n",
      "2022-11-08 18:23:38,993 INFO     Training average positive_sample_loss at step 452300: 0.227615\n",
      "2022-11-08 18:23:38,993 INFO     Training average negative_sample_loss at step 452300: 0.173949\n",
      "2022-11-08 18:23:38,993 INFO     Training average loss at step 452300: 0.200782\n",
      "2022-11-08 18:23:48,521 INFO     Training average positive_sample_loss at step 452400: 0.217029\n",
      "2022-11-08 18:23:48,521 INFO     Training average negative_sample_loss at step 452400: 0.170218\n",
      "2022-11-08 18:23:48,521 INFO     Training average loss at step 452400: 0.193623\n",
      "2022-11-08 18:23:58,046 INFO     Training average positive_sample_loss at step 452500: 0.224987\n",
      "2022-11-08 18:23:58,046 INFO     Training average negative_sample_loss at step 452500: 0.168267\n",
      "2022-11-08 18:23:58,046 INFO     Training average loss at step 452500: 0.196627\n",
      "2022-11-08 18:24:08,920 INFO     Training average positive_sample_loss at step 452600: 0.220646\n",
      "2022-11-08 18:24:08,920 INFO     Training average negative_sample_loss at step 452600: 0.180185\n",
      "2022-11-08 18:24:08,920 INFO     Training average loss at step 452600: 0.200416\n",
      "2022-11-08 18:24:18,781 INFO     Training average positive_sample_loss at step 452700: 0.215433\n",
      "2022-11-08 18:24:18,781 INFO     Training average negative_sample_loss at step 452700: 0.179591\n",
      "2022-11-08 18:24:18,781 INFO     Training average loss at step 452700: 0.197512\n",
      "2022-11-08 18:24:29,024 INFO     Training average positive_sample_loss at step 452800: 0.230565\n",
      "2022-11-08 18:24:29,024 INFO     Training average negative_sample_loss at step 452800: 0.170778\n",
      "2022-11-08 18:24:29,024 INFO     Training average loss at step 452800: 0.200671\n",
      "2022-11-08 18:24:38,549 INFO     Training average positive_sample_loss at step 452900: 0.221766\n",
      "2022-11-08 18:24:38,549 INFO     Training average negative_sample_loss at step 452900: 0.174043\n",
      "2022-11-08 18:24:38,549 INFO     Training average loss at step 452900: 0.197905\n",
      "2022-11-08 18:24:48,078 INFO     Training average positive_sample_loss at step 453000: 0.218480\n",
      "2022-11-08 18:24:48,078 INFO     Training average negative_sample_loss at step 453000: 0.169409\n",
      "2022-11-08 18:24:48,078 INFO     Training average loss at step 453000: 0.193944\n",
      "2022-11-08 18:24:57,601 INFO     Training average positive_sample_loss at step 453100: 0.224958\n",
      "2022-11-08 18:24:57,601 INFO     Training average negative_sample_loss at step 453100: 0.169882\n",
      "2022-11-08 18:24:57,601 INFO     Training average loss at step 453100: 0.197420\n",
      "2022-11-08 18:25:07,130 INFO     Training average positive_sample_loss at step 453200: 0.220347\n",
      "2022-11-08 18:25:07,130 INFO     Training average negative_sample_loss at step 453200: 0.168883\n",
      "2022-11-08 18:25:07,130 INFO     Training average loss at step 453200: 0.194615\n",
      "2022-11-08 18:25:16,656 INFO     Training average positive_sample_loss at step 453300: 0.217777\n",
      "2022-11-08 18:25:16,656 INFO     Training average negative_sample_loss at step 453300: 0.173392\n",
      "2022-11-08 18:25:16,657 INFO     Training average loss at step 453300: 0.195584\n",
      "2022-11-08 18:25:26,182 INFO     Training average positive_sample_loss at step 453400: 0.217603\n",
      "2022-11-08 18:25:26,182 INFO     Training average negative_sample_loss at step 453400: 0.172569\n",
      "2022-11-08 18:25:26,182 INFO     Training average loss at step 453400: 0.195086\n",
      "2022-11-08 18:25:35,710 INFO     Training average positive_sample_loss at step 453500: 0.227103\n",
      "2022-11-08 18:25:35,710 INFO     Training average negative_sample_loss at step 453500: 0.171754\n",
      "2022-11-08 18:25:35,710 INFO     Training average loss at step 453500: 0.199428\n",
      "2022-11-08 18:25:45,237 INFO     Training average positive_sample_loss at step 453600: 0.225347\n",
      "2022-11-08 18:25:45,237 INFO     Training average negative_sample_loss at step 453600: 0.173439\n",
      "2022-11-08 18:25:45,237 INFO     Training average loss at step 453600: 0.199393\n",
      "2022-11-08 18:25:54,763 INFO     Training average positive_sample_loss at step 453700: 0.213237\n",
      "2022-11-08 18:25:54,763 INFO     Training average negative_sample_loss at step 453700: 0.169765\n",
      "2022-11-08 18:25:54,763 INFO     Training average loss at step 453700: 0.191501\n",
      "2022-11-08 18:26:04,293 INFO     Training average positive_sample_loss at step 453800: 0.220265\n",
      "2022-11-08 18:26:04,293 INFO     Training average negative_sample_loss at step 453800: 0.174128\n",
      "2022-11-08 18:26:04,293 INFO     Training average loss at step 453800: 0.197196\n",
      "2022-11-08 18:26:13,819 INFO     Training average positive_sample_loss at step 453900: 0.226279\n",
      "2022-11-08 18:26:13,819 INFO     Training average negative_sample_loss at step 453900: 0.166982\n",
      "2022-11-08 18:26:13,819 INFO     Training average loss at step 453900: 0.196630\n",
      "2022-11-08 18:26:23,346 INFO     Training average positive_sample_loss at step 454000: 0.215548\n",
      "2022-11-08 18:26:23,346 INFO     Training average negative_sample_loss at step 454000: 0.166851\n",
      "2022-11-08 18:26:23,346 INFO     Training average loss at step 454000: 0.191200\n",
      "2022-11-08 18:26:32,877 INFO     Training average positive_sample_loss at step 454100: 0.216853\n",
      "2022-11-08 18:26:32,877 INFO     Training average negative_sample_loss at step 454100: 0.170621\n",
      "2022-11-08 18:26:32,877 INFO     Training average loss at step 454100: 0.193737\n",
      "2022-11-08 18:26:42,404 INFO     Training average positive_sample_loss at step 454200: 0.227152\n",
      "2022-11-08 18:26:42,404 INFO     Training average negative_sample_loss at step 454200: 0.167329\n",
      "2022-11-08 18:26:42,405 INFO     Training average loss at step 454200: 0.197240\n",
      "2022-11-08 18:26:51,933 INFO     Training average positive_sample_loss at step 454300: 0.218711\n",
      "2022-11-08 18:26:51,933 INFO     Training average negative_sample_loss at step 454300: 0.171728\n",
      "2022-11-08 18:26:51,933 INFO     Training average loss at step 454300: 0.195219\n",
      "2022-11-08 18:27:01,461 INFO     Training average positive_sample_loss at step 454400: 0.220610\n",
      "2022-11-08 18:27:01,461 INFO     Training average negative_sample_loss at step 454400: 0.167529\n",
      "2022-11-08 18:27:01,461 INFO     Training average loss at step 454400: 0.194070\n",
      "2022-11-08 18:27:10,988 INFO     Training average positive_sample_loss at step 454500: 0.233222\n",
      "2022-11-08 18:27:10,988 INFO     Training average negative_sample_loss at step 454500: 0.172102\n",
      "2022-11-08 18:27:10,988 INFO     Training average loss at step 454500: 0.202662\n",
      "2022-11-08 18:27:20,514 INFO     Training average positive_sample_loss at step 454600: 0.219224\n",
      "2022-11-08 18:27:20,514 INFO     Training average negative_sample_loss at step 454600: 0.166534\n",
      "2022-11-08 18:27:20,515 INFO     Training average loss at step 454600: 0.192879\n",
      "2022-11-08 18:27:30,042 INFO     Training average positive_sample_loss at step 454700: 0.218564\n",
      "2022-11-08 18:27:30,042 INFO     Training average negative_sample_loss at step 454700: 0.170023\n",
      "2022-11-08 18:27:30,042 INFO     Training average loss at step 454700: 0.194294\n",
      "2022-11-08 18:27:39,569 INFO     Training average positive_sample_loss at step 454800: 0.227993\n",
      "2022-11-08 18:27:39,570 INFO     Training average negative_sample_loss at step 454800: 0.169850\n",
      "2022-11-08 18:27:39,570 INFO     Training average loss at step 454800: 0.198921\n",
      "2022-11-08 18:27:49,097 INFO     Training average positive_sample_loss at step 454900: 0.212112\n",
      "2022-11-08 18:27:49,097 INFO     Training average negative_sample_loss at step 454900: 0.172301\n",
      "2022-11-08 18:27:49,097 INFO     Training average loss at step 454900: 0.192206\n",
      "2022-11-08 18:27:58,623 INFO     Training average positive_sample_loss at step 455000: 0.214880\n",
      "2022-11-08 18:27:58,623 INFO     Training average negative_sample_loss at step 455000: 0.166417\n",
      "2022-11-08 18:27:58,623 INFO     Training average loss at step 455000: 0.190649\n",
      "2022-11-08 18:28:08,153 INFO     Training average positive_sample_loss at step 455100: 0.216963\n",
      "2022-11-08 18:28:08,153 INFO     Training average negative_sample_loss at step 455100: 0.166945\n",
      "2022-11-08 18:28:08,153 INFO     Training average loss at step 455100: 0.191954\n",
      "2022-11-08 18:28:17,678 INFO     Training average positive_sample_loss at step 455200: 0.208564\n",
      "2022-11-08 18:28:17,679 INFO     Training average negative_sample_loss at step 455200: 0.170784\n",
      "2022-11-08 18:28:17,679 INFO     Training average loss at step 455200: 0.189674\n",
      "2022-11-08 18:28:27,203 INFO     Training average positive_sample_loss at step 455300: 0.225067\n",
      "2022-11-08 18:28:27,203 INFO     Training average negative_sample_loss at step 455300: 0.172102\n",
      "2022-11-08 18:28:27,203 INFO     Training average loss at step 455300: 0.198584\n",
      "2022-11-08 18:28:36,735 INFO     Training average positive_sample_loss at step 455400: 0.217921\n",
      "2022-11-08 18:28:36,735 INFO     Training average negative_sample_loss at step 455400: 0.169226\n",
      "2022-11-08 18:28:36,735 INFO     Training average loss at step 455400: 0.193574\n",
      "2022-11-08 18:28:45,585 INFO     Training average positive_sample_loss at step 455500: 0.228404\n",
      "2022-11-08 18:28:45,585 INFO     Training average negative_sample_loss at step 455500: 0.164864\n",
      "2022-11-08 18:28:45,585 INFO     Training average loss at step 455500: 0.196634\n",
      "2022-11-08 18:28:55,105 INFO     Training average positive_sample_loss at step 455600: 0.211569\n",
      "2022-11-08 18:28:55,105 INFO     Training average negative_sample_loss at step 455600: 0.170645\n",
      "2022-11-08 18:28:55,105 INFO     Training average loss at step 455600: 0.191107\n",
      "2022-11-08 18:29:04,628 INFO     Training average positive_sample_loss at step 455700: 0.212904\n",
      "2022-11-08 18:29:04,628 INFO     Training average negative_sample_loss at step 455700: 0.170461\n",
      "2022-11-08 18:29:04,628 INFO     Training average loss at step 455700: 0.191682\n",
      "2022-11-08 18:29:14,153 INFO     Training average positive_sample_loss at step 455800: 0.221310\n",
      "2022-11-08 18:29:14,153 INFO     Training average negative_sample_loss at step 455800: 0.173867\n",
      "2022-11-08 18:29:14,153 INFO     Training average loss at step 455800: 0.197588\n",
      "2022-11-08 18:29:23,677 INFO     Training average positive_sample_loss at step 455900: 0.221143\n",
      "2022-11-08 18:29:23,677 INFO     Training average negative_sample_loss at step 455900: 0.171613\n",
      "2022-11-08 18:29:23,677 INFO     Training average loss at step 455900: 0.196378\n",
      "2022-11-08 18:29:32,859 INFO     Training average positive_sample_loss at step 456000: 0.224209\n",
      "2022-11-08 18:29:32,859 INFO     Training average negative_sample_loss at step 456000: 0.168814\n",
      "2022-11-08 18:29:32,859 INFO     Training average loss at step 456000: 0.196511\n",
      "2022-11-08 18:29:42,009 INFO     Training average positive_sample_loss at step 456100: 0.219017\n",
      "2022-11-08 18:29:42,009 INFO     Training average negative_sample_loss at step 456100: 0.172055\n",
      "2022-11-08 18:29:42,009 INFO     Training average loss at step 456100: 0.195536\n",
      "2022-11-08 18:29:51,533 INFO     Training average positive_sample_loss at step 456200: 0.219402\n",
      "2022-11-08 18:29:51,533 INFO     Training average negative_sample_loss at step 456200: 0.172346\n",
      "2022-11-08 18:29:51,533 INFO     Training average loss at step 456200: 0.195874\n",
      "2022-11-08 18:30:01,060 INFO     Training average positive_sample_loss at step 456300: 0.220775\n",
      "2022-11-08 18:30:01,060 INFO     Training average negative_sample_loss at step 456300: 0.169232\n",
      "2022-11-08 18:30:01,060 INFO     Training average loss at step 456300: 0.195004\n",
      "2022-11-08 18:30:10,586 INFO     Training average positive_sample_loss at step 456400: 0.221546\n",
      "2022-11-08 18:30:10,586 INFO     Training average negative_sample_loss at step 456400: 0.173850\n",
      "2022-11-08 18:30:10,586 INFO     Training average loss at step 456400: 0.197698\n",
      "2022-11-08 18:30:20,113 INFO     Training average positive_sample_loss at step 456500: 0.223040\n",
      "2022-11-08 18:30:20,113 INFO     Training average negative_sample_loss at step 456500: 0.166352\n",
      "2022-11-08 18:30:20,113 INFO     Training average loss at step 456500: 0.194696\n",
      "2022-11-08 18:30:29,640 INFO     Training average positive_sample_loss at step 456600: 0.224527\n",
      "2022-11-08 18:30:29,640 INFO     Training average negative_sample_loss at step 456600: 0.171425\n",
      "2022-11-08 18:30:29,640 INFO     Training average loss at step 456600: 0.197976\n",
      "2022-11-08 18:30:39,165 INFO     Training average positive_sample_loss at step 456700: 0.215862\n",
      "2022-11-08 18:30:39,165 INFO     Training average negative_sample_loss at step 456700: 0.172126\n",
      "2022-11-08 18:30:39,165 INFO     Training average loss at step 456700: 0.193994\n",
      "2022-11-08 18:30:48,690 INFO     Training average positive_sample_loss at step 456800: 0.225052\n",
      "2022-11-08 18:30:48,690 INFO     Training average negative_sample_loss at step 456800: 0.168928\n",
      "2022-11-08 18:30:48,690 INFO     Training average loss at step 456800: 0.196990\n",
      "2022-11-08 18:30:58,216 INFO     Training average positive_sample_loss at step 456900: 0.216624\n",
      "2022-11-08 18:30:58,216 INFO     Training average negative_sample_loss at step 456900: 0.173012\n",
      "2022-11-08 18:30:58,216 INFO     Training average loss at step 456900: 0.194818\n",
      "2022-11-08 18:31:07,743 INFO     Training average positive_sample_loss at step 457000: 0.224837\n",
      "2022-11-08 18:31:07,743 INFO     Training average negative_sample_loss at step 457000: 0.168601\n",
      "2022-11-08 18:31:07,743 INFO     Training average loss at step 457000: 0.196719\n",
      "2022-11-08 18:31:17,269 INFO     Training average positive_sample_loss at step 457100: 0.220963\n",
      "2022-11-08 18:31:17,269 INFO     Training average negative_sample_loss at step 457100: 0.168163\n",
      "2022-11-08 18:31:17,269 INFO     Training average loss at step 457100: 0.194563\n",
      "2022-11-08 18:31:26,791 INFO     Training average positive_sample_loss at step 457200: 0.217353\n",
      "2022-11-08 18:31:26,791 INFO     Training average negative_sample_loss at step 457200: 0.168302\n",
      "2022-11-08 18:31:26,791 INFO     Training average loss at step 457200: 0.192828\n",
      "2022-11-08 18:31:37,684 INFO     Training average positive_sample_loss at step 457300: 0.214959\n",
      "2022-11-08 18:31:37,684 INFO     Training average negative_sample_loss at step 457300: 0.172417\n",
      "2022-11-08 18:31:37,684 INFO     Training average loss at step 457300: 0.193688\n",
      "2022-11-08 18:31:47,975 INFO     Training average positive_sample_loss at step 457400: 0.219057\n",
      "2022-11-08 18:31:47,975 INFO     Training average negative_sample_loss at step 457400: 0.173366\n",
      "2022-11-08 18:31:47,975 INFO     Training average loss at step 457400: 0.196211\n",
      "2022-11-08 18:31:57,742 INFO     Training average positive_sample_loss at step 457500: 0.216422\n",
      "2022-11-08 18:31:57,742 INFO     Training average negative_sample_loss at step 457500: 0.169037\n",
      "2022-11-08 18:31:57,742 INFO     Training average loss at step 457500: 0.192730\n",
      "2022-11-08 18:32:05,699 INFO     Training average positive_sample_loss at step 457600: 0.225247\n",
      "2022-11-08 18:32:05,699 INFO     Training average negative_sample_loss at step 457600: 0.170569\n",
      "2022-11-08 18:32:05,699 INFO     Training average loss at step 457600: 0.197908\n",
      "2022-11-08 18:32:15,225 INFO     Training average positive_sample_loss at step 457700: 0.218181\n",
      "2022-11-08 18:32:15,225 INFO     Training average negative_sample_loss at step 457700: 0.165465\n",
      "2022-11-08 18:32:15,225 INFO     Training average loss at step 457700: 0.191823\n",
      "2022-11-08 18:32:24,753 INFO     Training average positive_sample_loss at step 457800: 0.230910\n",
      "2022-11-08 18:32:24,753 INFO     Training average negative_sample_loss at step 457800: 0.171832\n",
      "2022-11-08 18:32:24,753 INFO     Training average loss at step 457800: 0.201371\n",
      "2022-11-08 18:32:34,280 INFO     Training average positive_sample_loss at step 457900: 0.219811\n",
      "2022-11-08 18:32:34,280 INFO     Training average negative_sample_loss at step 457900: 0.174361\n",
      "2022-11-08 18:32:34,280 INFO     Training average loss at step 457900: 0.197086\n",
      "2022-11-08 18:32:43,806 INFO     Training average positive_sample_loss at step 458000: 0.215043\n",
      "2022-11-08 18:32:43,807 INFO     Training average negative_sample_loss at step 458000: 0.168584\n",
      "2022-11-08 18:32:43,807 INFO     Training average loss at step 458000: 0.191814\n",
      "2022-11-08 18:32:53,330 INFO     Training average positive_sample_loss at step 458100: 0.216726\n",
      "2022-11-08 18:32:53,330 INFO     Training average negative_sample_loss at step 458100: 0.171899\n",
      "2022-11-08 18:32:53,330 INFO     Training average loss at step 458100: 0.194313\n",
      "2022-11-08 18:33:02,857 INFO     Training average positive_sample_loss at step 458200: 0.220582\n",
      "2022-11-08 18:33:02,857 INFO     Training average negative_sample_loss at step 458200: 0.171061\n",
      "2022-11-08 18:33:02,857 INFO     Training average loss at step 458200: 0.195822\n",
      "2022-11-08 18:33:12,384 INFO     Training average positive_sample_loss at step 458300: 0.227486\n",
      "2022-11-08 18:33:12,384 INFO     Training average negative_sample_loss at step 458300: 0.166325\n",
      "2022-11-08 18:33:12,384 INFO     Training average loss at step 458300: 0.196905\n",
      "2022-11-08 18:33:21,907 INFO     Training average positive_sample_loss at step 458400: 0.222160\n",
      "2022-11-08 18:33:21,907 INFO     Training average negative_sample_loss at step 458400: 0.166407\n",
      "2022-11-08 18:33:21,907 INFO     Training average loss at step 458400: 0.194284\n",
      "2022-11-08 18:33:31,435 INFO     Training average positive_sample_loss at step 458500: 0.213271\n",
      "2022-11-08 18:33:31,435 INFO     Training average negative_sample_loss at step 458500: 0.170900\n",
      "2022-11-08 18:33:31,435 INFO     Training average loss at step 458500: 0.192086\n",
      "2022-11-08 18:33:40,962 INFO     Training average positive_sample_loss at step 458600: 0.222575\n",
      "2022-11-08 18:33:40,962 INFO     Training average negative_sample_loss at step 458600: 0.165408\n",
      "2022-11-08 18:33:40,962 INFO     Training average loss at step 458600: 0.193991\n",
      "2022-11-08 18:33:50,483 INFO     Training average positive_sample_loss at step 458700: 0.225658\n",
      "2022-11-08 18:33:50,483 INFO     Training average negative_sample_loss at step 458700: 0.170338\n",
      "2022-11-08 18:33:50,483 INFO     Training average loss at step 458700: 0.197998\n",
      "2022-11-08 18:34:00,016 INFO     Training average positive_sample_loss at step 458800: 0.212382\n",
      "2022-11-08 18:34:00,016 INFO     Training average negative_sample_loss at step 458800: 0.175087\n",
      "2022-11-08 18:34:00,016 INFO     Training average loss at step 458800: 0.193734\n",
      "2022-11-08 18:34:09,539 INFO     Training average positive_sample_loss at step 458900: 0.216147\n",
      "2022-11-08 18:34:09,539 INFO     Training average negative_sample_loss at step 458900: 0.169879\n",
      "2022-11-08 18:34:09,539 INFO     Training average loss at step 458900: 0.193013\n",
      "2022-11-08 18:34:19,061 INFO     Training average positive_sample_loss at step 459000: 0.225256\n",
      "2022-11-08 18:34:19,061 INFO     Training average negative_sample_loss at step 459000: 0.172836\n",
      "2022-11-08 18:34:19,061 INFO     Training average loss at step 459000: 0.199046\n",
      "2022-11-08 18:34:28,592 INFO     Training average positive_sample_loss at step 459100: 0.224378\n",
      "2022-11-08 18:34:28,592 INFO     Training average negative_sample_loss at step 459100: 0.171909\n",
      "2022-11-08 18:34:28,592 INFO     Training average loss at step 459100: 0.198144\n",
      "2022-11-08 18:34:38,115 INFO     Training average positive_sample_loss at step 459200: 0.208167\n",
      "2022-11-08 18:34:38,116 INFO     Training average negative_sample_loss at step 459200: 0.168875\n",
      "2022-11-08 18:34:38,116 INFO     Training average loss at step 459200: 0.188521\n",
      "2022-11-08 18:34:47,637 INFO     Training average positive_sample_loss at step 459300: 0.217853\n",
      "2022-11-08 18:34:47,637 INFO     Training average negative_sample_loss at step 459300: 0.170416\n",
      "2022-11-08 18:34:47,637 INFO     Training average loss at step 459300: 0.194134\n",
      "2022-11-08 18:34:57,165 INFO     Training average positive_sample_loss at step 459400: 0.220298\n",
      "2022-11-08 18:34:57,166 INFO     Training average negative_sample_loss at step 459400: 0.164309\n",
      "2022-11-08 18:34:57,166 INFO     Training average loss at step 459400: 0.192304\n",
      "2022-11-08 18:35:06,689 INFO     Training average positive_sample_loss at step 459500: 0.225533\n",
      "2022-11-08 18:35:06,689 INFO     Training average negative_sample_loss at step 459500: 0.170721\n",
      "2022-11-08 18:35:06,689 INFO     Training average loss at step 459500: 0.198127\n",
      "2022-11-08 18:35:16,214 INFO     Training average positive_sample_loss at step 459600: 0.210781\n",
      "2022-11-08 18:35:16,214 INFO     Training average negative_sample_loss at step 459600: 0.166736\n",
      "2022-11-08 18:35:16,214 INFO     Training average loss at step 459600: 0.188759\n",
      "2022-11-08 18:35:25,742 INFO     Training average positive_sample_loss at step 459700: 0.217404\n",
      "2022-11-08 18:35:25,742 INFO     Training average negative_sample_loss at step 459700: 0.170487\n",
      "2022-11-08 18:35:25,742 INFO     Training average loss at step 459700: 0.193945\n",
      "2022-11-08 18:35:35,265 INFO     Training average positive_sample_loss at step 459800: 0.228022\n",
      "2022-11-08 18:35:35,265 INFO     Training average negative_sample_loss at step 459800: 0.167305\n",
      "2022-11-08 18:35:35,265 INFO     Training average loss at step 459800: 0.197664\n",
      "2022-11-08 18:35:44,790 INFO     Training average positive_sample_loss at step 459900: 0.223472\n",
      "2022-11-08 18:35:44,790 INFO     Training average negative_sample_loss at step 459900: 0.166535\n",
      "2022-11-08 18:35:44,790 INFO     Training average loss at step 459900: 0.195003\n",
      "2022-11-08 18:35:57,197 INFO     Training average positive_sample_loss at step 460000: 0.214462\n",
      "2022-11-08 18:35:57,197 INFO     Training average negative_sample_loss at step 460000: 0.169364\n",
      "2022-11-08 18:35:57,197 INFO     Training average loss at step 460000: 0.191913\n",
      "2022-11-08 18:36:06,720 INFO     Training average positive_sample_loss at step 460100: 0.220995\n",
      "2022-11-08 18:36:06,721 INFO     Training average negative_sample_loss at step 460100: 0.173583\n",
      "2022-11-08 18:36:06,721 INFO     Training average loss at step 460100: 0.197289\n",
      "2022-11-08 18:36:16,245 INFO     Training average positive_sample_loss at step 460200: 0.215748\n",
      "2022-11-08 18:36:16,245 INFO     Training average negative_sample_loss at step 460200: 0.169591\n",
      "2022-11-08 18:36:16,245 INFO     Training average loss at step 460200: 0.192670\n",
      "2022-11-08 18:36:25,769 INFO     Training average positive_sample_loss at step 460300: 0.217669\n",
      "2022-11-08 18:36:25,770 INFO     Training average negative_sample_loss at step 460300: 0.168192\n",
      "2022-11-08 18:36:25,770 INFO     Training average loss at step 460300: 0.192930\n",
      "2022-11-08 18:36:35,295 INFO     Training average positive_sample_loss at step 460400: 0.214843\n",
      "2022-11-08 18:36:35,295 INFO     Training average negative_sample_loss at step 460400: 0.168388\n",
      "2022-11-08 18:36:35,295 INFO     Training average loss at step 460400: 0.191615\n",
      "2022-11-08 18:36:44,825 INFO     Training average positive_sample_loss at step 460500: 0.225904\n",
      "2022-11-08 18:36:44,825 INFO     Training average negative_sample_loss at step 460500: 0.171550\n",
      "2022-11-08 18:36:44,825 INFO     Training average loss at step 460500: 0.198727\n",
      "2022-11-08 18:36:54,354 INFO     Training average positive_sample_loss at step 460600: 0.218007\n",
      "2022-11-08 18:36:54,354 INFO     Training average negative_sample_loss at step 460600: 0.172333\n",
      "2022-11-08 18:36:54,354 INFO     Training average loss at step 460600: 0.195170\n",
      "2022-11-08 18:37:03,884 INFO     Training average positive_sample_loss at step 460700: 0.217493\n",
      "2022-11-08 18:37:03,884 INFO     Training average negative_sample_loss at step 460700: 0.172249\n",
      "2022-11-08 18:37:03,884 INFO     Training average loss at step 460700: 0.194871\n",
      "2022-11-08 18:37:13,412 INFO     Training average positive_sample_loss at step 460800: 0.212278\n",
      "2022-11-08 18:37:13,412 INFO     Training average negative_sample_loss at step 460800: 0.168241\n",
      "2022-11-08 18:37:13,412 INFO     Training average loss at step 460800: 0.190260\n",
      "2022-11-08 18:37:22,270 INFO     Training average positive_sample_loss at step 460900: 0.214461\n",
      "2022-11-08 18:37:22,270 INFO     Training average negative_sample_loss at step 460900: 0.171781\n",
      "2022-11-08 18:37:22,270 INFO     Training average loss at step 460900: 0.193121\n",
      "2022-11-08 18:37:31,776 INFO     Training average positive_sample_loss at step 461000: 0.212877\n",
      "2022-11-08 18:37:31,776 INFO     Training average negative_sample_loss at step 461000: 0.170841\n",
      "2022-11-08 18:37:31,776 INFO     Training average loss at step 461000: 0.191859\n",
      "2022-11-08 18:37:41,299 INFO     Training average positive_sample_loss at step 461100: 0.214491\n",
      "2022-11-08 18:37:41,299 INFO     Training average negative_sample_loss at step 461100: 0.171372\n",
      "2022-11-08 18:37:41,299 INFO     Training average loss at step 461100: 0.192931\n",
      "2022-11-08 18:37:50,826 INFO     Training average positive_sample_loss at step 461200: 0.219559\n",
      "2022-11-08 18:37:50,826 INFO     Training average negative_sample_loss at step 461200: 0.170988\n",
      "2022-11-08 18:37:50,826 INFO     Training average loss at step 461200: 0.195273\n",
      "2022-11-08 18:38:00,351 INFO     Training average positive_sample_loss at step 461300: 0.221611\n",
      "2022-11-08 18:38:00,351 INFO     Training average negative_sample_loss at step 461300: 0.169872\n",
      "2022-11-08 18:38:00,351 INFO     Training average loss at step 461300: 0.195742\n",
      "2022-11-08 18:38:09,869 INFO     Training average positive_sample_loss at step 461400: 0.222220\n",
      "2022-11-08 18:38:09,869 INFO     Training average negative_sample_loss at step 461400: 0.172173\n",
      "2022-11-08 18:38:09,869 INFO     Training average loss at step 461400: 0.197197\n",
      "2022-11-08 18:38:18,710 INFO     Training average positive_sample_loss at step 461500: 0.217956\n",
      "2022-11-08 18:38:18,710 INFO     Training average negative_sample_loss at step 461500: 0.168714\n",
      "2022-11-08 18:38:18,710 INFO     Training average loss at step 461500: 0.193335\n",
      "2022-11-08 18:38:28,196 INFO     Training average positive_sample_loss at step 461600: 0.211018\n",
      "2022-11-08 18:38:28,196 INFO     Training average negative_sample_loss at step 461600: 0.174027\n",
      "2022-11-08 18:38:28,196 INFO     Training average loss at step 461600: 0.192522\n",
      "2022-11-08 18:38:37,727 INFO     Training average positive_sample_loss at step 461700: 0.224607\n",
      "2022-11-08 18:38:37,728 INFO     Training average negative_sample_loss at step 461700: 0.166638\n",
      "2022-11-08 18:38:37,728 INFO     Training average loss at step 461700: 0.195623\n",
      "2022-11-08 18:38:48,259 INFO     Training average positive_sample_loss at step 461800: 0.211833\n",
      "2022-11-08 18:38:48,259 INFO     Training average negative_sample_loss at step 461800: 0.171281\n",
      "2022-11-08 18:38:48,260 INFO     Training average loss at step 461800: 0.191557\n",
      "2022-11-08 18:38:57,785 INFO     Training average positive_sample_loss at step 461900: 0.220542\n",
      "2022-11-08 18:38:57,785 INFO     Training average negative_sample_loss at step 461900: 0.167488\n",
      "2022-11-08 18:38:57,786 INFO     Training average loss at step 461900: 0.194015\n",
      "2022-11-08 18:39:08,394 INFO     Training average positive_sample_loss at step 462000: 0.217988\n",
      "2022-11-08 18:39:08,394 INFO     Training average negative_sample_loss at step 462000: 0.173356\n",
      "2022-11-08 18:39:08,394 INFO     Training average loss at step 462000: 0.195672\n",
      "2022-11-08 18:39:17,921 INFO     Training average positive_sample_loss at step 462100: 0.224967\n",
      "2022-11-08 18:39:17,921 INFO     Training average negative_sample_loss at step 462100: 0.170751\n",
      "2022-11-08 18:39:17,921 INFO     Training average loss at step 462100: 0.197859\n",
      "2022-11-08 18:39:27,732 INFO     Training average positive_sample_loss at step 462200: 0.222452\n",
      "2022-11-08 18:39:27,733 INFO     Training average negative_sample_loss at step 462200: 0.169430\n",
      "2022-11-08 18:39:27,733 INFO     Training average loss at step 462200: 0.195941\n",
      "2022-11-08 18:39:37,257 INFO     Training average positive_sample_loss at step 462300: 0.209697\n",
      "2022-11-08 18:39:37,258 INFO     Training average negative_sample_loss at step 462300: 0.170737\n",
      "2022-11-08 18:39:37,258 INFO     Training average loss at step 462300: 0.190217\n",
      "2022-11-08 18:39:46,784 INFO     Training average positive_sample_loss at step 462400: 0.216868\n",
      "2022-11-08 18:39:46,784 INFO     Training average negative_sample_loss at step 462400: 0.168880\n",
      "2022-11-08 18:39:46,784 INFO     Training average loss at step 462400: 0.192874\n",
      "2022-11-08 18:39:56,314 INFO     Training average positive_sample_loss at step 462500: 0.216357\n",
      "2022-11-08 18:39:56,314 INFO     Training average negative_sample_loss at step 462500: 0.173910\n",
      "2022-11-08 18:39:56,314 INFO     Training average loss at step 462500: 0.195133\n",
      "2022-11-08 18:40:05,839 INFO     Training average positive_sample_loss at step 462600: 0.213763\n",
      "2022-11-08 18:40:05,839 INFO     Training average negative_sample_loss at step 462600: 0.165783\n",
      "2022-11-08 18:40:05,839 INFO     Training average loss at step 462600: 0.189773\n",
      "2022-11-08 18:40:15,367 INFO     Training average positive_sample_loss at step 462700: 0.216006\n",
      "2022-11-08 18:40:15,367 INFO     Training average negative_sample_loss at step 462700: 0.170234\n",
      "2022-11-08 18:40:15,367 INFO     Training average loss at step 462700: 0.193120\n",
      "2022-11-08 18:40:24,894 INFO     Training average positive_sample_loss at step 462800: 0.219407\n",
      "2022-11-08 18:40:24,894 INFO     Training average negative_sample_loss at step 462800: 0.170156\n",
      "2022-11-08 18:40:24,894 INFO     Training average loss at step 462800: 0.194782\n",
      "2022-11-08 18:40:34,419 INFO     Training average positive_sample_loss at step 462900: 0.218412\n",
      "2022-11-08 18:40:34,419 INFO     Training average negative_sample_loss at step 462900: 0.169213\n",
      "2022-11-08 18:40:34,419 INFO     Training average loss at step 462900: 0.193813\n",
      "2022-11-08 18:40:43,947 INFO     Training average positive_sample_loss at step 463000: 0.211753\n",
      "2022-11-08 18:40:43,947 INFO     Training average negative_sample_loss at step 463000: 0.167258\n",
      "2022-11-08 18:40:43,947 INFO     Training average loss at step 463000: 0.189505\n",
      "2022-11-08 18:40:53,473 INFO     Training average positive_sample_loss at step 463100: 0.215958\n",
      "2022-11-08 18:40:53,473 INFO     Training average negative_sample_loss at step 463100: 0.168786\n",
      "2022-11-08 18:40:53,473 INFO     Training average loss at step 463100: 0.192372\n",
      "2022-11-08 18:41:03,001 INFO     Training average positive_sample_loss at step 463200: 0.216947\n",
      "2022-11-08 18:41:03,001 INFO     Training average negative_sample_loss at step 463200: 0.171294\n",
      "2022-11-08 18:41:03,001 INFO     Training average loss at step 463200: 0.194121\n",
      "2022-11-08 18:41:12,529 INFO     Training average positive_sample_loss at step 463300: 0.215523\n",
      "2022-11-08 18:41:12,529 INFO     Training average negative_sample_loss at step 463300: 0.166299\n",
      "2022-11-08 18:41:12,529 INFO     Training average loss at step 463300: 0.190911\n",
      "2022-11-08 18:41:22,056 INFO     Training average positive_sample_loss at step 463400: 0.218974\n",
      "2022-11-08 18:41:22,056 INFO     Training average negative_sample_loss at step 463400: 0.170468\n",
      "2022-11-08 18:41:22,056 INFO     Training average loss at step 463400: 0.194721\n",
      "2022-11-08 18:41:31,584 INFO     Training average positive_sample_loss at step 463500: 0.213579\n",
      "2022-11-08 18:41:31,584 INFO     Training average negative_sample_loss at step 463500: 0.172737\n",
      "2022-11-08 18:41:31,584 INFO     Training average loss at step 463500: 0.193158\n",
      "2022-11-08 18:41:41,111 INFO     Training average positive_sample_loss at step 463600: 0.214583\n",
      "2022-11-08 18:41:41,111 INFO     Training average negative_sample_loss at step 463600: 0.168404\n",
      "2022-11-08 18:41:41,111 INFO     Training average loss at step 463600: 0.191493\n",
      "2022-11-08 18:41:50,637 INFO     Training average positive_sample_loss at step 463700: 0.215251\n",
      "2022-11-08 18:41:50,637 INFO     Training average negative_sample_loss at step 463700: 0.169484\n",
      "2022-11-08 18:41:50,637 INFO     Training average loss at step 463700: 0.192367\n",
      "2022-11-08 18:42:00,165 INFO     Training average positive_sample_loss at step 463800: 0.217389\n",
      "2022-11-08 18:42:00,165 INFO     Training average negative_sample_loss at step 463800: 0.169294\n",
      "2022-11-08 18:42:00,165 INFO     Training average loss at step 463800: 0.193342\n",
      "2022-11-08 18:42:09,689 INFO     Training average positive_sample_loss at step 463900: 0.214230\n",
      "2022-11-08 18:42:09,689 INFO     Training average negative_sample_loss at step 463900: 0.169466\n",
      "2022-11-08 18:42:09,689 INFO     Training average loss at step 463900: 0.191848\n",
      "2022-11-08 18:42:19,217 INFO     Training average positive_sample_loss at step 464000: 0.210295\n",
      "2022-11-08 18:42:19,217 INFO     Training average negative_sample_loss at step 464000: 0.169531\n",
      "2022-11-08 18:42:19,217 INFO     Training average loss at step 464000: 0.189913\n",
      "2022-11-08 18:42:28,742 INFO     Training average positive_sample_loss at step 464100: 0.215562\n",
      "2022-11-08 18:42:28,742 INFO     Training average negative_sample_loss at step 464100: 0.175106\n",
      "2022-11-08 18:42:28,743 INFO     Training average loss at step 464100: 0.195334\n",
      "2022-11-08 18:42:38,265 INFO     Training average positive_sample_loss at step 464200: 0.213152\n",
      "2022-11-08 18:42:38,265 INFO     Training average negative_sample_loss at step 464200: 0.174052\n",
      "2022-11-08 18:42:38,265 INFO     Training average loss at step 464200: 0.193602\n",
      "2022-11-08 18:42:47,793 INFO     Training average positive_sample_loss at step 464300: 0.219372\n",
      "2022-11-08 18:42:47,793 INFO     Training average negative_sample_loss at step 464300: 0.167033\n",
      "2022-11-08 18:42:47,793 INFO     Training average loss at step 464300: 0.193203\n",
      "2022-11-08 18:42:57,317 INFO     Training average positive_sample_loss at step 464400: 0.221158\n",
      "2022-11-08 18:42:57,317 INFO     Training average negative_sample_loss at step 464400: 0.169127\n",
      "2022-11-08 18:42:57,317 INFO     Training average loss at step 464400: 0.195143\n",
      "2022-11-08 18:43:06,841 INFO     Training average positive_sample_loss at step 464500: 0.213478\n",
      "2022-11-08 18:43:06,841 INFO     Training average negative_sample_loss at step 464500: 0.166819\n",
      "2022-11-08 18:43:06,841 INFO     Training average loss at step 464500: 0.190148\n",
      "2022-11-08 18:43:16,371 INFO     Training average positive_sample_loss at step 464600: 0.215359\n",
      "2022-11-08 18:43:16,371 INFO     Training average negative_sample_loss at step 464600: 0.166059\n",
      "2022-11-08 18:43:16,371 INFO     Training average loss at step 464600: 0.190709\n",
      "2022-11-08 18:43:25,895 INFO     Training average positive_sample_loss at step 464700: 0.212262\n",
      "2022-11-08 18:43:25,895 INFO     Training average negative_sample_loss at step 464700: 0.170376\n",
      "2022-11-08 18:43:25,895 INFO     Training average loss at step 464700: 0.191319\n",
      "2022-11-08 18:43:35,421 INFO     Training average positive_sample_loss at step 464800: 0.221441\n",
      "2022-11-08 18:43:35,421 INFO     Training average negative_sample_loss at step 464800: 0.167659\n",
      "2022-11-08 18:43:35,421 INFO     Training average loss at step 464800: 0.194550\n",
      "2022-11-08 18:43:44,949 INFO     Training average positive_sample_loss at step 464900: 0.217026\n",
      "2022-11-08 18:43:44,949 INFO     Training average negative_sample_loss at step 464900: 0.170815\n",
      "2022-11-08 18:43:44,949 INFO     Training average loss at step 464900: 0.193921\n",
      "2022-11-08 18:43:54,471 INFO     Training average positive_sample_loss at step 465000: 0.212159\n",
      "2022-11-08 18:43:54,471 INFO     Training average negative_sample_loss at step 465000: 0.169100\n",
      "2022-11-08 18:43:54,471 INFO     Training average loss at step 465000: 0.190629\n",
      "2022-11-08 18:44:03,997 INFO     Training average positive_sample_loss at step 465100: 0.219574\n",
      "2022-11-08 18:44:03,997 INFO     Training average negative_sample_loss at step 465100: 0.167292\n",
      "2022-11-08 18:44:03,997 INFO     Training average loss at step 465100: 0.193433\n",
      "2022-11-08 18:44:13,524 INFO     Training average positive_sample_loss at step 465200: 0.215575\n",
      "2022-11-08 18:44:13,524 INFO     Training average negative_sample_loss at step 465200: 0.172777\n",
      "2022-11-08 18:44:13,524 INFO     Training average loss at step 465200: 0.194176\n",
      "2022-11-08 18:44:23,048 INFO     Training average positive_sample_loss at step 465300: 0.212948\n",
      "2022-11-08 18:44:23,048 INFO     Training average negative_sample_loss at step 465300: 0.170466\n",
      "2022-11-08 18:44:23,048 INFO     Training average loss at step 465300: 0.191707\n",
      "2022-11-08 18:44:32,574 INFO     Training average positive_sample_loss at step 465400: 0.221034\n",
      "2022-11-08 18:44:32,574 INFO     Training average negative_sample_loss at step 465400: 0.166861\n",
      "2022-11-08 18:44:32,574 INFO     Training average loss at step 465400: 0.193948\n",
      "2022-11-08 18:44:42,102 INFO     Training average positive_sample_loss at step 465500: 0.221704\n",
      "2022-11-08 18:44:42,102 INFO     Training average negative_sample_loss at step 465500: 0.168386\n",
      "2022-11-08 18:44:42,102 INFO     Training average loss at step 465500: 0.195045\n",
      "2022-11-08 18:44:51,624 INFO     Training average positive_sample_loss at step 465600: 0.226276\n",
      "2022-11-08 18:44:51,624 INFO     Training average negative_sample_loss at step 465600: 0.169753\n",
      "2022-11-08 18:44:51,624 INFO     Training average loss at step 465600: 0.198015\n",
      "2022-11-08 18:45:01,152 INFO     Training average positive_sample_loss at step 465700: 0.220423\n",
      "2022-11-08 18:45:01,152 INFO     Training average negative_sample_loss at step 465700: 0.169812\n",
      "2022-11-08 18:45:01,152 INFO     Training average loss at step 465700: 0.195118\n",
      "2022-11-08 18:45:10,676 INFO     Training average positive_sample_loss at step 465800: 0.219162\n",
      "2022-11-08 18:45:10,676 INFO     Training average negative_sample_loss at step 465800: 0.171291\n",
      "2022-11-08 18:45:10,676 INFO     Training average loss at step 465800: 0.195227\n",
      "2022-11-08 18:45:20,200 INFO     Training average positive_sample_loss at step 465900: 0.215332\n",
      "2022-11-08 18:45:20,200 INFO     Training average negative_sample_loss at step 465900: 0.168376\n",
      "2022-11-08 18:45:20,200 INFO     Training average loss at step 465900: 0.191854\n",
      "2022-11-08 18:45:29,727 INFO     Training average positive_sample_loss at step 466000: 0.217430\n",
      "2022-11-08 18:45:29,727 INFO     Training average negative_sample_loss at step 466000: 0.165582\n",
      "2022-11-08 18:45:29,727 INFO     Training average loss at step 466000: 0.191506\n",
      "2022-11-08 18:45:39,253 INFO     Training average positive_sample_loss at step 466100: 0.214311\n",
      "2022-11-08 18:45:39,253 INFO     Training average negative_sample_loss at step 466100: 0.168667\n",
      "2022-11-08 18:45:39,254 INFO     Training average loss at step 466100: 0.191489\n",
      "2022-11-08 18:45:48,778 INFO     Training average positive_sample_loss at step 466200: 0.217689\n",
      "2022-11-08 18:45:48,778 INFO     Training average negative_sample_loss at step 466200: 0.170561\n",
      "2022-11-08 18:45:48,778 INFO     Training average loss at step 466200: 0.194125\n",
      "2022-11-08 18:45:56,822 INFO     Training average positive_sample_loss at step 466300: 0.221080\n",
      "2022-11-08 18:45:56,822 INFO     Training average negative_sample_loss at step 466300: 0.164039\n",
      "2022-11-08 18:45:56,822 INFO     Training average loss at step 466300: 0.192560\n",
      "2022-11-08 18:46:06,692 INFO     Training average positive_sample_loss at step 466400: 0.212426\n",
      "2022-11-08 18:46:06,692 INFO     Training average negative_sample_loss at step 466400: 0.167807\n",
      "2022-11-08 18:46:06,692 INFO     Training average loss at step 466400: 0.190117\n",
      "2022-11-08 18:46:16,219 INFO     Training average positive_sample_loss at step 466500: 0.207697\n",
      "2022-11-08 18:46:16,219 INFO     Training average negative_sample_loss at step 466500: 0.170916\n",
      "2022-11-08 18:46:16,219 INFO     Training average loss at step 466500: 0.189307\n",
      "2022-11-08 18:46:26,629 INFO     Training average positive_sample_loss at step 466600: 0.213882\n",
      "2022-11-08 18:46:26,629 INFO     Training average negative_sample_loss at step 466600: 0.166410\n",
      "2022-11-08 18:46:26,629 INFO     Training average loss at step 466600: 0.190146\n",
      "2022-11-08 18:46:36,164 INFO     Training average positive_sample_loss at step 466700: 0.216644\n",
      "2022-11-08 18:46:36,165 INFO     Training average negative_sample_loss at step 466700: 0.169780\n",
      "2022-11-08 18:46:36,165 INFO     Training average loss at step 466700: 0.193212\n",
      "2022-11-08 18:46:45,959 INFO     Training average positive_sample_loss at step 466800: 0.215864\n",
      "2022-11-08 18:46:45,959 INFO     Training average negative_sample_loss at step 466800: 0.171494\n",
      "2022-11-08 18:46:45,959 INFO     Training average loss at step 466800: 0.193679\n",
      "2022-11-08 18:46:55,488 INFO     Training average positive_sample_loss at step 466900: 0.220061\n",
      "2022-11-08 18:46:55,488 INFO     Training average negative_sample_loss at step 466900: 0.173304\n",
      "2022-11-08 18:46:55,488 INFO     Training average loss at step 466900: 0.196682\n",
      "2022-11-08 18:47:04,683 INFO     Training average positive_sample_loss at step 467000: 0.212326\n",
      "2022-11-08 18:47:04,683 INFO     Training average negative_sample_loss at step 467000: 0.173074\n",
      "2022-11-08 18:47:04,683 INFO     Training average loss at step 467000: 0.192700\n",
      "2022-11-08 18:47:14,210 INFO     Training average positive_sample_loss at step 467100: 0.220175\n",
      "2022-11-08 18:47:14,211 INFO     Training average negative_sample_loss at step 467100: 0.171916\n",
      "2022-11-08 18:47:14,211 INFO     Training average loss at step 467100: 0.196045\n",
      "2022-11-08 18:47:23,735 INFO     Training average positive_sample_loss at step 467200: 0.217098\n",
      "2022-11-08 18:47:23,735 INFO     Training average negative_sample_loss at step 467200: 0.171047\n",
      "2022-11-08 18:47:23,735 INFO     Training average loss at step 467200: 0.194072\n",
      "2022-11-08 18:47:33,259 INFO     Training average positive_sample_loss at step 467300: 0.214686\n",
      "2022-11-08 18:47:33,259 INFO     Training average negative_sample_loss at step 467300: 0.164492\n",
      "2022-11-08 18:47:33,259 INFO     Training average loss at step 467300: 0.189589\n",
      "2022-11-08 18:47:42,785 INFO     Training average positive_sample_loss at step 467400: 0.226172\n",
      "2022-11-08 18:47:42,785 INFO     Training average negative_sample_loss at step 467400: 0.167942\n",
      "2022-11-08 18:47:42,785 INFO     Training average loss at step 467400: 0.197057\n",
      "2022-11-08 18:47:52,308 INFO     Training average positive_sample_loss at step 467500: 0.218343\n",
      "2022-11-08 18:47:52,308 INFO     Training average negative_sample_loss at step 467500: 0.169341\n",
      "2022-11-08 18:47:52,308 INFO     Training average loss at step 467500: 0.193842\n",
      "2022-11-08 18:48:01,830 INFO     Training average positive_sample_loss at step 467600: 0.226358\n",
      "2022-11-08 18:48:01,830 INFO     Training average negative_sample_loss at step 467600: 0.167700\n",
      "2022-11-08 18:48:01,830 INFO     Training average loss at step 467600: 0.197029\n",
      "2022-11-08 18:48:11,359 INFO     Training average positive_sample_loss at step 467700: 0.210308\n",
      "2022-11-08 18:48:11,359 INFO     Training average negative_sample_loss at step 467700: 0.167368\n",
      "2022-11-08 18:48:11,359 INFO     Training average loss at step 467700: 0.188838\n",
      "2022-11-08 18:48:20,880 INFO     Training average positive_sample_loss at step 467800: 0.215519\n",
      "2022-11-08 18:48:20,880 INFO     Training average negative_sample_loss at step 467800: 0.167237\n",
      "2022-11-08 18:48:20,880 INFO     Training average loss at step 467800: 0.191378\n",
      "2022-11-08 18:48:30,408 INFO     Training average positive_sample_loss at step 467900: 0.220914\n",
      "2022-11-08 18:48:30,408 INFO     Training average negative_sample_loss at step 467900: 0.172553\n",
      "2022-11-08 18:48:30,408 INFO     Training average loss at step 467900: 0.196734\n",
      "2022-11-08 18:48:39,936 INFO     Training average positive_sample_loss at step 468000: 0.213301\n",
      "2022-11-08 18:48:39,937 INFO     Training average negative_sample_loss at step 468000: 0.171357\n",
      "2022-11-08 18:48:39,937 INFO     Training average loss at step 468000: 0.192329\n",
      "2022-11-08 18:48:49,457 INFO     Training average positive_sample_loss at step 468100: 0.219331\n",
      "2022-11-08 18:48:49,457 INFO     Training average negative_sample_loss at step 468100: 0.170696\n",
      "2022-11-08 18:48:49,457 INFO     Training average loss at step 468100: 0.195013\n",
      "2022-11-08 18:48:58,981 INFO     Training average positive_sample_loss at step 468200: 0.212399\n",
      "2022-11-08 18:48:58,981 INFO     Training average negative_sample_loss at step 468200: 0.168140\n",
      "2022-11-08 18:48:58,981 INFO     Training average loss at step 468200: 0.190270\n",
      "2022-11-08 18:49:08,509 INFO     Training average positive_sample_loss at step 468300: 0.210547\n",
      "2022-11-08 18:49:08,509 INFO     Training average negative_sample_loss at step 468300: 0.172331\n",
      "2022-11-08 18:49:08,509 INFO     Training average loss at step 468300: 0.191439\n",
      "2022-11-08 18:49:18,034 INFO     Training average positive_sample_loss at step 468400: 0.212368\n",
      "2022-11-08 18:49:18,034 INFO     Training average negative_sample_loss at step 468400: 0.170284\n",
      "2022-11-08 18:49:18,034 INFO     Training average loss at step 468400: 0.191326\n",
      "2022-11-08 18:49:27,558 INFO     Training average positive_sample_loss at step 468500: 0.214963\n",
      "2022-11-08 18:49:27,558 INFO     Training average negative_sample_loss at step 468500: 0.169835\n",
      "2022-11-08 18:49:27,558 INFO     Training average loss at step 468500: 0.192399\n",
      "2022-11-08 18:49:37,083 INFO     Training average positive_sample_loss at step 468600: 0.213262\n",
      "2022-11-08 18:49:37,084 INFO     Training average negative_sample_loss at step 468600: 0.168983\n",
      "2022-11-08 18:49:37,084 INFO     Training average loss at step 468600: 0.191123\n",
      "2022-11-08 18:49:46,606 INFO     Training average positive_sample_loss at step 468700: 0.210305\n",
      "2022-11-08 18:49:46,606 INFO     Training average negative_sample_loss at step 468700: 0.168020\n",
      "2022-11-08 18:49:46,606 INFO     Training average loss at step 468700: 0.189163\n",
      "2022-11-08 18:49:56,130 INFO     Training average positive_sample_loss at step 468800: 0.215879\n",
      "2022-11-08 18:49:56,131 INFO     Training average negative_sample_loss at step 468800: 0.164690\n",
      "2022-11-08 18:49:56,131 INFO     Training average loss at step 468800: 0.190284\n",
      "2022-11-08 18:50:05,656 INFO     Training average positive_sample_loss at step 468900: 0.207376\n",
      "2022-11-08 18:50:05,656 INFO     Training average negative_sample_loss at step 468900: 0.166975\n",
      "2022-11-08 18:50:05,656 INFO     Training average loss at step 468900: 0.187176\n",
      "2022-11-08 18:50:15,181 INFO     Training average positive_sample_loss at step 469000: 0.204317\n",
      "2022-11-08 18:50:15,181 INFO     Training average negative_sample_loss at step 469000: 0.168447\n",
      "2022-11-08 18:50:15,181 INFO     Training average loss at step 469000: 0.186382\n",
      "2022-11-08 18:50:24,706 INFO     Training average positive_sample_loss at step 469100: 0.213115\n",
      "2022-11-08 18:50:24,706 INFO     Training average negative_sample_loss at step 469100: 0.165138\n",
      "2022-11-08 18:50:24,706 INFO     Training average loss at step 469100: 0.189127\n",
      "2022-11-08 18:50:34,231 INFO     Training average positive_sample_loss at step 469200: 0.221141\n",
      "2022-11-08 18:50:34,231 INFO     Training average negative_sample_loss at step 469200: 0.168502\n",
      "2022-11-08 18:50:34,231 INFO     Training average loss at step 469200: 0.194822\n",
      "2022-11-08 18:50:43,756 INFO     Training average positive_sample_loss at step 469300: 0.213728\n",
      "2022-11-08 18:50:43,756 INFO     Training average negative_sample_loss at step 469300: 0.171149\n",
      "2022-11-08 18:50:43,756 INFO     Training average loss at step 469300: 0.192438\n",
      "2022-11-08 18:50:53,280 INFO     Training average positive_sample_loss at step 469400: 0.206200\n",
      "2022-11-08 18:50:53,280 INFO     Training average negative_sample_loss at step 469400: 0.168118\n",
      "2022-11-08 18:50:53,280 INFO     Training average loss at step 469400: 0.187159\n",
      "2022-11-08 18:51:02,806 INFO     Training average positive_sample_loss at step 469500: 0.222663\n",
      "2022-11-08 18:51:02,806 INFO     Training average negative_sample_loss at step 469500: 0.166632\n",
      "2022-11-08 18:51:02,806 INFO     Training average loss at step 469500: 0.194648\n",
      "2022-11-08 18:51:12,335 INFO     Training average positive_sample_loss at step 469600: 0.215723\n",
      "2022-11-08 18:51:12,335 INFO     Training average negative_sample_loss at step 469600: 0.170118\n",
      "2022-11-08 18:51:12,335 INFO     Training average loss at step 469600: 0.192920\n",
      "2022-11-08 18:51:21,859 INFO     Training average positive_sample_loss at step 469700: 0.216063\n",
      "2022-11-08 18:51:21,859 INFO     Training average negative_sample_loss at step 469700: 0.167783\n",
      "2022-11-08 18:51:21,859 INFO     Training average loss at step 469700: 0.191923\n",
      "2022-11-08 18:51:31,384 INFO     Training average positive_sample_loss at step 469800: 0.219906\n",
      "2022-11-08 18:51:31,384 INFO     Training average negative_sample_loss at step 469800: 0.168089\n",
      "2022-11-08 18:51:31,384 INFO     Training average loss at step 469800: 0.193998\n",
      "2022-11-08 18:51:40,909 INFO     Training average positive_sample_loss at step 469900: 0.211110\n",
      "2022-11-08 18:51:40,909 INFO     Training average negative_sample_loss at step 469900: 0.168752\n",
      "2022-11-08 18:51:40,909 INFO     Training average loss at step 469900: 0.189931\n",
      "2022-11-08 18:51:53,263 INFO     Training average positive_sample_loss at step 470000: 0.219094\n",
      "2022-11-08 18:51:53,263 INFO     Training average negative_sample_loss at step 470000: 0.168593\n",
      "2022-11-08 18:51:53,263 INFO     Training average loss at step 470000: 0.193843\n",
      "2022-11-08 18:52:02,789 INFO     Training average positive_sample_loss at step 470100: 0.215639\n",
      "2022-11-08 18:52:02,789 INFO     Training average negative_sample_loss at step 470100: 0.167502\n",
      "2022-11-08 18:52:02,789 INFO     Training average loss at step 470100: 0.191571\n",
      "2022-11-08 18:52:12,315 INFO     Training average positive_sample_loss at step 470200: 0.210440\n",
      "2022-11-08 18:52:12,315 INFO     Training average negative_sample_loss at step 470200: 0.166335\n",
      "2022-11-08 18:52:12,315 INFO     Training average loss at step 470200: 0.188387\n",
      "2022-11-08 18:52:21,838 INFO     Training average positive_sample_loss at step 470300: 0.210498\n",
      "2022-11-08 18:52:21,838 INFO     Training average negative_sample_loss at step 470300: 0.168985\n",
      "2022-11-08 18:52:21,838 INFO     Training average loss at step 470300: 0.189742\n",
      "2022-11-08 18:52:31,366 INFO     Training average positive_sample_loss at step 470400: 0.228531\n",
      "2022-11-08 18:52:31,366 INFO     Training average negative_sample_loss at step 470400: 0.170571\n",
      "2022-11-08 18:52:31,366 INFO     Training average loss at step 470400: 0.199551\n",
      "2022-11-08 18:52:40,891 INFO     Training average positive_sample_loss at step 470500: 0.219384\n",
      "2022-11-08 18:52:40,891 INFO     Training average negative_sample_loss at step 470500: 0.162636\n",
      "2022-11-08 18:52:40,891 INFO     Training average loss at step 470500: 0.191010\n",
      "2022-11-08 18:52:50,413 INFO     Training average positive_sample_loss at step 470600: 0.212141\n",
      "2022-11-08 18:52:50,413 INFO     Training average negative_sample_loss at step 470600: 0.173036\n",
      "2022-11-08 18:52:50,413 INFO     Training average loss at step 470600: 0.192588\n",
      "2022-11-08 18:52:59,941 INFO     Training average positive_sample_loss at step 470700: 0.214410\n",
      "2022-11-08 18:52:59,941 INFO     Training average negative_sample_loss at step 470700: 0.168895\n",
      "2022-11-08 18:52:59,941 INFO     Training average loss at step 470700: 0.191653\n",
      "2022-11-08 18:53:09,466 INFO     Training average positive_sample_loss at step 470800: 0.209773\n",
      "2022-11-08 18:53:09,466 INFO     Training average negative_sample_loss at step 470800: 0.169093\n",
      "2022-11-08 18:53:09,466 INFO     Training average loss at step 470800: 0.189433\n",
      "2022-11-08 18:53:18,989 INFO     Training average positive_sample_loss at step 470900: 0.215958\n",
      "2022-11-08 18:53:18,989 INFO     Training average negative_sample_loss at step 470900: 0.168838\n",
      "2022-11-08 18:53:18,989 INFO     Training average loss at step 470900: 0.192398\n",
      "2022-11-08 18:53:28,517 INFO     Training average positive_sample_loss at step 471000: 0.211213\n",
      "2022-11-08 18:53:28,518 INFO     Training average negative_sample_loss at step 471000: 0.167110\n",
      "2022-11-08 18:53:28,518 INFO     Training average loss at step 471000: 0.189162\n",
      "2022-11-08 18:53:38,422 INFO     Training average positive_sample_loss at step 471100: 0.207951\n",
      "2022-11-08 18:53:38,422 INFO     Training average negative_sample_loss at step 471100: 0.163808\n",
      "2022-11-08 18:53:38,422 INFO     Training average loss at step 471100: 0.185879\n",
      "2022-11-08 18:53:48,819 INFO     Training average positive_sample_loss at step 471200: 0.212783\n",
      "2022-11-08 18:53:48,819 INFO     Training average negative_sample_loss at step 471200: 0.166242\n",
      "2022-11-08 18:53:48,819 INFO     Training average loss at step 471200: 0.189512\n",
      "2022-11-08 18:53:59,323 INFO     Training average positive_sample_loss at step 471300: 0.209789\n",
      "2022-11-08 18:53:59,324 INFO     Training average negative_sample_loss at step 471300: 0.167788\n",
      "2022-11-08 18:53:59,324 INFO     Training average loss at step 471300: 0.188788\n",
      "2022-11-08 18:54:08,846 INFO     Training average positive_sample_loss at step 471400: 0.222443\n",
      "2022-11-08 18:54:08,846 INFO     Training average negative_sample_loss at step 471400: 0.173973\n",
      "2022-11-08 18:54:08,846 INFO     Training average loss at step 471400: 0.198208\n",
      "2022-11-08 18:54:18,634 INFO     Training average positive_sample_loss at step 471500: 0.209357\n",
      "2022-11-08 18:54:18,634 INFO     Training average negative_sample_loss at step 471500: 0.166143\n",
      "2022-11-08 18:54:18,634 INFO     Training average loss at step 471500: 0.187750\n",
      "2022-11-08 18:54:28,159 INFO     Training average positive_sample_loss at step 471600: 0.215904\n",
      "2022-11-08 18:54:28,159 INFO     Training average negative_sample_loss at step 471600: 0.166157\n",
      "2022-11-08 18:54:28,159 INFO     Training average loss at step 471600: 0.191031\n",
      "2022-11-08 18:54:37,684 INFO     Training average positive_sample_loss at step 471700: 0.216335\n",
      "2022-11-08 18:54:37,684 INFO     Training average negative_sample_loss at step 471700: 0.169893\n",
      "2022-11-08 18:54:37,684 INFO     Training average loss at step 471700: 0.193114\n",
      "2022-11-08 18:54:47,213 INFO     Training average positive_sample_loss at step 471800: 0.222868\n",
      "2022-11-08 18:54:47,213 INFO     Training average negative_sample_loss at step 471800: 0.169133\n",
      "2022-11-08 18:54:47,213 INFO     Training average loss at step 471800: 0.196001\n",
      "2022-11-08 18:54:56,032 INFO     Training average positive_sample_loss at step 471900: 0.218229\n",
      "2022-11-08 18:54:56,032 INFO     Training average negative_sample_loss at step 471900: 0.170093\n",
      "2022-11-08 18:54:56,032 INFO     Training average loss at step 471900: 0.194161\n",
      "2022-11-08 18:55:05,554 INFO     Training average positive_sample_loss at step 472000: 0.216380\n",
      "2022-11-08 18:55:05,554 INFO     Training average negative_sample_loss at step 472000: 0.172728\n",
      "2022-11-08 18:55:05,554 INFO     Training average loss at step 472000: 0.194554\n",
      "2022-11-08 18:55:15,075 INFO     Training average positive_sample_loss at step 472100: 0.212655\n",
      "2022-11-08 18:55:15,075 INFO     Training average negative_sample_loss at step 472100: 0.169629\n",
      "2022-11-08 18:55:15,075 INFO     Training average loss at step 472100: 0.191142\n",
      "2022-11-08 18:55:24,600 INFO     Training average positive_sample_loss at step 472200: 0.214021\n",
      "2022-11-08 18:55:24,600 INFO     Training average negative_sample_loss at step 472200: 0.169275\n",
      "2022-11-08 18:55:24,600 INFO     Training average loss at step 472200: 0.191648\n",
      "2022-11-08 18:55:34,121 INFO     Training average positive_sample_loss at step 472300: 0.214018\n",
      "2022-11-08 18:55:34,121 INFO     Training average negative_sample_loss at step 472300: 0.166787\n",
      "2022-11-08 18:55:34,121 INFO     Training average loss at step 472300: 0.190403\n",
      "2022-11-08 18:55:42,976 INFO     Training average positive_sample_loss at step 472400: 0.205264\n",
      "2022-11-08 18:55:42,976 INFO     Training average negative_sample_loss at step 472400: 0.169341\n",
      "2022-11-08 18:55:42,976 INFO     Training average loss at step 472400: 0.187303\n",
      "2022-11-08 18:55:52,496 INFO     Training average positive_sample_loss at step 472500: 0.212967\n",
      "2022-11-08 18:55:52,496 INFO     Training average negative_sample_loss at step 472500: 0.163903\n",
      "2022-11-08 18:55:52,496 INFO     Training average loss at step 472500: 0.188435\n",
      "2022-11-08 18:56:02,020 INFO     Training average positive_sample_loss at step 472600: 0.219043\n",
      "2022-11-08 18:56:02,020 INFO     Training average negative_sample_loss at step 472600: 0.168623\n",
      "2022-11-08 18:56:02,020 INFO     Training average loss at step 472600: 0.193833\n",
      "2022-11-08 18:56:11,544 INFO     Training average positive_sample_loss at step 472700: 0.208507\n",
      "2022-11-08 18:56:11,544 INFO     Training average negative_sample_loss at step 472700: 0.171176\n",
      "2022-11-08 18:56:11,544 INFO     Training average loss at step 472700: 0.189841\n",
      "2022-11-08 18:56:21,069 INFO     Training average positive_sample_loss at step 472800: 0.211974\n",
      "2022-11-08 18:56:21,070 INFO     Training average negative_sample_loss at step 472800: 0.166805\n",
      "2022-11-08 18:56:21,070 INFO     Training average loss at step 472800: 0.189389\n",
      "2022-11-08 18:56:30,590 INFO     Training average positive_sample_loss at step 472900: 0.205231\n",
      "2022-11-08 18:56:30,590 INFO     Training average negative_sample_loss at step 472900: 0.164468\n",
      "2022-11-08 18:56:30,590 INFO     Training average loss at step 472900: 0.184849\n",
      "2022-11-08 18:56:40,110 INFO     Training average positive_sample_loss at step 473000: 0.220395\n",
      "2022-11-08 18:56:40,110 INFO     Training average negative_sample_loss at step 473000: 0.170161\n",
      "2022-11-08 18:56:40,110 INFO     Training average loss at step 473000: 0.195278\n",
      "2022-11-08 18:56:49,634 INFO     Training average positive_sample_loss at step 473100: 0.216833\n",
      "2022-11-08 18:56:49,634 INFO     Training average negative_sample_loss at step 473100: 0.166812\n",
      "2022-11-08 18:56:49,634 INFO     Training average loss at step 473100: 0.191823\n",
      "2022-11-08 18:56:59,158 INFO     Training average positive_sample_loss at step 473200: 0.219418\n",
      "2022-11-08 18:56:59,158 INFO     Training average negative_sample_loss at step 473200: 0.170899\n",
      "2022-11-08 18:56:59,158 INFO     Training average loss at step 473200: 0.195159\n",
      "2022-11-08 18:57:08,682 INFO     Training average positive_sample_loss at step 473300: 0.217521\n",
      "2022-11-08 18:57:08,682 INFO     Training average negative_sample_loss at step 473300: 0.168980\n",
      "2022-11-08 18:57:08,682 INFO     Training average loss at step 473300: 0.193250\n",
      "2022-11-08 18:57:18,208 INFO     Training average positive_sample_loss at step 473400: 0.210188\n",
      "2022-11-08 18:57:18,209 INFO     Training average negative_sample_loss at step 473400: 0.164564\n",
      "2022-11-08 18:57:18,209 INFO     Training average loss at step 473400: 0.187376\n",
      "2022-11-08 18:57:27,729 INFO     Training average positive_sample_loss at step 473500: 0.214243\n",
      "2022-11-08 18:57:27,729 INFO     Training average negative_sample_loss at step 473500: 0.170758\n",
      "2022-11-08 18:57:27,729 INFO     Training average loss at step 473500: 0.192500\n",
      "2022-11-08 18:57:37,249 INFO     Training average positive_sample_loss at step 473600: 0.210800\n",
      "2022-11-08 18:57:37,249 INFO     Training average negative_sample_loss at step 473600: 0.165591\n",
      "2022-11-08 18:57:37,249 INFO     Training average loss at step 473600: 0.188196\n",
      "2022-11-08 18:57:46,773 INFO     Training average positive_sample_loss at step 473700: 0.209756\n",
      "2022-11-08 18:57:46,773 INFO     Training average negative_sample_loss at step 473700: 0.164837\n",
      "2022-11-08 18:57:46,773 INFO     Training average loss at step 473700: 0.187296\n",
      "2022-11-08 18:57:56,297 INFO     Training average positive_sample_loss at step 473800: 0.214281\n",
      "2022-11-08 18:57:56,297 INFO     Training average negative_sample_loss at step 473800: 0.167946\n",
      "2022-11-08 18:57:56,297 INFO     Training average loss at step 473800: 0.191114\n",
      "2022-11-08 18:58:05,822 INFO     Training average positive_sample_loss at step 473900: 0.213388\n",
      "2022-11-08 18:58:05,822 INFO     Training average negative_sample_loss at step 473900: 0.170992\n",
      "2022-11-08 18:58:05,822 INFO     Training average loss at step 473900: 0.192190\n",
      "2022-11-08 18:58:15,344 INFO     Training average positive_sample_loss at step 474000: 0.212753\n",
      "2022-11-08 18:58:15,344 INFO     Training average negative_sample_loss at step 474000: 0.173509\n",
      "2022-11-08 18:58:15,344 INFO     Training average loss at step 474000: 0.193131\n",
      "2022-11-08 18:58:24,864 INFO     Training average positive_sample_loss at step 474100: 0.208961\n",
      "2022-11-08 18:58:24,864 INFO     Training average negative_sample_loss at step 474100: 0.168575\n",
      "2022-11-08 18:58:24,864 INFO     Training average loss at step 474100: 0.188768\n",
      "2022-11-08 18:58:34,388 INFO     Training average positive_sample_loss at step 474200: 0.212950\n",
      "2022-11-08 18:58:34,388 INFO     Training average negative_sample_loss at step 474200: 0.169963\n",
      "2022-11-08 18:58:34,388 INFO     Training average loss at step 474200: 0.191456\n",
      "2022-11-08 18:58:43,911 INFO     Training average positive_sample_loss at step 474300: 0.223727\n",
      "2022-11-08 18:58:43,911 INFO     Training average negative_sample_loss at step 474300: 0.172419\n",
      "2022-11-08 18:58:43,911 INFO     Training average loss at step 474300: 0.198073\n",
      "2022-11-08 18:58:53,436 INFO     Training average positive_sample_loss at step 474400: 0.218256\n",
      "2022-11-08 18:58:53,436 INFO     Training average negative_sample_loss at step 474400: 0.165832\n",
      "2022-11-08 18:58:53,436 INFO     Training average loss at step 474400: 0.192044\n",
      "2022-11-08 18:59:02,961 INFO     Training average positive_sample_loss at step 474500: 0.214719\n",
      "2022-11-08 18:59:02,961 INFO     Training average negative_sample_loss at step 474500: 0.163332\n",
      "2022-11-08 18:59:02,961 INFO     Training average loss at step 474500: 0.189026\n",
      "2022-11-08 18:59:12,479 INFO     Training average positive_sample_loss at step 474600: 0.204862\n",
      "2022-11-08 18:59:12,479 INFO     Training average negative_sample_loss at step 474600: 0.164386\n",
      "2022-11-08 18:59:12,479 INFO     Training average loss at step 474600: 0.184624\n",
      "2022-11-08 18:59:22,002 INFO     Training average positive_sample_loss at step 474700: 0.215076\n",
      "2022-11-08 18:59:22,002 INFO     Training average negative_sample_loss at step 474700: 0.166237\n",
      "2022-11-08 18:59:22,002 INFO     Training average loss at step 474700: 0.190656\n",
      "2022-11-08 18:59:31,525 INFO     Training average positive_sample_loss at step 474800: 0.208410\n",
      "2022-11-08 18:59:31,525 INFO     Training average negative_sample_loss at step 474800: 0.167903\n",
      "2022-11-08 18:59:31,525 INFO     Training average loss at step 474800: 0.188157\n",
      "2022-11-08 18:59:41,046 INFO     Training average positive_sample_loss at step 474900: 0.206185\n",
      "2022-11-08 18:59:41,046 INFO     Training average negative_sample_loss at step 474900: 0.169934\n",
      "2022-11-08 18:59:41,047 INFO     Training average loss at step 474900: 0.188060\n",
      "2022-11-08 18:59:53,696 INFO     Training average positive_sample_loss at step 475000: 0.186066\n",
      "2022-11-08 18:59:53,696 INFO     Training average negative_sample_loss at step 475000: 0.166477\n",
      "2022-11-08 18:59:53,696 INFO     Training average loss at step 475000: 0.176272\n",
      "2022-11-08 19:00:03,308 INFO     Training average positive_sample_loss at step 475100: 0.160685\n",
      "2022-11-08 19:00:03,309 INFO     Training average negative_sample_loss at step 475100: 0.170914\n",
      "2022-11-08 19:00:03,309 INFO     Training average loss at step 475100: 0.165800\n",
      "2022-11-08 19:00:12,834 INFO     Training average positive_sample_loss at step 475200: 0.158845\n",
      "2022-11-08 19:00:12,834 INFO     Training average negative_sample_loss at step 475200: 0.165597\n",
      "2022-11-08 19:00:12,834 INFO     Training average loss at step 475200: 0.162221\n",
      "2022-11-08 19:00:22,365 INFO     Training average positive_sample_loss at step 475300: 0.155683\n",
      "2022-11-08 19:00:22,365 INFO     Training average negative_sample_loss at step 475300: 0.165216\n",
      "2022-11-08 19:00:22,365 INFO     Training average loss at step 475300: 0.160450\n",
      "2022-11-08 19:00:31,889 INFO     Training average positive_sample_loss at step 475400: 0.157753\n",
      "2022-11-08 19:00:31,889 INFO     Training average negative_sample_loss at step 475400: 0.156633\n",
      "2022-11-08 19:00:31,889 INFO     Training average loss at step 475400: 0.157193\n",
      "2022-11-08 19:00:41,416 INFO     Training average positive_sample_loss at step 475500: 0.159747\n",
      "2022-11-08 19:00:41,416 INFO     Training average negative_sample_loss at step 475500: 0.157587\n",
      "2022-11-08 19:00:41,416 INFO     Training average loss at step 475500: 0.158667\n",
      "2022-11-08 19:00:50,947 INFO     Training average positive_sample_loss at step 475600: 0.164443\n",
      "2022-11-08 19:00:50,947 INFO     Training average negative_sample_loss at step 475600: 0.156373\n",
      "2022-11-08 19:00:50,947 INFO     Training average loss at step 475600: 0.160408\n",
      "2022-11-08 19:01:00,471 INFO     Training average positive_sample_loss at step 475700: 0.163043\n",
      "2022-11-08 19:01:00,472 INFO     Training average negative_sample_loss at step 475700: 0.160775\n",
      "2022-11-08 19:01:00,472 INFO     Training average loss at step 475700: 0.161909\n",
      "2022-11-08 19:01:09,998 INFO     Training average positive_sample_loss at step 475800: 0.159699\n",
      "2022-11-08 19:01:09,998 INFO     Training average negative_sample_loss at step 475800: 0.158142\n",
      "2022-11-08 19:01:09,999 INFO     Training average loss at step 475800: 0.158920\n",
      "2022-11-08 19:01:19,527 INFO     Training average positive_sample_loss at step 475900: 0.161551\n",
      "2022-11-08 19:01:19,527 INFO     Training average negative_sample_loss at step 475900: 0.157945\n",
      "2022-11-08 19:01:19,527 INFO     Training average loss at step 475900: 0.159748\n",
      "2022-11-08 19:01:29,052 INFO     Training average positive_sample_loss at step 476000: 0.161098\n",
      "2022-11-08 19:01:29,053 INFO     Training average negative_sample_loss at step 476000: 0.157664\n",
      "2022-11-08 19:01:29,053 INFO     Training average loss at step 476000: 0.159381\n",
      "2022-11-08 19:01:38,580 INFO     Training average positive_sample_loss at step 476100: 0.161256\n",
      "2022-11-08 19:01:38,580 INFO     Training average negative_sample_loss at step 476100: 0.158360\n",
      "2022-11-08 19:01:38,580 INFO     Training average loss at step 476100: 0.159808\n",
      "2022-11-08 19:01:48,106 INFO     Training average positive_sample_loss at step 476200: 0.163308\n",
      "2022-11-08 19:01:48,106 INFO     Training average negative_sample_loss at step 476200: 0.160526\n",
      "2022-11-08 19:01:48,106 INFO     Training average loss at step 476200: 0.161917\n",
      "2022-11-08 19:01:57,631 INFO     Training average positive_sample_loss at step 476300: 0.156630\n",
      "2022-11-08 19:01:57,631 INFO     Training average negative_sample_loss at step 476300: 0.157169\n",
      "2022-11-08 19:01:57,631 INFO     Training average loss at step 476300: 0.156900\n",
      "2022-11-08 19:02:07,161 INFO     Training average positive_sample_loss at step 476400: 0.166590\n",
      "2022-11-08 19:02:07,161 INFO     Training average negative_sample_loss at step 476400: 0.155418\n",
      "2022-11-08 19:02:07,161 INFO     Training average loss at step 476400: 0.161004\n",
      "2022-11-08 19:02:16,687 INFO     Training average positive_sample_loss at step 476500: 0.162822\n",
      "2022-11-08 19:02:16,687 INFO     Training average negative_sample_loss at step 476500: 0.153233\n",
      "2022-11-08 19:02:16,687 INFO     Training average loss at step 476500: 0.158028\n",
      "2022-11-08 19:02:26,215 INFO     Training average positive_sample_loss at step 476600: 0.165061\n",
      "2022-11-08 19:02:26,215 INFO     Training average negative_sample_loss at step 476600: 0.153916\n",
      "2022-11-08 19:02:26,215 INFO     Training average loss at step 476600: 0.159489\n",
      "2022-11-08 19:02:35,740 INFO     Training average positive_sample_loss at step 476700: 0.162974\n",
      "2022-11-08 19:02:35,741 INFO     Training average negative_sample_loss at step 476700: 0.165350\n",
      "2022-11-08 19:02:35,741 INFO     Training average loss at step 476700: 0.164162\n",
      "2022-11-08 19:02:45,265 INFO     Training average positive_sample_loss at step 476800: 0.162709\n",
      "2022-11-08 19:02:45,265 INFO     Training average negative_sample_loss at step 476800: 0.155911\n",
      "2022-11-08 19:02:45,266 INFO     Training average loss at step 476800: 0.159310\n",
      "2022-11-08 19:02:54,792 INFO     Training average positive_sample_loss at step 476900: 0.170238\n",
      "2022-11-08 19:02:54,792 INFO     Training average negative_sample_loss at step 476900: 0.158477\n",
      "2022-11-08 19:02:54,792 INFO     Training average loss at step 476900: 0.164358\n",
      "2022-11-08 19:03:04,319 INFO     Training average positive_sample_loss at step 477000: 0.165774\n",
      "2022-11-08 19:03:04,319 INFO     Training average negative_sample_loss at step 477000: 0.153234\n",
      "2022-11-08 19:03:04,319 INFO     Training average loss at step 477000: 0.159504\n",
      "2022-11-08 19:03:13,846 INFO     Training average positive_sample_loss at step 477100: 0.168991\n",
      "2022-11-08 19:03:13,846 INFO     Training average negative_sample_loss at step 477100: 0.156731\n",
      "2022-11-08 19:03:13,846 INFO     Training average loss at step 477100: 0.162861\n",
      "2022-11-08 19:03:23,374 INFO     Training average positive_sample_loss at step 477200: 0.163129\n",
      "2022-11-08 19:03:23,374 INFO     Training average negative_sample_loss at step 477200: 0.154761\n",
      "2022-11-08 19:03:23,374 INFO     Training average loss at step 477200: 0.158945\n",
      "2022-11-08 19:03:32,293 INFO     Training average positive_sample_loss at step 477300: 0.164568\n",
      "2022-11-08 19:03:32,293 INFO     Training average negative_sample_loss at step 477300: 0.157500\n",
      "2022-11-08 19:03:32,293 INFO     Training average loss at step 477300: 0.161034\n",
      "2022-11-08 19:03:41,682 INFO     Training average positive_sample_loss at step 477400: 0.162265\n",
      "2022-11-08 19:03:41,682 INFO     Training average negative_sample_loss at step 477400: 0.157559\n",
      "2022-11-08 19:03:41,682 INFO     Training average loss at step 477400: 0.159912\n",
      "2022-11-08 19:03:51,208 INFO     Training average positive_sample_loss at step 477500: 0.161697\n",
      "2022-11-08 19:03:51,208 INFO     Training average negative_sample_loss at step 477500: 0.155237\n",
      "2022-11-08 19:03:51,208 INFO     Training average loss at step 477500: 0.158467\n",
      "2022-11-08 19:04:00,735 INFO     Training average positive_sample_loss at step 477600: 0.170214\n",
      "2022-11-08 19:04:00,735 INFO     Training average negative_sample_loss at step 477600: 0.156554\n",
      "2022-11-08 19:04:00,735 INFO     Training average loss at step 477600: 0.163384\n",
      "2022-11-08 19:04:10,261 INFO     Training average positive_sample_loss at step 477700: 0.162782\n",
      "2022-11-08 19:04:10,261 INFO     Training average negative_sample_loss at step 477700: 0.152789\n",
      "2022-11-08 19:04:10,261 INFO     Training average loss at step 477700: 0.157785\n",
      "2022-11-08 19:04:19,786 INFO     Training average positive_sample_loss at step 477800: 0.164847\n",
      "2022-11-08 19:04:19,786 INFO     Training average negative_sample_loss at step 477800: 0.161086\n",
      "2022-11-08 19:04:19,786 INFO     Training average loss at step 477800: 0.162966\n",
      "2022-11-08 19:04:28,619 INFO     Training average positive_sample_loss at step 477900: 0.165942\n",
      "2022-11-08 19:04:28,619 INFO     Training average negative_sample_loss at step 477900: 0.155280\n",
      "2022-11-08 19:04:28,619 INFO     Training average loss at step 477900: 0.160611\n",
      "2022-11-08 19:04:38,142 INFO     Training average positive_sample_loss at step 478000: 0.168474\n",
      "2022-11-08 19:04:38,142 INFO     Training average negative_sample_loss at step 478000: 0.158880\n",
      "2022-11-08 19:04:38,142 INFO     Training average loss at step 478000: 0.163677\n",
      "2022-11-08 19:04:47,660 INFO     Training average positive_sample_loss at step 478100: 0.165731\n",
      "2022-11-08 19:04:47,660 INFO     Training average negative_sample_loss at step 478100: 0.160640\n",
      "2022-11-08 19:04:47,660 INFO     Training average loss at step 478100: 0.163185\n",
      "2022-11-08 19:04:57,184 INFO     Training average positive_sample_loss at step 478200: 0.163042\n",
      "2022-11-08 19:04:57,184 INFO     Training average negative_sample_loss at step 478200: 0.149074\n",
      "2022-11-08 19:04:57,184 INFO     Training average loss at step 478200: 0.156058\n",
      "2022-11-08 19:05:06,708 INFO     Training average positive_sample_loss at step 478300: 0.168545\n",
      "2022-11-08 19:05:06,708 INFO     Training average negative_sample_loss at step 478300: 0.153786\n",
      "2022-11-08 19:05:06,708 INFO     Training average loss at step 478300: 0.161166\n",
      "2022-11-08 19:05:16,231 INFO     Training average positive_sample_loss at step 478400: 0.162596\n",
      "2022-11-08 19:05:16,231 INFO     Training average negative_sample_loss at step 478400: 0.154459\n",
      "2022-11-08 19:05:16,231 INFO     Training average loss at step 478400: 0.158527\n",
      "2022-11-08 19:05:25,754 INFO     Training average positive_sample_loss at step 478500: 0.168739\n",
      "2022-11-08 19:05:25,754 INFO     Training average negative_sample_loss at step 478500: 0.154664\n",
      "2022-11-08 19:05:25,754 INFO     Training average loss at step 478500: 0.161702\n",
      "2022-11-08 19:05:35,274 INFO     Training average positive_sample_loss at step 478600: 0.163921\n",
      "2022-11-08 19:05:35,274 INFO     Training average negative_sample_loss at step 478600: 0.155348\n",
      "2022-11-08 19:05:35,274 INFO     Training average loss at step 478600: 0.159635\n",
      "2022-11-08 19:05:44,793 INFO     Training average positive_sample_loss at step 478700: 0.167158\n",
      "2022-11-08 19:05:44,793 INFO     Training average negative_sample_loss at step 478700: 0.158783\n",
      "2022-11-08 19:05:44,793 INFO     Training average loss at step 478700: 0.162971\n",
      "2022-11-08 19:05:54,315 INFO     Training average positive_sample_loss at step 478800: 0.169556\n",
      "2022-11-08 19:05:54,315 INFO     Training average negative_sample_loss at step 478800: 0.158148\n",
      "2022-11-08 19:05:54,315 INFO     Training average loss at step 478800: 0.163852\n",
      "2022-11-08 19:06:03,841 INFO     Training average positive_sample_loss at step 478900: 0.167043\n",
      "2022-11-08 19:06:03,841 INFO     Training average negative_sample_loss at step 478900: 0.156841\n",
      "2022-11-08 19:06:03,841 INFO     Training average loss at step 478900: 0.161942\n",
      "2022-11-08 19:06:13,363 INFO     Training average positive_sample_loss at step 479000: 0.169379\n",
      "2022-11-08 19:06:13,363 INFO     Training average negative_sample_loss at step 479000: 0.153306\n",
      "2022-11-08 19:06:13,363 INFO     Training average loss at step 479000: 0.161342\n",
      "2022-11-08 19:06:22,885 INFO     Training average positive_sample_loss at step 479100: 0.168340\n",
      "2022-11-08 19:06:22,885 INFO     Training average negative_sample_loss at step 479100: 0.152606\n",
      "2022-11-08 19:06:22,885 INFO     Training average loss at step 479100: 0.160473\n",
      "2022-11-08 19:06:32,403 INFO     Training average positive_sample_loss at step 479200: 0.172391\n",
      "2022-11-08 19:06:32,403 INFO     Training average negative_sample_loss at step 479200: 0.157164\n",
      "2022-11-08 19:06:32,403 INFO     Training average loss at step 479200: 0.164778\n",
      "2022-11-08 19:06:41,927 INFO     Training average positive_sample_loss at step 479300: 0.167069\n",
      "2022-11-08 19:06:41,927 INFO     Training average negative_sample_loss at step 479300: 0.155824\n",
      "2022-11-08 19:06:41,927 INFO     Training average loss at step 479300: 0.161446\n",
      "2022-11-08 19:06:51,448 INFO     Training average positive_sample_loss at step 479400: 0.171014\n",
      "2022-11-08 19:06:51,448 INFO     Training average negative_sample_loss at step 479400: 0.157752\n",
      "2022-11-08 19:06:51,448 INFO     Training average loss at step 479400: 0.164383\n",
      "2022-11-08 19:07:00,971 INFO     Training average positive_sample_loss at step 479500: 0.172273\n",
      "2022-11-08 19:07:00,971 INFO     Training average negative_sample_loss at step 479500: 0.155221\n",
      "2022-11-08 19:07:00,971 INFO     Training average loss at step 479500: 0.163747\n",
      "2022-11-08 19:07:10,495 INFO     Training average positive_sample_loss at step 479600: 0.171316\n",
      "2022-11-08 19:07:10,495 INFO     Training average negative_sample_loss at step 479600: 0.154930\n",
      "2022-11-08 19:07:10,495 INFO     Training average loss at step 479600: 0.163123\n",
      "2022-11-08 19:07:20,014 INFO     Training average positive_sample_loss at step 479700: 0.168610\n",
      "2022-11-08 19:07:20,014 INFO     Training average negative_sample_loss at step 479700: 0.154426\n",
      "2022-11-08 19:07:20,014 INFO     Training average loss at step 479700: 0.161518\n",
      "2022-11-08 19:07:29,535 INFO     Training average positive_sample_loss at step 479800: 0.169806\n",
      "2022-11-08 19:07:29,535 INFO     Training average negative_sample_loss at step 479800: 0.149700\n",
      "2022-11-08 19:07:29,535 INFO     Training average loss at step 479800: 0.159753\n",
      "2022-11-08 19:07:39,061 INFO     Training average positive_sample_loss at step 479900: 0.171328\n",
      "2022-11-08 19:07:39,061 INFO     Training average negative_sample_loss at step 479900: 0.158381\n",
      "2022-11-08 19:07:39,061 INFO     Training average loss at step 479900: 0.164855\n",
      "2022-11-08 19:07:51,455 INFO     Training average positive_sample_loss at step 480000: 0.166456\n",
      "2022-11-08 19:07:51,455 INFO     Training average negative_sample_loss at step 480000: 0.150620\n",
      "2022-11-08 19:07:51,455 INFO     Training average loss at step 480000: 0.158538\n",
      "2022-11-08 19:08:00,974 INFO     Training average positive_sample_loss at step 480100: 0.165726\n",
      "2022-11-08 19:08:00,974 INFO     Training average negative_sample_loss at step 480100: 0.156449\n",
      "2022-11-08 19:08:00,974 INFO     Training average loss at step 480100: 0.161087\n",
      "2022-11-08 19:08:10,498 INFO     Training average positive_sample_loss at step 480200: 0.172513\n",
      "2022-11-08 19:08:10,498 INFO     Training average negative_sample_loss at step 480200: 0.154242\n",
      "2022-11-08 19:08:10,498 INFO     Training average loss at step 480200: 0.163378\n",
      "2022-11-08 19:08:20,020 INFO     Training average positive_sample_loss at step 480300: 0.167497\n",
      "2022-11-08 19:08:20,020 INFO     Training average negative_sample_loss at step 480300: 0.154456\n",
      "2022-11-08 19:08:20,020 INFO     Training average loss at step 480300: 0.160976\n",
      "2022-11-08 19:08:29,547 INFO     Training average positive_sample_loss at step 480400: 0.172063\n",
      "2022-11-08 19:08:29,547 INFO     Training average negative_sample_loss at step 480400: 0.153272\n",
      "2022-11-08 19:08:29,547 INFO     Training average loss at step 480400: 0.162668\n",
      "2022-11-08 19:08:39,071 INFO     Training average positive_sample_loss at step 480500: 0.167793\n",
      "2022-11-08 19:08:39,071 INFO     Training average negative_sample_loss at step 480500: 0.158632\n",
      "2022-11-08 19:08:39,071 INFO     Training average loss at step 480500: 0.163212\n",
      "2022-11-08 19:08:48,589 INFO     Training average positive_sample_loss at step 480600: 0.171044\n",
      "2022-11-08 19:08:48,590 INFO     Training average negative_sample_loss at step 480600: 0.157780\n",
      "2022-11-08 19:08:48,590 INFO     Training average loss at step 480600: 0.164412\n",
      "2022-11-08 19:08:58,111 INFO     Training average positive_sample_loss at step 480700: 0.165330\n",
      "2022-11-08 19:08:58,111 INFO     Training average negative_sample_loss at step 480700: 0.154755\n",
      "2022-11-08 19:08:58,111 INFO     Training average loss at step 480700: 0.160042\n",
      "2022-11-08 19:09:07,637 INFO     Training average positive_sample_loss at step 480800: 0.176314\n",
      "2022-11-08 19:09:07,637 INFO     Training average negative_sample_loss at step 480800: 0.155859\n",
      "2022-11-08 19:09:07,637 INFO     Training average loss at step 480800: 0.166087\n",
      "2022-11-08 19:09:17,159 INFO     Training average positive_sample_loss at step 480900: 0.169186\n",
      "2022-11-08 19:09:17,159 INFO     Training average negative_sample_loss at step 480900: 0.153499\n",
      "2022-11-08 19:09:17,160 INFO     Training average loss at step 480900: 0.161343\n",
      "2022-11-08 19:09:26,682 INFO     Training average positive_sample_loss at step 481000: 0.179810\n",
      "2022-11-08 19:09:26,682 INFO     Training average negative_sample_loss at step 481000: 0.153642\n",
      "2022-11-08 19:09:26,682 INFO     Training average loss at step 481000: 0.166726\n",
      "2022-11-08 19:09:36,204 INFO     Training average positive_sample_loss at step 481100: 0.169732\n",
      "2022-11-08 19:09:36,204 INFO     Training average negative_sample_loss at step 481100: 0.151443\n",
      "2022-11-08 19:09:36,204 INFO     Training average loss at step 481100: 0.160587\n",
      "2022-11-08 19:09:45,723 INFO     Training average positive_sample_loss at step 481200: 0.170131\n",
      "2022-11-08 19:09:45,723 INFO     Training average negative_sample_loss at step 481200: 0.155485\n",
      "2022-11-08 19:09:45,723 INFO     Training average loss at step 481200: 0.162808\n",
      "2022-11-08 19:09:55,246 INFO     Training average positive_sample_loss at step 481300: 0.168834\n",
      "2022-11-08 19:09:55,246 INFO     Training average negative_sample_loss at step 481300: 0.156015\n",
      "2022-11-08 19:09:55,246 INFO     Training average loss at step 481300: 0.162425\n",
      "2022-11-08 19:10:04,771 INFO     Training average positive_sample_loss at step 481400: 0.173800\n",
      "2022-11-08 19:10:04,771 INFO     Training average negative_sample_loss at step 481400: 0.155468\n",
      "2022-11-08 19:10:04,771 INFO     Training average loss at step 481400: 0.164634\n",
      "2022-11-08 19:10:14,292 INFO     Training average positive_sample_loss at step 481500: 0.171218\n",
      "2022-11-08 19:10:14,292 INFO     Training average negative_sample_loss at step 481500: 0.155874\n",
      "2022-11-08 19:10:14,292 INFO     Training average loss at step 481500: 0.163546\n",
      "2022-11-08 19:10:23,815 INFO     Training average positive_sample_loss at step 481600: 0.172062\n",
      "2022-11-08 19:10:23,816 INFO     Training average negative_sample_loss at step 481600: 0.159604\n",
      "2022-11-08 19:10:23,816 INFO     Training average loss at step 481600: 0.165833\n",
      "2022-11-08 19:10:33,338 INFO     Training average positive_sample_loss at step 481700: 0.168476\n",
      "2022-11-08 19:10:33,338 INFO     Training average negative_sample_loss at step 481700: 0.150648\n",
      "2022-11-08 19:10:33,338 INFO     Training average loss at step 481700: 0.159562\n",
      "2022-11-08 19:10:42,859 INFO     Training average positive_sample_loss at step 481800: 0.168085\n",
      "2022-11-08 19:10:42,859 INFO     Training average negative_sample_loss at step 481800: 0.157743\n",
      "2022-11-08 19:10:42,859 INFO     Training average loss at step 481800: 0.162914\n",
      "2022-11-08 19:10:52,382 INFO     Training average positive_sample_loss at step 481900: 0.167995\n",
      "2022-11-08 19:10:52,382 INFO     Training average negative_sample_loss at step 481900: 0.152753\n",
      "2022-11-08 19:10:52,382 INFO     Training average loss at step 481900: 0.160374\n",
      "2022-11-08 19:11:01,908 INFO     Training average positive_sample_loss at step 482000: 0.171805\n",
      "2022-11-08 19:11:01,908 INFO     Training average negative_sample_loss at step 482000: 0.153344\n",
      "2022-11-08 19:11:01,908 INFO     Training average loss at step 482000: 0.162575\n",
      "2022-11-08 19:11:11,431 INFO     Training average positive_sample_loss at step 482100: 0.166205\n",
      "2022-11-08 19:11:11,431 INFO     Training average negative_sample_loss at step 482100: 0.154111\n",
      "2022-11-08 19:11:11,431 INFO     Training average loss at step 482100: 0.160158\n",
      "2022-11-08 19:11:20,951 INFO     Training average positive_sample_loss at step 482200: 0.172396\n",
      "2022-11-08 19:11:20,951 INFO     Training average negative_sample_loss at step 482200: 0.153926\n",
      "2022-11-08 19:11:20,951 INFO     Training average loss at step 482200: 0.163161\n",
      "2022-11-08 19:11:30,472 INFO     Training average positive_sample_loss at step 482300: 0.168138\n",
      "2022-11-08 19:11:30,472 INFO     Training average negative_sample_loss at step 482300: 0.152182\n",
      "2022-11-08 19:11:30,472 INFO     Training average loss at step 482300: 0.160160\n",
      "2022-11-08 19:11:39,996 INFO     Training average positive_sample_loss at step 482400: 0.173985\n",
      "2022-11-08 19:11:39,996 INFO     Training average negative_sample_loss at step 482400: 0.153755\n",
      "2022-11-08 19:11:39,996 INFO     Training average loss at step 482400: 0.163870\n",
      "2022-11-08 19:11:49,520 INFO     Training average positive_sample_loss at step 482500: 0.171288\n",
      "2022-11-08 19:11:49,520 INFO     Training average negative_sample_loss at step 482500: 0.157855\n",
      "2022-11-08 19:11:49,520 INFO     Training average loss at step 482500: 0.164572\n",
      "2022-11-08 19:11:59,045 INFO     Training average positive_sample_loss at step 482600: 0.164973\n",
      "2022-11-08 19:11:59,045 INFO     Training average negative_sample_loss at step 482600: 0.157565\n",
      "2022-11-08 19:11:59,045 INFO     Training average loss at step 482600: 0.161269\n",
      "2022-11-08 19:12:08,568 INFO     Training average positive_sample_loss at step 482700: 0.174149\n",
      "2022-11-08 19:12:08,568 INFO     Training average negative_sample_loss at step 482700: 0.154165\n",
      "2022-11-08 19:12:08,568 INFO     Training average loss at step 482700: 0.164157\n",
      "2022-11-08 19:12:17,387 INFO     Training average positive_sample_loss at step 482800: 0.175373\n",
      "2022-11-08 19:12:17,388 INFO     Training average negative_sample_loss at step 482800: 0.154049\n",
      "2022-11-08 19:12:17,388 INFO     Training average loss at step 482800: 0.164711\n",
      "2022-11-08 19:12:26,918 INFO     Training average positive_sample_loss at step 482900: 0.177593\n",
      "2022-11-08 19:12:26,919 INFO     Training average negative_sample_loss at step 482900: 0.154102\n",
      "2022-11-08 19:12:26,919 INFO     Training average loss at step 482900: 0.165847\n",
      "2022-11-08 19:12:36,449 INFO     Training average positive_sample_loss at step 483000: 0.172592\n",
      "2022-11-08 19:12:36,449 INFO     Training average negative_sample_loss at step 483000: 0.154824\n",
      "2022-11-08 19:12:36,450 INFO     Training average loss at step 483000: 0.163708\n",
      "2022-11-08 19:12:45,980 INFO     Training average positive_sample_loss at step 483100: 0.173511\n",
      "2022-11-08 19:12:45,980 INFO     Training average negative_sample_loss at step 483100: 0.158629\n",
      "2022-11-08 19:12:45,980 INFO     Training average loss at step 483100: 0.166070\n",
      "2022-11-08 19:12:55,510 INFO     Training average positive_sample_loss at step 483200: 0.166578\n",
      "2022-11-08 19:12:55,510 INFO     Training average negative_sample_loss at step 483200: 0.158919\n",
      "2022-11-08 19:12:55,510 INFO     Training average loss at step 483200: 0.162748\n",
      "2022-11-08 19:13:05,036 INFO     Training average positive_sample_loss at step 483300: 0.169277\n",
      "2022-11-08 19:13:05,036 INFO     Training average negative_sample_loss at step 483300: 0.152290\n",
      "2022-11-08 19:13:05,036 INFO     Training average loss at step 483300: 0.160784\n",
      "2022-11-08 19:13:13,866 INFO     Training average positive_sample_loss at step 483400: 0.178516\n",
      "2022-11-08 19:13:13,866 INFO     Training average negative_sample_loss at step 483400: 0.158310\n",
      "2022-11-08 19:13:13,866 INFO     Training average loss at step 483400: 0.168413\n",
      "2022-11-08 19:13:23,394 INFO     Training average positive_sample_loss at step 483500: 0.172161\n",
      "2022-11-08 19:13:23,394 INFO     Training average negative_sample_loss at step 483500: 0.151563\n",
      "2022-11-08 19:13:23,394 INFO     Training average loss at step 483500: 0.161862\n",
      "2022-11-08 19:13:32,924 INFO     Training average positive_sample_loss at step 483600: 0.171335\n",
      "2022-11-08 19:13:32,924 INFO     Training average negative_sample_loss at step 483600: 0.153298\n",
      "2022-11-08 19:13:32,924 INFO     Training average loss at step 483600: 0.162316\n",
      "2022-11-08 19:13:42,453 INFO     Training average positive_sample_loss at step 483700: 0.166916\n",
      "2022-11-08 19:13:42,453 INFO     Training average negative_sample_loss at step 483700: 0.155244\n",
      "2022-11-08 19:13:42,453 INFO     Training average loss at step 483700: 0.161080\n",
      "2022-11-08 19:13:51,985 INFO     Training average positive_sample_loss at step 483800: 0.173021\n",
      "2022-11-08 19:13:51,985 INFO     Training average negative_sample_loss at step 483800: 0.155567\n",
      "2022-11-08 19:13:51,985 INFO     Training average loss at step 483800: 0.164294\n",
      "2022-11-08 19:14:01,515 INFO     Training average positive_sample_loss at step 483900: 0.168038\n",
      "2022-11-08 19:14:01,515 INFO     Training average negative_sample_loss at step 483900: 0.160106\n",
      "2022-11-08 19:14:01,515 INFO     Training average loss at step 483900: 0.164072\n",
      "2022-11-08 19:14:11,043 INFO     Training average positive_sample_loss at step 484000: 0.172162\n",
      "2022-11-08 19:14:11,043 INFO     Training average negative_sample_loss at step 484000: 0.150838\n",
      "2022-11-08 19:14:11,043 INFO     Training average loss at step 484000: 0.161500\n",
      "2022-11-08 19:14:20,570 INFO     Training average positive_sample_loss at step 484100: 0.169114\n",
      "2022-11-08 19:14:20,570 INFO     Training average negative_sample_loss at step 484100: 0.157483\n",
      "2022-11-08 19:14:20,570 INFO     Training average loss at step 484100: 0.163298\n",
      "2022-11-08 19:14:30,099 INFO     Training average positive_sample_loss at step 484200: 0.164729\n",
      "2022-11-08 19:14:30,099 INFO     Training average negative_sample_loss at step 484200: 0.155035\n",
      "2022-11-08 19:14:30,099 INFO     Training average loss at step 484200: 0.159882\n",
      "2022-11-08 19:14:39,627 INFO     Training average positive_sample_loss at step 484300: 0.170105\n",
      "2022-11-08 19:14:39,628 INFO     Training average negative_sample_loss at step 484300: 0.153032\n",
      "2022-11-08 19:14:39,628 INFO     Training average loss at step 484300: 0.161569\n",
      "2022-11-08 19:14:49,161 INFO     Training average positive_sample_loss at step 484400: 0.172236\n",
      "2022-11-08 19:14:49,161 INFO     Training average negative_sample_loss at step 484400: 0.152136\n",
      "2022-11-08 19:14:49,161 INFO     Training average loss at step 484400: 0.162186\n",
      "2022-11-08 19:14:58,690 INFO     Training average positive_sample_loss at step 484500: 0.168288\n",
      "2022-11-08 19:14:58,690 INFO     Training average negative_sample_loss at step 484500: 0.161040\n",
      "2022-11-08 19:14:58,690 INFO     Training average loss at step 484500: 0.164664\n",
      "2022-11-08 19:15:08,217 INFO     Training average positive_sample_loss at step 484600: 0.173180\n",
      "2022-11-08 19:15:08,217 INFO     Training average negative_sample_loss at step 484600: 0.155950\n",
      "2022-11-08 19:15:08,217 INFO     Training average loss at step 484600: 0.164565\n",
      "2022-11-08 19:15:17,746 INFO     Training average positive_sample_loss at step 484700: 0.178191\n",
      "2022-11-08 19:15:17,746 INFO     Training average negative_sample_loss at step 484700: 0.156473\n",
      "2022-11-08 19:15:17,746 INFO     Training average loss at step 484700: 0.167332\n",
      "2022-11-08 19:15:27,278 INFO     Training average positive_sample_loss at step 484800: 0.170351\n",
      "2022-11-08 19:15:27,278 INFO     Training average negative_sample_loss at step 484800: 0.154785\n",
      "2022-11-08 19:15:27,278 INFO     Training average loss at step 484800: 0.162568\n",
      "2022-11-08 19:15:36,808 INFO     Training average positive_sample_loss at step 484900: 0.173557\n",
      "2022-11-08 19:15:36,808 INFO     Training average negative_sample_loss at step 484900: 0.153745\n",
      "2022-11-08 19:15:36,808 INFO     Training average loss at step 484900: 0.163651\n",
      "2022-11-08 19:15:46,337 INFO     Training average positive_sample_loss at step 485000: 0.175738\n",
      "2022-11-08 19:15:46,337 INFO     Training average negative_sample_loss at step 485000: 0.152434\n",
      "2022-11-08 19:15:46,337 INFO     Training average loss at step 485000: 0.164086\n",
      "2022-11-08 19:15:56,783 INFO     Training average positive_sample_loss at step 485100: 0.171701\n",
      "2022-11-08 19:15:56,783 INFO     Training average negative_sample_loss at step 485100: 0.158626\n",
      "2022-11-08 19:15:56,783 INFO     Training average loss at step 485100: 0.165164\n",
      "2022-11-08 19:16:07,876 INFO     Training average positive_sample_loss at step 485200: 0.167482\n",
      "2022-11-08 19:16:07,876 INFO     Training average negative_sample_loss at step 485200: 0.159197\n",
      "2022-11-08 19:16:07,877 INFO     Training average loss at step 485200: 0.163340\n",
      "2022-11-08 19:16:17,409 INFO     Training average positive_sample_loss at step 485300: 0.177243\n",
      "2022-11-08 19:16:17,409 INFO     Training average negative_sample_loss at step 485300: 0.153172\n",
      "2022-11-08 19:16:17,409 INFO     Training average loss at step 485300: 0.165207\n",
      "2022-11-08 19:16:26,937 INFO     Training average positive_sample_loss at step 485400: 0.164775\n",
      "2022-11-08 19:16:26,938 INFO     Training average negative_sample_loss at step 485400: 0.161065\n",
      "2022-11-08 19:16:26,938 INFO     Training average loss at step 485400: 0.162920\n",
      "2022-11-08 19:16:36,463 INFO     Training average positive_sample_loss at step 485500: 0.175042\n",
      "2022-11-08 19:16:36,463 INFO     Training average negative_sample_loss at step 485500: 0.153891\n",
      "2022-11-08 19:16:36,463 INFO     Training average loss at step 485500: 0.164466\n",
      "2022-11-08 19:16:45,991 INFO     Training average positive_sample_loss at step 485600: 0.176136\n",
      "2022-11-08 19:16:45,991 INFO     Training average negative_sample_loss at step 485600: 0.156203\n",
      "2022-11-08 19:16:45,991 INFO     Training average loss at step 485600: 0.166169\n",
      "2022-11-08 19:16:55,519 INFO     Training average positive_sample_loss at step 485700: 0.170799\n",
      "2022-11-08 19:16:55,519 INFO     Training average negative_sample_loss at step 485700: 0.154888\n",
      "2022-11-08 19:16:55,519 INFO     Training average loss at step 485700: 0.162844\n",
      "2022-11-08 19:17:05,052 INFO     Training average positive_sample_loss at step 485800: 0.176982\n",
      "2022-11-08 19:17:05,052 INFO     Training average negative_sample_loss at step 485800: 0.155710\n",
      "2022-11-08 19:17:05,052 INFO     Training average loss at step 485800: 0.166346\n",
      "2022-11-08 19:17:14,581 INFO     Training average positive_sample_loss at step 485900: 0.171595\n",
      "2022-11-08 19:17:14,581 INFO     Training average negative_sample_loss at step 485900: 0.154488\n",
      "2022-11-08 19:17:14,581 INFO     Training average loss at step 485900: 0.163041\n",
      "2022-11-08 19:17:24,118 INFO     Training average positive_sample_loss at step 486000: 0.170479\n",
      "2022-11-08 19:17:24,118 INFO     Training average negative_sample_loss at step 486000: 0.152856\n",
      "2022-11-08 19:17:24,118 INFO     Training average loss at step 486000: 0.161667\n",
      "2022-11-08 19:17:33,643 INFO     Training average positive_sample_loss at step 486100: 0.173133\n",
      "2022-11-08 19:17:33,643 INFO     Training average negative_sample_loss at step 486100: 0.155686\n",
      "2022-11-08 19:17:33,643 INFO     Training average loss at step 486100: 0.164409\n",
      "2022-11-08 19:17:43,170 INFO     Training average positive_sample_loss at step 486200: 0.170769\n",
      "2022-11-08 19:17:43,170 INFO     Training average negative_sample_loss at step 486200: 0.158176\n",
      "2022-11-08 19:17:43,170 INFO     Training average loss at step 486200: 0.164472\n",
      "2022-11-08 19:17:52,701 INFO     Training average positive_sample_loss at step 486300: 0.178744\n",
      "2022-11-08 19:17:52,701 INFO     Training average negative_sample_loss at step 486300: 0.158887\n",
      "2022-11-08 19:17:52,701 INFO     Training average loss at step 486300: 0.168815\n",
      "2022-11-08 19:18:02,232 INFO     Training average positive_sample_loss at step 486400: 0.173323\n",
      "2022-11-08 19:18:02,232 INFO     Training average negative_sample_loss at step 486400: 0.154859\n",
      "2022-11-08 19:18:02,233 INFO     Training average loss at step 486400: 0.164091\n",
      "2022-11-08 19:18:11,759 INFO     Training average positive_sample_loss at step 486500: 0.172586\n",
      "2022-11-08 19:18:11,759 INFO     Training average negative_sample_loss at step 486500: 0.153885\n",
      "2022-11-08 19:18:11,759 INFO     Training average loss at step 486500: 0.163236\n",
      "2022-11-08 19:18:21,288 INFO     Training average positive_sample_loss at step 486600: 0.176555\n",
      "2022-11-08 19:18:21,288 INFO     Training average negative_sample_loss at step 486600: 0.156203\n",
      "2022-11-08 19:18:21,288 INFO     Training average loss at step 486600: 0.166379\n",
      "2022-11-08 19:18:30,814 INFO     Training average positive_sample_loss at step 486700: 0.172896\n",
      "2022-11-08 19:18:30,814 INFO     Training average negative_sample_loss at step 486700: 0.151541\n",
      "2022-11-08 19:18:30,814 INFO     Training average loss at step 486700: 0.162218\n",
      "2022-11-08 19:18:40,346 INFO     Training average positive_sample_loss at step 486800: 0.168132\n",
      "2022-11-08 19:18:40,346 INFO     Training average negative_sample_loss at step 486800: 0.158580\n",
      "2022-11-08 19:18:40,346 INFO     Training average loss at step 486800: 0.163356\n",
      "2022-11-08 19:18:49,877 INFO     Training average positive_sample_loss at step 486900: 0.173896\n",
      "2022-11-08 19:18:49,877 INFO     Training average negative_sample_loss at step 486900: 0.155656\n",
      "2022-11-08 19:18:49,877 INFO     Training average loss at step 486900: 0.164776\n",
      "2022-11-08 19:18:59,406 INFO     Training average positive_sample_loss at step 487000: 0.178245\n",
      "2022-11-08 19:18:59,407 INFO     Training average negative_sample_loss at step 487000: 0.150926\n",
      "2022-11-08 19:18:59,407 INFO     Training average loss at step 487000: 0.164586\n",
      "2022-11-08 19:19:08,935 INFO     Training average positive_sample_loss at step 487100: 0.175684\n",
      "2022-11-08 19:19:08,935 INFO     Training average negative_sample_loss at step 487100: 0.155346\n",
      "2022-11-08 19:19:08,935 INFO     Training average loss at step 487100: 0.165515\n",
      "2022-11-08 19:19:18,462 INFO     Training average positive_sample_loss at step 487200: 0.169200\n",
      "2022-11-08 19:19:18,462 INFO     Training average negative_sample_loss at step 487200: 0.153231\n",
      "2022-11-08 19:19:18,462 INFO     Training average loss at step 487200: 0.161216\n",
      "2022-11-08 19:19:27,989 INFO     Training average positive_sample_loss at step 487300: 0.175885\n",
      "2022-11-08 19:19:27,989 INFO     Training average negative_sample_loss at step 487300: 0.151336\n",
      "2022-11-08 19:19:27,990 INFO     Training average loss at step 487300: 0.163610\n",
      "2022-11-08 19:19:37,518 INFO     Training average positive_sample_loss at step 487400: 0.182638\n",
      "2022-11-08 19:19:37,518 INFO     Training average negative_sample_loss at step 487400: 0.157460\n",
      "2022-11-08 19:19:37,518 INFO     Training average loss at step 487400: 0.170049\n",
      "2022-11-08 19:19:47,051 INFO     Training average positive_sample_loss at step 487500: 0.176212\n",
      "2022-11-08 19:19:47,051 INFO     Training average negative_sample_loss at step 487500: 0.155671\n",
      "2022-11-08 19:19:47,051 INFO     Training average loss at step 487500: 0.165942\n",
      "2022-11-08 19:19:56,579 INFO     Training average positive_sample_loss at step 487600: 0.180159\n",
      "2022-11-08 19:19:56,579 INFO     Training average negative_sample_loss at step 487600: 0.149624\n",
      "2022-11-08 19:19:56,579 INFO     Training average loss at step 487600: 0.164892\n",
      "2022-11-08 19:20:06,106 INFO     Training average positive_sample_loss at step 487700: 0.177715\n",
      "2022-11-08 19:20:06,106 INFO     Training average negative_sample_loss at step 487700: 0.158242\n",
      "2022-11-08 19:20:06,106 INFO     Training average loss at step 487700: 0.167978\n",
      "2022-11-08 19:20:15,633 INFO     Training average positive_sample_loss at step 487800: 0.175556\n",
      "2022-11-08 19:20:15,633 INFO     Training average negative_sample_loss at step 487800: 0.154555\n",
      "2022-11-08 19:20:15,634 INFO     Training average loss at step 487800: 0.165056\n",
      "2022-11-08 19:20:25,162 INFO     Training average positive_sample_loss at step 487900: 0.174585\n",
      "2022-11-08 19:20:25,162 INFO     Training average negative_sample_loss at step 487900: 0.153489\n",
      "2022-11-08 19:20:25,162 INFO     Training average loss at step 487900: 0.164037\n",
      "2022-11-08 19:20:34,692 INFO     Training average positive_sample_loss at step 488000: 0.171412\n",
      "2022-11-08 19:20:34,693 INFO     Training average negative_sample_loss at step 488000: 0.154917\n",
      "2022-11-08 19:20:34,693 INFO     Training average loss at step 488000: 0.163164\n",
      "2022-11-08 19:20:44,224 INFO     Training average positive_sample_loss at step 488100: 0.176555\n",
      "2022-11-08 19:20:44,224 INFO     Training average negative_sample_loss at step 488100: 0.158955\n",
      "2022-11-08 19:20:44,224 INFO     Training average loss at step 488100: 0.167755\n",
      "2022-11-08 19:20:53,751 INFO     Training average positive_sample_loss at step 488200: 0.179251\n",
      "2022-11-08 19:20:53,751 INFO     Training average negative_sample_loss at step 488200: 0.156744\n",
      "2022-11-08 19:20:53,751 INFO     Training average loss at step 488200: 0.167997\n",
      "2022-11-08 19:21:02,622 INFO     Training average positive_sample_loss at step 488300: 0.175208\n",
      "2022-11-08 19:21:02,622 INFO     Training average negative_sample_loss at step 488300: 0.153306\n",
      "2022-11-08 19:21:02,622 INFO     Training average loss at step 488300: 0.164257\n",
      "2022-11-08 19:21:12,149 INFO     Training average positive_sample_loss at step 488400: 0.177045\n",
      "2022-11-08 19:21:12,149 INFO     Training average negative_sample_loss at step 488400: 0.154429\n",
      "2022-11-08 19:21:12,149 INFO     Training average loss at step 488400: 0.165737\n",
      "2022-11-08 19:21:21,679 INFO     Training average positive_sample_loss at step 488500: 0.170776\n",
      "2022-11-08 19:21:21,679 INFO     Training average negative_sample_loss at step 488500: 0.154022\n",
      "2022-11-08 19:21:21,679 INFO     Training average loss at step 488500: 0.162399\n",
      "2022-11-08 19:21:31,209 INFO     Training average positive_sample_loss at step 488600: 0.174756\n",
      "2022-11-08 19:21:31,209 INFO     Training average negative_sample_loss at step 488600: 0.159660\n",
      "2022-11-08 19:21:31,209 INFO     Training average loss at step 488600: 0.167208\n",
      "2022-11-08 19:21:40,742 INFO     Training average positive_sample_loss at step 488700: 0.181094\n",
      "2022-11-08 19:21:40,742 INFO     Training average negative_sample_loss at step 488700: 0.157990\n",
      "2022-11-08 19:21:40,742 INFO     Training average loss at step 488700: 0.169542\n",
      "2022-11-08 19:21:49,864 INFO     Training average positive_sample_loss at step 488800: 0.174026\n",
      "2022-11-08 19:21:49,864 INFO     Training average negative_sample_loss at step 488800: 0.152137\n",
      "2022-11-08 19:21:49,864 INFO     Training average loss at step 488800: 0.163081\n",
      "2022-11-08 19:21:59,152 INFO     Training average positive_sample_loss at step 488900: 0.172857\n",
      "2022-11-08 19:21:59,152 INFO     Training average negative_sample_loss at step 488900: 0.157695\n",
      "2022-11-08 19:21:59,152 INFO     Training average loss at step 488900: 0.165276\n",
      "2022-11-08 19:22:08,848 INFO     Training average positive_sample_loss at step 489000: 0.174412\n",
      "2022-11-08 19:22:08,848 INFO     Training average negative_sample_loss at step 489000: 0.155646\n",
      "2022-11-08 19:22:08,848 INFO     Training average loss at step 489000: 0.165029\n",
      "2022-11-08 19:22:18,541 INFO     Training average positive_sample_loss at step 489100: 0.177308\n",
      "2022-11-08 19:22:18,541 INFO     Training average negative_sample_loss at step 489100: 0.156003\n",
      "2022-11-08 19:22:18,542 INFO     Training average loss at step 489100: 0.166656\n",
      "2022-11-08 19:22:28,240 INFO     Training average positive_sample_loss at step 489200: 0.169994\n",
      "2022-11-08 19:22:28,240 INFO     Training average negative_sample_loss at step 489200: 0.153240\n",
      "2022-11-08 19:22:28,240 INFO     Training average loss at step 489200: 0.161617\n",
      "2022-11-08 19:22:37,935 INFO     Training average positive_sample_loss at step 489300: 0.174394\n",
      "2022-11-08 19:22:37,935 INFO     Training average negative_sample_loss at step 489300: 0.155599\n",
      "2022-11-08 19:22:37,935 INFO     Training average loss at step 489300: 0.164996\n",
      "2022-11-08 19:22:47,626 INFO     Training average positive_sample_loss at step 489400: 0.172796\n",
      "2022-11-08 19:22:47,626 INFO     Training average negative_sample_loss at step 489400: 0.157341\n",
      "2022-11-08 19:22:47,626 INFO     Training average loss at step 489400: 0.165069\n",
      "2022-11-08 19:22:57,317 INFO     Training average positive_sample_loss at step 489500: 0.181191\n",
      "2022-11-08 19:22:57,317 INFO     Training average negative_sample_loss at step 489500: 0.157984\n",
      "2022-11-08 19:22:57,318 INFO     Training average loss at step 489500: 0.169587\n",
      "2022-11-08 19:23:07,012 INFO     Training average positive_sample_loss at step 489600: 0.179114\n",
      "2022-11-08 19:23:07,012 INFO     Training average negative_sample_loss at step 489600: 0.155435\n",
      "2022-11-08 19:23:07,012 INFO     Training average loss at step 489600: 0.167274\n",
      "2022-11-08 19:23:18,038 INFO     Training average positive_sample_loss at step 489700: 0.177116\n",
      "2022-11-08 19:23:18,038 INFO     Training average negative_sample_loss at step 489700: 0.154026\n",
      "2022-11-08 19:23:18,038 INFO     Training average loss at step 489700: 0.165571\n",
      "2022-11-08 19:23:27,879 INFO     Training average positive_sample_loss at step 489800: 0.174506\n",
      "2022-11-08 19:23:27,879 INFO     Training average negative_sample_loss at step 489800: 0.153801\n",
      "2022-11-08 19:23:27,879 INFO     Training average loss at step 489800: 0.164153\n",
      "2022-11-08 19:23:38,183 INFO     Training average positive_sample_loss at step 489900: 0.174229\n",
      "2022-11-08 19:23:38,183 INFO     Training average negative_sample_loss at step 489900: 0.152310\n",
      "2022-11-08 19:23:38,183 INFO     Training average loss at step 489900: 0.163270\n",
      "2022-11-08 19:23:50,809 INFO     Training average positive_sample_loss at step 490000: 0.183826\n",
      "2022-11-08 19:23:50,809 INFO     Training average negative_sample_loss at step 490000: 0.153486\n",
      "2022-11-08 19:23:50,809 INFO     Training average loss at step 490000: 0.168656\n",
      "2022-11-08 19:24:00,507 INFO     Training average positive_sample_loss at step 490100: 0.174184\n",
      "2022-11-08 19:24:00,507 INFO     Training average negative_sample_loss at step 490100: 0.156613\n",
      "2022-11-08 19:24:00,507 INFO     Training average loss at step 490100: 0.165399\n",
      "2022-11-08 19:24:10,203 INFO     Training average positive_sample_loss at step 490200: 0.178927\n",
      "2022-11-08 19:24:10,203 INFO     Training average negative_sample_loss at step 490200: 0.152375\n",
      "2022-11-08 19:24:10,203 INFO     Training average loss at step 490200: 0.165651\n",
      "2022-11-08 19:24:19,893 INFO     Training average positive_sample_loss at step 490300: 0.178179\n",
      "2022-11-08 19:24:19,893 INFO     Training average negative_sample_loss at step 490300: 0.157356\n",
      "2022-11-08 19:24:19,893 INFO     Training average loss at step 490300: 0.167767\n",
      "2022-11-08 19:24:29,586 INFO     Training average positive_sample_loss at step 490400: 0.177097\n",
      "2022-11-08 19:24:29,586 INFO     Training average negative_sample_loss at step 490400: 0.156443\n",
      "2022-11-08 19:24:29,586 INFO     Training average loss at step 490400: 0.166770\n",
      "2022-11-08 19:24:39,282 INFO     Training average positive_sample_loss at step 490500: 0.178810\n",
      "2022-11-08 19:24:39,283 INFO     Training average negative_sample_loss at step 490500: 0.155584\n",
      "2022-11-08 19:24:39,283 INFO     Training average loss at step 490500: 0.167197\n",
      "2022-11-08 19:24:48,975 INFO     Training average positive_sample_loss at step 490600: 0.177770\n",
      "2022-11-08 19:24:48,975 INFO     Training average negative_sample_loss at step 490600: 0.156006\n",
      "2022-11-08 19:24:48,975 INFO     Training average loss at step 490600: 0.166888\n",
      "2022-11-08 19:24:58,671 INFO     Training average positive_sample_loss at step 490700: 0.183218\n",
      "2022-11-08 19:24:58,671 INFO     Training average negative_sample_loss at step 490700: 0.151425\n",
      "2022-11-08 19:24:58,671 INFO     Training average loss at step 490700: 0.167322\n",
      "2022-11-08 19:25:08,365 INFO     Training average positive_sample_loss at step 490800: 0.175693\n",
      "2022-11-08 19:25:08,365 INFO     Training average negative_sample_loss at step 490800: 0.155056\n",
      "2022-11-08 19:25:08,365 INFO     Training average loss at step 490800: 0.165375\n",
      "2022-11-08 19:25:18,054 INFO     Training average positive_sample_loss at step 490900: 0.182397\n",
      "2022-11-08 19:25:18,055 INFO     Training average negative_sample_loss at step 490900: 0.152566\n",
      "2022-11-08 19:25:18,055 INFO     Training average loss at step 490900: 0.167481\n",
      "2022-11-08 19:25:27,749 INFO     Training average positive_sample_loss at step 491000: 0.173981\n",
      "2022-11-08 19:25:27,749 INFO     Training average negative_sample_loss at step 491000: 0.154810\n",
      "2022-11-08 19:25:27,749 INFO     Training average loss at step 491000: 0.164396\n",
      "2022-11-08 19:25:37,446 INFO     Training average positive_sample_loss at step 491100: 0.180146\n",
      "2022-11-08 19:25:37,446 INFO     Training average negative_sample_loss at step 491100: 0.153523\n",
      "2022-11-08 19:25:37,446 INFO     Training average loss at step 491100: 0.166834\n",
      "2022-11-08 19:25:47,144 INFO     Training average positive_sample_loss at step 491200: 0.170861\n",
      "2022-11-08 19:25:47,144 INFO     Training average negative_sample_loss at step 491200: 0.154655\n",
      "2022-11-08 19:25:47,144 INFO     Training average loss at step 491200: 0.162758\n",
      "2022-11-08 19:25:56,844 INFO     Training average positive_sample_loss at step 491300: 0.175973\n",
      "2022-11-08 19:25:56,844 INFO     Training average negative_sample_loss at step 491300: 0.157331\n",
      "2022-11-08 19:25:56,844 INFO     Training average loss at step 491300: 0.166652\n",
      "2022-11-08 19:26:06,549 INFO     Training average positive_sample_loss at step 491400: 0.171626\n",
      "2022-11-08 19:26:06,549 INFO     Training average negative_sample_loss at step 491400: 0.154612\n",
      "2022-11-08 19:26:06,549 INFO     Training average loss at step 491400: 0.163119\n",
      "2022-11-08 19:26:16,243 INFO     Training average positive_sample_loss at step 491500: 0.172390\n",
      "2022-11-08 19:26:16,243 INFO     Training average negative_sample_loss at step 491500: 0.153526\n",
      "2022-11-08 19:26:16,243 INFO     Training average loss at step 491500: 0.162958\n",
      "2022-11-08 19:26:25,939 INFO     Training average positive_sample_loss at step 491600: 0.174194\n",
      "2022-11-08 19:26:25,939 INFO     Training average negative_sample_loss at step 491600: 0.161349\n",
      "2022-11-08 19:26:25,939 INFO     Training average loss at step 491600: 0.167772\n",
      "2022-11-08 19:26:35,637 INFO     Training average positive_sample_loss at step 491700: 0.176425\n",
      "2022-11-08 19:26:35,637 INFO     Training average negative_sample_loss at step 491700: 0.153067\n",
      "2022-11-08 19:26:35,637 INFO     Training average loss at step 491700: 0.164746\n",
      "2022-11-08 19:26:45,333 INFO     Training average positive_sample_loss at step 491800: 0.177633\n",
      "2022-11-08 19:26:45,333 INFO     Training average negative_sample_loss at step 491800: 0.156650\n",
      "2022-11-08 19:26:45,333 INFO     Training average loss at step 491800: 0.167141\n",
      "2022-11-08 19:26:55,026 INFO     Training average positive_sample_loss at step 491900: 0.173667\n",
      "2022-11-08 19:26:55,026 INFO     Training average negative_sample_loss at step 491900: 0.152739\n",
      "2022-11-08 19:26:55,026 INFO     Training average loss at step 491900: 0.163203\n",
      "2022-11-08 19:27:04,720 INFO     Training average positive_sample_loss at step 492000: 0.178481\n",
      "2022-11-08 19:27:04,721 INFO     Training average negative_sample_loss at step 492000: 0.156797\n",
      "2022-11-08 19:27:04,721 INFO     Training average loss at step 492000: 0.167639\n",
      "2022-11-08 19:27:14,418 INFO     Training average positive_sample_loss at step 492100: 0.180552\n",
      "2022-11-08 19:27:14,418 INFO     Training average negative_sample_loss at step 492100: 0.158389\n",
      "2022-11-08 19:27:14,418 INFO     Training average loss at step 492100: 0.169471\n",
      "2022-11-08 19:27:24,113 INFO     Training average positive_sample_loss at step 492200: 0.171654\n",
      "2022-11-08 19:27:24,114 INFO     Training average negative_sample_loss at step 492200: 0.151209\n",
      "2022-11-08 19:27:24,114 INFO     Training average loss at step 492200: 0.161432\n",
      "2022-11-08 19:27:33,811 INFO     Training average positive_sample_loss at step 492300: 0.173976\n",
      "2022-11-08 19:27:33,811 INFO     Training average negative_sample_loss at step 492300: 0.155073\n",
      "2022-11-08 19:27:33,811 INFO     Training average loss at step 492300: 0.164524\n",
      "2022-11-08 19:27:43,510 INFO     Training average positive_sample_loss at step 492400: 0.179011\n",
      "2022-11-08 19:27:43,510 INFO     Training average negative_sample_loss at step 492400: 0.158646\n",
      "2022-11-08 19:27:43,510 INFO     Training average loss at step 492400: 0.168829\n",
      "2022-11-08 19:27:53,203 INFO     Training average positive_sample_loss at step 492500: 0.175281\n",
      "2022-11-08 19:27:53,203 INFO     Training average negative_sample_loss at step 492500: 0.159327\n",
      "2022-11-08 19:27:53,203 INFO     Training average loss at step 492500: 0.167304\n",
      "2022-11-08 19:28:02,905 INFO     Training average positive_sample_loss at step 492600: 0.178026\n",
      "2022-11-08 19:28:02,905 INFO     Training average negative_sample_loss at step 492600: 0.156074\n",
      "2022-11-08 19:28:02,905 INFO     Training average loss at step 492600: 0.167050\n",
      "2022-11-08 19:28:12,605 INFO     Training average positive_sample_loss at step 492700: 0.177718\n",
      "2022-11-08 19:28:12,605 INFO     Training average negative_sample_loss at step 492700: 0.154203\n",
      "2022-11-08 19:28:12,605 INFO     Training average loss at step 492700: 0.165961\n",
      "2022-11-08 19:28:22,302 INFO     Training average positive_sample_loss at step 492800: 0.178020\n",
      "2022-11-08 19:28:22,302 INFO     Training average negative_sample_loss at step 492800: 0.157198\n",
      "2022-11-08 19:28:22,302 INFO     Training average loss at step 492800: 0.167609\n",
      "2022-11-08 19:28:32,002 INFO     Training average positive_sample_loss at step 492900: 0.171653\n",
      "2022-11-08 19:28:32,002 INFO     Training average negative_sample_loss at step 492900: 0.158076\n",
      "2022-11-08 19:28:32,002 INFO     Training average loss at step 492900: 0.164865\n",
      "2022-11-08 19:28:41,695 INFO     Training average positive_sample_loss at step 493000: 0.172703\n",
      "2022-11-08 19:28:41,695 INFO     Training average negative_sample_loss at step 493000: 0.157663\n",
      "2022-11-08 19:28:41,695 INFO     Training average loss at step 493000: 0.165183\n",
      "2022-11-08 19:28:51,389 INFO     Training average positive_sample_loss at step 493100: 0.176268\n",
      "2022-11-08 19:28:51,389 INFO     Training average negative_sample_loss at step 493100: 0.158089\n",
      "2022-11-08 19:28:51,389 INFO     Training average loss at step 493100: 0.167178\n",
      "2022-11-08 19:29:01,089 INFO     Training average positive_sample_loss at step 493200: 0.182623\n",
      "2022-11-08 19:29:01,089 INFO     Training average negative_sample_loss at step 493200: 0.155199\n",
      "2022-11-08 19:29:01,089 INFO     Training average loss at step 493200: 0.168911\n",
      "2022-11-08 19:29:10,785 INFO     Training average positive_sample_loss at step 493300: 0.171741\n",
      "2022-11-08 19:29:10,785 INFO     Training average negative_sample_loss at step 493300: 0.154936\n",
      "2022-11-08 19:29:10,785 INFO     Training average loss at step 493300: 0.163339\n",
      "2022-11-08 19:29:20,482 INFO     Training average positive_sample_loss at step 493400: 0.175233\n",
      "2022-11-08 19:29:20,482 INFO     Training average negative_sample_loss at step 493400: 0.151504\n",
      "2022-11-08 19:29:20,482 INFO     Training average loss at step 493400: 0.163368\n",
      "2022-11-08 19:29:30,180 INFO     Training average positive_sample_loss at step 493500: 0.176631\n",
      "2022-11-08 19:29:30,180 INFO     Training average negative_sample_loss at step 493500: 0.154788\n",
      "2022-11-08 19:29:30,181 INFO     Training average loss at step 493500: 0.165709\n",
      "2022-11-08 19:29:39,873 INFO     Training average positive_sample_loss at step 493600: 0.174553\n",
      "2022-11-08 19:29:39,873 INFO     Training average negative_sample_loss at step 493600: 0.155408\n",
      "2022-11-08 19:29:39,873 INFO     Training average loss at step 493600: 0.164981\n",
      "2022-11-08 19:29:49,153 INFO     Training average positive_sample_loss at step 493700: 0.175280\n",
      "2022-11-08 19:29:49,153 INFO     Training average negative_sample_loss at step 493700: 0.155950\n",
      "2022-11-08 19:29:49,153 INFO     Training average loss at step 493700: 0.165615\n",
      "2022-11-08 19:29:58,575 INFO     Training average positive_sample_loss at step 493800: 0.179921\n",
      "2022-11-08 19:29:58,575 INFO     Training average negative_sample_loss at step 493800: 0.159268\n",
      "2022-11-08 19:29:58,575 INFO     Training average loss at step 493800: 0.169595\n",
      "2022-11-08 19:30:08,272 INFO     Training average positive_sample_loss at step 493900: 0.174960\n",
      "2022-11-08 19:30:08,272 INFO     Training average negative_sample_loss at step 493900: 0.154309\n",
      "2022-11-08 19:30:08,272 INFO     Training average loss at step 493900: 0.164634\n",
      "2022-11-08 19:30:17,969 INFO     Training average positive_sample_loss at step 494000: 0.182655\n",
      "2022-11-08 19:30:17,969 INFO     Training average negative_sample_loss at step 494000: 0.155445\n",
      "2022-11-08 19:30:17,969 INFO     Training average loss at step 494000: 0.169050\n",
      "2022-11-08 19:30:27,669 INFO     Training average positive_sample_loss at step 494100: 0.177635\n",
      "2022-11-08 19:30:27,669 INFO     Training average negative_sample_loss at step 494100: 0.152427\n",
      "2022-11-08 19:30:27,670 INFO     Training average loss at step 494100: 0.165031\n",
      "2022-11-08 19:30:37,366 INFO     Training average positive_sample_loss at step 494200: 0.177774\n",
      "2022-11-08 19:30:37,366 INFO     Training average negative_sample_loss at step 494200: 0.159101\n",
      "2022-11-08 19:30:37,366 INFO     Training average loss at step 494200: 0.168438\n",
      "2022-11-08 19:30:46,386 INFO     Training average positive_sample_loss at step 494300: 0.175836\n",
      "2022-11-08 19:30:46,387 INFO     Training average negative_sample_loss at step 494300: 0.158003\n",
      "2022-11-08 19:30:46,387 INFO     Training average loss at step 494300: 0.166919\n",
      "2022-11-08 19:30:57,587 INFO     Training average positive_sample_loss at step 494400: 0.174457\n",
      "2022-11-08 19:30:57,587 INFO     Training average negative_sample_loss at step 494400: 0.152318\n",
      "2022-11-08 19:30:57,587 INFO     Training average loss at step 494400: 0.163387\n",
      "2022-11-08 19:31:07,286 INFO     Training average positive_sample_loss at step 494500: 0.174018\n",
      "2022-11-08 19:31:07,286 INFO     Training average negative_sample_loss at step 494500: 0.154368\n",
      "2022-11-08 19:31:07,286 INFO     Training average loss at step 494500: 0.164193\n",
      "2022-11-08 19:31:17,550 INFO     Training average positive_sample_loss at step 494600: 0.172332\n",
      "2022-11-08 19:31:17,550 INFO     Training average negative_sample_loss at step 494600: 0.151868\n",
      "2022-11-08 19:31:17,550 INFO     Training average loss at step 494600: 0.162100\n",
      "2022-11-08 19:31:27,246 INFO     Training average positive_sample_loss at step 494700: 0.180406\n",
      "2022-11-08 19:31:27,246 INFO     Training average negative_sample_loss at step 494700: 0.154659\n",
      "2022-11-08 19:31:27,246 INFO     Training average loss at step 494700: 0.167532\n",
      "2022-11-08 19:31:36,943 INFO     Training average positive_sample_loss at step 494800: 0.174607\n",
      "2022-11-08 19:31:36,943 INFO     Training average negative_sample_loss at step 494800: 0.157953\n",
      "2022-11-08 19:31:36,943 INFO     Training average loss at step 494800: 0.166280\n",
      "2022-11-08 19:31:46,637 INFO     Training average positive_sample_loss at step 494900: 0.172442\n",
      "2022-11-08 19:31:46,637 INFO     Training average negative_sample_loss at step 494900: 0.149504\n",
      "2022-11-08 19:31:46,637 INFO     Training average loss at step 494900: 0.160973\n",
      "2022-11-08 19:31:56,329 INFO     Training average positive_sample_loss at step 495000: 0.181327\n",
      "2022-11-08 19:31:56,329 INFO     Training average negative_sample_loss at step 495000: 0.157146\n",
      "2022-11-08 19:31:56,329 INFO     Training average loss at step 495000: 0.169237\n",
      "2022-11-08 19:32:06,022 INFO     Training average positive_sample_loss at step 495100: 0.176947\n",
      "2022-11-08 19:32:06,022 INFO     Training average negative_sample_loss at step 495100: 0.156462\n",
      "2022-11-08 19:32:06,022 INFO     Training average loss at step 495100: 0.166705\n",
      "2022-11-08 19:32:15,712 INFO     Training average positive_sample_loss at step 495200: 0.178237\n",
      "2022-11-08 19:32:15,713 INFO     Training average negative_sample_loss at step 495200: 0.159244\n",
      "2022-11-08 19:32:15,713 INFO     Training average loss at step 495200: 0.168741\n",
      "2022-11-08 19:32:25,403 INFO     Training average positive_sample_loss at step 495300: 0.180629\n",
      "2022-11-08 19:32:25,403 INFO     Training average negative_sample_loss at step 495300: 0.159444\n",
      "2022-11-08 19:32:25,403 INFO     Training average loss at step 495300: 0.170036\n",
      "2022-11-08 19:32:35,096 INFO     Training average positive_sample_loss at step 495400: 0.182625\n",
      "2022-11-08 19:32:35,096 INFO     Training average negative_sample_loss at step 495400: 0.153994\n",
      "2022-11-08 19:32:35,096 INFO     Training average loss at step 495400: 0.168309\n",
      "2022-11-08 19:32:44,785 INFO     Training average positive_sample_loss at step 495500: 0.172720\n",
      "2022-11-08 19:32:44,785 INFO     Training average negative_sample_loss at step 495500: 0.154635\n",
      "2022-11-08 19:32:44,785 INFO     Training average loss at step 495500: 0.163678\n",
      "2022-11-08 19:32:54,478 INFO     Training average positive_sample_loss at step 495600: 0.177299\n",
      "2022-11-08 19:32:54,478 INFO     Training average negative_sample_loss at step 495600: 0.150188\n",
      "2022-11-08 19:32:54,478 INFO     Training average loss at step 495600: 0.163744\n",
      "2022-11-08 19:33:04,175 INFO     Training average positive_sample_loss at step 495700: 0.175636\n",
      "2022-11-08 19:33:04,175 INFO     Training average negative_sample_loss at step 495700: 0.150553\n",
      "2022-11-08 19:33:04,175 INFO     Training average loss at step 495700: 0.163095\n",
      "2022-11-08 19:33:13,865 INFO     Training average positive_sample_loss at step 495800: 0.183084\n",
      "2022-11-08 19:33:13,865 INFO     Training average negative_sample_loss at step 495800: 0.154125\n",
      "2022-11-08 19:33:13,865 INFO     Training average loss at step 495800: 0.168605\n",
      "2022-11-08 19:33:23,564 INFO     Training average positive_sample_loss at step 495900: 0.174218\n",
      "2022-11-08 19:33:23,564 INFO     Training average negative_sample_loss at step 495900: 0.155779\n",
      "2022-11-08 19:33:23,564 INFO     Training average loss at step 495900: 0.164999\n",
      "2022-11-08 19:33:33,256 INFO     Training average positive_sample_loss at step 496000: 0.177709\n",
      "2022-11-08 19:33:33,256 INFO     Training average negative_sample_loss at step 496000: 0.158453\n",
      "2022-11-08 19:33:33,256 INFO     Training average loss at step 496000: 0.168081\n",
      "2022-11-08 19:33:42,943 INFO     Training average positive_sample_loss at step 496100: 0.174991\n",
      "2022-11-08 19:33:42,943 INFO     Training average negative_sample_loss at step 496100: 0.158390\n",
      "2022-11-08 19:33:42,943 INFO     Training average loss at step 496100: 0.166690\n",
      "2022-11-08 19:33:52,641 INFO     Training average positive_sample_loss at step 496200: 0.164155\n",
      "2022-11-08 19:33:52,641 INFO     Training average negative_sample_loss at step 496200: 0.162616\n",
      "2022-11-08 19:33:52,641 INFO     Training average loss at step 496200: 0.163385\n",
      "2022-11-08 19:34:02,329 INFO     Training average positive_sample_loss at step 496300: 0.178040\n",
      "2022-11-08 19:34:02,330 INFO     Training average negative_sample_loss at step 496300: 0.154934\n",
      "2022-11-08 19:34:02,330 INFO     Training average loss at step 496300: 0.166487\n",
      "2022-11-08 19:34:12,017 INFO     Training average positive_sample_loss at step 496400: 0.177857\n",
      "2022-11-08 19:34:12,017 INFO     Training average negative_sample_loss at step 496400: 0.154039\n",
      "2022-11-08 19:34:12,017 INFO     Training average loss at step 496400: 0.165948\n",
      "2022-11-08 19:34:21,712 INFO     Training average positive_sample_loss at step 496500: 0.176364\n",
      "2022-11-08 19:34:21,712 INFO     Training average negative_sample_loss at step 496500: 0.154261\n",
      "2022-11-08 19:34:21,712 INFO     Training average loss at step 496500: 0.165312\n",
      "2022-11-08 19:34:31,408 INFO     Training average positive_sample_loss at step 496600: 0.171473\n",
      "2022-11-08 19:34:31,408 INFO     Training average negative_sample_loss at step 496600: 0.153209\n",
      "2022-11-08 19:34:31,408 INFO     Training average loss at step 496600: 0.162341\n",
      "2022-11-08 19:34:41,099 INFO     Training average positive_sample_loss at step 496700: 0.174161\n",
      "2022-11-08 19:34:41,099 INFO     Training average negative_sample_loss at step 496700: 0.156645\n",
      "2022-11-08 19:34:41,099 INFO     Training average loss at step 496700: 0.165403\n",
      "2022-11-08 19:34:50,792 INFO     Training average positive_sample_loss at step 496800: 0.179708\n",
      "2022-11-08 19:34:50,792 INFO     Training average negative_sample_loss at step 496800: 0.156404\n",
      "2022-11-08 19:34:50,792 INFO     Training average loss at step 496800: 0.168056\n",
      "2022-11-08 19:35:00,481 INFO     Training average positive_sample_loss at step 496900: 0.170843\n",
      "2022-11-08 19:35:00,481 INFO     Training average negative_sample_loss at step 496900: 0.154822\n",
      "2022-11-08 19:35:00,481 INFO     Training average loss at step 496900: 0.162832\n",
      "2022-11-08 19:35:10,172 INFO     Training average positive_sample_loss at step 497000: 0.180243\n",
      "2022-11-08 19:35:10,172 INFO     Training average negative_sample_loss at step 497000: 0.157589\n",
      "2022-11-08 19:35:10,172 INFO     Training average loss at step 497000: 0.168916\n",
      "2022-11-08 19:35:19,867 INFO     Training average positive_sample_loss at step 497100: 0.173400\n",
      "2022-11-08 19:35:19,867 INFO     Training average negative_sample_loss at step 497100: 0.157088\n",
      "2022-11-08 19:35:19,867 INFO     Training average loss at step 497100: 0.165244\n",
      "2022-11-08 19:35:29,557 INFO     Training average positive_sample_loss at step 497200: 0.179214\n",
      "2022-11-08 19:35:29,557 INFO     Training average negative_sample_loss at step 497200: 0.158795\n",
      "2022-11-08 19:35:29,557 INFO     Training average loss at step 497200: 0.169004\n",
      "2022-11-08 19:35:39,249 INFO     Training average positive_sample_loss at step 497300: 0.183312\n",
      "2022-11-08 19:35:39,249 INFO     Training average negative_sample_loss at step 497300: 0.154312\n",
      "2022-11-08 19:35:39,249 INFO     Training average loss at step 497300: 0.168812\n",
      "2022-11-08 19:35:48,941 INFO     Training average positive_sample_loss at step 497400: 0.174813\n",
      "2022-11-08 19:35:48,942 INFO     Training average negative_sample_loss at step 497400: 0.155122\n",
      "2022-11-08 19:35:48,942 INFO     Training average loss at step 497400: 0.164967\n",
      "2022-11-08 19:35:58,631 INFO     Training average positive_sample_loss at step 497500: 0.170787\n",
      "2022-11-08 19:35:58,631 INFO     Training average negative_sample_loss at step 497500: 0.151928\n",
      "2022-11-08 19:35:58,631 INFO     Training average loss at step 497500: 0.161357\n",
      "2022-11-08 19:36:08,324 INFO     Training average positive_sample_loss at step 497600: 0.180670\n",
      "2022-11-08 19:36:08,324 INFO     Training average negative_sample_loss at step 497600: 0.154325\n",
      "2022-11-08 19:36:08,324 INFO     Training average loss at step 497600: 0.167498\n",
      "2022-11-08 19:36:18,013 INFO     Training average positive_sample_loss at step 497700: 0.177743\n",
      "2022-11-08 19:36:18,013 INFO     Training average negative_sample_loss at step 497700: 0.154486\n",
      "2022-11-08 19:36:18,013 INFO     Training average loss at step 497700: 0.166115\n",
      "2022-11-08 19:36:27,701 INFO     Training average positive_sample_loss at step 497800: 0.178601\n",
      "2022-11-08 19:36:27,701 INFO     Training average negative_sample_loss at step 497800: 0.158632\n",
      "2022-11-08 19:36:27,702 INFO     Training average loss at step 497800: 0.168616\n",
      "2022-11-08 19:36:37,392 INFO     Training average positive_sample_loss at step 497900: 0.177509\n",
      "2022-11-08 19:36:37,393 INFO     Training average negative_sample_loss at step 497900: 0.161728\n",
      "2022-11-08 19:36:37,393 INFO     Training average loss at step 497900: 0.169618\n",
      "2022-11-08 19:36:47,084 INFO     Training average positive_sample_loss at step 498000: 0.177012\n",
      "2022-11-08 19:36:47,084 INFO     Training average negative_sample_loss at step 498000: 0.152326\n",
      "2022-11-08 19:36:47,084 INFO     Training average loss at step 498000: 0.164669\n",
      "2022-11-08 19:36:56,778 INFO     Training average positive_sample_loss at step 498100: 0.179080\n",
      "2022-11-08 19:36:56,778 INFO     Training average negative_sample_loss at step 498100: 0.155239\n",
      "2022-11-08 19:36:56,778 INFO     Training average loss at step 498100: 0.167159\n",
      "2022-11-08 19:37:06,469 INFO     Training average positive_sample_loss at step 498200: 0.174958\n",
      "2022-11-08 19:37:06,469 INFO     Training average negative_sample_loss at step 498200: 0.157184\n",
      "2022-11-08 19:37:06,469 INFO     Training average loss at step 498200: 0.166071\n",
      "2022-11-08 19:37:16,157 INFO     Training average positive_sample_loss at step 498300: 0.173508\n",
      "2022-11-08 19:37:16,157 INFO     Training average negative_sample_loss at step 498300: 0.152385\n",
      "2022-11-08 19:37:16,157 INFO     Training average loss at step 498300: 0.162947\n",
      "2022-11-08 19:37:25,852 INFO     Training average positive_sample_loss at step 498400: 0.188536\n",
      "2022-11-08 19:37:25,852 INFO     Training average negative_sample_loss at step 498400: 0.158172\n",
      "2022-11-08 19:37:25,852 INFO     Training average loss at step 498400: 0.173354\n",
      "2022-11-08 19:37:35,542 INFO     Training average positive_sample_loss at step 498500: 0.180177\n",
      "2022-11-08 19:37:35,543 INFO     Training average negative_sample_loss at step 498500: 0.156794\n",
      "2022-11-08 19:37:35,543 INFO     Training average loss at step 498500: 0.168486\n",
      "2022-11-08 19:37:45,234 INFO     Training average positive_sample_loss at step 498600: 0.180292\n",
      "2022-11-08 19:37:45,234 INFO     Training average negative_sample_loss at step 498600: 0.157242\n",
      "2022-11-08 19:37:45,234 INFO     Training average loss at step 498600: 0.168767\n",
      "2022-11-08 19:37:54,926 INFO     Training average positive_sample_loss at step 498700: 0.177781\n",
      "2022-11-08 19:37:54,926 INFO     Training average negative_sample_loss at step 498700: 0.152414\n",
      "2022-11-08 19:37:54,926 INFO     Training average loss at step 498700: 0.165097\n",
      "2022-11-08 19:38:04,616 INFO     Training average positive_sample_loss at step 498800: 0.177277\n",
      "2022-11-08 19:38:04,616 INFO     Training average negative_sample_loss at step 498800: 0.154587\n",
      "2022-11-08 19:38:04,616 INFO     Training average loss at step 498800: 0.165932\n",
      "2022-11-08 19:38:14,309 INFO     Training average positive_sample_loss at step 498900: 0.177673\n",
      "2022-11-08 19:38:14,309 INFO     Training average negative_sample_loss at step 498900: 0.157327\n",
      "2022-11-08 19:38:14,309 INFO     Training average loss at step 498900: 0.167500\n",
      "2022-11-08 19:38:24,872 INFO     Training average positive_sample_loss at step 499000: 0.176988\n",
      "2022-11-08 19:38:24,872 INFO     Training average negative_sample_loss at step 499000: 0.156063\n",
      "2022-11-08 19:38:24,872 INFO     Training average loss at step 499000: 0.166525\n",
      "2022-11-08 19:38:35,350 INFO     Training average positive_sample_loss at step 499100: 0.187456\n",
      "2022-11-08 19:38:35,350 INFO     Training average negative_sample_loss at step 499100: 0.159865\n",
      "2022-11-08 19:38:35,350 INFO     Training average loss at step 499100: 0.173661\n",
      "2022-11-08 19:38:44,342 INFO     Training average positive_sample_loss at step 499200: 0.178376\n",
      "2022-11-08 19:38:44,342 INFO     Training average negative_sample_loss at step 499200: 0.153460\n",
      "2022-11-08 19:38:44,342 INFO     Training average loss at step 499200: 0.165918\n",
      "2022-11-08 19:38:54,536 INFO     Training average positive_sample_loss at step 499300: 0.175625\n",
      "2022-11-08 19:38:54,536 INFO     Training average negative_sample_loss at step 499300: 0.153952\n",
      "2022-11-08 19:38:54,536 INFO     Training average loss at step 499300: 0.164788\n",
      "2022-11-08 19:39:04,227 INFO     Training average positive_sample_loss at step 499400: 0.177496\n",
      "2022-11-08 19:39:04,227 INFO     Training average negative_sample_loss at step 499400: 0.155273\n",
      "2022-11-08 19:39:04,227 INFO     Training average loss at step 499400: 0.166385\n",
      "2022-11-08 19:39:13,919 INFO     Training average positive_sample_loss at step 499500: 0.175009\n",
      "2022-11-08 19:39:13,919 INFO     Training average negative_sample_loss at step 499500: 0.154129\n",
      "2022-11-08 19:39:13,919 INFO     Training average loss at step 499500: 0.164569\n",
      "2022-11-08 19:39:23,610 INFO     Training average positive_sample_loss at step 499600: 0.174520\n",
      "2022-11-08 19:39:23,611 INFO     Training average negative_sample_loss at step 499600: 0.158288\n",
      "2022-11-08 19:39:23,611 INFO     Training average loss at step 499600: 0.166404\n",
      "2022-11-08 19:39:32,924 INFO     Training average positive_sample_loss at step 499700: 0.181837\n",
      "2022-11-08 19:39:32,924 INFO     Training average negative_sample_loss at step 499700: 0.151321\n",
      "2022-11-08 19:39:32,924 INFO     Training average loss at step 499700: 0.166579\n",
      "2022-11-08 19:39:42,328 INFO     Training average positive_sample_loss at step 499800: 0.174902\n",
      "2022-11-08 19:39:42,328 INFO     Training average negative_sample_loss at step 499800: 0.155146\n",
      "2022-11-08 19:39:42,328 INFO     Training average loss at step 499800: 0.165024\n",
      "2022-11-08 19:39:52,018 INFO     Training average positive_sample_loss at step 499900: 0.181431\n",
      "2022-11-08 19:39:52,018 INFO     Training average negative_sample_loss at step 499900: 0.156769\n",
      "2022-11-08 19:39:52,018 INFO     Training average loss at step 499900: 0.169100\n",
      "2022-11-08 19:40:01,710 INFO     Change learning_rate to 0.000010 at step 500000\n",
      "2022-11-08 19:40:03,081 INFO     Training average positive_sample_loss at step 500000: 0.180384\n",
      "2022-11-08 19:40:03,081 INFO     Training average negative_sample_loss at step 500000: 0.150598\n",
      "2022-11-08 19:40:03,081 INFO     Training average loss at step 500000: 0.165491\n",
      "2022-11-08 19:40:12,776 INFO     Training average positive_sample_loss at step 500100: 0.175005\n",
      "2022-11-08 19:40:12,776 INFO     Training average negative_sample_loss at step 500100: 0.157355\n",
      "2022-11-08 19:40:12,776 INFO     Training average loss at step 500100: 0.166180\n",
      "2022-11-08 19:40:22,468 INFO     Training average positive_sample_loss at step 500200: 0.177089\n",
      "2022-11-08 19:40:22,468 INFO     Training average negative_sample_loss at step 500200: 0.153265\n",
      "2022-11-08 19:40:22,468 INFO     Training average loss at step 500200: 0.165177\n",
      "2022-11-08 19:40:32,159 INFO     Training average positive_sample_loss at step 500300: 0.177552\n",
      "2022-11-08 19:40:32,159 INFO     Training average negative_sample_loss at step 500300: 0.154287\n",
      "2022-11-08 19:40:32,160 INFO     Training average loss at step 500300: 0.165919\n",
      "2022-11-08 19:40:41,853 INFO     Training average positive_sample_loss at step 500400: 0.183730\n",
      "2022-11-08 19:40:41,853 INFO     Training average negative_sample_loss at step 500400: 0.159881\n",
      "2022-11-08 19:40:41,853 INFO     Training average loss at step 500400: 0.171806\n",
      "2022-11-08 19:40:51,543 INFO     Training average positive_sample_loss at step 500500: 0.172568\n",
      "2022-11-08 19:40:51,543 INFO     Training average negative_sample_loss at step 500500: 0.159897\n",
      "2022-11-08 19:40:51,543 INFO     Training average loss at step 500500: 0.166233\n",
      "2022-11-08 19:41:01,232 INFO     Training average positive_sample_loss at step 500600: 0.181483\n",
      "2022-11-08 19:41:01,232 INFO     Training average negative_sample_loss at step 500600: 0.151647\n",
      "2022-11-08 19:41:01,232 INFO     Training average loss at step 500600: 0.166565\n",
      "2022-11-08 19:41:10,925 INFO     Training average positive_sample_loss at step 500700: 0.175956\n",
      "2022-11-08 19:41:10,925 INFO     Training average negative_sample_loss at step 500700: 0.152714\n",
      "2022-11-08 19:41:10,925 INFO     Training average loss at step 500700: 0.164335\n",
      "2022-11-08 19:41:20,621 INFO     Training average positive_sample_loss at step 500800: 0.179409\n",
      "2022-11-08 19:41:20,621 INFO     Training average negative_sample_loss at step 500800: 0.149996\n",
      "2022-11-08 19:41:20,621 INFO     Training average loss at step 500800: 0.164702\n",
      "2022-11-08 19:41:30,314 INFO     Training average positive_sample_loss at step 500900: 0.182328\n",
      "2022-11-08 19:41:30,314 INFO     Training average negative_sample_loss at step 500900: 0.155564\n",
      "2022-11-08 19:41:30,314 INFO     Training average loss at step 500900: 0.168946\n",
      "2022-11-08 19:41:40,008 INFO     Training average positive_sample_loss at step 501000: 0.181487\n",
      "2022-11-08 19:41:40,008 INFO     Training average negative_sample_loss at step 501000: 0.156591\n",
      "2022-11-08 19:41:40,008 INFO     Training average loss at step 501000: 0.169039\n",
      "2022-11-08 19:41:49,701 INFO     Training average positive_sample_loss at step 501100: 0.181907\n",
      "2022-11-08 19:41:49,701 INFO     Training average negative_sample_loss at step 501100: 0.150870\n",
      "2022-11-08 19:41:49,701 INFO     Training average loss at step 501100: 0.166388\n",
      "2022-11-08 19:41:59,389 INFO     Training average positive_sample_loss at step 501200: 0.184614\n",
      "2022-11-08 19:41:59,390 INFO     Training average negative_sample_loss at step 501200: 0.157286\n",
      "2022-11-08 19:41:59,390 INFO     Training average loss at step 501200: 0.170950\n",
      "2022-11-08 19:42:09,087 INFO     Training average positive_sample_loss at step 501300: 0.182600\n",
      "2022-11-08 19:42:09,087 INFO     Training average negative_sample_loss at step 501300: 0.153053\n",
      "2022-11-08 19:42:09,087 INFO     Training average loss at step 501300: 0.167826\n",
      "2022-11-08 19:42:18,780 INFO     Training average positive_sample_loss at step 501400: 0.175672\n",
      "2022-11-08 19:42:18,780 INFO     Training average negative_sample_loss at step 501400: 0.150497\n",
      "2022-11-08 19:42:18,780 INFO     Training average loss at step 501400: 0.163084\n",
      "2022-11-08 19:42:28,481 INFO     Training average positive_sample_loss at step 501500: 0.184327\n",
      "2022-11-08 19:42:28,481 INFO     Training average negative_sample_loss at step 501500: 0.154856\n",
      "2022-11-08 19:42:28,481 INFO     Training average loss at step 501500: 0.169591\n",
      "2022-11-08 19:42:38,172 INFO     Training average positive_sample_loss at step 501600: 0.176810\n",
      "2022-11-08 19:42:38,172 INFO     Training average negative_sample_loss at step 501600: 0.154716\n",
      "2022-11-08 19:42:38,172 INFO     Training average loss at step 501600: 0.165763\n",
      "2022-11-08 19:42:47,860 INFO     Training average positive_sample_loss at step 501700: 0.186681\n",
      "2022-11-08 19:42:47,861 INFO     Training average negative_sample_loss at step 501700: 0.152716\n",
      "2022-11-08 19:42:47,861 INFO     Training average loss at step 501700: 0.169698\n",
      "2022-11-08 19:42:57,550 INFO     Training average positive_sample_loss at step 501800: 0.179452\n",
      "2022-11-08 19:42:57,550 INFO     Training average negative_sample_loss at step 501800: 0.153570\n",
      "2022-11-08 19:42:57,550 INFO     Training average loss at step 501800: 0.166511\n",
      "2022-11-08 19:43:07,251 INFO     Training average positive_sample_loss at step 501900: 0.181802\n",
      "2022-11-08 19:43:07,251 INFO     Training average negative_sample_loss at step 501900: 0.153803\n",
      "2022-11-08 19:43:07,251 INFO     Training average loss at step 501900: 0.167802\n",
      "2022-11-08 19:43:16,942 INFO     Training average positive_sample_loss at step 502000: 0.187736\n",
      "2022-11-08 19:43:16,942 INFO     Training average negative_sample_loss at step 502000: 0.151538\n",
      "2022-11-08 19:43:16,942 INFO     Training average loss at step 502000: 0.169637\n",
      "2022-11-08 19:43:26,637 INFO     Training average positive_sample_loss at step 502100: 0.176203\n",
      "2022-11-08 19:43:26,637 INFO     Training average negative_sample_loss at step 502100: 0.153199\n",
      "2022-11-08 19:43:26,637 INFO     Training average loss at step 502100: 0.164701\n",
      "2022-11-08 19:43:36,329 INFO     Training average positive_sample_loss at step 502200: 0.169453\n",
      "2022-11-08 19:43:36,329 INFO     Training average negative_sample_loss at step 502200: 0.151557\n",
      "2022-11-08 19:43:36,329 INFO     Training average loss at step 502200: 0.160505\n",
      "2022-11-08 19:43:46,015 INFO     Training average positive_sample_loss at step 502300: 0.180344\n",
      "2022-11-08 19:43:46,015 INFO     Training average negative_sample_loss at step 502300: 0.151435\n",
      "2022-11-08 19:43:46,015 INFO     Training average loss at step 502300: 0.165890\n",
      "2022-11-08 19:43:55,706 INFO     Training average positive_sample_loss at step 502400: 0.178396\n",
      "2022-11-08 19:43:55,707 INFO     Training average negative_sample_loss at step 502400: 0.156834\n",
      "2022-11-08 19:43:55,707 INFO     Training average loss at step 502400: 0.167615\n",
      "2022-11-08 19:44:05,402 INFO     Training average positive_sample_loss at step 502500: 0.173116\n",
      "2022-11-08 19:44:05,402 INFO     Training average negative_sample_loss at step 502500: 0.156296\n",
      "2022-11-08 19:44:05,402 INFO     Training average loss at step 502500: 0.164706\n",
      "2022-11-08 19:44:15,093 INFO     Training average positive_sample_loss at step 502600: 0.184585\n",
      "2022-11-08 19:44:15,093 INFO     Training average negative_sample_loss at step 502600: 0.152900\n",
      "2022-11-08 19:44:15,093 INFO     Training average loss at step 502600: 0.168743\n",
      "2022-11-08 19:44:24,787 INFO     Training average positive_sample_loss at step 502700: 0.175730\n",
      "2022-11-08 19:44:24,787 INFO     Training average negative_sample_loss at step 502700: 0.149573\n",
      "2022-11-08 19:44:24,787 INFO     Training average loss at step 502700: 0.162651\n",
      "2022-11-08 19:44:34,475 INFO     Training average positive_sample_loss at step 502800: 0.176216\n",
      "2022-11-08 19:44:34,475 INFO     Training average negative_sample_loss at step 502800: 0.152575\n",
      "2022-11-08 19:44:34,475 INFO     Training average loss at step 502800: 0.164395\n",
      "2022-11-08 19:44:44,171 INFO     Training average positive_sample_loss at step 502900: 0.178656\n",
      "2022-11-08 19:44:44,171 INFO     Training average negative_sample_loss at step 502900: 0.150634\n",
      "2022-11-08 19:44:44,171 INFO     Training average loss at step 502900: 0.164645\n",
      "2022-11-08 19:44:53,865 INFO     Training average positive_sample_loss at step 503000: 0.170872\n",
      "2022-11-08 19:44:53,865 INFO     Training average negative_sample_loss at step 503000: 0.154305\n",
      "2022-11-08 19:44:53,865 INFO     Training average loss at step 503000: 0.162588\n",
      "2022-11-08 19:45:03,570 INFO     Training average positive_sample_loss at step 503100: 0.182111\n",
      "2022-11-08 19:45:03,570 INFO     Training average negative_sample_loss at step 503100: 0.151425\n",
      "2022-11-08 19:45:03,570 INFO     Training average loss at step 503100: 0.166768\n",
      "2022-11-08 19:45:13,281 INFO     Training average positive_sample_loss at step 503200: 0.175691\n",
      "2022-11-08 19:45:13,282 INFO     Training average negative_sample_loss at step 503200: 0.153719\n",
      "2022-11-08 19:45:13,282 INFO     Training average loss at step 503200: 0.164705\n",
      "2022-11-08 19:45:22,977 INFO     Training average positive_sample_loss at step 503300: 0.187045\n",
      "2022-11-08 19:45:22,977 INFO     Training average negative_sample_loss at step 503300: 0.150897\n",
      "2022-11-08 19:45:22,977 INFO     Training average loss at step 503300: 0.168971\n",
      "2022-11-08 19:45:32,668 INFO     Training average positive_sample_loss at step 503400: 0.179849\n",
      "2022-11-08 19:45:32,668 INFO     Training average negative_sample_loss at step 503400: 0.149808\n",
      "2022-11-08 19:45:32,668 INFO     Training average loss at step 503400: 0.164829\n",
      "2022-11-08 19:45:42,359 INFO     Training average positive_sample_loss at step 503500: 0.186406\n",
      "2022-11-08 19:45:42,359 INFO     Training average negative_sample_loss at step 503500: 0.152134\n",
      "2022-11-08 19:45:42,359 INFO     Training average loss at step 503500: 0.169270\n",
      "2022-11-08 19:45:52,885 INFO     Training average positive_sample_loss at step 503600: 0.176552\n",
      "2022-11-08 19:45:52,885 INFO     Training average negative_sample_loss at step 503600: 0.155884\n",
      "2022-11-08 19:45:52,885 INFO     Training average loss at step 503600: 0.166218\n",
      "2022-11-08 19:46:02,868 INFO     Training average positive_sample_loss at step 503700: 0.179024\n",
      "2022-11-08 19:46:02,868 INFO     Training average negative_sample_loss at step 503700: 0.156275\n",
      "2022-11-08 19:46:02,868 INFO     Training average loss at step 503700: 0.167650\n",
      "2022-11-08 19:46:13,422 INFO     Training average positive_sample_loss at step 503800: 0.173608\n",
      "2022-11-08 19:46:13,422 INFO     Training average negative_sample_loss at step 503800: 0.155296\n",
      "2022-11-08 19:46:13,422 INFO     Training average loss at step 503800: 0.164452\n",
      "2022-11-08 19:46:23,112 INFO     Training average positive_sample_loss at step 503900: 0.180493\n",
      "2022-11-08 19:46:23,112 INFO     Training average negative_sample_loss at step 503900: 0.155001\n",
      "2022-11-08 19:46:23,112 INFO     Training average loss at step 503900: 0.167747\n",
      "2022-11-08 19:46:32,804 INFO     Training average positive_sample_loss at step 504000: 0.180279\n",
      "2022-11-08 19:46:32,804 INFO     Training average negative_sample_loss at step 504000: 0.155212\n",
      "2022-11-08 19:46:32,804 INFO     Training average loss at step 504000: 0.167746\n",
      "2022-11-08 19:46:42,492 INFO     Training average positive_sample_loss at step 504100: 0.178254\n",
      "2022-11-08 19:46:42,492 INFO     Training average negative_sample_loss at step 504100: 0.148627\n",
      "2022-11-08 19:46:42,492 INFO     Training average loss at step 504100: 0.163440\n",
      "2022-11-08 19:46:52,181 INFO     Training average positive_sample_loss at step 504200: 0.177898\n",
      "2022-11-08 19:46:52,182 INFO     Training average negative_sample_loss at step 504200: 0.148998\n",
      "2022-11-08 19:46:52,182 INFO     Training average loss at step 504200: 0.163448\n",
      "2022-11-08 19:47:01,876 INFO     Training average positive_sample_loss at step 504300: 0.180010\n",
      "2022-11-08 19:47:01,877 INFO     Training average negative_sample_loss at step 504300: 0.157365\n",
      "2022-11-08 19:47:01,877 INFO     Training average loss at step 504300: 0.168688\n",
      "2022-11-08 19:47:11,565 INFO     Training average positive_sample_loss at step 504400: 0.176983\n",
      "2022-11-08 19:47:11,565 INFO     Training average negative_sample_loss at step 504400: 0.150620\n",
      "2022-11-08 19:47:11,566 INFO     Training average loss at step 504400: 0.163802\n",
      "2022-11-08 19:47:21,262 INFO     Training average positive_sample_loss at step 504500: 0.177370\n",
      "2022-11-08 19:47:21,262 INFO     Training average negative_sample_loss at step 504500: 0.152058\n",
      "2022-11-08 19:47:21,262 INFO     Training average loss at step 504500: 0.164714\n",
      "2022-11-08 19:47:30,952 INFO     Training average positive_sample_loss at step 504600: 0.178980\n",
      "2022-11-08 19:47:30,952 INFO     Training average negative_sample_loss at step 504600: 0.147097\n",
      "2022-11-08 19:47:30,952 INFO     Training average loss at step 504600: 0.163038\n",
      "2022-11-08 19:47:39,936 INFO     Training average positive_sample_loss at step 504700: 0.178176\n",
      "2022-11-08 19:47:39,936 INFO     Training average negative_sample_loss at step 504700: 0.150312\n",
      "2022-11-08 19:47:39,936 INFO     Training average loss at step 504700: 0.164244\n",
      "2022-11-08 19:47:49,626 INFO     Training average positive_sample_loss at step 504800: 0.177161\n",
      "2022-11-08 19:47:49,626 INFO     Training average negative_sample_loss at step 504800: 0.153311\n",
      "2022-11-08 19:47:49,626 INFO     Training average loss at step 504800: 0.165236\n",
      "2022-11-08 19:47:59,321 INFO     Training average positive_sample_loss at step 504900: 0.186043\n",
      "2022-11-08 19:47:59,321 INFO     Training average negative_sample_loss at step 504900: 0.152965\n",
      "2022-11-08 19:47:59,321 INFO     Training average loss at step 504900: 0.169504\n",
      "2022-11-08 19:48:09,011 INFO     Training average positive_sample_loss at step 505000: 0.169204\n",
      "2022-11-08 19:48:09,011 INFO     Training average negative_sample_loss at step 505000: 0.153945\n",
      "2022-11-08 19:48:09,011 INFO     Training average loss at step 505000: 0.161574\n",
      "2022-11-08 19:48:18,706 INFO     Training average positive_sample_loss at step 505100: 0.172037\n",
      "2022-11-08 19:48:18,706 INFO     Training average negative_sample_loss at step 505100: 0.154071\n",
      "2022-11-08 19:48:18,706 INFO     Training average loss at step 505100: 0.163054\n",
      "2022-11-08 19:48:27,733 INFO     Training average positive_sample_loss at step 505200: 0.175638\n",
      "2022-11-08 19:48:27,734 INFO     Training average negative_sample_loss at step 505200: 0.152660\n",
      "2022-11-08 19:48:27,734 INFO     Training average loss at step 505200: 0.164149\n",
      "2022-11-08 19:48:37,426 INFO     Training average positive_sample_loss at step 505300: 0.179814\n",
      "2022-11-08 19:48:37,426 INFO     Training average negative_sample_loss at step 505300: 0.154194\n",
      "2022-11-08 19:48:37,426 INFO     Training average loss at step 505300: 0.167004\n",
      "2022-11-08 19:48:47,117 INFO     Training average positive_sample_loss at step 505400: 0.175135\n",
      "2022-11-08 19:48:47,117 INFO     Training average negative_sample_loss at step 505400: 0.152053\n",
      "2022-11-08 19:48:47,117 INFO     Training average loss at step 505400: 0.163594\n",
      "2022-11-08 19:48:56,812 INFO     Training average positive_sample_loss at step 505500: 0.175083\n",
      "2022-11-08 19:48:56,812 INFO     Training average negative_sample_loss at step 505500: 0.155087\n",
      "2022-11-08 19:48:56,812 INFO     Training average loss at step 505500: 0.165085\n",
      "2022-11-08 19:49:06,508 INFO     Training average positive_sample_loss at step 505600: 0.180179\n",
      "2022-11-08 19:49:06,508 INFO     Training average negative_sample_loss at step 505600: 0.151021\n",
      "2022-11-08 19:49:06,508 INFO     Training average loss at step 505600: 0.165600\n",
      "2022-11-08 19:49:16,200 INFO     Training average positive_sample_loss at step 505700: 0.173428\n",
      "2022-11-08 19:49:16,200 INFO     Training average negative_sample_loss at step 505700: 0.153780\n",
      "2022-11-08 19:49:16,200 INFO     Training average loss at step 505700: 0.163604\n",
      "2022-11-08 19:49:25,893 INFO     Training average positive_sample_loss at step 505800: 0.177882\n",
      "2022-11-08 19:49:25,893 INFO     Training average negative_sample_loss at step 505800: 0.151826\n",
      "2022-11-08 19:49:25,893 INFO     Training average loss at step 505800: 0.164854\n",
      "2022-11-08 19:49:35,580 INFO     Training average positive_sample_loss at step 505900: 0.175350\n",
      "2022-11-08 19:49:35,580 INFO     Training average negative_sample_loss at step 505900: 0.150069\n",
      "2022-11-08 19:49:35,580 INFO     Training average loss at step 505900: 0.162709\n",
      "2022-11-08 19:49:45,273 INFO     Training average positive_sample_loss at step 506000: 0.179709\n",
      "2022-11-08 19:49:45,273 INFO     Training average negative_sample_loss at step 506000: 0.153256\n",
      "2022-11-08 19:49:45,273 INFO     Training average loss at step 506000: 0.166483\n",
      "2022-11-08 19:49:54,968 INFO     Training average positive_sample_loss at step 506100: 0.179073\n",
      "2022-11-08 19:49:54,968 INFO     Training average negative_sample_loss at step 506100: 0.151833\n",
      "2022-11-08 19:49:54,969 INFO     Training average loss at step 506100: 0.165453\n",
      "2022-11-08 19:50:04,660 INFO     Training average positive_sample_loss at step 506200: 0.182583\n",
      "2022-11-08 19:50:04,660 INFO     Training average negative_sample_loss at step 506200: 0.148499\n",
      "2022-11-08 19:50:04,660 INFO     Training average loss at step 506200: 0.165541\n",
      "2022-11-08 19:50:14,352 INFO     Training average positive_sample_loss at step 506300: 0.179871\n",
      "2022-11-08 19:50:14,352 INFO     Training average negative_sample_loss at step 506300: 0.153838\n",
      "2022-11-08 19:50:14,352 INFO     Training average loss at step 506300: 0.166854\n",
      "2022-11-08 19:50:24,043 INFO     Training average positive_sample_loss at step 506400: 0.180581\n",
      "2022-11-08 19:50:24,043 INFO     Training average negative_sample_loss at step 506400: 0.153043\n",
      "2022-11-08 19:50:24,043 INFO     Training average loss at step 506400: 0.166812\n",
      "2022-11-08 19:50:33,732 INFO     Training average positive_sample_loss at step 506500: 0.170688\n",
      "2022-11-08 19:50:33,732 INFO     Training average negative_sample_loss at step 506500: 0.149938\n",
      "2022-11-08 19:50:33,732 INFO     Training average loss at step 506500: 0.160313\n",
      "2022-11-08 19:50:43,424 INFO     Training average positive_sample_loss at step 506600: 0.165491\n",
      "2022-11-08 19:50:43,424 INFO     Training average negative_sample_loss at step 506600: 0.153265\n",
      "2022-11-08 19:50:43,424 INFO     Training average loss at step 506600: 0.159378\n",
      "2022-11-08 19:50:53,137 INFO     Training average positive_sample_loss at step 506700: 0.173351\n",
      "2022-11-08 19:50:53,137 INFO     Training average negative_sample_loss at step 506700: 0.147615\n",
      "2022-11-08 19:50:53,137 INFO     Training average loss at step 506700: 0.160483\n",
      "2022-11-08 19:51:02,833 INFO     Training average positive_sample_loss at step 506800: 0.174717\n",
      "2022-11-08 19:51:02,833 INFO     Training average negative_sample_loss at step 506800: 0.150470\n",
      "2022-11-08 19:51:02,833 INFO     Training average loss at step 506800: 0.162594\n",
      "2022-11-08 19:51:12,525 INFO     Training average positive_sample_loss at step 506900: 0.172462\n",
      "2022-11-08 19:51:12,525 INFO     Training average negative_sample_loss at step 506900: 0.151196\n",
      "2022-11-08 19:51:12,525 INFO     Training average loss at step 506900: 0.161829\n",
      "2022-11-08 19:51:22,214 INFO     Training average positive_sample_loss at step 507000: 0.180895\n",
      "2022-11-08 19:51:22,214 INFO     Training average negative_sample_loss at step 507000: 0.155313\n",
      "2022-11-08 19:51:22,214 INFO     Training average loss at step 507000: 0.168104\n",
      "2022-11-08 19:51:31,904 INFO     Training average positive_sample_loss at step 507100: 0.186594\n",
      "2022-11-08 19:51:31,904 INFO     Training average negative_sample_loss at step 507100: 0.153963\n",
      "2022-11-08 19:51:31,904 INFO     Training average loss at step 507100: 0.170279\n",
      "2022-11-08 19:51:41,603 INFO     Training average positive_sample_loss at step 507200: 0.174686\n",
      "2022-11-08 19:51:41,603 INFO     Training average negative_sample_loss at step 507200: 0.149932\n",
      "2022-11-08 19:51:41,603 INFO     Training average loss at step 507200: 0.162309\n",
      "2022-11-08 19:51:51,304 INFO     Training average positive_sample_loss at step 507300: 0.178279\n",
      "2022-11-08 19:51:51,305 INFO     Training average negative_sample_loss at step 507300: 0.151780\n",
      "2022-11-08 19:51:51,305 INFO     Training average loss at step 507300: 0.165030\n",
      "2022-11-08 19:52:00,999 INFO     Training average positive_sample_loss at step 507400: 0.174902\n",
      "2022-11-08 19:52:00,999 INFO     Training average negative_sample_loss at step 507400: 0.152033\n",
      "2022-11-08 19:52:00,999 INFO     Training average loss at step 507400: 0.163468\n",
      "2022-11-08 19:52:10,693 INFO     Training average positive_sample_loss at step 507500: 0.181184\n",
      "2022-11-08 19:52:10,693 INFO     Training average negative_sample_loss at step 507500: 0.154323\n",
      "2022-11-08 19:52:10,693 INFO     Training average loss at step 507500: 0.167754\n",
      "2022-11-08 19:52:20,383 INFO     Training average positive_sample_loss at step 507600: 0.183762\n",
      "2022-11-08 19:52:20,383 INFO     Training average negative_sample_loss at step 507600: 0.150947\n",
      "2022-11-08 19:52:20,383 INFO     Training average loss at step 507600: 0.167354\n",
      "2022-11-08 19:52:30,074 INFO     Training average positive_sample_loss at step 507700: 0.170898\n",
      "2022-11-08 19:52:30,075 INFO     Training average negative_sample_loss at step 507700: 0.150446\n",
      "2022-11-08 19:52:30,075 INFO     Training average loss at step 507700: 0.160672\n",
      "2022-11-08 19:52:39,768 INFO     Training average positive_sample_loss at step 507800: 0.178571\n",
      "2022-11-08 19:52:39,768 INFO     Training average negative_sample_loss at step 507800: 0.156664\n",
      "2022-11-08 19:52:39,768 INFO     Training average loss at step 507800: 0.167617\n",
      "2022-11-08 19:52:49,461 INFO     Training average positive_sample_loss at step 507900: 0.177374\n",
      "2022-11-08 19:52:49,461 INFO     Training average negative_sample_loss at step 507900: 0.156267\n",
      "2022-11-08 19:52:49,461 INFO     Training average loss at step 507900: 0.166820\n",
      "2022-11-08 19:52:59,153 INFO     Training average positive_sample_loss at step 508000: 0.179035\n",
      "2022-11-08 19:52:59,153 INFO     Training average negative_sample_loss at step 508000: 0.150711\n",
      "2022-11-08 19:52:59,153 INFO     Training average loss at step 508000: 0.164873\n",
      "2022-11-08 19:53:08,846 INFO     Training average positive_sample_loss at step 508100: 0.172894\n",
      "2022-11-08 19:53:08,846 INFO     Training average negative_sample_loss at step 508100: 0.151207\n",
      "2022-11-08 19:53:08,846 INFO     Training average loss at step 508100: 0.162051\n",
      "2022-11-08 19:53:18,536 INFO     Training average positive_sample_loss at step 508200: 0.180648\n",
      "2022-11-08 19:53:18,537 INFO     Training average negative_sample_loss at step 508200: 0.149574\n",
      "2022-11-08 19:53:18,537 INFO     Training average loss at step 508200: 0.165111\n",
      "2022-11-08 19:53:29,159 INFO     Training average positive_sample_loss at step 508300: 0.176848\n",
      "2022-11-08 19:53:29,159 INFO     Training average negative_sample_loss at step 508300: 0.151261\n",
      "2022-11-08 19:53:29,159 INFO     Training average loss at step 508300: 0.164054\n",
      "2022-11-08 19:53:40,138 INFO     Training average positive_sample_loss at step 508400: 0.172521\n",
      "2022-11-08 19:53:40,138 INFO     Training average negative_sample_loss at step 508400: 0.154882\n",
      "2022-11-08 19:53:40,138 INFO     Training average loss at step 508400: 0.163701\n",
      "2022-11-08 19:53:49,828 INFO     Training average positive_sample_loss at step 508500: 0.178004\n",
      "2022-11-08 19:53:49,828 INFO     Training average negative_sample_loss at step 508500: 0.151620\n",
      "2022-11-08 19:53:49,828 INFO     Training average loss at step 508500: 0.164812\n",
      "2022-11-08 19:53:59,516 INFO     Training average positive_sample_loss at step 508600: 0.178594\n",
      "2022-11-08 19:53:59,516 INFO     Training average negative_sample_loss at step 508600: 0.148025\n",
      "2022-11-08 19:53:59,516 INFO     Training average loss at step 508600: 0.163309\n",
      "2022-11-08 19:54:09,214 INFO     Training average positive_sample_loss at step 508700: 0.179255\n",
      "2022-11-08 19:54:09,214 INFO     Training average negative_sample_loss at step 508700: 0.150888\n",
      "2022-11-08 19:54:09,214 INFO     Training average loss at step 508700: 0.165072\n",
      "2022-11-08 19:54:18,925 INFO     Training average positive_sample_loss at step 508800: 0.171580\n",
      "2022-11-08 19:54:18,925 INFO     Training average negative_sample_loss at step 508800: 0.150973\n",
      "2022-11-08 19:54:18,925 INFO     Training average loss at step 508800: 0.161276\n",
      "2022-11-08 19:54:28,628 INFO     Training average positive_sample_loss at step 508900: 0.175645\n",
      "2022-11-08 19:54:28,628 INFO     Training average negative_sample_loss at step 508900: 0.151149\n",
      "2022-11-08 19:54:28,629 INFO     Training average loss at step 508900: 0.163397\n",
      "2022-11-08 19:54:38,318 INFO     Training average positive_sample_loss at step 509000: 0.175854\n",
      "2022-11-08 19:54:38,318 INFO     Training average negative_sample_loss at step 509000: 0.157909\n",
      "2022-11-08 19:54:38,318 INFO     Training average loss at step 509000: 0.166881\n",
      "2022-11-08 19:54:48,013 INFO     Training average positive_sample_loss at step 509100: 0.174916\n",
      "2022-11-08 19:54:48,013 INFO     Training average negative_sample_loss at step 509100: 0.152718\n",
      "2022-11-08 19:54:48,013 INFO     Training average loss at step 509100: 0.163817\n",
      "2022-11-08 19:54:57,702 INFO     Training average positive_sample_loss at step 509200: 0.171667\n",
      "2022-11-08 19:54:57,702 INFO     Training average negative_sample_loss at step 509200: 0.149927\n",
      "2022-11-08 19:54:57,702 INFO     Training average loss at step 509200: 0.160797\n",
      "2022-11-08 19:55:07,396 INFO     Training average positive_sample_loss at step 509300: 0.173588\n",
      "2022-11-08 19:55:07,396 INFO     Training average negative_sample_loss at step 509300: 0.153741\n",
      "2022-11-08 19:55:07,396 INFO     Training average loss at step 509300: 0.163664\n",
      "2022-11-08 19:55:17,087 INFO     Training average positive_sample_loss at step 509400: 0.178013\n",
      "2022-11-08 19:55:17,087 INFO     Training average negative_sample_loss at step 509400: 0.147986\n",
      "2022-11-08 19:55:17,087 INFO     Training average loss at step 509400: 0.162999\n",
      "2022-11-08 19:55:26,780 INFO     Training average positive_sample_loss at step 509500: 0.179246\n",
      "2022-11-08 19:55:26,780 INFO     Training average negative_sample_loss at step 509500: 0.151851\n",
      "2022-11-08 19:55:26,780 INFO     Training average loss at step 509500: 0.165549\n",
      "2022-11-08 19:55:36,470 INFO     Training average positive_sample_loss at step 509600: 0.172277\n",
      "2022-11-08 19:55:36,470 INFO     Training average negative_sample_loss at step 509600: 0.151070\n",
      "2022-11-08 19:55:36,470 INFO     Training average loss at step 509600: 0.161674\n",
      "2022-11-08 19:55:46,158 INFO     Training average positive_sample_loss at step 509700: 0.177274\n",
      "2022-11-08 19:55:46,158 INFO     Training average negative_sample_loss at step 509700: 0.152158\n",
      "2022-11-08 19:55:46,158 INFO     Training average loss at step 509700: 0.164716\n",
      "2022-11-08 19:55:55,850 INFO     Training average positive_sample_loss at step 509800: 0.177946\n",
      "2022-11-08 19:55:55,850 INFO     Training average negative_sample_loss at step 509800: 0.152456\n",
      "2022-11-08 19:55:55,850 INFO     Training average loss at step 509800: 0.165201\n",
      "2022-11-08 19:56:05,545 INFO     Training average positive_sample_loss at step 509900: 0.172579\n",
      "2022-11-08 19:56:05,545 INFO     Training average negative_sample_loss at step 509900: 0.148883\n",
      "2022-11-08 19:56:05,545 INFO     Training average loss at step 509900: 0.160731\n",
      "2022-11-08 19:56:18,030 INFO     Training average positive_sample_loss at step 510000: 0.176627\n",
      "2022-11-08 19:56:18,030 INFO     Training average negative_sample_loss at step 510000: 0.149769\n",
      "2022-11-08 19:56:18,030 INFO     Training average loss at step 510000: 0.163198\n",
      "2022-11-08 19:56:27,075 INFO     Training average positive_sample_loss at step 510100: 0.177514\n",
      "2022-11-08 19:56:27,075 INFO     Training average negative_sample_loss at step 510100: 0.148048\n",
      "2022-11-08 19:56:27,075 INFO     Training average loss at step 510100: 0.162781\n",
      "2022-11-08 19:56:36,774 INFO     Training average positive_sample_loss at step 510200: 0.183372\n",
      "2022-11-08 19:56:36,775 INFO     Training average negative_sample_loss at step 510200: 0.154299\n",
      "2022-11-08 19:56:36,775 INFO     Training average loss at step 510200: 0.168835\n",
      "2022-11-08 19:56:45,845 INFO     Training average positive_sample_loss at step 510300: 0.179346\n",
      "2022-11-08 19:56:45,846 INFO     Training average negative_sample_loss at step 510300: 0.153545\n",
      "2022-11-08 19:56:45,846 INFO     Training average loss at step 510300: 0.166445\n",
      "2022-11-08 19:56:54,581 INFO     Training average positive_sample_loss at step 510400: 0.184693\n",
      "2022-11-08 19:56:54,581 INFO     Training average negative_sample_loss at step 510400: 0.147210\n",
      "2022-11-08 19:56:54,581 INFO     Training average loss at step 510400: 0.165951\n",
      "2022-11-08 19:57:04,281 INFO     Training average positive_sample_loss at step 510500: 0.185136\n",
      "2022-11-08 19:57:04,281 INFO     Training average negative_sample_loss at step 510500: 0.152387\n",
      "2022-11-08 19:57:04,281 INFO     Training average loss at step 510500: 0.168762\n",
      "2022-11-08 19:57:13,972 INFO     Training average positive_sample_loss at step 510600: 0.178272\n",
      "2022-11-08 19:57:13,972 INFO     Training average negative_sample_loss at step 510600: 0.152165\n",
      "2022-11-08 19:57:13,972 INFO     Training average loss at step 510600: 0.165219\n",
      "2022-11-08 19:57:22,943 INFO     Training average positive_sample_loss at step 510700: 0.176893\n",
      "2022-11-08 19:57:22,943 INFO     Training average negative_sample_loss at step 510700: 0.157250\n",
      "2022-11-08 19:57:22,943 INFO     Training average loss at step 510700: 0.167072\n",
      "2022-11-08 19:57:32,641 INFO     Training average positive_sample_loss at step 510800: 0.180812\n",
      "2022-11-08 19:57:32,641 INFO     Training average negative_sample_loss at step 510800: 0.149456\n",
      "2022-11-08 19:57:32,641 INFO     Training average loss at step 510800: 0.165134\n",
      "2022-11-08 19:57:42,333 INFO     Training average positive_sample_loss at step 510900: 0.175733\n",
      "2022-11-08 19:57:42,333 INFO     Training average negative_sample_loss at step 510900: 0.154309\n",
      "2022-11-08 19:57:42,333 INFO     Training average loss at step 510900: 0.165021\n",
      "2022-11-08 19:57:52,023 INFO     Training average positive_sample_loss at step 511000: 0.172899\n",
      "2022-11-08 19:57:52,024 INFO     Training average negative_sample_loss at step 511000: 0.151566\n",
      "2022-11-08 19:57:52,024 INFO     Training average loss at step 511000: 0.162233\n",
      "2022-11-08 19:58:01,716 INFO     Training average positive_sample_loss at step 511100: 0.178448\n",
      "2022-11-08 19:58:01,716 INFO     Training average negative_sample_loss at step 511100: 0.150426\n",
      "2022-11-08 19:58:01,716 INFO     Training average loss at step 511100: 0.164437\n",
      "2022-11-08 19:58:11,407 INFO     Training average positive_sample_loss at step 511200: 0.176161\n",
      "2022-11-08 19:58:11,407 INFO     Training average negative_sample_loss at step 511200: 0.152353\n",
      "2022-11-08 19:58:11,407 INFO     Training average loss at step 511200: 0.164257\n",
      "2022-11-08 19:58:21,102 INFO     Training average positive_sample_loss at step 511300: 0.181348\n",
      "2022-11-08 19:58:21,102 INFO     Training average negative_sample_loss at step 511300: 0.151717\n",
      "2022-11-08 19:58:21,102 INFO     Training average loss at step 511300: 0.166533\n",
      "2022-11-08 19:58:30,794 INFO     Training average positive_sample_loss at step 511400: 0.175986\n",
      "2022-11-08 19:58:30,794 INFO     Training average negative_sample_loss at step 511400: 0.154138\n",
      "2022-11-08 19:58:30,794 INFO     Training average loss at step 511400: 0.165062\n",
      "2022-11-08 19:58:40,486 INFO     Training average positive_sample_loss at step 511500: 0.179090\n",
      "2022-11-08 19:58:40,486 INFO     Training average negative_sample_loss at step 511500: 0.151657\n",
      "2022-11-08 19:58:40,486 INFO     Training average loss at step 511500: 0.165374\n",
      "2022-11-08 19:58:50,178 INFO     Training average positive_sample_loss at step 511600: 0.176981\n",
      "2022-11-08 19:58:50,179 INFO     Training average negative_sample_loss at step 511600: 0.152461\n",
      "2022-11-08 19:58:50,179 INFO     Training average loss at step 511600: 0.164721\n",
      "2022-11-08 19:58:59,870 INFO     Training average positive_sample_loss at step 511700: 0.173252\n",
      "2022-11-08 19:58:59,870 INFO     Training average negative_sample_loss at step 511700: 0.151242\n",
      "2022-11-08 19:58:59,870 INFO     Training average loss at step 511700: 0.162247\n",
      "2022-11-08 19:59:09,564 INFO     Training average positive_sample_loss at step 511800: 0.170275\n",
      "2022-11-08 19:59:09,564 INFO     Training average negative_sample_loss at step 511800: 0.149340\n",
      "2022-11-08 19:59:09,564 INFO     Training average loss at step 511800: 0.159807\n",
      "2022-11-08 19:59:19,257 INFO     Training average positive_sample_loss at step 511900: 0.179982\n",
      "2022-11-08 19:59:19,257 INFO     Training average negative_sample_loss at step 511900: 0.156677\n",
      "2022-11-08 19:59:19,257 INFO     Training average loss at step 511900: 0.168330\n",
      "2022-11-08 19:59:28,949 INFO     Training average positive_sample_loss at step 512000: 0.176148\n",
      "2022-11-08 19:59:28,949 INFO     Training average negative_sample_loss at step 512000: 0.152547\n",
      "2022-11-08 19:59:28,949 INFO     Training average loss at step 512000: 0.164347\n",
      "2022-11-08 19:59:38,641 INFO     Training average positive_sample_loss at step 512100: 0.180996\n",
      "2022-11-08 19:59:38,641 INFO     Training average negative_sample_loss at step 512100: 0.150241\n",
      "2022-11-08 19:59:38,641 INFO     Training average loss at step 512100: 0.165618\n",
      "2022-11-08 19:59:48,338 INFO     Training average positive_sample_loss at step 512200: 0.181483\n",
      "2022-11-08 19:59:48,338 INFO     Training average negative_sample_loss at step 512200: 0.147874\n",
      "2022-11-08 19:59:48,338 INFO     Training average loss at step 512200: 0.164678\n",
      "2022-11-08 19:59:58,028 INFO     Training average positive_sample_loss at step 512300: 0.174161\n",
      "2022-11-08 19:59:58,028 INFO     Training average negative_sample_loss at step 512300: 0.154692\n",
      "2022-11-08 19:59:58,028 INFO     Training average loss at step 512300: 0.164427\n",
      "2022-11-08 20:00:07,723 INFO     Training average positive_sample_loss at step 512400: 0.174405\n",
      "2022-11-08 20:00:07,723 INFO     Training average negative_sample_loss at step 512400: 0.149559\n",
      "2022-11-08 20:00:07,723 INFO     Training average loss at step 512400: 0.161982\n",
      "2022-11-08 20:00:17,418 INFO     Training average positive_sample_loss at step 512500: 0.172582\n",
      "2022-11-08 20:00:17,418 INFO     Training average negative_sample_loss at step 512500: 0.152730\n",
      "2022-11-08 20:00:17,418 INFO     Training average loss at step 512500: 0.162656\n",
      "2022-11-08 20:00:27,107 INFO     Training average positive_sample_loss at step 512600: 0.183109\n",
      "2022-11-08 20:00:27,107 INFO     Training average negative_sample_loss at step 512600: 0.151625\n",
      "2022-11-08 20:00:27,107 INFO     Training average loss at step 512600: 0.167367\n",
      "2022-11-08 20:00:36,799 INFO     Training average positive_sample_loss at step 512700: 0.174893\n",
      "2022-11-08 20:00:36,799 INFO     Training average negative_sample_loss at step 512700: 0.152249\n",
      "2022-11-08 20:00:36,799 INFO     Training average loss at step 512700: 0.163571\n",
      "2022-11-08 20:00:46,489 INFO     Training average positive_sample_loss at step 512800: 0.173489\n",
      "2022-11-08 20:00:46,489 INFO     Training average negative_sample_loss at step 512800: 0.150266\n",
      "2022-11-08 20:00:46,489 INFO     Training average loss at step 512800: 0.161878\n",
      "2022-11-08 20:00:56,178 INFO     Training average positive_sample_loss at step 512900: 0.173980\n",
      "2022-11-08 20:00:56,178 INFO     Training average negative_sample_loss at step 512900: 0.147878\n",
      "2022-11-08 20:00:56,178 INFO     Training average loss at step 512900: 0.160929\n",
      "2022-11-08 20:01:06,748 INFO     Training average positive_sample_loss at step 513000: 0.171074\n",
      "2022-11-08 20:01:06,748 INFO     Training average negative_sample_loss at step 513000: 0.150056\n",
      "2022-11-08 20:01:06,748 INFO     Training average loss at step 513000: 0.160565\n",
      "2022-11-08 20:01:17,786 INFO     Training average positive_sample_loss at step 513100: 0.181361\n",
      "2022-11-08 20:01:17,786 INFO     Training average negative_sample_loss at step 513100: 0.150534\n",
      "2022-11-08 20:01:17,786 INFO     Training average loss at step 513100: 0.165948\n",
      "2022-11-08 20:01:27,478 INFO     Training average positive_sample_loss at step 513200: 0.177811\n",
      "2022-11-08 20:01:27,478 INFO     Training average negative_sample_loss at step 513200: 0.149736\n",
      "2022-11-08 20:01:27,478 INFO     Training average loss at step 513200: 0.163773\n",
      "2022-11-08 20:01:37,174 INFO     Training average positive_sample_loss at step 513300: 0.175337\n",
      "2022-11-08 20:01:37,174 INFO     Training average negative_sample_loss at step 513300: 0.150179\n",
      "2022-11-08 20:01:37,174 INFO     Training average loss at step 513300: 0.162758\n",
      "2022-11-08 20:01:46,865 INFO     Training average positive_sample_loss at step 513400: 0.174926\n",
      "2022-11-08 20:01:46,865 INFO     Training average negative_sample_loss at step 513400: 0.149409\n",
      "2022-11-08 20:01:46,865 INFO     Training average loss at step 513400: 0.162167\n",
      "2022-11-08 20:01:56,554 INFO     Training average positive_sample_loss at step 513500: 0.182117\n",
      "2022-11-08 20:01:56,554 INFO     Training average negative_sample_loss at step 513500: 0.146494\n",
      "2022-11-08 20:01:56,554 INFO     Training average loss at step 513500: 0.164306\n",
      "2022-11-08 20:02:06,248 INFO     Training average positive_sample_loss at step 513600: 0.184193\n",
      "2022-11-08 20:02:06,248 INFO     Training average negative_sample_loss at step 513600: 0.150765\n",
      "2022-11-08 20:02:06,248 INFO     Training average loss at step 513600: 0.167479\n",
      "2022-11-08 20:02:15,937 INFO     Training average positive_sample_loss at step 513700: 0.178368\n",
      "2022-11-08 20:02:15,937 INFO     Training average negative_sample_loss at step 513700: 0.151714\n",
      "2022-11-08 20:02:15,937 INFO     Training average loss at step 513700: 0.165041\n",
      "2022-11-08 20:02:25,626 INFO     Training average positive_sample_loss at step 513800: 0.180016\n",
      "2022-11-08 20:02:25,626 INFO     Training average negative_sample_loss at step 513800: 0.149798\n",
      "2022-11-08 20:02:25,626 INFO     Training average loss at step 513800: 0.164907\n",
      "2022-11-08 20:02:35,319 INFO     Training average positive_sample_loss at step 513900: 0.172965\n",
      "2022-11-08 20:02:35,319 INFO     Training average negative_sample_loss at step 513900: 0.150473\n",
      "2022-11-08 20:02:35,319 INFO     Training average loss at step 513900: 0.161719\n",
      "2022-11-08 20:02:45,009 INFO     Training average positive_sample_loss at step 514000: 0.175301\n",
      "2022-11-08 20:02:45,009 INFO     Training average negative_sample_loss at step 514000: 0.148880\n",
      "2022-11-08 20:02:45,009 INFO     Training average loss at step 514000: 0.162090\n",
      "2022-11-08 20:02:54,703 INFO     Training average positive_sample_loss at step 514100: 0.173728\n",
      "2022-11-08 20:02:54,703 INFO     Training average negative_sample_loss at step 514100: 0.148017\n",
      "2022-11-08 20:02:54,703 INFO     Training average loss at step 514100: 0.160873\n",
      "2022-11-08 20:03:04,403 INFO     Training average positive_sample_loss at step 514200: 0.176926\n",
      "2022-11-08 20:03:04,403 INFO     Training average negative_sample_loss at step 514200: 0.151303\n",
      "2022-11-08 20:03:04,403 INFO     Training average loss at step 514200: 0.164115\n",
      "2022-11-08 20:03:14,098 INFO     Training average positive_sample_loss at step 514300: 0.169612\n",
      "2022-11-08 20:03:14,098 INFO     Training average negative_sample_loss at step 514300: 0.151471\n",
      "2022-11-08 20:03:14,098 INFO     Training average loss at step 514300: 0.160542\n",
      "2022-11-08 20:03:23,806 INFO     Training average positive_sample_loss at step 514400: 0.175943\n",
      "2022-11-08 20:03:23,806 INFO     Training average negative_sample_loss at step 514400: 0.147805\n",
      "2022-11-08 20:03:23,806 INFO     Training average loss at step 514400: 0.161874\n",
      "2022-11-08 20:03:33,511 INFO     Training average positive_sample_loss at step 514500: 0.169737\n",
      "2022-11-08 20:03:33,511 INFO     Training average negative_sample_loss at step 514500: 0.151177\n",
      "2022-11-08 20:03:33,511 INFO     Training average loss at step 514500: 0.160457\n",
      "2022-11-08 20:03:43,207 INFO     Training average positive_sample_loss at step 514600: 0.175106\n",
      "2022-11-08 20:03:43,207 INFO     Training average negative_sample_loss at step 514600: 0.148502\n",
      "2022-11-08 20:03:43,207 INFO     Training average loss at step 514600: 0.161804\n",
      "2022-11-08 20:03:52,905 INFO     Training average positive_sample_loss at step 514700: 0.165584\n",
      "2022-11-08 20:03:52,905 INFO     Training average negative_sample_loss at step 514700: 0.149648\n",
      "2022-11-08 20:03:52,905 INFO     Training average loss at step 514700: 0.157616\n",
      "2022-11-08 20:04:02,602 INFO     Training average positive_sample_loss at step 514800: 0.176592\n",
      "2022-11-08 20:04:02,602 INFO     Training average negative_sample_loss at step 514800: 0.150244\n",
      "2022-11-08 20:04:02,602 INFO     Training average loss at step 514800: 0.163418\n",
      "2022-11-08 20:04:12,300 INFO     Training average positive_sample_loss at step 514900: 0.174537\n",
      "2022-11-08 20:04:12,300 INFO     Training average negative_sample_loss at step 514900: 0.148376\n",
      "2022-11-08 20:04:12,300 INFO     Training average loss at step 514900: 0.161456\n",
      "2022-11-08 20:04:21,998 INFO     Training average positive_sample_loss at step 515000: 0.179580\n",
      "2022-11-08 20:04:21,998 INFO     Training average negative_sample_loss at step 515000: 0.150780\n",
      "2022-11-08 20:04:21,998 INFO     Training average loss at step 515000: 0.165180\n",
      "2022-11-08 20:04:31,696 INFO     Training average positive_sample_loss at step 515100: 0.175110\n",
      "2022-11-08 20:04:31,696 INFO     Training average negative_sample_loss at step 515100: 0.145181\n",
      "2022-11-08 20:04:31,696 INFO     Training average loss at step 515100: 0.160145\n",
      "2022-11-08 20:04:41,396 INFO     Training average positive_sample_loss at step 515200: 0.168732\n",
      "2022-11-08 20:04:41,396 INFO     Training average negative_sample_loss at step 515200: 0.154088\n",
      "2022-11-08 20:04:41,396 INFO     Training average loss at step 515200: 0.161410\n",
      "2022-11-08 20:04:51,097 INFO     Training average positive_sample_loss at step 515300: 0.174345\n",
      "2022-11-08 20:04:51,098 INFO     Training average negative_sample_loss at step 515300: 0.151538\n",
      "2022-11-08 20:04:51,098 INFO     Training average loss at step 515300: 0.162942\n",
      "2022-11-08 20:05:00,799 INFO     Training average positive_sample_loss at step 515400: 0.180093\n",
      "2022-11-08 20:05:00,799 INFO     Training average negative_sample_loss at step 515400: 0.150112\n",
      "2022-11-08 20:05:00,799 INFO     Training average loss at step 515400: 0.165103\n",
      "2022-11-08 20:05:10,497 INFO     Training average positive_sample_loss at step 515500: 0.171106\n",
      "2022-11-08 20:05:10,497 INFO     Training average negative_sample_loss at step 515500: 0.149907\n",
      "2022-11-08 20:05:10,497 INFO     Training average loss at step 515500: 0.160506\n",
      "2022-11-08 20:05:19,509 INFO     Training average positive_sample_loss at step 515600: 0.171278\n",
      "2022-11-08 20:05:19,509 INFO     Training average negative_sample_loss at step 515600: 0.152709\n",
      "2022-11-08 20:05:19,509 INFO     Training average loss at step 515600: 0.161994\n",
      "2022-11-08 20:05:29,208 INFO     Training average positive_sample_loss at step 515700: 0.173859\n",
      "2022-11-08 20:05:29,208 INFO     Training average negative_sample_loss at step 515700: 0.151844\n",
      "2022-11-08 20:05:29,208 INFO     Training average loss at step 515700: 0.162851\n",
      "2022-11-08 20:05:38,906 INFO     Training average positive_sample_loss at step 515800: 0.177728\n",
      "2022-11-08 20:05:38,906 INFO     Training average negative_sample_loss at step 515800: 0.154067\n",
      "2022-11-08 20:05:38,906 INFO     Training average loss at step 515800: 0.165897\n",
      "2022-11-08 20:05:48,601 INFO     Training average positive_sample_loss at step 515900: 0.176741\n",
      "2022-11-08 20:05:48,601 INFO     Training average negative_sample_loss at step 515900: 0.155480\n",
      "2022-11-08 20:05:48,601 INFO     Training average loss at step 515900: 0.166111\n",
      "2022-11-08 20:05:58,298 INFO     Training average positive_sample_loss at step 516000: 0.174208\n",
      "2022-11-08 20:05:58,298 INFO     Training average negative_sample_loss at step 516000: 0.155148\n",
      "2022-11-08 20:05:58,298 INFO     Training average loss at step 516000: 0.164678\n",
      "2022-11-08 20:06:08,000 INFO     Training average positive_sample_loss at step 516100: 0.182458\n",
      "2022-11-08 20:06:08,000 INFO     Training average negative_sample_loss at step 516100: 0.152266\n",
      "2022-11-08 20:06:08,000 INFO     Training average loss at step 516100: 0.167362\n",
      "2022-11-08 20:06:16,987 INFO     Training average positive_sample_loss at step 516200: 0.176308\n",
      "2022-11-08 20:06:16,987 INFO     Training average negative_sample_loss at step 516200: 0.154211\n",
      "2022-11-08 20:06:16,987 INFO     Training average loss at step 516200: 0.165259\n",
      "2022-11-08 20:06:26,688 INFO     Training average positive_sample_loss at step 516300: 0.171741\n",
      "2022-11-08 20:06:26,688 INFO     Training average negative_sample_loss at step 516300: 0.149614\n",
      "2022-11-08 20:06:26,688 INFO     Training average loss at step 516300: 0.160678\n",
      "2022-11-08 20:06:36,386 INFO     Training average positive_sample_loss at step 516400: 0.172677\n",
      "2022-11-08 20:06:36,386 INFO     Training average negative_sample_loss at step 516400: 0.148595\n",
      "2022-11-08 20:06:36,386 INFO     Training average loss at step 516400: 0.160636\n",
      "2022-11-08 20:06:46,083 INFO     Training average positive_sample_loss at step 516500: 0.172935\n",
      "2022-11-08 20:06:46,083 INFO     Training average negative_sample_loss at step 516500: 0.151184\n",
      "2022-11-08 20:06:46,083 INFO     Training average loss at step 516500: 0.162060\n",
      "2022-11-08 20:06:55,785 INFO     Training average positive_sample_loss at step 516600: 0.175414\n",
      "2022-11-08 20:06:55,785 INFO     Training average negative_sample_loss at step 516600: 0.149121\n",
      "2022-11-08 20:06:55,785 INFO     Training average loss at step 516600: 0.162267\n",
      "2022-11-08 20:07:05,482 INFO     Training average positive_sample_loss at step 516700: 0.175640\n",
      "2022-11-08 20:07:05,482 INFO     Training average negative_sample_loss at step 516700: 0.147627\n",
      "2022-11-08 20:07:05,482 INFO     Training average loss at step 516700: 0.161634\n",
      "2022-11-08 20:07:15,181 INFO     Training average positive_sample_loss at step 516800: 0.177019\n",
      "2022-11-08 20:07:15,181 INFO     Training average negative_sample_loss at step 516800: 0.152895\n",
      "2022-11-08 20:07:15,181 INFO     Training average loss at step 516800: 0.164957\n",
      "2022-11-08 20:07:24,881 INFO     Training average positive_sample_loss at step 516900: 0.168659\n",
      "2022-11-08 20:07:24,882 INFO     Training average negative_sample_loss at step 516900: 0.148328\n",
      "2022-11-08 20:07:24,882 INFO     Training average loss at step 516900: 0.158493\n",
      "2022-11-08 20:07:34,575 INFO     Training average positive_sample_loss at step 517000: 0.178050\n",
      "2022-11-08 20:07:34,576 INFO     Training average negative_sample_loss at step 517000: 0.150095\n",
      "2022-11-08 20:07:34,576 INFO     Training average loss at step 517000: 0.164073\n",
      "2022-11-08 20:07:44,272 INFO     Training average positive_sample_loss at step 517100: 0.176199\n",
      "2022-11-08 20:07:44,272 INFO     Training average negative_sample_loss at step 517100: 0.147203\n",
      "2022-11-08 20:07:44,272 INFO     Training average loss at step 517100: 0.161701\n",
      "2022-11-08 20:07:53,973 INFO     Training average positive_sample_loss at step 517200: 0.171670\n",
      "2022-11-08 20:07:53,973 INFO     Training average negative_sample_loss at step 517200: 0.153275\n",
      "2022-11-08 20:07:53,973 INFO     Training average loss at step 517200: 0.162472\n",
      "2022-11-08 20:08:03,669 INFO     Training average positive_sample_loss at step 517300: 0.170405\n",
      "2022-11-08 20:08:03,669 INFO     Training average negative_sample_loss at step 517300: 0.151519\n",
      "2022-11-08 20:08:03,669 INFO     Training average loss at step 517300: 0.160962\n",
      "2022-11-08 20:08:13,367 INFO     Training average positive_sample_loss at step 517400: 0.172725\n",
      "2022-11-08 20:08:13,367 INFO     Training average negative_sample_loss at step 517400: 0.154729\n",
      "2022-11-08 20:08:13,367 INFO     Training average loss at step 517400: 0.163727\n",
      "2022-11-08 20:08:23,527 INFO     Training average positive_sample_loss at step 517500: 0.183390\n",
      "2022-11-08 20:08:23,527 INFO     Training average negative_sample_loss at step 517500: 0.148156\n",
      "2022-11-08 20:08:23,527 INFO     Training average loss at step 517500: 0.165773\n",
      "2022-11-08 20:08:33,230 INFO     Training average positive_sample_loss at step 517600: 0.173563\n",
      "2022-11-08 20:08:33,230 INFO     Training average negative_sample_loss at step 517600: 0.154261\n",
      "2022-11-08 20:08:33,230 INFO     Training average loss at step 517600: 0.163912\n",
      "2022-11-08 20:08:43,496 INFO     Training average positive_sample_loss at step 517700: 0.174002\n",
      "2022-11-08 20:08:43,496 INFO     Training average negative_sample_loss at step 517700: 0.147700\n",
      "2022-11-08 20:08:43,496 INFO     Training average loss at step 517700: 0.160851\n",
      "2022-11-08 20:08:54,393 INFO     Training average positive_sample_loss at step 517800: 0.172730\n",
      "2022-11-08 20:08:54,393 INFO     Training average negative_sample_loss at step 517800: 0.150921\n",
      "2022-11-08 20:08:54,393 INFO     Training average loss at step 517800: 0.161826\n",
      "2022-11-08 20:09:04,094 INFO     Training average positive_sample_loss at step 517900: 0.172108\n",
      "2022-11-08 20:09:04,094 INFO     Training average negative_sample_loss at step 517900: 0.154639\n",
      "2022-11-08 20:09:04,094 INFO     Training average loss at step 517900: 0.163373\n",
      "2022-11-08 20:09:13,791 INFO     Training average positive_sample_loss at step 518000: 0.173372\n",
      "2022-11-08 20:09:13,791 INFO     Training average negative_sample_loss at step 518000: 0.148093\n",
      "2022-11-08 20:09:13,791 INFO     Training average loss at step 518000: 0.160733\n",
      "2022-11-08 20:09:23,496 INFO     Training average positive_sample_loss at step 518100: 0.174627\n",
      "2022-11-08 20:09:23,496 INFO     Training average negative_sample_loss at step 518100: 0.150760\n",
      "2022-11-08 20:09:23,496 INFO     Training average loss at step 518100: 0.162694\n",
      "2022-11-08 20:09:33,193 INFO     Training average positive_sample_loss at step 518200: 0.171068\n",
      "2022-11-08 20:09:33,194 INFO     Training average negative_sample_loss at step 518200: 0.151884\n",
      "2022-11-08 20:09:33,194 INFO     Training average loss at step 518200: 0.161476\n",
      "2022-11-08 20:09:42,888 INFO     Training average positive_sample_loss at step 518300: 0.180897\n",
      "2022-11-08 20:09:42,888 INFO     Training average negative_sample_loss at step 518300: 0.148932\n",
      "2022-11-08 20:09:42,888 INFO     Training average loss at step 518300: 0.164914\n",
      "2022-11-08 20:09:52,589 INFO     Training average positive_sample_loss at step 518400: 0.178410\n",
      "2022-11-08 20:09:52,590 INFO     Training average negative_sample_loss at step 518400: 0.152348\n",
      "2022-11-08 20:09:52,590 INFO     Training average loss at step 518400: 0.165379\n",
      "2022-11-08 20:10:02,287 INFO     Training average positive_sample_loss at step 518500: 0.171538\n",
      "2022-11-08 20:10:02,287 INFO     Training average negative_sample_loss at step 518500: 0.151494\n",
      "2022-11-08 20:10:02,287 INFO     Training average loss at step 518500: 0.161516\n",
      "2022-11-08 20:10:11,986 INFO     Training average positive_sample_loss at step 518600: 0.174105\n",
      "2022-11-08 20:10:11,986 INFO     Training average negative_sample_loss at step 518600: 0.154985\n",
      "2022-11-08 20:10:11,986 INFO     Training average loss at step 518600: 0.164545\n",
      "2022-11-08 20:10:21,685 INFO     Training average positive_sample_loss at step 518700: 0.174165\n",
      "2022-11-08 20:10:21,685 INFO     Training average negative_sample_loss at step 518700: 0.151456\n",
      "2022-11-08 20:10:21,685 INFO     Training average loss at step 518700: 0.162811\n",
      "2022-11-08 20:10:31,379 INFO     Training average positive_sample_loss at step 518800: 0.178584\n",
      "2022-11-08 20:10:31,379 INFO     Training average negative_sample_loss at step 518800: 0.149616\n",
      "2022-11-08 20:10:31,379 INFO     Training average loss at step 518800: 0.164100\n",
      "2022-11-08 20:10:41,079 INFO     Training average positive_sample_loss at step 518900: 0.170377\n",
      "2022-11-08 20:10:41,079 INFO     Training average negative_sample_loss at step 518900: 0.150830\n",
      "2022-11-08 20:10:41,079 INFO     Training average loss at step 518900: 0.160603\n",
      "2022-11-08 20:10:50,778 INFO     Training average positive_sample_loss at step 519000: 0.170312\n",
      "2022-11-08 20:10:50,778 INFO     Training average negative_sample_loss at step 519000: 0.155868\n",
      "2022-11-08 20:10:50,778 INFO     Training average loss at step 519000: 0.163090\n",
      "2022-11-08 20:11:00,475 INFO     Training average positive_sample_loss at step 519100: 0.175017\n",
      "2022-11-08 20:11:00,475 INFO     Training average negative_sample_loss at step 519100: 0.150737\n",
      "2022-11-08 20:11:00,475 INFO     Training average loss at step 519100: 0.162877\n",
      "2022-11-08 20:11:10,172 INFO     Training average positive_sample_loss at step 519200: 0.173001\n",
      "2022-11-08 20:11:10,172 INFO     Training average negative_sample_loss at step 519200: 0.151444\n",
      "2022-11-08 20:11:10,172 INFO     Training average loss at step 519200: 0.162222\n",
      "2022-11-08 20:11:19,870 INFO     Training average positive_sample_loss at step 519300: 0.171444\n",
      "2022-11-08 20:11:19,870 INFO     Training average negative_sample_loss at step 519300: 0.146368\n",
      "2022-11-08 20:11:19,870 INFO     Training average loss at step 519300: 0.158906\n",
      "2022-11-08 20:11:29,563 INFO     Training average positive_sample_loss at step 519400: 0.171765\n",
      "2022-11-08 20:11:29,564 INFO     Training average negative_sample_loss at step 519400: 0.150337\n",
      "2022-11-08 20:11:29,564 INFO     Training average loss at step 519400: 0.161051\n",
      "2022-11-08 20:11:39,267 INFO     Training average positive_sample_loss at step 519500: 0.169457\n",
      "2022-11-08 20:11:39,267 INFO     Training average negative_sample_loss at step 519500: 0.150148\n",
      "2022-11-08 20:11:39,267 INFO     Training average loss at step 519500: 0.159803\n",
      "2022-11-08 20:11:48,968 INFO     Training average positive_sample_loss at step 519600: 0.174591\n",
      "2022-11-08 20:11:48,968 INFO     Training average negative_sample_loss at step 519600: 0.148554\n",
      "2022-11-08 20:11:48,968 INFO     Training average loss at step 519600: 0.161572\n",
      "2022-11-08 20:11:58,663 INFO     Training average positive_sample_loss at step 519700: 0.171979\n",
      "2022-11-08 20:11:58,663 INFO     Training average negative_sample_loss at step 519700: 0.151879\n",
      "2022-11-08 20:11:58,664 INFO     Training average loss at step 519700: 0.161929\n",
      "2022-11-08 20:12:08,363 INFO     Training average positive_sample_loss at step 519800: 0.169201\n",
      "2022-11-08 20:12:08,363 INFO     Training average negative_sample_loss at step 519800: 0.145872\n",
      "2022-11-08 20:12:08,363 INFO     Training average loss at step 519800: 0.157537\n",
      "2022-11-08 20:12:18,059 INFO     Training average positive_sample_loss at step 519900: 0.174360\n",
      "2022-11-08 20:12:18,059 INFO     Training average negative_sample_loss at step 519900: 0.146449\n",
      "2022-11-08 20:12:18,059 INFO     Training average loss at step 519900: 0.160404\n",
      "2022-11-08 20:12:30,673 INFO     Training average positive_sample_loss at step 520000: 0.173576\n",
      "2022-11-08 20:12:30,673 INFO     Training average negative_sample_loss at step 520000: 0.150299\n",
      "2022-11-08 20:12:30,673 INFO     Training average loss at step 520000: 0.161937\n",
      "2022-11-08 20:12:40,369 INFO     Training average positive_sample_loss at step 520100: 0.171867\n",
      "2022-11-08 20:12:40,369 INFO     Training average negative_sample_loss at step 520100: 0.152828\n",
      "2022-11-08 20:12:40,369 INFO     Training average loss at step 520100: 0.162347\n",
      "2022-11-08 20:12:50,066 INFO     Training average positive_sample_loss at step 520200: 0.171987\n",
      "2022-11-08 20:12:50,066 INFO     Training average negative_sample_loss at step 520200: 0.154545\n",
      "2022-11-08 20:12:50,066 INFO     Training average loss at step 520200: 0.163266\n",
      "2022-11-08 20:12:59,763 INFO     Training average positive_sample_loss at step 520300: 0.173605\n",
      "2022-11-08 20:12:59,763 INFO     Training average negative_sample_loss at step 520300: 0.154660\n",
      "2022-11-08 20:12:59,763 INFO     Training average loss at step 520300: 0.164132\n",
      "2022-11-08 20:13:09,468 INFO     Training average positive_sample_loss at step 520400: 0.178237\n",
      "2022-11-08 20:13:09,468 INFO     Training average negative_sample_loss at step 520400: 0.152912\n",
      "2022-11-08 20:13:09,468 INFO     Training average loss at step 520400: 0.165575\n",
      "2022-11-08 20:13:19,165 INFO     Training average positive_sample_loss at step 520500: 0.170257\n",
      "2022-11-08 20:13:19,165 INFO     Training average negative_sample_loss at step 520500: 0.149065\n",
      "2022-11-08 20:13:19,165 INFO     Training average loss at step 520500: 0.159661\n",
      "2022-11-08 20:13:28,863 INFO     Training average positive_sample_loss at step 520600: 0.180560\n",
      "2022-11-08 20:13:28,863 INFO     Training average negative_sample_loss at step 520600: 0.154660\n",
      "2022-11-08 20:13:28,863 INFO     Training average loss at step 520600: 0.167610\n",
      "2022-11-08 20:13:38,563 INFO     Training average positive_sample_loss at step 520700: 0.174343\n",
      "2022-11-08 20:13:38,563 INFO     Training average negative_sample_loss at step 520700: 0.149396\n",
      "2022-11-08 20:13:38,563 INFO     Training average loss at step 520700: 0.161870\n",
      "2022-11-08 20:13:48,261 INFO     Training average positive_sample_loss at step 520800: 0.177931\n",
      "2022-11-08 20:13:48,261 INFO     Training average negative_sample_loss at step 520800: 0.152061\n",
      "2022-11-08 20:13:48,261 INFO     Training average loss at step 520800: 0.164996\n",
      "2022-11-08 20:13:57,959 INFO     Training average positive_sample_loss at step 520900: 0.170182\n",
      "2022-11-08 20:13:57,959 INFO     Training average negative_sample_loss at step 520900: 0.150412\n",
      "2022-11-08 20:13:57,959 INFO     Training average loss at step 520900: 0.160297\n",
      "2022-11-08 20:14:07,266 INFO     Training average positive_sample_loss at step 521000: 0.171454\n",
      "2022-11-08 20:14:07,266 INFO     Training average negative_sample_loss at step 521000: 0.146459\n",
      "2022-11-08 20:14:07,266 INFO     Training average loss at step 521000: 0.158957\n",
      "2022-11-08 20:14:16,679 INFO     Training average positive_sample_loss at step 521100: 0.175220\n",
      "2022-11-08 20:14:16,679 INFO     Training average negative_sample_loss at step 521100: 0.152164\n",
      "2022-11-08 20:14:16,679 INFO     Training average loss at step 521100: 0.163692\n",
      "2022-11-08 20:14:26,377 INFO     Training average positive_sample_loss at step 521200: 0.172129\n",
      "2022-11-08 20:14:26,377 INFO     Training average negative_sample_loss at step 521200: 0.149425\n",
      "2022-11-08 20:14:26,377 INFO     Training average loss at step 521200: 0.160777\n",
      "2022-11-08 20:14:36,072 INFO     Training average positive_sample_loss at step 521300: 0.172168\n",
      "2022-11-08 20:14:36,072 INFO     Training average negative_sample_loss at step 521300: 0.153474\n",
      "2022-11-08 20:14:36,072 INFO     Training average loss at step 521300: 0.162821\n",
      "2022-11-08 20:14:45,771 INFO     Training average positive_sample_loss at step 521400: 0.177369\n",
      "2022-11-08 20:14:45,771 INFO     Training average negative_sample_loss at step 521400: 0.151091\n",
      "2022-11-08 20:14:45,771 INFO     Training average loss at step 521400: 0.164230\n",
      "2022-11-08 20:14:55,471 INFO     Training average positive_sample_loss at step 521500: 0.178655\n",
      "2022-11-08 20:14:55,471 INFO     Training average negative_sample_loss at step 521500: 0.149050\n",
      "2022-11-08 20:14:55,471 INFO     Training average loss at step 521500: 0.163853\n",
      "2022-11-08 20:15:04,512 INFO     Training average positive_sample_loss at step 521600: 0.177206\n",
      "2022-11-08 20:15:04,512 INFO     Training average negative_sample_loss at step 521600: 0.144279\n",
      "2022-11-08 20:15:04,512 INFO     Training average loss at step 521600: 0.160743\n",
      "2022-11-08 20:15:14,140 INFO     Training average positive_sample_loss at step 521700: 0.172003\n",
      "2022-11-08 20:15:14,140 INFO     Training average negative_sample_loss at step 521700: 0.150336\n",
      "2022-11-08 20:15:14,140 INFO     Training average loss at step 521700: 0.161170\n",
      "2022-11-08 20:15:23,841 INFO     Training average positive_sample_loss at step 521800: 0.168191\n",
      "2022-11-08 20:15:23,841 INFO     Training average negative_sample_loss at step 521800: 0.153235\n",
      "2022-11-08 20:15:23,841 INFO     Training average loss at step 521800: 0.160713\n",
      "2022-11-08 20:15:33,538 INFO     Training average positive_sample_loss at step 521900: 0.175188\n",
      "2022-11-08 20:15:33,538 INFO     Training average negative_sample_loss at step 521900: 0.149115\n",
      "2022-11-08 20:15:33,538 INFO     Training average loss at step 521900: 0.162152\n",
      "2022-11-08 20:15:43,236 INFO     Training average positive_sample_loss at step 522000: 0.177320\n",
      "2022-11-08 20:15:43,236 INFO     Training average negative_sample_loss at step 522000: 0.151493\n",
      "2022-11-08 20:15:43,236 INFO     Training average loss at step 522000: 0.164406\n",
      "2022-11-08 20:15:53,366 INFO     Training average positive_sample_loss at step 522100: 0.181086\n",
      "2022-11-08 20:15:53,366 INFO     Training average negative_sample_loss at step 522100: 0.152148\n",
      "2022-11-08 20:15:53,366 INFO     Training average loss at step 522100: 0.166617\n",
      "2022-11-08 20:16:03,510 INFO     Training average positive_sample_loss at step 522200: 0.170879\n",
      "2022-11-08 20:16:03,510 INFO     Training average negative_sample_loss at step 522200: 0.147650\n",
      "2022-11-08 20:16:03,510 INFO     Training average loss at step 522200: 0.159265\n",
      "2022-11-08 20:16:14,142 INFO     Training average positive_sample_loss at step 522300: 0.174626\n",
      "2022-11-08 20:16:14,142 INFO     Training average negative_sample_loss at step 522300: 0.150904\n",
      "2022-11-08 20:16:14,142 INFO     Training average loss at step 522300: 0.162765\n",
      "2022-11-08 20:16:23,840 INFO     Training average positive_sample_loss at step 522400: 0.174062\n",
      "2022-11-08 20:16:23,840 INFO     Training average negative_sample_loss at step 522400: 0.150124\n",
      "2022-11-08 20:16:23,840 INFO     Training average loss at step 522400: 0.162093\n",
      "2022-11-08 20:16:34,034 INFO     Training average positive_sample_loss at step 522500: 0.176140\n",
      "2022-11-08 20:16:34,034 INFO     Training average negative_sample_loss at step 522500: 0.154166\n",
      "2022-11-08 20:16:34,034 INFO     Training average loss at step 522500: 0.165153\n",
      "2022-11-08 20:16:43,729 INFO     Training average positive_sample_loss at step 522600: 0.178177\n",
      "2022-11-08 20:16:43,729 INFO     Training average negative_sample_loss at step 522600: 0.154056\n",
      "2022-11-08 20:16:43,729 INFO     Training average loss at step 522600: 0.166117\n",
      "2022-11-08 20:16:53,427 INFO     Training average positive_sample_loss at step 522700: 0.177336\n",
      "2022-11-08 20:16:53,427 INFO     Training average negative_sample_loss at step 522700: 0.151663\n",
      "2022-11-08 20:16:53,427 INFO     Training average loss at step 522700: 0.164500\n",
      "2022-11-08 20:17:03,126 INFO     Training average positive_sample_loss at step 522800: 0.168724\n",
      "2022-11-08 20:17:03,126 INFO     Training average negative_sample_loss at step 522800: 0.147795\n",
      "2022-11-08 20:17:03,126 INFO     Training average loss at step 522800: 0.158260\n",
      "2022-11-08 20:17:12,825 INFO     Training average positive_sample_loss at step 522900: 0.170798\n",
      "2022-11-08 20:17:12,826 INFO     Training average negative_sample_loss at step 522900: 0.151116\n",
      "2022-11-08 20:17:12,826 INFO     Training average loss at step 522900: 0.160957\n",
      "2022-11-08 20:17:22,541 INFO     Training average positive_sample_loss at step 523000: 0.177436\n",
      "2022-11-08 20:17:22,541 INFO     Training average negative_sample_loss at step 523000: 0.148886\n",
      "2022-11-08 20:17:22,541 INFO     Training average loss at step 523000: 0.163161\n",
      "2022-11-08 20:17:32,234 INFO     Training average positive_sample_loss at step 523100: 0.172696\n",
      "2022-11-08 20:17:32,235 INFO     Training average negative_sample_loss at step 523100: 0.148443\n",
      "2022-11-08 20:17:32,235 INFO     Training average loss at step 523100: 0.160570\n",
      "2022-11-08 20:17:41,930 INFO     Training average positive_sample_loss at step 523200: 0.169937\n",
      "2022-11-08 20:17:41,930 INFO     Training average negative_sample_loss at step 523200: 0.152251\n",
      "2022-11-08 20:17:41,930 INFO     Training average loss at step 523200: 0.161094\n",
      "2022-11-08 20:17:51,635 INFO     Training average positive_sample_loss at step 523300: 0.179602\n",
      "2022-11-08 20:17:51,636 INFO     Training average negative_sample_loss at step 523300: 0.151368\n",
      "2022-11-08 20:17:51,636 INFO     Training average loss at step 523300: 0.165485\n",
      "2022-11-08 20:18:01,333 INFO     Training average positive_sample_loss at step 523400: 0.172276\n",
      "2022-11-08 20:18:01,333 INFO     Training average negative_sample_loss at step 523400: 0.149205\n",
      "2022-11-08 20:18:01,333 INFO     Training average loss at step 523400: 0.160741\n",
      "2022-11-08 20:18:11,033 INFO     Training average positive_sample_loss at step 523500: 0.173184\n",
      "2022-11-08 20:18:11,033 INFO     Training average negative_sample_loss at step 523500: 0.152395\n",
      "2022-11-08 20:18:11,033 INFO     Training average loss at step 523500: 0.162790\n",
      "2022-11-08 20:18:20,726 INFO     Training average positive_sample_loss at step 523600: 0.176471\n",
      "2022-11-08 20:18:20,726 INFO     Training average negative_sample_loss at step 523600: 0.147484\n",
      "2022-11-08 20:18:20,726 INFO     Training average loss at step 523600: 0.161978\n",
      "2022-11-08 20:18:30,428 INFO     Training average positive_sample_loss at step 523700: 0.172152\n",
      "2022-11-08 20:18:30,428 INFO     Training average negative_sample_loss at step 523700: 0.145633\n",
      "2022-11-08 20:18:30,428 INFO     Training average loss at step 523700: 0.158893\n",
      "2022-11-08 20:18:40,127 INFO     Training average positive_sample_loss at step 523800: 0.177298\n",
      "2022-11-08 20:18:40,127 INFO     Training average negative_sample_loss at step 523800: 0.150564\n",
      "2022-11-08 20:18:40,127 INFO     Training average loss at step 523800: 0.163931\n",
      "2022-11-08 20:18:49,825 INFO     Training average positive_sample_loss at step 523900: 0.176236\n",
      "2022-11-08 20:18:49,825 INFO     Training average negative_sample_loss at step 523900: 0.150928\n",
      "2022-11-08 20:18:49,825 INFO     Training average loss at step 523900: 0.163582\n",
      "2022-11-08 20:18:59,524 INFO     Training average positive_sample_loss at step 524000: 0.172065\n",
      "2022-11-08 20:18:59,524 INFO     Training average negative_sample_loss at step 524000: 0.144779\n",
      "2022-11-08 20:18:59,524 INFO     Training average loss at step 524000: 0.158422\n",
      "2022-11-08 20:19:09,226 INFO     Training average positive_sample_loss at step 524100: 0.179775\n",
      "2022-11-08 20:19:09,226 INFO     Training average negative_sample_loss at step 524100: 0.153323\n",
      "2022-11-08 20:19:09,226 INFO     Training average loss at step 524100: 0.166549\n",
      "2022-11-08 20:19:18,922 INFO     Training average positive_sample_loss at step 524200: 0.178070\n",
      "2022-11-08 20:19:18,922 INFO     Training average negative_sample_loss at step 524200: 0.150305\n",
      "2022-11-08 20:19:18,922 INFO     Training average loss at step 524200: 0.164187\n",
      "2022-11-08 20:19:28,616 INFO     Training average positive_sample_loss at step 524300: 0.178268\n",
      "2022-11-08 20:19:28,616 INFO     Training average negative_sample_loss at step 524300: 0.147830\n",
      "2022-11-08 20:19:28,616 INFO     Training average loss at step 524300: 0.163049\n",
      "2022-11-08 20:19:38,316 INFO     Training average positive_sample_loss at step 524400: 0.165816\n",
      "2022-11-08 20:19:38,316 INFO     Training average negative_sample_loss at step 524400: 0.147258\n",
      "2022-11-08 20:19:38,316 INFO     Training average loss at step 524400: 0.156537\n",
      "2022-11-08 20:19:48,014 INFO     Training average positive_sample_loss at step 524500: 0.176497\n",
      "2022-11-08 20:19:48,014 INFO     Training average negative_sample_loss at step 524500: 0.152164\n",
      "2022-11-08 20:19:48,014 INFO     Training average loss at step 524500: 0.164330\n",
      "2022-11-08 20:19:57,712 INFO     Training average positive_sample_loss at step 524600: 0.173949\n",
      "2022-11-08 20:19:57,712 INFO     Training average negative_sample_loss at step 524600: 0.150424\n",
      "2022-11-08 20:19:57,712 INFO     Training average loss at step 524600: 0.162187\n",
      "2022-11-08 20:20:07,411 INFO     Training average positive_sample_loss at step 524700: 0.171230\n",
      "2022-11-08 20:20:07,411 INFO     Training average negative_sample_loss at step 524700: 0.153786\n",
      "2022-11-08 20:20:07,411 INFO     Training average loss at step 524700: 0.162508\n",
      "2022-11-08 20:20:17,103 INFO     Training average positive_sample_loss at step 524800: 0.168992\n",
      "2022-11-08 20:20:17,103 INFO     Training average negative_sample_loss at step 524800: 0.152560\n",
      "2022-11-08 20:20:17,103 INFO     Training average loss at step 524800: 0.160776\n",
      "2022-11-08 20:20:26,801 INFO     Training average positive_sample_loss at step 524900: 0.176913\n",
      "2022-11-08 20:20:26,801 INFO     Training average negative_sample_loss at step 524900: 0.151022\n",
      "2022-11-08 20:20:26,801 INFO     Training average loss at step 524900: 0.163967\n",
      "2022-11-08 20:20:36,503 INFO     Training average positive_sample_loss at step 525000: 0.173170\n",
      "2022-11-08 20:20:36,503 INFO     Training average negative_sample_loss at step 525000: 0.151027\n",
      "2022-11-08 20:20:36,503 INFO     Training average loss at step 525000: 0.162098\n",
      "2022-11-08 20:20:46,200 INFO     Training average positive_sample_loss at step 525100: 0.184120\n",
      "2022-11-08 20:20:46,200 INFO     Training average negative_sample_loss at step 525100: 0.148669\n",
      "2022-11-08 20:20:46,200 INFO     Training average loss at step 525100: 0.166394\n",
      "2022-11-08 20:20:55,897 INFO     Training average positive_sample_loss at step 525200: 0.170899\n",
      "2022-11-08 20:20:55,897 INFO     Training average negative_sample_loss at step 525200: 0.146542\n",
      "2022-11-08 20:20:55,897 INFO     Training average loss at step 525200: 0.158721\n",
      "2022-11-08 20:21:05,598 INFO     Training average positive_sample_loss at step 525300: 0.174164\n",
      "2022-11-08 20:21:05,598 INFO     Training average negative_sample_loss at step 525300: 0.150981\n",
      "2022-11-08 20:21:05,598 INFO     Training average loss at step 525300: 0.162572\n",
      "2022-11-08 20:21:15,297 INFO     Training average positive_sample_loss at step 525400: 0.173331\n",
      "2022-11-08 20:21:15,297 INFO     Training average negative_sample_loss at step 525400: 0.145957\n",
      "2022-11-08 20:21:15,297 INFO     Training average loss at step 525400: 0.159644\n",
      "2022-11-08 20:21:25,000 INFO     Training average positive_sample_loss at step 525500: 0.166367\n",
      "2022-11-08 20:21:25,000 INFO     Training average negative_sample_loss at step 525500: 0.150049\n",
      "2022-11-08 20:21:25,000 INFO     Training average loss at step 525500: 0.158208\n",
      "2022-11-08 20:21:34,699 INFO     Training average positive_sample_loss at step 525600: 0.177583\n",
      "2022-11-08 20:21:34,699 INFO     Training average negative_sample_loss at step 525600: 0.154123\n",
      "2022-11-08 20:21:34,699 INFO     Training average loss at step 525600: 0.165853\n",
      "2022-11-08 20:21:44,397 INFO     Training average positive_sample_loss at step 525700: 0.176784\n",
      "2022-11-08 20:21:44,397 INFO     Training average negative_sample_loss at step 525700: 0.150332\n",
      "2022-11-08 20:21:44,397 INFO     Training average loss at step 525700: 0.163558\n",
      "2022-11-08 20:21:54,093 INFO     Training average positive_sample_loss at step 525800: 0.170666\n",
      "2022-11-08 20:21:54,093 INFO     Training average negative_sample_loss at step 525800: 0.151188\n",
      "2022-11-08 20:21:54,093 INFO     Training average loss at step 525800: 0.160927\n",
      "2022-11-08 20:22:03,789 INFO     Training average positive_sample_loss at step 525900: 0.177540\n",
      "2022-11-08 20:22:03,789 INFO     Training average negative_sample_loss at step 525900: 0.149343\n",
      "2022-11-08 20:22:03,789 INFO     Training average loss at step 525900: 0.163442\n",
      "2022-11-08 20:22:13,491 INFO     Training average positive_sample_loss at step 526000: 0.179245\n",
      "2022-11-08 20:22:13,491 INFO     Training average negative_sample_loss at step 526000: 0.150607\n",
      "2022-11-08 20:22:13,491 INFO     Training average loss at step 526000: 0.164926\n",
      "2022-11-08 20:22:23,192 INFO     Training average positive_sample_loss at step 526100: 0.177964\n",
      "2022-11-08 20:22:23,192 INFO     Training average negative_sample_loss at step 526100: 0.149329\n",
      "2022-11-08 20:22:23,192 INFO     Training average loss at step 526100: 0.163647\n",
      "2022-11-08 20:22:32,891 INFO     Training average positive_sample_loss at step 526200: 0.170327\n",
      "2022-11-08 20:22:32,891 INFO     Training average negative_sample_loss at step 526200: 0.150836\n",
      "2022-11-08 20:22:32,891 INFO     Training average loss at step 526200: 0.160581\n",
      "2022-11-08 20:22:42,589 INFO     Training average positive_sample_loss at step 526300: 0.170011\n",
      "2022-11-08 20:22:42,589 INFO     Training average negative_sample_loss at step 526300: 0.148380\n",
      "2022-11-08 20:22:42,589 INFO     Training average loss at step 526300: 0.159195\n",
      "2022-11-08 20:22:52,284 INFO     Training average positive_sample_loss at step 526400: 0.171331\n",
      "2022-11-08 20:22:52,284 INFO     Training average negative_sample_loss at step 526400: 0.149294\n",
      "2022-11-08 20:22:52,284 INFO     Training average loss at step 526400: 0.160313\n",
      "2022-11-08 20:23:01,291 INFO     Training average positive_sample_loss at step 526500: 0.173678\n",
      "2022-11-08 20:23:01,291 INFO     Training average negative_sample_loss at step 526500: 0.153557\n",
      "2022-11-08 20:23:01,291 INFO     Training average loss at step 526500: 0.163617\n",
      "2022-11-08 20:23:10,990 INFO     Training average positive_sample_loss at step 526600: 0.178422\n",
      "2022-11-08 20:23:10,991 INFO     Training average negative_sample_loss at step 526600: 0.150980\n",
      "2022-11-08 20:23:10,991 INFO     Training average loss at step 526600: 0.164701\n",
      "2022-11-08 20:23:20,686 INFO     Training average positive_sample_loss at step 526700: 0.186470\n",
      "2022-11-08 20:23:20,686 INFO     Training average negative_sample_loss at step 526700: 0.152391\n",
      "2022-11-08 20:23:20,686 INFO     Training average loss at step 526700: 0.169431\n",
      "2022-11-08 20:23:30,811 INFO     Training average positive_sample_loss at step 526800: 0.170709\n",
      "2022-11-08 20:23:30,811 INFO     Training average negative_sample_loss at step 526800: 0.147019\n",
      "2022-11-08 20:23:30,812 INFO     Training average loss at step 526800: 0.158864\n",
      "2022-11-08 20:23:41,384 INFO     Training average positive_sample_loss at step 526900: 0.174904\n",
      "2022-11-08 20:23:41,385 INFO     Training average negative_sample_loss at step 526900: 0.148956\n",
      "2022-11-08 20:23:41,385 INFO     Training average loss at step 526900: 0.161930\n",
      "2022-11-08 20:23:51,597 INFO     Training average positive_sample_loss at step 527000: 0.169201\n",
      "2022-11-08 20:23:51,598 INFO     Training average negative_sample_loss at step 527000: 0.153788\n",
      "2022-11-08 20:23:51,598 INFO     Training average loss at step 527000: 0.161494\n",
      "2022-11-08 20:24:00,596 INFO     Training average positive_sample_loss at step 527100: 0.165101\n",
      "2022-11-08 20:24:00,596 INFO     Training average negative_sample_loss at step 527100: 0.151028\n",
      "2022-11-08 20:24:00,597 INFO     Training average loss at step 527100: 0.158065\n",
      "2022-11-08 20:24:10,292 INFO     Training average positive_sample_loss at step 527200: 0.171866\n",
      "2022-11-08 20:24:10,292 INFO     Training average negative_sample_loss at step 527200: 0.150943\n",
      "2022-11-08 20:24:10,293 INFO     Training average loss at step 527200: 0.161404\n",
      "2022-11-08 20:24:19,990 INFO     Training average positive_sample_loss at step 527300: 0.175574\n",
      "2022-11-08 20:24:19,990 INFO     Training average negative_sample_loss at step 527300: 0.145149\n",
      "2022-11-08 20:24:19,990 INFO     Training average loss at step 527300: 0.160362\n",
      "2022-11-08 20:24:29,690 INFO     Training average positive_sample_loss at step 527400: 0.171575\n",
      "2022-11-08 20:24:29,691 INFO     Training average negative_sample_loss at step 527400: 0.151300\n",
      "2022-11-08 20:24:29,691 INFO     Training average loss at step 527400: 0.161437\n",
      "2022-11-08 20:24:39,387 INFO     Training average positive_sample_loss at step 527500: 0.174198\n",
      "2022-11-08 20:24:39,388 INFO     Training average negative_sample_loss at step 527500: 0.146325\n",
      "2022-11-08 20:24:39,388 INFO     Training average loss at step 527500: 0.160261\n",
      "2022-11-08 20:24:49,084 INFO     Training average positive_sample_loss at step 527600: 0.171893\n",
      "2022-11-08 20:24:49,084 INFO     Training average negative_sample_loss at step 527600: 0.148088\n",
      "2022-11-08 20:24:49,084 INFO     Training average loss at step 527600: 0.159991\n",
      "2022-11-08 20:24:58,781 INFO     Training average positive_sample_loss at step 527700: 0.165330\n",
      "2022-11-08 20:24:58,781 INFO     Training average negative_sample_loss at step 527700: 0.143135\n",
      "2022-11-08 20:24:58,781 INFO     Training average loss at step 527700: 0.154232\n",
      "2022-11-08 20:25:08,481 INFO     Training average positive_sample_loss at step 527800: 0.177522\n",
      "2022-11-08 20:25:08,481 INFO     Training average negative_sample_loss at step 527800: 0.148680\n",
      "2022-11-08 20:25:08,481 INFO     Training average loss at step 527800: 0.163101\n",
      "2022-11-08 20:25:18,178 INFO     Training average positive_sample_loss at step 527900: 0.181416\n",
      "2022-11-08 20:25:18,178 INFO     Training average negative_sample_loss at step 527900: 0.151455\n",
      "2022-11-08 20:25:18,178 INFO     Training average loss at step 527900: 0.166435\n",
      "2022-11-08 20:25:27,880 INFO     Training average positive_sample_loss at step 528000: 0.177239\n",
      "2022-11-08 20:25:27,880 INFO     Training average negative_sample_loss at step 528000: 0.151156\n",
      "2022-11-08 20:25:27,880 INFO     Training average loss at step 528000: 0.164198\n",
      "2022-11-08 20:25:37,579 INFO     Training average positive_sample_loss at step 528100: 0.178464\n",
      "2022-11-08 20:25:37,579 INFO     Training average negative_sample_loss at step 528100: 0.150177\n",
      "2022-11-08 20:25:37,579 INFO     Training average loss at step 528100: 0.164321\n",
      "2022-11-08 20:25:47,273 INFO     Training average positive_sample_loss at step 528200: 0.175527\n",
      "2022-11-08 20:25:47,273 INFO     Training average negative_sample_loss at step 528200: 0.149748\n",
      "2022-11-08 20:25:47,273 INFO     Training average loss at step 528200: 0.162638\n",
      "2022-11-08 20:25:56,970 INFO     Training average positive_sample_loss at step 528300: 0.176940\n",
      "2022-11-08 20:25:56,970 INFO     Training average negative_sample_loss at step 528300: 0.158181\n",
      "2022-11-08 20:25:56,970 INFO     Training average loss at step 528300: 0.167560\n",
      "2022-11-08 20:26:06,669 INFO     Training average positive_sample_loss at step 528400: 0.182173\n",
      "2022-11-08 20:26:06,669 INFO     Training average negative_sample_loss at step 528400: 0.154752\n",
      "2022-11-08 20:26:06,669 INFO     Training average loss at step 528400: 0.168462\n",
      "2022-11-08 20:26:16,365 INFO     Training average positive_sample_loss at step 528500: 0.173367\n",
      "2022-11-08 20:26:16,365 INFO     Training average negative_sample_loss at step 528500: 0.148688\n",
      "2022-11-08 20:26:16,365 INFO     Training average loss at step 528500: 0.161028\n",
      "2022-11-08 20:26:26,065 INFO     Training average positive_sample_loss at step 528600: 0.171915\n",
      "2022-11-08 20:26:26,065 INFO     Training average negative_sample_loss at step 528600: 0.149878\n",
      "2022-11-08 20:26:26,066 INFO     Training average loss at step 528600: 0.160897\n",
      "2022-11-08 20:26:35,762 INFO     Training average positive_sample_loss at step 528700: 0.171730\n",
      "2022-11-08 20:26:35,762 INFO     Training average negative_sample_loss at step 528700: 0.150845\n",
      "2022-11-08 20:26:35,762 INFO     Training average loss at step 528700: 0.161288\n",
      "2022-11-08 20:26:45,455 INFO     Training average positive_sample_loss at step 528800: 0.172259\n",
      "2022-11-08 20:26:45,455 INFO     Training average negative_sample_loss at step 528800: 0.150034\n",
      "2022-11-08 20:26:45,455 INFO     Training average loss at step 528800: 0.161146\n",
      "2022-11-08 20:26:55,155 INFO     Training average positive_sample_loss at step 528900: 0.172506\n",
      "2022-11-08 20:26:55,155 INFO     Training average negative_sample_loss at step 528900: 0.144603\n",
      "2022-11-08 20:26:55,155 INFO     Training average loss at step 528900: 0.158554\n",
      "2022-11-08 20:27:04,856 INFO     Training average positive_sample_loss at step 529000: 0.170350\n",
      "2022-11-08 20:27:04,856 INFO     Training average negative_sample_loss at step 529000: 0.151000\n",
      "2022-11-08 20:27:04,856 INFO     Training average loss at step 529000: 0.160675\n",
      "2022-11-08 20:27:14,554 INFO     Training average positive_sample_loss at step 529100: 0.171078\n",
      "2022-11-08 20:27:14,555 INFO     Training average negative_sample_loss at step 529100: 0.153717\n",
      "2022-11-08 20:27:14,555 INFO     Training average loss at step 529100: 0.162398\n",
      "2022-11-08 20:27:24,255 INFO     Training average positive_sample_loss at step 529200: 0.171515\n",
      "2022-11-08 20:27:24,255 INFO     Training average negative_sample_loss at step 529200: 0.146704\n",
      "2022-11-08 20:27:24,255 INFO     Training average loss at step 529200: 0.159109\n",
      "2022-11-08 20:27:33,950 INFO     Training average positive_sample_loss at step 529300: 0.177984\n",
      "2022-11-08 20:27:33,950 INFO     Training average negative_sample_loss at step 529300: 0.148857\n",
      "2022-11-08 20:27:33,950 INFO     Training average loss at step 529300: 0.163420\n",
      "2022-11-08 20:27:43,646 INFO     Training average positive_sample_loss at step 529400: 0.173090\n",
      "2022-11-08 20:27:43,646 INFO     Training average negative_sample_loss at step 529400: 0.151614\n",
      "2022-11-08 20:27:43,646 INFO     Training average loss at step 529400: 0.162352\n",
      "2022-11-08 20:27:53,347 INFO     Training average positive_sample_loss at step 529500: 0.173692\n",
      "2022-11-08 20:27:53,347 INFO     Training average negative_sample_loss at step 529500: 0.148631\n",
      "2022-11-08 20:27:53,347 INFO     Training average loss at step 529500: 0.161161\n",
      "2022-11-08 20:28:03,042 INFO     Training average positive_sample_loss at step 529600: 0.174158\n",
      "2022-11-08 20:28:03,042 INFO     Training average negative_sample_loss at step 529600: 0.150730\n",
      "2022-11-08 20:28:03,042 INFO     Training average loss at step 529600: 0.162444\n",
      "2022-11-08 20:28:12,741 INFO     Training average positive_sample_loss at step 529700: 0.172499\n",
      "2022-11-08 20:28:12,741 INFO     Training average negative_sample_loss at step 529700: 0.151931\n",
      "2022-11-08 20:28:12,741 INFO     Training average loss at step 529700: 0.162215\n",
      "2022-11-08 20:28:22,442 INFO     Training average positive_sample_loss at step 529800: 0.177259\n",
      "2022-11-08 20:28:22,442 INFO     Training average negative_sample_loss at step 529800: 0.147464\n",
      "2022-11-08 20:28:22,442 INFO     Training average loss at step 529800: 0.162361\n",
      "2022-11-08 20:28:32,142 INFO     Training average positive_sample_loss at step 529900: 0.168889\n",
      "2022-11-08 20:28:32,142 INFO     Training average negative_sample_loss at step 529900: 0.150841\n",
      "2022-11-08 20:28:32,142 INFO     Training average loss at step 529900: 0.159865\n",
      "2022-11-08 20:28:44,690 INFO     Training average positive_sample_loss at step 530000: 0.170745\n",
      "2022-11-08 20:28:44,690 INFO     Training average negative_sample_loss at step 530000: 0.152873\n",
      "2022-11-08 20:28:44,690 INFO     Training average loss at step 530000: 0.161809\n",
      "2022-11-08 20:28:54,387 INFO     Training average positive_sample_loss at step 530100: 0.173915\n",
      "2022-11-08 20:28:54,387 INFO     Training average negative_sample_loss at step 530100: 0.149496\n",
      "2022-11-08 20:28:54,387 INFO     Training average loss at step 530100: 0.161705\n",
      "2022-11-08 20:29:04,080 INFO     Training average positive_sample_loss at step 530200: 0.175658\n",
      "2022-11-08 20:29:04,080 INFO     Training average negative_sample_loss at step 530200: 0.152873\n",
      "2022-11-08 20:29:04,080 INFO     Training average loss at step 530200: 0.164266\n",
      "2022-11-08 20:29:13,778 INFO     Training average positive_sample_loss at step 530300: 0.169165\n",
      "2022-11-08 20:29:13,778 INFO     Training average negative_sample_loss at step 530300: 0.147667\n",
      "2022-11-08 20:29:13,778 INFO     Training average loss at step 530300: 0.158416\n",
      "2022-11-08 20:29:23,476 INFO     Training average positive_sample_loss at step 530400: 0.173545\n",
      "2022-11-08 20:29:23,476 INFO     Training average negative_sample_loss at step 530400: 0.149558\n",
      "2022-11-08 20:29:23,476 INFO     Training average loss at step 530400: 0.161552\n",
      "2022-11-08 20:29:33,172 INFO     Training average positive_sample_loss at step 530500: 0.174611\n",
      "2022-11-08 20:29:33,172 INFO     Training average negative_sample_loss at step 530500: 0.146061\n",
      "2022-11-08 20:29:33,172 INFO     Training average loss at step 530500: 0.160336\n",
      "2022-11-08 20:29:42,872 INFO     Training average positive_sample_loss at step 530600: 0.170638\n",
      "2022-11-08 20:29:42,872 INFO     Training average negative_sample_loss at step 530600: 0.147813\n",
      "2022-11-08 20:29:42,872 INFO     Training average loss at step 530600: 0.159226\n",
      "2022-11-08 20:29:52,569 INFO     Training average positive_sample_loss at step 530700: 0.180089\n",
      "2022-11-08 20:29:52,569 INFO     Training average negative_sample_loss at step 530700: 0.144620\n",
      "2022-11-08 20:29:52,569 INFO     Training average loss at step 530700: 0.162354\n",
      "2022-11-08 20:30:02,263 INFO     Training average positive_sample_loss at step 530800: 0.179674\n",
      "2022-11-08 20:30:02,263 INFO     Training average negative_sample_loss at step 530800: 0.152255\n",
      "2022-11-08 20:30:02,263 INFO     Training average loss at step 530800: 0.165965\n",
      "2022-11-08 20:30:11,964 INFO     Training average positive_sample_loss at step 530900: 0.169471\n",
      "2022-11-08 20:30:11,964 INFO     Training average negative_sample_loss at step 530900: 0.146742\n",
      "2022-11-08 20:30:11,964 INFO     Training average loss at step 530900: 0.158106\n",
      "2022-11-08 20:30:21,663 INFO     Training average positive_sample_loss at step 531000: 0.171399\n",
      "2022-11-08 20:30:21,663 INFO     Training average negative_sample_loss at step 531000: 0.155381\n",
      "2022-11-08 20:30:21,663 INFO     Training average loss at step 531000: 0.163390\n",
      "2022-11-08 20:30:31,360 INFO     Training average positive_sample_loss at step 531100: 0.172066\n",
      "2022-11-08 20:30:31,360 INFO     Training average negative_sample_loss at step 531100: 0.147713\n",
      "2022-11-08 20:30:31,360 INFO     Training average loss at step 531100: 0.159890\n",
      "2022-11-08 20:30:41,060 INFO     Training average positive_sample_loss at step 531200: 0.170483\n",
      "2022-11-08 20:30:41,060 INFO     Training average negative_sample_loss at step 531200: 0.150127\n",
      "2022-11-08 20:30:41,060 INFO     Training average loss at step 531200: 0.160305\n",
      "2022-11-08 20:30:50,754 INFO     Training average positive_sample_loss at step 531300: 0.173624\n",
      "2022-11-08 20:30:50,754 INFO     Training average negative_sample_loss at step 531300: 0.147149\n",
      "2022-11-08 20:30:50,754 INFO     Training average loss at step 531300: 0.160387\n",
      "2022-11-08 20:31:00,453 INFO     Training average positive_sample_loss at step 531400: 0.169687\n",
      "2022-11-08 20:31:00,453 INFO     Training average negative_sample_loss at step 531400: 0.147385\n",
      "2022-11-08 20:31:00,453 INFO     Training average loss at step 531400: 0.158536\n",
      "2022-11-08 20:31:10,653 INFO     Training average positive_sample_loss at step 531500: 0.182797\n",
      "2022-11-08 20:31:10,653 INFO     Training average negative_sample_loss at step 531500: 0.153628\n",
      "2022-11-08 20:31:10,653 INFO     Training average loss at step 531500: 0.168213\n",
      "2022-11-08 20:31:21,238 INFO     Training average positive_sample_loss at step 531600: 0.164038\n",
      "2022-11-08 20:31:21,239 INFO     Training average negative_sample_loss at step 531600: 0.153576\n",
      "2022-11-08 20:31:21,239 INFO     Training average loss at step 531600: 0.158807\n",
      "2022-11-08 20:31:31,560 INFO     Training average positive_sample_loss at step 531700: 0.178721\n",
      "2022-11-08 20:31:31,560 INFO     Training average negative_sample_loss at step 531700: 0.150898\n",
      "2022-11-08 20:31:31,560 INFO     Training average loss at step 531700: 0.164809\n",
      "2022-11-08 20:31:41,261 INFO     Training average positive_sample_loss at step 531800: 0.177828\n",
      "2022-11-08 20:31:41,261 INFO     Training average negative_sample_loss at step 531800: 0.148887\n",
      "2022-11-08 20:31:41,261 INFO     Training average loss at step 531800: 0.163357\n",
      "2022-11-08 20:31:50,706 INFO     Training average positive_sample_loss at step 531900: 0.174325\n",
      "2022-11-08 20:31:50,706 INFO     Training average negative_sample_loss at step 531900: 0.149572\n",
      "2022-11-08 20:31:50,706 INFO     Training average loss at step 531900: 0.161948\n",
      "2022-11-08 20:31:59,972 INFO     Training average positive_sample_loss at step 532000: 0.177150\n",
      "2022-11-08 20:31:59,972 INFO     Training average negative_sample_loss at step 532000: 0.148832\n",
      "2022-11-08 20:31:59,972 INFO     Training average loss at step 532000: 0.162991\n",
      "2022-11-08 20:32:09,673 INFO     Training average positive_sample_loss at step 532100: 0.178571\n",
      "2022-11-08 20:32:09,673 INFO     Training average negative_sample_loss at step 532100: 0.155473\n",
      "2022-11-08 20:32:09,673 INFO     Training average loss at step 532100: 0.167022\n",
      "2022-11-08 20:32:19,371 INFO     Training average positive_sample_loss at step 532200: 0.173944\n",
      "2022-11-08 20:32:19,371 INFO     Training average negative_sample_loss at step 532200: 0.149263\n",
      "2022-11-08 20:32:19,371 INFO     Training average loss at step 532200: 0.161604\n",
      "2022-11-08 20:32:29,068 INFO     Training average positive_sample_loss at step 532300: 0.173441\n",
      "2022-11-08 20:32:29,069 INFO     Training average negative_sample_loss at step 532300: 0.152979\n",
      "2022-11-08 20:32:29,069 INFO     Training average loss at step 532300: 0.163210\n",
      "2022-11-08 20:32:38,764 INFO     Training average positive_sample_loss at step 532400: 0.171088\n",
      "2022-11-08 20:32:38,764 INFO     Training average negative_sample_loss at step 532400: 0.149659\n",
      "2022-11-08 20:32:38,764 INFO     Training average loss at step 532400: 0.160374\n",
      "2022-11-08 20:32:48,011 INFO     Training average positive_sample_loss at step 532500: 0.173663\n",
      "2022-11-08 20:32:48,011 INFO     Training average negative_sample_loss at step 532500: 0.147532\n",
      "2022-11-08 20:32:48,011 INFO     Training average loss at step 532500: 0.160597\n",
      "2022-11-08 20:32:57,435 INFO     Training average positive_sample_loss at step 532600: 0.169146\n",
      "2022-11-08 20:32:57,435 INFO     Training average negative_sample_loss at step 532600: 0.145739\n",
      "2022-11-08 20:32:57,435 INFO     Training average loss at step 532600: 0.157442\n",
      "2022-11-08 20:33:07,135 INFO     Training average positive_sample_loss at step 532700: 0.173022\n",
      "2022-11-08 20:33:07,136 INFO     Training average negative_sample_loss at step 532700: 0.151219\n",
      "2022-11-08 20:33:07,136 INFO     Training average loss at step 532700: 0.162120\n",
      "2022-11-08 20:33:16,836 INFO     Training average positive_sample_loss at step 532800: 0.176680\n",
      "2022-11-08 20:33:16,836 INFO     Training average negative_sample_loss at step 532800: 0.153487\n",
      "2022-11-08 20:33:16,836 INFO     Training average loss at step 532800: 0.165083\n",
      "2022-11-08 20:33:26,534 INFO     Training average positive_sample_loss at step 532900: 0.165222\n",
      "2022-11-08 20:33:26,534 INFO     Training average negative_sample_loss at step 532900: 0.153030\n",
      "2022-11-08 20:33:26,534 INFO     Training average loss at step 532900: 0.159126\n",
      "2022-11-08 20:33:36,233 INFO     Training average positive_sample_loss at step 533000: 0.174310\n",
      "2022-11-08 20:33:36,233 INFO     Training average negative_sample_loss at step 533000: 0.152718\n",
      "2022-11-08 20:33:36,233 INFO     Training average loss at step 533000: 0.163514\n",
      "2022-11-08 20:33:45,929 INFO     Training average positive_sample_loss at step 533100: 0.174227\n",
      "2022-11-08 20:33:45,929 INFO     Training average negative_sample_loss at step 533100: 0.149960\n",
      "2022-11-08 20:33:45,929 INFO     Training average loss at step 533100: 0.162093\n",
      "2022-11-08 20:33:55,630 INFO     Training average positive_sample_loss at step 533200: 0.178153\n",
      "2022-11-08 20:33:55,630 INFO     Training average negative_sample_loss at step 533200: 0.149130\n",
      "2022-11-08 20:33:55,630 INFO     Training average loss at step 533200: 0.163642\n",
      "2022-11-08 20:34:05,333 INFO     Training average positive_sample_loss at step 533300: 0.171043\n",
      "2022-11-08 20:34:05,333 INFO     Training average negative_sample_loss at step 533300: 0.146563\n",
      "2022-11-08 20:34:05,333 INFO     Training average loss at step 533300: 0.158803\n",
      "2022-11-08 20:34:15,027 INFO     Training average positive_sample_loss at step 533400: 0.174334\n",
      "2022-11-08 20:34:15,027 INFO     Training average negative_sample_loss at step 533400: 0.153482\n",
      "2022-11-08 20:34:15,027 INFO     Training average loss at step 533400: 0.163908\n",
      "2022-11-08 20:34:24,719 INFO     Training average positive_sample_loss at step 533500: 0.170980\n",
      "2022-11-08 20:34:24,719 INFO     Training average negative_sample_loss at step 533500: 0.146443\n",
      "2022-11-08 20:34:24,719 INFO     Training average loss at step 533500: 0.158712\n",
      "2022-11-08 20:34:34,410 INFO     Training average positive_sample_loss at step 533600: 0.169827\n",
      "2022-11-08 20:34:34,410 INFO     Training average negative_sample_loss at step 533600: 0.148647\n",
      "2022-11-08 20:34:34,410 INFO     Training average loss at step 533600: 0.159237\n",
      "2022-11-08 20:34:44,104 INFO     Training average positive_sample_loss at step 533700: 0.173397\n",
      "2022-11-08 20:34:44,104 INFO     Training average negative_sample_loss at step 533700: 0.149338\n",
      "2022-11-08 20:34:44,104 INFO     Training average loss at step 533700: 0.161368\n",
      "2022-11-08 20:34:53,797 INFO     Training average positive_sample_loss at step 533800: 0.170008\n",
      "2022-11-08 20:34:53,797 INFO     Training average negative_sample_loss at step 533800: 0.151939\n",
      "2022-11-08 20:34:53,797 INFO     Training average loss at step 533800: 0.160974\n",
      "2022-11-08 20:35:03,495 INFO     Training average positive_sample_loss at step 533900: 0.174389\n",
      "2022-11-08 20:35:03,496 INFO     Training average negative_sample_loss at step 533900: 0.148201\n",
      "2022-11-08 20:35:03,496 INFO     Training average loss at step 533900: 0.161295\n",
      "2022-11-08 20:35:13,188 INFO     Training average positive_sample_loss at step 534000: 0.176173\n",
      "2022-11-08 20:35:13,188 INFO     Training average negative_sample_loss at step 534000: 0.152791\n",
      "2022-11-08 20:35:13,188 INFO     Training average loss at step 534000: 0.164482\n",
      "2022-11-08 20:35:22,879 INFO     Training average positive_sample_loss at step 534100: 0.173528\n",
      "2022-11-08 20:35:22,879 INFO     Training average negative_sample_loss at step 534100: 0.152979\n",
      "2022-11-08 20:35:22,879 INFO     Training average loss at step 534100: 0.163254\n",
      "2022-11-08 20:35:32,575 INFO     Training average positive_sample_loss at step 534200: 0.175720\n",
      "2022-11-08 20:35:32,575 INFO     Training average negative_sample_loss at step 534200: 0.149112\n",
      "2022-11-08 20:35:32,575 INFO     Training average loss at step 534200: 0.162416\n",
      "2022-11-08 20:35:42,270 INFO     Training average positive_sample_loss at step 534300: 0.178119\n",
      "2022-11-08 20:35:42,270 INFO     Training average negative_sample_loss at step 534300: 0.150788\n",
      "2022-11-08 20:35:42,270 INFO     Training average loss at step 534300: 0.164454\n",
      "2022-11-08 20:35:51,963 INFO     Training average positive_sample_loss at step 534400: 0.173132\n",
      "2022-11-08 20:35:51,963 INFO     Training average negative_sample_loss at step 534400: 0.148760\n",
      "2022-11-08 20:35:51,963 INFO     Training average loss at step 534400: 0.160946\n",
      "2022-11-08 20:36:01,660 INFO     Training average positive_sample_loss at step 534500: 0.163591\n",
      "2022-11-08 20:36:01,660 INFO     Training average negative_sample_loss at step 534500: 0.149697\n",
      "2022-11-08 20:36:01,660 INFO     Training average loss at step 534500: 0.156644\n",
      "2022-11-08 20:36:11,350 INFO     Training average positive_sample_loss at step 534600: 0.171617\n",
      "2022-11-08 20:36:11,350 INFO     Training average negative_sample_loss at step 534600: 0.147685\n",
      "2022-11-08 20:36:11,350 INFO     Training average loss at step 534600: 0.159651\n",
      "2022-11-08 20:36:21,040 INFO     Training average positive_sample_loss at step 534700: 0.169543\n",
      "2022-11-08 20:36:21,040 INFO     Training average negative_sample_loss at step 534700: 0.149450\n",
      "2022-11-08 20:36:21,040 INFO     Training average loss at step 534700: 0.159496\n",
      "2022-11-08 20:36:30,739 INFO     Training average positive_sample_loss at step 534800: 0.167600\n",
      "2022-11-08 20:36:30,739 INFO     Training average negative_sample_loss at step 534800: 0.146373\n",
      "2022-11-08 20:36:30,739 INFO     Training average loss at step 534800: 0.156987\n",
      "2022-11-08 20:36:40,434 INFO     Training average positive_sample_loss at step 534900: 0.174264\n",
      "2022-11-08 20:36:40,434 INFO     Training average negative_sample_loss at step 534900: 0.152769\n",
      "2022-11-08 20:36:40,434 INFO     Training average loss at step 534900: 0.163516\n",
      "2022-11-08 20:36:50,131 INFO     Training average positive_sample_loss at step 535000: 0.181503\n",
      "2022-11-08 20:36:50,132 INFO     Training average negative_sample_loss at step 535000: 0.149420\n",
      "2022-11-08 20:36:50,132 INFO     Training average loss at step 535000: 0.165462\n",
      "2022-11-08 20:36:59,823 INFO     Training average positive_sample_loss at step 535100: 0.172275\n",
      "2022-11-08 20:36:59,823 INFO     Training average negative_sample_loss at step 535100: 0.150806\n",
      "2022-11-08 20:36:59,823 INFO     Training average loss at step 535100: 0.161540\n",
      "2022-11-08 20:37:09,517 INFO     Training average positive_sample_loss at step 535200: 0.170694\n",
      "2022-11-08 20:37:09,517 INFO     Training average negative_sample_loss at step 535200: 0.147690\n",
      "2022-11-08 20:37:09,517 INFO     Training average loss at step 535200: 0.159192\n",
      "2022-11-08 20:37:19,208 INFO     Training average positive_sample_loss at step 535300: 0.171862\n",
      "2022-11-08 20:37:19,208 INFO     Training average negative_sample_loss at step 535300: 0.147802\n",
      "2022-11-08 20:37:19,208 INFO     Training average loss at step 535300: 0.159832\n",
      "2022-11-08 20:37:28,901 INFO     Training average positive_sample_loss at step 535400: 0.172150\n",
      "2022-11-08 20:37:28,901 INFO     Training average negative_sample_loss at step 535400: 0.151386\n",
      "2022-11-08 20:37:28,901 INFO     Training average loss at step 535400: 0.161768\n",
      "2022-11-08 20:37:38,594 INFO     Training average positive_sample_loss at step 535500: 0.165287\n",
      "2022-11-08 20:37:38,594 INFO     Training average negative_sample_loss at step 535500: 0.149235\n",
      "2022-11-08 20:37:38,595 INFO     Training average loss at step 535500: 0.157261\n",
      "2022-11-08 20:37:48,286 INFO     Training average positive_sample_loss at step 535600: 0.171297\n",
      "2022-11-08 20:37:48,286 INFO     Training average negative_sample_loss at step 535600: 0.149614\n",
      "2022-11-08 20:37:48,286 INFO     Training average loss at step 535600: 0.160455\n",
      "2022-11-08 20:37:57,976 INFO     Training average positive_sample_loss at step 535700: 0.174960\n",
      "2022-11-08 20:37:57,976 INFO     Training average negative_sample_loss at step 535700: 0.150580\n",
      "2022-11-08 20:37:57,976 INFO     Training average loss at step 535700: 0.162770\n",
      "2022-11-08 20:38:07,668 INFO     Training average positive_sample_loss at step 535800: 0.171770\n",
      "2022-11-08 20:38:07,668 INFO     Training average negative_sample_loss at step 535800: 0.148796\n",
      "2022-11-08 20:38:07,668 INFO     Training average loss at step 535800: 0.160283\n",
      "2022-11-08 20:38:17,361 INFO     Training average positive_sample_loss at step 535900: 0.172112\n",
      "2022-11-08 20:38:17,361 INFO     Training average negative_sample_loss at step 535900: 0.148708\n",
      "2022-11-08 20:38:17,361 INFO     Training average loss at step 535900: 0.160410\n",
      "2022-11-08 20:38:27,053 INFO     Training average positive_sample_loss at step 536000: 0.173343\n",
      "2022-11-08 20:38:27,053 INFO     Training average negative_sample_loss at step 536000: 0.147809\n",
      "2022-11-08 20:38:27,053 INFO     Training average loss at step 536000: 0.160576\n",
      "2022-11-08 20:38:36,751 INFO     Training average positive_sample_loss at step 536100: 0.177267\n",
      "2022-11-08 20:38:36,751 INFO     Training average negative_sample_loss at step 536100: 0.149151\n",
      "2022-11-08 20:38:36,751 INFO     Training average loss at step 536100: 0.163209\n",
      "2022-11-08 20:38:46,867 INFO     Training average positive_sample_loss at step 536200: 0.173259\n",
      "2022-11-08 20:38:46,867 INFO     Training average negative_sample_loss at step 536200: 0.149700\n",
      "2022-11-08 20:38:46,867 INFO     Training average loss at step 536200: 0.161480\n",
      "2022-11-08 20:38:57,604 INFO     Training average positive_sample_loss at step 536300: 0.169622\n",
      "2022-11-08 20:38:57,604 INFO     Training average negative_sample_loss at step 536300: 0.149714\n",
      "2022-11-08 20:38:57,604 INFO     Training average loss at step 536300: 0.159668\n",
      "2022-11-08 20:39:07,881 INFO     Training average positive_sample_loss at step 536400: 0.175360\n",
      "2022-11-08 20:39:07,881 INFO     Training average negative_sample_loss at step 536400: 0.151275\n",
      "2022-11-08 20:39:07,881 INFO     Training average loss at step 536400: 0.163317\n",
      "2022-11-08 20:39:17,569 INFO     Training average positive_sample_loss at step 536500: 0.169013\n",
      "2022-11-08 20:39:17,569 INFO     Training average negative_sample_loss at step 536500: 0.152079\n",
      "2022-11-08 20:39:17,570 INFO     Training average loss at step 536500: 0.160546\n",
      "2022-11-08 20:39:27,265 INFO     Training average positive_sample_loss at step 536600: 0.174001\n",
      "2022-11-08 20:39:27,265 INFO     Training average negative_sample_loss at step 536600: 0.149786\n",
      "2022-11-08 20:39:27,265 INFO     Training average loss at step 536600: 0.161893\n",
      "2022-11-08 20:39:36,956 INFO     Training average positive_sample_loss at step 536700: 0.175242\n",
      "2022-11-08 20:39:36,957 INFO     Training average negative_sample_loss at step 536700: 0.147230\n",
      "2022-11-08 20:39:36,957 INFO     Training average loss at step 536700: 0.161236\n",
      "2022-11-08 20:39:46,648 INFO     Training average positive_sample_loss at step 536800: 0.172627\n",
      "2022-11-08 20:39:46,648 INFO     Training average negative_sample_loss at step 536800: 0.148473\n",
      "2022-11-08 20:39:46,648 INFO     Training average loss at step 536800: 0.160550\n",
      "2022-11-08 20:39:56,344 INFO     Training average positive_sample_loss at step 536900: 0.175803\n",
      "2022-11-08 20:39:56,344 INFO     Training average negative_sample_loss at step 536900: 0.145085\n",
      "2022-11-08 20:39:56,344 INFO     Training average loss at step 536900: 0.160444\n",
      "2022-11-08 20:40:06,032 INFO     Training average positive_sample_loss at step 537000: 0.167761\n",
      "2022-11-08 20:40:06,033 INFO     Training average negative_sample_loss at step 537000: 0.151484\n",
      "2022-11-08 20:40:06,033 INFO     Training average loss at step 537000: 0.159623\n",
      "2022-11-08 20:40:15,723 INFO     Training average positive_sample_loss at step 537100: 0.177081\n",
      "2022-11-08 20:40:15,723 INFO     Training average negative_sample_loss at step 537100: 0.149853\n",
      "2022-11-08 20:40:15,723 INFO     Training average loss at step 537100: 0.163467\n",
      "2022-11-08 20:40:25,418 INFO     Training average positive_sample_loss at step 537200: 0.176127\n",
      "2022-11-08 20:40:25,418 INFO     Training average negative_sample_loss at step 537200: 0.149798\n",
      "2022-11-08 20:40:25,418 INFO     Training average loss at step 537200: 0.162962\n",
      "2022-11-08 20:40:35,109 INFO     Training average positive_sample_loss at step 537300: 0.171637\n",
      "2022-11-08 20:40:35,109 INFO     Training average negative_sample_loss at step 537300: 0.152077\n",
      "2022-11-08 20:40:35,110 INFO     Training average loss at step 537300: 0.161857\n",
      "2022-11-08 20:40:44,221 INFO     Training average positive_sample_loss at step 537400: 0.172895\n",
      "2022-11-08 20:40:44,221 INFO     Training average negative_sample_loss at step 537400: 0.147700\n",
      "2022-11-08 20:40:44,221 INFO     Training average loss at step 537400: 0.160297\n",
      "2022-11-08 20:40:53,807 INFO     Training average positive_sample_loss at step 537500: 0.173908\n",
      "2022-11-08 20:40:53,807 INFO     Training average negative_sample_loss at step 537500: 0.154500\n",
      "2022-11-08 20:40:53,807 INFO     Training average loss at step 537500: 0.164204\n",
      "2022-11-08 20:41:03,500 INFO     Training average positive_sample_loss at step 537600: 0.173093\n",
      "2022-11-08 20:41:03,500 INFO     Training average negative_sample_loss at step 537600: 0.152748\n",
      "2022-11-08 20:41:03,500 INFO     Training average loss at step 537600: 0.162920\n",
      "2022-11-08 20:41:13,193 INFO     Training average positive_sample_loss at step 537700: 0.173968\n",
      "2022-11-08 20:41:13,194 INFO     Training average negative_sample_loss at step 537700: 0.147457\n",
      "2022-11-08 20:41:13,194 INFO     Training average loss at step 537700: 0.160712\n",
      "2022-11-08 20:41:22,886 INFO     Training average positive_sample_loss at step 537800: 0.171997\n",
      "2022-11-08 20:41:22,886 INFO     Training average negative_sample_loss at step 537800: 0.150034\n",
      "2022-11-08 20:41:22,886 INFO     Training average loss at step 537800: 0.161016\n",
      "2022-11-08 20:41:32,575 INFO     Training average positive_sample_loss at step 537900: 0.172241\n",
      "2022-11-08 20:41:32,575 INFO     Training average negative_sample_loss at step 537900: 0.150110\n",
      "2022-11-08 20:41:32,575 INFO     Training average loss at step 537900: 0.161175\n",
      "2022-11-08 20:41:41,580 INFO     Training average positive_sample_loss at step 538000: 0.172619\n",
      "2022-11-08 20:41:41,580 INFO     Training average negative_sample_loss at step 538000: 0.150288\n",
      "2022-11-08 20:41:41,580 INFO     Training average loss at step 538000: 0.161454\n",
      "2022-11-08 20:41:51,274 INFO     Training average positive_sample_loss at step 538100: 0.177539\n",
      "2022-11-08 20:41:51,274 INFO     Training average negative_sample_loss at step 538100: 0.152851\n",
      "2022-11-08 20:41:51,274 INFO     Training average loss at step 538100: 0.165195\n",
      "2022-11-08 20:42:00,966 INFO     Training average positive_sample_loss at step 538200: 0.173928\n",
      "2022-11-08 20:42:00,967 INFO     Training average negative_sample_loss at step 538200: 0.151241\n",
      "2022-11-08 20:42:00,967 INFO     Training average loss at step 538200: 0.162585\n",
      "2022-11-08 20:42:10,656 INFO     Training average positive_sample_loss at step 538300: 0.176189\n",
      "2022-11-08 20:42:10,656 INFO     Training average negative_sample_loss at step 538300: 0.147462\n",
      "2022-11-08 20:42:10,656 INFO     Training average loss at step 538300: 0.161826\n",
      "2022-11-08 20:42:20,350 INFO     Training average positive_sample_loss at step 538400: 0.174203\n",
      "2022-11-08 20:42:20,350 INFO     Training average negative_sample_loss at step 538400: 0.148701\n",
      "2022-11-08 20:42:20,350 INFO     Training average loss at step 538400: 0.161452\n",
      "2022-11-08 20:42:30,046 INFO     Training average positive_sample_loss at step 538500: 0.165232\n",
      "2022-11-08 20:42:30,046 INFO     Training average negative_sample_loss at step 538500: 0.150436\n",
      "2022-11-08 20:42:30,046 INFO     Training average loss at step 538500: 0.157834\n",
      "2022-11-08 20:42:39,742 INFO     Training average positive_sample_loss at step 538600: 0.166576\n",
      "2022-11-08 20:42:39,742 INFO     Training average negative_sample_loss at step 538600: 0.153534\n",
      "2022-11-08 20:42:39,742 INFO     Training average loss at step 538600: 0.160055\n",
      "2022-11-08 20:42:49,431 INFO     Training average positive_sample_loss at step 538700: 0.174115\n",
      "2022-11-08 20:42:49,431 INFO     Training average negative_sample_loss at step 538700: 0.153025\n",
      "2022-11-08 20:42:49,431 INFO     Training average loss at step 538700: 0.163570\n",
      "2022-11-08 20:42:59,124 INFO     Training average positive_sample_loss at step 538800: 0.165373\n",
      "2022-11-08 20:42:59,124 INFO     Training average negative_sample_loss at step 538800: 0.149536\n",
      "2022-11-08 20:42:59,124 INFO     Training average loss at step 538800: 0.157454\n",
      "2022-11-08 20:43:08,821 INFO     Training average positive_sample_loss at step 538900: 0.176364\n",
      "2022-11-08 20:43:08,821 INFO     Training average negative_sample_loss at step 538900: 0.148254\n",
      "2022-11-08 20:43:08,821 INFO     Training average loss at step 538900: 0.162309\n",
      "2022-11-08 20:43:18,515 INFO     Training average positive_sample_loss at step 539000: 0.177898\n",
      "2022-11-08 20:43:18,515 INFO     Training average negative_sample_loss at step 539000: 0.152156\n",
      "2022-11-08 20:43:18,515 INFO     Training average loss at step 539000: 0.165027\n",
      "2022-11-08 20:43:28,214 INFO     Training average positive_sample_loss at step 539100: 0.171041\n",
      "2022-11-08 20:43:28,214 INFO     Training average negative_sample_loss at step 539100: 0.151762\n",
      "2022-11-08 20:43:28,214 INFO     Training average loss at step 539100: 0.161402\n",
      "2022-11-08 20:43:37,909 INFO     Training average positive_sample_loss at step 539200: 0.169582\n",
      "2022-11-08 20:43:37,909 INFO     Training average negative_sample_loss at step 539200: 0.149042\n",
      "2022-11-08 20:43:37,909 INFO     Training average loss at step 539200: 0.159312\n",
      "2022-11-08 20:43:47,603 INFO     Training average positive_sample_loss at step 539300: 0.167262\n",
      "2022-11-08 20:43:47,603 INFO     Training average negative_sample_loss at step 539300: 0.147827\n",
      "2022-11-08 20:43:47,603 INFO     Training average loss at step 539300: 0.157544\n",
      "2022-11-08 20:43:57,296 INFO     Training average positive_sample_loss at step 539400: 0.172537\n",
      "2022-11-08 20:43:57,296 INFO     Training average negative_sample_loss at step 539400: 0.145618\n",
      "2022-11-08 20:43:57,296 INFO     Training average loss at step 539400: 0.159077\n",
      "2022-11-08 20:44:06,992 INFO     Training average positive_sample_loss at step 539500: 0.170798\n",
      "2022-11-08 20:44:06,992 INFO     Training average negative_sample_loss at step 539500: 0.149967\n",
      "2022-11-08 20:44:06,992 INFO     Training average loss at step 539500: 0.160383\n",
      "2022-11-08 20:44:16,685 INFO     Training average positive_sample_loss at step 539600: 0.169530\n",
      "2022-11-08 20:44:16,685 INFO     Training average negative_sample_loss at step 539600: 0.153492\n",
      "2022-11-08 20:44:16,685 INFO     Training average loss at step 539600: 0.161511\n",
      "2022-11-08 20:44:26,381 INFO     Training average positive_sample_loss at step 539700: 0.176506\n",
      "2022-11-08 20:44:26,381 INFO     Training average negative_sample_loss at step 539700: 0.141562\n",
      "2022-11-08 20:44:26,381 INFO     Training average loss at step 539700: 0.159034\n",
      "2022-11-08 20:44:36,072 INFO     Training average positive_sample_loss at step 539800: 0.170327\n",
      "2022-11-08 20:44:36,072 INFO     Training average negative_sample_loss at step 539800: 0.142509\n",
      "2022-11-08 20:44:36,072 INFO     Training average loss at step 539800: 0.156418\n",
      "2022-11-08 20:44:45,762 INFO     Training average positive_sample_loss at step 539900: 0.172446\n",
      "2022-11-08 20:44:45,763 INFO     Training average negative_sample_loss at step 539900: 0.148333\n",
      "2022-11-08 20:44:45,763 INFO     Training average loss at step 539900: 0.160390\n",
      "2022-11-08 20:44:58,295 INFO     Training average positive_sample_loss at step 540000: 0.169961\n",
      "2022-11-08 20:44:58,295 INFO     Training average negative_sample_loss at step 540000: 0.148433\n",
      "2022-11-08 20:44:58,295 INFO     Training average loss at step 540000: 0.159197\n",
      "2022-11-08 20:45:07,988 INFO     Training average positive_sample_loss at step 540100: 0.175053\n",
      "2022-11-08 20:45:07,988 INFO     Training average negative_sample_loss at step 540100: 0.147749\n",
      "2022-11-08 20:45:07,988 INFO     Training average loss at step 540100: 0.161401\n",
      "2022-11-08 20:45:17,685 INFO     Training average positive_sample_loss at step 540200: 0.166486\n",
      "2022-11-08 20:45:17,685 INFO     Training average negative_sample_loss at step 540200: 0.148852\n",
      "2022-11-08 20:45:17,685 INFO     Training average loss at step 540200: 0.157669\n",
      "2022-11-08 20:45:27,382 INFO     Training average positive_sample_loss at step 540300: 0.174842\n",
      "2022-11-08 20:45:27,382 INFO     Training average negative_sample_loss at step 540300: 0.149244\n",
      "2022-11-08 20:45:27,382 INFO     Training average loss at step 540300: 0.162043\n",
      "2022-11-08 20:45:37,075 INFO     Training average positive_sample_loss at step 540400: 0.169459\n",
      "2022-11-08 20:45:37,076 INFO     Training average negative_sample_loss at step 540400: 0.152733\n",
      "2022-11-08 20:45:37,076 INFO     Training average loss at step 540400: 0.161096\n",
      "2022-11-08 20:45:46,767 INFO     Training average positive_sample_loss at step 540500: 0.173804\n",
      "2022-11-08 20:45:46,768 INFO     Training average negative_sample_loss at step 540500: 0.146662\n",
      "2022-11-08 20:45:46,768 INFO     Training average loss at step 540500: 0.160233\n",
      "2022-11-08 20:45:56,457 INFO     Training average positive_sample_loss at step 540600: 0.173734\n",
      "2022-11-08 20:45:56,457 INFO     Training average negative_sample_loss at step 540600: 0.147923\n",
      "2022-11-08 20:45:56,457 INFO     Training average loss at step 540600: 0.160829\n",
      "2022-11-08 20:46:06,713 INFO     Training average positive_sample_loss at step 540700: 0.176937\n",
      "2022-11-08 20:46:06,713 INFO     Training average negative_sample_loss at step 540700: 0.149258\n",
      "2022-11-08 20:46:06,713 INFO     Training average loss at step 540700: 0.163098\n",
      "2022-11-08 20:46:16,411 INFO     Training average positive_sample_loss at step 540800: 0.173597\n",
      "2022-11-08 20:46:16,411 INFO     Training average negative_sample_loss at step 540800: 0.151692\n",
      "2022-11-08 20:46:16,411 INFO     Training average loss at step 540800: 0.162645\n",
      "2022-11-08 20:46:26,423 INFO     Training average positive_sample_loss at step 540900: 0.173855\n",
      "2022-11-08 20:46:26,423 INFO     Training average negative_sample_loss at step 540900: 0.152819\n",
      "2022-11-08 20:46:26,423 INFO     Training average loss at step 540900: 0.163337\n",
      "2022-11-08 20:46:37,121 INFO     Training average positive_sample_loss at step 541000: 0.170405\n",
      "2022-11-08 20:46:37,121 INFO     Training average negative_sample_loss at step 541000: 0.148904\n",
      "2022-11-08 20:46:37,121 INFO     Training average loss at step 541000: 0.159654\n",
      "2022-11-08 20:46:47,251 INFO     Training average positive_sample_loss at step 541100: 0.176737\n",
      "2022-11-08 20:46:47,251 INFO     Training average negative_sample_loss at step 541100: 0.147962\n",
      "2022-11-08 20:46:47,251 INFO     Training average loss at step 541100: 0.162350\n",
      "2022-11-08 20:46:56,945 INFO     Training average positive_sample_loss at step 541200: 0.174276\n",
      "2022-11-08 20:46:56,945 INFO     Training average negative_sample_loss at step 541200: 0.149293\n",
      "2022-11-08 20:46:56,945 INFO     Training average loss at step 541200: 0.161784\n",
      "2022-11-08 20:47:06,640 INFO     Training average positive_sample_loss at step 541300: 0.165277\n",
      "2022-11-08 20:47:06,640 INFO     Training average negative_sample_loss at step 541300: 0.154240\n",
      "2022-11-08 20:47:06,640 INFO     Training average loss at step 541300: 0.159758\n",
      "2022-11-08 20:47:16,336 INFO     Training average positive_sample_loss at step 541400: 0.169885\n",
      "2022-11-08 20:47:16,336 INFO     Training average negative_sample_loss at step 541400: 0.150317\n",
      "2022-11-08 20:47:16,336 INFO     Training average loss at step 541400: 0.160101\n",
      "2022-11-08 20:47:26,029 INFO     Training average positive_sample_loss at step 541500: 0.172568\n",
      "2022-11-08 20:47:26,029 INFO     Training average negative_sample_loss at step 541500: 0.147261\n",
      "2022-11-08 20:47:26,029 INFO     Training average loss at step 541500: 0.159915\n",
      "2022-11-08 20:47:35,101 INFO     Training average positive_sample_loss at step 541600: 0.176090\n",
      "2022-11-08 20:47:35,101 INFO     Training average negative_sample_loss at step 541600: 0.153553\n",
      "2022-11-08 20:47:35,101 INFO     Training average loss at step 541600: 0.164821\n",
      "2022-11-08 20:47:43,873 INFO     Training average positive_sample_loss at step 541700: 0.166627\n",
      "2022-11-08 20:47:43,873 INFO     Training average negative_sample_loss at step 541700: 0.149964\n",
      "2022-11-08 20:47:43,873 INFO     Training average loss at step 541700: 0.158296\n",
      "2022-11-08 20:47:53,563 INFO     Training average positive_sample_loss at step 541800: 0.166612\n",
      "2022-11-08 20:47:53,563 INFO     Training average negative_sample_loss at step 541800: 0.153298\n",
      "2022-11-08 20:47:53,563 INFO     Training average loss at step 541800: 0.159955\n",
      "2022-11-08 20:48:03,258 INFO     Training average positive_sample_loss at step 541900: 0.170583\n",
      "2022-11-08 20:48:03,258 INFO     Training average negative_sample_loss at step 541900: 0.152468\n",
      "2022-11-08 20:48:03,258 INFO     Training average loss at step 541900: 0.161526\n",
      "2022-11-08 20:48:12,954 INFO     Training average positive_sample_loss at step 542000: 0.170934\n",
      "2022-11-08 20:48:12,955 INFO     Training average negative_sample_loss at step 542000: 0.151771\n",
      "2022-11-08 20:48:12,955 INFO     Training average loss at step 542000: 0.161352\n",
      "2022-11-08 20:48:22,649 INFO     Training average positive_sample_loss at step 542100: 0.174412\n",
      "2022-11-08 20:48:22,649 INFO     Training average negative_sample_loss at step 542100: 0.147381\n",
      "2022-11-08 20:48:22,649 INFO     Training average loss at step 542100: 0.160896\n",
      "2022-11-08 20:48:32,339 INFO     Training average positive_sample_loss at step 542200: 0.172959\n",
      "2022-11-08 20:48:32,339 INFO     Training average negative_sample_loss at step 542200: 0.149939\n",
      "2022-11-08 20:48:32,339 INFO     Training average loss at step 542200: 0.161449\n",
      "2022-11-08 20:48:42,030 INFO     Training average positive_sample_loss at step 542300: 0.166276\n",
      "2022-11-08 20:48:42,031 INFO     Training average negative_sample_loss at step 542300: 0.150861\n",
      "2022-11-08 20:48:42,031 INFO     Training average loss at step 542300: 0.158568\n",
      "2022-11-08 20:48:51,724 INFO     Training average positive_sample_loss at step 542400: 0.176754\n",
      "2022-11-08 20:48:51,724 INFO     Training average negative_sample_loss at step 542400: 0.146740\n",
      "2022-11-08 20:48:51,724 INFO     Training average loss at step 542400: 0.161747\n",
      "2022-11-08 20:49:01,420 INFO     Training average positive_sample_loss at step 542500: 0.170985\n",
      "2022-11-08 20:49:01,420 INFO     Training average negative_sample_loss at step 542500: 0.149960\n",
      "2022-11-08 20:49:01,420 INFO     Training average loss at step 542500: 0.160473\n",
      "2022-11-08 20:49:11,115 INFO     Training average positive_sample_loss at step 542600: 0.172281\n",
      "2022-11-08 20:49:11,115 INFO     Training average negative_sample_loss at step 542600: 0.154635\n",
      "2022-11-08 20:49:11,115 INFO     Training average loss at step 542600: 0.163458\n",
      "2022-11-08 20:49:20,805 INFO     Training average positive_sample_loss at step 542700: 0.170074\n",
      "2022-11-08 20:49:20,805 INFO     Training average negative_sample_loss at step 542700: 0.151262\n",
      "2022-11-08 20:49:20,805 INFO     Training average loss at step 542700: 0.160668\n",
      "2022-11-08 20:49:30,496 INFO     Training average positive_sample_loss at step 542800: 0.167902\n",
      "2022-11-08 20:49:30,496 INFO     Training average negative_sample_loss at step 542800: 0.146867\n",
      "2022-11-08 20:49:30,496 INFO     Training average loss at step 542800: 0.157385\n",
      "2022-11-08 20:49:39,493 INFO     Training average positive_sample_loss at step 542900: 0.171105\n",
      "2022-11-08 20:49:39,493 INFO     Training average negative_sample_loss at step 542900: 0.147420\n",
      "2022-11-08 20:49:39,493 INFO     Training average loss at step 542900: 0.159263\n",
      "2022-11-08 20:49:49,184 INFO     Training average positive_sample_loss at step 543000: 0.176742\n",
      "2022-11-08 20:49:49,184 INFO     Training average negative_sample_loss at step 543000: 0.150447\n",
      "2022-11-08 20:49:49,184 INFO     Training average loss at step 543000: 0.163594\n",
      "2022-11-08 20:49:58,874 INFO     Training average positive_sample_loss at step 543100: 0.172953\n",
      "2022-11-08 20:49:58,875 INFO     Training average negative_sample_loss at step 543100: 0.150752\n",
      "2022-11-08 20:49:58,875 INFO     Training average loss at step 543100: 0.161852\n",
      "2022-11-08 20:50:08,565 INFO     Training average positive_sample_loss at step 543200: 0.169441\n",
      "2022-11-08 20:50:08,565 INFO     Training average negative_sample_loss at step 543200: 0.145117\n",
      "2022-11-08 20:50:08,565 INFO     Training average loss at step 543200: 0.157279\n",
      "2022-11-08 20:50:18,257 INFO     Training average positive_sample_loss at step 543300: 0.174086\n",
      "2022-11-08 20:50:18,257 INFO     Training average negative_sample_loss at step 543300: 0.149431\n",
      "2022-11-08 20:50:18,257 INFO     Training average loss at step 543300: 0.161758\n",
      "2022-11-08 20:50:27,948 INFO     Training average positive_sample_loss at step 543400: 0.172309\n",
      "2022-11-08 20:50:27,948 INFO     Training average negative_sample_loss at step 543400: 0.146558\n",
      "2022-11-08 20:50:27,948 INFO     Training average loss at step 543400: 0.159433\n",
      "2022-11-08 20:50:36,914 INFO     Training average positive_sample_loss at step 543500: 0.180603\n",
      "2022-11-08 20:50:36,914 INFO     Training average negative_sample_loss at step 543500: 0.147519\n",
      "2022-11-08 20:50:36,914 INFO     Training average loss at step 543500: 0.164061\n",
      "2022-11-08 20:50:46,608 INFO     Training average positive_sample_loss at step 543600: 0.174421\n",
      "2022-11-08 20:50:46,608 INFO     Training average negative_sample_loss at step 543600: 0.148243\n",
      "2022-11-08 20:50:46,608 INFO     Training average loss at step 543600: 0.161332\n",
      "2022-11-08 20:50:56,298 INFO     Training average positive_sample_loss at step 543700: 0.168853\n",
      "2022-11-08 20:50:56,298 INFO     Training average negative_sample_loss at step 543700: 0.153009\n",
      "2022-11-08 20:50:56,298 INFO     Training average loss at step 543700: 0.160931\n",
      "2022-11-08 20:51:05,988 INFO     Training average positive_sample_loss at step 543800: 0.168680\n",
      "2022-11-08 20:51:05,989 INFO     Training average negative_sample_loss at step 543800: 0.148193\n",
      "2022-11-08 20:51:05,989 INFO     Training average loss at step 543800: 0.158436\n",
      "2022-11-08 20:51:15,685 INFO     Training average positive_sample_loss at step 543900: 0.178752\n",
      "2022-11-08 20:51:15,685 INFO     Training average negative_sample_loss at step 543900: 0.148358\n",
      "2022-11-08 20:51:15,685 INFO     Training average loss at step 543900: 0.163555\n",
      "2022-11-08 20:51:25,377 INFO     Training average positive_sample_loss at step 544000: 0.178222\n",
      "2022-11-08 20:51:25,377 INFO     Training average negative_sample_loss at step 544000: 0.150438\n",
      "2022-11-08 20:51:25,377 INFO     Training average loss at step 544000: 0.164330\n",
      "2022-11-08 20:51:35,068 INFO     Training average positive_sample_loss at step 544100: 0.172953\n",
      "2022-11-08 20:51:35,068 INFO     Training average negative_sample_loss at step 544100: 0.152240\n",
      "2022-11-08 20:51:35,068 INFO     Training average loss at step 544100: 0.162597\n",
      "2022-11-08 20:51:44,759 INFO     Training average positive_sample_loss at step 544200: 0.171311\n",
      "2022-11-08 20:51:44,759 INFO     Training average negative_sample_loss at step 544200: 0.145931\n",
      "2022-11-08 20:51:44,759 INFO     Training average loss at step 544200: 0.158621\n",
      "2022-11-08 20:51:54,452 INFO     Training average positive_sample_loss at step 544300: 0.167936\n",
      "2022-11-08 20:51:54,452 INFO     Training average negative_sample_loss at step 544300: 0.152693\n",
      "2022-11-08 20:51:54,452 INFO     Training average loss at step 544300: 0.160314\n",
      "2022-11-08 20:52:04,146 INFO     Training average positive_sample_loss at step 544400: 0.181668\n",
      "2022-11-08 20:52:04,146 INFO     Training average negative_sample_loss at step 544400: 0.151614\n",
      "2022-11-08 20:52:04,146 INFO     Training average loss at step 544400: 0.166641\n",
      "2022-11-08 20:52:13,840 INFO     Training average positive_sample_loss at step 544500: 0.178332\n",
      "2022-11-08 20:52:13,840 INFO     Training average negative_sample_loss at step 544500: 0.147625\n",
      "2022-11-08 20:52:13,840 INFO     Training average loss at step 544500: 0.162979\n",
      "2022-11-08 20:52:23,534 INFO     Training average positive_sample_loss at step 544600: 0.172290\n",
      "2022-11-08 20:52:23,534 INFO     Training average negative_sample_loss at step 544600: 0.147694\n",
      "2022-11-08 20:52:23,534 INFO     Training average loss at step 544600: 0.159992\n",
      "2022-11-08 20:52:33,228 INFO     Training average positive_sample_loss at step 544700: 0.166660\n",
      "2022-11-08 20:52:33,228 INFO     Training average negative_sample_loss at step 544700: 0.150373\n",
      "2022-11-08 20:52:33,228 INFO     Training average loss at step 544700: 0.158516\n",
      "2022-11-08 20:52:42,924 INFO     Training average positive_sample_loss at step 544800: 0.168689\n",
      "2022-11-08 20:52:42,924 INFO     Training average negative_sample_loss at step 544800: 0.149519\n",
      "2022-11-08 20:52:42,924 INFO     Training average loss at step 544800: 0.159104\n",
      "2022-11-08 20:52:52,618 INFO     Training average positive_sample_loss at step 544900: 0.171281\n",
      "2022-11-08 20:52:52,618 INFO     Training average negative_sample_loss at step 544900: 0.145596\n",
      "2022-11-08 20:52:52,618 INFO     Training average loss at step 544900: 0.158438\n",
      "2022-11-08 20:53:02,319 INFO     Training average positive_sample_loss at step 545000: 0.166107\n",
      "2022-11-08 20:53:02,319 INFO     Training average negative_sample_loss at step 545000: 0.148920\n",
      "2022-11-08 20:53:02,319 INFO     Training average loss at step 545000: 0.157513\n",
      "2022-11-08 20:53:12,014 INFO     Training average positive_sample_loss at step 545100: 0.169398\n",
      "2022-11-08 20:53:12,014 INFO     Training average negative_sample_loss at step 545100: 0.145146\n",
      "2022-11-08 20:53:12,014 INFO     Training average loss at step 545100: 0.157272\n",
      "2022-11-08 20:53:21,706 INFO     Training average positive_sample_loss at step 545200: 0.168825\n",
      "2022-11-08 20:53:21,706 INFO     Training average negative_sample_loss at step 545200: 0.153381\n",
      "2022-11-08 20:53:21,706 INFO     Training average loss at step 545200: 0.161103\n",
      "2022-11-08 20:53:31,397 INFO     Training average positive_sample_loss at step 545300: 0.180791\n",
      "2022-11-08 20:53:31,397 INFO     Training average negative_sample_loss at step 545300: 0.151605\n",
      "2022-11-08 20:53:31,397 INFO     Training average loss at step 545300: 0.166198\n",
      "2022-11-08 20:53:41,599 INFO     Training average positive_sample_loss at step 545400: 0.167376\n",
      "2022-11-08 20:53:41,600 INFO     Training average negative_sample_loss at step 545400: 0.151465\n",
      "2022-11-08 20:53:41,600 INFO     Training average loss at step 545400: 0.159420\n",
      "2022-11-08 20:53:52,009 INFO     Training average positive_sample_loss at step 545500: 0.171023\n",
      "2022-11-08 20:53:52,009 INFO     Training average negative_sample_loss at step 545500: 0.148719\n",
      "2022-11-08 20:53:52,009 INFO     Training average loss at step 545500: 0.159871\n",
      "2022-11-08 20:54:01,706 INFO     Training average positive_sample_loss at step 545600: 0.176053\n",
      "2022-11-08 20:54:01,706 INFO     Training average negative_sample_loss at step 545600: 0.150210\n",
      "2022-11-08 20:54:01,706 INFO     Training average loss at step 545600: 0.163132\n",
      "2022-11-08 20:54:11,989 INFO     Training average positive_sample_loss at step 545700: 0.177415\n",
      "2022-11-08 20:54:11,989 INFO     Training average negative_sample_loss at step 545700: 0.148875\n",
      "2022-11-08 20:54:11,989 INFO     Training average loss at step 545700: 0.163145\n",
      "2022-11-08 20:54:22,017 INFO     Training average positive_sample_loss at step 545800: 0.169222\n",
      "2022-11-08 20:54:22,017 INFO     Training average negative_sample_loss at step 545800: 0.142990\n",
      "2022-11-08 20:54:22,017 INFO     Training average loss at step 545800: 0.156106\n",
      "2022-11-08 20:54:31,709 INFO     Training average positive_sample_loss at step 545900: 0.176512\n",
      "2022-11-08 20:54:31,709 INFO     Training average negative_sample_loss at step 545900: 0.148016\n",
      "2022-11-08 20:54:31,709 INFO     Training average loss at step 545900: 0.162264\n",
      "2022-11-08 20:54:41,403 INFO     Training average positive_sample_loss at step 546000: 0.163925\n",
      "2022-11-08 20:54:41,403 INFO     Training average negative_sample_loss at step 546000: 0.151010\n",
      "2022-11-08 20:54:41,403 INFO     Training average loss at step 546000: 0.157468\n",
      "2022-11-08 20:54:51,096 INFO     Training average positive_sample_loss at step 546100: 0.172950\n",
      "2022-11-08 20:54:51,096 INFO     Training average negative_sample_loss at step 546100: 0.147312\n",
      "2022-11-08 20:54:51,096 INFO     Training average loss at step 546100: 0.160131\n",
      "2022-11-08 20:55:00,791 INFO     Training average positive_sample_loss at step 546200: 0.166897\n",
      "2022-11-08 20:55:00,791 INFO     Training average negative_sample_loss at step 546200: 0.152009\n",
      "2022-11-08 20:55:00,791 INFO     Training average loss at step 546200: 0.159453\n",
      "2022-11-08 20:55:10,486 INFO     Training average positive_sample_loss at step 546300: 0.177336\n",
      "2022-11-08 20:55:10,486 INFO     Training average negative_sample_loss at step 546300: 0.149918\n",
      "2022-11-08 20:55:10,486 INFO     Training average loss at step 546300: 0.163627\n",
      "2022-11-08 20:55:20,184 INFO     Training average positive_sample_loss at step 546400: 0.171671\n",
      "2022-11-08 20:55:20,184 INFO     Training average negative_sample_loss at step 546400: 0.148786\n",
      "2022-11-08 20:55:20,184 INFO     Training average loss at step 546400: 0.160229\n",
      "2022-11-08 20:55:29,873 INFO     Training average positive_sample_loss at step 546500: 0.171511\n",
      "2022-11-08 20:55:29,874 INFO     Training average negative_sample_loss at step 546500: 0.149057\n",
      "2022-11-08 20:55:29,874 INFO     Training average loss at step 546500: 0.160284\n",
      "2022-11-08 20:55:39,566 INFO     Training average positive_sample_loss at step 546600: 0.171011\n",
      "2022-11-08 20:55:39,567 INFO     Training average negative_sample_loss at step 546600: 0.145513\n",
      "2022-11-08 20:55:39,567 INFO     Training average loss at step 546600: 0.158262\n",
      "2022-11-08 20:55:49,259 INFO     Training average positive_sample_loss at step 546700: 0.172576\n",
      "2022-11-08 20:55:49,259 INFO     Training average negative_sample_loss at step 546700: 0.149516\n",
      "2022-11-08 20:55:49,259 INFO     Training average loss at step 546700: 0.161046\n",
      "2022-11-08 20:55:58,954 INFO     Training average positive_sample_loss at step 546800: 0.171619\n",
      "2022-11-08 20:55:58,954 INFO     Training average negative_sample_loss at step 546800: 0.151112\n",
      "2022-11-08 20:55:58,954 INFO     Training average loss at step 546800: 0.161365\n",
      "2022-11-08 20:56:08,649 INFO     Training average positive_sample_loss at step 546900: 0.173055\n",
      "2022-11-08 20:56:08,649 INFO     Training average negative_sample_loss at step 546900: 0.148733\n",
      "2022-11-08 20:56:08,649 INFO     Training average loss at step 546900: 0.160894\n",
      "2022-11-08 20:56:18,339 INFO     Training average positive_sample_loss at step 547000: 0.175231\n",
      "2022-11-08 20:56:18,339 INFO     Training average negative_sample_loss at step 547000: 0.152604\n",
      "2022-11-08 20:56:18,339 INFO     Training average loss at step 547000: 0.163918\n",
      "2022-11-08 20:56:28,030 INFO     Training average positive_sample_loss at step 547100: 0.173709\n",
      "2022-11-08 20:56:28,030 INFO     Training average negative_sample_loss at step 547100: 0.149049\n",
      "2022-11-08 20:56:28,030 INFO     Training average loss at step 547100: 0.161379\n",
      "2022-11-08 20:56:37,722 INFO     Training average positive_sample_loss at step 547200: 0.173000\n",
      "2022-11-08 20:56:37,722 INFO     Training average negative_sample_loss at step 547200: 0.149228\n",
      "2022-11-08 20:56:37,722 INFO     Training average loss at step 547200: 0.161114\n",
      "2022-11-08 20:56:47,414 INFO     Training average positive_sample_loss at step 547300: 0.169144\n",
      "2022-11-08 20:56:47,414 INFO     Training average negative_sample_loss at step 547300: 0.147621\n",
      "2022-11-08 20:56:47,414 INFO     Training average loss at step 547300: 0.158383\n",
      "2022-11-08 20:56:57,112 INFO     Training average positive_sample_loss at step 547400: 0.168253\n",
      "2022-11-08 20:56:57,112 INFO     Training average negative_sample_loss at step 547400: 0.151265\n",
      "2022-11-08 20:56:57,113 INFO     Training average loss at step 547400: 0.159759\n",
      "2022-11-08 20:57:06,805 INFO     Training average positive_sample_loss at step 547500: 0.169590\n",
      "2022-11-08 20:57:06,805 INFO     Training average negative_sample_loss at step 547500: 0.146619\n",
      "2022-11-08 20:57:06,805 INFO     Training average loss at step 547500: 0.158104\n",
      "2022-11-08 20:57:16,493 INFO     Training average positive_sample_loss at step 547600: 0.166316\n",
      "2022-11-08 20:57:16,493 INFO     Training average negative_sample_loss at step 547600: 0.150491\n",
      "2022-11-08 20:57:16,493 INFO     Training average loss at step 547600: 0.158404\n",
      "2022-11-08 20:57:26,191 INFO     Training average positive_sample_loss at step 547700: 0.169523\n",
      "2022-11-08 20:57:26,191 INFO     Training average negative_sample_loss at step 547700: 0.148265\n",
      "2022-11-08 20:57:26,191 INFO     Training average loss at step 547700: 0.158894\n",
      "2022-11-08 20:57:35,886 INFO     Training average positive_sample_loss at step 547800: 0.165604\n",
      "2022-11-08 20:57:35,886 INFO     Training average negative_sample_loss at step 547800: 0.144166\n",
      "2022-11-08 20:57:35,886 INFO     Training average loss at step 547800: 0.154885\n",
      "2022-11-08 20:57:45,577 INFO     Training average positive_sample_loss at step 547900: 0.169264\n",
      "2022-11-08 20:57:45,577 INFO     Training average negative_sample_loss at step 547900: 0.150018\n",
      "2022-11-08 20:57:45,578 INFO     Training average loss at step 547900: 0.159641\n",
      "2022-11-08 20:57:55,272 INFO     Training average positive_sample_loss at step 548000: 0.178676\n",
      "2022-11-08 20:57:55,272 INFO     Training average negative_sample_loss at step 548000: 0.151942\n",
      "2022-11-08 20:57:55,272 INFO     Training average loss at step 548000: 0.165309\n",
      "2022-11-08 20:58:04,969 INFO     Training average positive_sample_loss at step 548100: 0.167841\n",
      "2022-11-08 20:58:04,969 INFO     Training average negative_sample_loss at step 548100: 0.146394\n",
      "2022-11-08 20:58:04,969 INFO     Training average loss at step 548100: 0.157117\n",
      "2022-11-08 20:58:14,659 INFO     Training average positive_sample_loss at step 548200: 0.168043\n",
      "2022-11-08 20:58:14,659 INFO     Training average negative_sample_loss at step 548200: 0.149453\n",
      "2022-11-08 20:58:14,659 INFO     Training average loss at step 548200: 0.158748\n",
      "2022-11-08 20:58:24,353 INFO     Training average positive_sample_loss at step 548300: 0.174085\n",
      "2022-11-08 20:58:24,353 INFO     Training average negative_sample_loss at step 548300: 0.148614\n",
      "2022-11-08 20:58:24,353 INFO     Training average loss at step 548300: 0.161349\n",
      "2022-11-08 20:58:33,328 INFO     Training average positive_sample_loss at step 548400: 0.175369\n",
      "2022-11-08 20:58:33,328 INFO     Training average negative_sample_loss at step 548400: 0.150240\n",
      "2022-11-08 20:58:33,328 INFO     Training average loss at step 548400: 0.162805\n",
      "2022-11-08 20:58:43,018 INFO     Training average positive_sample_loss at step 548500: 0.169741\n",
      "2022-11-08 20:58:43,019 INFO     Training average negative_sample_loss at step 548500: 0.149381\n",
      "2022-11-08 20:58:43,019 INFO     Training average loss at step 548500: 0.159561\n",
      "2022-11-08 20:58:52,709 INFO     Training average positive_sample_loss at step 548600: 0.172040\n",
      "2022-11-08 20:58:52,709 INFO     Training average negative_sample_loss at step 548600: 0.147079\n",
      "2022-11-08 20:58:52,709 INFO     Training average loss at step 548600: 0.159560\n",
      "2022-11-08 20:59:02,404 INFO     Training average positive_sample_loss at step 548700: 0.176796\n",
      "2022-11-08 20:59:02,404 INFO     Training average negative_sample_loss at step 548700: 0.150509\n",
      "2022-11-08 20:59:02,404 INFO     Training average loss at step 548700: 0.163652\n",
      "2022-11-08 20:59:12,097 INFO     Training average positive_sample_loss at step 548800: 0.173695\n",
      "2022-11-08 20:59:12,097 INFO     Training average negative_sample_loss at step 548800: 0.152330\n",
      "2022-11-08 20:59:12,097 INFO     Training average loss at step 548800: 0.163013\n",
      "2022-11-08 20:59:21,789 INFO     Training average positive_sample_loss at step 548900: 0.166793\n",
      "2022-11-08 20:59:21,790 INFO     Training average negative_sample_loss at step 548900: 0.150433\n",
      "2022-11-08 20:59:21,790 INFO     Training average loss at step 548900: 0.158613\n",
      "2022-11-08 20:59:30,776 INFO     Training average positive_sample_loss at step 549000: 0.169292\n",
      "2022-11-08 20:59:30,776 INFO     Training average negative_sample_loss at step 549000: 0.145703\n",
      "2022-11-08 20:59:30,776 INFO     Training average loss at step 549000: 0.157497\n",
      "2022-11-08 20:59:40,469 INFO     Training average positive_sample_loss at step 549100: 0.173069\n",
      "2022-11-08 20:59:40,469 INFO     Training average negative_sample_loss at step 549100: 0.151323\n",
      "2022-11-08 20:59:40,469 INFO     Training average loss at step 549100: 0.162196\n",
      "2022-11-08 20:59:50,159 INFO     Training average positive_sample_loss at step 549200: 0.168022\n",
      "2022-11-08 20:59:50,159 INFO     Training average negative_sample_loss at step 549200: 0.148042\n",
      "2022-11-08 20:59:50,159 INFO     Training average loss at step 549200: 0.158032\n",
      "2022-11-08 20:59:59,854 INFO     Training average positive_sample_loss at step 549300: 0.168115\n",
      "2022-11-08 20:59:59,854 INFO     Training average negative_sample_loss at step 549300: 0.151263\n",
      "2022-11-08 20:59:59,854 INFO     Training average loss at step 549300: 0.159689\n",
      "2022-11-08 21:00:09,548 INFO     Training average positive_sample_loss at step 549400: 0.172249\n",
      "2022-11-08 21:00:09,548 INFO     Training average negative_sample_loss at step 549400: 0.147705\n",
      "2022-11-08 21:00:09,548 INFO     Training average loss at step 549400: 0.159977\n",
      "2022-11-08 21:00:19,236 INFO     Training average positive_sample_loss at step 549500: 0.169233\n",
      "2022-11-08 21:00:19,237 INFO     Training average negative_sample_loss at step 549500: 0.150028\n",
      "2022-11-08 21:00:19,237 INFO     Training average loss at step 549500: 0.159630\n",
      "2022-11-08 21:00:28,932 INFO     Training average positive_sample_loss at step 549600: 0.171082\n",
      "2022-11-08 21:00:28,932 INFO     Training average negative_sample_loss at step 549600: 0.151063\n",
      "2022-11-08 21:00:28,932 INFO     Training average loss at step 549600: 0.161073\n",
      "2022-11-08 21:00:38,627 INFO     Training average positive_sample_loss at step 549700: 0.175751\n",
      "2022-11-08 21:00:38,627 INFO     Training average negative_sample_loss at step 549700: 0.151505\n",
      "2022-11-08 21:00:38,628 INFO     Training average loss at step 549700: 0.163628\n",
      "2022-11-08 21:00:48,317 INFO     Training average positive_sample_loss at step 549800: 0.174513\n",
      "2022-11-08 21:00:48,317 INFO     Training average negative_sample_loss at step 549800: 0.150966\n",
      "2022-11-08 21:00:48,317 INFO     Training average loss at step 549800: 0.162739\n",
      "2022-11-08 21:00:58,014 INFO     Training average positive_sample_loss at step 549900: 0.179748\n",
      "2022-11-08 21:00:58,014 INFO     Training average negative_sample_loss at step 549900: 0.150261\n",
      "2022-11-08 21:00:58,014 INFO     Training average loss at step 549900: 0.165004\n",
      "2022-11-08 21:01:10,548 INFO     Training average positive_sample_loss at step 550000: 0.167641\n",
      "2022-11-08 21:01:10,548 INFO     Training average negative_sample_loss at step 550000: 0.150263\n",
      "2022-11-08 21:01:10,548 INFO     Training average loss at step 550000: 0.158952\n",
      "2022-11-08 21:01:20,655 INFO     Training average positive_sample_loss at step 550100: 0.168413\n",
      "2022-11-08 21:01:20,655 INFO     Training average negative_sample_loss at step 550100: 0.151063\n",
      "2022-11-08 21:01:20,655 INFO     Training average loss at step 550100: 0.159738\n",
      "2022-11-08 21:01:31,151 INFO     Training average positive_sample_loss at step 550200: 0.175476\n",
      "2022-11-08 21:01:31,151 INFO     Training average negative_sample_loss at step 550200: 0.149948\n",
      "2022-11-08 21:01:31,151 INFO     Training average loss at step 550200: 0.162712\n",
      "2022-11-08 21:01:40,841 INFO     Training average positive_sample_loss at step 550300: 0.176322\n",
      "2022-11-08 21:01:40,841 INFO     Training average negative_sample_loss at step 550300: 0.151770\n",
      "2022-11-08 21:01:40,841 INFO     Training average loss at step 550300: 0.164046\n",
      "2022-11-08 21:01:51,224 INFO     Training average positive_sample_loss at step 550400: 0.172368\n",
      "2022-11-08 21:01:51,224 INFO     Training average negative_sample_loss at step 550400: 0.150908\n",
      "2022-11-08 21:01:51,224 INFO     Training average loss at step 550400: 0.161638\n",
      "2022-11-08 21:02:01,192 INFO     Training average positive_sample_loss at step 550500: 0.172267\n",
      "2022-11-08 21:02:01,193 INFO     Training average negative_sample_loss at step 550500: 0.147290\n",
      "2022-11-08 21:02:01,193 INFO     Training average loss at step 550500: 0.159779\n",
      "2022-11-08 21:02:10,886 INFO     Training average positive_sample_loss at step 550600: 0.173438\n",
      "2022-11-08 21:02:10,886 INFO     Training average negative_sample_loss at step 550600: 0.150314\n",
      "2022-11-08 21:02:10,886 INFO     Training average loss at step 550600: 0.161876\n",
      "2022-11-08 21:02:20,578 INFO     Training average positive_sample_loss at step 550700: 0.174426\n",
      "2022-11-08 21:02:20,578 INFO     Training average negative_sample_loss at step 550700: 0.149886\n",
      "2022-11-08 21:02:20,578 INFO     Training average loss at step 550700: 0.162156\n",
      "2022-11-08 21:02:30,269 INFO     Training average positive_sample_loss at step 550800: 0.176440\n",
      "2022-11-08 21:02:30,269 INFO     Training average negative_sample_loss at step 550800: 0.150975\n",
      "2022-11-08 21:02:30,269 INFO     Training average loss at step 550800: 0.163708\n",
      "2022-11-08 21:02:39,968 INFO     Training average positive_sample_loss at step 550900: 0.176917\n",
      "2022-11-08 21:02:39,968 INFO     Training average negative_sample_loss at step 550900: 0.154732\n",
      "2022-11-08 21:02:39,968 INFO     Training average loss at step 550900: 0.165825\n",
      "2022-11-08 21:02:49,662 INFO     Training average positive_sample_loss at step 551000: 0.166367\n",
      "2022-11-08 21:02:49,662 INFO     Training average negative_sample_loss at step 551000: 0.145534\n",
      "2022-11-08 21:02:49,662 INFO     Training average loss at step 551000: 0.155950\n",
      "2022-11-08 21:02:59,352 INFO     Training average positive_sample_loss at step 551100: 0.170932\n",
      "2022-11-08 21:02:59,353 INFO     Training average negative_sample_loss at step 551100: 0.153668\n",
      "2022-11-08 21:02:59,353 INFO     Training average loss at step 551100: 0.162300\n",
      "2022-11-08 21:03:09,048 INFO     Training average positive_sample_loss at step 551200: 0.166236\n",
      "2022-11-08 21:03:09,048 INFO     Training average negative_sample_loss at step 551200: 0.147691\n",
      "2022-11-08 21:03:09,048 INFO     Training average loss at step 551200: 0.156964\n",
      "2022-11-08 21:03:18,743 INFO     Training average positive_sample_loss at step 551300: 0.179473\n",
      "2022-11-08 21:03:18,743 INFO     Training average negative_sample_loss at step 551300: 0.150211\n",
      "2022-11-08 21:03:18,744 INFO     Training average loss at step 551300: 0.164842\n",
      "2022-11-08 21:03:28,435 INFO     Training average positive_sample_loss at step 551400: 0.175807\n",
      "2022-11-08 21:03:28,435 INFO     Training average negative_sample_loss at step 551400: 0.152799\n",
      "2022-11-08 21:03:28,435 INFO     Training average loss at step 551400: 0.164303\n",
      "2022-11-08 21:03:38,130 INFO     Training average positive_sample_loss at step 551500: 0.168214\n",
      "2022-11-08 21:03:38,130 INFO     Training average negative_sample_loss at step 551500: 0.146665\n",
      "2022-11-08 21:03:38,130 INFO     Training average loss at step 551500: 0.157439\n",
      "2022-11-08 21:03:47,822 INFO     Training average positive_sample_loss at step 551600: 0.168694\n",
      "2022-11-08 21:03:47,822 INFO     Training average negative_sample_loss at step 551600: 0.152442\n",
      "2022-11-08 21:03:47,822 INFO     Training average loss at step 551600: 0.160568\n",
      "2022-11-08 21:03:57,517 INFO     Training average positive_sample_loss at step 551700: 0.169486\n",
      "2022-11-08 21:03:57,517 INFO     Training average negative_sample_loss at step 551700: 0.147601\n",
      "2022-11-08 21:03:57,518 INFO     Training average loss at step 551700: 0.158544\n",
      "2022-11-08 21:04:07,211 INFO     Training average positive_sample_loss at step 551800: 0.168776\n",
      "2022-11-08 21:04:07,211 INFO     Training average negative_sample_loss at step 551800: 0.146536\n",
      "2022-11-08 21:04:07,211 INFO     Training average loss at step 551800: 0.157656\n",
      "2022-11-08 21:04:16,903 INFO     Training average positive_sample_loss at step 551900: 0.169419\n",
      "2022-11-08 21:04:16,903 INFO     Training average negative_sample_loss at step 551900: 0.148279\n",
      "2022-11-08 21:04:16,903 INFO     Training average loss at step 551900: 0.158849\n",
      "2022-11-08 21:04:26,596 INFO     Training average positive_sample_loss at step 552000: 0.170559\n",
      "2022-11-08 21:04:26,596 INFO     Training average negative_sample_loss at step 552000: 0.154531\n",
      "2022-11-08 21:04:26,596 INFO     Training average loss at step 552000: 0.162545\n",
      "2022-11-08 21:04:36,289 INFO     Training average positive_sample_loss at step 552100: 0.177096\n",
      "2022-11-08 21:04:36,290 INFO     Training average negative_sample_loss at step 552100: 0.147086\n",
      "2022-11-08 21:04:36,290 INFO     Training average loss at step 552100: 0.162091\n",
      "2022-11-08 21:04:45,985 INFO     Training average positive_sample_loss at step 552200: 0.172371\n",
      "2022-11-08 21:04:45,985 INFO     Training average negative_sample_loss at step 552200: 0.146795\n",
      "2022-11-08 21:04:45,985 INFO     Training average loss at step 552200: 0.159583\n",
      "2022-11-08 21:04:55,679 INFO     Training average positive_sample_loss at step 552300: 0.171159\n",
      "2022-11-08 21:04:55,679 INFO     Training average negative_sample_loss at step 552300: 0.148454\n",
      "2022-11-08 21:04:55,679 INFO     Training average loss at step 552300: 0.159807\n",
      "2022-11-08 21:05:05,376 INFO     Training average positive_sample_loss at step 552400: 0.171917\n",
      "2022-11-08 21:05:05,376 INFO     Training average negative_sample_loss at step 552400: 0.151142\n",
      "2022-11-08 21:05:05,376 INFO     Training average loss at step 552400: 0.161529\n",
      "2022-11-08 21:05:15,074 INFO     Training average positive_sample_loss at step 552500: 0.172978\n",
      "2022-11-08 21:05:15,074 INFO     Training average negative_sample_loss at step 552500: 0.146936\n",
      "2022-11-08 21:05:15,074 INFO     Training average loss at step 552500: 0.159957\n",
      "2022-11-08 21:05:24,766 INFO     Training average positive_sample_loss at step 552600: 0.169055\n",
      "2022-11-08 21:05:24,766 INFO     Training average negative_sample_loss at step 552600: 0.146237\n",
      "2022-11-08 21:05:24,766 INFO     Training average loss at step 552600: 0.157646\n",
      "2022-11-08 21:05:34,454 INFO     Training average positive_sample_loss at step 552700: 0.165875\n",
      "2022-11-08 21:05:34,454 INFO     Training average negative_sample_loss at step 552700: 0.150684\n",
      "2022-11-08 21:05:34,454 INFO     Training average loss at step 552700: 0.158279\n",
      "2022-11-08 21:05:44,149 INFO     Training average positive_sample_loss at step 552800: 0.174289\n",
      "2022-11-08 21:05:44,149 INFO     Training average negative_sample_loss at step 552800: 0.147235\n",
      "2022-11-08 21:05:44,149 INFO     Training average loss at step 552800: 0.160762\n",
      "2022-11-08 21:05:53,840 INFO     Training average positive_sample_loss at step 552900: 0.171334\n",
      "2022-11-08 21:05:53,840 INFO     Training average negative_sample_loss at step 552900: 0.151331\n",
      "2022-11-08 21:05:53,840 INFO     Training average loss at step 552900: 0.161333\n",
      "2022-11-08 21:06:03,530 INFO     Training average positive_sample_loss at step 553000: 0.163816\n",
      "2022-11-08 21:06:03,530 INFO     Training average negative_sample_loss at step 553000: 0.152720\n",
      "2022-11-08 21:06:03,531 INFO     Training average loss at step 553000: 0.158268\n",
      "2022-11-08 21:06:13,225 INFO     Training average positive_sample_loss at step 553100: 0.171577\n",
      "2022-11-08 21:06:13,225 INFO     Training average negative_sample_loss at step 553100: 0.147606\n",
      "2022-11-08 21:06:13,225 INFO     Training average loss at step 553100: 0.159592\n",
      "2022-11-08 21:06:22,922 INFO     Training average positive_sample_loss at step 553200: 0.168932\n",
      "2022-11-08 21:06:22,922 INFO     Training average negative_sample_loss at step 553200: 0.154517\n",
      "2022-11-08 21:06:22,922 INFO     Training average loss at step 553200: 0.161724\n",
      "2022-11-08 21:06:32,611 INFO     Training average positive_sample_loss at step 553300: 0.165650\n",
      "2022-11-08 21:06:32,612 INFO     Training average negative_sample_loss at step 553300: 0.147240\n",
      "2022-11-08 21:06:32,612 INFO     Training average loss at step 553300: 0.156445\n",
      "2022-11-08 21:06:42,304 INFO     Training average positive_sample_loss at step 553400: 0.179956\n",
      "2022-11-08 21:06:42,305 INFO     Training average negative_sample_loss at step 553400: 0.145088\n",
      "2022-11-08 21:06:42,305 INFO     Training average loss at step 553400: 0.162522\n",
      "2022-11-08 21:06:51,993 INFO     Training average positive_sample_loss at step 553500: 0.169061\n",
      "2022-11-08 21:06:51,993 INFO     Training average negative_sample_loss at step 553500: 0.148672\n",
      "2022-11-08 21:06:51,993 INFO     Training average loss at step 553500: 0.158867\n",
      "2022-11-08 21:07:01,685 INFO     Training average positive_sample_loss at step 553600: 0.172391\n",
      "2022-11-08 21:07:01,685 INFO     Training average negative_sample_loss at step 553600: 0.148941\n",
      "2022-11-08 21:07:01,685 INFO     Training average loss at step 553600: 0.160666\n",
      "2022-11-08 21:07:11,378 INFO     Training average positive_sample_loss at step 553700: 0.173426\n",
      "2022-11-08 21:07:11,378 INFO     Training average negative_sample_loss at step 553700: 0.150768\n",
      "2022-11-08 21:07:11,378 INFO     Training average loss at step 553700: 0.162097\n",
      "2022-11-08 21:07:21,066 INFO     Training average positive_sample_loss at step 553800: 0.170306\n",
      "2022-11-08 21:07:21,066 INFO     Training average negative_sample_loss at step 553800: 0.148867\n",
      "2022-11-08 21:07:21,066 INFO     Training average loss at step 553800: 0.159586\n",
      "2022-11-08 21:07:30,068 INFO     Training average positive_sample_loss at step 553900: 0.173766\n",
      "2022-11-08 21:07:30,068 INFO     Training average negative_sample_loss at step 553900: 0.150051\n",
      "2022-11-08 21:07:30,068 INFO     Training average loss at step 553900: 0.161908\n",
      "2022-11-08 21:07:39,761 INFO     Training average positive_sample_loss at step 554000: 0.169158\n",
      "2022-11-08 21:07:39,761 INFO     Training average negative_sample_loss at step 554000: 0.150160\n",
      "2022-11-08 21:07:39,761 INFO     Training average loss at step 554000: 0.159659\n",
      "2022-11-08 21:07:50,631 INFO     Training average positive_sample_loss at step 554100: 0.172525\n",
      "2022-11-08 21:07:50,631 INFO     Training average negative_sample_loss at step 554100: 0.145249\n",
      "2022-11-08 21:07:50,631 INFO     Training average loss at step 554100: 0.158887\n",
      "2022-11-08 21:08:02,390 INFO     Training average positive_sample_loss at step 554200: 0.149494\n",
      "2022-11-08 21:08:02,390 INFO     Training average negative_sample_loss at step 554200: 0.149696\n",
      "2022-11-08 21:08:02,390 INFO     Training average loss at step 554200: 0.149595\n",
      "2022-11-08 21:08:12,081 INFO     Training average positive_sample_loss at step 554300: 0.143418\n",
      "2022-11-08 21:08:12,081 INFO     Training average negative_sample_loss at step 554300: 0.149309\n",
      "2022-11-08 21:08:12,081 INFO     Training average loss at step 554300: 0.146363\n",
      "2022-11-08 21:08:21,059 INFO     Training average positive_sample_loss at step 554400: 0.144925\n",
      "2022-11-08 21:08:21,059 INFO     Training average negative_sample_loss at step 554400: 0.147869\n",
      "2022-11-08 21:08:21,059 INFO     Training average loss at step 554400: 0.146397\n",
      "2022-11-08 21:08:30,751 INFO     Training average positive_sample_loss at step 554500: 0.146278\n",
      "2022-11-08 21:08:30,751 INFO     Training average negative_sample_loss at step 554500: 0.146356\n",
      "2022-11-08 21:08:30,751 INFO     Training average loss at step 554500: 0.146317\n",
      "2022-11-08 21:08:40,446 INFO     Training average positive_sample_loss at step 554600: 0.153006\n",
      "2022-11-08 21:08:40,446 INFO     Training average negative_sample_loss at step 554600: 0.145448\n",
      "2022-11-08 21:08:40,446 INFO     Training average loss at step 554600: 0.149227\n",
      "2022-11-08 21:08:50,137 INFO     Training average positive_sample_loss at step 554700: 0.149526\n",
      "2022-11-08 21:08:50,137 INFO     Training average negative_sample_loss at step 554700: 0.153166\n",
      "2022-11-08 21:08:50,137 INFO     Training average loss at step 554700: 0.151346\n",
      "2022-11-08 21:08:59,828 INFO     Training average positive_sample_loss at step 554800: 0.155006\n",
      "2022-11-08 21:08:59,828 INFO     Training average negative_sample_loss at step 554800: 0.149806\n",
      "2022-11-08 21:08:59,828 INFO     Training average loss at step 554800: 0.152406\n",
      "2022-11-08 21:09:09,519 INFO     Training average positive_sample_loss at step 554900: 0.148693\n",
      "2022-11-08 21:09:09,519 INFO     Training average negative_sample_loss at step 554900: 0.148595\n",
      "2022-11-08 21:09:09,519 INFO     Training average loss at step 554900: 0.148644\n",
      "2022-11-08 21:09:19,210 INFO     Training average positive_sample_loss at step 555000: 0.151623\n",
      "2022-11-08 21:09:19,210 INFO     Training average negative_sample_loss at step 555000: 0.147786\n",
      "2022-11-08 21:09:19,210 INFO     Training average loss at step 555000: 0.149705\n",
      "2022-11-08 21:09:28,900 INFO     Training average positive_sample_loss at step 555100: 0.152060\n",
      "2022-11-08 21:09:28,900 INFO     Training average negative_sample_loss at step 555100: 0.153375\n",
      "2022-11-08 21:09:28,900 INFO     Training average loss at step 555100: 0.152717\n",
      "2022-11-08 21:09:38,596 INFO     Training average positive_sample_loss at step 555200: 0.150866\n",
      "2022-11-08 21:09:38,596 INFO     Training average negative_sample_loss at step 555200: 0.146746\n",
      "2022-11-08 21:09:38,596 INFO     Training average loss at step 555200: 0.148806\n",
      "2022-11-08 21:09:48,289 INFO     Training average positive_sample_loss at step 555300: 0.149282\n",
      "2022-11-08 21:09:48,289 INFO     Training average negative_sample_loss at step 555300: 0.147522\n",
      "2022-11-08 21:09:48,289 INFO     Training average loss at step 555300: 0.148402\n",
      "2022-11-08 21:09:57,980 INFO     Training average positive_sample_loss at step 555400: 0.150762\n",
      "2022-11-08 21:09:57,981 INFO     Training average negative_sample_loss at step 555400: 0.148402\n",
      "2022-11-08 21:09:57,981 INFO     Training average loss at step 555400: 0.149582\n",
      "2022-11-08 21:10:07,673 INFO     Training average positive_sample_loss at step 555500: 0.150440\n",
      "2022-11-08 21:10:07,673 INFO     Training average negative_sample_loss at step 555500: 0.147308\n",
      "2022-11-08 21:10:07,673 INFO     Training average loss at step 555500: 0.148874\n",
      "2022-11-08 21:10:17,366 INFO     Training average positive_sample_loss at step 555600: 0.147637\n",
      "2022-11-08 21:10:17,366 INFO     Training average negative_sample_loss at step 555600: 0.149024\n",
      "2022-11-08 21:10:17,366 INFO     Training average loss at step 555600: 0.148330\n",
      "2022-11-08 21:10:27,058 INFO     Training average positive_sample_loss at step 555700: 0.149035\n",
      "2022-11-08 21:10:27,058 INFO     Training average negative_sample_loss at step 555700: 0.147147\n",
      "2022-11-08 21:10:27,058 INFO     Training average loss at step 555700: 0.148091\n",
      "2022-11-08 21:10:36,752 INFO     Training average positive_sample_loss at step 555800: 0.152867\n",
      "2022-11-08 21:10:36,752 INFO     Training average negative_sample_loss at step 555800: 0.151729\n",
      "2022-11-08 21:10:36,752 INFO     Training average loss at step 555800: 0.152298\n",
      "2022-11-08 21:10:46,442 INFO     Training average positive_sample_loss at step 555900: 0.156373\n",
      "2022-11-08 21:10:46,442 INFO     Training average negative_sample_loss at step 555900: 0.142942\n",
      "2022-11-08 21:10:46,442 INFO     Training average loss at step 555900: 0.149658\n",
      "2022-11-08 21:10:56,133 INFO     Training average positive_sample_loss at step 556000: 0.151247\n",
      "2022-11-08 21:10:56,133 INFO     Training average negative_sample_loss at step 556000: 0.150792\n",
      "2022-11-08 21:10:56,133 INFO     Training average loss at step 556000: 0.151019\n",
      "2022-11-08 21:11:05,831 INFO     Training average positive_sample_loss at step 556100: 0.149735\n",
      "2022-11-08 21:11:05,831 INFO     Training average negative_sample_loss at step 556100: 0.149735\n",
      "2022-11-08 21:11:05,831 INFO     Training average loss at step 556100: 0.149735\n",
      "2022-11-08 21:11:15,521 INFO     Training average positive_sample_loss at step 556200: 0.144031\n",
      "2022-11-08 21:11:15,521 INFO     Training average negative_sample_loss at step 556200: 0.148071\n",
      "2022-11-08 21:11:15,521 INFO     Training average loss at step 556200: 0.146051\n",
      "2022-11-08 21:11:25,212 INFO     Training average positive_sample_loss at step 556300: 0.156295\n",
      "2022-11-08 21:11:25,212 INFO     Training average negative_sample_loss at step 556300: 0.147953\n",
      "2022-11-08 21:11:25,212 INFO     Training average loss at step 556300: 0.152124\n",
      "2022-11-08 21:11:34,910 INFO     Training average positive_sample_loss at step 556400: 0.151858\n",
      "2022-11-08 21:11:34,910 INFO     Training average negative_sample_loss at step 556400: 0.148425\n",
      "2022-11-08 21:11:34,910 INFO     Training average loss at step 556400: 0.150142\n",
      "2022-11-08 21:11:44,599 INFO     Training average positive_sample_loss at step 556500: 0.150414\n",
      "2022-11-08 21:11:44,599 INFO     Training average negative_sample_loss at step 556500: 0.144374\n",
      "2022-11-08 21:11:44,599 INFO     Training average loss at step 556500: 0.147394\n",
      "2022-11-08 21:11:54,289 INFO     Training average positive_sample_loss at step 556600: 0.150657\n",
      "2022-11-08 21:11:54,289 INFO     Training average negative_sample_loss at step 556600: 0.144818\n",
      "2022-11-08 21:11:54,289 INFO     Training average loss at step 556600: 0.147737\n",
      "2022-11-08 21:12:03,984 INFO     Training average positive_sample_loss at step 556700: 0.148800\n",
      "2022-11-08 21:12:03,984 INFO     Training average negative_sample_loss at step 556700: 0.152420\n",
      "2022-11-08 21:12:03,984 INFO     Training average loss at step 556700: 0.150610\n",
      "2022-11-08 21:12:13,675 INFO     Training average positive_sample_loss at step 556800: 0.154593\n",
      "2022-11-08 21:12:13,675 INFO     Training average negative_sample_loss at step 556800: 0.150949\n",
      "2022-11-08 21:12:13,675 INFO     Training average loss at step 556800: 0.152771\n",
      "2022-11-08 21:12:23,367 INFO     Training average positive_sample_loss at step 556900: 0.149602\n",
      "2022-11-08 21:12:23,367 INFO     Training average negative_sample_loss at step 556900: 0.150477\n",
      "2022-11-08 21:12:23,367 INFO     Training average loss at step 556900: 0.150040\n",
      "2022-11-08 21:12:33,057 INFO     Training average positive_sample_loss at step 557000: 0.150912\n",
      "2022-11-08 21:12:33,057 INFO     Training average negative_sample_loss at step 557000: 0.147276\n",
      "2022-11-08 21:12:33,057 INFO     Training average loss at step 557000: 0.149094\n",
      "2022-11-08 21:12:42,746 INFO     Training average positive_sample_loss at step 557100: 0.147613\n",
      "2022-11-08 21:12:42,746 INFO     Training average negative_sample_loss at step 557100: 0.146184\n",
      "2022-11-08 21:12:42,746 INFO     Training average loss at step 557100: 0.146899\n",
      "2022-11-08 21:12:52,439 INFO     Training average positive_sample_loss at step 557200: 0.150010\n",
      "2022-11-08 21:12:52,439 INFO     Training average negative_sample_loss at step 557200: 0.146729\n",
      "2022-11-08 21:12:52,439 INFO     Training average loss at step 557200: 0.148369\n",
      "2022-11-08 21:13:02,135 INFO     Training average positive_sample_loss at step 557300: 0.155616\n",
      "2022-11-08 21:13:02,135 INFO     Training average negative_sample_loss at step 557300: 0.148493\n",
      "2022-11-08 21:13:02,135 INFO     Training average loss at step 557300: 0.152055\n",
      "2022-11-08 21:13:11,832 INFO     Training average positive_sample_loss at step 557400: 0.146548\n",
      "2022-11-08 21:13:11,832 INFO     Training average negative_sample_loss at step 557400: 0.147199\n",
      "2022-11-08 21:13:11,832 INFO     Training average loss at step 557400: 0.146874\n",
      "2022-11-08 21:13:21,524 INFO     Training average positive_sample_loss at step 557500: 0.154655\n",
      "2022-11-08 21:13:21,524 INFO     Training average negative_sample_loss at step 557500: 0.145967\n",
      "2022-11-08 21:13:21,524 INFO     Training average loss at step 557500: 0.150311\n",
      "2022-11-08 21:13:31,214 INFO     Training average positive_sample_loss at step 557600: 0.153630\n",
      "2022-11-08 21:13:31,214 INFO     Training average negative_sample_loss at step 557600: 0.148808\n",
      "2022-11-08 21:13:31,214 INFO     Training average loss at step 557600: 0.151219\n",
      "2022-11-08 21:13:40,908 INFO     Training average positive_sample_loss at step 557700: 0.156671\n",
      "2022-11-08 21:13:40,909 INFO     Training average negative_sample_loss at step 557700: 0.148771\n",
      "2022-11-08 21:13:40,909 INFO     Training average loss at step 557700: 0.152721\n",
      "2022-11-08 21:13:50,601 INFO     Training average positive_sample_loss at step 557800: 0.158305\n",
      "2022-11-08 21:13:50,601 INFO     Training average negative_sample_loss at step 557800: 0.149481\n",
      "2022-11-08 21:13:50,601 INFO     Training average loss at step 557800: 0.153893\n",
      "2022-11-08 21:14:00,295 INFO     Training average positive_sample_loss at step 557900: 0.152605\n",
      "2022-11-08 21:14:00,295 INFO     Training average negative_sample_loss at step 557900: 0.146979\n",
      "2022-11-08 21:14:00,295 INFO     Training average loss at step 557900: 0.149792\n",
      "2022-11-08 21:14:09,988 INFO     Training average positive_sample_loss at step 558000: 0.150884\n",
      "2022-11-08 21:14:09,988 INFO     Training average negative_sample_loss at step 558000: 0.149862\n",
      "2022-11-08 21:14:09,988 INFO     Training average loss at step 558000: 0.150373\n",
      "2022-11-08 21:14:19,677 INFO     Training average positive_sample_loss at step 558100: 0.156601\n",
      "2022-11-08 21:14:19,677 INFO     Training average negative_sample_loss at step 558100: 0.145883\n",
      "2022-11-08 21:14:19,677 INFO     Training average loss at step 558100: 0.151242\n",
      "2022-11-08 21:14:29,367 INFO     Training average positive_sample_loss at step 558200: 0.148330\n",
      "2022-11-08 21:14:29,367 INFO     Training average negative_sample_loss at step 558200: 0.146244\n",
      "2022-11-08 21:14:29,367 INFO     Training average loss at step 558200: 0.147287\n",
      "2022-11-08 21:14:39,059 INFO     Training average positive_sample_loss at step 558300: 0.152210\n",
      "2022-11-08 21:14:39,059 INFO     Training average negative_sample_loss at step 558300: 0.145315\n",
      "2022-11-08 21:14:39,059 INFO     Training average loss at step 558300: 0.148762\n",
      "2022-11-08 21:14:48,750 INFO     Training average positive_sample_loss at step 558400: 0.150256\n",
      "2022-11-08 21:14:48,750 INFO     Training average negative_sample_loss at step 558400: 0.144674\n",
      "2022-11-08 21:14:48,750 INFO     Training average loss at step 558400: 0.147465\n",
      "2022-11-08 21:14:58,443 INFO     Training average positive_sample_loss at step 558500: 0.147736\n",
      "2022-11-08 21:14:58,443 INFO     Training average negative_sample_loss at step 558500: 0.147925\n",
      "2022-11-08 21:14:58,443 INFO     Training average loss at step 558500: 0.147830\n",
      "2022-11-08 21:15:08,140 INFO     Training average positive_sample_loss at step 558600: 0.157304\n",
      "2022-11-08 21:15:08,140 INFO     Training average negative_sample_loss at step 558600: 0.145918\n",
      "2022-11-08 21:15:08,140 INFO     Training average loss at step 558600: 0.151611\n",
      "2022-11-08 21:15:17,828 INFO     Training average positive_sample_loss at step 558700: 0.147985\n",
      "2022-11-08 21:15:17,828 INFO     Training average negative_sample_loss at step 558700: 0.147305\n",
      "2022-11-08 21:15:17,828 INFO     Training average loss at step 558700: 0.147645\n",
      "2022-11-08 21:15:27,523 INFO     Training average positive_sample_loss at step 558800: 0.152072\n",
      "2022-11-08 21:15:27,523 INFO     Training average negative_sample_loss at step 558800: 0.149586\n",
      "2022-11-08 21:15:27,523 INFO     Training average loss at step 558800: 0.150829\n",
      "2022-11-08 21:15:37,218 INFO     Training average positive_sample_loss at step 558900: 0.149944\n",
      "2022-11-08 21:15:37,218 INFO     Training average negative_sample_loss at step 558900: 0.145785\n",
      "2022-11-08 21:15:37,218 INFO     Training average loss at step 558900: 0.147864\n",
      "2022-11-08 21:15:46,910 INFO     Training average positive_sample_loss at step 559000: 0.153108\n",
      "2022-11-08 21:15:46,910 INFO     Training average negative_sample_loss at step 559000: 0.140062\n",
      "2022-11-08 21:15:46,910 INFO     Training average loss at step 559000: 0.146585\n",
      "2022-11-08 21:15:56,605 INFO     Training average positive_sample_loss at step 559100: 0.151889\n",
      "2022-11-08 21:15:56,605 INFO     Training average negative_sample_loss at step 559100: 0.141943\n",
      "2022-11-08 21:15:56,605 INFO     Training average loss at step 559100: 0.146916\n",
      "2022-11-08 21:16:06,294 INFO     Training average positive_sample_loss at step 559200: 0.156132\n",
      "2022-11-08 21:16:06,294 INFO     Training average negative_sample_loss at step 559200: 0.150509\n",
      "2022-11-08 21:16:06,294 INFO     Training average loss at step 559200: 0.153321\n",
      "2022-11-08 21:16:15,325 INFO     Training average positive_sample_loss at step 559300: 0.152268\n",
      "2022-11-08 21:16:15,325 INFO     Training average negative_sample_loss at step 559300: 0.143124\n",
      "2022-11-08 21:16:15,325 INFO     Training average loss at step 559300: 0.147696\n",
      "2022-11-08 21:16:25,016 INFO     Training average positive_sample_loss at step 559400: 0.147118\n",
      "2022-11-08 21:16:25,017 INFO     Training average negative_sample_loss at step 559400: 0.143835\n",
      "2022-11-08 21:16:25,017 INFO     Training average loss at step 559400: 0.145477\n",
      "2022-11-08 21:16:34,710 INFO     Training average positive_sample_loss at step 559500: 0.152131\n",
      "2022-11-08 21:16:34,710 INFO     Training average negative_sample_loss at step 559500: 0.150101\n",
      "2022-11-08 21:16:34,710 INFO     Training average loss at step 559500: 0.151116\n",
      "2022-11-08 21:16:44,401 INFO     Training average positive_sample_loss at step 559600: 0.145054\n",
      "2022-11-08 21:16:44,401 INFO     Training average negative_sample_loss at step 559600: 0.149918\n",
      "2022-11-08 21:16:44,401 INFO     Training average loss at step 559600: 0.147486\n",
      "2022-11-08 21:16:54,095 INFO     Training average positive_sample_loss at step 559700: 0.153505\n",
      "2022-11-08 21:16:54,095 INFO     Training average negative_sample_loss at step 559700: 0.147337\n",
      "2022-11-08 21:16:54,095 INFO     Training average loss at step 559700: 0.150421\n",
      "2022-11-08 21:17:03,792 INFO     Training average positive_sample_loss at step 559800: 0.156071\n",
      "2022-11-08 21:17:03,792 INFO     Training average negative_sample_loss at step 559800: 0.150692\n",
      "2022-11-08 21:17:03,792 INFO     Training average loss at step 559800: 0.153381\n",
      "2022-11-08 21:17:12,753 INFO     Training average positive_sample_loss at step 559900: 0.154582\n",
      "2022-11-08 21:17:12,753 INFO     Training average negative_sample_loss at step 559900: 0.145550\n",
      "2022-11-08 21:17:12,753 INFO     Training average loss at step 559900: 0.150066\n",
      "2022-11-08 21:17:25,365 INFO     Training average positive_sample_loss at step 560000: 0.156375\n",
      "2022-11-08 21:17:25,365 INFO     Training average negative_sample_loss at step 560000: 0.149143\n",
      "2022-11-08 21:17:25,365 INFO     Training average loss at step 560000: 0.152759\n",
      "2022-11-08 21:17:35,054 INFO     Training average positive_sample_loss at step 560100: 0.147476\n",
      "2022-11-08 21:17:35,054 INFO     Training average negative_sample_loss at step 560100: 0.143227\n",
      "2022-11-08 21:17:35,054 INFO     Training average loss at step 560100: 0.145351\n",
      "2022-11-08 21:17:44,743 INFO     Training average positive_sample_loss at step 560200: 0.154873\n",
      "2022-11-08 21:17:44,743 INFO     Training average negative_sample_loss at step 560200: 0.145075\n",
      "2022-11-08 21:17:44,743 INFO     Training average loss at step 560200: 0.149974\n",
      "2022-11-08 21:17:54,443 INFO     Training average positive_sample_loss at step 560300: 0.150745\n",
      "2022-11-08 21:17:54,443 INFO     Training average negative_sample_loss at step 560300: 0.146982\n",
      "2022-11-08 21:17:54,443 INFO     Training average loss at step 560300: 0.148864\n",
      "2022-11-08 21:18:04,134 INFO     Training average positive_sample_loss at step 560400: 0.153796\n",
      "2022-11-08 21:18:04,134 INFO     Training average negative_sample_loss at step 560400: 0.147473\n",
      "2022-11-08 21:18:04,134 INFO     Training average loss at step 560400: 0.150634\n",
      "2022-11-08 21:18:13,824 INFO     Training average positive_sample_loss at step 560500: 0.154755\n",
      "2022-11-08 21:18:13,824 INFO     Training average negative_sample_loss at step 560500: 0.139308\n",
      "2022-11-08 21:18:13,824 INFO     Training average loss at step 560500: 0.147032\n",
      "2022-11-08 21:18:23,519 INFO     Training average positive_sample_loss at step 560600: 0.151662\n",
      "2022-11-08 21:18:23,519 INFO     Training average negative_sample_loss at step 560600: 0.143255\n",
      "2022-11-08 21:18:23,519 INFO     Training average loss at step 560600: 0.147459\n",
      "2022-11-08 21:18:33,210 INFO     Training average positive_sample_loss at step 560700: 0.155911\n",
      "2022-11-08 21:18:33,210 INFO     Training average negative_sample_loss at step 560700: 0.144114\n",
      "2022-11-08 21:18:33,210 INFO     Training average loss at step 560700: 0.150012\n",
      "2022-11-08 21:18:42,900 INFO     Training average positive_sample_loss at step 560800: 0.149865\n",
      "2022-11-08 21:18:42,900 INFO     Training average negative_sample_loss at step 560800: 0.147815\n",
      "2022-11-08 21:18:42,900 INFO     Training average loss at step 560800: 0.148840\n",
      "2022-11-08 21:18:52,597 INFO     Training average positive_sample_loss at step 560900: 0.155523\n",
      "2022-11-08 21:18:52,597 INFO     Training average negative_sample_loss at step 560900: 0.140866\n",
      "2022-11-08 21:18:52,597 INFO     Training average loss at step 560900: 0.148194\n",
      "2022-11-08 21:19:02,288 INFO     Training average positive_sample_loss at step 561000: 0.150562\n",
      "2022-11-08 21:19:02,289 INFO     Training average negative_sample_loss at step 561000: 0.146520\n",
      "2022-11-08 21:19:02,289 INFO     Training average loss at step 561000: 0.148541\n",
      "2022-11-08 21:19:11,980 INFO     Training average positive_sample_loss at step 561100: 0.151874\n",
      "2022-11-08 21:19:11,980 INFO     Training average negative_sample_loss at step 561100: 0.145594\n",
      "2022-11-08 21:19:11,980 INFO     Training average loss at step 561100: 0.148734\n",
      "2022-11-08 21:19:21,673 INFO     Training average positive_sample_loss at step 561200: 0.153784\n",
      "2022-11-08 21:19:21,673 INFO     Training average negative_sample_loss at step 561200: 0.141004\n",
      "2022-11-08 21:19:21,673 INFO     Training average loss at step 561200: 0.147394\n",
      "2022-11-08 21:19:31,360 INFO     Training average positive_sample_loss at step 561300: 0.151807\n",
      "2022-11-08 21:19:31,360 INFO     Training average negative_sample_loss at step 561300: 0.147676\n",
      "2022-11-08 21:19:31,360 INFO     Training average loss at step 561300: 0.149741\n",
      "2022-11-08 21:19:41,053 INFO     Training average positive_sample_loss at step 561400: 0.160202\n",
      "2022-11-08 21:19:41,053 INFO     Training average negative_sample_loss at step 561400: 0.141223\n",
      "2022-11-08 21:19:41,053 INFO     Training average loss at step 561400: 0.150713\n",
      "2022-11-08 21:19:50,745 INFO     Training average positive_sample_loss at step 561500: 0.155931\n",
      "2022-11-08 21:19:50,746 INFO     Training average negative_sample_loss at step 561500: 0.142161\n",
      "2022-11-08 21:19:50,746 INFO     Training average loss at step 561500: 0.149046\n",
      "2022-11-08 21:20:00,437 INFO     Training average positive_sample_loss at step 561600: 0.154553\n",
      "2022-11-08 21:20:00,437 INFO     Training average negative_sample_loss at step 561600: 0.145131\n",
      "2022-11-08 21:20:00,437 INFO     Training average loss at step 561600: 0.149842\n",
      "2022-11-08 21:20:10,128 INFO     Training average positive_sample_loss at step 561700: 0.161711\n",
      "2022-11-08 21:20:10,128 INFO     Training average negative_sample_loss at step 561700: 0.143643\n",
      "2022-11-08 21:20:10,128 INFO     Training average loss at step 561700: 0.152677\n",
      "2022-11-08 21:20:19,819 INFO     Training average positive_sample_loss at step 561800: 0.153395\n",
      "2022-11-08 21:20:19,819 INFO     Training average negative_sample_loss at step 561800: 0.146932\n",
      "2022-11-08 21:20:19,819 INFO     Training average loss at step 561800: 0.150163\n",
      "2022-11-08 21:20:29,508 INFO     Training average positive_sample_loss at step 561900: 0.150919\n",
      "2022-11-08 21:20:29,508 INFO     Training average negative_sample_loss at step 561900: 0.149448\n",
      "2022-11-08 21:20:29,508 INFO     Training average loss at step 561900: 0.150183\n",
      "2022-11-08 21:20:39,199 INFO     Training average positive_sample_loss at step 562000: 0.152426\n",
      "2022-11-08 21:20:39,199 INFO     Training average negative_sample_loss at step 562000: 0.150077\n",
      "2022-11-08 21:20:39,199 INFO     Training average loss at step 562000: 0.151251\n",
      "2022-11-08 21:20:48,890 INFO     Training average positive_sample_loss at step 562100: 0.150084\n",
      "2022-11-08 21:20:48,890 INFO     Training average negative_sample_loss at step 562100: 0.145614\n",
      "2022-11-08 21:20:48,890 INFO     Training average loss at step 562100: 0.147849\n",
      "2022-11-08 21:20:58,583 INFO     Training average positive_sample_loss at step 562200: 0.149716\n",
      "2022-11-08 21:20:58,583 INFO     Training average negative_sample_loss at step 562200: 0.144879\n",
      "2022-11-08 21:20:58,583 INFO     Training average loss at step 562200: 0.147297\n",
      "2022-11-08 21:21:08,280 INFO     Training average positive_sample_loss at step 562300: 0.152912\n",
      "2022-11-08 21:21:08,280 INFO     Training average negative_sample_loss at step 562300: 0.144445\n",
      "2022-11-08 21:21:08,280 INFO     Training average loss at step 562300: 0.148679\n",
      "2022-11-08 21:21:17,972 INFO     Training average positive_sample_loss at step 562400: 0.155162\n",
      "2022-11-08 21:21:17,973 INFO     Training average negative_sample_loss at step 562400: 0.147658\n",
      "2022-11-08 21:21:17,973 INFO     Training average loss at step 562400: 0.151410\n",
      "2022-11-08 21:21:27,664 INFO     Training average positive_sample_loss at step 562500: 0.154094\n",
      "2022-11-08 21:21:27,664 INFO     Training average negative_sample_loss at step 562500: 0.148393\n",
      "2022-11-08 21:21:27,664 INFO     Training average loss at step 562500: 0.151243\n",
      "2022-11-08 21:21:37,354 INFO     Training average positive_sample_loss at step 562600: 0.153422\n",
      "2022-11-08 21:21:37,354 INFO     Training average negative_sample_loss at step 562600: 0.145237\n",
      "2022-11-08 21:21:37,354 INFO     Training average loss at step 562600: 0.149329\n",
      "2022-11-08 21:21:47,045 INFO     Training average positive_sample_loss at step 562700: 0.151019\n",
      "2022-11-08 21:21:47,045 INFO     Training average negative_sample_loss at step 562700: 0.144318\n",
      "2022-11-08 21:21:47,045 INFO     Training average loss at step 562700: 0.147668\n",
      "2022-11-08 21:21:56,737 INFO     Training average positive_sample_loss at step 562800: 0.149101\n",
      "2022-11-08 21:21:56,737 INFO     Training average negative_sample_loss at step 562800: 0.146673\n",
      "2022-11-08 21:21:56,738 INFO     Training average loss at step 562800: 0.147887\n",
      "2022-11-08 21:22:06,427 INFO     Training average positive_sample_loss at step 562900: 0.149153\n",
      "2022-11-08 21:22:06,427 INFO     Training average negative_sample_loss at step 562900: 0.143132\n",
      "2022-11-08 21:22:06,427 INFO     Training average loss at step 562900: 0.146143\n",
      "2022-11-08 21:22:16,119 INFO     Training average positive_sample_loss at step 563000: 0.152837\n",
      "2022-11-08 21:22:16,119 INFO     Training average negative_sample_loss at step 563000: 0.145534\n",
      "2022-11-08 21:22:16,119 INFO     Training average loss at step 563000: 0.149185\n",
      "2022-11-08 21:22:25,532 INFO     Training average positive_sample_loss at step 563100: 0.155208\n",
      "2022-11-08 21:22:25,532 INFO     Training average negative_sample_loss at step 563100: 0.153254\n",
      "2022-11-08 21:22:25,532 INFO     Training average loss at step 563100: 0.154231\n",
      "2022-11-08 21:22:33,828 INFO     Training average positive_sample_loss at step 563200: 0.156558\n",
      "2022-11-08 21:22:33,828 INFO     Training average negative_sample_loss at step 563200: 0.146510\n",
      "2022-11-08 21:22:33,828 INFO     Training average loss at step 563200: 0.151534\n",
      "2022-11-08 21:22:43,521 INFO     Training average positive_sample_loss at step 563300: 0.153728\n",
      "2022-11-08 21:22:43,522 INFO     Training average negative_sample_loss at step 563300: 0.145326\n",
      "2022-11-08 21:22:43,522 INFO     Training average loss at step 563300: 0.149527\n",
      "2022-11-08 21:22:53,213 INFO     Training average positive_sample_loss at step 563400: 0.156427\n",
      "2022-11-08 21:22:53,213 INFO     Training average negative_sample_loss at step 563400: 0.146673\n",
      "2022-11-08 21:22:53,213 INFO     Training average loss at step 563400: 0.151550\n",
      "2022-11-08 21:23:02,903 INFO     Training average positive_sample_loss at step 563500: 0.150341\n",
      "2022-11-08 21:23:02,903 INFO     Training average negative_sample_loss at step 563500: 0.144359\n",
      "2022-11-08 21:23:02,903 INFO     Training average loss at step 563500: 0.147350\n",
      "2022-11-08 21:23:12,598 INFO     Training average positive_sample_loss at step 563600: 0.156049\n",
      "2022-11-08 21:23:12,598 INFO     Training average negative_sample_loss at step 563600: 0.147022\n",
      "2022-11-08 21:23:12,598 INFO     Training average loss at step 563600: 0.151536\n",
      "2022-11-08 21:23:22,290 INFO     Training average positive_sample_loss at step 563700: 0.154551\n",
      "2022-11-08 21:23:22,291 INFO     Training average negative_sample_loss at step 563700: 0.143069\n",
      "2022-11-08 21:23:22,291 INFO     Training average loss at step 563700: 0.148810\n",
      "2022-11-08 21:23:31,985 INFO     Training average positive_sample_loss at step 563800: 0.151526\n",
      "2022-11-08 21:23:31,985 INFO     Training average negative_sample_loss at step 563800: 0.145425\n",
      "2022-11-08 21:23:31,985 INFO     Training average loss at step 563800: 0.148476\n",
      "2022-11-08 21:23:41,679 INFO     Training average positive_sample_loss at step 563900: 0.154844\n",
      "2022-11-08 21:23:41,679 INFO     Training average negative_sample_loss at step 563900: 0.145650\n",
      "2022-11-08 21:23:41,679 INFO     Training average loss at step 563900: 0.150247\n",
      "2022-11-08 21:23:51,367 INFO     Training average positive_sample_loss at step 564000: 0.152627\n",
      "2022-11-08 21:23:51,368 INFO     Training average negative_sample_loss at step 564000: 0.146521\n",
      "2022-11-08 21:23:51,368 INFO     Training average loss at step 564000: 0.149574\n",
      "2022-11-08 21:24:01,062 INFO     Training average positive_sample_loss at step 564100: 0.153432\n",
      "2022-11-08 21:24:01,062 INFO     Training average negative_sample_loss at step 564100: 0.146637\n",
      "2022-11-08 21:24:01,062 INFO     Training average loss at step 564100: 0.150035\n",
      "2022-11-08 21:24:11,159 INFO     Training average positive_sample_loss at step 564200: 0.154502\n",
      "2022-11-08 21:24:11,159 INFO     Training average negative_sample_loss at step 564200: 0.144407\n",
      "2022-11-08 21:24:11,159 INFO     Training average loss at step 564200: 0.149455\n",
      "2022-11-08 21:24:23,528 INFO     Training average positive_sample_loss at step 564300: 0.156808\n",
      "2022-11-08 21:24:23,528 INFO     Training average negative_sample_loss at step 564300: 0.146743\n",
      "2022-11-08 21:24:23,528 INFO     Training average loss at step 564300: 0.151776\n",
      "2022-11-08 21:24:33,220 INFO     Training average positive_sample_loss at step 564400: 0.153309\n",
      "2022-11-08 21:24:33,220 INFO     Training average negative_sample_loss at step 564400: 0.149438\n",
      "2022-11-08 21:24:33,220 INFO     Training average loss at step 564400: 0.151373\n",
      "2022-11-08 21:24:42,912 INFO     Training average positive_sample_loss at step 564500: 0.149817\n",
      "2022-11-08 21:24:42,912 INFO     Training average negative_sample_loss at step 564500: 0.143086\n",
      "2022-11-08 21:24:42,912 INFO     Training average loss at step 564500: 0.146451\n",
      "2022-11-08 21:24:52,601 INFO     Training average positive_sample_loss at step 564600: 0.153898\n",
      "2022-11-08 21:24:52,601 INFO     Training average negative_sample_loss at step 564600: 0.141322\n",
      "2022-11-08 21:24:52,601 INFO     Training average loss at step 564600: 0.147610\n",
      "2022-11-08 21:25:02,297 INFO     Training average positive_sample_loss at step 564700: 0.150760\n",
      "2022-11-08 21:25:02,298 INFO     Training average negative_sample_loss at step 564700: 0.143645\n",
      "2022-11-08 21:25:02,298 INFO     Training average loss at step 564700: 0.147202\n",
      "2022-11-08 21:25:11,289 INFO     Training average positive_sample_loss at step 564800: 0.152729\n",
      "2022-11-08 21:25:11,289 INFO     Training average negative_sample_loss at step 564800: 0.143413\n",
      "2022-11-08 21:25:11,289 INFO     Training average loss at step 564800: 0.148071\n",
      "2022-11-08 21:25:20,978 INFO     Training average positive_sample_loss at step 564900: 0.156125\n",
      "2022-11-08 21:25:20,978 INFO     Training average negative_sample_loss at step 564900: 0.149642\n",
      "2022-11-08 21:25:20,978 INFO     Training average loss at step 564900: 0.152883\n",
      "2022-11-08 21:25:30,670 INFO     Training average positive_sample_loss at step 565000: 0.152277\n",
      "2022-11-08 21:25:30,670 INFO     Training average negative_sample_loss at step 565000: 0.141139\n",
      "2022-11-08 21:25:30,670 INFO     Training average loss at step 565000: 0.146708\n",
      "2022-11-08 21:25:40,365 INFO     Training average positive_sample_loss at step 565100: 0.149978\n",
      "2022-11-08 21:25:40,365 INFO     Training average negative_sample_loss at step 565100: 0.145413\n",
      "2022-11-08 21:25:40,365 INFO     Training average loss at step 565100: 0.147695\n",
      "2022-11-08 21:25:50,052 INFO     Training average positive_sample_loss at step 565200: 0.150510\n",
      "2022-11-08 21:25:50,052 INFO     Training average negative_sample_loss at step 565200: 0.143755\n",
      "2022-11-08 21:25:50,052 INFO     Training average loss at step 565200: 0.147133\n",
      "2022-11-08 21:25:59,746 INFO     Training average positive_sample_loss at step 565300: 0.146299\n",
      "2022-11-08 21:25:59,746 INFO     Training average negative_sample_loss at step 565300: 0.142706\n",
      "2022-11-08 21:25:59,746 INFO     Training average loss at step 565300: 0.144502\n",
      "2022-11-08 21:26:08,729 INFO     Training average positive_sample_loss at step 565400: 0.153771\n",
      "2022-11-08 21:26:08,729 INFO     Training average negative_sample_loss at step 565400: 0.144133\n",
      "2022-11-08 21:26:08,729 INFO     Training average loss at step 565400: 0.148952\n",
      "2022-11-08 21:26:18,421 INFO     Training average positive_sample_loss at step 565500: 0.154274\n",
      "2022-11-08 21:26:18,422 INFO     Training average negative_sample_loss at step 565500: 0.142556\n",
      "2022-11-08 21:26:18,422 INFO     Training average loss at step 565500: 0.148415\n",
      "2022-11-08 21:26:28,116 INFO     Training average positive_sample_loss at step 565600: 0.150747\n",
      "2022-11-08 21:26:28,116 INFO     Training average negative_sample_loss at step 565600: 0.144399\n",
      "2022-11-08 21:26:28,116 INFO     Training average loss at step 565600: 0.147573\n",
      "2022-11-08 21:26:37,806 INFO     Training average positive_sample_loss at step 565700: 0.156959\n",
      "2022-11-08 21:26:37,806 INFO     Training average negative_sample_loss at step 565700: 0.143656\n",
      "2022-11-08 21:26:37,806 INFO     Training average loss at step 565700: 0.150307\n",
      "2022-11-08 21:26:47,495 INFO     Training average positive_sample_loss at step 565800: 0.149894\n",
      "2022-11-08 21:26:47,495 INFO     Training average negative_sample_loss at step 565800: 0.142630\n",
      "2022-11-08 21:26:47,495 INFO     Training average loss at step 565800: 0.146262\n",
      "2022-11-08 21:26:57,187 INFO     Training average positive_sample_loss at step 565900: 0.148266\n",
      "2022-11-08 21:26:57,187 INFO     Training average negative_sample_loss at step 565900: 0.142872\n",
      "2022-11-08 21:26:57,188 INFO     Training average loss at step 565900: 0.145569\n",
      "2022-11-08 21:27:06,883 INFO     Training average positive_sample_loss at step 566000: 0.150493\n",
      "2022-11-08 21:27:06,883 INFO     Training average negative_sample_loss at step 566000: 0.142558\n",
      "2022-11-08 21:27:06,883 INFO     Training average loss at step 566000: 0.146526\n",
      "2022-11-08 21:27:16,575 INFO     Training average positive_sample_loss at step 566100: 0.149651\n",
      "2022-11-08 21:27:16,575 INFO     Training average negative_sample_loss at step 566100: 0.147378\n",
      "2022-11-08 21:27:16,575 INFO     Training average loss at step 566100: 0.148514\n",
      "2022-11-08 21:27:26,265 INFO     Training average positive_sample_loss at step 566200: 0.152189\n",
      "2022-11-08 21:27:26,265 INFO     Training average negative_sample_loss at step 566200: 0.151813\n",
      "2022-11-08 21:27:26,265 INFO     Training average loss at step 566200: 0.152001\n",
      "2022-11-08 21:27:35,955 INFO     Training average positive_sample_loss at step 566300: 0.155023\n",
      "2022-11-08 21:27:35,956 INFO     Training average negative_sample_loss at step 566300: 0.141211\n",
      "2022-11-08 21:27:35,956 INFO     Training average loss at step 566300: 0.148117\n",
      "2022-11-08 21:27:45,651 INFO     Training average positive_sample_loss at step 566400: 0.151749\n",
      "2022-11-08 21:27:45,651 INFO     Training average negative_sample_loss at step 566400: 0.141240\n",
      "2022-11-08 21:27:45,651 INFO     Training average loss at step 566400: 0.146494\n",
      "2022-11-08 21:27:55,344 INFO     Training average positive_sample_loss at step 566500: 0.150806\n",
      "2022-11-08 21:27:55,344 INFO     Training average negative_sample_loss at step 566500: 0.145381\n",
      "2022-11-08 21:27:55,344 INFO     Training average loss at step 566500: 0.148093\n",
      "2022-11-08 21:28:05,038 INFO     Training average positive_sample_loss at step 566600: 0.147847\n",
      "2022-11-08 21:28:05,039 INFO     Training average negative_sample_loss at step 566600: 0.144472\n",
      "2022-11-08 21:28:05,039 INFO     Training average loss at step 566600: 0.146159\n",
      "2022-11-08 21:28:14,729 INFO     Training average positive_sample_loss at step 566700: 0.154125\n",
      "2022-11-08 21:28:14,729 INFO     Training average negative_sample_loss at step 566700: 0.144117\n",
      "2022-11-08 21:28:14,729 INFO     Training average loss at step 566700: 0.149121\n",
      "2022-11-08 21:28:24,417 INFO     Training average positive_sample_loss at step 566800: 0.153498\n",
      "2022-11-08 21:28:24,417 INFO     Training average negative_sample_loss at step 566800: 0.141892\n",
      "2022-11-08 21:28:24,417 INFO     Training average loss at step 566800: 0.147695\n",
      "2022-11-08 21:28:34,112 INFO     Training average positive_sample_loss at step 566900: 0.156956\n",
      "2022-11-08 21:28:34,112 INFO     Training average negative_sample_loss at step 566900: 0.143431\n",
      "2022-11-08 21:28:34,112 INFO     Training average loss at step 566900: 0.150193\n",
      "2022-11-08 21:28:43,804 INFO     Training average positive_sample_loss at step 567000: 0.154512\n",
      "2022-11-08 21:28:43,804 INFO     Training average negative_sample_loss at step 567000: 0.142348\n",
      "2022-11-08 21:28:43,804 INFO     Training average loss at step 567000: 0.148430\n",
      "2022-11-08 21:28:53,496 INFO     Training average positive_sample_loss at step 567100: 0.154058\n",
      "2022-11-08 21:28:53,496 INFO     Training average negative_sample_loss at step 567100: 0.145455\n",
      "2022-11-08 21:28:53,496 INFO     Training average loss at step 567100: 0.149757\n",
      "2022-11-08 21:29:03,191 INFO     Training average positive_sample_loss at step 567200: 0.157086\n",
      "2022-11-08 21:29:03,191 INFO     Training average negative_sample_loss at step 567200: 0.143502\n",
      "2022-11-08 21:29:03,191 INFO     Training average loss at step 567200: 0.150294\n",
      "2022-11-08 21:29:12,881 INFO     Training average positive_sample_loss at step 567300: 0.157847\n",
      "2022-11-08 21:29:12,881 INFO     Training average negative_sample_loss at step 567300: 0.145357\n",
      "2022-11-08 21:29:12,881 INFO     Training average loss at step 567300: 0.151602\n",
      "2022-11-08 21:29:22,571 INFO     Training average positive_sample_loss at step 567400: 0.159352\n",
      "2022-11-08 21:29:22,571 INFO     Training average negative_sample_loss at step 567400: 0.140835\n",
      "2022-11-08 21:29:22,571 INFO     Training average loss at step 567400: 0.150094\n",
      "2022-11-08 21:29:32,262 INFO     Training average positive_sample_loss at step 567500: 0.152602\n",
      "2022-11-08 21:29:32,262 INFO     Training average negative_sample_loss at step 567500: 0.142719\n",
      "2022-11-08 21:29:32,262 INFO     Training average loss at step 567500: 0.147661\n",
      "2022-11-08 21:29:41,953 INFO     Training average positive_sample_loss at step 567600: 0.149841\n",
      "2022-11-08 21:29:41,953 INFO     Training average negative_sample_loss at step 567600: 0.145286\n",
      "2022-11-08 21:29:41,953 INFO     Training average loss at step 567600: 0.147564\n",
      "2022-11-08 21:29:51,649 INFO     Training average positive_sample_loss at step 567700: 0.150616\n",
      "2022-11-08 21:29:51,649 INFO     Training average negative_sample_loss at step 567700: 0.144926\n",
      "2022-11-08 21:29:51,649 INFO     Training average loss at step 567700: 0.147771\n",
      "2022-11-08 21:30:01,346 INFO     Training average positive_sample_loss at step 567800: 0.152596\n",
      "2022-11-08 21:30:01,346 INFO     Training average negative_sample_loss at step 567800: 0.145953\n",
      "2022-11-08 21:30:01,346 INFO     Training average loss at step 567800: 0.149275\n",
      "2022-11-08 21:30:11,034 INFO     Training average positive_sample_loss at step 567900: 0.159431\n",
      "2022-11-08 21:30:11,034 INFO     Training average negative_sample_loss at step 567900: 0.142575\n",
      "2022-11-08 21:30:11,034 INFO     Training average loss at step 567900: 0.151003\n",
      "2022-11-08 21:30:20,721 INFO     Training average positive_sample_loss at step 568000: 0.153342\n",
      "2022-11-08 21:30:20,721 INFO     Training average negative_sample_loss at step 568000: 0.142119\n",
      "2022-11-08 21:30:20,721 INFO     Training average loss at step 568000: 0.147730\n",
      "2022-11-08 21:30:30,414 INFO     Training average positive_sample_loss at step 568100: 0.157352\n",
      "2022-11-08 21:30:30,415 INFO     Training average negative_sample_loss at step 568100: 0.142817\n",
      "2022-11-08 21:30:30,415 INFO     Training average loss at step 568100: 0.150084\n",
      "2022-11-08 21:30:40,107 INFO     Training average positive_sample_loss at step 568200: 0.149485\n",
      "2022-11-08 21:30:40,107 INFO     Training average negative_sample_loss at step 568200: 0.140298\n",
      "2022-11-08 21:30:40,107 INFO     Training average loss at step 568200: 0.144892\n",
      "2022-11-08 21:30:49,799 INFO     Training average positive_sample_loss at step 568300: 0.148045\n",
      "2022-11-08 21:30:49,799 INFO     Training average negative_sample_loss at step 568300: 0.140386\n",
      "2022-11-08 21:30:49,799 INFO     Training average loss at step 568300: 0.144215\n",
      "2022-11-08 21:30:59,490 INFO     Training average positive_sample_loss at step 568400: 0.155068\n",
      "2022-11-08 21:30:59,490 INFO     Training average negative_sample_loss at step 568400: 0.140211\n",
      "2022-11-08 21:30:59,490 INFO     Training average loss at step 568400: 0.147639\n",
      "2022-11-08 21:31:09,184 INFO     Training average positive_sample_loss at step 568500: 0.151342\n",
      "2022-11-08 21:31:09,184 INFO     Training average negative_sample_loss at step 568500: 0.139346\n",
      "2022-11-08 21:31:09,184 INFO     Training average loss at step 568500: 0.145344\n",
      "2022-11-08 21:31:18,873 INFO     Training average positive_sample_loss at step 568600: 0.155877\n",
      "2022-11-08 21:31:18,873 INFO     Training average negative_sample_loss at step 568600: 0.144806\n",
      "2022-11-08 21:31:18,873 INFO     Training average loss at step 568600: 0.150342\n",
      "2022-11-08 21:31:28,568 INFO     Training average positive_sample_loss at step 568700: 0.155702\n",
      "2022-11-08 21:31:28,568 INFO     Training average negative_sample_loss at step 568700: 0.142898\n",
      "2022-11-08 21:31:28,568 INFO     Training average loss at step 568700: 0.149300\n",
      "2022-11-08 21:31:38,264 INFO     Training average positive_sample_loss at step 568800: 0.152799\n",
      "2022-11-08 21:31:38,264 INFO     Training average negative_sample_loss at step 568800: 0.138257\n",
      "2022-11-08 21:31:38,264 INFO     Training average loss at step 568800: 0.145528\n",
      "2022-11-08 21:31:48,412 INFO     Training average positive_sample_loss at step 568900: 0.154067\n",
      "2022-11-08 21:31:48,412 INFO     Training average negative_sample_loss at step 568900: 0.141767\n",
      "2022-11-08 21:31:48,412 INFO     Training average loss at step 568900: 0.147917\n",
      "2022-11-08 21:32:00,388 INFO     Training average positive_sample_loss at step 569000: 0.149663\n",
      "2022-11-08 21:32:00,388 INFO     Training average negative_sample_loss at step 569000: 0.145564\n",
      "2022-11-08 21:32:00,388 INFO     Training average loss at step 569000: 0.147613\n",
      "2022-11-08 21:32:10,079 INFO     Training average positive_sample_loss at step 569100: 0.155347\n",
      "2022-11-08 21:32:10,079 INFO     Training average negative_sample_loss at step 569100: 0.145706\n",
      "2022-11-08 21:32:10,079 INFO     Training average loss at step 569100: 0.150526\n",
      "2022-11-08 21:32:19,768 INFO     Training average positive_sample_loss at step 569200: 0.157573\n",
      "2022-11-08 21:32:19,768 INFO     Training average negative_sample_loss at step 569200: 0.146623\n",
      "2022-11-08 21:32:19,769 INFO     Training average loss at step 569200: 0.152098\n",
      "2022-11-08 21:32:29,458 INFO     Training average positive_sample_loss at step 569300: 0.157972\n",
      "2022-11-08 21:32:29,458 INFO     Training average negative_sample_loss at step 569300: 0.146201\n",
      "2022-11-08 21:32:29,458 INFO     Training average loss at step 569300: 0.152086\n",
      "2022-11-08 21:32:39,146 INFO     Training average positive_sample_loss at step 569400: 0.157777\n",
      "2022-11-08 21:32:39,147 INFO     Training average negative_sample_loss at step 569400: 0.143297\n",
      "2022-11-08 21:32:39,147 INFO     Training average loss at step 569400: 0.150537\n",
      "2022-11-08 21:32:48,840 INFO     Training average positive_sample_loss at step 569500: 0.152948\n",
      "2022-11-08 21:32:48,840 INFO     Training average negative_sample_loss at step 569500: 0.143828\n",
      "2022-11-08 21:32:48,840 INFO     Training average loss at step 569500: 0.148388\n",
      "2022-11-08 21:32:58,538 INFO     Training average positive_sample_loss at step 569600: 0.156627\n",
      "2022-11-08 21:32:58,538 INFO     Training average negative_sample_loss at step 569600: 0.146748\n",
      "2022-11-08 21:32:58,538 INFO     Training average loss at step 569600: 0.151688\n",
      "2022-11-08 21:33:08,233 INFO     Training average positive_sample_loss at step 569700: 0.157608\n",
      "2022-11-08 21:33:08,234 INFO     Training average negative_sample_loss at step 569700: 0.143388\n",
      "2022-11-08 21:33:08,234 INFO     Training average loss at step 569700: 0.150498\n",
      "2022-11-08 21:33:17,923 INFO     Training average positive_sample_loss at step 569800: 0.152027\n",
      "2022-11-08 21:33:17,923 INFO     Training average negative_sample_loss at step 569800: 0.146642\n",
      "2022-11-08 21:33:17,924 INFO     Training average loss at step 569800: 0.149334\n",
      "2022-11-08 21:33:27,613 INFO     Training average positive_sample_loss at step 569900: 0.148303\n",
      "2022-11-08 21:33:27,613 INFO     Training average negative_sample_loss at step 569900: 0.145201\n",
      "2022-11-08 21:33:27,613 INFO     Training average loss at step 569900: 0.146752\n",
      "2022-11-08 21:33:40,272 INFO     Training average positive_sample_loss at step 570000: 0.154726\n",
      "2022-11-08 21:33:40,272 INFO     Training average negative_sample_loss at step 570000: 0.147163\n",
      "2022-11-08 21:33:40,272 INFO     Training average loss at step 570000: 0.150944\n",
      "2022-11-08 21:33:49,965 INFO     Training average positive_sample_loss at step 570100: 0.150420\n",
      "2022-11-08 21:33:49,966 INFO     Training average negative_sample_loss at step 570100: 0.143147\n",
      "2022-11-08 21:33:49,966 INFO     Training average loss at step 570100: 0.146783\n",
      "2022-11-08 21:33:58,936 INFO     Training average positive_sample_loss at step 570200: 0.153617\n",
      "2022-11-08 21:33:58,936 INFO     Training average negative_sample_loss at step 570200: 0.149144\n",
      "2022-11-08 21:33:58,936 INFO     Training average loss at step 570200: 0.151380\n",
      "2022-11-08 21:34:08,627 INFO     Training average positive_sample_loss at step 570300: 0.155698\n",
      "2022-11-08 21:34:08,627 INFO     Training average negative_sample_loss at step 570300: 0.145675\n",
      "2022-11-08 21:34:08,627 INFO     Training average loss at step 570300: 0.150687\n",
      "2022-11-08 21:34:18,322 INFO     Training average positive_sample_loss at step 570400: 0.155532\n",
      "2022-11-08 21:34:18,322 INFO     Training average negative_sample_loss at step 570400: 0.148405\n",
      "2022-11-08 21:34:18,323 INFO     Training average loss at step 570400: 0.151969\n",
      "2022-11-08 21:34:28,015 INFO     Training average positive_sample_loss at step 570500: 0.153219\n",
      "2022-11-08 21:34:28,015 INFO     Training average negative_sample_loss at step 570500: 0.144267\n",
      "2022-11-08 21:34:28,015 INFO     Training average loss at step 570500: 0.148743\n",
      "2022-11-08 21:34:37,707 INFO     Training average positive_sample_loss at step 570600: 0.157636\n",
      "2022-11-08 21:34:37,707 INFO     Training average negative_sample_loss at step 570600: 0.142082\n",
      "2022-11-08 21:34:37,707 INFO     Training average loss at step 570600: 0.149859\n",
      "2022-11-08 21:34:47,395 INFO     Training average positive_sample_loss at step 570700: 0.153139\n",
      "2022-11-08 21:34:47,395 INFO     Training average negative_sample_loss at step 570700: 0.143050\n",
      "2022-11-08 21:34:47,395 INFO     Training average loss at step 570700: 0.148095\n",
      "2022-11-08 21:34:56,373 INFO     Training average positive_sample_loss at step 570800: 0.152616\n",
      "2022-11-08 21:34:56,373 INFO     Training average negative_sample_loss at step 570800: 0.150420\n",
      "2022-11-08 21:34:56,373 INFO     Training average loss at step 570800: 0.151518\n",
      "2022-11-08 21:35:06,065 INFO     Training average positive_sample_loss at step 570900: 0.154947\n",
      "2022-11-08 21:35:06,065 INFO     Training average negative_sample_loss at step 570900: 0.142879\n",
      "2022-11-08 21:35:06,065 INFO     Training average loss at step 570900: 0.148913\n",
      "2022-11-08 21:35:15,755 INFO     Training average positive_sample_loss at step 571000: 0.153276\n",
      "2022-11-08 21:35:15,755 INFO     Training average negative_sample_loss at step 571000: 0.142730\n",
      "2022-11-08 21:35:15,755 INFO     Training average loss at step 571000: 0.148003\n",
      "2022-11-08 21:35:25,450 INFO     Training average positive_sample_loss at step 571100: 0.152924\n",
      "2022-11-08 21:35:25,450 INFO     Training average negative_sample_loss at step 571100: 0.143670\n",
      "2022-11-08 21:35:25,450 INFO     Training average loss at step 571100: 0.148297\n",
      "2022-11-08 21:35:35,140 INFO     Training average positive_sample_loss at step 571200: 0.155252\n",
      "2022-11-08 21:35:35,140 INFO     Training average negative_sample_loss at step 571200: 0.145349\n",
      "2022-11-08 21:35:35,140 INFO     Training average loss at step 571200: 0.150301\n",
      "2022-11-08 21:35:44,831 INFO     Training average positive_sample_loss at step 571300: 0.155958\n",
      "2022-11-08 21:35:44,831 INFO     Training average negative_sample_loss at step 571300: 0.143615\n",
      "2022-11-08 21:35:44,831 INFO     Training average loss at step 571300: 0.149787\n",
      "2022-11-08 21:35:54,532 INFO     Training average positive_sample_loss at step 571400: 0.150821\n",
      "2022-11-08 21:35:54,532 INFO     Training average negative_sample_loss at step 571400: 0.145162\n",
      "2022-11-08 21:35:54,532 INFO     Training average loss at step 571400: 0.147992\n",
      "2022-11-08 21:36:04,224 INFO     Training average positive_sample_loss at step 571500: 0.148090\n",
      "2022-11-08 21:36:04,224 INFO     Training average negative_sample_loss at step 571500: 0.142109\n",
      "2022-11-08 21:36:04,224 INFO     Training average loss at step 571500: 0.145099\n",
      "2022-11-08 21:36:13,925 INFO     Training average positive_sample_loss at step 571600: 0.150367\n",
      "2022-11-08 21:36:13,926 INFO     Training average negative_sample_loss at step 571600: 0.144376\n",
      "2022-11-08 21:36:13,926 INFO     Training average loss at step 571600: 0.147371\n",
      "2022-11-08 21:36:23,623 INFO     Training average positive_sample_loss at step 571700: 0.148943\n",
      "2022-11-08 21:36:23,623 INFO     Training average negative_sample_loss at step 571700: 0.145894\n",
      "2022-11-08 21:36:23,623 INFO     Training average loss at step 571700: 0.147419\n",
      "2022-11-08 21:36:33,318 INFO     Training average positive_sample_loss at step 571800: 0.154599\n",
      "2022-11-08 21:36:33,318 INFO     Training average negative_sample_loss at step 571800: 0.143679\n",
      "2022-11-08 21:36:33,318 INFO     Training average loss at step 571800: 0.149139\n",
      "2022-11-08 21:36:43,010 INFO     Training average positive_sample_loss at step 571900: 0.152906\n",
      "2022-11-08 21:36:43,010 INFO     Training average negative_sample_loss at step 571900: 0.144897\n",
      "2022-11-08 21:36:43,010 INFO     Training average loss at step 571900: 0.148901\n",
      "2022-11-08 21:36:52,705 INFO     Training average positive_sample_loss at step 572000: 0.156306\n",
      "2022-11-08 21:36:52,706 INFO     Training average negative_sample_loss at step 572000: 0.147404\n",
      "2022-11-08 21:36:52,706 INFO     Training average loss at step 572000: 0.151855\n",
      "2022-11-08 21:37:02,400 INFO     Training average positive_sample_loss at step 572100: 0.152063\n",
      "2022-11-08 21:37:02,401 INFO     Training average negative_sample_loss at step 572100: 0.146031\n",
      "2022-11-08 21:37:02,401 INFO     Training average loss at step 572100: 0.149047\n",
      "2022-11-08 21:37:12,093 INFO     Training average positive_sample_loss at step 572200: 0.156432\n",
      "2022-11-08 21:37:12,094 INFO     Training average negative_sample_loss at step 572200: 0.146047\n",
      "2022-11-08 21:37:12,094 INFO     Training average loss at step 572200: 0.151239\n",
      "2022-11-08 21:37:21,787 INFO     Training average positive_sample_loss at step 572300: 0.150700\n",
      "2022-11-08 21:37:21,787 INFO     Training average negative_sample_loss at step 572300: 0.145630\n",
      "2022-11-08 21:37:21,787 INFO     Training average loss at step 572300: 0.148165\n",
      "2022-11-08 21:37:31,482 INFO     Training average positive_sample_loss at step 572400: 0.152177\n",
      "2022-11-08 21:37:31,482 INFO     Training average negative_sample_loss at step 572400: 0.142602\n",
      "2022-11-08 21:37:31,482 INFO     Training average loss at step 572400: 0.147390\n",
      "2022-11-08 21:37:41,172 INFO     Training average positive_sample_loss at step 572500: 0.152892\n",
      "2022-11-08 21:37:41,172 INFO     Training average negative_sample_loss at step 572500: 0.143475\n",
      "2022-11-08 21:37:41,172 INFO     Training average loss at step 572500: 0.148183\n",
      "2022-11-08 21:37:50,862 INFO     Training average positive_sample_loss at step 572600: 0.149119\n",
      "2022-11-08 21:37:50,862 INFO     Training average negative_sample_loss at step 572600: 0.141862\n",
      "2022-11-08 21:37:50,862 INFO     Training average loss at step 572600: 0.145491\n",
      "2022-11-08 21:38:00,558 INFO     Training average positive_sample_loss at step 572700: 0.158517\n",
      "2022-11-08 21:38:00,558 INFO     Training average negative_sample_loss at step 572700: 0.140556\n",
      "2022-11-08 21:38:00,558 INFO     Training average loss at step 572700: 0.149537\n",
      "2022-11-08 21:38:10,250 INFO     Training average positive_sample_loss at step 572800: 0.153525\n",
      "2022-11-08 21:38:10,250 INFO     Training average negative_sample_loss at step 572800: 0.146574\n",
      "2022-11-08 21:38:10,250 INFO     Training average loss at step 572800: 0.150050\n",
      "2022-11-08 21:38:19,944 INFO     Training average positive_sample_loss at step 572900: 0.150614\n",
      "2022-11-08 21:38:19,944 INFO     Training average negative_sample_loss at step 572900: 0.143571\n",
      "2022-11-08 21:38:19,944 INFO     Training average loss at step 572900: 0.147093\n",
      "2022-11-08 21:38:29,636 INFO     Training average positive_sample_loss at step 573000: 0.153908\n",
      "2022-11-08 21:38:29,636 INFO     Training average negative_sample_loss at step 573000: 0.141219\n",
      "2022-11-08 21:38:29,636 INFO     Training average loss at step 573000: 0.147563\n",
      "2022-11-08 21:38:39,329 INFO     Training average positive_sample_loss at step 573100: 0.149453\n",
      "2022-11-08 21:38:39,329 INFO     Training average negative_sample_loss at step 573100: 0.144027\n",
      "2022-11-08 21:38:39,329 INFO     Training average loss at step 573100: 0.146740\n",
      "2022-11-08 21:38:49,024 INFO     Training average positive_sample_loss at step 573200: 0.162865\n",
      "2022-11-08 21:38:49,024 INFO     Training average negative_sample_loss at step 573200: 0.142617\n",
      "2022-11-08 21:38:49,024 INFO     Training average loss at step 573200: 0.152741\n",
      "2022-11-08 21:38:58,718 INFO     Training average positive_sample_loss at step 573300: 0.151510\n",
      "2022-11-08 21:38:58,718 INFO     Training average negative_sample_loss at step 573300: 0.141654\n",
      "2022-11-08 21:38:58,718 INFO     Training average loss at step 573300: 0.146582\n",
      "2022-11-08 21:39:08,411 INFO     Training average positive_sample_loss at step 573400: 0.152801\n",
      "2022-11-08 21:39:08,411 INFO     Training average negative_sample_loss at step 573400: 0.143572\n",
      "2022-11-08 21:39:08,411 INFO     Training average loss at step 573400: 0.148186\n",
      "2022-11-08 21:39:18,106 INFO     Training average positive_sample_loss at step 573500: 0.152097\n",
      "2022-11-08 21:39:18,106 INFO     Training average negative_sample_loss at step 573500: 0.142823\n",
      "2022-11-08 21:39:18,106 INFO     Training average loss at step 573500: 0.147460\n",
      "2022-11-08 21:39:28,269 INFO     Training average positive_sample_loss at step 573600: 0.150943\n",
      "2022-11-08 21:39:28,269 INFO     Training average negative_sample_loss at step 573600: 0.146282\n",
      "2022-11-08 21:39:28,269 INFO     Training average loss at step 573600: 0.148612\n",
      "2022-11-08 21:39:40,270 INFO     Training average positive_sample_loss at step 573700: 0.153174\n",
      "2022-11-08 21:39:40,270 INFO     Training average negative_sample_loss at step 573700: 0.144128\n",
      "2022-11-08 21:39:40,270 INFO     Training average loss at step 573700: 0.148651\n",
      "2022-11-08 21:39:49,962 INFO     Training average positive_sample_loss at step 573800: 0.149392\n",
      "2022-11-08 21:39:49,962 INFO     Training average negative_sample_loss at step 573800: 0.142634\n",
      "2022-11-08 21:39:49,962 INFO     Training average loss at step 573800: 0.146013\n",
      "2022-11-08 21:39:59,656 INFO     Training average positive_sample_loss at step 573900: 0.150405\n",
      "2022-11-08 21:39:59,656 INFO     Training average negative_sample_loss at step 573900: 0.146269\n",
      "2022-11-08 21:39:59,656 INFO     Training average loss at step 573900: 0.148337\n",
      "2022-11-08 21:40:09,346 INFO     Training average positive_sample_loss at step 574000: 0.156580\n",
      "2022-11-08 21:40:09,346 INFO     Training average negative_sample_loss at step 574000: 0.148589\n",
      "2022-11-08 21:40:09,346 INFO     Training average loss at step 574000: 0.152584\n",
      "2022-11-08 21:40:19,039 INFO     Training average positive_sample_loss at step 574100: 0.153590\n",
      "2022-11-08 21:40:19,040 INFO     Training average negative_sample_loss at step 574100: 0.142527\n",
      "2022-11-08 21:40:19,040 INFO     Training average loss at step 574100: 0.148058\n",
      "2022-11-08 21:40:28,737 INFO     Training average positive_sample_loss at step 574200: 0.152942\n",
      "2022-11-08 21:40:28,737 INFO     Training average negative_sample_loss at step 574200: 0.143028\n",
      "2022-11-08 21:40:28,737 INFO     Training average loss at step 574200: 0.147985\n",
      "2022-11-08 21:40:38,429 INFO     Training average positive_sample_loss at step 574300: 0.150728\n",
      "2022-11-08 21:40:38,429 INFO     Training average negative_sample_loss at step 574300: 0.143031\n",
      "2022-11-08 21:40:38,429 INFO     Training average loss at step 574300: 0.146879\n",
      "2022-11-08 21:40:48,123 INFO     Training average positive_sample_loss at step 574400: 0.157370\n",
      "2022-11-08 21:40:48,124 INFO     Training average negative_sample_loss at step 574400: 0.143871\n",
      "2022-11-08 21:40:48,124 INFO     Training average loss at step 574400: 0.150621\n",
      "2022-11-08 21:40:57,813 INFO     Training average positive_sample_loss at step 574500: 0.153202\n",
      "2022-11-08 21:40:57,813 INFO     Training average negative_sample_loss at step 574500: 0.145340\n",
      "2022-11-08 21:40:57,813 INFO     Training average loss at step 574500: 0.149271\n",
      "2022-11-08 21:41:07,502 INFO     Training average positive_sample_loss at step 574600: 0.152213\n",
      "2022-11-08 21:41:07,502 INFO     Training average negative_sample_loss at step 574600: 0.140835\n",
      "2022-11-08 21:41:07,502 INFO     Training average loss at step 574600: 0.146524\n",
      "2022-11-08 21:41:17,199 INFO     Training average positive_sample_loss at step 574700: 0.155474\n",
      "2022-11-08 21:41:17,199 INFO     Training average negative_sample_loss at step 574700: 0.140515\n",
      "2022-11-08 21:41:17,199 INFO     Training average loss at step 574700: 0.147995\n",
      "2022-11-08 21:41:26,889 INFO     Training average positive_sample_loss at step 574800: 0.158548\n",
      "2022-11-08 21:41:26,890 INFO     Training average negative_sample_loss at step 574800: 0.138489\n",
      "2022-11-08 21:41:26,890 INFO     Training average loss at step 574800: 0.148519\n",
      "2022-11-08 21:41:36,583 INFO     Training average positive_sample_loss at step 574900: 0.151731\n",
      "2022-11-08 21:41:36,583 INFO     Training average negative_sample_loss at step 574900: 0.148500\n",
      "2022-11-08 21:41:36,584 INFO     Training average loss at step 574900: 0.150115\n",
      "2022-11-08 21:41:46,278 INFO     Training average positive_sample_loss at step 575000: 0.154550\n",
      "2022-11-08 21:41:46,278 INFO     Training average negative_sample_loss at step 575000: 0.144000\n",
      "2022-11-08 21:41:46,278 INFO     Training average loss at step 575000: 0.149275\n",
      "2022-11-08 21:41:55,965 INFO     Training average positive_sample_loss at step 575100: 0.149014\n",
      "2022-11-08 21:41:55,966 INFO     Training average negative_sample_loss at step 575100: 0.148179\n",
      "2022-11-08 21:41:55,966 INFO     Training average loss at step 575100: 0.148596\n",
      "2022-11-08 21:42:05,659 INFO     Training average positive_sample_loss at step 575200: 0.153678\n",
      "2022-11-08 21:42:05,659 INFO     Training average negative_sample_loss at step 575200: 0.142514\n",
      "2022-11-08 21:42:05,659 INFO     Training average loss at step 575200: 0.148096\n",
      "2022-11-08 21:42:15,353 INFO     Training average positive_sample_loss at step 575300: 0.154384\n",
      "2022-11-08 21:42:15,354 INFO     Training average negative_sample_loss at step 575300: 0.146652\n",
      "2022-11-08 21:42:15,354 INFO     Training average loss at step 575300: 0.150518\n",
      "2022-11-08 21:42:25,044 INFO     Training average positive_sample_loss at step 575400: 0.149947\n",
      "2022-11-08 21:42:25,044 INFO     Training average negative_sample_loss at step 575400: 0.141573\n",
      "2022-11-08 21:42:25,044 INFO     Training average loss at step 575400: 0.145760\n",
      "2022-11-08 21:42:34,735 INFO     Training average positive_sample_loss at step 575500: 0.154870\n",
      "2022-11-08 21:42:34,735 INFO     Training average negative_sample_loss at step 575500: 0.145608\n",
      "2022-11-08 21:42:34,735 INFO     Training average loss at step 575500: 0.150239\n",
      "2022-11-08 21:42:44,427 INFO     Training average positive_sample_loss at step 575600: 0.156703\n",
      "2022-11-08 21:42:44,427 INFO     Training average negative_sample_loss at step 575600: 0.143513\n",
      "2022-11-08 21:42:44,427 INFO     Training average loss at step 575600: 0.150108\n",
      "2022-11-08 21:42:53,464 INFO     Training average positive_sample_loss at step 575700: 0.156375\n",
      "2022-11-08 21:42:53,464 INFO     Training average negative_sample_loss at step 575700: 0.144292\n",
      "2022-11-08 21:42:53,464 INFO     Training average loss at step 575700: 0.150334\n",
      "2022-11-08 21:43:03,155 INFO     Training average positive_sample_loss at step 575800: 0.156478\n",
      "2022-11-08 21:43:03,155 INFO     Training average negative_sample_loss at step 575800: 0.143053\n",
      "2022-11-08 21:43:03,155 INFO     Training average loss at step 575800: 0.149765\n",
      "2022-11-08 21:43:12,846 INFO     Training average positive_sample_loss at step 575900: 0.151926\n",
      "2022-11-08 21:43:12,846 INFO     Training average negative_sample_loss at step 575900: 0.144161\n",
      "2022-11-08 21:43:12,846 INFO     Training average loss at step 575900: 0.148044\n",
      "2022-11-08 21:43:22,538 INFO     Training average positive_sample_loss at step 576000: 0.157521\n",
      "2022-11-08 21:43:22,538 INFO     Training average negative_sample_loss at step 576000: 0.145283\n",
      "2022-11-08 21:43:22,538 INFO     Training average loss at step 576000: 0.151402\n",
      "2022-11-08 21:43:32,234 INFO     Training average positive_sample_loss at step 576100: 0.151386\n",
      "2022-11-08 21:43:32,234 INFO     Training average negative_sample_loss at step 576100: 0.146978\n",
      "2022-11-08 21:43:32,234 INFO     Training average loss at step 576100: 0.149182\n",
      "2022-11-08 21:43:41,929 INFO     Training average positive_sample_loss at step 576200: 0.156043\n",
      "2022-11-08 21:43:41,929 INFO     Training average negative_sample_loss at step 576200: 0.141353\n",
      "2022-11-08 21:43:41,929 INFO     Training average loss at step 576200: 0.148698\n",
      "2022-11-08 21:43:50,922 INFO     Training average positive_sample_loss at step 576300: 0.157649\n",
      "2022-11-08 21:43:50,922 INFO     Training average negative_sample_loss at step 576300: 0.139534\n",
      "2022-11-08 21:43:50,922 INFO     Training average loss at step 576300: 0.148592\n",
      "2022-11-08 21:44:00,617 INFO     Training average positive_sample_loss at step 576400: 0.151700\n",
      "2022-11-08 21:44:00,617 INFO     Training average negative_sample_loss at step 576400: 0.143488\n",
      "2022-11-08 21:44:00,617 INFO     Training average loss at step 576400: 0.147594\n",
      "2022-11-08 21:44:10,312 INFO     Training average positive_sample_loss at step 576500: 0.160720\n",
      "2022-11-08 21:44:10,312 INFO     Training average negative_sample_loss at step 576500: 0.142413\n",
      "2022-11-08 21:44:10,312 INFO     Training average loss at step 576500: 0.151567\n",
      "2022-11-08 21:44:20,000 INFO     Training average positive_sample_loss at step 576600: 0.151828\n",
      "2022-11-08 21:44:20,000 INFO     Training average negative_sample_loss at step 576600: 0.145709\n",
      "2022-11-08 21:44:20,000 INFO     Training average loss at step 576600: 0.148768\n",
      "2022-11-08 21:44:29,691 INFO     Training average positive_sample_loss at step 576700: 0.155386\n",
      "2022-11-08 21:44:29,691 INFO     Training average negative_sample_loss at step 576700: 0.146212\n",
      "2022-11-08 21:44:29,691 INFO     Training average loss at step 576700: 0.150799\n",
      "2022-11-08 21:44:39,383 INFO     Training average positive_sample_loss at step 576800: 0.156553\n",
      "2022-11-08 21:44:39,383 INFO     Training average negative_sample_loss at step 576800: 0.149010\n",
      "2022-11-08 21:44:39,383 INFO     Training average loss at step 576800: 0.152781\n",
      "2022-11-08 21:44:49,072 INFO     Training average positive_sample_loss at step 576900: 0.154890\n",
      "2022-11-08 21:44:49,072 INFO     Training average negative_sample_loss at step 576900: 0.143650\n",
      "2022-11-08 21:44:49,072 INFO     Training average loss at step 576900: 0.149270\n",
      "2022-11-08 21:44:58,766 INFO     Training average positive_sample_loss at step 577000: 0.157487\n",
      "2022-11-08 21:44:58,766 INFO     Training average negative_sample_loss at step 577000: 0.146275\n",
      "2022-11-08 21:44:58,766 INFO     Training average loss at step 577000: 0.151881\n",
      "2022-11-08 21:45:08,463 INFO     Training average positive_sample_loss at step 577100: 0.152935\n",
      "2022-11-08 21:45:08,463 INFO     Training average negative_sample_loss at step 577100: 0.144860\n",
      "2022-11-08 21:45:08,463 INFO     Training average loss at step 577100: 0.148898\n",
      "2022-11-08 21:45:18,152 INFO     Training average positive_sample_loss at step 577200: 0.150376\n",
      "2022-11-08 21:45:18,152 INFO     Training average negative_sample_loss at step 577200: 0.140363\n",
      "2022-11-08 21:45:18,152 INFO     Training average loss at step 577200: 0.145369\n",
      "2022-11-08 21:45:27,846 INFO     Training average positive_sample_loss at step 577300: 0.154428\n",
      "2022-11-08 21:45:27,847 INFO     Training average negative_sample_loss at step 577300: 0.143124\n",
      "2022-11-08 21:45:27,847 INFO     Training average loss at step 577300: 0.148776\n",
      "2022-11-08 21:45:37,541 INFO     Training average positive_sample_loss at step 577400: 0.150084\n",
      "2022-11-08 21:45:37,541 INFO     Training average negative_sample_loss at step 577400: 0.140761\n",
      "2022-11-08 21:45:37,541 INFO     Training average loss at step 577400: 0.145423\n",
      "2022-11-08 21:45:47,230 INFO     Training average positive_sample_loss at step 577500: 0.154781\n",
      "2022-11-08 21:45:47,230 INFO     Training average negative_sample_loss at step 577500: 0.143743\n",
      "2022-11-08 21:45:47,230 INFO     Training average loss at step 577500: 0.149262\n",
      "2022-11-08 21:45:56,923 INFO     Training average positive_sample_loss at step 577600: 0.150039\n",
      "2022-11-08 21:45:56,923 INFO     Training average negative_sample_loss at step 577600: 0.146839\n",
      "2022-11-08 21:45:56,923 INFO     Training average loss at step 577600: 0.148439\n",
      "2022-11-08 21:46:06,620 INFO     Training average positive_sample_loss at step 577700: 0.155341\n",
      "2022-11-08 21:46:06,620 INFO     Training average negative_sample_loss at step 577700: 0.140865\n",
      "2022-11-08 21:46:06,620 INFO     Training average loss at step 577700: 0.148103\n",
      "2022-11-08 21:46:16,308 INFO     Training average positive_sample_loss at step 577800: 0.155743\n",
      "2022-11-08 21:46:16,308 INFO     Training average negative_sample_loss at step 577800: 0.142756\n",
      "2022-11-08 21:46:16,308 INFO     Training average loss at step 577800: 0.149250\n",
      "2022-11-08 21:46:26,000 INFO     Training average positive_sample_loss at step 577900: 0.152613\n",
      "2022-11-08 21:46:26,000 INFO     Training average negative_sample_loss at step 577900: 0.144306\n",
      "2022-11-08 21:46:26,000 INFO     Training average loss at step 577900: 0.148459\n",
      "2022-11-08 21:46:35,692 INFO     Training average positive_sample_loss at step 578000: 0.155271\n",
      "2022-11-08 21:46:35,692 INFO     Training average negative_sample_loss at step 578000: 0.147053\n",
      "2022-11-08 21:46:35,692 INFO     Training average loss at step 578000: 0.151162\n",
      "2022-11-08 21:46:45,388 INFO     Training average positive_sample_loss at step 578100: 0.153284\n",
      "2022-11-08 21:46:45,388 INFO     Training average negative_sample_loss at step 578100: 0.147096\n",
      "2022-11-08 21:46:45,388 INFO     Training average loss at step 578100: 0.150190\n",
      "2022-11-08 21:46:55,364 INFO     Training average positive_sample_loss at step 578200: 0.151835\n",
      "2022-11-08 21:46:55,364 INFO     Training average negative_sample_loss at step 578200: 0.140756\n",
      "2022-11-08 21:46:55,364 INFO     Training average loss at step 578200: 0.146295\n",
      "2022-11-08 21:47:05,953 INFO     Training average positive_sample_loss at step 578300: 0.152817\n",
      "2022-11-08 21:47:05,954 INFO     Training average negative_sample_loss at step 578300: 0.144693\n",
      "2022-11-08 21:47:05,954 INFO     Training average loss at step 578300: 0.148755\n",
      "2022-11-08 21:47:16,583 INFO     Training average positive_sample_loss at step 578400: 0.153719\n",
      "2022-11-08 21:47:16,583 INFO     Training average negative_sample_loss at step 578400: 0.144172\n",
      "2022-11-08 21:47:16,583 INFO     Training average loss at step 578400: 0.148945\n",
      "2022-11-08 21:47:26,270 INFO     Training average positive_sample_loss at step 578500: 0.154875\n",
      "2022-11-08 21:47:26,270 INFO     Training average negative_sample_loss at step 578500: 0.149998\n",
      "2022-11-08 21:47:26,270 INFO     Training average loss at step 578500: 0.152437\n",
      "2022-11-08 21:47:35,964 INFO     Training average positive_sample_loss at step 578600: 0.157966\n",
      "2022-11-08 21:47:35,964 INFO     Training average negative_sample_loss at step 578600: 0.143396\n",
      "2022-11-08 21:47:35,964 INFO     Training average loss at step 578600: 0.150681\n",
      "2022-11-08 21:47:45,655 INFO     Training average positive_sample_loss at step 578700: 0.152385\n",
      "2022-11-08 21:47:45,655 INFO     Training average negative_sample_loss at step 578700: 0.146177\n",
      "2022-11-08 21:47:45,655 INFO     Training average loss at step 578700: 0.149281\n",
      "2022-11-08 21:47:55,347 INFO     Training average positive_sample_loss at step 578800: 0.155774\n",
      "2022-11-08 21:47:55,347 INFO     Training average negative_sample_loss at step 578800: 0.141015\n",
      "2022-11-08 21:47:55,347 INFO     Training average loss at step 578800: 0.148394\n",
      "2022-11-08 21:48:05,041 INFO     Training average positive_sample_loss at step 578900: 0.153810\n",
      "2022-11-08 21:48:05,041 INFO     Training average negative_sample_loss at step 578900: 0.141209\n",
      "2022-11-08 21:48:05,041 INFO     Training average loss at step 578900: 0.147509\n",
      "2022-11-08 21:48:14,734 INFO     Training average positive_sample_loss at step 579000: 0.154916\n",
      "2022-11-08 21:48:14,734 INFO     Training average negative_sample_loss at step 579000: 0.145323\n",
      "2022-11-08 21:48:14,734 INFO     Training average loss at step 579000: 0.150119\n",
      "2022-11-08 21:48:24,425 INFO     Training average positive_sample_loss at step 579100: 0.155352\n",
      "2022-11-08 21:48:24,425 INFO     Training average negative_sample_loss at step 579100: 0.141540\n",
      "2022-11-08 21:48:24,425 INFO     Training average loss at step 579100: 0.148446\n",
      "2022-11-08 21:48:34,120 INFO     Training average positive_sample_loss at step 579200: 0.159329\n",
      "2022-11-08 21:48:34,121 INFO     Training average negative_sample_loss at step 579200: 0.144383\n",
      "2022-11-08 21:48:34,121 INFO     Training average loss at step 579200: 0.151856\n",
      "2022-11-08 21:48:43,810 INFO     Training average positive_sample_loss at step 579300: 0.155569\n",
      "2022-11-08 21:48:43,810 INFO     Training average negative_sample_loss at step 579300: 0.142369\n",
      "2022-11-08 21:48:43,811 INFO     Training average loss at step 579300: 0.148969\n",
      "2022-11-08 21:48:53,502 INFO     Training average positive_sample_loss at step 579400: 0.154446\n",
      "2022-11-08 21:48:53,502 INFO     Training average negative_sample_loss at step 579400: 0.144539\n",
      "2022-11-08 21:48:53,502 INFO     Training average loss at step 579400: 0.149493\n",
      "2022-11-08 21:49:03,195 INFO     Training average positive_sample_loss at step 579500: 0.159327\n",
      "2022-11-08 21:49:03,195 INFO     Training average negative_sample_loss at step 579500: 0.147151\n",
      "2022-11-08 21:49:03,195 INFO     Training average loss at step 579500: 0.153239\n",
      "2022-11-08 21:49:12,883 INFO     Training average positive_sample_loss at step 579600: 0.156922\n",
      "2022-11-08 21:49:12,883 INFO     Training average negative_sample_loss at step 579600: 0.140311\n",
      "2022-11-08 21:49:12,883 INFO     Training average loss at step 579600: 0.148617\n",
      "2022-11-08 21:49:22,575 INFO     Training average positive_sample_loss at step 579700: 0.153297\n",
      "2022-11-08 21:49:22,575 INFO     Training average negative_sample_loss at step 579700: 0.150078\n",
      "2022-11-08 21:49:22,575 INFO     Training average loss at step 579700: 0.151687\n",
      "2022-11-08 21:49:32,267 INFO     Training average positive_sample_loss at step 579800: 0.155512\n",
      "2022-11-08 21:49:32,267 INFO     Training average negative_sample_loss at step 579800: 0.139265\n",
      "2022-11-08 21:49:32,267 INFO     Training average loss at step 579800: 0.147389\n",
      "2022-11-08 21:49:41,958 INFO     Training average positive_sample_loss at step 579900: 0.159582\n",
      "2022-11-08 21:49:41,958 INFO     Training average negative_sample_loss at step 579900: 0.141629\n",
      "2022-11-08 21:49:41,958 INFO     Training average loss at step 579900: 0.150605\n",
      "2022-11-08 21:49:54,553 INFO     Training average positive_sample_loss at step 580000: 0.151195\n",
      "2022-11-08 21:49:54,553 INFO     Training average negative_sample_loss at step 580000: 0.139323\n",
      "2022-11-08 21:49:54,553 INFO     Training average loss at step 580000: 0.145259\n",
      "2022-11-08 21:50:04,247 INFO     Training average positive_sample_loss at step 580100: 0.151565\n",
      "2022-11-08 21:50:04,247 INFO     Training average negative_sample_loss at step 580100: 0.138696\n",
      "2022-11-08 21:50:04,247 INFO     Training average loss at step 580100: 0.145130\n",
      "2022-11-08 21:50:13,935 INFO     Training average positive_sample_loss at step 580200: 0.149348\n",
      "2022-11-08 21:50:13,935 INFO     Training average negative_sample_loss at step 580200: 0.144129\n",
      "2022-11-08 21:50:13,935 INFO     Training average loss at step 580200: 0.146739\n",
      "2022-11-08 21:50:23,623 INFO     Training average positive_sample_loss at step 580300: 0.159242\n",
      "2022-11-08 21:50:23,623 INFO     Training average negative_sample_loss at step 580300: 0.143361\n",
      "2022-11-08 21:50:23,623 INFO     Training average loss at step 580300: 0.151302\n",
      "2022-11-08 21:50:33,314 INFO     Training average positive_sample_loss at step 580400: 0.154069\n",
      "2022-11-08 21:50:33,315 INFO     Training average negative_sample_loss at step 580400: 0.145159\n",
      "2022-11-08 21:50:33,315 INFO     Training average loss at step 580400: 0.149614\n",
      "2022-11-08 21:50:43,005 INFO     Training average positive_sample_loss at step 580500: 0.150876\n",
      "2022-11-08 21:50:43,005 INFO     Training average negative_sample_loss at step 580500: 0.141838\n",
      "2022-11-08 21:50:43,005 INFO     Training average loss at step 580500: 0.146357\n",
      "2022-11-08 21:50:52,695 INFO     Training average positive_sample_loss at step 580600: 0.149136\n",
      "2022-11-08 21:50:52,696 INFO     Training average negative_sample_loss at step 580600: 0.142267\n",
      "2022-11-08 21:50:52,696 INFO     Training average loss at step 580600: 0.145702\n",
      "2022-11-08 21:51:02,389 INFO     Training average positive_sample_loss at step 580700: 0.156218\n",
      "2022-11-08 21:51:02,389 INFO     Training average negative_sample_loss at step 580700: 0.140089\n",
      "2022-11-08 21:51:02,389 INFO     Training average loss at step 580700: 0.148153\n",
      "2022-11-08 21:51:12,082 INFO     Training average positive_sample_loss at step 580800: 0.156645\n",
      "2022-11-08 21:51:12,082 INFO     Training average negative_sample_loss at step 580800: 0.146793\n",
      "2022-11-08 21:51:12,082 INFO     Training average loss at step 580800: 0.151719\n",
      "2022-11-08 21:51:21,771 INFO     Training average positive_sample_loss at step 580900: 0.158686\n",
      "2022-11-08 21:51:21,771 INFO     Training average negative_sample_loss at step 580900: 0.144205\n",
      "2022-11-08 21:51:21,771 INFO     Training average loss at step 580900: 0.151445\n",
      "2022-11-08 21:51:31,467 INFO     Training average positive_sample_loss at step 581000: 0.154128\n",
      "2022-11-08 21:51:31,467 INFO     Training average negative_sample_loss at step 581000: 0.148140\n",
      "2022-11-08 21:51:31,467 INFO     Training average loss at step 581000: 0.151134\n",
      "2022-11-08 21:51:40,517 INFO     Training average positive_sample_loss at step 581100: 0.150863\n",
      "2022-11-08 21:51:40,518 INFO     Training average negative_sample_loss at step 581100: 0.142512\n",
      "2022-11-08 21:51:40,518 INFO     Training average loss at step 581100: 0.146687\n",
      "2022-11-08 21:51:50,208 INFO     Training average positive_sample_loss at step 581200: 0.154564\n",
      "2022-11-08 21:51:50,208 INFO     Training average negative_sample_loss at step 581200: 0.144263\n",
      "2022-11-08 21:51:50,208 INFO     Training average loss at step 581200: 0.149413\n",
      "2022-11-08 21:51:59,898 INFO     Training average positive_sample_loss at step 581300: 0.150802\n",
      "2022-11-08 21:51:59,898 INFO     Training average negative_sample_loss at step 581300: 0.141009\n",
      "2022-11-08 21:51:59,898 INFO     Training average loss at step 581300: 0.145906\n",
      "2022-11-08 21:52:09,600 INFO     Training average positive_sample_loss at step 581400: 0.155221\n",
      "2022-11-08 21:52:09,600 INFO     Training average negative_sample_loss at step 581400: 0.145293\n",
      "2022-11-08 21:52:09,600 INFO     Training average loss at step 581400: 0.150257\n",
      "2022-11-08 21:52:19,291 INFO     Training average positive_sample_loss at step 581500: 0.151715\n",
      "2022-11-08 21:52:19,291 INFO     Training average negative_sample_loss at step 581500: 0.139053\n",
      "2022-11-08 21:52:19,291 INFO     Training average loss at step 581500: 0.145384\n",
      "2022-11-08 21:52:28,985 INFO     Training average positive_sample_loss at step 581600: 0.159043\n",
      "2022-11-08 21:52:28,985 INFO     Training average negative_sample_loss at step 581600: 0.143715\n",
      "2022-11-08 21:52:28,985 INFO     Training average loss at step 581600: 0.151379\n",
      "2022-11-08 21:52:37,982 INFO     Training average positive_sample_loss at step 581700: 0.151315\n",
      "2022-11-08 21:52:37,982 INFO     Training average negative_sample_loss at step 581700: 0.147149\n",
      "2022-11-08 21:52:37,982 INFO     Training average loss at step 581700: 0.149232\n",
      "2022-11-08 21:52:47,673 INFO     Training average positive_sample_loss at step 581800: 0.154466\n",
      "2022-11-08 21:52:47,673 INFO     Training average negative_sample_loss at step 581800: 0.146483\n",
      "2022-11-08 21:52:47,673 INFO     Training average loss at step 581800: 0.150475\n",
      "2022-11-08 21:52:57,365 INFO     Training average positive_sample_loss at step 581900: 0.158840\n",
      "2022-11-08 21:52:57,365 INFO     Training average negative_sample_loss at step 581900: 0.145639\n",
      "2022-11-08 21:52:57,365 INFO     Training average loss at step 581900: 0.152240\n",
      "2022-11-08 21:53:07,054 INFO     Training average positive_sample_loss at step 582000: 0.153427\n",
      "2022-11-08 21:53:07,055 INFO     Training average negative_sample_loss at step 582000: 0.144132\n",
      "2022-11-08 21:53:07,055 INFO     Training average loss at step 582000: 0.148780\n",
      "2022-11-08 21:53:16,742 INFO     Training average positive_sample_loss at step 582100: 0.155211\n",
      "2022-11-08 21:53:16,742 INFO     Training average negative_sample_loss at step 582100: 0.142913\n",
      "2022-11-08 21:53:16,742 INFO     Training average loss at step 582100: 0.149062\n",
      "2022-11-08 21:53:26,437 INFO     Training average positive_sample_loss at step 582200: 0.146560\n",
      "2022-11-08 21:53:26,437 INFO     Training average negative_sample_loss at step 582200: 0.146602\n",
      "2022-11-08 21:53:26,437 INFO     Training average loss at step 582200: 0.146581\n",
      "2022-11-08 21:53:36,133 INFO     Training average positive_sample_loss at step 582300: 0.153160\n",
      "2022-11-08 21:53:36,133 INFO     Training average negative_sample_loss at step 582300: 0.139784\n",
      "2022-11-08 21:53:36,133 INFO     Training average loss at step 582300: 0.146472\n",
      "2022-11-08 21:53:45,823 INFO     Training average positive_sample_loss at step 582400: 0.157023\n",
      "2022-11-08 21:53:45,823 INFO     Training average negative_sample_loss at step 582400: 0.143069\n",
      "2022-11-08 21:53:45,823 INFO     Training average loss at step 582400: 0.150046\n",
      "2022-11-08 21:53:55,517 INFO     Training average positive_sample_loss at step 582500: 0.153156\n",
      "2022-11-08 21:53:55,518 INFO     Training average negative_sample_loss at step 582500: 0.144477\n",
      "2022-11-08 21:53:55,518 INFO     Training average loss at step 582500: 0.148816\n",
      "2022-11-08 21:54:05,206 INFO     Training average positive_sample_loss at step 582600: 0.151221\n",
      "2022-11-08 21:54:05,206 INFO     Training average negative_sample_loss at step 582600: 0.144917\n",
      "2022-11-08 21:54:05,206 INFO     Training average loss at step 582600: 0.148069\n",
      "2022-11-08 21:54:14,897 INFO     Training average positive_sample_loss at step 582700: 0.158835\n",
      "2022-11-08 21:54:14,897 INFO     Training average negative_sample_loss at step 582700: 0.144843\n",
      "2022-11-08 21:54:14,897 INFO     Training average loss at step 582700: 0.151839\n",
      "2022-11-08 21:54:25,805 INFO     Training average positive_sample_loss at step 582800: 0.157977\n",
      "2022-11-08 21:54:25,805 INFO     Training average negative_sample_loss at step 582800: 0.143691\n",
      "2022-11-08 21:54:25,805 INFO     Training average loss at step 582800: 0.150834\n",
      "2022-11-08 21:54:35,498 INFO     Training average positive_sample_loss at step 582900: 0.155763\n",
      "2022-11-08 21:54:35,498 INFO     Training average negative_sample_loss at step 582900: 0.147772\n",
      "2022-11-08 21:54:35,498 INFO     Training average loss at step 582900: 0.151767\n",
      "2022-11-08 21:54:45,187 INFO     Training average positive_sample_loss at step 583000: 0.155310\n",
      "2022-11-08 21:54:45,187 INFO     Training average negative_sample_loss at step 583000: 0.144723\n",
      "2022-11-08 21:54:45,187 INFO     Training average loss at step 583000: 0.150017\n",
      "2022-11-08 21:54:55,713 INFO     Training average positive_sample_loss at step 583100: 0.157880\n",
      "2022-11-08 21:54:55,713 INFO     Training average negative_sample_loss at step 583100: 0.146215\n",
      "2022-11-08 21:54:55,713 INFO     Training average loss at step 583100: 0.152047\n",
      "2022-11-08 21:55:05,402 INFO     Training average positive_sample_loss at step 583200: 0.155288\n",
      "2022-11-08 21:55:05,402 INFO     Training average negative_sample_loss at step 583200: 0.140120\n",
      "2022-11-08 21:55:05,402 INFO     Training average loss at step 583200: 0.147704\n",
      "2022-11-08 21:55:15,093 INFO     Training average positive_sample_loss at step 583300: 0.153614\n",
      "2022-11-08 21:55:15,093 INFO     Training average negative_sample_loss at step 583300: 0.141016\n",
      "2022-11-08 21:55:15,093 INFO     Training average loss at step 583300: 0.147315\n",
      "2022-11-08 21:55:24,786 INFO     Training average positive_sample_loss at step 583400: 0.158389\n",
      "2022-11-08 21:55:24,786 INFO     Training average negative_sample_loss at step 583400: 0.145324\n",
      "2022-11-08 21:55:24,786 INFO     Training average loss at step 583400: 0.151857\n",
      "2022-11-08 21:55:34,476 INFO     Training average positive_sample_loss at step 583500: 0.158534\n",
      "2022-11-08 21:55:34,477 INFO     Training average negative_sample_loss at step 583500: 0.141682\n",
      "2022-11-08 21:55:34,477 INFO     Training average loss at step 583500: 0.150108\n",
      "2022-11-08 21:55:44,174 INFO     Training average positive_sample_loss at step 583600: 0.151879\n",
      "2022-11-08 21:55:44,174 INFO     Training average negative_sample_loss at step 583600: 0.140946\n",
      "2022-11-08 21:55:44,174 INFO     Training average loss at step 583600: 0.146412\n",
      "2022-11-08 21:55:53,866 INFO     Training average positive_sample_loss at step 583700: 0.157832\n",
      "2022-11-08 21:55:53,866 INFO     Training average negative_sample_loss at step 583700: 0.143450\n",
      "2022-11-08 21:55:53,866 INFO     Training average loss at step 583700: 0.150641\n",
      "2022-11-08 21:56:03,559 INFO     Training average positive_sample_loss at step 583800: 0.155884\n",
      "2022-11-08 21:56:03,559 INFO     Training average negative_sample_loss at step 583800: 0.146612\n",
      "2022-11-08 21:56:03,559 INFO     Training average loss at step 583800: 0.151248\n",
      "2022-11-08 21:56:13,252 INFO     Training average positive_sample_loss at step 583900: 0.153106\n",
      "2022-11-08 21:56:13,252 INFO     Training average negative_sample_loss at step 583900: 0.142676\n",
      "2022-11-08 21:56:13,252 INFO     Training average loss at step 583900: 0.147891\n",
      "2022-11-08 21:56:22,946 INFO     Training average positive_sample_loss at step 584000: 0.161345\n",
      "2022-11-08 21:56:22,946 INFO     Training average negative_sample_loss at step 584000: 0.142908\n",
      "2022-11-08 21:56:22,946 INFO     Training average loss at step 584000: 0.152127\n",
      "2022-11-08 21:56:32,638 INFO     Training average positive_sample_loss at step 584100: 0.160956\n",
      "2022-11-08 21:56:32,638 INFO     Training average negative_sample_loss at step 584100: 0.145352\n",
      "2022-11-08 21:56:32,638 INFO     Training average loss at step 584100: 0.153154\n",
      "2022-11-08 21:56:42,339 INFO     Training average positive_sample_loss at step 584200: 0.158252\n",
      "2022-11-08 21:56:42,339 INFO     Training average negative_sample_loss at step 584200: 0.147898\n",
      "2022-11-08 21:56:42,339 INFO     Training average loss at step 584200: 0.153075\n",
      "2022-11-08 21:56:52,028 INFO     Training average positive_sample_loss at step 584300: 0.154872\n",
      "2022-11-08 21:56:52,028 INFO     Training average negative_sample_loss at step 584300: 0.147304\n",
      "2022-11-08 21:56:52,028 INFO     Training average loss at step 584300: 0.151088\n",
      "2022-11-08 21:57:01,720 INFO     Training average positive_sample_loss at step 584400: 0.158979\n",
      "2022-11-08 21:57:01,720 INFO     Training average negative_sample_loss at step 584400: 0.147584\n",
      "2022-11-08 21:57:01,720 INFO     Training average loss at step 584400: 0.153282\n",
      "2022-11-08 21:57:11,412 INFO     Training average positive_sample_loss at step 584500: 0.162576\n",
      "2022-11-08 21:57:11,412 INFO     Training average negative_sample_loss at step 584500: 0.143151\n",
      "2022-11-08 21:57:11,412 INFO     Training average loss at step 584500: 0.152863\n",
      "2022-11-08 21:57:21,105 INFO     Training average positive_sample_loss at step 584600: 0.156233\n",
      "2022-11-08 21:57:21,105 INFO     Training average negative_sample_loss at step 584600: 0.141106\n",
      "2022-11-08 21:57:21,105 INFO     Training average loss at step 584600: 0.148669\n",
      "2022-11-08 21:57:30,801 INFO     Training average positive_sample_loss at step 584700: 0.157005\n",
      "2022-11-08 21:57:30,801 INFO     Training average negative_sample_loss at step 584700: 0.146319\n",
      "2022-11-08 21:57:30,801 INFO     Training average loss at step 584700: 0.151662\n",
      "2022-11-08 21:57:40,490 INFO     Training average positive_sample_loss at step 584800: 0.151978\n",
      "2022-11-08 21:57:40,490 INFO     Training average negative_sample_loss at step 584800: 0.139893\n",
      "2022-11-08 21:57:40,490 INFO     Training average loss at step 584800: 0.145936\n",
      "2022-11-08 21:57:50,180 INFO     Training average positive_sample_loss at step 584900: 0.155188\n",
      "2022-11-08 21:57:50,181 INFO     Training average negative_sample_loss at step 584900: 0.144314\n",
      "2022-11-08 21:57:50,181 INFO     Training average loss at step 584900: 0.149751\n",
      "2022-11-08 21:57:59,873 INFO     Training average positive_sample_loss at step 585000: 0.159055\n",
      "2022-11-08 21:57:59,874 INFO     Training average negative_sample_loss at step 585000: 0.139890\n",
      "2022-11-08 21:57:59,874 INFO     Training average loss at step 585000: 0.149472\n",
      "2022-11-08 21:58:09,564 INFO     Training average positive_sample_loss at step 585100: 0.152206\n",
      "2022-11-08 21:58:09,565 INFO     Training average negative_sample_loss at step 585100: 0.145575\n",
      "2022-11-08 21:58:09,565 INFO     Training average loss at step 585100: 0.148891\n",
      "2022-11-08 21:58:19,258 INFO     Training average positive_sample_loss at step 585200: 0.154178\n",
      "2022-11-08 21:58:19,258 INFO     Training average negative_sample_loss at step 585200: 0.145439\n",
      "2022-11-08 21:58:19,258 INFO     Training average loss at step 585200: 0.149808\n",
      "2022-11-08 21:58:28,948 INFO     Training average positive_sample_loss at step 585300: 0.155671\n",
      "2022-11-08 21:58:28,948 INFO     Training average negative_sample_loss at step 585300: 0.140879\n",
      "2022-11-08 21:58:28,948 INFO     Training average loss at step 585300: 0.148275\n",
      "2022-11-08 21:58:38,638 INFO     Training average positive_sample_loss at step 585400: 0.156021\n",
      "2022-11-08 21:58:38,638 INFO     Training average negative_sample_loss at step 585400: 0.138983\n",
      "2022-11-08 21:58:38,638 INFO     Training average loss at step 585400: 0.147502\n",
      "2022-11-08 21:58:48,329 INFO     Training average positive_sample_loss at step 585500: 0.150414\n",
      "2022-11-08 21:58:48,329 INFO     Training average negative_sample_loss at step 585500: 0.141281\n",
      "2022-11-08 21:58:48,329 INFO     Training average loss at step 585500: 0.145848\n",
      "2022-11-08 21:58:58,017 INFO     Training average positive_sample_loss at step 585600: 0.155055\n",
      "2022-11-08 21:58:58,018 INFO     Training average negative_sample_loss at step 585600: 0.138693\n",
      "2022-11-08 21:58:58,018 INFO     Training average loss at step 585600: 0.146874\n",
      "2022-11-08 21:59:07,710 INFO     Training average positive_sample_loss at step 585700: 0.156604\n",
      "2022-11-08 21:59:07,710 INFO     Training average negative_sample_loss at step 585700: 0.141143\n",
      "2022-11-08 21:59:07,710 INFO     Training average loss at step 585700: 0.148873\n",
      "2022-11-08 21:59:17,402 INFO     Training average positive_sample_loss at step 585800: 0.154972\n",
      "2022-11-08 21:59:17,403 INFO     Training average negative_sample_loss at step 585800: 0.137136\n",
      "2022-11-08 21:59:17,403 INFO     Training average loss at step 585800: 0.146054\n",
      "2022-11-08 21:59:27,090 INFO     Training average positive_sample_loss at step 585900: 0.152935\n",
      "2022-11-08 21:59:27,090 INFO     Training average negative_sample_loss at step 585900: 0.149324\n",
      "2022-11-08 21:59:27,090 INFO     Training average loss at step 585900: 0.151129\n",
      "2022-11-08 21:59:36,780 INFO     Training average positive_sample_loss at step 586000: 0.153944\n",
      "2022-11-08 21:59:36,780 INFO     Training average negative_sample_loss at step 586000: 0.140125\n",
      "2022-11-08 21:59:36,780 INFO     Training average loss at step 586000: 0.147035\n",
      "2022-11-08 21:59:46,479 INFO     Training average positive_sample_loss at step 586100: 0.153622\n",
      "2022-11-08 21:59:46,479 INFO     Training average negative_sample_loss at step 586100: 0.144094\n",
      "2022-11-08 21:59:46,480 INFO     Training average loss at step 586100: 0.148858\n",
      "2022-11-08 21:59:56,169 INFO     Training average positive_sample_loss at step 586200: 0.156057\n",
      "2022-11-08 21:59:56,169 INFO     Training average negative_sample_loss at step 586200: 0.144840\n",
      "2022-11-08 21:59:56,169 INFO     Training average loss at step 586200: 0.150449\n",
      "2022-11-08 22:00:05,862 INFO     Training average positive_sample_loss at step 586300: 0.162298\n",
      "2022-11-08 22:00:05,863 INFO     Training average negative_sample_loss at step 586300: 0.142922\n",
      "2022-11-08 22:00:05,863 INFO     Training average loss at step 586300: 0.152610\n",
      "2022-11-08 22:00:15,554 INFO     Training average positive_sample_loss at step 586400: 0.152165\n",
      "2022-11-08 22:00:15,554 INFO     Training average negative_sample_loss at step 586400: 0.142435\n",
      "2022-11-08 22:00:15,554 INFO     Training average loss at step 586400: 0.147300\n",
      "2022-11-08 22:00:25,242 INFO     Training average positive_sample_loss at step 586500: 0.155964\n",
      "2022-11-08 22:00:25,242 INFO     Training average negative_sample_loss at step 586500: 0.141519\n",
      "2022-11-08 22:00:25,242 INFO     Training average loss at step 586500: 0.148742\n",
      "2022-11-08 22:00:34,255 INFO     Training average positive_sample_loss at step 586600: 0.152190\n",
      "2022-11-08 22:00:34,255 INFO     Training average negative_sample_loss at step 586600: 0.147601\n",
      "2022-11-08 22:00:34,255 INFO     Training average loss at step 586600: 0.149895\n",
      "2022-11-08 22:00:43,949 INFO     Training average positive_sample_loss at step 586700: 0.150089\n",
      "2022-11-08 22:00:43,949 INFO     Training average negative_sample_loss at step 586700: 0.138248\n",
      "2022-11-08 22:00:43,949 INFO     Training average loss at step 586700: 0.144168\n",
      "2022-11-08 22:00:53,638 INFO     Training average positive_sample_loss at step 586800: 0.152021\n",
      "2022-11-08 22:00:53,638 INFO     Training average negative_sample_loss at step 586800: 0.145469\n",
      "2022-11-08 22:00:53,638 INFO     Training average loss at step 586800: 0.148745\n",
      "2022-11-08 22:01:03,330 INFO     Training average positive_sample_loss at step 586900: 0.149880\n",
      "2022-11-08 22:01:03,330 INFO     Training average negative_sample_loss at step 586900: 0.142723\n",
      "2022-11-08 22:01:03,330 INFO     Training average loss at step 586900: 0.146302\n",
      "2022-11-08 22:01:13,025 INFO     Training average positive_sample_loss at step 587000: 0.153424\n",
      "2022-11-08 22:01:13,025 INFO     Training average negative_sample_loss at step 587000: 0.145298\n",
      "2022-11-08 22:01:13,025 INFO     Training average loss at step 587000: 0.149361\n",
      "2022-11-08 22:01:22,716 INFO     Training average positive_sample_loss at step 587100: 0.154179\n",
      "2022-11-08 22:01:22,717 INFO     Training average negative_sample_loss at step 587100: 0.145306\n",
      "2022-11-08 22:01:22,717 INFO     Training average loss at step 587100: 0.149743\n",
      "2022-11-08 22:01:31,768 INFO     Training average positive_sample_loss at step 587200: 0.158760\n",
      "2022-11-08 22:01:31,769 INFO     Training average negative_sample_loss at step 587200: 0.142638\n",
      "2022-11-08 22:01:31,769 INFO     Training average loss at step 587200: 0.150699\n",
      "2022-11-08 22:01:41,463 INFO     Training average positive_sample_loss at step 587300: 0.154691\n",
      "2022-11-08 22:01:41,463 INFO     Training average negative_sample_loss at step 587300: 0.144621\n",
      "2022-11-08 22:01:41,463 INFO     Training average loss at step 587300: 0.149656\n",
      "2022-11-08 22:01:51,161 INFO     Training average positive_sample_loss at step 587400: 0.159795\n",
      "2022-11-08 22:01:51,161 INFO     Training average negative_sample_loss at step 587400: 0.139165\n",
      "2022-11-08 22:01:51,161 INFO     Training average loss at step 587400: 0.149480\n",
      "2022-11-08 22:02:02,085 INFO     Training average positive_sample_loss at step 587500: 0.158231\n",
      "2022-11-08 22:02:02,085 INFO     Training average negative_sample_loss at step 587500: 0.143021\n",
      "2022-11-08 22:02:02,085 INFO     Training average loss at step 587500: 0.150626\n",
      "2022-11-08 22:02:11,782 INFO     Training average positive_sample_loss at step 587600: 0.157121\n",
      "2022-11-08 22:02:11,782 INFO     Training average negative_sample_loss at step 587600: 0.142117\n",
      "2022-11-08 22:02:11,782 INFO     Training average loss at step 587600: 0.149619\n",
      "2022-11-08 22:02:21,475 INFO     Training average positive_sample_loss at step 587700: 0.153573\n",
      "2022-11-08 22:02:21,475 INFO     Training average negative_sample_loss at step 587700: 0.145777\n",
      "2022-11-08 22:02:21,475 INFO     Training average loss at step 587700: 0.149675\n",
      "2022-11-08 22:02:32,055 INFO     Training average positive_sample_loss at step 587800: 0.155793\n",
      "2022-11-08 22:02:32,055 INFO     Training average negative_sample_loss at step 587800: 0.148237\n",
      "2022-11-08 22:02:32,055 INFO     Training average loss at step 587800: 0.152015\n",
      "2022-11-08 22:02:41,745 INFO     Training average positive_sample_loss at step 587900: 0.154876\n",
      "2022-11-08 22:02:41,745 INFO     Training average negative_sample_loss at step 587900: 0.136831\n",
      "2022-11-08 22:02:41,745 INFO     Training average loss at step 587900: 0.145854\n",
      "2022-11-08 22:02:51,437 INFO     Training average positive_sample_loss at step 588000: 0.150246\n",
      "2022-11-08 22:02:51,437 INFO     Training average negative_sample_loss at step 588000: 0.143106\n",
      "2022-11-08 22:02:51,437 INFO     Training average loss at step 588000: 0.146676\n",
      "2022-11-08 22:03:01,134 INFO     Training average positive_sample_loss at step 588100: 0.152121\n",
      "2022-11-08 22:03:01,134 INFO     Training average negative_sample_loss at step 588100: 0.144842\n",
      "2022-11-08 22:03:01,134 INFO     Training average loss at step 588100: 0.148482\n",
      "2022-11-08 22:03:10,830 INFO     Training average positive_sample_loss at step 588200: 0.158240\n",
      "2022-11-08 22:03:10,830 INFO     Training average negative_sample_loss at step 588200: 0.141032\n",
      "2022-11-08 22:03:10,830 INFO     Training average loss at step 588200: 0.149636\n",
      "2022-11-08 22:03:20,520 INFO     Training average positive_sample_loss at step 588300: 0.151705\n",
      "2022-11-08 22:03:20,520 INFO     Training average negative_sample_loss at step 588300: 0.146015\n",
      "2022-11-08 22:03:20,520 INFO     Training average loss at step 588300: 0.148860\n",
      "2022-11-08 22:03:30,209 INFO     Training average positive_sample_loss at step 588400: 0.150865\n",
      "2022-11-08 22:03:30,209 INFO     Training average negative_sample_loss at step 588400: 0.145556\n",
      "2022-11-08 22:03:30,209 INFO     Training average loss at step 588400: 0.148210\n",
      "2022-11-08 22:03:39,902 INFO     Training average positive_sample_loss at step 588500: 0.150602\n",
      "2022-11-08 22:03:39,902 INFO     Training average negative_sample_loss at step 588500: 0.143821\n",
      "2022-11-08 22:03:39,902 INFO     Training average loss at step 588500: 0.147212\n",
      "2022-11-08 22:03:49,594 INFO     Training average positive_sample_loss at step 588600: 0.150708\n",
      "2022-11-08 22:03:49,594 INFO     Training average negative_sample_loss at step 588600: 0.150430\n",
      "2022-11-08 22:03:49,594 INFO     Training average loss at step 588600: 0.150569\n",
      "2022-11-08 22:03:59,290 INFO     Training average positive_sample_loss at step 588700: 0.156520\n",
      "2022-11-08 22:03:59,290 INFO     Training average negative_sample_loss at step 588700: 0.145803\n",
      "2022-11-08 22:03:59,290 INFO     Training average loss at step 588700: 0.151161\n",
      "2022-11-08 22:04:08,986 INFO     Training average positive_sample_loss at step 588800: 0.156083\n",
      "2022-11-08 22:04:08,986 INFO     Training average negative_sample_loss at step 588800: 0.147264\n",
      "2022-11-08 22:04:08,986 INFO     Training average loss at step 588800: 0.151673\n",
      "2022-11-08 22:04:18,674 INFO     Training average positive_sample_loss at step 588900: 0.154102\n",
      "2022-11-08 22:04:18,674 INFO     Training average negative_sample_loss at step 588900: 0.142662\n",
      "2022-11-08 22:04:18,674 INFO     Training average loss at step 588900: 0.148382\n",
      "2022-11-08 22:04:28,364 INFO     Training average positive_sample_loss at step 589000: 0.154675\n",
      "2022-11-08 22:04:28,364 INFO     Training average negative_sample_loss at step 589000: 0.147049\n",
      "2022-11-08 22:04:28,364 INFO     Training average loss at step 589000: 0.150862\n",
      "2022-11-08 22:04:38,058 INFO     Training average positive_sample_loss at step 589100: 0.158341\n",
      "2022-11-08 22:04:38,058 INFO     Training average negative_sample_loss at step 589100: 0.142892\n",
      "2022-11-08 22:04:38,058 INFO     Training average loss at step 589100: 0.150617\n",
      "2022-11-08 22:04:47,750 INFO     Training average positive_sample_loss at step 589200: 0.150201\n",
      "2022-11-08 22:04:47,750 INFO     Training average negative_sample_loss at step 589200: 0.145057\n",
      "2022-11-08 22:04:47,751 INFO     Training average loss at step 589200: 0.147629\n",
      "2022-11-08 22:04:57,443 INFO     Training average positive_sample_loss at step 589300: 0.158536\n",
      "2022-11-08 22:04:57,443 INFO     Training average negative_sample_loss at step 589300: 0.143650\n",
      "2022-11-08 22:04:57,443 INFO     Training average loss at step 589300: 0.151093\n",
      "2022-11-08 22:05:07,140 INFO     Training average positive_sample_loss at step 589400: 0.155882\n",
      "2022-11-08 22:05:07,140 INFO     Training average negative_sample_loss at step 589400: 0.141632\n",
      "2022-11-08 22:05:07,140 INFO     Training average loss at step 589400: 0.148757\n",
      "2022-11-08 22:05:16,828 INFO     Training average positive_sample_loss at step 589500: 0.151674\n",
      "2022-11-08 22:05:16,828 INFO     Training average negative_sample_loss at step 589500: 0.145096\n",
      "2022-11-08 22:05:16,828 INFO     Training average loss at step 589500: 0.148385\n",
      "2022-11-08 22:05:26,522 INFO     Training average positive_sample_loss at step 589600: 0.157531\n",
      "2022-11-08 22:05:26,522 INFO     Training average negative_sample_loss at step 589600: 0.142888\n",
      "2022-11-08 22:05:26,522 INFO     Training average loss at step 589600: 0.150209\n",
      "2022-11-08 22:05:36,216 INFO     Training average positive_sample_loss at step 589700: 0.152038\n",
      "2022-11-08 22:05:36,217 INFO     Training average negative_sample_loss at step 589700: 0.142340\n",
      "2022-11-08 22:05:36,217 INFO     Training average loss at step 589700: 0.147189\n",
      "2022-11-08 22:05:45,908 INFO     Training average positive_sample_loss at step 589800: 0.159390\n",
      "2022-11-08 22:05:45,908 INFO     Training average negative_sample_loss at step 589800: 0.142669\n",
      "2022-11-08 22:05:45,908 INFO     Training average loss at step 589800: 0.151029\n",
      "2022-11-08 22:05:55,600 INFO     Training average positive_sample_loss at step 589900: 0.154590\n",
      "2022-11-08 22:05:55,600 INFO     Training average negative_sample_loss at step 589900: 0.143313\n",
      "2022-11-08 22:05:55,600 INFO     Training average loss at step 589900: 0.148952\n",
      "2022-11-08 22:06:08,172 INFO     Training average positive_sample_loss at step 590000: 0.151831\n",
      "2022-11-08 22:06:08,172 INFO     Training average negative_sample_loss at step 590000: 0.147810\n",
      "2022-11-08 22:06:08,172 INFO     Training average loss at step 590000: 0.149821\n",
      "2022-11-08 22:06:17,864 INFO     Training average positive_sample_loss at step 590100: 0.150362\n",
      "2022-11-08 22:06:17,864 INFO     Training average negative_sample_loss at step 590100: 0.143134\n",
      "2022-11-08 22:06:17,864 INFO     Training average loss at step 590100: 0.146748\n",
      "2022-11-08 22:06:27,559 INFO     Training average positive_sample_loss at step 590200: 0.159401\n",
      "2022-11-08 22:06:27,559 INFO     Training average negative_sample_loss at step 590200: 0.143386\n",
      "2022-11-08 22:06:27,559 INFO     Training average loss at step 590200: 0.151394\n",
      "2022-11-08 22:06:37,250 INFO     Training average positive_sample_loss at step 590300: 0.148950\n",
      "2022-11-08 22:06:37,250 INFO     Training average negative_sample_loss at step 590300: 0.143915\n",
      "2022-11-08 22:06:37,250 INFO     Training average loss at step 590300: 0.146433\n",
      "2022-11-08 22:06:46,937 INFO     Training average positive_sample_loss at step 590400: 0.152340\n",
      "2022-11-08 22:06:46,937 INFO     Training average negative_sample_loss at step 590400: 0.141258\n",
      "2022-11-08 22:06:46,937 INFO     Training average loss at step 590400: 0.146799\n",
      "2022-11-08 22:06:56,625 INFO     Training average positive_sample_loss at step 590500: 0.151861\n",
      "2022-11-08 22:06:56,625 INFO     Training average negative_sample_loss at step 590500: 0.146771\n",
      "2022-11-08 22:06:56,625 INFO     Training average loss at step 590500: 0.149316\n",
      "2022-11-08 22:07:06,323 INFO     Training average positive_sample_loss at step 590600: 0.154785\n",
      "2022-11-08 22:07:06,324 INFO     Training average negative_sample_loss at step 590600: 0.144262\n",
      "2022-11-08 22:07:06,324 INFO     Training average loss at step 590600: 0.149524\n",
      "2022-11-08 22:07:16,022 INFO     Training average positive_sample_loss at step 590700: 0.152939\n",
      "2022-11-08 22:07:16,022 INFO     Training average negative_sample_loss at step 590700: 0.144150\n",
      "2022-11-08 22:07:16,022 INFO     Training average loss at step 590700: 0.148545\n",
      "2022-11-08 22:07:25,715 INFO     Training average positive_sample_loss at step 590800: 0.158513\n",
      "2022-11-08 22:07:25,715 INFO     Training average negative_sample_loss at step 590800: 0.142097\n",
      "2022-11-08 22:07:25,715 INFO     Training average loss at step 590800: 0.150305\n",
      "2022-11-08 22:07:35,409 INFO     Training average positive_sample_loss at step 590900: 0.151669\n",
      "2022-11-08 22:07:35,409 INFO     Training average negative_sample_loss at step 590900: 0.142191\n",
      "2022-11-08 22:07:35,409 INFO     Training average loss at step 590900: 0.146930\n",
      "2022-11-08 22:07:45,099 INFO     Training average positive_sample_loss at step 591000: 0.150526\n",
      "2022-11-08 22:07:45,100 INFO     Training average negative_sample_loss at step 591000: 0.143437\n",
      "2022-11-08 22:07:45,100 INFO     Training average loss at step 591000: 0.146982\n",
      "2022-11-08 22:07:54,799 INFO     Training average positive_sample_loss at step 591100: 0.160081\n",
      "2022-11-08 22:07:54,799 INFO     Training average negative_sample_loss at step 591100: 0.141412\n",
      "2022-11-08 22:07:54,800 INFO     Training average loss at step 591100: 0.150747\n",
      "2022-11-08 22:08:04,500 INFO     Training average positive_sample_loss at step 591200: 0.156515\n",
      "2022-11-08 22:08:04,500 INFO     Training average negative_sample_loss at step 591200: 0.144431\n",
      "2022-11-08 22:08:04,500 INFO     Training average loss at step 591200: 0.150473\n",
      "2022-11-08 22:08:14,196 INFO     Training average positive_sample_loss at step 591300: 0.155876\n",
      "2022-11-08 22:08:14,196 INFO     Training average negative_sample_loss at step 591300: 0.147618\n",
      "2022-11-08 22:08:14,196 INFO     Training average loss at step 591300: 0.151747\n",
      "2022-11-08 22:08:23,883 INFO     Training average positive_sample_loss at step 591400: 0.159518\n",
      "2022-11-08 22:08:23,883 INFO     Training average negative_sample_loss at step 591400: 0.141763\n",
      "2022-11-08 22:08:23,883 INFO     Training average loss at step 591400: 0.150641\n",
      "2022-11-08 22:08:33,576 INFO     Training average positive_sample_loss at step 591500: 0.158500\n",
      "2022-11-08 22:08:33,577 INFO     Training average negative_sample_loss at step 591500: 0.143645\n",
      "2022-11-08 22:08:33,577 INFO     Training average loss at step 591500: 0.151072\n",
      "2022-11-08 22:08:43,270 INFO     Training average positive_sample_loss at step 591600: 0.153402\n",
      "2022-11-08 22:08:43,270 INFO     Training average negative_sample_loss at step 591600: 0.144394\n",
      "2022-11-08 22:08:43,270 INFO     Training average loss at step 591600: 0.148898\n",
      "2022-11-08 22:08:52,964 INFO     Training average positive_sample_loss at step 591700: 0.150491\n",
      "2022-11-08 22:08:52,964 INFO     Training average negative_sample_loss at step 591700: 0.143316\n",
      "2022-11-08 22:08:52,964 INFO     Training average loss at step 591700: 0.146903\n",
      "2022-11-08 22:09:02,663 INFO     Training average positive_sample_loss at step 591800: 0.158087\n",
      "2022-11-08 22:09:02,663 INFO     Training average negative_sample_loss at step 591800: 0.143116\n",
      "2022-11-08 22:09:02,663 INFO     Training average loss at step 591800: 0.150602\n",
      "2022-11-08 22:09:12,354 INFO     Training average positive_sample_loss at step 591900: 0.155090\n",
      "2022-11-08 22:09:12,354 INFO     Training average negative_sample_loss at step 591900: 0.148584\n",
      "2022-11-08 22:09:12,354 INFO     Training average loss at step 591900: 0.151837\n",
      "2022-11-08 22:09:22,037 INFO     Training average positive_sample_loss at step 592000: 0.152207\n",
      "2022-11-08 22:09:22,037 INFO     Training average negative_sample_loss at step 592000: 0.142034\n",
      "2022-11-08 22:09:22,037 INFO     Training average loss at step 592000: 0.147120\n",
      "2022-11-08 22:09:31,061 INFO     Training average positive_sample_loss at step 592100: 0.148295\n",
      "2022-11-08 22:09:31,061 INFO     Training average negative_sample_loss at step 592100: 0.144733\n",
      "2022-11-08 22:09:31,061 INFO     Training average loss at step 592100: 0.146514\n",
      "2022-11-08 22:09:41,850 INFO     Training average positive_sample_loss at step 592200: 0.158020\n",
      "2022-11-08 22:09:41,850 INFO     Training average negative_sample_loss at step 592200: 0.146030\n",
      "2022-11-08 22:09:41,850 INFO     Training average loss at step 592200: 0.152025\n",
      "2022-11-08 22:09:51,541 INFO     Training average positive_sample_loss at step 592300: 0.154115\n",
      "2022-11-08 22:09:51,541 INFO     Training average negative_sample_loss at step 592300: 0.139908\n",
      "2022-11-08 22:09:51,541 INFO     Training average loss at step 592300: 0.147012\n",
      "2022-11-08 22:10:01,238 INFO     Training average positive_sample_loss at step 592400: 0.157100\n",
      "2022-11-08 22:10:01,238 INFO     Training average negative_sample_loss at step 592400: 0.141421\n",
      "2022-11-08 22:10:01,238 INFO     Training average loss at step 592400: 0.149260\n",
      "2022-11-08 22:10:11,902 INFO     Training average positive_sample_loss at step 592500: 0.157956\n",
      "2022-11-08 22:10:11,902 INFO     Training average negative_sample_loss at step 592500: 0.143786\n",
      "2022-11-08 22:10:11,902 INFO     Training average loss at step 592500: 0.150871\n",
      "2022-11-08 22:10:20,901 INFO     Training average positive_sample_loss at step 592600: 0.152288\n",
      "2022-11-08 22:10:20,902 INFO     Training average negative_sample_loss at step 592600: 0.141758\n",
      "2022-11-08 22:10:20,902 INFO     Training average loss at step 592600: 0.147023\n",
      "2022-11-08 22:10:30,599 INFO     Training average positive_sample_loss at step 592700: 0.161098\n",
      "2022-11-08 22:10:30,599 INFO     Training average negative_sample_loss at step 592700: 0.145212\n",
      "2022-11-08 22:10:30,599 INFO     Training average loss at step 592700: 0.153155\n",
      "2022-11-08 22:10:40,291 INFO     Training average positive_sample_loss at step 592800: 0.154285\n",
      "2022-11-08 22:10:40,291 INFO     Training average negative_sample_loss at step 592800: 0.144675\n",
      "2022-11-08 22:10:40,291 INFO     Training average loss at step 592800: 0.149480\n",
      "2022-11-08 22:10:49,981 INFO     Training average positive_sample_loss at step 592900: 0.152025\n",
      "2022-11-08 22:10:49,982 INFO     Training average negative_sample_loss at step 592900: 0.143043\n",
      "2022-11-08 22:10:49,982 INFO     Training average loss at step 592900: 0.147534\n",
      "2022-11-08 22:10:59,680 INFO     Training average positive_sample_loss at step 593000: 0.158541\n",
      "2022-11-08 22:10:59,680 INFO     Training average negative_sample_loss at step 593000: 0.140133\n",
      "2022-11-08 22:10:59,680 INFO     Training average loss at step 593000: 0.149337\n",
      "2022-11-08 22:11:09,373 INFO     Training average positive_sample_loss at step 593100: 0.159892\n",
      "2022-11-08 22:11:09,373 INFO     Training average negative_sample_loss at step 593100: 0.139564\n",
      "2022-11-08 22:11:09,373 INFO     Training average loss at step 593100: 0.149728\n",
      "2022-11-08 22:11:19,064 INFO     Training average positive_sample_loss at step 593200: 0.152277\n",
      "2022-11-08 22:11:19,065 INFO     Training average negative_sample_loss at step 593200: 0.141014\n",
      "2022-11-08 22:11:19,065 INFO     Training average loss at step 593200: 0.146645\n",
      "2022-11-08 22:11:28,763 INFO     Training average positive_sample_loss at step 593300: 0.153030\n",
      "2022-11-08 22:11:28,763 INFO     Training average negative_sample_loss at step 593300: 0.146176\n",
      "2022-11-08 22:11:28,763 INFO     Training average loss at step 593300: 0.149603\n",
      "2022-11-08 22:11:38,456 INFO     Training average positive_sample_loss at step 593400: 0.156187\n",
      "2022-11-08 22:11:38,456 INFO     Training average negative_sample_loss at step 593400: 0.143461\n",
      "2022-11-08 22:11:38,456 INFO     Training average loss at step 593400: 0.149824\n",
      "2022-11-08 22:11:48,149 INFO     Training average positive_sample_loss at step 593500: 0.148973\n",
      "2022-11-08 22:11:48,149 INFO     Training average negative_sample_loss at step 593500: 0.144632\n",
      "2022-11-08 22:11:48,149 INFO     Training average loss at step 593500: 0.146802\n",
      "2022-11-08 22:11:57,850 INFO     Training average positive_sample_loss at step 593600: 0.150027\n",
      "2022-11-08 22:11:57,850 INFO     Training average negative_sample_loss at step 593600: 0.140642\n",
      "2022-11-08 22:11:57,850 INFO     Training average loss at step 593600: 0.145335\n",
      "2022-11-08 22:12:07,541 INFO     Training average positive_sample_loss at step 593700: 0.154213\n",
      "2022-11-08 22:12:07,541 INFO     Training average negative_sample_loss at step 593700: 0.143579\n",
      "2022-11-08 22:12:07,541 INFO     Training average loss at step 593700: 0.148896\n",
      "2022-11-08 22:12:17,235 INFO     Training average positive_sample_loss at step 593800: 0.155260\n",
      "2022-11-08 22:12:17,235 INFO     Training average negative_sample_loss at step 593800: 0.141354\n",
      "2022-11-08 22:12:17,235 INFO     Training average loss at step 593800: 0.148307\n",
      "2022-11-08 22:12:26,928 INFO     Training average positive_sample_loss at step 593900: 0.153229\n",
      "2022-11-08 22:12:26,928 INFO     Training average negative_sample_loss at step 593900: 0.142336\n",
      "2022-11-08 22:12:26,928 INFO     Training average loss at step 593900: 0.147782\n",
      "2022-11-08 22:12:36,621 INFO     Training average positive_sample_loss at step 594000: 0.156007\n",
      "2022-11-08 22:12:36,621 INFO     Training average negative_sample_loss at step 594000: 0.145443\n",
      "2022-11-08 22:12:36,621 INFO     Training average loss at step 594000: 0.150725\n",
      "2022-11-08 22:12:46,315 INFO     Training average positive_sample_loss at step 594100: 0.149859\n",
      "2022-11-08 22:12:46,315 INFO     Training average negative_sample_loss at step 594100: 0.143441\n",
      "2022-11-08 22:12:46,315 INFO     Training average loss at step 594100: 0.146650\n",
      "2022-11-08 22:12:56,013 INFO     Training average positive_sample_loss at step 594200: 0.150201\n",
      "2022-11-08 22:12:56,013 INFO     Training average negative_sample_loss at step 594200: 0.142074\n",
      "2022-11-08 22:12:56,013 INFO     Training average loss at step 594200: 0.146137\n",
      "2022-11-08 22:13:05,706 INFO     Training average positive_sample_loss at step 594300: 0.154371\n",
      "2022-11-08 22:13:05,706 INFO     Training average negative_sample_loss at step 594300: 0.141960\n",
      "2022-11-08 22:13:05,706 INFO     Training average loss at step 594300: 0.148166\n",
      "2022-11-08 22:13:15,405 INFO     Training average positive_sample_loss at step 594400: 0.155077\n",
      "2022-11-08 22:13:15,406 INFO     Training average negative_sample_loss at step 594400: 0.142647\n",
      "2022-11-08 22:13:15,406 INFO     Training average loss at step 594400: 0.148862\n",
      "2022-11-08 22:13:25,099 INFO     Training average positive_sample_loss at step 594500: 0.153643\n",
      "2022-11-08 22:13:25,099 INFO     Training average negative_sample_loss at step 594500: 0.147311\n",
      "2022-11-08 22:13:25,099 INFO     Training average loss at step 594500: 0.150477\n",
      "2022-11-08 22:13:34,795 INFO     Training average positive_sample_loss at step 594600: 0.153070\n",
      "2022-11-08 22:13:34,795 INFO     Training average negative_sample_loss at step 594600: 0.141372\n",
      "2022-11-08 22:13:34,795 INFO     Training average loss at step 594600: 0.147221\n",
      "2022-11-08 22:13:44,490 INFO     Training average positive_sample_loss at step 594700: 0.155969\n",
      "2022-11-08 22:13:44,490 INFO     Training average negative_sample_loss at step 594700: 0.143437\n",
      "2022-11-08 22:13:44,490 INFO     Training average loss at step 594700: 0.149703\n",
      "2022-11-08 22:13:54,182 INFO     Training average positive_sample_loss at step 594800: 0.160413\n",
      "2022-11-08 22:13:54,182 INFO     Training average negative_sample_loss at step 594800: 0.143395\n",
      "2022-11-08 22:13:54,182 INFO     Training average loss at step 594800: 0.151904\n",
      "2022-11-08 22:14:03,878 INFO     Training average positive_sample_loss at step 594900: 0.155468\n",
      "2022-11-08 22:14:03,878 INFO     Training average negative_sample_loss at step 594900: 0.143884\n",
      "2022-11-08 22:14:03,878 INFO     Training average loss at step 594900: 0.149676\n",
      "2022-11-08 22:14:13,571 INFO     Training average positive_sample_loss at step 595000: 0.160207\n",
      "2022-11-08 22:14:13,571 INFO     Training average negative_sample_loss at step 595000: 0.145916\n",
      "2022-11-08 22:14:13,571 INFO     Training average loss at step 595000: 0.153062\n",
      "2022-11-08 22:14:23,264 INFO     Training average positive_sample_loss at step 595100: 0.152280\n",
      "2022-11-08 22:14:23,265 INFO     Training average negative_sample_loss at step 595100: 0.142886\n",
      "2022-11-08 22:14:23,265 INFO     Training average loss at step 595100: 0.147583\n",
      "2022-11-08 22:14:32,959 INFO     Training average positive_sample_loss at step 595200: 0.156920\n",
      "2022-11-08 22:14:32,959 INFO     Training average negative_sample_loss at step 595200: 0.141266\n",
      "2022-11-08 22:14:32,959 INFO     Training average loss at step 595200: 0.149093\n",
      "2022-11-08 22:14:42,651 INFO     Training average positive_sample_loss at step 595300: 0.154427\n",
      "2022-11-08 22:14:42,651 INFO     Training average negative_sample_loss at step 595300: 0.143557\n",
      "2022-11-08 22:14:42,651 INFO     Training average loss at step 595300: 0.148992\n",
      "2022-11-08 22:14:52,346 INFO     Training average positive_sample_loss at step 595400: 0.158270\n",
      "2022-11-08 22:14:52,346 INFO     Training average negative_sample_loss at step 595400: 0.141599\n",
      "2022-11-08 22:14:52,346 INFO     Training average loss at step 595400: 0.149935\n",
      "2022-11-08 22:15:02,043 INFO     Training average positive_sample_loss at step 595500: 0.158073\n",
      "2022-11-08 22:15:02,043 INFO     Training average negative_sample_loss at step 595500: 0.141781\n",
      "2022-11-08 22:15:02,043 INFO     Training average loss at step 595500: 0.149927\n",
      "2022-11-08 22:15:11,739 INFO     Training average positive_sample_loss at step 595600: 0.156204\n",
      "2022-11-08 22:15:11,739 INFO     Training average negative_sample_loss at step 595600: 0.145352\n",
      "2022-11-08 22:15:11,739 INFO     Training average loss at step 595600: 0.150778\n",
      "2022-11-08 22:15:21,436 INFO     Training average positive_sample_loss at step 595700: 0.149910\n",
      "2022-11-08 22:15:21,436 INFO     Training average negative_sample_loss at step 595700: 0.141633\n",
      "2022-11-08 22:15:21,436 INFO     Training average loss at step 595700: 0.145772\n",
      "2022-11-08 22:15:31,134 INFO     Training average positive_sample_loss at step 595800: 0.155857\n",
      "2022-11-08 22:15:31,134 INFO     Training average negative_sample_loss at step 595800: 0.143517\n",
      "2022-11-08 22:15:31,134 INFO     Training average loss at step 595800: 0.149687\n",
      "2022-11-08 22:15:40,823 INFO     Training average positive_sample_loss at step 595900: 0.158270\n",
      "2022-11-08 22:15:40,824 INFO     Training average negative_sample_loss at step 595900: 0.139701\n",
      "2022-11-08 22:15:40,824 INFO     Training average loss at step 595900: 0.148986\n",
      "2022-11-08 22:15:50,519 INFO     Training average positive_sample_loss at step 596000: 0.151096\n",
      "2022-11-08 22:15:50,519 INFO     Training average negative_sample_loss at step 596000: 0.139910\n",
      "2022-11-08 22:15:50,519 INFO     Training average loss at step 596000: 0.145503\n",
      "2022-11-08 22:16:00,218 INFO     Training average positive_sample_loss at step 596100: 0.153165\n",
      "2022-11-08 22:16:00,218 INFO     Training average negative_sample_loss at step 596100: 0.144813\n",
      "2022-11-08 22:16:00,218 INFO     Training average loss at step 596100: 0.148989\n",
      "2022-11-08 22:16:09,909 INFO     Training average positive_sample_loss at step 596200: 0.152020\n",
      "2022-11-08 22:16:09,909 INFO     Training average negative_sample_loss at step 596200: 0.146363\n",
      "2022-11-08 22:16:09,909 INFO     Training average loss at step 596200: 0.149191\n",
      "2022-11-08 22:16:19,606 INFO     Training average positive_sample_loss at step 596300: 0.155456\n",
      "2022-11-08 22:16:19,606 INFO     Training average negative_sample_loss at step 596300: 0.142022\n",
      "2022-11-08 22:16:19,606 INFO     Training average loss at step 596300: 0.148739\n",
      "2022-11-08 22:16:29,299 INFO     Training average positive_sample_loss at step 596400: 0.155976\n",
      "2022-11-08 22:16:29,299 INFO     Training average negative_sample_loss at step 596400: 0.142592\n",
      "2022-11-08 22:16:29,299 INFO     Training average loss at step 596400: 0.149284\n",
      "2022-11-08 22:16:38,991 INFO     Training average positive_sample_loss at step 596500: 0.156333\n",
      "2022-11-08 22:16:38,991 INFO     Training average negative_sample_loss at step 596500: 0.146388\n",
      "2022-11-08 22:16:38,991 INFO     Training average loss at step 596500: 0.151360\n",
      "2022-11-08 22:16:48,687 INFO     Training average positive_sample_loss at step 596600: 0.158388\n",
      "2022-11-08 22:16:48,687 INFO     Training average negative_sample_loss at step 596600: 0.146680\n",
      "2022-11-08 22:16:48,687 INFO     Training average loss at step 596600: 0.152534\n",
      "2022-11-08 22:16:58,382 INFO     Training average positive_sample_loss at step 596700: 0.149489\n",
      "2022-11-08 22:16:58,382 INFO     Training average negative_sample_loss at step 596700: 0.142738\n",
      "2022-11-08 22:16:58,382 INFO     Training average loss at step 596700: 0.146114\n",
      "2022-11-08 22:17:08,633 INFO     Training average positive_sample_loss at step 596800: 0.155913\n",
      "2022-11-08 22:17:08,633 INFO     Training average negative_sample_loss at step 596800: 0.139297\n",
      "2022-11-08 22:17:08,633 INFO     Training average loss at step 596800: 0.147605\n",
      "2022-11-08 22:17:18,857 INFO     Training average positive_sample_loss at step 596900: 0.154651\n",
      "2022-11-08 22:17:18,858 INFO     Training average negative_sample_loss at step 596900: 0.145942\n",
      "2022-11-08 22:17:18,858 INFO     Training average loss at step 596900: 0.150297\n",
      "2022-11-08 22:17:28,557 INFO     Training average positive_sample_loss at step 597000: 0.160890\n",
      "2022-11-08 22:17:28,557 INFO     Training average negative_sample_loss at step 597000: 0.139906\n",
      "2022-11-08 22:17:28,557 INFO     Training average loss at step 597000: 0.150398\n",
      "2022-11-08 22:17:38,251 INFO     Training average positive_sample_loss at step 597100: 0.156746\n",
      "2022-11-08 22:17:38,251 INFO     Training average negative_sample_loss at step 597100: 0.143251\n",
      "2022-11-08 22:17:38,251 INFO     Training average loss at step 597100: 0.149999\n",
      "2022-11-08 22:17:48,747 INFO     Training average positive_sample_loss at step 597200: 0.150650\n",
      "2022-11-08 22:17:48,747 INFO     Training average negative_sample_loss at step 597200: 0.140302\n",
      "2022-11-08 22:17:48,747 INFO     Training average loss at step 597200: 0.145476\n",
      "2022-11-08 22:17:58,442 INFO     Training average positive_sample_loss at step 597300: 0.154069\n",
      "2022-11-08 22:17:58,442 INFO     Training average negative_sample_loss at step 597300: 0.142174\n",
      "2022-11-08 22:17:58,442 INFO     Training average loss at step 597300: 0.148122\n",
      "2022-11-08 22:18:08,134 INFO     Training average positive_sample_loss at step 597400: 0.150477\n",
      "2022-11-08 22:18:08,134 INFO     Training average negative_sample_loss at step 597400: 0.141652\n",
      "2022-11-08 22:18:08,134 INFO     Training average loss at step 597400: 0.146064\n",
      "2022-11-08 22:18:17,139 INFO     Training average positive_sample_loss at step 597500: 0.154284\n",
      "2022-11-08 22:18:17,140 INFO     Training average negative_sample_loss at step 597500: 0.141196\n",
      "2022-11-08 22:18:17,140 INFO     Training average loss at step 597500: 0.147740\n",
      "2022-11-08 22:18:26,834 INFO     Training average positive_sample_loss at step 597600: 0.157130\n",
      "2022-11-08 22:18:26,834 INFO     Training average negative_sample_loss at step 597600: 0.142231\n",
      "2022-11-08 22:18:26,834 INFO     Training average loss at step 597600: 0.149681\n",
      "2022-11-08 22:18:36,527 INFO     Training average positive_sample_loss at step 597700: 0.157431\n",
      "2022-11-08 22:18:36,527 INFO     Training average negative_sample_loss at step 597700: 0.145816\n",
      "2022-11-08 22:18:36,527 INFO     Training average loss at step 597700: 0.151623\n",
      "2022-11-08 22:18:46,226 INFO     Training average positive_sample_loss at step 597800: 0.151926\n",
      "2022-11-08 22:18:46,226 INFO     Training average negative_sample_loss at step 597800: 0.141220\n",
      "2022-11-08 22:18:46,226 INFO     Training average loss at step 597800: 0.146573\n",
      "2022-11-08 22:18:55,919 INFO     Training average positive_sample_loss at step 597900: 0.157235\n",
      "2022-11-08 22:18:55,919 INFO     Training average negative_sample_loss at step 597900: 0.140835\n",
      "2022-11-08 22:18:55,919 INFO     Training average loss at step 597900: 0.149035\n",
      "2022-11-08 22:19:05,617 INFO     Training average positive_sample_loss at step 598000: 0.162340\n",
      "2022-11-08 22:19:05,617 INFO     Training average negative_sample_loss at step 598000: 0.145587\n",
      "2022-11-08 22:19:05,617 INFO     Training average loss at step 598000: 0.153963\n",
      "2022-11-08 22:19:14,602 INFO     Training average positive_sample_loss at step 598100: 0.155412\n",
      "2022-11-08 22:19:14,602 INFO     Training average negative_sample_loss at step 598100: 0.139102\n",
      "2022-11-08 22:19:14,602 INFO     Training average loss at step 598100: 0.147257\n",
      "2022-11-08 22:19:24,296 INFO     Training average positive_sample_loss at step 598200: 0.157733\n",
      "2022-11-08 22:19:24,296 INFO     Training average negative_sample_loss at step 598200: 0.144570\n",
      "2022-11-08 22:19:24,296 INFO     Training average loss at step 598200: 0.151151\n",
      "2022-11-08 22:19:33,989 INFO     Training average positive_sample_loss at step 598300: 0.156979\n",
      "2022-11-08 22:19:33,989 INFO     Training average negative_sample_loss at step 598300: 0.145007\n",
      "2022-11-08 22:19:33,989 INFO     Training average loss at step 598300: 0.150993\n",
      "2022-11-08 22:19:43,685 INFO     Training average positive_sample_loss at step 598400: 0.152889\n",
      "2022-11-08 22:19:43,685 INFO     Training average negative_sample_loss at step 598400: 0.145555\n",
      "2022-11-08 22:19:43,685 INFO     Training average loss at step 598400: 0.149222\n",
      "2022-11-08 22:19:53,376 INFO     Training average positive_sample_loss at step 598500: 0.153088\n",
      "2022-11-08 22:19:53,376 INFO     Training average negative_sample_loss at step 598500: 0.142553\n",
      "2022-11-08 22:19:53,376 INFO     Training average loss at step 598500: 0.147821\n",
      "2022-11-08 22:20:03,067 INFO     Training average positive_sample_loss at step 598600: 0.154322\n",
      "2022-11-08 22:20:03,068 INFO     Training average negative_sample_loss at step 598600: 0.145750\n",
      "2022-11-08 22:20:03,068 INFO     Training average loss at step 598600: 0.150036\n",
      "2022-11-08 22:20:12,764 INFO     Training average positive_sample_loss at step 598700: 0.155361\n",
      "2022-11-08 22:20:12,764 INFO     Training average negative_sample_loss at step 598700: 0.142432\n",
      "2022-11-08 22:20:12,764 INFO     Training average loss at step 598700: 0.148896\n",
      "2022-11-08 22:20:22,456 INFO     Training average positive_sample_loss at step 598800: 0.155148\n",
      "2022-11-08 22:20:22,456 INFO     Training average negative_sample_loss at step 598800: 0.141874\n",
      "2022-11-08 22:20:22,456 INFO     Training average loss at step 598800: 0.148511\n",
      "2022-11-08 22:20:32,151 INFO     Training average positive_sample_loss at step 598900: 0.152044\n",
      "2022-11-08 22:20:32,151 INFO     Training average negative_sample_loss at step 598900: 0.144217\n",
      "2022-11-08 22:20:32,151 INFO     Training average loss at step 598900: 0.148130\n",
      "2022-11-08 22:20:41,845 INFO     Training average positive_sample_loss at step 599000: 0.156934\n",
      "2022-11-08 22:20:41,845 INFO     Training average negative_sample_loss at step 599000: 0.148036\n",
      "2022-11-08 22:20:41,846 INFO     Training average loss at step 599000: 0.152485\n",
      "2022-11-08 22:20:51,536 INFO     Training average positive_sample_loss at step 599100: 0.153750\n",
      "2022-11-08 22:20:51,536 INFO     Training average negative_sample_loss at step 599100: 0.138323\n",
      "2022-11-08 22:20:51,536 INFO     Training average loss at step 599100: 0.146037\n",
      "2022-11-08 22:21:01,231 INFO     Training average positive_sample_loss at step 599200: 0.155949\n",
      "2022-11-08 22:21:01,231 INFO     Training average negative_sample_loss at step 599200: 0.145060\n",
      "2022-11-08 22:21:01,231 INFO     Training average loss at step 599200: 0.150504\n",
      "2022-11-08 22:21:10,927 INFO     Training average positive_sample_loss at step 599300: 0.150230\n",
      "2022-11-08 22:21:10,927 INFO     Training average negative_sample_loss at step 599300: 0.152542\n",
      "2022-11-08 22:21:10,927 INFO     Training average loss at step 599300: 0.151386\n",
      "2022-11-08 22:21:20,619 INFO     Training average positive_sample_loss at step 599400: 0.158435\n",
      "2022-11-08 22:21:20,620 INFO     Training average negative_sample_loss at step 599400: 0.145102\n",
      "2022-11-08 22:21:20,620 INFO     Training average loss at step 599400: 0.151768\n",
      "2022-11-08 22:21:30,314 INFO     Training average positive_sample_loss at step 599500: 0.155395\n",
      "2022-11-08 22:21:30,314 INFO     Training average negative_sample_loss at step 599500: 0.142948\n",
      "2022-11-08 22:21:30,314 INFO     Training average loss at step 599500: 0.149171\n",
      "2022-11-08 22:21:40,007 INFO     Training average positive_sample_loss at step 599600: 0.162362\n",
      "2022-11-08 22:21:40,007 INFO     Training average negative_sample_loss at step 599600: 0.146352\n",
      "2022-11-08 22:21:40,007 INFO     Training average loss at step 599600: 0.154357\n",
      "2022-11-08 22:21:49,697 INFO     Training average positive_sample_loss at step 599700: 0.153277\n",
      "2022-11-08 22:21:49,697 INFO     Training average negative_sample_loss at step 599700: 0.149924\n",
      "2022-11-08 22:21:49,697 INFO     Training average loss at step 599700: 0.151600\n",
      "2022-11-08 22:21:59,392 INFO     Training average positive_sample_loss at step 599800: 0.159992\n",
      "2022-11-08 22:21:59,392 INFO     Training average negative_sample_loss at step 599800: 0.143884\n",
      "2022-11-08 22:21:59,392 INFO     Training average loss at step 599800: 0.151938\n",
      "2022-11-08 22:22:09,088 INFO     Training average positive_sample_loss at step 599900: 0.157605\n",
      "2022-11-08 22:22:09,088 INFO     Training average negative_sample_loss at step 599900: 0.147377\n",
      "2022-11-08 22:22:09,088 INFO     Training average loss at step 599900: 0.152491\n",
      "2022-11-08 22:22:21,691 INFO     Training average positive_sample_loss at step 600000: 0.151735\n",
      "2022-11-08 22:22:21,691 INFO     Training average negative_sample_loss at step 600000: 0.145145\n",
      "2022-11-08 22:22:21,691 INFO     Training average loss at step 600000: 0.148440\n",
      "2022-11-08 22:22:31,385 INFO     Training average positive_sample_loss at step 600100: 0.160357\n",
      "2022-11-08 22:22:31,385 INFO     Training average negative_sample_loss at step 600100: 0.144736\n",
      "2022-11-08 22:22:31,385 INFO     Training average loss at step 600100: 0.152546\n",
      "2022-11-08 22:22:41,083 INFO     Training average positive_sample_loss at step 600200: 0.158251\n",
      "2022-11-08 22:22:41,083 INFO     Training average negative_sample_loss at step 600200: 0.144290\n",
      "2022-11-08 22:22:41,083 INFO     Training average loss at step 600200: 0.151271\n",
      "2022-11-08 22:22:50,776 INFO     Training average positive_sample_loss at step 600300: 0.160012\n",
      "2022-11-08 22:22:50,776 INFO     Training average negative_sample_loss at step 600300: 0.139268\n",
      "2022-11-08 22:22:50,776 INFO     Training average loss at step 600300: 0.149640\n",
      "2022-11-08 22:23:00,468 INFO     Training average positive_sample_loss at step 600400: 0.153556\n",
      "2022-11-08 22:23:00,468 INFO     Training average negative_sample_loss at step 600400: 0.140196\n",
      "2022-11-08 22:23:00,468 INFO     Training average loss at step 600400: 0.146876\n",
      "2022-11-08 22:23:10,165 INFO     Training average positive_sample_loss at step 600500: 0.156782\n",
      "2022-11-08 22:23:10,165 INFO     Training average negative_sample_loss at step 600500: 0.140311\n",
      "2022-11-08 22:23:10,165 INFO     Training average loss at step 600500: 0.148546\n",
      "2022-11-08 22:23:19,859 INFO     Training average positive_sample_loss at step 600600: 0.154274\n",
      "2022-11-08 22:23:19,859 INFO     Training average negative_sample_loss at step 600600: 0.143304\n",
      "2022-11-08 22:23:19,859 INFO     Training average loss at step 600600: 0.148789\n",
      "2022-11-08 22:23:29,554 INFO     Training average positive_sample_loss at step 600700: 0.153948\n",
      "2022-11-08 22:23:29,554 INFO     Training average negative_sample_loss at step 600700: 0.140359\n",
      "2022-11-08 22:23:29,555 INFO     Training average loss at step 600700: 0.147154\n",
      "2022-11-08 22:23:39,253 INFO     Training average positive_sample_loss at step 600800: 0.156523\n",
      "2022-11-08 22:23:39,253 INFO     Training average negative_sample_loss at step 600800: 0.144015\n",
      "2022-11-08 22:23:39,253 INFO     Training average loss at step 600800: 0.150269\n",
      "2022-11-08 22:23:48,944 INFO     Training average positive_sample_loss at step 600900: 0.153888\n",
      "2022-11-08 22:23:48,944 INFO     Training average negative_sample_loss at step 600900: 0.142924\n",
      "2022-11-08 22:23:48,944 INFO     Training average loss at step 600900: 0.148406\n",
      "2022-11-08 22:23:58,635 INFO     Training average positive_sample_loss at step 601000: 0.152181\n",
      "2022-11-08 22:23:58,635 INFO     Training average negative_sample_loss at step 601000: 0.143784\n",
      "2022-11-08 22:23:58,635 INFO     Training average loss at step 601000: 0.147982\n",
      "2022-11-08 22:24:08,335 INFO     Training average positive_sample_loss at step 601100: 0.159768\n",
      "2022-11-08 22:24:08,335 INFO     Training average negative_sample_loss at step 601100: 0.144936\n",
      "2022-11-08 22:24:08,335 INFO     Training average loss at step 601100: 0.152352\n",
      "2022-11-08 22:24:18,029 INFO     Training average positive_sample_loss at step 601200: 0.155821\n",
      "2022-11-08 22:24:18,029 INFO     Training average negative_sample_loss at step 601200: 0.137687\n",
      "2022-11-08 22:24:18,029 INFO     Training average loss at step 601200: 0.146754\n",
      "2022-11-08 22:24:27,724 INFO     Training average positive_sample_loss at step 601300: 0.152929\n",
      "2022-11-08 22:24:27,724 INFO     Training average negative_sample_loss at step 601300: 0.145209\n",
      "2022-11-08 22:24:27,724 INFO     Training average loss at step 601300: 0.149069\n",
      "2022-11-08 22:24:38,078 INFO     Training average positive_sample_loss at step 601400: 0.156796\n",
      "2022-11-08 22:24:38,078 INFO     Training average negative_sample_loss at step 601400: 0.144332\n",
      "2022-11-08 22:24:38,078 INFO     Training average loss at step 601400: 0.150564\n",
      "2022-11-08 22:24:48,175 INFO     Training average positive_sample_loss at step 601500: 0.151934\n",
      "2022-11-08 22:24:48,175 INFO     Training average negative_sample_loss at step 601500: 0.140869\n",
      "2022-11-08 22:24:48,175 INFO     Training average loss at step 601500: 0.146402\n",
      "2022-11-08 22:24:58,197 INFO     Training average positive_sample_loss at step 601600: 0.155934\n",
      "2022-11-08 22:24:58,198 INFO     Training average negative_sample_loss at step 601600: 0.142156\n",
      "2022-11-08 22:24:58,198 INFO     Training average loss at step 601600: 0.149045\n",
      "2022-11-08 22:25:07,895 INFO     Training average positive_sample_loss at step 601700: 0.157393\n",
      "2022-11-08 22:25:07,895 INFO     Training average negative_sample_loss at step 601700: 0.144920\n",
      "2022-11-08 22:25:07,895 INFO     Training average loss at step 601700: 0.151157\n",
      "2022-11-08 22:25:18,185 INFO     Training average positive_sample_loss at step 601800: 0.155055\n",
      "2022-11-08 22:25:18,186 INFO     Training average negative_sample_loss at step 601800: 0.146120\n",
      "2022-11-08 22:25:18,186 INFO     Training average loss at step 601800: 0.150588\n",
      "2022-11-08 22:25:28,171 INFO     Training average positive_sample_loss at step 601900: 0.155863\n",
      "2022-11-08 22:25:28,172 INFO     Training average negative_sample_loss at step 601900: 0.143294\n",
      "2022-11-08 22:25:28,172 INFO     Training average loss at step 601900: 0.149578\n",
      "2022-11-08 22:25:37,862 INFO     Training average positive_sample_loss at step 602000: 0.152961\n",
      "2022-11-08 22:25:37,863 INFO     Training average negative_sample_loss at step 602000: 0.141042\n",
      "2022-11-08 22:25:37,863 INFO     Training average loss at step 602000: 0.147001\n",
      "2022-11-08 22:25:47,555 INFO     Training average positive_sample_loss at step 602100: 0.152818\n",
      "2022-11-08 22:25:47,555 INFO     Training average negative_sample_loss at step 602100: 0.138716\n",
      "2022-11-08 22:25:47,555 INFO     Training average loss at step 602100: 0.145767\n",
      "2022-11-08 22:25:57,248 INFO     Training average positive_sample_loss at step 602200: 0.153646\n",
      "2022-11-08 22:25:57,248 INFO     Training average negative_sample_loss at step 602200: 0.146960\n",
      "2022-11-08 22:25:57,248 INFO     Training average loss at step 602200: 0.150303\n",
      "2022-11-08 22:26:06,945 INFO     Training average positive_sample_loss at step 602300: 0.153633\n",
      "2022-11-08 22:26:06,945 INFO     Training average negative_sample_loss at step 602300: 0.145147\n",
      "2022-11-08 22:26:06,945 INFO     Training average loss at step 602300: 0.149390\n",
      "2022-11-08 22:26:16,642 INFO     Training average positive_sample_loss at step 602400: 0.150760\n",
      "2022-11-08 22:26:16,642 INFO     Training average negative_sample_loss at step 602400: 0.148060\n",
      "2022-11-08 22:26:16,642 INFO     Training average loss at step 602400: 0.149410\n",
      "2022-11-08 22:26:26,333 INFO     Training average positive_sample_loss at step 602500: 0.156192\n",
      "2022-11-08 22:26:26,333 INFO     Training average negative_sample_loss at step 602500: 0.141473\n",
      "2022-11-08 22:26:26,333 INFO     Training average loss at step 602500: 0.148832\n",
      "2022-11-08 22:26:36,047 INFO     Training average positive_sample_loss at step 602600: 0.156903\n",
      "2022-11-08 22:26:36,047 INFO     Training average negative_sample_loss at step 602600: 0.142382\n",
      "2022-11-08 22:26:36,047 INFO     Training average loss at step 602600: 0.149643\n",
      "2022-11-08 22:26:45,742 INFO     Training average positive_sample_loss at step 602700: 0.152373\n",
      "2022-11-08 22:26:45,742 INFO     Training average negative_sample_loss at step 602700: 0.144483\n",
      "2022-11-08 22:26:45,742 INFO     Training average loss at step 602700: 0.148428\n",
      "2022-11-08 22:26:55,437 INFO     Training average positive_sample_loss at step 602800: 0.154913\n",
      "2022-11-08 22:26:55,438 INFO     Training average negative_sample_loss at step 602800: 0.144951\n",
      "2022-11-08 22:26:55,438 INFO     Training average loss at step 602800: 0.149932\n",
      "2022-11-08 22:27:05,135 INFO     Training average positive_sample_loss at step 602900: 0.157793\n",
      "2022-11-08 22:27:05,135 INFO     Training average negative_sample_loss at step 602900: 0.148725\n",
      "2022-11-08 22:27:05,135 INFO     Training average loss at step 602900: 0.153259\n",
      "2022-11-08 22:27:14,162 INFO     Training average positive_sample_loss at step 603000: 0.154398\n",
      "2022-11-08 22:27:14,162 INFO     Training average negative_sample_loss at step 603000: 0.146722\n",
      "2022-11-08 22:27:14,162 INFO     Training average loss at step 603000: 0.150560\n",
      "2022-11-08 22:27:23,856 INFO     Training average positive_sample_loss at step 603100: 0.155667\n",
      "2022-11-08 22:27:23,856 INFO     Training average negative_sample_loss at step 603100: 0.146063\n",
      "2022-11-08 22:27:23,856 INFO     Training average loss at step 603100: 0.150865\n",
      "2022-11-08 22:27:33,550 INFO     Training average positive_sample_loss at step 603200: 0.157661\n",
      "2022-11-08 22:27:33,550 INFO     Training average negative_sample_loss at step 603200: 0.143188\n",
      "2022-11-08 22:27:33,550 INFO     Training average loss at step 603200: 0.150424\n",
      "2022-11-08 22:27:43,246 INFO     Training average positive_sample_loss at step 603300: 0.152515\n",
      "2022-11-08 22:27:43,246 INFO     Training average negative_sample_loss at step 603300: 0.142781\n",
      "2022-11-08 22:27:43,246 INFO     Training average loss at step 603300: 0.147648\n",
      "2022-11-08 22:27:52,937 INFO     Training average positive_sample_loss at step 603400: 0.154176\n",
      "2022-11-08 22:27:52,937 INFO     Training average negative_sample_loss at step 603400: 0.144631\n",
      "2022-11-08 22:27:52,938 INFO     Training average loss at step 603400: 0.149404\n",
      "2022-11-08 22:28:02,571 INFO     Training average positive_sample_loss at step 603500: 0.155434\n",
      "2022-11-08 22:28:02,571 INFO     Training average negative_sample_loss at step 603500: 0.140546\n",
      "2022-11-08 22:28:02,572 INFO     Training average loss at step 603500: 0.147990\n",
      "2022-11-08 22:28:11,642 INFO     Training average positive_sample_loss at step 603600: 0.158337\n",
      "2022-11-08 22:28:11,643 INFO     Training average negative_sample_loss at step 603600: 0.141380\n",
      "2022-11-08 22:28:11,643 INFO     Training average loss at step 603600: 0.149858\n",
      "2022-11-08 22:28:21,336 INFO     Training average positive_sample_loss at step 603700: 0.155851\n",
      "2022-11-08 22:28:21,337 INFO     Training average negative_sample_loss at step 603700: 0.142544\n",
      "2022-11-08 22:28:21,337 INFO     Training average loss at step 603700: 0.149198\n",
      "2022-11-08 22:28:31,033 INFO     Training average positive_sample_loss at step 603800: 0.157208\n",
      "2022-11-08 22:28:31,033 INFO     Training average negative_sample_loss at step 603800: 0.140797\n",
      "2022-11-08 22:28:31,033 INFO     Training average loss at step 603800: 0.149003\n",
      "2022-11-08 22:28:40,729 INFO     Training average positive_sample_loss at step 603900: 0.152295\n",
      "2022-11-08 22:28:40,729 INFO     Training average negative_sample_loss at step 603900: 0.142284\n",
      "2022-11-08 22:28:40,729 INFO     Training average loss at step 603900: 0.147290\n",
      "2022-11-08 22:28:50,421 INFO     Training average positive_sample_loss at step 604000: 0.152747\n",
      "2022-11-08 22:28:50,421 INFO     Training average negative_sample_loss at step 604000: 0.143768\n",
      "2022-11-08 22:28:50,421 INFO     Training average loss at step 604000: 0.148258\n",
      "2022-11-08 22:29:00,119 INFO     Training average positive_sample_loss at step 604100: 0.153102\n",
      "2022-11-08 22:29:00,119 INFO     Training average negative_sample_loss at step 604100: 0.145539\n",
      "2022-11-08 22:29:00,119 INFO     Training average loss at step 604100: 0.149321\n",
      "2022-11-08 22:29:09,813 INFO     Training average positive_sample_loss at step 604200: 0.153531\n",
      "2022-11-08 22:29:09,813 INFO     Training average negative_sample_loss at step 604200: 0.145435\n",
      "2022-11-08 22:29:09,813 INFO     Training average loss at step 604200: 0.149483\n",
      "2022-11-08 22:29:19,507 INFO     Training average positive_sample_loss at step 604300: 0.152521\n",
      "2022-11-08 22:29:19,507 INFO     Training average negative_sample_loss at step 604300: 0.142959\n",
      "2022-11-08 22:29:19,507 INFO     Training average loss at step 604300: 0.147740\n",
      "2022-11-08 22:29:29,201 INFO     Training average positive_sample_loss at step 604400: 0.152686\n",
      "2022-11-08 22:29:29,201 INFO     Training average negative_sample_loss at step 604400: 0.140446\n",
      "2022-11-08 22:29:29,201 INFO     Training average loss at step 604400: 0.146566\n",
      "2022-11-08 22:29:38,893 INFO     Training average positive_sample_loss at step 604500: 0.156392\n",
      "2022-11-08 22:29:38,893 INFO     Training average negative_sample_loss at step 604500: 0.147308\n",
      "2022-11-08 22:29:38,893 INFO     Training average loss at step 604500: 0.151850\n",
      "2022-11-08 22:29:48,589 INFO     Training average positive_sample_loss at step 604600: 0.150960\n",
      "2022-11-08 22:29:48,589 INFO     Training average negative_sample_loss at step 604600: 0.146909\n",
      "2022-11-08 22:29:48,589 INFO     Training average loss at step 604600: 0.148934\n",
      "2022-11-08 22:29:58,282 INFO     Training average positive_sample_loss at step 604700: 0.155785\n",
      "2022-11-08 22:29:58,282 INFO     Training average negative_sample_loss at step 604700: 0.146776\n",
      "2022-11-08 22:29:58,282 INFO     Training average loss at step 604700: 0.151281\n",
      "2022-11-08 22:30:07,978 INFO     Training average positive_sample_loss at step 604800: 0.152520\n",
      "2022-11-08 22:30:07,978 INFO     Training average negative_sample_loss at step 604800: 0.143916\n",
      "2022-11-08 22:30:07,978 INFO     Training average loss at step 604800: 0.148218\n",
      "2022-11-08 22:30:17,671 INFO     Training average positive_sample_loss at step 604900: 0.158367\n",
      "2022-11-08 22:30:17,671 INFO     Training average negative_sample_loss at step 604900: 0.146528\n",
      "2022-11-08 22:30:17,671 INFO     Training average loss at step 604900: 0.152448\n",
      "2022-11-08 22:30:27,364 INFO     Training average positive_sample_loss at step 605000: 0.160916\n",
      "2022-11-08 22:30:27,364 INFO     Training average negative_sample_loss at step 605000: 0.146633\n",
      "2022-11-08 22:30:27,365 INFO     Training average loss at step 605000: 0.153774\n",
      "2022-11-08 22:30:37,059 INFO     Training average positive_sample_loss at step 605100: 0.152801\n",
      "2022-11-08 22:30:37,059 INFO     Training average negative_sample_loss at step 605100: 0.140189\n",
      "2022-11-08 22:30:37,059 INFO     Training average loss at step 605100: 0.146495\n",
      "2022-11-08 22:30:46,753 INFO     Training average positive_sample_loss at step 605200: 0.154520\n",
      "2022-11-08 22:30:46,753 INFO     Training average negative_sample_loss at step 605200: 0.139243\n",
      "2022-11-08 22:30:46,753 INFO     Training average loss at step 605200: 0.146881\n",
      "2022-11-08 22:30:56,449 INFO     Training average positive_sample_loss at step 605300: 0.149518\n",
      "2022-11-08 22:30:56,449 INFO     Training average negative_sample_loss at step 605300: 0.144376\n",
      "2022-11-08 22:30:56,449 INFO     Training average loss at step 605300: 0.146947\n",
      "2022-11-08 22:31:06,146 INFO     Training average positive_sample_loss at step 605400: 0.154280\n",
      "2022-11-08 22:31:06,146 INFO     Training average negative_sample_loss at step 605400: 0.143128\n",
      "2022-11-08 22:31:06,146 INFO     Training average loss at step 605400: 0.148704\n",
      "2022-11-08 22:31:15,837 INFO     Training average positive_sample_loss at step 605500: 0.161795\n",
      "2022-11-08 22:31:15,838 INFO     Training average negative_sample_loss at step 605500: 0.144124\n",
      "2022-11-08 22:31:15,838 INFO     Training average loss at step 605500: 0.152960\n",
      "2022-11-08 22:31:25,534 INFO     Training average positive_sample_loss at step 605600: 0.153474\n",
      "2022-11-08 22:31:25,534 INFO     Training average negative_sample_loss at step 605600: 0.141602\n",
      "2022-11-08 22:31:25,534 INFO     Training average loss at step 605600: 0.147538\n",
      "2022-11-08 22:31:35,231 INFO     Training average positive_sample_loss at step 605700: 0.146915\n",
      "2022-11-08 22:31:35,231 INFO     Training average negative_sample_loss at step 605700: 0.141319\n",
      "2022-11-08 22:31:35,231 INFO     Training average loss at step 605700: 0.144117\n",
      "2022-11-08 22:31:44,922 INFO     Training average positive_sample_loss at step 605800: 0.159587\n",
      "2022-11-08 22:31:44,922 INFO     Training average negative_sample_loss at step 605800: 0.142097\n",
      "2022-11-08 22:31:44,923 INFO     Training average loss at step 605800: 0.150842\n",
      "2022-11-08 22:31:54,620 INFO     Training average positive_sample_loss at step 605900: 0.149143\n",
      "2022-11-08 22:31:54,620 INFO     Training average negative_sample_loss at step 605900: 0.143272\n",
      "2022-11-08 22:31:54,620 INFO     Training average loss at step 605900: 0.146208\n",
      "2022-11-08 22:32:04,316 INFO     Training average positive_sample_loss at step 606000: 0.156312\n",
      "2022-11-08 22:32:04,316 INFO     Training average negative_sample_loss at step 606000: 0.142782\n",
      "2022-11-08 22:32:04,316 INFO     Training average loss at step 606000: 0.149547\n",
      "2022-11-08 22:32:14,606 INFO     Training average positive_sample_loss at step 606100: 0.153887\n",
      "2022-11-08 22:32:14,606 INFO     Training average negative_sample_loss at step 606100: 0.146579\n",
      "2022-11-08 22:32:14,606 INFO     Training average loss at step 606100: 0.150233\n",
      "2022-11-08 22:32:24,691 INFO     Training average positive_sample_loss at step 606200: 0.155902\n",
      "2022-11-08 22:32:24,691 INFO     Training average negative_sample_loss at step 606200: 0.145191\n",
      "2022-11-08 22:32:24,692 INFO     Training average loss at step 606200: 0.150546\n",
      "2022-11-08 22:32:34,698 INFO     Training average positive_sample_loss at step 606300: 0.153360\n",
      "2022-11-08 22:32:34,698 INFO     Training average negative_sample_loss at step 606300: 0.144894\n",
      "2022-11-08 22:32:34,699 INFO     Training average loss at step 606300: 0.149127\n",
      "2022-11-08 22:32:44,396 INFO     Training average positive_sample_loss at step 606400: 0.153850\n",
      "2022-11-08 22:32:44,396 INFO     Training average negative_sample_loss at step 606400: 0.142041\n",
      "2022-11-08 22:32:44,396 INFO     Training average loss at step 606400: 0.147945\n",
      "2022-11-08 22:32:54,875 INFO     Training average positive_sample_loss at step 606500: 0.159169\n",
      "2022-11-08 22:32:54,875 INFO     Training average negative_sample_loss at step 606500: 0.146590\n",
      "2022-11-08 22:32:54,875 INFO     Training average loss at step 606500: 0.152880\n",
      "2022-11-08 22:33:04,568 INFO     Training average positive_sample_loss at step 606600: 0.154035\n",
      "2022-11-08 22:33:04,568 INFO     Training average negative_sample_loss at step 606600: 0.148450\n",
      "2022-11-08 22:33:04,568 INFO     Training average loss at step 606600: 0.151242\n",
      "2022-11-08 22:33:14,261 INFO     Training average positive_sample_loss at step 606700: 0.153491\n",
      "2022-11-08 22:33:14,261 INFO     Training average negative_sample_loss at step 606700: 0.138553\n",
      "2022-11-08 22:33:14,261 INFO     Training average loss at step 606700: 0.146022\n",
      "2022-11-08 22:33:23,959 INFO     Training average positive_sample_loss at step 606800: 0.156384\n",
      "2022-11-08 22:33:23,959 INFO     Training average negative_sample_loss at step 606800: 0.143467\n",
      "2022-11-08 22:33:23,959 INFO     Training average loss at step 606800: 0.149926\n",
      "2022-11-08 22:33:33,652 INFO     Training average positive_sample_loss at step 606900: 0.158330\n",
      "2022-11-08 22:33:33,652 INFO     Training average negative_sample_loss at step 606900: 0.142892\n",
      "2022-11-08 22:33:33,652 INFO     Training average loss at step 606900: 0.150611\n",
      "2022-11-08 22:33:43,346 INFO     Training average positive_sample_loss at step 607000: 0.158178\n",
      "2022-11-08 22:33:43,346 INFO     Training average negative_sample_loss at step 607000: 0.147081\n",
      "2022-11-08 22:33:43,346 INFO     Training average loss at step 607000: 0.152630\n",
      "2022-11-08 22:33:53,041 INFO     Training average positive_sample_loss at step 607100: 0.154288\n",
      "2022-11-08 22:33:53,041 INFO     Training average negative_sample_loss at step 607100: 0.141958\n",
      "2022-11-08 22:33:53,041 INFO     Training average loss at step 607100: 0.148123\n",
      "2022-11-08 22:34:02,731 INFO     Training average positive_sample_loss at step 607200: 0.157311\n",
      "2022-11-08 22:34:02,732 INFO     Training average negative_sample_loss at step 607200: 0.141875\n",
      "2022-11-08 22:34:02,732 INFO     Training average loss at step 607200: 0.149593\n",
      "2022-11-08 22:34:12,426 INFO     Training average positive_sample_loss at step 607300: 0.151763\n",
      "2022-11-08 22:34:12,426 INFO     Training average negative_sample_loss at step 607300: 0.140490\n",
      "2022-11-08 22:34:12,426 INFO     Training average loss at step 607300: 0.146126\n",
      "2022-11-08 22:34:22,126 INFO     Training average positive_sample_loss at step 607400: 0.157614\n",
      "2022-11-08 22:34:22,126 INFO     Training average negative_sample_loss at step 607400: 0.140173\n",
      "2022-11-08 22:34:22,126 INFO     Training average loss at step 607400: 0.148894\n",
      "2022-11-08 22:34:31,818 INFO     Training average positive_sample_loss at step 607500: 0.160146\n",
      "2022-11-08 22:34:31,818 INFO     Training average negative_sample_loss at step 607500: 0.141731\n",
      "2022-11-08 22:34:31,818 INFO     Training average loss at step 607500: 0.150939\n",
      "2022-11-08 22:34:41,513 INFO     Training average positive_sample_loss at step 607600: 0.155913\n",
      "2022-11-08 22:34:41,513 INFO     Training average negative_sample_loss at step 607600: 0.144730\n",
      "2022-11-08 22:34:41,514 INFO     Training average loss at step 607600: 0.150322\n",
      "2022-11-08 22:34:51,208 INFO     Training average positive_sample_loss at step 607700: 0.157292\n",
      "2022-11-08 22:34:51,208 INFO     Training average negative_sample_loss at step 607700: 0.142757\n",
      "2022-11-08 22:34:51,208 INFO     Training average loss at step 607700: 0.150025\n",
      "2022-11-08 22:35:00,906 INFO     Training average positive_sample_loss at step 607800: 0.153047\n",
      "2022-11-08 22:35:00,906 INFO     Training average negative_sample_loss at step 607800: 0.145031\n",
      "2022-11-08 22:35:00,906 INFO     Training average loss at step 607800: 0.149039\n",
      "2022-11-08 22:35:10,601 INFO     Training average positive_sample_loss at step 607900: 0.156669\n",
      "2022-11-08 22:35:10,601 INFO     Training average negative_sample_loss at step 607900: 0.140583\n",
      "2022-11-08 22:35:10,601 INFO     Training average loss at step 607900: 0.148626\n",
      "2022-11-08 22:35:20,296 INFO     Training average positive_sample_loss at step 608000: 0.155711\n",
      "2022-11-08 22:35:20,296 INFO     Training average negative_sample_loss at step 608000: 0.140235\n",
      "2022-11-08 22:35:20,296 INFO     Training average loss at step 608000: 0.147973\n",
      "2022-11-08 22:35:29,992 INFO     Training average positive_sample_loss at step 608100: 0.157705\n",
      "2022-11-08 22:35:29,992 INFO     Training average negative_sample_loss at step 608100: 0.143154\n",
      "2022-11-08 22:35:29,992 INFO     Training average loss at step 608100: 0.150430\n",
      "2022-11-08 22:35:39,685 INFO     Training average positive_sample_loss at step 608200: 0.154099\n",
      "2022-11-08 22:35:39,686 INFO     Training average negative_sample_loss at step 608200: 0.145757\n",
      "2022-11-08 22:35:39,686 INFO     Training average loss at step 608200: 0.149928\n",
      "2022-11-08 22:35:49,379 INFO     Training average positive_sample_loss at step 608300: 0.151209\n",
      "2022-11-08 22:35:49,379 INFO     Training average negative_sample_loss at step 608300: 0.141706\n",
      "2022-11-08 22:35:49,379 INFO     Training average loss at step 608300: 0.146458\n",
      "2022-11-08 22:35:58,766 INFO     Training average positive_sample_loss at step 608400: 0.155387\n",
      "2022-11-08 22:35:58,766 INFO     Training average negative_sample_loss at step 608400: 0.141322\n",
      "2022-11-08 22:35:58,766 INFO     Training average loss at step 608400: 0.148355\n",
      "2022-11-08 22:36:08,100 INFO     Training average positive_sample_loss at step 608500: 0.157627\n",
      "2022-11-08 22:36:08,100 INFO     Training average negative_sample_loss at step 608500: 0.145804\n",
      "2022-11-08 22:36:08,100 INFO     Training average loss at step 608500: 0.151716\n",
      "2022-11-08 22:36:17,792 INFO     Training average positive_sample_loss at step 608600: 0.152939\n",
      "2022-11-08 22:36:17,792 INFO     Training average negative_sample_loss at step 608600: 0.146527\n",
      "2022-11-08 22:36:17,792 INFO     Training average loss at step 608600: 0.149733\n",
      "2022-11-08 22:36:27,483 INFO     Training average positive_sample_loss at step 608700: 0.156482\n",
      "2022-11-08 22:36:27,484 INFO     Training average negative_sample_loss at step 608700: 0.141716\n",
      "2022-11-08 22:36:27,484 INFO     Training average loss at step 608700: 0.149099\n",
      "2022-11-08 22:36:37,178 INFO     Training average positive_sample_loss at step 608800: 0.156823\n",
      "2022-11-08 22:36:37,178 INFO     Training average negative_sample_loss at step 608800: 0.146964\n",
      "2022-11-08 22:36:37,178 INFO     Training average loss at step 608800: 0.151893\n",
      "2022-11-08 22:36:46,872 INFO     Training average positive_sample_loss at step 608900: 0.159922\n",
      "2022-11-08 22:36:46,872 INFO     Training average negative_sample_loss at step 608900: 0.143899\n",
      "2022-11-08 22:36:46,872 INFO     Training average loss at step 608900: 0.151911\n",
      "2022-11-08 22:36:56,148 INFO     Training average positive_sample_loss at step 609000: 0.158708\n",
      "2022-11-08 22:36:56,148 INFO     Training average negative_sample_loss at step 609000: 0.147802\n",
      "2022-11-08 22:36:56,148 INFO     Training average loss at step 609000: 0.153255\n",
      "2022-11-08 22:37:05,546 INFO     Training average positive_sample_loss at step 609100: 0.151631\n",
      "2022-11-08 22:37:05,546 INFO     Training average negative_sample_loss at step 609100: 0.143247\n",
      "2022-11-08 22:37:05,546 INFO     Training average loss at step 609100: 0.147439\n",
      "2022-11-08 22:37:15,243 INFO     Training average positive_sample_loss at step 609200: 0.155059\n",
      "2022-11-08 22:37:15,243 INFO     Training average negative_sample_loss at step 609200: 0.143305\n",
      "2022-11-08 22:37:15,243 INFO     Training average loss at step 609200: 0.149182\n",
      "2022-11-08 22:37:24,934 INFO     Training average positive_sample_loss at step 609300: 0.151487\n",
      "2022-11-08 22:37:24,935 INFO     Training average negative_sample_loss at step 609300: 0.144053\n",
      "2022-11-08 22:37:24,935 INFO     Training average loss at step 609300: 0.147770\n",
      "2022-11-08 22:37:34,626 INFO     Training average positive_sample_loss at step 609400: 0.152769\n",
      "2022-11-08 22:37:34,626 INFO     Training average negative_sample_loss at step 609400: 0.143899\n",
      "2022-11-08 22:37:34,626 INFO     Training average loss at step 609400: 0.148334\n",
      "2022-11-08 22:37:44,320 INFO     Training average positive_sample_loss at step 609500: 0.158693\n",
      "2022-11-08 22:37:44,320 INFO     Training average negative_sample_loss at step 609500: 0.142607\n",
      "2022-11-08 22:37:44,320 INFO     Training average loss at step 609500: 0.150650\n",
      "2022-11-08 22:37:54,017 INFO     Training average positive_sample_loss at step 609600: 0.151889\n",
      "2022-11-08 22:37:54,017 INFO     Training average negative_sample_loss at step 609600: 0.143840\n",
      "2022-11-08 22:37:54,017 INFO     Training average loss at step 609600: 0.147865\n",
      "2022-11-08 22:38:03,713 INFO     Training average positive_sample_loss at step 609700: 0.150923\n",
      "2022-11-08 22:38:03,713 INFO     Training average negative_sample_loss at step 609700: 0.143657\n",
      "2022-11-08 22:38:03,713 INFO     Training average loss at step 609700: 0.147290\n",
      "2022-11-08 22:38:13,414 INFO     Training average positive_sample_loss at step 609800: 0.149887\n",
      "2022-11-08 22:38:13,414 INFO     Training average negative_sample_loss at step 609800: 0.144751\n",
      "2022-11-08 22:38:13,414 INFO     Training average loss at step 609800: 0.147319\n",
      "2022-11-08 22:38:23,104 INFO     Training average positive_sample_loss at step 609900: 0.154470\n",
      "2022-11-08 22:38:23,104 INFO     Training average negative_sample_loss at step 609900: 0.145037\n",
      "2022-11-08 22:38:23,104 INFO     Training average loss at step 609900: 0.149754\n",
      "2022-11-08 22:38:35,635 INFO     Training average positive_sample_loss at step 610000: 0.155692\n",
      "2022-11-08 22:38:35,635 INFO     Training average negative_sample_loss at step 610000: 0.143925\n",
      "2022-11-08 22:38:35,635 INFO     Training average loss at step 610000: 0.149809\n",
      "2022-11-08 22:38:45,331 INFO     Training average positive_sample_loss at step 610100: 0.159626\n",
      "2022-11-08 22:38:45,331 INFO     Training average negative_sample_loss at step 610100: 0.140632\n",
      "2022-11-08 22:38:45,331 INFO     Training average loss at step 610100: 0.150129\n",
      "2022-11-08 22:38:55,026 INFO     Training average positive_sample_loss at step 610200: 0.157708\n",
      "2022-11-08 22:38:55,026 INFO     Training average negative_sample_loss at step 610200: 0.141788\n",
      "2022-11-08 22:38:55,026 INFO     Training average loss at step 610200: 0.149748\n",
      "2022-11-08 22:39:04,723 INFO     Training average positive_sample_loss at step 610300: 0.157043\n",
      "2022-11-08 22:39:04,723 INFO     Training average negative_sample_loss at step 610300: 0.145716\n",
      "2022-11-08 22:39:04,723 INFO     Training average loss at step 610300: 0.151379\n",
      "2022-11-08 22:39:14,419 INFO     Training average positive_sample_loss at step 610400: 0.150383\n",
      "2022-11-08 22:39:14,419 INFO     Training average negative_sample_loss at step 610400: 0.145388\n",
      "2022-11-08 22:39:14,419 INFO     Training average loss at step 610400: 0.147885\n",
      "2022-11-08 22:39:24,110 INFO     Training average positive_sample_loss at step 610500: 0.155403\n",
      "2022-11-08 22:39:24,110 INFO     Training average negative_sample_loss at step 610500: 0.138231\n",
      "2022-11-08 22:39:24,110 INFO     Training average loss at step 610500: 0.146817\n",
      "2022-11-08 22:39:33,802 INFO     Training average positive_sample_loss at step 610600: 0.153550\n",
      "2022-11-08 22:39:33,802 INFO     Training average negative_sample_loss at step 610600: 0.143590\n",
      "2022-11-08 22:39:33,802 INFO     Training average loss at step 610600: 0.148570\n",
      "2022-11-08 22:39:44,140 INFO     Training average positive_sample_loss at step 610700: 0.154336\n",
      "2022-11-08 22:39:44,140 INFO     Training average negative_sample_loss at step 610700: 0.142818\n",
      "2022-11-08 22:39:44,140 INFO     Training average loss at step 610700: 0.148577\n",
      "2022-11-08 22:39:53,834 INFO     Training average positive_sample_loss at step 610800: 0.150685\n",
      "2022-11-08 22:39:53,834 INFO     Training average negative_sample_loss at step 610800: 0.146305\n",
      "2022-11-08 22:39:53,834 INFO     Training average loss at step 610800: 0.148495\n",
      "2022-11-08 22:40:04,008 INFO     Training average positive_sample_loss at step 610900: 0.155579\n",
      "2022-11-08 22:40:04,008 INFO     Training average negative_sample_loss at step 610900: 0.144479\n",
      "2022-11-08 22:40:04,008 INFO     Training average loss at step 610900: 0.150029\n",
      "2022-11-08 22:40:13,987 INFO     Training average positive_sample_loss at step 611000: 0.159787\n",
      "2022-11-08 22:40:13,988 INFO     Training average negative_sample_loss at step 611000: 0.143717\n",
      "2022-11-08 22:40:13,988 INFO     Training average loss at step 611000: 0.151752\n",
      "2022-11-08 22:40:23,682 INFO     Training average positive_sample_loss at step 611100: 0.153823\n",
      "2022-11-08 22:40:23,682 INFO     Training average negative_sample_loss at step 611100: 0.145852\n",
      "2022-11-08 22:40:23,682 INFO     Training average loss at step 611100: 0.149837\n",
      "2022-11-08 22:40:34,256 INFO     Training average positive_sample_loss at step 611200: 0.150876\n",
      "2022-11-08 22:40:34,256 INFO     Training average negative_sample_loss at step 611200: 0.142236\n",
      "2022-11-08 22:40:34,256 INFO     Training average loss at step 611200: 0.146556\n",
      "2022-11-08 22:40:43,951 INFO     Training average positive_sample_loss at step 611300: 0.157606\n",
      "2022-11-08 22:40:43,951 INFO     Training average negative_sample_loss at step 611300: 0.143960\n",
      "2022-11-08 22:40:43,951 INFO     Training average loss at step 611300: 0.150783\n",
      "2022-11-08 22:40:53,645 INFO     Training average positive_sample_loss at step 611400: 0.155783\n",
      "2022-11-08 22:40:53,645 INFO     Training average negative_sample_loss at step 611400: 0.144526\n",
      "2022-11-08 22:40:53,645 INFO     Training average loss at step 611400: 0.150155\n",
      "2022-11-08 22:41:03,340 INFO     Training average positive_sample_loss at step 611500: 0.155043\n",
      "2022-11-08 22:41:03,340 INFO     Training average negative_sample_loss at step 611500: 0.143523\n",
      "2022-11-08 22:41:03,341 INFO     Training average loss at step 611500: 0.149283\n",
      "2022-11-08 22:41:13,030 INFO     Training average positive_sample_loss at step 611600: 0.153669\n",
      "2022-11-08 22:41:13,030 INFO     Training average negative_sample_loss at step 611600: 0.140063\n",
      "2022-11-08 22:41:13,030 INFO     Training average loss at step 611600: 0.146866\n",
      "2022-11-08 22:41:22,721 INFO     Training average positive_sample_loss at step 611700: 0.150812\n",
      "2022-11-08 22:41:22,721 INFO     Training average negative_sample_loss at step 611700: 0.140845\n",
      "2022-11-08 22:41:22,721 INFO     Training average loss at step 611700: 0.145829\n",
      "2022-11-08 22:41:32,417 INFO     Training average positive_sample_loss at step 611800: 0.154275\n",
      "2022-11-08 22:41:32,417 INFO     Training average negative_sample_loss at step 611800: 0.142082\n",
      "2022-11-08 22:41:32,417 INFO     Training average loss at step 611800: 0.148178\n",
      "2022-11-08 22:41:42,115 INFO     Training average positive_sample_loss at step 611900: 0.151238\n",
      "2022-11-08 22:41:42,115 INFO     Training average negative_sample_loss at step 611900: 0.142994\n",
      "2022-11-08 22:41:42,115 INFO     Training average loss at step 611900: 0.147116\n",
      "2022-11-08 22:41:51,810 INFO     Training average positive_sample_loss at step 612000: 0.153207\n",
      "2022-11-08 22:41:51,810 INFO     Training average negative_sample_loss at step 612000: 0.141677\n",
      "2022-11-08 22:41:51,810 INFO     Training average loss at step 612000: 0.147442\n",
      "2022-11-08 22:42:01,504 INFO     Training average positive_sample_loss at step 612100: 0.155407\n",
      "2022-11-08 22:42:01,504 INFO     Training average negative_sample_loss at step 612100: 0.144623\n",
      "2022-11-08 22:42:01,504 INFO     Training average loss at step 612100: 0.150015\n",
      "2022-11-08 22:42:11,195 INFO     Training average positive_sample_loss at step 612200: 0.158684\n",
      "2022-11-08 22:42:11,195 INFO     Training average negative_sample_loss at step 612200: 0.145128\n",
      "2022-11-08 22:42:11,195 INFO     Training average loss at step 612200: 0.151906\n",
      "2022-11-08 22:42:20,889 INFO     Training average positive_sample_loss at step 612300: 0.152771\n",
      "2022-11-08 22:42:20,889 INFO     Training average negative_sample_loss at step 612300: 0.138411\n",
      "2022-11-08 22:42:20,889 INFO     Training average loss at step 612300: 0.145591\n",
      "2022-11-08 22:42:30,586 INFO     Training average positive_sample_loss at step 612400: 0.160579\n",
      "2022-11-08 22:42:30,587 INFO     Training average negative_sample_loss at step 612400: 0.142761\n",
      "2022-11-08 22:42:30,587 INFO     Training average loss at step 612400: 0.151670\n",
      "2022-11-08 22:42:40,284 INFO     Training average positive_sample_loss at step 612500: 0.158184\n",
      "2022-11-08 22:42:40,284 INFO     Training average negative_sample_loss at step 612500: 0.144402\n",
      "2022-11-08 22:42:40,284 INFO     Training average loss at step 612500: 0.151293\n",
      "2022-11-08 22:42:49,977 INFO     Training average positive_sample_loss at step 612600: 0.160116\n",
      "2022-11-08 22:42:49,977 INFO     Training average negative_sample_loss at step 612600: 0.140208\n",
      "2022-11-08 22:42:49,977 INFO     Training average loss at step 612600: 0.150162\n",
      "2022-11-08 22:42:59,667 INFO     Training average positive_sample_loss at step 612700: 0.153472\n",
      "2022-11-08 22:42:59,667 INFO     Training average negative_sample_loss at step 612700: 0.146599\n",
      "2022-11-08 22:42:59,667 INFO     Training average loss at step 612700: 0.150036\n",
      "2022-11-08 22:43:09,362 INFO     Training average positive_sample_loss at step 612800: 0.146335\n",
      "2022-11-08 22:43:09,362 INFO     Training average negative_sample_loss at step 612800: 0.139966\n",
      "2022-11-08 22:43:09,363 INFO     Training average loss at step 612800: 0.143150\n",
      "2022-11-08 22:43:19,056 INFO     Training average positive_sample_loss at step 612900: 0.160396\n",
      "2022-11-08 22:43:19,056 INFO     Training average negative_sample_loss at step 612900: 0.143100\n",
      "2022-11-08 22:43:19,056 INFO     Training average loss at step 612900: 0.151748\n",
      "2022-11-08 22:43:28,753 INFO     Training average positive_sample_loss at step 613000: 0.150338\n",
      "2022-11-08 22:43:28,754 INFO     Training average negative_sample_loss at step 613000: 0.146001\n",
      "2022-11-08 22:43:28,754 INFO     Training average loss at step 613000: 0.148169\n",
      "2022-11-08 22:43:38,452 INFO     Training average positive_sample_loss at step 613100: 0.150421\n",
      "2022-11-08 22:43:38,452 INFO     Training average negative_sample_loss at step 613100: 0.143873\n",
      "2022-11-08 22:43:38,452 INFO     Training average loss at step 613100: 0.147147\n",
      "2022-11-08 22:43:48,144 INFO     Training average positive_sample_loss at step 613200: 0.158129\n",
      "2022-11-08 22:43:48,144 INFO     Training average negative_sample_loss at step 613200: 0.146528\n",
      "2022-11-08 22:43:48,144 INFO     Training average loss at step 613200: 0.152328\n",
      "2022-11-08 22:43:57,835 INFO     Training average positive_sample_loss at step 613300: 0.156246\n",
      "2022-11-08 22:43:57,836 INFO     Training average negative_sample_loss at step 613300: 0.140463\n",
      "2022-11-08 22:43:57,836 INFO     Training average loss at step 613300: 0.148354\n",
      "2022-11-08 22:44:07,534 INFO     Training average positive_sample_loss at step 613400: 0.160324\n",
      "2022-11-08 22:44:07,534 INFO     Training average negative_sample_loss at step 613400: 0.143309\n",
      "2022-11-08 22:44:07,534 INFO     Training average loss at step 613400: 0.151817\n",
      "2022-11-08 22:44:17,228 INFO     Training average positive_sample_loss at step 613500: 0.152679\n",
      "2022-11-08 22:44:17,228 INFO     Training average negative_sample_loss at step 613500: 0.142667\n",
      "2022-11-08 22:44:17,228 INFO     Training average loss at step 613500: 0.147673\n",
      "2022-11-08 22:44:26,923 INFO     Training average positive_sample_loss at step 613600: 0.155950\n",
      "2022-11-08 22:44:26,923 INFO     Training average negative_sample_loss at step 613600: 0.146366\n",
      "2022-11-08 22:44:26,923 INFO     Training average loss at step 613600: 0.151158\n",
      "2022-11-08 22:44:36,619 INFO     Training average positive_sample_loss at step 613700: 0.153568\n",
      "2022-11-08 22:44:36,619 INFO     Training average negative_sample_loss at step 613700: 0.145019\n",
      "2022-11-08 22:44:36,619 INFO     Training average loss at step 613700: 0.149293\n",
      "2022-11-08 22:44:46,315 INFO     Training average positive_sample_loss at step 613800: 0.152310\n",
      "2022-11-08 22:44:46,315 INFO     Training average negative_sample_loss at step 613800: 0.140778\n",
      "2022-11-08 22:44:46,315 INFO     Training average loss at step 613800: 0.146544\n",
      "2022-11-08 22:44:55,329 INFO     Training average positive_sample_loss at step 613900: 0.157843\n",
      "2022-11-08 22:44:55,329 INFO     Training average negative_sample_loss at step 613900: 0.147642\n",
      "2022-11-08 22:44:55,329 INFO     Training average loss at step 613900: 0.152742\n",
      "2022-11-08 22:45:05,027 INFO     Training average positive_sample_loss at step 614000: 0.155139\n",
      "2022-11-08 22:45:05,027 INFO     Training average negative_sample_loss at step 614000: 0.140377\n",
      "2022-11-08 22:45:05,027 INFO     Training average loss at step 614000: 0.147758\n",
      "2022-11-08 22:45:14,727 INFO     Training average positive_sample_loss at step 614100: 0.153192\n",
      "2022-11-08 22:45:14,727 INFO     Training average negative_sample_loss at step 614100: 0.144428\n",
      "2022-11-08 22:45:14,727 INFO     Training average loss at step 614100: 0.148810\n",
      "2022-11-08 22:45:24,419 INFO     Training average positive_sample_loss at step 614200: 0.154408\n",
      "2022-11-08 22:45:24,420 INFO     Training average negative_sample_loss at step 614200: 0.143689\n",
      "2022-11-08 22:45:24,420 INFO     Training average loss at step 614200: 0.149048\n",
      "2022-11-08 22:45:34,111 INFO     Training average positive_sample_loss at step 614300: 0.158129\n",
      "2022-11-08 22:45:34,111 INFO     Training average negative_sample_loss at step 614300: 0.137713\n",
      "2022-11-08 22:45:34,111 INFO     Training average loss at step 614300: 0.147921\n",
      "2022-11-08 22:45:43,800 INFO     Training average positive_sample_loss at step 614400: 0.154288\n",
      "2022-11-08 22:45:43,800 INFO     Training average negative_sample_loss at step 614400: 0.136055\n",
      "2022-11-08 22:45:43,800 INFO     Training average loss at step 614400: 0.145171\n",
      "2022-11-08 22:45:52,824 INFO     Training average positive_sample_loss at step 614500: 0.151063\n",
      "2022-11-08 22:45:52,824 INFO     Training average negative_sample_loss at step 614500: 0.143833\n",
      "2022-11-08 22:45:52,824 INFO     Training average loss at step 614500: 0.147448\n",
      "2022-11-08 22:46:02,521 INFO     Training average positive_sample_loss at step 614600: 0.157163\n",
      "2022-11-08 22:46:02,521 INFO     Training average negative_sample_loss at step 614600: 0.147123\n",
      "2022-11-08 22:46:02,521 INFO     Training average loss at step 614600: 0.152143\n",
      "2022-11-08 22:46:12,213 INFO     Training average positive_sample_loss at step 614700: 0.153276\n",
      "2022-11-08 22:46:12,213 INFO     Training average negative_sample_loss at step 614700: 0.142517\n",
      "2022-11-08 22:46:12,213 INFO     Training average loss at step 614700: 0.147897\n",
      "2022-11-08 22:46:21,908 INFO     Training average positive_sample_loss at step 614800: 0.155166\n",
      "2022-11-08 22:46:21,908 INFO     Training average negative_sample_loss at step 614800: 0.139879\n",
      "2022-11-08 22:46:21,908 INFO     Training average loss at step 614800: 0.147523\n",
      "2022-11-08 22:46:31,602 INFO     Training average positive_sample_loss at step 614900: 0.156181\n",
      "2022-11-08 22:46:31,602 INFO     Training average negative_sample_loss at step 614900: 0.142045\n",
      "2022-11-08 22:46:31,602 INFO     Training average loss at step 614900: 0.149113\n",
      "2022-11-08 22:46:41,294 INFO     Training average positive_sample_loss at step 615000: 0.153213\n",
      "2022-11-08 22:46:41,294 INFO     Training average negative_sample_loss at step 615000: 0.144787\n",
      "2022-11-08 22:46:41,294 INFO     Training average loss at step 615000: 0.149000\n",
      "2022-11-08 22:46:50,991 INFO     Training average positive_sample_loss at step 615100: 0.157134\n",
      "2022-11-08 22:46:50,991 INFO     Training average negative_sample_loss at step 615100: 0.143382\n",
      "2022-11-08 22:46:50,991 INFO     Training average loss at step 615100: 0.150258\n",
      "2022-11-08 22:47:00,686 INFO     Training average positive_sample_loss at step 615200: 0.156984\n",
      "2022-11-08 22:47:00,686 INFO     Training average negative_sample_loss at step 615200: 0.144501\n",
      "2022-11-08 22:47:00,686 INFO     Training average loss at step 615200: 0.150743\n",
      "2022-11-08 22:47:10,384 INFO     Training average positive_sample_loss at step 615300: 0.161177\n",
      "2022-11-08 22:47:10,384 INFO     Training average negative_sample_loss at step 615300: 0.146759\n",
      "2022-11-08 22:47:10,384 INFO     Training average loss at step 615300: 0.153968\n",
      "2022-11-08 22:47:20,617 INFO     Training average positive_sample_loss at step 615400: 0.163757\n",
      "2022-11-08 22:47:20,618 INFO     Training average negative_sample_loss at step 615400: 0.141831\n",
      "2022-11-08 22:47:20,618 INFO     Training average loss at step 615400: 0.152794\n",
      "2022-11-08 22:47:30,316 INFO     Training average positive_sample_loss at step 615500: 0.155442\n",
      "2022-11-08 22:47:30,316 INFO     Training average negative_sample_loss at step 615500: 0.142709\n",
      "2022-11-08 22:47:30,316 INFO     Training average loss at step 615500: 0.149075\n",
      "2022-11-08 22:47:40,379 INFO     Training average positive_sample_loss at step 615600: 0.152181\n",
      "2022-11-08 22:47:40,379 INFO     Training average negative_sample_loss at step 615600: 0.140364\n",
      "2022-11-08 22:47:40,379 INFO     Training average loss at step 615600: 0.146272\n",
      "2022-11-08 22:47:50,369 INFO     Training average positive_sample_loss at step 615700: 0.152171\n",
      "2022-11-08 22:47:50,369 INFO     Training average negative_sample_loss at step 615700: 0.141444\n",
      "2022-11-08 22:47:50,369 INFO     Training average loss at step 615700: 0.146808\n",
      "2022-11-08 22:48:00,066 INFO     Training average positive_sample_loss at step 615800: 0.154439\n",
      "2022-11-08 22:48:00,066 INFO     Training average negative_sample_loss at step 615800: 0.144685\n",
      "2022-11-08 22:48:00,066 INFO     Training average loss at step 615800: 0.149562\n",
      "2022-11-08 22:48:09,774 INFO     Training average positive_sample_loss at step 615900: 0.160271\n",
      "2022-11-08 22:48:09,774 INFO     Training average negative_sample_loss at step 615900: 0.147184\n",
      "2022-11-08 22:48:09,774 INFO     Training average loss at step 615900: 0.153728\n",
      "2022-11-08 22:48:19,469 INFO     Training average positive_sample_loss at step 616000: 0.161591\n",
      "2022-11-08 22:48:19,469 INFO     Training average negative_sample_loss at step 616000: 0.147299\n",
      "2022-11-08 22:48:19,469 INFO     Training average loss at step 616000: 0.154445\n",
      "2022-11-08 22:48:29,166 INFO     Training average positive_sample_loss at step 616100: 0.156243\n",
      "2022-11-08 22:48:29,166 INFO     Training average negative_sample_loss at step 616100: 0.143476\n",
      "2022-11-08 22:48:29,166 INFO     Training average loss at step 616100: 0.149860\n",
      "2022-11-08 22:48:38,862 INFO     Training average positive_sample_loss at step 616200: 0.153438\n",
      "2022-11-08 22:48:38,863 INFO     Training average negative_sample_loss at step 616200: 0.144800\n",
      "2022-11-08 22:48:38,863 INFO     Training average loss at step 616200: 0.149119\n",
      "2022-11-08 22:48:48,561 INFO     Training average positive_sample_loss at step 616300: 0.152522\n",
      "2022-11-08 22:48:48,561 INFO     Training average negative_sample_loss at step 616300: 0.142982\n",
      "2022-11-08 22:48:48,561 INFO     Training average loss at step 616300: 0.147752\n",
      "2022-11-08 22:48:58,257 INFO     Training average positive_sample_loss at step 616400: 0.158226\n",
      "2022-11-08 22:48:58,257 INFO     Training average negative_sample_loss at step 616400: 0.144795\n",
      "2022-11-08 22:48:58,257 INFO     Training average loss at step 616400: 0.151510\n",
      "2022-11-08 22:49:07,951 INFO     Training average positive_sample_loss at step 616500: 0.156210\n",
      "2022-11-08 22:49:07,951 INFO     Training average negative_sample_loss at step 616500: 0.142951\n",
      "2022-11-08 22:49:07,951 INFO     Training average loss at step 616500: 0.149580\n",
      "2022-11-08 22:49:17,646 INFO     Training average positive_sample_loss at step 616600: 0.158822\n",
      "2022-11-08 22:49:17,646 INFO     Training average negative_sample_loss at step 616600: 0.145268\n",
      "2022-11-08 22:49:17,646 INFO     Training average loss at step 616600: 0.152045\n",
      "2022-11-08 22:49:27,341 INFO     Training average positive_sample_loss at step 616700: 0.148961\n",
      "2022-11-08 22:49:27,341 INFO     Training average negative_sample_loss at step 616700: 0.143033\n",
      "2022-11-08 22:49:27,341 INFO     Training average loss at step 616700: 0.145997\n",
      "2022-11-08 22:49:37,036 INFO     Training average positive_sample_loss at step 616800: 0.158114\n",
      "2022-11-08 22:49:37,036 INFO     Training average negative_sample_loss at step 616800: 0.141833\n",
      "2022-11-08 22:49:37,036 INFO     Training average loss at step 616800: 0.149973\n",
      "2022-11-08 22:49:46,733 INFO     Training average positive_sample_loss at step 616900: 0.154281\n",
      "2022-11-08 22:49:46,733 INFO     Training average negative_sample_loss at step 616900: 0.144734\n",
      "2022-11-08 22:49:46,733 INFO     Training average loss at step 616900: 0.149507\n",
      "2022-11-08 22:49:54,924 INFO     Training average positive_sample_loss at step 617000: 0.153735\n",
      "2022-11-08 22:49:54,924 INFO     Training average negative_sample_loss at step 617000: 0.149424\n",
      "2022-11-08 22:49:54,924 INFO     Training average loss at step 617000: 0.151580\n",
      "2022-11-08 22:50:04,576 INFO     Training average positive_sample_loss at step 617100: 0.159458\n",
      "2022-11-08 22:50:04,576 INFO     Training average negative_sample_loss at step 617100: 0.144864\n",
      "2022-11-08 22:50:04,576 INFO     Training average loss at step 617100: 0.152161\n",
      "2022-11-08 22:50:14,274 INFO     Training average positive_sample_loss at step 617200: 0.152676\n",
      "2022-11-08 22:50:14,274 INFO     Training average negative_sample_loss at step 617200: 0.142840\n",
      "2022-11-08 22:50:14,274 INFO     Training average loss at step 617200: 0.147758\n",
      "2022-11-08 22:50:23,968 INFO     Training average positive_sample_loss at step 617300: 0.156133\n",
      "2022-11-08 22:50:23,968 INFO     Training average negative_sample_loss at step 617300: 0.142283\n",
      "2022-11-08 22:50:23,968 INFO     Training average loss at step 617300: 0.149208\n",
      "2022-11-08 22:50:33,659 INFO     Training average positive_sample_loss at step 617400: 0.156261\n",
      "2022-11-08 22:50:33,659 INFO     Training average negative_sample_loss at step 617400: 0.140634\n",
      "2022-11-08 22:50:33,659 INFO     Training average loss at step 617400: 0.148447\n",
      "2022-11-08 22:50:43,353 INFO     Training average positive_sample_loss at step 617500: 0.157986\n",
      "2022-11-08 22:50:43,353 INFO     Training average negative_sample_loss at step 617500: 0.142061\n",
      "2022-11-08 22:50:43,353 INFO     Training average loss at step 617500: 0.150023\n",
      "2022-11-08 22:50:53,052 INFO     Training average positive_sample_loss at step 617600: 0.153551\n",
      "2022-11-08 22:50:53,053 INFO     Training average negative_sample_loss at step 617600: 0.141839\n",
      "2022-11-08 22:50:53,053 INFO     Training average loss at step 617600: 0.147695\n",
      "2022-11-08 22:51:02,748 INFO     Training average positive_sample_loss at step 617700: 0.155203\n",
      "2022-11-08 22:51:02,748 INFO     Training average negative_sample_loss at step 617700: 0.137305\n",
      "2022-11-08 22:51:02,748 INFO     Training average loss at step 617700: 0.146254\n",
      "2022-11-08 22:51:12,441 INFO     Training average positive_sample_loss at step 617800: 0.152344\n",
      "2022-11-08 22:51:12,441 INFO     Training average negative_sample_loss at step 617800: 0.142781\n",
      "2022-11-08 22:51:12,441 INFO     Training average loss at step 617800: 0.147563\n",
      "2022-11-08 22:51:22,134 INFO     Training average positive_sample_loss at step 617900: 0.160133\n",
      "2022-11-08 22:51:22,135 INFO     Training average negative_sample_loss at step 617900: 0.139481\n",
      "2022-11-08 22:51:22,135 INFO     Training average loss at step 617900: 0.149807\n",
      "2022-11-08 22:51:31,827 INFO     Training average positive_sample_loss at step 618000: 0.157234\n",
      "2022-11-08 22:51:31,827 INFO     Training average negative_sample_loss at step 618000: 0.140099\n",
      "2022-11-08 22:51:31,827 INFO     Training average loss at step 618000: 0.148667\n",
      "2022-11-08 22:51:41,523 INFO     Training average positive_sample_loss at step 618100: 0.155278\n",
      "2022-11-08 22:51:41,523 INFO     Training average negative_sample_loss at step 618100: 0.143593\n",
      "2022-11-08 22:51:41,523 INFO     Training average loss at step 618100: 0.149436\n",
      "2022-11-08 22:51:51,219 INFO     Training average positive_sample_loss at step 618200: 0.151235\n",
      "2022-11-08 22:51:51,219 INFO     Training average negative_sample_loss at step 618200: 0.141544\n",
      "2022-11-08 22:51:51,219 INFO     Training average loss at step 618200: 0.146389\n",
      "2022-11-08 22:52:00,915 INFO     Training average positive_sample_loss at step 618300: 0.155016\n",
      "2022-11-08 22:52:00,915 INFO     Training average negative_sample_loss at step 618300: 0.143573\n",
      "2022-11-08 22:52:00,915 INFO     Training average loss at step 618300: 0.149294\n",
      "2022-11-08 22:52:10,608 INFO     Training average positive_sample_loss at step 618400: 0.156612\n",
      "2022-11-08 22:52:10,608 INFO     Training average negative_sample_loss at step 618400: 0.145902\n",
      "2022-11-08 22:52:10,608 INFO     Training average loss at step 618400: 0.151257\n",
      "2022-11-08 22:52:20,302 INFO     Training average positive_sample_loss at step 618500: 0.148177\n",
      "2022-11-08 22:52:20,302 INFO     Training average negative_sample_loss at step 618500: 0.145436\n",
      "2022-11-08 22:52:20,302 INFO     Training average loss at step 618500: 0.146807\n",
      "2022-11-08 22:52:29,997 INFO     Training average positive_sample_loss at step 618600: 0.156636\n",
      "2022-11-08 22:52:29,997 INFO     Training average negative_sample_loss at step 618600: 0.143734\n",
      "2022-11-08 22:52:29,997 INFO     Training average loss at step 618600: 0.150185\n",
      "2022-11-08 22:52:39,690 INFO     Training average positive_sample_loss at step 618700: 0.155146\n",
      "2022-11-08 22:52:39,690 INFO     Training average negative_sample_loss at step 618700: 0.145309\n",
      "2022-11-08 22:52:39,691 INFO     Training average loss at step 618700: 0.150228\n",
      "2022-11-08 22:52:49,388 INFO     Training average positive_sample_loss at step 618800: 0.156518\n",
      "2022-11-08 22:52:49,388 INFO     Training average negative_sample_loss at step 618800: 0.141814\n",
      "2022-11-08 22:52:49,388 INFO     Training average loss at step 618800: 0.149166\n",
      "2022-11-08 22:52:59,081 INFO     Training average positive_sample_loss at step 618900: 0.160612\n",
      "2022-11-08 22:52:59,081 INFO     Training average negative_sample_loss at step 618900: 0.139393\n",
      "2022-11-08 22:52:59,081 INFO     Training average loss at step 618900: 0.150003\n",
      "2022-11-08 22:53:08,777 INFO     Training average positive_sample_loss at step 619000: 0.156435\n",
      "2022-11-08 22:53:08,777 INFO     Training average negative_sample_loss at step 619000: 0.144110\n",
      "2022-11-08 22:53:08,777 INFO     Training average loss at step 619000: 0.150272\n",
      "2022-11-08 22:53:18,472 INFO     Training average positive_sample_loss at step 619100: 0.152911\n",
      "2022-11-08 22:53:18,472 INFO     Training average negative_sample_loss at step 619100: 0.144240\n",
      "2022-11-08 22:53:18,472 INFO     Training average loss at step 619100: 0.148576\n",
      "2022-11-08 22:53:28,167 INFO     Training average positive_sample_loss at step 619200: 0.155486\n",
      "2022-11-08 22:53:28,167 INFO     Training average negative_sample_loss at step 619200: 0.143659\n",
      "2022-11-08 22:53:28,167 INFO     Training average loss at step 619200: 0.149573\n",
      "2022-11-08 22:53:37,864 INFO     Training average positive_sample_loss at step 619300: 0.154036\n",
      "2022-11-08 22:53:37,864 INFO     Training average negative_sample_loss at step 619300: 0.140018\n",
      "2022-11-08 22:53:37,864 INFO     Training average loss at step 619300: 0.147027\n",
      "2022-11-08 22:53:46,860 INFO     Training average positive_sample_loss at step 619400: 0.151926\n",
      "2022-11-08 22:53:46,860 INFO     Training average negative_sample_loss at step 619400: 0.146463\n",
      "2022-11-08 22:53:46,860 INFO     Training average loss at step 619400: 0.149195\n",
      "2022-11-08 22:53:56,555 INFO     Training average positive_sample_loss at step 619500: 0.152122\n",
      "2022-11-08 22:53:56,555 INFO     Training average negative_sample_loss at step 619500: 0.144927\n",
      "2022-11-08 22:53:56,555 INFO     Training average loss at step 619500: 0.148524\n",
      "2022-11-08 22:54:06,250 INFO     Training average positive_sample_loss at step 619600: 0.155826\n",
      "2022-11-08 22:54:06,250 INFO     Training average negative_sample_loss at step 619600: 0.142383\n",
      "2022-11-08 22:54:06,250 INFO     Training average loss at step 619600: 0.149105\n",
      "2022-11-08 22:54:15,942 INFO     Training average positive_sample_loss at step 619700: 0.155820\n",
      "2022-11-08 22:54:15,942 INFO     Training average negative_sample_loss at step 619700: 0.142287\n",
      "2022-11-08 22:54:15,942 INFO     Training average loss at step 619700: 0.149053\n",
      "2022-11-08 22:54:25,637 INFO     Training average positive_sample_loss at step 619800: 0.158491\n",
      "2022-11-08 22:54:25,637 INFO     Training average negative_sample_loss at step 619800: 0.140635\n",
      "2022-11-08 22:54:25,637 INFO     Training average loss at step 619800: 0.149563\n",
      "2022-11-08 22:54:35,332 INFO     Training average positive_sample_loss at step 619900: 0.155813\n",
      "2022-11-08 22:54:35,332 INFO     Training average negative_sample_loss at step 619900: 0.143448\n",
      "2022-11-08 22:54:35,332 INFO     Training average loss at step 619900: 0.149631\n",
      "2022-11-08 22:54:47,816 INFO     Training average positive_sample_loss at step 620000: 0.162491\n",
      "2022-11-08 22:54:47,816 INFO     Training average negative_sample_loss at step 620000: 0.144318\n",
      "2022-11-08 22:54:47,816 INFO     Training average loss at step 620000: 0.153404\n",
      "2022-11-08 22:54:57,819 INFO     Training average positive_sample_loss at step 620100: 0.151566\n",
      "2022-11-08 22:54:57,819 INFO     Training average negative_sample_loss at step 620100: 0.141831\n",
      "2022-11-08 22:54:57,819 INFO     Training average loss at step 620100: 0.146698\n",
      "2022-11-08 22:55:07,513 INFO     Training average positive_sample_loss at step 620200: 0.156591\n",
      "2022-11-08 22:55:07,513 INFO     Training average negative_sample_loss at step 620200: 0.146810\n",
      "2022-11-08 22:55:07,513 INFO     Training average loss at step 620200: 0.151701\n",
      "2022-11-08 22:55:17,506 INFO     Training average positive_sample_loss at step 620300: 0.157598\n",
      "2022-11-08 22:55:17,506 INFO     Training average negative_sample_loss at step 620300: 0.144199\n",
      "2022-11-08 22:55:17,506 INFO     Training average loss at step 620300: 0.150899\n",
      "2022-11-08 22:55:27,552 INFO     Training average positive_sample_loss at step 620400: 0.153448\n",
      "2022-11-08 22:55:27,552 INFO     Training average negative_sample_loss at step 620400: 0.145158\n",
      "2022-11-08 22:55:27,552 INFO     Training average loss at step 620400: 0.149303\n",
      "2022-11-08 22:55:37,247 INFO     Training average positive_sample_loss at step 620500: 0.153135\n",
      "2022-11-08 22:55:37,248 INFO     Training average negative_sample_loss at step 620500: 0.143209\n",
      "2022-11-08 22:55:37,248 INFO     Training average loss at step 620500: 0.148172\n",
      "2022-11-08 22:55:47,738 INFO     Training average positive_sample_loss at step 620600: 0.150436\n",
      "2022-11-08 22:55:47,738 INFO     Training average negative_sample_loss at step 620600: 0.143028\n",
      "2022-11-08 22:55:47,738 INFO     Training average loss at step 620600: 0.146732\n",
      "2022-11-08 22:55:57,430 INFO     Training average positive_sample_loss at step 620700: 0.156932\n",
      "2022-11-08 22:55:57,431 INFO     Training average negative_sample_loss at step 620700: 0.143151\n",
      "2022-11-08 22:55:57,431 INFO     Training average loss at step 620700: 0.150041\n",
      "2022-11-08 22:56:07,126 INFO     Training average positive_sample_loss at step 620800: 0.160508\n",
      "2022-11-08 22:56:07,127 INFO     Training average negative_sample_loss at step 620800: 0.142035\n",
      "2022-11-08 22:56:07,127 INFO     Training average loss at step 620800: 0.151272\n",
      "2022-11-08 22:56:16,824 INFO     Training average positive_sample_loss at step 620900: 0.164195\n",
      "2022-11-08 22:56:16,824 INFO     Training average negative_sample_loss at step 620900: 0.143993\n",
      "2022-11-08 22:56:16,824 INFO     Training average loss at step 620900: 0.154094\n",
      "2022-11-08 22:56:26,515 INFO     Training average positive_sample_loss at step 621000: 0.149457\n",
      "2022-11-08 22:56:26,515 INFO     Training average negative_sample_loss at step 621000: 0.143521\n",
      "2022-11-08 22:56:26,515 INFO     Training average loss at step 621000: 0.146489\n",
      "2022-11-08 22:56:36,210 INFO     Training average positive_sample_loss at step 621100: 0.160387\n",
      "2022-11-08 22:56:36,210 INFO     Training average negative_sample_loss at step 621100: 0.147965\n",
      "2022-11-08 22:56:36,211 INFO     Training average loss at step 621100: 0.154176\n",
      "2022-11-08 22:56:45,911 INFO     Training average positive_sample_loss at step 621200: 0.153978\n",
      "2022-11-08 22:56:45,911 INFO     Training average negative_sample_loss at step 621200: 0.147744\n",
      "2022-11-08 22:56:45,911 INFO     Training average loss at step 621200: 0.150861\n",
      "2022-11-08 22:56:55,604 INFO     Training average positive_sample_loss at step 621300: 0.155527\n",
      "2022-11-08 22:56:55,604 INFO     Training average negative_sample_loss at step 621300: 0.139568\n",
      "2022-11-08 22:56:55,604 INFO     Training average loss at step 621300: 0.147547\n",
      "2022-11-08 22:57:05,300 INFO     Training average positive_sample_loss at step 621400: 0.151611\n",
      "2022-11-08 22:57:05,300 INFO     Training average negative_sample_loss at step 621400: 0.147202\n",
      "2022-11-08 22:57:05,300 INFO     Training average loss at step 621400: 0.149406\n",
      "2022-11-08 22:57:14,993 INFO     Training average positive_sample_loss at step 621500: 0.158309\n",
      "2022-11-08 22:57:14,993 INFO     Training average negative_sample_loss at step 621500: 0.143646\n",
      "2022-11-08 22:57:14,993 INFO     Training average loss at step 621500: 0.150978\n",
      "2022-11-08 22:57:24,688 INFO     Training average positive_sample_loss at step 621600: 0.150054\n",
      "2022-11-08 22:57:24,688 INFO     Training average negative_sample_loss at step 621600: 0.135446\n",
      "2022-11-08 22:57:24,688 INFO     Training average loss at step 621600: 0.142750\n",
      "2022-11-08 22:57:34,383 INFO     Training average positive_sample_loss at step 621700: 0.151988\n",
      "2022-11-08 22:57:34,383 INFO     Training average negative_sample_loss at step 621700: 0.147078\n",
      "2022-11-08 22:57:34,383 INFO     Training average loss at step 621700: 0.149533\n",
      "2022-11-08 22:57:44,078 INFO     Training average positive_sample_loss at step 621800: 0.160805\n",
      "2022-11-08 22:57:44,078 INFO     Training average negative_sample_loss at step 621800: 0.143781\n",
      "2022-11-08 22:57:44,078 INFO     Training average loss at step 621800: 0.152293\n",
      "2022-11-08 22:57:53,771 INFO     Training average positive_sample_loss at step 621900: 0.158224\n",
      "2022-11-08 22:57:53,771 INFO     Training average negative_sample_loss at step 621900: 0.140650\n",
      "2022-11-08 22:57:53,771 INFO     Training average loss at step 621900: 0.149437\n",
      "2022-11-08 22:58:03,467 INFO     Training average positive_sample_loss at step 622000: 0.157361\n",
      "2022-11-08 22:58:03,467 INFO     Training average negative_sample_loss at step 622000: 0.145853\n",
      "2022-11-08 22:58:03,467 INFO     Training average loss at step 622000: 0.151607\n",
      "2022-11-08 22:58:13,160 INFO     Training average positive_sample_loss at step 622100: 0.157841\n",
      "2022-11-08 22:58:13,160 INFO     Training average negative_sample_loss at step 622100: 0.143250\n",
      "2022-11-08 22:58:13,160 INFO     Training average loss at step 622100: 0.150545\n",
      "2022-11-08 22:58:22,856 INFO     Training average positive_sample_loss at step 622200: 0.152708\n",
      "2022-11-08 22:58:22,856 INFO     Training average negative_sample_loss at step 622200: 0.140350\n",
      "2022-11-08 22:58:22,856 INFO     Training average loss at step 622200: 0.146529\n",
      "2022-11-08 22:58:32,556 INFO     Training average positive_sample_loss at step 622300: 0.159742\n",
      "2022-11-08 22:58:32,556 INFO     Training average negative_sample_loss at step 622300: 0.139577\n",
      "2022-11-08 22:58:32,556 INFO     Training average loss at step 622300: 0.149660\n",
      "2022-11-08 22:58:42,251 INFO     Training average positive_sample_loss at step 622400: 0.155520\n",
      "2022-11-08 22:58:42,251 INFO     Training average negative_sample_loss at step 622400: 0.141409\n",
      "2022-11-08 22:58:42,251 INFO     Training average loss at step 622400: 0.148465\n",
      "2022-11-08 22:58:51,947 INFO     Training average positive_sample_loss at step 622500: 0.158007\n",
      "2022-11-08 22:58:51,947 INFO     Training average negative_sample_loss at step 622500: 0.148691\n",
      "2022-11-08 22:58:51,947 INFO     Training average loss at step 622500: 0.153349\n",
      "2022-11-08 22:59:01,641 INFO     Training average positive_sample_loss at step 622600: 0.157098\n",
      "2022-11-08 22:59:01,641 INFO     Training average negative_sample_loss at step 622600: 0.143059\n",
      "2022-11-08 22:59:01,641 INFO     Training average loss at step 622600: 0.150078\n",
      "2022-11-08 22:59:11,338 INFO     Training average positive_sample_loss at step 622700: 0.154830\n",
      "2022-11-08 22:59:11,338 INFO     Training average negative_sample_loss at step 622700: 0.145401\n",
      "2022-11-08 22:59:11,338 INFO     Training average loss at step 622700: 0.150115\n",
      "2022-11-08 22:59:21,034 INFO     Training average positive_sample_loss at step 622800: 0.158775\n",
      "2022-11-08 22:59:21,034 INFO     Training average negative_sample_loss at step 622800: 0.146860\n",
      "2022-11-08 22:59:21,034 INFO     Training average loss at step 622800: 0.152818\n",
      "2022-11-08 22:59:30,727 INFO     Training average positive_sample_loss at step 622900: 0.155483\n",
      "2022-11-08 22:59:30,727 INFO     Training average negative_sample_loss at step 622900: 0.144190\n",
      "2022-11-08 22:59:30,727 INFO     Training average loss at step 622900: 0.149837\n",
      "2022-11-08 22:59:40,423 INFO     Training average positive_sample_loss at step 623000: 0.152616\n",
      "2022-11-08 22:59:40,423 INFO     Training average negative_sample_loss at step 623000: 0.145849\n",
      "2022-11-08 22:59:40,423 INFO     Training average loss at step 623000: 0.149233\n",
      "2022-11-08 22:59:50,118 INFO     Training average positive_sample_loss at step 623100: 0.154419\n",
      "2022-11-08 22:59:50,118 INFO     Training average negative_sample_loss at step 623100: 0.139758\n",
      "2022-11-08 22:59:50,118 INFO     Training average loss at step 623100: 0.147088\n",
      "2022-11-08 22:59:59,809 INFO     Training average positive_sample_loss at step 623200: 0.156354\n",
      "2022-11-08 22:59:59,809 INFO     Training average negative_sample_loss at step 623200: 0.139833\n",
      "2022-11-08 22:59:59,809 INFO     Training average loss at step 623200: 0.148093\n",
      "2022-11-08 23:00:09,513 INFO     Training average positive_sample_loss at step 623300: 0.153345\n",
      "2022-11-08 23:00:09,514 INFO     Training average negative_sample_loss at step 623300: 0.143593\n",
      "2022-11-08 23:00:09,514 INFO     Training average loss at step 623300: 0.148469\n",
      "2022-11-08 23:00:19,208 INFO     Training average positive_sample_loss at step 623400: 0.152909\n",
      "2022-11-08 23:00:19,208 INFO     Training average negative_sample_loss at step 623400: 0.145889\n",
      "2022-11-08 23:00:19,208 INFO     Training average loss at step 623400: 0.149399\n",
      "2022-11-08 23:00:28,904 INFO     Training average positive_sample_loss at step 623500: 0.150554\n",
      "2022-11-08 23:00:28,904 INFO     Training average negative_sample_loss at step 623500: 0.144764\n",
      "2022-11-08 23:00:28,904 INFO     Training average loss at step 623500: 0.147659\n",
      "2022-11-08 23:00:38,602 INFO     Training average positive_sample_loss at step 623600: 0.151617\n",
      "2022-11-08 23:00:38,603 INFO     Training average negative_sample_loss at step 623600: 0.141777\n",
      "2022-11-08 23:00:38,603 INFO     Training average loss at step 623600: 0.146697\n",
      "2022-11-08 23:00:48,294 INFO     Training average positive_sample_loss at step 623700: 0.156582\n",
      "2022-11-08 23:00:48,294 INFO     Training average negative_sample_loss at step 623700: 0.139719\n",
      "2022-11-08 23:00:48,294 INFO     Training average loss at step 623700: 0.148151\n",
      "2022-11-08 23:00:57,988 INFO     Training average positive_sample_loss at step 623800: 0.154827\n",
      "2022-11-08 23:00:57,988 INFO     Training average negative_sample_loss at step 623800: 0.145098\n",
      "2022-11-08 23:00:57,988 INFO     Training average loss at step 623800: 0.149963\n",
      "2022-11-08 23:01:07,687 INFO     Training average positive_sample_loss at step 623900: 0.153365\n",
      "2022-11-08 23:01:07,687 INFO     Training average negative_sample_loss at step 623900: 0.138196\n",
      "2022-11-08 23:01:07,687 INFO     Training average loss at step 623900: 0.145781\n",
      "2022-11-08 23:01:17,381 INFO     Training average positive_sample_loss at step 624000: 0.153448\n",
      "2022-11-08 23:01:17,381 INFO     Training average negative_sample_loss at step 624000: 0.139733\n",
      "2022-11-08 23:01:17,381 INFO     Training average loss at step 624000: 0.146590\n",
      "2022-11-08 23:01:27,076 INFO     Training average positive_sample_loss at step 624100: 0.157848\n",
      "2022-11-08 23:01:27,076 INFO     Training average negative_sample_loss at step 624100: 0.147002\n",
      "2022-11-08 23:01:27,076 INFO     Training average loss at step 624100: 0.152425\n",
      "2022-11-08 23:01:36,772 INFO     Training average positive_sample_loss at step 624200: 0.153236\n",
      "2022-11-08 23:01:36,772 INFO     Training average negative_sample_loss at step 624200: 0.146065\n",
      "2022-11-08 23:01:36,772 INFO     Training average loss at step 624200: 0.149650\n",
      "2022-11-08 23:01:46,461 INFO     Training average positive_sample_loss at step 624300: 0.152928\n",
      "2022-11-08 23:01:46,462 INFO     Training average negative_sample_loss at step 624300: 0.140531\n",
      "2022-11-08 23:01:46,462 INFO     Training average loss at step 624300: 0.146729\n",
      "2022-11-08 23:01:56,156 INFO     Training average positive_sample_loss at step 624400: 0.158028\n",
      "2022-11-08 23:01:56,156 INFO     Training average negative_sample_loss at step 624400: 0.143684\n",
      "2022-11-08 23:01:56,156 INFO     Training average loss at step 624400: 0.150856\n",
      "2022-11-08 23:02:05,853 INFO     Training average positive_sample_loss at step 624500: 0.153113\n",
      "2022-11-08 23:02:05,853 INFO     Training average negative_sample_loss at step 624500: 0.142380\n",
      "2022-11-08 23:02:05,853 INFO     Training average loss at step 624500: 0.147746\n",
      "2022-11-08 23:02:15,546 INFO     Training average positive_sample_loss at step 624600: 0.153144\n",
      "2022-11-08 23:02:15,546 INFO     Training average negative_sample_loss at step 624600: 0.147060\n",
      "2022-11-08 23:02:15,546 INFO     Training average loss at step 624600: 0.150102\n",
      "2022-11-08 23:02:25,828 INFO     Training average positive_sample_loss at step 624700: 0.154011\n",
      "2022-11-08 23:02:25,828 INFO     Training average negative_sample_loss at step 624700: 0.138509\n",
      "2022-11-08 23:02:25,828 INFO     Training average loss at step 624700: 0.146260\n",
      "2022-11-08 23:02:35,182 INFO     Training average positive_sample_loss at step 624800: 0.154613\n",
      "2022-11-08 23:02:35,182 INFO     Training average negative_sample_loss at step 624800: 0.145016\n",
      "2022-11-08 23:02:35,182 INFO     Training average loss at step 624800: 0.149815\n",
      "2022-11-08 23:02:45,133 INFO     Training average positive_sample_loss at step 624900: 0.153992\n",
      "2022-11-08 23:02:45,133 INFO     Training average negative_sample_loss at step 624900: 0.142243\n",
      "2022-11-08 23:02:45,133 INFO     Training average loss at step 624900: 0.148118\n",
      "2022-11-08 23:02:54,828 INFO     Training average positive_sample_loss at step 625000: 0.156365\n",
      "2022-11-08 23:02:54,828 INFO     Training average negative_sample_loss at step 625000: 0.142443\n",
      "2022-11-08 23:02:54,828 INFO     Training average loss at step 625000: 0.149404\n",
      "2022-11-08 23:03:04,870 INFO     Training average positive_sample_loss at step 625100: 0.154910\n",
      "2022-11-08 23:03:04,870 INFO     Training average negative_sample_loss at step 625100: 0.144151\n",
      "2022-11-08 23:03:04,871 INFO     Training average loss at step 625100: 0.149530\n",
      "2022-11-08 23:03:14,568 INFO     Training average positive_sample_loss at step 625200: 0.155623\n",
      "2022-11-08 23:03:14,568 INFO     Training average negative_sample_loss at step 625200: 0.146447\n",
      "2022-11-08 23:03:14,568 INFO     Training average loss at step 625200: 0.151035\n",
      "2022-11-08 23:03:25,106 INFO     Training average positive_sample_loss at step 625300: 0.158376\n",
      "2022-11-08 23:03:25,106 INFO     Training average negative_sample_loss at step 625300: 0.140042\n",
      "2022-11-08 23:03:25,106 INFO     Training average loss at step 625300: 0.149209\n",
      "2022-11-08 23:03:34,100 INFO     Training average positive_sample_loss at step 625400: 0.158664\n",
      "2022-11-08 23:03:34,100 INFO     Training average negative_sample_loss at step 625400: 0.145066\n",
      "2022-11-08 23:03:34,100 INFO     Training average loss at step 625400: 0.151865\n",
      "2022-11-08 23:03:43,784 INFO     Training average positive_sample_loss at step 625500: 0.153554\n",
      "2022-11-08 23:03:43,785 INFO     Training average negative_sample_loss at step 625500: 0.146721\n",
      "2022-11-08 23:03:43,785 INFO     Training average loss at step 625500: 0.150137\n",
      "2022-11-08 23:03:53,475 INFO     Training average positive_sample_loss at step 625600: 0.158142\n",
      "2022-11-08 23:03:53,475 INFO     Training average negative_sample_loss at step 625600: 0.142527\n",
      "2022-11-08 23:03:53,475 INFO     Training average loss at step 625600: 0.150334\n",
      "2022-11-08 23:04:03,171 INFO     Training average positive_sample_loss at step 625700: 0.155721\n",
      "2022-11-08 23:04:03,171 INFO     Training average negative_sample_loss at step 625700: 0.141432\n",
      "2022-11-08 23:04:03,171 INFO     Training average loss at step 625700: 0.148576\n",
      "2022-11-08 23:04:12,865 INFO     Training average positive_sample_loss at step 625800: 0.158479\n",
      "2022-11-08 23:04:12,865 INFO     Training average negative_sample_loss at step 625800: 0.143021\n",
      "2022-11-08 23:04:12,865 INFO     Training average loss at step 625800: 0.150750\n",
      "2022-11-08 23:04:22,560 INFO     Training average positive_sample_loss at step 625900: 0.156447\n",
      "2022-11-08 23:04:22,560 INFO     Training average negative_sample_loss at step 625900: 0.140314\n",
      "2022-11-08 23:04:22,560 INFO     Training average loss at step 625900: 0.148381\n",
      "2022-11-08 23:04:32,254 INFO     Training average positive_sample_loss at step 626000: 0.154974\n",
      "2022-11-08 23:04:32,254 INFO     Training average negative_sample_loss at step 626000: 0.140325\n",
      "2022-11-08 23:04:32,254 INFO     Training average loss at step 626000: 0.147649\n",
      "2022-11-08 23:04:41,946 INFO     Training average positive_sample_loss at step 626100: 0.149962\n",
      "2022-11-08 23:04:41,946 INFO     Training average negative_sample_loss at step 626100: 0.141492\n",
      "2022-11-08 23:04:41,946 INFO     Training average loss at step 626100: 0.145727\n",
      "2022-11-08 23:04:51,638 INFO     Training average positive_sample_loss at step 626200: 0.155452\n",
      "2022-11-08 23:04:51,638 INFO     Training average negative_sample_loss at step 626200: 0.141738\n",
      "2022-11-08 23:04:51,638 INFO     Training average loss at step 626200: 0.148595\n",
      "2022-11-08 23:05:01,335 INFO     Training average positive_sample_loss at step 626300: 0.150072\n",
      "2022-11-08 23:05:01,335 INFO     Training average negative_sample_loss at step 626300: 0.143054\n",
      "2022-11-08 23:05:01,335 INFO     Training average loss at step 626300: 0.146563\n",
      "2022-11-08 23:05:11,027 INFO     Training average positive_sample_loss at step 626400: 0.155249\n",
      "2022-11-08 23:05:11,027 INFO     Training average negative_sample_loss at step 626400: 0.141107\n",
      "2022-11-08 23:05:11,027 INFO     Training average loss at step 626400: 0.148178\n",
      "2022-11-08 23:05:20,721 INFO     Training average positive_sample_loss at step 626500: 0.155847\n",
      "2022-11-08 23:05:20,722 INFO     Training average negative_sample_loss at step 626500: 0.140139\n",
      "2022-11-08 23:05:20,722 INFO     Training average loss at step 626500: 0.147993\n",
      "2022-11-08 23:05:30,416 INFO     Training average positive_sample_loss at step 626600: 0.150472\n",
      "2022-11-08 23:05:30,416 INFO     Training average negative_sample_loss at step 626600: 0.143434\n",
      "2022-11-08 23:05:30,416 INFO     Training average loss at step 626600: 0.146953\n",
      "2022-11-08 23:05:40,109 INFO     Training average positive_sample_loss at step 626700: 0.154175\n",
      "2022-11-08 23:05:40,109 INFO     Training average negative_sample_loss at step 626700: 0.140873\n",
      "2022-11-08 23:05:40,110 INFO     Training average loss at step 626700: 0.147524\n",
      "2022-11-08 23:05:49,803 INFO     Training average positive_sample_loss at step 626800: 0.153831\n",
      "2022-11-08 23:05:49,803 INFO     Training average negative_sample_loss at step 626800: 0.145131\n",
      "2022-11-08 23:05:49,803 INFO     Training average loss at step 626800: 0.149481\n",
      "2022-11-08 23:05:59,498 INFO     Training average positive_sample_loss at step 626900: 0.150592\n",
      "2022-11-08 23:05:59,499 INFO     Training average negative_sample_loss at step 626900: 0.145368\n",
      "2022-11-08 23:05:59,499 INFO     Training average loss at step 626900: 0.147980\n",
      "2022-11-08 23:06:09,197 INFO     Training average positive_sample_loss at step 627000: 0.156729\n",
      "2022-11-08 23:06:09,197 INFO     Training average negative_sample_loss at step 627000: 0.145413\n",
      "2022-11-08 23:06:09,197 INFO     Training average loss at step 627000: 0.151071\n",
      "2022-11-08 23:06:18,891 INFO     Training average positive_sample_loss at step 627100: 0.161416\n",
      "2022-11-08 23:06:18,891 INFO     Training average negative_sample_loss at step 627100: 0.147156\n",
      "2022-11-08 23:06:18,891 INFO     Training average loss at step 627100: 0.154286\n",
      "2022-11-08 23:06:28,585 INFO     Training average positive_sample_loss at step 627200: 0.153565\n",
      "2022-11-08 23:06:28,585 INFO     Training average negative_sample_loss at step 627200: 0.143762\n",
      "2022-11-08 23:06:28,585 INFO     Training average loss at step 627200: 0.148664\n",
      "2022-11-08 23:06:38,278 INFO     Training average positive_sample_loss at step 627300: 0.154754\n",
      "2022-11-08 23:06:38,278 INFO     Training average negative_sample_loss at step 627300: 0.143186\n",
      "2022-11-08 23:06:38,278 INFO     Training average loss at step 627300: 0.148970\n",
      "2022-11-08 23:06:47,972 INFO     Training average positive_sample_loss at step 627400: 0.154924\n",
      "2022-11-08 23:06:47,972 INFO     Training average negative_sample_loss at step 627400: 0.144638\n",
      "2022-11-08 23:06:47,972 INFO     Training average loss at step 627400: 0.149781\n",
      "2022-11-08 23:06:57,668 INFO     Training average positive_sample_loss at step 627500: 0.150191\n",
      "2022-11-08 23:06:57,669 INFO     Training average negative_sample_loss at step 627500: 0.140429\n",
      "2022-11-08 23:06:57,669 INFO     Training average loss at step 627500: 0.145310\n",
      "2022-11-08 23:07:07,364 INFO     Training average positive_sample_loss at step 627600: 0.151386\n",
      "2022-11-08 23:07:07,364 INFO     Training average negative_sample_loss at step 627600: 0.138754\n",
      "2022-11-08 23:07:07,364 INFO     Training average loss at step 627600: 0.145070\n",
      "2022-11-08 23:07:17,054 INFO     Training average positive_sample_loss at step 627700: 0.152861\n",
      "2022-11-08 23:07:17,054 INFO     Training average negative_sample_loss at step 627700: 0.146245\n",
      "2022-11-08 23:07:17,054 INFO     Training average loss at step 627700: 0.149553\n",
      "2022-11-08 23:07:26,751 INFO     Training average positive_sample_loss at step 627800: 0.154566\n",
      "2022-11-08 23:07:26,752 INFO     Training average negative_sample_loss at step 627800: 0.147268\n",
      "2022-11-08 23:07:26,752 INFO     Training average loss at step 627800: 0.150917\n",
      "2022-11-08 23:07:36,446 INFO     Training average positive_sample_loss at step 627900: 0.161177\n",
      "2022-11-08 23:07:36,446 INFO     Training average negative_sample_loss at step 627900: 0.142908\n",
      "2022-11-08 23:07:36,446 INFO     Training average loss at step 627900: 0.152042\n",
      "2022-11-08 23:07:46,140 INFO     Training average positive_sample_loss at step 628000: 0.155535\n",
      "2022-11-08 23:07:46,140 INFO     Training average negative_sample_loss at step 628000: 0.142373\n",
      "2022-11-08 23:07:46,140 INFO     Training average loss at step 628000: 0.148954\n",
      "2022-11-08 23:07:55,837 INFO     Training average positive_sample_loss at step 628100: 0.154367\n",
      "2022-11-08 23:07:55,837 INFO     Training average negative_sample_loss at step 628100: 0.142070\n",
      "2022-11-08 23:07:55,837 INFO     Training average loss at step 628100: 0.148218\n",
      "2022-11-08 23:08:05,534 INFO     Training average positive_sample_loss at step 628200: 0.153436\n",
      "2022-11-08 23:08:05,535 INFO     Training average negative_sample_loss at step 628200: 0.143616\n",
      "2022-11-08 23:08:05,535 INFO     Training average loss at step 628200: 0.148526\n",
      "2022-11-08 23:08:15,226 INFO     Training average positive_sample_loss at step 628300: 0.154757\n",
      "2022-11-08 23:08:15,226 INFO     Training average negative_sample_loss at step 628300: 0.148120\n",
      "2022-11-08 23:08:15,226 INFO     Training average loss at step 628300: 0.151438\n",
      "2022-11-08 23:08:24,920 INFO     Training average positive_sample_loss at step 628400: 0.152836\n",
      "2022-11-08 23:08:24,920 INFO     Training average negative_sample_loss at step 628400: 0.144972\n",
      "2022-11-08 23:08:24,920 INFO     Training average loss at step 628400: 0.148904\n",
      "2022-11-08 23:08:34,616 INFO     Training average positive_sample_loss at step 628500: 0.156789\n",
      "2022-11-08 23:08:34,616 INFO     Training average negative_sample_loss at step 628500: 0.136106\n",
      "2022-11-08 23:08:34,616 INFO     Training average loss at step 628500: 0.146447\n",
      "2022-11-08 23:08:44,309 INFO     Training average positive_sample_loss at step 628600: 0.158662\n",
      "2022-11-08 23:08:44,309 INFO     Training average negative_sample_loss at step 628600: 0.141952\n",
      "2022-11-08 23:08:44,309 INFO     Training average loss at step 628600: 0.150307\n",
      "2022-11-08 23:08:54,010 INFO     Training average positive_sample_loss at step 628700: 0.152592\n",
      "2022-11-08 23:08:54,010 INFO     Training average negative_sample_loss at step 628700: 0.144089\n",
      "2022-11-08 23:08:54,010 INFO     Training average loss at step 628700: 0.148341\n",
      "2022-11-08 23:09:03,703 INFO     Training average positive_sample_loss at step 628800: 0.151907\n",
      "2022-11-08 23:09:03,703 INFO     Training average negative_sample_loss at step 628800: 0.145482\n",
      "2022-11-08 23:09:03,703 INFO     Training average loss at step 628800: 0.148695\n",
      "2022-11-08 23:09:13,393 INFO     Training average positive_sample_loss at step 628900: 0.149944\n",
      "2022-11-08 23:09:13,393 INFO     Training average negative_sample_loss at step 628900: 0.141383\n",
      "2022-11-08 23:09:13,393 INFO     Training average loss at step 628900: 0.145664\n",
      "2022-11-08 23:09:23,089 INFO     Training average positive_sample_loss at step 629000: 0.151970\n",
      "2022-11-08 23:09:23,090 INFO     Training average negative_sample_loss at step 629000: 0.138445\n",
      "2022-11-08 23:09:23,090 INFO     Training average loss at step 629000: 0.145207\n",
      "2022-11-08 23:09:32,781 INFO     Training average positive_sample_loss at step 629100: 0.152564\n",
      "2022-11-08 23:09:32,781 INFO     Training average negative_sample_loss at step 629100: 0.141080\n",
      "2022-11-08 23:09:32,781 INFO     Training average loss at step 629100: 0.146822\n",
      "2022-11-08 23:09:42,471 INFO     Training average positive_sample_loss at step 629200: 0.160945\n",
      "2022-11-08 23:09:42,471 INFO     Training average negative_sample_loss at step 629200: 0.145124\n",
      "2022-11-08 23:09:42,471 INFO     Training average loss at step 629200: 0.153034\n",
      "2022-11-08 23:09:52,162 INFO     Training average positive_sample_loss at step 629300: 0.153147\n",
      "2022-11-08 23:09:52,162 INFO     Training average negative_sample_loss at step 629300: 0.138857\n",
      "2022-11-08 23:09:52,162 INFO     Training average loss at step 629300: 0.146002\n",
      "2022-11-08 23:10:02,494 INFO     Training average positive_sample_loss at step 629400: 0.155288\n",
      "2022-11-08 23:10:02,494 INFO     Training average negative_sample_loss at step 629400: 0.141973\n",
      "2022-11-08 23:10:02,494 INFO     Training average loss at step 629400: 0.148631\n",
      "2022-11-08 23:10:12,461 INFO     Training average positive_sample_loss at step 629500: 0.154160\n",
      "2022-11-08 23:10:12,461 INFO     Training average negative_sample_loss at step 629500: 0.141625\n",
      "2022-11-08 23:10:12,461 INFO     Training average loss at step 629500: 0.147892\n",
      "2022-11-08 23:10:22,396 INFO     Training average positive_sample_loss at step 629600: 0.157382\n",
      "2022-11-08 23:10:22,396 INFO     Training average negative_sample_loss at step 629600: 0.145995\n",
      "2022-11-08 23:10:22,396 INFO     Training average loss at step 629600: 0.151688\n",
      "2022-11-08 23:10:32,371 INFO     Training average positive_sample_loss at step 629700: 0.150088\n",
      "2022-11-08 23:10:32,371 INFO     Training average negative_sample_loss at step 629700: 0.138979\n",
      "2022-11-08 23:10:32,371 INFO     Training average loss at step 629700: 0.144534\n",
      "2022-11-08 23:10:42,064 INFO     Training average positive_sample_loss at step 629800: 0.158458\n",
      "2022-11-08 23:10:42,064 INFO     Training average negative_sample_loss at step 629800: 0.145394\n",
      "2022-11-08 23:10:42,064 INFO     Training average loss at step 629800: 0.151926\n",
      "2022-11-08 23:10:51,759 INFO     Training average positive_sample_loss at step 629900: 0.157035\n",
      "2022-11-08 23:10:51,759 INFO     Training average negative_sample_loss at step 629900: 0.149864\n",
      "2022-11-08 23:10:51,759 INFO     Training average loss at step 629900: 0.153449\n",
      "2022-11-08 23:11:05,123 INFO     Training average positive_sample_loss at step 630000: 0.154714\n",
      "2022-11-08 23:11:05,123 INFO     Training average negative_sample_loss at step 630000: 0.141905\n",
      "2022-11-08 23:11:05,123 INFO     Training average loss at step 630000: 0.148310\n",
      "2022-11-08 23:11:14,810 INFO     Training average positive_sample_loss at step 630100: 0.153131\n",
      "2022-11-08 23:11:14,810 INFO     Training average negative_sample_loss at step 630100: 0.142216\n",
      "2022-11-08 23:11:14,810 INFO     Training average loss at step 630100: 0.147674\n",
      "2022-11-08 23:11:24,390 INFO     Training average positive_sample_loss at step 630200: 0.159104\n",
      "2022-11-08 23:11:24,390 INFO     Training average negative_sample_loss at step 630200: 0.143164\n",
      "2022-11-08 23:11:24,390 INFO     Training average loss at step 630200: 0.151134\n",
      "2022-11-08 23:11:33,496 INFO     Training average positive_sample_loss at step 630300: 0.157449\n",
      "2022-11-08 23:11:33,497 INFO     Training average negative_sample_loss at step 630300: 0.141784\n",
      "2022-11-08 23:11:33,497 INFO     Training average loss at step 630300: 0.149617\n",
      "2022-11-08 23:11:43,187 INFO     Training average positive_sample_loss at step 630400: 0.158368\n",
      "2022-11-08 23:11:43,187 INFO     Training average negative_sample_loss at step 630400: 0.141899\n",
      "2022-11-08 23:11:43,187 INFO     Training average loss at step 630400: 0.150133\n",
      "2022-11-08 23:11:52,876 INFO     Training average positive_sample_loss at step 630500: 0.157923\n",
      "2022-11-08 23:11:52,876 INFO     Training average negative_sample_loss at step 630500: 0.143942\n",
      "2022-11-08 23:11:52,876 INFO     Training average loss at step 630500: 0.150932\n",
      "2022-11-08 23:12:02,566 INFO     Training average positive_sample_loss at step 630600: 0.153550\n",
      "2022-11-08 23:12:02,566 INFO     Training average negative_sample_loss at step 630600: 0.144941\n",
      "2022-11-08 23:12:02,566 INFO     Training average loss at step 630600: 0.149246\n",
      "2022-11-08 23:12:12,260 INFO     Training average positive_sample_loss at step 630700: 0.156755\n",
      "2022-11-08 23:12:12,260 INFO     Training average negative_sample_loss at step 630700: 0.144882\n",
      "2022-11-08 23:12:12,260 INFO     Training average loss at step 630700: 0.150818\n",
      "2022-11-08 23:12:21,954 INFO     Training average positive_sample_loss at step 630800: 0.153238\n",
      "2022-11-08 23:12:21,954 INFO     Training average negative_sample_loss at step 630800: 0.137310\n",
      "2022-11-08 23:12:21,954 INFO     Training average loss at step 630800: 0.145274\n",
      "2022-11-08 23:12:30,935 INFO     Training average positive_sample_loss at step 630900: 0.158326\n",
      "2022-11-08 23:12:30,936 INFO     Training average negative_sample_loss at step 630900: 0.143702\n",
      "2022-11-08 23:12:30,936 INFO     Training average loss at step 630900: 0.151014\n",
      "2022-11-08 23:12:40,634 INFO     Training average positive_sample_loss at step 631000: 0.157522\n",
      "2022-11-08 23:12:40,634 INFO     Training average negative_sample_loss at step 631000: 0.142258\n",
      "2022-11-08 23:12:40,634 INFO     Training average loss at step 631000: 0.149890\n",
      "2022-11-08 23:12:50,321 INFO     Training average positive_sample_loss at step 631100: 0.150747\n",
      "2022-11-08 23:12:50,322 INFO     Training average negative_sample_loss at step 631100: 0.144803\n",
      "2022-11-08 23:12:50,322 INFO     Training average loss at step 631100: 0.147775\n",
      "2022-11-08 23:13:00,012 INFO     Training average positive_sample_loss at step 631200: 0.152180\n",
      "2022-11-08 23:13:00,012 INFO     Training average negative_sample_loss at step 631200: 0.141702\n",
      "2022-11-08 23:13:00,012 INFO     Training average loss at step 631200: 0.146941\n",
      "2022-11-08 23:13:09,706 INFO     Training average positive_sample_loss at step 631300: 0.155956\n",
      "2022-11-08 23:13:09,706 INFO     Training average negative_sample_loss at step 631300: 0.145437\n",
      "2022-11-08 23:13:09,706 INFO     Training average loss at step 631300: 0.150697\n",
      "2022-11-08 23:13:19,399 INFO     Training average positive_sample_loss at step 631400: 0.154800\n",
      "2022-11-08 23:13:19,399 INFO     Training average negative_sample_loss at step 631400: 0.142632\n",
      "2022-11-08 23:13:19,399 INFO     Training average loss at step 631400: 0.148716\n",
      "2022-11-08 23:13:29,095 INFO     Training average positive_sample_loss at step 631500: 0.155912\n",
      "2022-11-08 23:13:29,095 INFO     Training average negative_sample_loss at step 631500: 0.144766\n",
      "2022-11-08 23:13:29,095 INFO     Training average loss at step 631500: 0.150339\n",
      "2022-11-08 23:13:38,789 INFO     Training average positive_sample_loss at step 631600: 0.149375\n",
      "2022-11-08 23:13:38,789 INFO     Training average negative_sample_loss at step 631600: 0.146867\n",
      "2022-11-08 23:13:38,789 INFO     Training average loss at step 631600: 0.148121\n",
      "2022-11-08 23:13:48,477 INFO     Training average positive_sample_loss at step 631700: 0.158126\n",
      "2022-11-08 23:13:48,477 INFO     Training average negative_sample_loss at step 631700: 0.141107\n",
      "2022-11-08 23:13:48,477 INFO     Training average loss at step 631700: 0.149616\n",
      "2022-11-08 23:13:58,169 INFO     Training average positive_sample_loss at step 631800: 0.158044\n",
      "2022-11-08 23:13:58,170 INFO     Training average negative_sample_loss at step 631800: 0.139961\n",
      "2022-11-08 23:13:58,170 INFO     Training average loss at step 631800: 0.149003\n",
      "2022-11-08 23:14:07,865 INFO     Training average positive_sample_loss at step 631900: 0.155454\n",
      "2022-11-08 23:14:07,865 INFO     Training average negative_sample_loss at step 631900: 0.141510\n",
      "2022-11-08 23:14:07,865 INFO     Training average loss at step 631900: 0.148482\n",
      "2022-11-08 23:14:17,556 INFO     Training average positive_sample_loss at step 632000: 0.155885\n",
      "2022-11-08 23:14:17,557 INFO     Training average negative_sample_loss at step 632000: 0.143368\n",
      "2022-11-08 23:14:17,557 INFO     Training average loss at step 632000: 0.149626\n",
      "2022-11-08 23:14:27,245 INFO     Training average positive_sample_loss at step 632100: 0.155117\n",
      "2022-11-08 23:14:27,245 INFO     Training average negative_sample_loss at step 632100: 0.143813\n",
      "2022-11-08 23:14:27,245 INFO     Training average loss at step 632100: 0.149465\n",
      "2022-11-08 23:14:36,934 INFO     Training average positive_sample_loss at step 632200: 0.157892\n",
      "2022-11-08 23:14:36,934 INFO     Training average negative_sample_loss at step 632200: 0.140153\n",
      "2022-11-08 23:14:36,934 INFO     Training average loss at step 632200: 0.149022\n",
      "2022-11-08 23:14:46,625 INFO     Training average positive_sample_loss at step 632300: 0.155293\n",
      "2022-11-08 23:14:46,625 INFO     Training average negative_sample_loss at step 632300: 0.144572\n",
      "2022-11-08 23:14:46,625 INFO     Training average loss at step 632300: 0.149933\n",
      "2022-11-08 23:14:56,318 INFO     Training average positive_sample_loss at step 632400: 0.155368\n",
      "2022-11-08 23:14:56,318 INFO     Training average negative_sample_loss at step 632400: 0.143997\n",
      "2022-11-08 23:14:56,318 INFO     Training average loss at step 632400: 0.149683\n",
      "2022-11-08 23:15:06,012 INFO     Training average positive_sample_loss at step 632500: 0.153293\n",
      "2022-11-08 23:15:06,012 INFO     Training average negative_sample_loss at step 632500: 0.146175\n",
      "2022-11-08 23:15:06,012 INFO     Training average loss at step 632500: 0.149734\n",
      "2022-11-08 23:15:15,704 INFO     Training average positive_sample_loss at step 632600: 0.158722\n",
      "2022-11-08 23:15:15,704 INFO     Training average negative_sample_loss at step 632600: 0.145463\n",
      "2022-11-08 23:15:15,704 INFO     Training average loss at step 632600: 0.152093\n",
      "2022-11-08 23:15:25,391 INFO     Training average positive_sample_loss at step 632700: 0.157929\n",
      "2022-11-08 23:15:25,391 INFO     Training average negative_sample_loss at step 632700: 0.144923\n",
      "2022-11-08 23:15:25,391 INFO     Training average loss at step 632700: 0.151426\n",
      "2022-11-08 23:15:35,078 INFO     Training average positive_sample_loss at step 632800: 0.159282\n",
      "2022-11-08 23:15:35,078 INFO     Training average negative_sample_loss at step 632800: 0.144682\n",
      "2022-11-08 23:15:35,078 INFO     Training average loss at step 632800: 0.151982\n",
      "2022-11-08 23:15:44,773 INFO     Training average positive_sample_loss at step 632900: 0.151967\n",
      "2022-11-08 23:15:44,773 INFO     Training average negative_sample_loss at step 632900: 0.138422\n",
      "2022-11-08 23:15:44,773 INFO     Training average loss at step 632900: 0.145195\n",
      "2022-11-08 23:15:54,470 INFO     Training average positive_sample_loss at step 633000: 0.154369\n",
      "2022-11-08 23:15:54,470 INFO     Training average negative_sample_loss at step 633000: 0.141655\n",
      "2022-11-08 23:15:54,470 INFO     Training average loss at step 633000: 0.148012\n",
      "2022-11-08 23:16:04,162 INFO     Training average positive_sample_loss at step 633100: 0.158724\n",
      "2022-11-08 23:16:04,162 INFO     Training average negative_sample_loss at step 633100: 0.140844\n",
      "2022-11-08 23:16:04,162 INFO     Training average loss at step 633100: 0.149784\n",
      "2022-11-08 23:16:13,857 INFO     Training average positive_sample_loss at step 633200: 0.158260\n",
      "2022-11-08 23:16:13,857 INFO     Training average negative_sample_loss at step 633200: 0.139779\n",
      "2022-11-08 23:16:13,857 INFO     Training average loss at step 633200: 0.149019\n",
      "2022-11-08 23:16:26,797 INFO     Training average positive_sample_loss at step 633300: 0.153611\n",
      "2022-11-08 23:16:26,798 INFO     Training average negative_sample_loss at step 633300: 0.142955\n",
      "2022-11-08 23:16:26,798 INFO     Training average loss at step 633300: 0.148283\n",
      "2022-11-08 23:16:36,497 INFO     Training average positive_sample_loss at step 633400: 0.151311\n",
      "2022-11-08 23:16:36,497 INFO     Training average negative_sample_loss at step 633400: 0.144959\n",
      "2022-11-08 23:16:36,497 INFO     Training average loss at step 633400: 0.148135\n",
      "2022-11-08 23:16:46,189 INFO     Training average positive_sample_loss at step 633500: 0.147281\n",
      "2022-11-08 23:16:46,189 INFO     Training average negative_sample_loss at step 633500: 0.142602\n",
      "2022-11-08 23:16:46,189 INFO     Training average loss at step 633500: 0.144942\n",
      "2022-11-08 23:16:55,881 INFO     Training average positive_sample_loss at step 633600: 0.148991\n",
      "2022-11-08 23:16:55,881 INFO     Training average negative_sample_loss at step 633600: 0.143295\n",
      "2022-11-08 23:16:55,882 INFO     Training average loss at step 633600: 0.146143\n",
      "2022-11-08 23:17:05,574 INFO     Training average positive_sample_loss at step 633700: 0.144580\n",
      "2022-11-08 23:17:05,575 INFO     Training average negative_sample_loss at step 633700: 0.141994\n",
      "2022-11-08 23:17:05,575 INFO     Training average loss at step 633700: 0.143287\n",
      "2022-11-08 23:17:15,263 INFO     Training average positive_sample_loss at step 633800: 0.145324\n",
      "2022-11-08 23:17:15,263 INFO     Training average negative_sample_loss at step 633800: 0.142320\n",
      "2022-11-08 23:17:15,263 INFO     Training average loss at step 633800: 0.143822\n",
      "2022-11-08 23:17:24,956 INFO     Training average positive_sample_loss at step 633900: 0.148569\n",
      "2022-11-08 23:17:24,956 INFO     Training average negative_sample_loss at step 633900: 0.148323\n",
      "2022-11-08 23:17:24,956 INFO     Training average loss at step 633900: 0.148446\n",
      "2022-11-08 23:17:34,649 INFO     Training average positive_sample_loss at step 634000: 0.144300\n",
      "2022-11-08 23:17:34,649 INFO     Training average negative_sample_loss at step 634000: 0.142541\n",
      "2022-11-08 23:17:34,649 INFO     Training average loss at step 634000: 0.143420\n",
      "2022-11-08 23:17:44,341 INFO     Training average positive_sample_loss at step 634100: 0.144630\n",
      "2022-11-08 23:17:44,341 INFO     Training average negative_sample_loss at step 634100: 0.141037\n",
      "2022-11-08 23:17:44,341 INFO     Training average loss at step 634100: 0.142834\n",
      "2022-11-08 23:17:54,033 INFO     Training average positive_sample_loss at step 634200: 0.149367\n",
      "2022-11-08 23:17:54,033 INFO     Training average negative_sample_loss at step 634200: 0.143064\n",
      "2022-11-08 23:17:54,033 INFO     Training average loss at step 634200: 0.146216\n",
      "2022-11-08 23:18:03,728 INFO     Training average positive_sample_loss at step 634300: 0.148859\n",
      "2022-11-08 23:18:03,728 INFO     Training average negative_sample_loss at step 634300: 0.145859\n",
      "2022-11-08 23:18:03,728 INFO     Training average loss at step 634300: 0.147359\n",
      "2022-11-08 23:18:13,419 INFO     Training average positive_sample_loss at step 634400: 0.152538\n",
      "2022-11-08 23:18:13,419 INFO     Training average negative_sample_loss at step 634400: 0.140841\n",
      "2022-11-08 23:18:13,419 INFO     Training average loss at step 634400: 0.146689\n",
      "2022-11-08 23:18:23,113 INFO     Training average positive_sample_loss at step 634500: 0.146260\n",
      "2022-11-08 23:18:23,113 INFO     Training average negative_sample_loss at step 634500: 0.142996\n",
      "2022-11-08 23:18:23,113 INFO     Training average loss at step 634500: 0.144628\n",
      "2022-11-08 23:18:32,815 INFO     Training average positive_sample_loss at step 634600: 0.153324\n",
      "2022-11-08 23:18:32,815 INFO     Training average negative_sample_loss at step 634600: 0.141843\n",
      "2022-11-08 23:18:32,815 INFO     Training average loss at step 634600: 0.147583\n",
      "2022-11-08 23:18:42,507 INFO     Training average positive_sample_loss at step 634700: 0.149928\n",
      "2022-11-08 23:18:42,507 INFO     Training average negative_sample_loss at step 634700: 0.144084\n",
      "2022-11-08 23:18:42,508 INFO     Training average loss at step 634700: 0.147006\n",
      "2022-11-08 23:18:52,201 INFO     Training average positive_sample_loss at step 634800: 0.146687\n",
      "2022-11-08 23:18:52,201 INFO     Training average negative_sample_loss at step 634800: 0.135939\n",
      "2022-11-08 23:18:52,201 INFO     Training average loss at step 634800: 0.141313\n",
      "2022-11-08 23:19:01,893 INFO     Training average positive_sample_loss at step 634900: 0.145561\n",
      "2022-11-08 23:19:01,894 INFO     Training average negative_sample_loss at step 634900: 0.143721\n",
      "2022-11-08 23:19:01,894 INFO     Training average loss at step 634900: 0.144641\n",
      "2022-11-08 23:19:11,586 INFO     Training average positive_sample_loss at step 635000: 0.147781\n",
      "2022-11-08 23:19:11,586 INFO     Training average negative_sample_loss at step 635000: 0.145163\n",
      "2022-11-08 23:19:11,586 INFO     Training average loss at step 635000: 0.146472\n",
      "2022-11-08 23:19:21,278 INFO     Training average positive_sample_loss at step 635100: 0.147167\n",
      "2022-11-08 23:19:21,278 INFO     Training average negative_sample_loss at step 635100: 0.143511\n",
      "2022-11-08 23:19:21,278 INFO     Training average loss at step 635100: 0.145339\n",
      "2022-11-08 23:19:30,973 INFO     Training average positive_sample_loss at step 635200: 0.153573\n",
      "2022-11-08 23:19:30,973 INFO     Training average negative_sample_loss at step 635200: 0.143683\n",
      "2022-11-08 23:19:30,973 INFO     Training average loss at step 635200: 0.148628\n",
      "2022-11-08 23:19:40,664 INFO     Training average positive_sample_loss at step 635300: 0.146473\n",
      "2022-11-08 23:19:40,664 INFO     Training average negative_sample_loss at step 635300: 0.140282\n",
      "2022-11-08 23:19:40,664 INFO     Training average loss at step 635300: 0.143378\n",
      "2022-11-08 23:19:50,351 INFO     Training average positive_sample_loss at step 635400: 0.148760\n",
      "2022-11-08 23:19:50,352 INFO     Training average negative_sample_loss at step 635400: 0.144166\n",
      "2022-11-08 23:19:50,352 INFO     Training average loss at step 635400: 0.146463\n",
      "2022-11-08 23:20:00,044 INFO     Training average positive_sample_loss at step 635500: 0.141583\n",
      "2022-11-08 23:20:00,044 INFO     Training average negative_sample_loss at step 635500: 0.145673\n",
      "2022-11-08 23:20:00,044 INFO     Training average loss at step 635500: 0.143628\n",
      "2022-11-08 23:20:09,736 INFO     Training average positive_sample_loss at step 635600: 0.152220\n",
      "2022-11-08 23:20:09,736 INFO     Training average negative_sample_loss at step 635600: 0.149176\n",
      "2022-11-08 23:20:09,736 INFO     Training average loss at step 635600: 0.150698\n",
      "2022-11-08 23:20:18,367 INFO     Training average positive_sample_loss at step 635700: 0.148023\n",
      "2022-11-08 23:20:18,367 INFO     Training average negative_sample_loss at step 635700: 0.137581\n",
      "2022-11-08 23:20:18,367 INFO     Training average loss at step 635700: 0.142802\n",
      "2022-11-08 23:20:24,743 INFO     Training average positive_sample_loss at step 635800: 0.146183\n",
      "2022-11-08 23:20:24,743 INFO     Training average negative_sample_loss at step 635800: 0.145642\n",
      "2022-11-08 23:20:24,743 INFO     Training average loss at step 635800: 0.145913\n",
      "2022-11-08 23:20:31,129 INFO     Training average positive_sample_loss at step 635900: 0.145708\n",
      "2022-11-08 23:20:31,129 INFO     Training average negative_sample_loss at step 635900: 0.138941\n",
      "2022-11-08 23:20:31,129 INFO     Training average loss at step 635900: 0.142325\n",
      "2022-11-08 23:20:37,496 INFO     Training average positive_sample_loss at step 636000: 0.146272\n",
      "2022-11-08 23:20:37,496 INFO     Training average negative_sample_loss at step 636000: 0.148227\n",
      "2022-11-08 23:20:37,496 INFO     Training average loss at step 636000: 0.147249\n",
      "2022-11-08 23:20:43,842 INFO     Training average positive_sample_loss at step 636100: 0.148489\n",
      "2022-11-08 23:20:43,842 INFO     Training average negative_sample_loss at step 636100: 0.145329\n",
      "2022-11-08 23:20:43,842 INFO     Training average loss at step 636100: 0.146909\n",
      "2022-11-08 23:20:50,203 INFO     Training average positive_sample_loss at step 636200: 0.148020\n",
      "2022-11-08 23:20:50,203 INFO     Training average negative_sample_loss at step 636200: 0.141831\n",
      "2022-11-08 23:20:50,203 INFO     Training average loss at step 636200: 0.144925\n",
      "2022-11-08 23:20:56,540 INFO     Training average positive_sample_loss at step 636300: 0.146943\n",
      "2022-11-08 23:20:56,540 INFO     Training average negative_sample_loss at step 636300: 0.146045\n",
      "2022-11-08 23:20:56,540 INFO     Training average loss at step 636300: 0.146494\n",
      "2022-11-08 23:21:01,469 INFO     Training average positive_sample_loss at step 636400: 0.147872\n",
      "2022-11-08 23:21:01,469 INFO     Training average negative_sample_loss at step 636400: 0.144633\n",
      "2022-11-08 23:21:01,469 INFO     Training average loss at step 636400: 0.146252\n",
      "2022-11-08 23:21:07,809 INFO     Training average positive_sample_loss at step 636500: 0.152014\n",
      "2022-11-08 23:21:07,809 INFO     Training average negative_sample_loss at step 636500: 0.144146\n",
      "2022-11-08 23:21:07,809 INFO     Training average loss at step 636500: 0.148080\n",
      "2022-11-08 23:21:14,156 INFO     Training average positive_sample_loss at step 636600: 0.149886\n",
      "2022-11-08 23:21:14,157 INFO     Training average negative_sample_loss at step 636600: 0.147452\n",
      "2022-11-08 23:21:14,157 INFO     Training average loss at step 636600: 0.148669\n",
      "2022-11-08 23:21:20,493 INFO     Training average positive_sample_loss at step 636700: 0.147375\n",
      "2022-11-08 23:21:20,494 INFO     Training average negative_sample_loss at step 636700: 0.144892\n",
      "2022-11-08 23:21:20,494 INFO     Training average loss at step 636700: 0.146134\n",
      "2022-11-08 23:21:26,836 INFO     Training average positive_sample_loss at step 636800: 0.148489\n",
      "2022-11-08 23:21:26,836 INFO     Training average negative_sample_loss at step 636800: 0.144627\n",
      "2022-11-08 23:21:26,836 INFO     Training average loss at step 636800: 0.146558\n",
      "2022-11-08 23:21:33,188 INFO     Training average positive_sample_loss at step 636900: 0.151333\n",
      "2022-11-08 23:21:33,188 INFO     Training average negative_sample_loss at step 636900: 0.144159\n",
      "2022-11-08 23:21:33,188 INFO     Training average loss at step 636900: 0.147746\n",
      "2022-11-08 23:21:39,532 INFO     Training average positive_sample_loss at step 637000: 0.147205\n",
      "2022-11-08 23:21:39,533 INFO     Training average negative_sample_loss at step 637000: 0.139163\n",
      "2022-11-08 23:21:39,533 INFO     Training average loss at step 637000: 0.143184\n",
      "2022-11-08 23:21:45,875 INFO     Training average positive_sample_loss at step 637100: 0.149145\n",
      "2022-11-08 23:21:45,875 INFO     Training average negative_sample_loss at step 637100: 0.140209\n",
      "2022-11-08 23:21:45,875 INFO     Training average loss at step 637100: 0.144677\n",
      "2022-11-08 23:21:52,213 INFO     Training average positive_sample_loss at step 637200: 0.147327\n",
      "2022-11-08 23:21:52,213 INFO     Training average negative_sample_loss at step 637200: 0.142535\n",
      "2022-11-08 23:21:52,214 INFO     Training average loss at step 637200: 0.144931\n",
      "2022-11-08 23:21:58,581 INFO     Training average positive_sample_loss at step 637300: 0.150501\n",
      "2022-11-08 23:21:58,581 INFO     Training average negative_sample_loss at step 637300: 0.143072\n",
      "2022-11-08 23:21:58,581 INFO     Training average loss at step 637300: 0.146787\n",
      "2022-11-08 23:22:04,970 INFO     Training average positive_sample_loss at step 637400: 0.146921\n",
      "2022-11-08 23:22:04,970 INFO     Training average negative_sample_loss at step 637400: 0.143103\n",
      "2022-11-08 23:22:04,970 INFO     Training average loss at step 637400: 0.145012\n",
      "2022-11-08 23:22:11,341 INFO     Training average positive_sample_loss at step 637500: 0.149735\n",
      "2022-11-08 23:22:11,341 INFO     Training average negative_sample_loss at step 637500: 0.143119\n",
      "2022-11-08 23:22:11,341 INFO     Training average loss at step 637500: 0.146427\n",
      "2022-11-08 23:22:17,697 INFO     Training average positive_sample_loss at step 637600: 0.149649\n",
      "2022-11-08 23:22:17,697 INFO     Training average negative_sample_loss at step 637600: 0.139921\n",
      "2022-11-08 23:22:17,697 INFO     Training average loss at step 637600: 0.144785\n",
      "2022-11-08 23:22:24,051 INFO     Training average positive_sample_loss at step 637700: 0.147575\n",
      "2022-11-08 23:22:24,051 INFO     Training average negative_sample_loss at step 637700: 0.142141\n",
      "2022-11-08 23:22:24,051 INFO     Training average loss at step 637700: 0.144858\n",
      "2022-11-08 23:22:30,407 INFO     Training average positive_sample_loss at step 637800: 0.149379\n",
      "2022-11-08 23:22:30,407 INFO     Training average negative_sample_loss at step 637800: 0.137761\n",
      "2022-11-08 23:22:30,407 INFO     Training average loss at step 637800: 0.143570\n",
      "2022-11-08 23:22:36,765 INFO     Training average positive_sample_loss at step 637900: 0.145225\n",
      "2022-11-08 23:22:36,765 INFO     Training average negative_sample_loss at step 637900: 0.147935\n",
      "2022-11-08 23:22:36,765 INFO     Training average loss at step 637900: 0.146580\n",
      "2022-11-08 23:22:43,160 INFO     Training average positive_sample_loss at step 638000: 0.153395\n",
      "2022-11-08 23:22:43,160 INFO     Training average negative_sample_loss at step 638000: 0.140839\n",
      "2022-11-08 23:22:43,160 INFO     Training average loss at step 638000: 0.147117\n",
      "2022-11-08 23:22:49,511 INFO     Training average positive_sample_loss at step 638100: 0.146134\n",
      "2022-11-08 23:22:49,511 INFO     Training average negative_sample_loss at step 638100: 0.137991\n",
      "2022-11-08 23:22:49,511 INFO     Training average loss at step 638100: 0.142062\n",
      "2022-11-08 23:22:55,872 INFO     Training average positive_sample_loss at step 638200: 0.152042\n",
      "2022-11-08 23:22:55,872 INFO     Training average negative_sample_loss at step 638200: 0.144149\n",
      "2022-11-08 23:22:55,872 INFO     Training average loss at step 638200: 0.148095\n",
      "2022-11-08 23:23:02,214 INFO     Training average positive_sample_loss at step 638300: 0.150264\n",
      "2022-11-08 23:23:02,215 INFO     Training average negative_sample_loss at step 638300: 0.139909\n",
      "2022-11-08 23:23:02,215 INFO     Training average loss at step 638300: 0.145087\n",
      "2022-11-08 23:23:08,574 INFO     Training average positive_sample_loss at step 638400: 0.150814\n",
      "2022-11-08 23:23:08,574 INFO     Training average negative_sample_loss at step 638400: 0.141424\n",
      "2022-11-08 23:23:08,574 INFO     Training average loss at step 638400: 0.146119\n",
      "2022-11-08 23:23:14,943 INFO     Training average positive_sample_loss at step 638500: 0.150333\n",
      "2022-11-08 23:23:14,943 INFO     Training average negative_sample_loss at step 638500: 0.143542\n",
      "2022-11-08 23:23:14,943 INFO     Training average loss at step 638500: 0.146938\n",
      "2022-11-08 23:23:21,316 INFO     Training average positive_sample_loss at step 638600: 0.149511\n",
      "2022-11-08 23:23:21,316 INFO     Training average negative_sample_loss at step 638600: 0.139950\n",
      "2022-11-08 23:23:21,316 INFO     Training average loss at step 638600: 0.144730\n",
      "2022-11-08 23:23:27,701 INFO     Training average positive_sample_loss at step 638700: 0.146964\n",
      "2022-11-08 23:23:27,701 INFO     Training average negative_sample_loss at step 638700: 0.143562\n",
      "2022-11-08 23:23:27,701 INFO     Training average loss at step 638700: 0.145263\n",
      "2022-11-08 23:23:34,076 INFO     Training average positive_sample_loss at step 638800: 0.148667\n",
      "2022-11-08 23:23:34,076 INFO     Training average negative_sample_loss at step 638800: 0.141598\n",
      "2022-11-08 23:23:34,076 INFO     Training average loss at step 638800: 0.145132\n",
      "2022-11-08 23:23:40,424 INFO     Training average positive_sample_loss at step 638900: 0.149808\n",
      "2022-11-08 23:23:40,424 INFO     Training average negative_sample_loss at step 638900: 0.142591\n",
      "2022-11-08 23:23:40,424 INFO     Training average loss at step 638900: 0.146200\n",
      "2022-11-08 23:23:46,779 INFO     Training average positive_sample_loss at step 639000: 0.149205\n",
      "2022-11-08 23:23:46,779 INFO     Training average negative_sample_loss at step 639000: 0.143230\n",
      "2022-11-08 23:23:46,779 INFO     Training average loss at step 639000: 0.146218\n",
      "2022-11-08 23:23:53,134 INFO     Training average positive_sample_loss at step 639100: 0.148833\n",
      "2022-11-08 23:23:53,134 INFO     Training average negative_sample_loss at step 639100: 0.138272\n",
      "2022-11-08 23:23:53,134 INFO     Training average loss at step 639100: 0.143552\n",
      "2022-11-08 23:23:59,532 INFO     Training average positive_sample_loss at step 639200: 0.148125\n",
      "2022-11-08 23:23:59,532 INFO     Training average negative_sample_loss at step 639200: 0.141454\n",
      "2022-11-08 23:23:59,532 INFO     Training average loss at step 639200: 0.144789\n",
      "2022-11-08 23:24:05,899 INFO     Training average positive_sample_loss at step 639300: 0.147596\n",
      "2022-11-08 23:24:05,899 INFO     Training average negative_sample_loss at step 639300: 0.145800\n",
      "2022-11-08 23:24:05,899 INFO     Training average loss at step 639300: 0.146698\n",
      "2022-11-08 23:24:12,276 INFO     Training average positive_sample_loss at step 639400: 0.144998\n",
      "2022-11-08 23:24:12,276 INFO     Training average negative_sample_loss at step 639400: 0.139233\n",
      "2022-11-08 23:24:12,276 INFO     Training average loss at step 639400: 0.142116\n",
      "2022-11-08 23:24:18,648 INFO     Training average positive_sample_loss at step 639500: 0.149590\n",
      "2022-11-08 23:24:18,648 INFO     Training average negative_sample_loss at step 639500: 0.141836\n",
      "2022-11-08 23:24:18,648 INFO     Training average loss at step 639500: 0.145713\n",
      "2022-11-08 23:24:25,011 INFO     Training average positive_sample_loss at step 639600: 0.148572\n",
      "2022-11-08 23:24:25,011 INFO     Training average negative_sample_loss at step 639600: 0.141250\n",
      "2022-11-08 23:24:25,011 INFO     Training average loss at step 639600: 0.144911\n",
      "2022-11-08 23:24:31,404 INFO     Training average positive_sample_loss at step 639700: 0.147353\n",
      "2022-11-08 23:24:31,404 INFO     Training average negative_sample_loss at step 639700: 0.139402\n",
      "2022-11-08 23:24:31,404 INFO     Training average loss at step 639700: 0.143378\n",
      "2022-11-08 23:24:37,780 INFO     Training average positive_sample_loss at step 639800: 0.155261\n",
      "2022-11-08 23:24:37,781 INFO     Training average negative_sample_loss at step 639800: 0.140564\n",
      "2022-11-08 23:24:37,781 INFO     Training average loss at step 639800: 0.147912\n",
      "2022-11-08 23:24:44,141 INFO     Training average positive_sample_loss at step 639900: 0.146225\n",
      "2022-11-08 23:24:44,141 INFO     Training average negative_sample_loss at step 639900: 0.141838\n",
      "2022-11-08 23:24:44,141 INFO     Training average loss at step 639900: 0.144031\n",
      "2022-11-08 23:24:53,511 INFO     Training average positive_sample_loss at step 640000: 0.152239\n",
      "2022-11-08 23:24:53,511 INFO     Training average negative_sample_loss at step 640000: 0.140596\n",
      "2022-11-08 23:24:53,511 INFO     Training average loss at step 640000: 0.146418\n",
      "2022-11-08 23:24:59,894 INFO     Training average positive_sample_loss at step 640100: 0.151585\n",
      "2022-11-08 23:24:59,894 INFO     Training average negative_sample_loss at step 640100: 0.137635\n",
      "2022-11-08 23:24:59,894 INFO     Training average loss at step 640100: 0.144610\n",
      "2022-11-08 23:25:06,293 INFO     Training average positive_sample_loss at step 640200: 0.154075\n",
      "2022-11-08 23:25:06,293 INFO     Training average negative_sample_loss at step 640200: 0.142788\n",
      "2022-11-08 23:25:06,293 INFO     Training average loss at step 640200: 0.148431\n",
      "2022-11-08 23:25:12,700 INFO     Training average positive_sample_loss at step 640300: 0.147213\n",
      "2022-11-08 23:25:12,700 INFO     Training average negative_sample_loss at step 640300: 0.147787\n",
      "2022-11-08 23:25:12,700 INFO     Training average loss at step 640300: 0.147500\n",
      "2022-11-08 23:25:19,082 INFO     Training average positive_sample_loss at step 640400: 0.152798\n",
      "2022-11-08 23:25:19,082 INFO     Training average negative_sample_loss at step 640400: 0.143955\n",
      "2022-11-08 23:25:19,082 INFO     Training average loss at step 640400: 0.148377\n",
      "2022-11-08 23:25:25,452 INFO     Training average positive_sample_loss at step 640500: 0.150485\n",
      "2022-11-08 23:25:25,452 INFO     Training average negative_sample_loss at step 640500: 0.143216\n",
      "2022-11-08 23:25:25,452 INFO     Training average loss at step 640500: 0.146850\n",
      "2022-11-08 23:25:31,836 INFO     Training average positive_sample_loss at step 640600: 0.152106\n",
      "2022-11-08 23:25:31,836 INFO     Training average negative_sample_loss at step 640600: 0.144051\n",
      "2022-11-08 23:25:31,836 INFO     Training average loss at step 640600: 0.148079\n",
      "2022-11-08 23:25:38,228 INFO     Training average positive_sample_loss at step 640700: 0.145809\n",
      "2022-11-08 23:25:38,228 INFO     Training average negative_sample_loss at step 640700: 0.141990\n",
      "2022-11-08 23:25:38,228 INFO     Training average loss at step 640700: 0.143899\n",
      "2022-11-08 23:25:44,571 INFO     Training average positive_sample_loss at step 640800: 0.151541\n",
      "2022-11-08 23:25:44,571 INFO     Training average negative_sample_loss at step 640800: 0.146956\n",
      "2022-11-08 23:25:44,571 INFO     Training average loss at step 640800: 0.149248\n",
      "2022-11-08 23:25:50,968 INFO     Training average positive_sample_loss at step 640900: 0.147162\n",
      "2022-11-08 23:25:50,968 INFO     Training average negative_sample_loss at step 640900: 0.142550\n",
      "2022-11-08 23:25:50,968 INFO     Training average loss at step 640900: 0.144856\n",
      "2022-11-08 23:25:57,336 INFO     Training average positive_sample_loss at step 641000: 0.152162\n",
      "2022-11-08 23:25:57,336 INFO     Training average negative_sample_loss at step 641000: 0.142935\n",
      "2022-11-08 23:25:57,336 INFO     Training average loss at step 641000: 0.147548\n",
      "2022-11-08 23:26:03,728 INFO     Training average positive_sample_loss at step 641100: 0.151605\n",
      "2022-11-08 23:26:03,728 INFO     Training average negative_sample_loss at step 641100: 0.144297\n",
      "2022-11-08 23:26:03,728 INFO     Training average loss at step 641100: 0.147951\n",
      "2022-11-08 23:26:10,096 INFO     Training average positive_sample_loss at step 641200: 0.151384\n",
      "2022-11-08 23:26:10,096 INFO     Training average negative_sample_loss at step 641200: 0.140674\n",
      "2022-11-08 23:26:10,096 INFO     Training average loss at step 641200: 0.146029\n",
      "2022-11-08 23:26:16,474 INFO     Training average positive_sample_loss at step 641300: 0.150966\n",
      "2022-11-08 23:26:16,474 INFO     Training average negative_sample_loss at step 641300: 0.141307\n",
      "2022-11-08 23:26:16,475 INFO     Training average loss at step 641300: 0.146137\n",
      "2022-11-08 23:26:22,827 INFO     Training average positive_sample_loss at step 641400: 0.152272\n",
      "2022-11-08 23:26:22,827 INFO     Training average negative_sample_loss at step 641400: 0.142653\n",
      "2022-11-08 23:26:22,827 INFO     Training average loss at step 641400: 0.147462\n",
      "2022-11-08 23:26:29,189 INFO     Training average positive_sample_loss at step 641500: 0.149098\n",
      "2022-11-08 23:26:29,190 INFO     Training average negative_sample_loss at step 641500: 0.142899\n",
      "2022-11-08 23:26:29,190 INFO     Training average loss at step 641500: 0.145998\n",
      "2022-11-08 23:26:35,536 INFO     Training average positive_sample_loss at step 641600: 0.150135\n",
      "2022-11-08 23:26:35,536 INFO     Training average negative_sample_loss at step 641600: 0.144026\n",
      "2022-11-08 23:26:35,536 INFO     Training average loss at step 641600: 0.147081\n",
      "2022-11-08 23:26:41,918 INFO     Training average positive_sample_loss at step 641700: 0.147244\n",
      "2022-11-08 23:26:41,918 INFO     Training average negative_sample_loss at step 641700: 0.144099\n",
      "2022-11-08 23:26:41,918 INFO     Training average loss at step 641700: 0.145672\n",
      "2022-11-08 23:26:48,265 INFO     Training average positive_sample_loss at step 641800: 0.148344\n",
      "2022-11-08 23:26:48,265 INFO     Training average negative_sample_loss at step 641800: 0.144138\n",
      "2022-11-08 23:26:48,265 INFO     Training average loss at step 641800: 0.146241\n",
      "2022-11-08 23:26:54,627 INFO     Training average positive_sample_loss at step 641900: 0.154232\n",
      "2022-11-08 23:26:54,628 INFO     Training average negative_sample_loss at step 641900: 0.138517\n",
      "2022-11-08 23:26:54,628 INFO     Training average loss at step 641900: 0.146374\n",
      "2022-11-08 23:26:59,576 INFO     Training average positive_sample_loss at step 642000: 0.154702\n",
      "2022-11-08 23:26:59,577 INFO     Training average negative_sample_loss at step 642000: 0.140456\n",
      "2022-11-08 23:26:59,577 INFO     Training average loss at step 642000: 0.147579\n",
      "2022-11-08 23:27:05,939 INFO     Training average positive_sample_loss at step 642100: 0.144182\n",
      "2022-11-08 23:27:05,939 INFO     Training average negative_sample_loss at step 642100: 0.139952\n",
      "2022-11-08 23:27:05,939 INFO     Training average loss at step 642100: 0.142067\n",
      "2022-11-08 23:27:12,289 INFO     Training average positive_sample_loss at step 642200: 0.149031\n",
      "2022-11-08 23:27:12,289 INFO     Training average negative_sample_loss at step 642200: 0.141531\n",
      "2022-11-08 23:27:12,289 INFO     Training average loss at step 642200: 0.145281\n",
      "2022-11-08 23:27:18,648 INFO     Training average positive_sample_loss at step 642300: 0.149960\n",
      "2022-11-08 23:27:18,648 INFO     Training average negative_sample_loss at step 642300: 0.140476\n",
      "2022-11-08 23:27:18,648 INFO     Training average loss at step 642300: 0.145218\n",
      "2022-11-08 23:27:25,017 INFO     Training average positive_sample_loss at step 642400: 0.148537\n",
      "2022-11-08 23:27:25,017 INFO     Training average negative_sample_loss at step 642400: 0.137224\n",
      "2022-11-08 23:27:25,017 INFO     Training average loss at step 642400: 0.142881\n",
      "2022-11-08 23:27:31,378 INFO     Training average positive_sample_loss at step 642500: 0.152626\n",
      "2022-11-08 23:27:31,378 INFO     Training average negative_sample_loss at step 642500: 0.142486\n",
      "2022-11-08 23:27:31,378 INFO     Training average loss at step 642500: 0.147556\n",
      "2022-11-08 23:27:37,737 INFO     Training average positive_sample_loss at step 642600: 0.153058\n",
      "2022-11-08 23:27:37,737 INFO     Training average negative_sample_loss at step 642600: 0.140294\n",
      "2022-11-08 23:27:37,737 INFO     Training average loss at step 642600: 0.146676\n",
      "2022-11-08 23:27:44,087 INFO     Training average positive_sample_loss at step 642700: 0.148666\n",
      "2022-11-08 23:27:44,087 INFO     Training average negative_sample_loss at step 642700: 0.141686\n",
      "2022-11-08 23:27:44,087 INFO     Training average loss at step 642700: 0.145176\n",
      "2022-11-08 23:27:50,447 INFO     Training average positive_sample_loss at step 642800: 0.145536\n",
      "2022-11-08 23:27:50,447 INFO     Training average negative_sample_loss at step 642800: 0.136548\n",
      "2022-11-08 23:27:50,447 INFO     Training average loss at step 642800: 0.141042\n",
      "2022-11-08 23:27:56,798 INFO     Training average positive_sample_loss at step 642900: 0.144353\n",
      "2022-11-08 23:27:56,798 INFO     Training average negative_sample_loss at step 642900: 0.140665\n",
      "2022-11-08 23:27:56,798 INFO     Training average loss at step 642900: 0.142509\n",
      "2022-11-08 23:28:03,168 INFO     Training average positive_sample_loss at step 643000: 0.148635\n",
      "2022-11-08 23:28:03,169 INFO     Training average negative_sample_loss at step 643000: 0.141471\n",
      "2022-11-08 23:28:03,169 INFO     Training average loss at step 643000: 0.145053\n",
      "2022-11-08 23:28:09,534 INFO     Training average positive_sample_loss at step 643100: 0.149330\n",
      "2022-11-08 23:28:09,534 INFO     Training average negative_sample_loss at step 643100: 0.144666\n",
      "2022-11-08 23:28:09,534 INFO     Training average loss at step 643100: 0.146998\n",
      "2022-11-08 23:28:15,933 INFO     Training average positive_sample_loss at step 643200: 0.150232\n",
      "2022-11-08 23:28:15,933 INFO     Training average negative_sample_loss at step 643200: 0.140255\n",
      "2022-11-08 23:28:15,933 INFO     Training average loss at step 643200: 0.145244\n",
      "2022-11-08 23:28:22,359 INFO     Training average positive_sample_loss at step 643300: 0.149214\n",
      "2022-11-08 23:28:22,360 INFO     Training average negative_sample_loss at step 643300: 0.139228\n",
      "2022-11-08 23:28:22,360 INFO     Training average loss at step 643300: 0.144221\n",
      "2022-11-08 23:28:28,747 INFO     Training average positive_sample_loss at step 643400: 0.150518\n",
      "2022-11-08 23:28:28,747 INFO     Training average negative_sample_loss at step 643400: 0.141027\n",
      "2022-11-08 23:28:28,747 INFO     Training average loss at step 643400: 0.145773\n",
      "2022-11-08 23:28:38,535 INFO     Training average positive_sample_loss at step 643500: 0.150944\n",
      "2022-11-08 23:28:38,535 INFO     Training average negative_sample_loss at step 643500: 0.142343\n",
      "2022-11-08 23:28:38,535 INFO     Training average loss at step 643500: 0.146643\n",
      "2022-11-08 23:28:44,921 INFO     Training average positive_sample_loss at step 643600: 0.148040\n",
      "2022-11-08 23:28:44,921 INFO     Training average negative_sample_loss at step 643600: 0.142884\n",
      "2022-11-08 23:28:44,921 INFO     Training average loss at step 643600: 0.145462\n",
      "2022-11-08 23:28:51,296 INFO     Training average positive_sample_loss at step 643700: 0.152799\n",
      "2022-11-08 23:28:51,297 INFO     Training average negative_sample_loss at step 643700: 0.143205\n",
      "2022-11-08 23:28:51,297 INFO     Training average loss at step 643700: 0.148002\n",
      "2022-11-08 23:28:57,684 INFO     Training average positive_sample_loss at step 643800: 0.141770\n",
      "2022-11-08 23:28:57,684 INFO     Training average negative_sample_loss at step 643800: 0.139871\n",
      "2022-11-08 23:28:57,684 INFO     Training average loss at step 643800: 0.140821\n",
      "2022-11-08 23:29:04,070 INFO     Training average positive_sample_loss at step 643900: 0.153259\n",
      "2022-11-08 23:29:04,070 INFO     Training average negative_sample_loss at step 643900: 0.144759\n",
      "2022-11-08 23:29:04,071 INFO     Training average loss at step 643900: 0.149009\n",
      "2022-11-08 23:29:10,477 INFO     Training average positive_sample_loss at step 644000: 0.150605\n",
      "2022-11-08 23:29:10,477 INFO     Training average negative_sample_loss at step 644000: 0.141515\n",
      "2022-11-08 23:29:10,477 INFO     Training average loss at step 644000: 0.146060\n",
      "2022-11-08 23:29:16,858 INFO     Training average positive_sample_loss at step 644100: 0.151281\n",
      "2022-11-08 23:29:16,858 INFO     Training average negative_sample_loss at step 644100: 0.140689\n",
      "2022-11-08 23:29:16,858 INFO     Training average loss at step 644100: 0.145985\n",
      "2022-11-08 23:29:23,243 INFO     Training average positive_sample_loss at step 644200: 0.151834\n",
      "2022-11-08 23:29:23,243 INFO     Training average negative_sample_loss at step 644200: 0.142343\n",
      "2022-11-08 23:29:23,243 INFO     Training average loss at step 644200: 0.147089\n",
      "2022-11-08 23:29:29,623 INFO     Training average positive_sample_loss at step 644300: 0.150286\n",
      "2022-11-08 23:29:29,623 INFO     Training average negative_sample_loss at step 644300: 0.142286\n",
      "2022-11-08 23:29:29,623 INFO     Training average loss at step 644300: 0.146286\n",
      "2022-11-08 23:29:36,030 INFO     Training average positive_sample_loss at step 644400: 0.150855\n",
      "2022-11-08 23:29:36,031 INFO     Training average negative_sample_loss at step 644400: 0.144064\n",
      "2022-11-08 23:29:36,031 INFO     Training average loss at step 644400: 0.147459\n",
      "2022-11-08 23:29:42,444 INFO     Training average positive_sample_loss at step 644500: 0.148013\n",
      "2022-11-08 23:29:42,445 INFO     Training average negative_sample_loss at step 644500: 0.142746\n",
      "2022-11-08 23:29:42,445 INFO     Training average loss at step 644500: 0.145379\n",
      "2022-11-08 23:29:48,834 INFO     Training average positive_sample_loss at step 644600: 0.143484\n",
      "2022-11-08 23:29:48,834 INFO     Training average negative_sample_loss at step 644600: 0.138146\n",
      "2022-11-08 23:29:48,834 INFO     Training average loss at step 644600: 0.140815\n",
      "2022-11-08 23:29:55,238 INFO     Training average positive_sample_loss at step 644700: 0.150459\n",
      "2022-11-08 23:29:55,239 INFO     Training average negative_sample_loss at step 644700: 0.138576\n",
      "2022-11-08 23:29:55,239 INFO     Training average loss at step 644700: 0.144518\n",
      "2022-11-08 23:30:01,615 INFO     Training average positive_sample_loss at step 644800: 0.150007\n",
      "2022-11-08 23:30:01,615 INFO     Training average negative_sample_loss at step 644800: 0.144665\n",
      "2022-11-08 23:30:01,615 INFO     Training average loss at step 644800: 0.147336\n",
      "2022-11-08 23:30:08,018 INFO     Training average positive_sample_loss at step 644900: 0.151538\n",
      "2022-11-08 23:30:08,018 INFO     Training average negative_sample_loss at step 644900: 0.141480\n",
      "2022-11-08 23:30:08,018 INFO     Training average loss at step 644900: 0.146509\n",
      "2022-11-08 23:30:14,371 INFO     Training average positive_sample_loss at step 645000: 0.143282\n",
      "2022-11-08 23:30:14,372 INFO     Training average negative_sample_loss at step 645000: 0.141726\n",
      "2022-11-08 23:30:14,372 INFO     Training average loss at step 645000: 0.142504\n",
      "2022-11-08 23:30:20,769 INFO     Training average positive_sample_loss at step 645100: 0.148155\n",
      "2022-11-08 23:30:20,769 INFO     Training average negative_sample_loss at step 645100: 0.145345\n",
      "2022-11-08 23:30:20,769 INFO     Training average loss at step 645100: 0.146750\n",
      "2022-11-08 23:30:27,159 INFO     Training average positive_sample_loss at step 645200: 0.146227\n",
      "2022-11-08 23:30:27,159 INFO     Training average negative_sample_loss at step 645200: 0.143203\n",
      "2022-11-08 23:30:27,159 INFO     Training average loss at step 645200: 0.144715\n",
      "2022-11-08 23:30:33,505 INFO     Training average positive_sample_loss at step 645300: 0.150106\n",
      "2022-11-08 23:30:33,505 INFO     Training average negative_sample_loss at step 645300: 0.145003\n",
      "2022-11-08 23:30:33,505 INFO     Training average loss at step 645300: 0.147555\n",
      "2022-11-08 23:30:39,884 INFO     Training average positive_sample_loss at step 645400: 0.148493\n",
      "2022-11-08 23:30:39,885 INFO     Training average negative_sample_loss at step 645400: 0.140105\n",
      "2022-11-08 23:30:39,885 INFO     Training average loss at step 645400: 0.144299\n",
      "2022-11-08 23:30:46,250 INFO     Training average positive_sample_loss at step 645500: 0.148034\n",
      "2022-11-08 23:30:46,250 INFO     Training average negative_sample_loss at step 645500: 0.141524\n",
      "2022-11-08 23:30:46,250 INFO     Training average loss at step 645500: 0.144779\n",
      "2022-11-08 23:30:52,601 INFO     Training average positive_sample_loss at step 645600: 0.146572\n",
      "2022-11-08 23:30:52,601 INFO     Training average negative_sample_loss at step 645600: 0.135932\n",
      "2022-11-08 23:30:52,601 INFO     Training average loss at step 645600: 0.141252\n",
      "2022-11-08 23:30:58,961 INFO     Training average positive_sample_loss at step 645700: 0.147126\n",
      "2022-11-08 23:30:58,961 INFO     Training average negative_sample_loss at step 645700: 0.140660\n",
      "2022-11-08 23:30:58,961 INFO     Training average loss at step 645700: 0.143893\n",
      "2022-11-08 23:31:05,353 INFO     Training average positive_sample_loss at step 645800: 0.154145\n",
      "2022-11-08 23:31:05,353 INFO     Training average negative_sample_loss at step 645800: 0.139737\n",
      "2022-11-08 23:31:05,353 INFO     Training average loss at step 645800: 0.146941\n",
      "2022-11-08 23:31:11,717 INFO     Training average positive_sample_loss at step 645900: 0.145115\n",
      "2022-11-08 23:31:11,717 INFO     Training average negative_sample_loss at step 645900: 0.139902\n",
      "2022-11-08 23:31:11,717 INFO     Training average loss at step 645900: 0.142508\n",
      "2022-11-08 23:31:18,077 INFO     Training average positive_sample_loss at step 646000: 0.151932\n",
      "2022-11-08 23:31:18,077 INFO     Training average negative_sample_loss at step 646000: 0.140536\n",
      "2022-11-08 23:31:18,077 INFO     Training average loss at step 646000: 0.146234\n",
      "2022-11-08 23:31:24,454 INFO     Training average positive_sample_loss at step 646100: 0.147444\n",
      "2022-11-08 23:31:24,454 INFO     Training average negative_sample_loss at step 646100: 0.143096\n",
      "2022-11-08 23:31:24,454 INFO     Training average loss at step 646100: 0.145270\n",
      "2022-11-08 23:31:30,840 INFO     Training average positive_sample_loss at step 646200: 0.156212\n",
      "2022-11-08 23:31:30,840 INFO     Training average negative_sample_loss at step 646200: 0.144751\n",
      "2022-11-08 23:31:30,840 INFO     Training average loss at step 646200: 0.150481\n",
      "2022-11-08 23:31:37,214 INFO     Training average positive_sample_loss at step 646300: 0.157071\n",
      "2022-11-08 23:31:37,214 INFO     Training average negative_sample_loss at step 646300: 0.142900\n",
      "2022-11-08 23:31:37,214 INFO     Training average loss at step 646300: 0.149986\n",
      "2022-11-08 23:31:43,597 INFO     Training average positive_sample_loss at step 646400: 0.148239\n",
      "2022-11-08 23:31:43,597 INFO     Training average negative_sample_loss at step 646400: 0.141762\n",
      "2022-11-08 23:31:43,597 INFO     Training average loss at step 646400: 0.145001\n",
      "2022-11-08 23:31:49,993 INFO     Training average positive_sample_loss at step 646500: 0.152678\n",
      "2022-11-08 23:31:49,993 INFO     Training average negative_sample_loss at step 646500: 0.140692\n",
      "2022-11-08 23:31:49,994 INFO     Training average loss at step 646500: 0.146685\n",
      "2022-11-08 23:31:56,402 INFO     Training average positive_sample_loss at step 646600: 0.151265\n",
      "2022-11-08 23:31:56,402 INFO     Training average negative_sample_loss at step 646600: 0.137853\n",
      "2022-11-08 23:31:56,402 INFO     Training average loss at step 646600: 0.144559\n",
      "2022-11-08 23:32:02,809 INFO     Training average positive_sample_loss at step 646700: 0.149068\n",
      "2022-11-08 23:32:02,809 INFO     Training average negative_sample_loss at step 646700: 0.144849\n",
      "2022-11-08 23:32:02,809 INFO     Training average loss at step 646700: 0.146959\n",
      "2022-11-08 23:32:09,168 INFO     Training average positive_sample_loss at step 646800: 0.152195\n",
      "2022-11-08 23:32:09,168 INFO     Training average negative_sample_loss at step 646800: 0.139700\n",
      "2022-11-08 23:32:09,168 INFO     Training average loss at step 646800: 0.145948\n",
      "2022-11-08 23:32:15,532 INFO     Training average positive_sample_loss at step 646900: 0.146089\n",
      "2022-11-08 23:32:15,532 INFO     Training average negative_sample_loss at step 646900: 0.144852\n",
      "2022-11-08 23:32:15,532 INFO     Training average loss at step 646900: 0.145471\n",
      "2022-11-08 23:32:21,894 INFO     Training average positive_sample_loss at step 647000: 0.148047\n",
      "2022-11-08 23:32:21,894 INFO     Training average negative_sample_loss at step 647000: 0.148228\n",
      "2022-11-08 23:32:21,894 INFO     Training average loss at step 647000: 0.148137\n",
      "2022-11-08 23:32:28,264 INFO     Training average positive_sample_loss at step 647100: 0.150428\n",
      "2022-11-08 23:32:28,265 INFO     Training average negative_sample_loss at step 647100: 0.140743\n",
      "2022-11-08 23:32:28,265 INFO     Training average loss at step 647100: 0.145585\n",
      "2022-11-08 23:32:34,684 INFO     Training average positive_sample_loss at step 647200: 0.154981\n",
      "2022-11-08 23:32:34,684 INFO     Training average negative_sample_loss at step 647200: 0.140880\n",
      "2022-11-08 23:32:34,684 INFO     Training average loss at step 647200: 0.147931\n",
      "2022-11-08 23:32:41,094 INFO     Training average positive_sample_loss at step 647300: 0.147903\n",
      "2022-11-08 23:32:41,094 INFO     Training average negative_sample_loss at step 647300: 0.141850\n",
      "2022-11-08 23:32:41,094 INFO     Training average loss at step 647300: 0.144877\n",
      "2022-11-08 23:32:47,465 INFO     Training average positive_sample_loss at step 647400: 0.151999\n",
      "2022-11-08 23:32:47,466 INFO     Training average negative_sample_loss at step 647400: 0.139599\n",
      "2022-11-08 23:32:47,466 INFO     Training average loss at step 647400: 0.145799\n",
      "2022-11-08 23:32:53,824 INFO     Training average positive_sample_loss at step 647500: 0.146115\n",
      "2022-11-08 23:32:53,824 INFO     Training average negative_sample_loss at step 647500: 0.141515\n",
      "2022-11-08 23:32:53,824 INFO     Training average loss at step 647500: 0.143815\n",
      "2022-11-08 23:32:58,773 INFO     Training average positive_sample_loss at step 647600: 0.152987\n",
      "2022-11-08 23:32:58,773 INFO     Training average negative_sample_loss at step 647600: 0.141141\n",
      "2022-11-08 23:32:58,773 INFO     Training average loss at step 647600: 0.147064\n",
      "2022-11-08 23:33:05,140 INFO     Training average positive_sample_loss at step 647700: 0.147321\n",
      "2022-11-08 23:33:05,140 INFO     Training average negative_sample_loss at step 647700: 0.141315\n",
      "2022-11-08 23:33:05,140 INFO     Training average loss at step 647700: 0.144318\n",
      "2022-11-08 23:33:11,492 INFO     Training average positive_sample_loss at step 647800: 0.145648\n",
      "2022-11-08 23:33:11,492 INFO     Training average negative_sample_loss at step 647800: 0.141978\n",
      "2022-11-08 23:33:11,492 INFO     Training average loss at step 647800: 0.143813\n",
      "2022-11-08 23:33:17,855 INFO     Training average positive_sample_loss at step 647900: 0.146594\n",
      "2022-11-08 23:33:17,855 INFO     Training average negative_sample_loss at step 647900: 0.141568\n",
      "2022-11-08 23:33:17,855 INFO     Training average loss at step 647900: 0.144081\n",
      "2022-11-08 23:33:24,235 INFO     Training average positive_sample_loss at step 648000: 0.151489\n",
      "2022-11-08 23:33:24,235 INFO     Training average negative_sample_loss at step 648000: 0.141768\n",
      "2022-11-08 23:33:24,235 INFO     Training average loss at step 648000: 0.146628\n",
      "2022-11-08 23:33:30,633 INFO     Training average positive_sample_loss at step 648100: 0.153777\n",
      "2022-11-08 23:33:30,633 INFO     Training average negative_sample_loss at step 648100: 0.140763\n",
      "2022-11-08 23:33:30,633 INFO     Training average loss at step 648100: 0.147270\n",
      "2022-11-08 23:33:40,281 INFO     Training average positive_sample_loss at step 648200: 0.147696\n",
      "2022-11-08 23:33:40,281 INFO     Training average negative_sample_loss at step 648200: 0.143314\n",
      "2022-11-08 23:33:40,281 INFO     Training average loss at step 648200: 0.145505\n",
      "2022-11-08 23:33:46,633 INFO     Training average positive_sample_loss at step 648300: 0.154466\n",
      "2022-11-08 23:33:46,633 INFO     Training average negative_sample_loss at step 648300: 0.144007\n",
      "2022-11-08 23:33:46,633 INFO     Training average loss at step 648300: 0.149237\n",
      "2022-11-08 23:33:53,034 INFO     Training average positive_sample_loss at step 648400: 0.148629\n",
      "2022-11-08 23:33:53,034 INFO     Training average negative_sample_loss at step 648400: 0.145424\n",
      "2022-11-08 23:33:53,034 INFO     Training average loss at step 648400: 0.147027\n",
      "2022-11-08 23:33:59,414 INFO     Training average positive_sample_loss at step 648500: 0.154219\n",
      "2022-11-08 23:33:59,414 INFO     Training average negative_sample_loss at step 648500: 0.144318\n",
      "2022-11-08 23:33:59,414 INFO     Training average loss at step 648500: 0.149268\n",
      "2022-11-08 23:34:05,789 INFO     Training average positive_sample_loss at step 648600: 0.149816\n",
      "2022-11-08 23:34:05,789 INFO     Training average negative_sample_loss at step 648600: 0.140803\n",
      "2022-11-08 23:34:05,789 INFO     Training average loss at step 648600: 0.145309\n",
      "2022-11-08 23:34:12,169 INFO     Training average positive_sample_loss at step 648700: 0.145907\n",
      "2022-11-08 23:34:12,169 INFO     Training average negative_sample_loss at step 648700: 0.142388\n",
      "2022-11-08 23:34:12,169 INFO     Training average loss at step 648700: 0.144148\n",
      "2022-11-08 23:34:18,583 INFO     Training average positive_sample_loss at step 648800: 0.150169\n",
      "2022-11-08 23:34:18,583 INFO     Training average negative_sample_loss at step 648800: 0.138893\n",
      "2022-11-08 23:34:18,583 INFO     Training average loss at step 648800: 0.144531\n",
      "2022-11-08 23:34:24,959 INFO     Training average positive_sample_loss at step 648900: 0.153141\n",
      "2022-11-08 23:34:24,959 INFO     Training average negative_sample_loss at step 648900: 0.142625\n",
      "2022-11-08 23:34:24,959 INFO     Training average loss at step 648900: 0.147883\n",
      "2022-11-08 23:34:31,328 INFO     Training average positive_sample_loss at step 649000: 0.149659\n",
      "2022-11-08 23:34:31,328 INFO     Training average negative_sample_loss at step 649000: 0.140534\n",
      "2022-11-08 23:34:31,328 INFO     Training average loss at step 649000: 0.145096\n",
      "2022-11-08 23:34:37,683 INFO     Training average positive_sample_loss at step 649100: 0.152026\n",
      "2022-11-08 23:34:37,683 INFO     Training average negative_sample_loss at step 649100: 0.136797\n",
      "2022-11-08 23:34:37,683 INFO     Training average loss at step 649100: 0.144411\n",
      "2022-11-08 23:34:44,059 INFO     Training average positive_sample_loss at step 649200: 0.155509\n",
      "2022-11-08 23:34:44,059 INFO     Training average negative_sample_loss at step 649200: 0.140887\n",
      "2022-11-08 23:34:44,059 INFO     Training average loss at step 649200: 0.148198\n",
      "2022-11-08 23:34:50,409 INFO     Training average positive_sample_loss at step 649300: 0.144760\n",
      "2022-11-08 23:34:50,409 INFO     Training average negative_sample_loss at step 649300: 0.143731\n",
      "2022-11-08 23:34:50,409 INFO     Training average loss at step 649300: 0.144246\n",
      "2022-11-08 23:34:56,778 INFO     Training average positive_sample_loss at step 649400: 0.149805\n",
      "2022-11-08 23:34:56,778 INFO     Training average negative_sample_loss at step 649400: 0.143203\n",
      "2022-11-08 23:34:56,778 INFO     Training average loss at step 649400: 0.146504\n",
      "2022-11-08 23:35:03,176 INFO     Training average positive_sample_loss at step 649500: 0.148621\n",
      "2022-11-08 23:35:03,176 INFO     Training average negative_sample_loss at step 649500: 0.143472\n",
      "2022-11-08 23:35:03,176 INFO     Training average loss at step 649500: 0.146047\n",
      "2022-11-08 23:35:09,550 INFO     Training average positive_sample_loss at step 649600: 0.151992\n",
      "2022-11-08 23:35:09,550 INFO     Training average negative_sample_loss at step 649600: 0.141199\n",
      "2022-11-08 23:35:09,550 INFO     Training average loss at step 649600: 0.146595\n",
      "2022-11-08 23:35:15,920 INFO     Training average positive_sample_loss at step 649700: 0.149849\n",
      "2022-11-08 23:35:15,920 INFO     Training average negative_sample_loss at step 649700: 0.137307\n",
      "2022-11-08 23:35:15,920 INFO     Training average loss at step 649700: 0.143578\n",
      "2022-11-08 23:35:22,313 INFO     Training average positive_sample_loss at step 649800: 0.147453\n",
      "2022-11-08 23:35:22,313 INFO     Training average negative_sample_loss at step 649800: 0.144072\n",
      "2022-11-08 23:35:22,313 INFO     Training average loss at step 649800: 0.145762\n",
      "2022-11-08 23:35:28,682 INFO     Training average positive_sample_loss at step 649900: 0.152457\n",
      "2022-11-08 23:35:28,683 INFO     Training average negative_sample_loss at step 649900: 0.145373\n",
      "2022-11-08 23:35:28,683 INFO     Training average loss at step 649900: 0.148915\n",
      "2022-11-08 23:35:38,006 INFO     Training average positive_sample_loss at step 650000: 0.150424\n",
      "2022-11-08 23:35:38,006 INFO     Training average negative_sample_loss at step 650000: 0.141588\n",
      "2022-11-08 23:35:38,006 INFO     Training average loss at step 650000: 0.146006\n",
      "2022-11-08 23:35:44,409 INFO     Training average positive_sample_loss at step 650100: 0.150802\n",
      "2022-11-08 23:35:44,409 INFO     Training average negative_sample_loss at step 650100: 0.141984\n",
      "2022-11-08 23:35:44,409 INFO     Training average loss at step 650100: 0.146393\n",
      "2022-11-08 23:35:50,793 INFO     Training average positive_sample_loss at step 650200: 0.146434\n",
      "2022-11-08 23:35:50,793 INFO     Training average negative_sample_loss at step 650200: 0.141899\n",
      "2022-11-08 23:35:50,793 INFO     Training average loss at step 650200: 0.144167\n",
      "2022-11-08 23:35:57,170 INFO     Training average positive_sample_loss at step 650300: 0.144379\n",
      "2022-11-08 23:35:57,170 INFO     Training average negative_sample_loss at step 650300: 0.140116\n",
      "2022-11-08 23:35:57,170 INFO     Training average loss at step 650300: 0.142248\n",
      "2022-11-08 23:36:03,549 INFO     Training average positive_sample_loss at step 650400: 0.151297\n",
      "2022-11-08 23:36:03,550 INFO     Training average negative_sample_loss at step 650400: 0.146757\n",
      "2022-11-08 23:36:03,550 INFO     Training average loss at step 650400: 0.149027\n",
      "2022-11-08 23:36:09,933 INFO     Training average positive_sample_loss at step 650500: 0.144520\n",
      "2022-11-08 23:36:09,933 INFO     Training average negative_sample_loss at step 650500: 0.142195\n",
      "2022-11-08 23:36:09,933 INFO     Training average loss at step 650500: 0.143358\n",
      "2022-11-08 23:36:16,290 INFO     Training average positive_sample_loss at step 650600: 0.151430\n",
      "2022-11-08 23:36:16,290 INFO     Training average negative_sample_loss at step 650600: 0.138613\n",
      "2022-11-08 23:36:16,290 INFO     Training average loss at step 650600: 0.145021\n",
      "2022-11-08 23:36:22,646 INFO     Training average positive_sample_loss at step 650700: 0.145173\n",
      "2022-11-08 23:36:22,646 INFO     Training average negative_sample_loss at step 650700: 0.140389\n",
      "2022-11-08 23:36:22,646 INFO     Training average loss at step 650700: 0.142781\n",
      "2022-11-08 23:36:29,018 INFO     Training average positive_sample_loss at step 650800: 0.150427\n",
      "2022-11-08 23:36:29,018 INFO     Training average negative_sample_loss at step 650800: 0.141432\n",
      "2022-11-08 23:36:29,018 INFO     Training average loss at step 650800: 0.145930\n",
      "2022-11-08 23:36:35,387 INFO     Training average positive_sample_loss at step 650900: 0.149100\n",
      "2022-11-08 23:36:35,387 INFO     Training average negative_sample_loss at step 650900: 0.139635\n",
      "2022-11-08 23:36:35,387 INFO     Training average loss at step 650900: 0.144368\n",
      "2022-11-08 23:36:41,732 INFO     Training average positive_sample_loss at step 651000: 0.151823\n",
      "2022-11-08 23:36:41,733 INFO     Training average negative_sample_loss at step 651000: 0.139801\n",
      "2022-11-08 23:36:41,733 INFO     Training average loss at step 651000: 0.145812\n",
      "2022-11-08 23:36:48,104 INFO     Training average positive_sample_loss at step 651100: 0.150630\n",
      "2022-11-08 23:36:48,104 INFO     Training average negative_sample_loss at step 651100: 0.140026\n",
      "2022-11-08 23:36:48,104 INFO     Training average loss at step 651100: 0.145328\n",
      "2022-11-08 23:36:54,473 INFO     Training average positive_sample_loss at step 651200: 0.146405\n",
      "2022-11-08 23:36:54,473 INFO     Training average negative_sample_loss at step 651200: 0.141018\n",
      "2022-11-08 23:36:54,473 INFO     Training average loss at step 651200: 0.143711\n",
      "2022-11-08 23:37:00,837 INFO     Training average positive_sample_loss at step 651300: 0.150579\n",
      "2022-11-08 23:37:00,838 INFO     Training average negative_sample_loss at step 651300: 0.139904\n",
      "2022-11-08 23:37:00,838 INFO     Training average loss at step 651300: 0.145242\n",
      "2022-11-08 23:37:07,207 INFO     Training average positive_sample_loss at step 651400: 0.146868\n",
      "2022-11-08 23:37:07,207 INFO     Training average negative_sample_loss at step 651400: 0.138727\n",
      "2022-11-08 23:37:07,207 INFO     Training average loss at step 651400: 0.142798\n",
      "2022-11-08 23:37:13,571 INFO     Training average positive_sample_loss at step 651500: 0.147902\n",
      "2022-11-08 23:37:13,571 INFO     Training average negative_sample_loss at step 651500: 0.146588\n",
      "2022-11-08 23:37:13,571 INFO     Training average loss at step 651500: 0.147245\n",
      "2022-11-08 23:37:19,967 INFO     Training average positive_sample_loss at step 651600: 0.148561\n",
      "2022-11-08 23:37:19,967 INFO     Training average negative_sample_loss at step 651600: 0.135976\n",
      "2022-11-08 23:37:19,967 INFO     Training average loss at step 651600: 0.142269\n",
      "2022-11-08 23:37:26,356 INFO     Training average positive_sample_loss at step 651700: 0.151519\n",
      "2022-11-08 23:37:26,356 INFO     Training average negative_sample_loss at step 651700: 0.140841\n",
      "2022-11-08 23:37:26,356 INFO     Training average loss at step 651700: 0.146180\n",
      "2022-11-08 23:37:32,757 INFO     Training average positive_sample_loss at step 651800: 0.156086\n",
      "2022-11-08 23:37:32,757 INFO     Training average negative_sample_loss at step 651800: 0.140417\n",
      "2022-11-08 23:37:32,757 INFO     Training average loss at step 651800: 0.148252\n",
      "2022-11-08 23:37:39,127 INFO     Training average positive_sample_loss at step 651900: 0.153901\n",
      "2022-11-08 23:37:39,127 INFO     Training average negative_sample_loss at step 651900: 0.141639\n",
      "2022-11-08 23:37:39,127 INFO     Training average loss at step 651900: 0.147770\n",
      "2022-11-08 23:37:45,486 INFO     Training average positive_sample_loss at step 652000: 0.147570\n",
      "2022-11-08 23:37:45,486 INFO     Training average negative_sample_loss at step 652000: 0.143119\n",
      "2022-11-08 23:37:45,486 INFO     Training average loss at step 652000: 0.145344\n",
      "2022-11-08 23:37:51,870 INFO     Training average positive_sample_loss at step 652100: 0.153118\n",
      "2022-11-08 23:37:51,870 INFO     Training average negative_sample_loss at step 652100: 0.143281\n",
      "2022-11-08 23:37:51,870 INFO     Training average loss at step 652100: 0.148200\n",
      "2022-11-08 23:37:58,255 INFO     Training average positive_sample_loss at step 652200: 0.149148\n",
      "2022-11-08 23:37:58,255 INFO     Training average negative_sample_loss at step 652200: 0.138353\n",
      "2022-11-08 23:37:58,255 INFO     Training average loss at step 652200: 0.143750\n",
      "2022-11-08 23:38:04,653 INFO     Training average positive_sample_loss at step 652300: 0.149512\n",
      "2022-11-08 23:38:04,653 INFO     Training average negative_sample_loss at step 652300: 0.143556\n",
      "2022-11-08 23:38:04,653 INFO     Training average loss at step 652300: 0.146534\n",
      "2022-11-08 23:38:11,004 INFO     Training average positive_sample_loss at step 652400: 0.152535\n",
      "2022-11-08 23:38:11,004 INFO     Training average negative_sample_loss at step 652400: 0.137670\n",
      "2022-11-08 23:38:11,004 INFO     Training average loss at step 652400: 0.145103\n",
      "2022-11-08 23:38:17,390 INFO     Training average positive_sample_loss at step 652500: 0.152121\n",
      "2022-11-08 23:38:17,390 INFO     Training average negative_sample_loss at step 652500: 0.138346\n",
      "2022-11-08 23:38:17,390 INFO     Training average loss at step 652500: 0.145234\n",
      "2022-11-08 23:38:23,740 INFO     Training average positive_sample_loss at step 652600: 0.148500\n",
      "2022-11-08 23:38:23,740 INFO     Training average negative_sample_loss at step 652600: 0.142355\n",
      "2022-11-08 23:38:23,740 INFO     Training average loss at step 652600: 0.145428\n",
      "2022-11-08 23:38:31,391 INFO     Training average positive_sample_loss at step 652700: 0.150648\n",
      "2022-11-08 23:38:31,391 INFO     Training average negative_sample_loss at step 652700: 0.143916\n",
      "2022-11-08 23:38:31,391 INFO     Training average loss at step 652700: 0.147282\n",
      "2022-11-08 23:38:37,743 INFO     Training average positive_sample_loss at step 652800: 0.147421\n",
      "2022-11-08 23:38:37,743 INFO     Training average negative_sample_loss at step 652800: 0.141724\n",
      "2022-11-08 23:38:37,743 INFO     Training average loss at step 652800: 0.144573\n",
      "2022-11-08 23:38:45,478 INFO     Training average positive_sample_loss at step 652900: 0.151217\n",
      "2022-11-08 23:38:45,478 INFO     Training average negative_sample_loss at step 652900: 0.142161\n",
      "2022-11-08 23:38:45,478 INFO     Training average loss at step 652900: 0.146689\n",
      "2022-11-08 23:38:51,397 INFO     Training average positive_sample_loss at step 653000: 0.145724\n",
      "2022-11-08 23:38:51,397 INFO     Training average negative_sample_loss at step 653000: 0.141332\n",
      "2022-11-08 23:38:51,397 INFO     Training average loss at step 653000: 0.143528\n",
      "2022-11-08 23:38:56,867 INFO     Training average positive_sample_loss at step 653100: 0.149535\n",
      "2022-11-08 23:38:56,867 INFO     Training average negative_sample_loss at step 653100: 0.136488\n",
      "2022-11-08 23:38:56,867 INFO     Training average loss at step 653100: 0.143011\n",
      "2022-11-08 23:39:03,244 INFO     Training average positive_sample_loss at step 653200: 0.153582\n",
      "2022-11-08 23:39:03,244 INFO     Training average negative_sample_loss at step 653200: 0.141077\n",
      "2022-11-08 23:39:03,244 INFO     Training average loss at step 653200: 0.147330\n",
      "2022-11-08 23:39:09,613 INFO     Training average positive_sample_loss at step 653300: 0.148555\n",
      "2022-11-08 23:39:09,613 INFO     Training average negative_sample_loss at step 653300: 0.143106\n",
      "2022-11-08 23:39:09,613 INFO     Training average loss at step 653300: 0.145831\n",
      "2022-11-08 23:39:15,992 INFO     Training average positive_sample_loss at step 653400: 0.150072\n",
      "2022-11-08 23:39:15,992 INFO     Training average negative_sample_loss at step 653400: 0.137662\n",
      "2022-11-08 23:39:15,993 INFO     Training average loss at step 653400: 0.143867\n",
      "2022-11-08 23:39:22,364 INFO     Training average positive_sample_loss at step 653500: 0.151004\n",
      "2022-11-08 23:39:22,364 INFO     Training average negative_sample_loss at step 653500: 0.139751\n",
      "2022-11-08 23:39:22,364 INFO     Training average loss at step 653500: 0.145378\n",
      "2022-11-08 23:39:28,741 INFO     Training average positive_sample_loss at step 653600: 0.145257\n",
      "2022-11-08 23:39:28,741 INFO     Training average negative_sample_loss at step 653600: 0.141232\n",
      "2022-11-08 23:39:28,741 INFO     Training average loss at step 653600: 0.143244\n",
      "2022-11-08 23:39:35,099 INFO     Training average positive_sample_loss at step 653700: 0.149050\n",
      "2022-11-08 23:39:35,099 INFO     Training average negative_sample_loss at step 653700: 0.140376\n",
      "2022-11-08 23:39:35,099 INFO     Training average loss at step 653700: 0.144713\n",
      "2022-11-08 23:39:41,470 INFO     Training average positive_sample_loss at step 653800: 0.158571\n",
      "2022-11-08 23:39:41,470 INFO     Training average negative_sample_loss at step 653800: 0.143668\n",
      "2022-11-08 23:39:41,470 INFO     Training average loss at step 653800: 0.151120\n",
      "2022-11-08 23:39:47,844 INFO     Training average positive_sample_loss at step 653900: 0.149397\n",
      "2022-11-08 23:39:47,844 INFO     Training average negative_sample_loss at step 653900: 0.141642\n",
      "2022-11-08 23:39:47,844 INFO     Training average loss at step 653900: 0.145519\n",
      "2022-11-08 23:39:54,203 INFO     Training average positive_sample_loss at step 654000: 0.149466\n",
      "2022-11-08 23:39:54,203 INFO     Training average negative_sample_loss at step 654000: 0.145004\n",
      "2022-11-08 23:39:54,203 INFO     Training average loss at step 654000: 0.147235\n",
      "2022-11-08 23:40:00,555 INFO     Training average positive_sample_loss at step 654100: 0.150295\n",
      "2022-11-08 23:40:00,555 INFO     Training average negative_sample_loss at step 654100: 0.142296\n",
      "2022-11-08 23:40:00,555 INFO     Training average loss at step 654100: 0.146295\n",
      "2022-11-08 23:40:06,905 INFO     Training average positive_sample_loss at step 654200: 0.151620\n",
      "2022-11-08 23:40:06,905 INFO     Training average negative_sample_loss at step 654200: 0.142966\n",
      "2022-11-08 23:40:06,905 INFO     Training average loss at step 654200: 0.147293\n",
      "2022-11-08 23:40:13,262 INFO     Training average positive_sample_loss at step 654300: 0.149597\n",
      "2022-11-08 23:40:13,262 INFO     Training average negative_sample_loss at step 654300: 0.141468\n",
      "2022-11-08 23:40:13,262 INFO     Training average loss at step 654300: 0.145532\n",
      "2022-11-08 23:40:19,629 INFO     Training average positive_sample_loss at step 654400: 0.151666\n",
      "2022-11-08 23:40:19,630 INFO     Training average negative_sample_loss at step 654400: 0.139173\n",
      "2022-11-08 23:40:19,630 INFO     Training average loss at step 654400: 0.145420\n",
      "2022-11-08 23:40:25,990 INFO     Training average positive_sample_loss at step 654500: 0.153396\n",
      "2022-11-08 23:40:25,990 INFO     Training average negative_sample_loss at step 654500: 0.136803\n",
      "2022-11-08 23:40:25,990 INFO     Training average loss at step 654500: 0.145099\n",
      "2022-11-08 23:40:32,357 INFO     Training average positive_sample_loss at step 654600: 0.153866\n",
      "2022-11-08 23:40:32,357 INFO     Training average negative_sample_loss at step 654600: 0.146411\n",
      "2022-11-08 23:40:32,357 INFO     Training average loss at step 654600: 0.150139\n",
      "2022-11-08 23:40:38,717 INFO     Training average positive_sample_loss at step 654700: 0.150803\n",
      "2022-11-08 23:40:38,717 INFO     Training average negative_sample_loss at step 654700: 0.145416\n",
      "2022-11-08 23:40:38,717 INFO     Training average loss at step 654700: 0.148110\n",
      "2022-11-08 23:40:45,077 INFO     Training average positive_sample_loss at step 654800: 0.151558\n",
      "2022-11-08 23:40:45,077 INFO     Training average negative_sample_loss at step 654800: 0.143644\n",
      "2022-11-08 23:40:45,077 INFO     Training average loss at step 654800: 0.147601\n",
      "2022-11-08 23:40:51,465 INFO     Training average positive_sample_loss at step 654900: 0.148862\n",
      "2022-11-08 23:40:51,466 INFO     Training average negative_sample_loss at step 654900: 0.142686\n",
      "2022-11-08 23:40:51,466 INFO     Training average loss at step 654900: 0.145774\n",
      "2022-11-08 23:40:57,868 INFO     Training average positive_sample_loss at step 655000: 0.147280\n",
      "2022-11-08 23:40:57,868 INFO     Training average negative_sample_loss at step 655000: 0.139787\n",
      "2022-11-08 23:40:57,868 INFO     Training average loss at step 655000: 0.143533\n",
      "2022-11-08 23:41:04,269 INFO     Training average positive_sample_loss at step 655100: 0.154227\n",
      "2022-11-08 23:41:04,269 INFO     Training average negative_sample_loss at step 655100: 0.142030\n",
      "2022-11-08 23:41:04,270 INFO     Training average loss at step 655100: 0.148129\n",
      "2022-11-08 23:41:10,644 INFO     Training average positive_sample_loss at step 655200: 0.148370\n",
      "2022-11-08 23:41:10,644 INFO     Training average negative_sample_loss at step 655200: 0.139859\n",
      "2022-11-08 23:41:10,644 INFO     Training average loss at step 655200: 0.144115\n",
      "2022-11-08 23:41:17,046 INFO     Training average positive_sample_loss at step 655300: 0.151749\n",
      "2022-11-08 23:41:17,046 INFO     Training average negative_sample_loss at step 655300: 0.139771\n",
      "2022-11-08 23:41:17,046 INFO     Training average loss at step 655300: 0.145760\n",
      "2022-11-08 23:41:23,418 INFO     Training average positive_sample_loss at step 655400: 0.154061\n",
      "2022-11-08 23:41:23,418 INFO     Training average negative_sample_loss at step 655400: 0.143198\n",
      "2022-11-08 23:41:23,418 INFO     Training average loss at step 655400: 0.148629\n",
      "2022-11-08 23:41:29,795 INFO     Training average positive_sample_loss at step 655500: 0.151129\n",
      "2022-11-08 23:41:29,795 INFO     Training average negative_sample_loss at step 655500: 0.136803\n",
      "2022-11-08 23:41:29,795 INFO     Training average loss at step 655500: 0.143966\n",
      "2022-11-08 23:41:36,171 INFO     Training average positive_sample_loss at step 655600: 0.148946\n",
      "2022-11-08 23:41:36,172 INFO     Training average negative_sample_loss at step 655600: 0.140345\n",
      "2022-11-08 23:41:36,172 INFO     Training average loss at step 655600: 0.144645\n",
      "2022-11-08 23:41:42,539 INFO     Training average positive_sample_loss at step 655700: 0.150089\n",
      "2022-11-08 23:41:42,539 INFO     Training average negative_sample_loss at step 655700: 0.139926\n",
      "2022-11-08 23:41:42,539 INFO     Training average loss at step 655700: 0.145008\n",
      "2022-11-08 23:41:48,890 INFO     Training average positive_sample_loss at step 655800: 0.147309\n",
      "2022-11-08 23:41:48,890 INFO     Training average negative_sample_loss at step 655800: 0.139028\n",
      "2022-11-08 23:41:48,890 INFO     Training average loss at step 655800: 0.143169\n",
      "2022-11-08 23:41:55,250 INFO     Training average positive_sample_loss at step 655900: 0.150826\n",
      "2022-11-08 23:41:55,250 INFO     Training average negative_sample_loss at step 655900: 0.138468\n",
      "2022-11-08 23:41:55,250 INFO     Training average loss at step 655900: 0.144647\n",
      "2022-11-08 23:42:01,617 INFO     Training average positive_sample_loss at step 656000: 0.150068\n",
      "2022-11-08 23:42:01,617 INFO     Training average negative_sample_loss at step 656000: 0.140217\n",
      "2022-11-08 23:42:01,617 INFO     Training average loss at step 656000: 0.145143\n",
      "2022-11-08 23:42:07,981 INFO     Training average positive_sample_loss at step 656100: 0.149197\n",
      "2022-11-08 23:42:07,981 INFO     Training average negative_sample_loss at step 656100: 0.141983\n",
      "2022-11-08 23:42:07,981 INFO     Training average loss at step 656100: 0.145590\n",
      "2022-11-08 23:42:14,345 INFO     Training average positive_sample_loss at step 656200: 0.149053\n",
      "2022-11-08 23:42:14,345 INFO     Training average negative_sample_loss at step 656200: 0.140207\n",
      "2022-11-08 23:42:14,345 INFO     Training average loss at step 656200: 0.144630\n",
      "2022-11-08 23:42:20,712 INFO     Training average positive_sample_loss at step 656300: 0.149112\n",
      "2022-11-08 23:42:20,713 INFO     Training average negative_sample_loss at step 656300: 0.139779\n",
      "2022-11-08 23:42:20,713 INFO     Training average loss at step 656300: 0.144446\n",
      "2022-11-08 23:42:27,078 INFO     Training average positive_sample_loss at step 656400: 0.149681\n",
      "2022-11-08 23:42:27,078 INFO     Training average negative_sample_loss at step 656400: 0.143754\n",
      "2022-11-08 23:42:27,078 INFO     Training average loss at step 656400: 0.146718\n",
      "2022-11-08 23:42:33,433 INFO     Training average positive_sample_loss at step 656500: 0.147601\n",
      "2022-11-08 23:42:33,433 INFO     Training average negative_sample_loss at step 656500: 0.141370\n",
      "2022-11-08 23:42:33,433 INFO     Training average loss at step 656500: 0.144485\n",
      "2022-11-08 23:42:39,806 INFO     Training average positive_sample_loss at step 656600: 0.152017\n",
      "2022-11-08 23:42:39,806 INFO     Training average negative_sample_loss at step 656600: 0.141131\n",
      "2022-11-08 23:42:39,806 INFO     Training average loss at step 656600: 0.146574\n",
      "2022-11-08 23:42:46,194 INFO     Training average positive_sample_loss at step 656700: 0.153015\n",
      "2022-11-08 23:42:46,194 INFO     Training average negative_sample_loss at step 656700: 0.143105\n",
      "2022-11-08 23:42:46,194 INFO     Training average loss at step 656700: 0.148060\n",
      "2022-11-08 23:42:52,580 INFO     Training average positive_sample_loss at step 656800: 0.149680\n",
      "2022-11-08 23:42:52,580 INFO     Training average negative_sample_loss at step 656800: 0.140633\n",
      "2022-11-08 23:42:52,580 INFO     Training average loss at step 656800: 0.145156\n",
      "2022-11-08 23:42:58,964 INFO     Training average positive_sample_loss at step 656900: 0.143648\n",
      "2022-11-08 23:42:58,964 INFO     Training average negative_sample_loss at step 656900: 0.137249\n",
      "2022-11-08 23:42:58,964 INFO     Training average loss at step 656900: 0.140448\n",
      "2022-11-08 23:43:05,346 INFO     Training average positive_sample_loss at step 657000: 0.147706\n",
      "2022-11-08 23:43:05,346 INFO     Training average negative_sample_loss at step 657000: 0.139783\n",
      "2022-11-08 23:43:05,346 INFO     Training average loss at step 657000: 0.143745\n",
      "2022-11-08 23:43:11,717 INFO     Training average positive_sample_loss at step 657100: 0.149412\n",
      "2022-11-08 23:43:11,717 INFO     Training average negative_sample_loss at step 657100: 0.137865\n",
      "2022-11-08 23:43:11,717 INFO     Training average loss at step 657100: 0.143639\n",
      "2022-11-08 23:43:18,104 INFO     Training average positive_sample_loss at step 657200: 0.146921\n",
      "2022-11-08 23:43:18,104 INFO     Training average negative_sample_loss at step 657200: 0.141329\n",
      "2022-11-08 23:43:18,104 INFO     Training average loss at step 657200: 0.144125\n",
      "2022-11-08 23:43:25,845 INFO     Training average positive_sample_loss at step 657300: 0.153331\n",
      "2022-11-08 23:43:25,845 INFO     Training average negative_sample_loss at step 657300: 0.143138\n",
      "2022-11-08 23:43:25,845 INFO     Training average loss at step 657300: 0.148235\n",
      "2022-11-08 23:43:32,216 INFO     Training average positive_sample_loss at step 657400: 0.147169\n",
      "2022-11-08 23:43:32,216 INFO     Training average negative_sample_loss at step 657400: 0.138322\n",
      "2022-11-08 23:43:32,216 INFO     Training average loss at step 657400: 0.142746\n",
      "2022-11-08 23:43:40,018 INFO     Training average positive_sample_loss at step 657500: 0.147470\n",
      "2022-11-08 23:43:40,019 INFO     Training average negative_sample_loss at step 657500: 0.137432\n",
      "2022-11-08 23:43:40,019 INFO     Training average loss at step 657500: 0.142451\n",
      "2022-11-08 23:43:46,402 INFO     Training average positive_sample_loss at step 657600: 0.152230\n",
      "2022-11-08 23:43:46,402 INFO     Training average negative_sample_loss at step 657600: 0.142293\n",
      "2022-11-08 23:43:46,402 INFO     Training average loss at step 657600: 0.147262\n",
      "2022-11-08 23:43:52,782 INFO     Training average positive_sample_loss at step 657700: 0.150070\n",
      "2022-11-08 23:43:52,782 INFO     Training average negative_sample_loss at step 657700: 0.143101\n",
      "2022-11-08 23:43:52,782 INFO     Training average loss at step 657700: 0.146585\n",
      "2022-11-08 23:43:59,131 INFO     Training average positive_sample_loss at step 657800: 0.153748\n",
      "2022-11-08 23:43:59,131 INFO     Training average negative_sample_loss at step 657800: 0.141546\n",
      "2022-11-08 23:43:59,131 INFO     Training average loss at step 657800: 0.147647\n",
      "2022-11-08 23:44:05,516 INFO     Training average positive_sample_loss at step 657900: 0.152622\n",
      "2022-11-08 23:44:05,516 INFO     Training average negative_sample_loss at step 657900: 0.140763\n",
      "2022-11-08 23:44:05,516 INFO     Training average loss at step 657900: 0.146693\n",
      "2022-11-08 23:44:11,887 INFO     Training average positive_sample_loss at step 658000: 0.158008\n",
      "2022-11-08 23:44:11,888 INFO     Training average negative_sample_loss at step 658000: 0.144955\n",
      "2022-11-08 23:44:11,888 INFO     Training average loss at step 658000: 0.151481\n",
      "2022-11-08 23:44:18,273 INFO     Training average positive_sample_loss at step 658100: 0.148959\n",
      "2022-11-08 23:44:18,273 INFO     Training average negative_sample_loss at step 658100: 0.140193\n",
      "2022-11-08 23:44:18,273 INFO     Training average loss at step 658100: 0.144576\n",
      "2022-11-08 23:44:24,655 INFO     Training average positive_sample_loss at step 658200: 0.149183\n",
      "2022-11-08 23:44:24,655 INFO     Training average negative_sample_loss at step 658200: 0.141127\n",
      "2022-11-08 23:44:24,655 INFO     Training average loss at step 658200: 0.145155\n",
      "2022-11-08 23:44:31,070 INFO     Training average positive_sample_loss at step 658300: 0.152618\n",
      "2022-11-08 23:44:31,070 INFO     Training average negative_sample_loss at step 658300: 0.144005\n",
      "2022-11-08 23:44:31,070 INFO     Training average loss at step 658300: 0.148311\n",
      "2022-11-08 23:44:37,434 INFO     Training average positive_sample_loss at step 658400: 0.150104\n",
      "2022-11-08 23:44:37,434 INFO     Training average negative_sample_loss at step 658400: 0.143345\n",
      "2022-11-08 23:44:37,434 INFO     Training average loss at step 658400: 0.146724\n",
      "2022-11-08 23:44:43,779 INFO     Training average positive_sample_loss at step 658500: 0.149917\n",
      "2022-11-08 23:44:43,779 INFO     Training average negative_sample_loss at step 658500: 0.141692\n",
      "2022-11-08 23:44:43,779 INFO     Training average loss at step 658500: 0.145805\n",
      "2022-11-08 23:44:50,146 INFO     Training average positive_sample_loss at step 658600: 0.145108\n",
      "2022-11-08 23:44:50,146 INFO     Training average negative_sample_loss at step 658600: 0.138972\n",
      "2022-11-08 23:44:50,146 INFO     Training average loss at step 658600: 0.142040\n",
      "2022-11-08 23:44:55,130 INFO     Training average positive_sample_loss at step 658700: 0.149234\n",
      "2022-11-08 23:44:55,131 INFO     Training average negative_sample_loss at step 658700: 0.135349\n",
      "2022-11-08 23:44:55,131 INFO     Training average loss at step 658700: 0.142291\n",
      "2022-11-08 23:45:01,508 INFO     Training average positive_sample_loss at step 658800: 0.149614\n",
      "2022-11-08 23:45:01,509 INFO     Training average negative_sample_loss at step 658800: 0.140528\n",
      "2022-11-08 23:45:01,509 INFO     Training average loss at step 658800: 0.145071\n",
      "2022-11-08 23:45:07,861 INFO     Training average positive_sample_loss at step 658900: 0.147413\n",
      "2022-11-08 23:45:07,862 INFO     Training average negative_sample_loss at step 658900: 0.140521\n",
      "2022-11-08 23:45:07,862 INFO     Training average loss at step 658900: 0.143967\n",
      "2022-11-08 23:45:14,219 INFO     Training average positive_sample_loss at step 659000: 0.151458\n",
      "2022-11-08 23:45:14,219 INFO     Training average negative_sample_loss at step 659000: 0.146945\n",
      "2022-11-08 23:45:14,219 INFO     Training average loss at step 659000: 0.149201\n",
      "2022-11-08 23:45:20,577 INFO     Training average positive_sample_loss at step 659100: 0.149415\n",
      "2022-11-08 23:45:20,577 INFO     Training average negative_sample_loss at step 659100: 0.141257\n",
      "2022-11-08 23:45:20,577 INFO     Training average loss at step 659100: 0.145336\n",
      "2022-11-08 23:45:26,955 INFO     Training average positive_sample_loss at step 659200: 0.147121\n",
      "2022-11-08 23:45:26,956 INFO     Training average negative_sample_loss at step 659200: 0.141416\n",
      "2022-11-08 23:45:26,956 INFO     Training average loss at step 659200: 0.144269\n",
      "2022-11-08 23:45:33,351 INFO     Training average positive_sample_loss at step 659300: 0.150498\n",
      "2022-11-08 23:45:33,351 INFO     Training average negative_sample_loss at step 659300: 0.141979\n",
      "2022-11-08 23:45:33,351 INFO     Training average loss at step 659300: 0.146239\n",
      "2022-11-08 23:45:39,720 INFO     Training average positive_sample_loss at step 659400: 0.153824\n",
      "2022-11-08 23:45:39,720 INFO     Training average negative_sample_loss at step 659400: 0.139605\n",
      "2022-11-08 23:45:39,720 INFO     Training average loss at step 659400: 0.146715\n",
      "2022-11-08 23:45:46,079 INFO     Training average positive_sample_loss at step 659500: 0.146929\n",
      "2022-11-08 23:45:46,079 INFO     Training average negative_sample_loss at step 659500: 0.140939\n",
      "2022-11-08 23:45:46,079 INFO     Training average loss at step 659500: 0.143934\n",
      "2022-11-08 23:45:52,445 INFO     Training average positive_sample_loss at step 659600: 0.146759\n",
      "2022-11-08 23:45:52,445 INFO     Training average negative_sample_loss at step 659600: 0.143150\n",
      "2022-11-08 23:45:52,445 INFO     Training average loss at step 659600: 0.144955\n",
      "2022-11-08 23:45:58,798 INFO     Training average positive_sample_loss at step 659700: 0.148230\n",
      "2022-11-08 23:45:58,798 INFO     Training average negative_sample_loss at step 659700: 0.140659\n",
      "2022-11-08 23:45:58,798 INFO     Training average loss at step 659700: 0.144445\n",
      "2022-11-08 23:46:05,166 INFO     Training average positive_sample_loss at step 659800: 0.150803\n",
      "2022-11-08 23:46:05,167 INFO     Training average negative_sample_loss at step 659800: 0.144923\n",
      "2022-11-08 23:46:05,167 INFO     Training average loss at step 659800: 0.147863\n",
      "2022-11-08 23:46:11,547 INFO     Training average positive_sample_loss at step 659900: 0.148360\n",
      "2022-11-08 23:46:11,547 INFO     Training average negative_sample_loss at step 659900: 0.140986\n",
      "2022-11-08 23:46:11,547 INFO     Training average loss at step 659900: 0.144673\n",
      "2022-11-08 23:46:20,849 INFO     Training average positive_sample_loss at step 660000: 0.149682\n",
      "2022-11-08 23:46:20,850 INFO     Training average negative_sample_loss at step 660000: 0.142756\n",
      "2022-11-08 23:46:20,850 INFO     Training average loss at step 660000: 0.146219\n",
      "2022-11-08 23:46:27,203 INFO     Training average positive_sample_loss at step 660100: 0.155336\n",
      "2022-11-08 23:46:27,203 INFO     Training average negative_sample_loss at step 660100: 0.143434\n",
      "2022-11-08 23:46:27,203 INFO     Training average loss at step 660100: 0.149385\n",
      "2022-11-08 23:46:33,556 INFO     Training average positive_sample_loss at step 660200: 0.146498\n",
      "2022-11-08 23:46:33,556 INFO     Training average negative_sample_loss at step 660200: 0.139874\n",
      "2022-11-08 23:46:33,556 INFO     Training average loss at step 660200: 0.143186\n",
      "2022-11-08 23:46:39,900 INFO     Training average positive_sample_loss at step 660300: 0.156947\n",
      "2022-11-08 23:46:39,900 INFO     Training average negative_sample_loss at step 660300: 0.137532\n",
      "2022-11-08 23:46:39,900 INFO     Training average loss at step 660300: 0.147239\n",
      "2022-11-08 23:46:46,269 INFO     Training average positive_sample_loss at step 660400: 0.152031\n",
      "2022-11-08 23:46:46,269 INFO     Training average negative_sample_loss at step 660400: 0.138244\n",
      "2022-11-08 23:46:46,269 INFO     Training average loss at step 660400: 0.145137\n",
      "2022-11-08 23:46:52,646 INFO     Training average positive_sample_loss at step 660500: 0.149141\n",
      "2022-11-08 23:46:52,646 INFO     Training average negative_sample_loss at step 660500: 0.139658\n",
      "2022-11-08 23:46:52,646 INFO     Training average loss at step 660500: 0.144399\n",
      "2022-11-08 23:46:59,000 INFO     Training average positive_sample_loss at step 660600: 0.152854\n",
      "2022-11-08 23:46:59,000 INFO     Training average negative_sample_loss at step 660600: 0.139042\n",
      "2022-11-08 23:46:59,000 INFO     Training average loss at step 660600: 0.145948\n",
      "2022-11-08 23:47:05,376 INFO     Training average positive_sample_loss at step 660700: 0.150511\n",
      "2022-11-08 23:47:05,376 INFO     Training average negative_sample_loss at step 660700: 0.143649\n",
      "2022-11-08 23:47:05,376 INFO     Training average loss at step 660700: 0.147080\n",
      "2022-11-08 23:47:11,739 INFO     Training average positive_sample_loss at step 660800: 0.149042\n",
      "2022-11-08 23:47:11,739 INFO     Training average negative_sample_loss at step 660800: 0.142759\n",
      "2022-11-08 23:47:11,739 INFO     Training average loss at step 660800: 0.145901\n",
      "2022-11-08 23:47:18,115 INFO     Training average positive_sample_loss at step 660900: 0.144010\n",
      "2022-11-08 23:47:18,116 INFO     Training average negative_sample_loss at step 660900: 0.139184\n",
      "2022-11-08 23:47:18,116 INFO     Training average loss at step 660900: 0.141597\n",
      "2022-11-08 23:47:24,518 INFO     Training average positive_sample_loss at step 661000: 0.151407\n",
      "2022-11-08 23:47:24,518 INFO     Training average negative_sample_loss at step 661000: 0.139292\n",
      "2022-11-08 23:47:24,518 INFO     Training average loss at step 661000: 0.145350\n",
      "2022-11-08 23:47:30,910 INFO     Training average positive_sample_loss at step 661100: 0.147671\n",
      "2022-11-08 23:47:30,911 INFO     Training average negative_sample_loss at step 661100: 0.143467\n",
      "2022-11-08 23:47:30,911 INFO     Training average loss at step 661100: 0.145569\n",
      "2022-11-08 23:47:37,293 INFO     Training average positive_sample_loss at step 661200: 0.153125\n",
      "2022-11-08 23:47:37,293 INFO     Training average negative_sample_loss at step 661200: 0.144863\n",
      "2022-11-08 23:47:37,293 INFO     Training average loss at step 661200: 0.148994\n",
      "2022-11-08 23:47:43,668 INFO     Training average positive_sample_loss at step 661300: 0.153117\n",
      "2022-11-08 23:47:43,668 INFO     Training average negative_sample_loss at step 661300: 0.146652\n",
      "2022-11-08 23:47:43,668 INFO     Training average loss at step 661300: 0.149884\n",
      "2022-11-08 23:47:50,051 INFO     Training average positive_sample_loss at step 661400: 0.153047\n",
      "2022-11-08 23:47:50,051 INFO     Training average negative_sample_loss at step 661400: 0.142214\n",
      "2022-11-08 23:47:50,051 INFO     Training average loss at step 661400: 0.147630\n",
      "2022-11-08 23:47:56,440 INFO     Training average positive_sample_loss at step 661500: 0.153279\n",
      "2022-11-08 23:47:56,440 INFO     Training average negative_sample_loss at step 661500: 0.142326\n",
      "2022-11-08 23:47:56,440 INFO     Training average loss at step 661500: 0.147803\n",
      "2022-11-08 23:48:02,844 INFO     Training average positive_sample_loss at step 661600: 0.145056\n",
      "2022-11-08 23:48:02,844 INFO     Training average negative_sample_loss at step 661600: 0.139169\n",
      "2022-11-08 23:48:02,844 INFO     Training average loss at step 661600: 0.142112\n",
      "2022-11-08 23:48:09,220 INFO     Training average positive_sample_loss at step 661700: 0.148710\n",
      "2022-11-08 23:48:09,220 INFO     Training average negative_sample_loss at step 661700: 0.142725\n",
      "2022-11-08 23:48:09,220 INFO     Training average loss at step 661700: 0.145718\n",
      "2022-11-08 23:48:15,630 INFO     Training average positive_sample_loss at step 661800: 0.151710\n",
      "2022-11-08 23:48:15,630 INFO     Training average negative_sample_loss at step 661800: 0.140256\n",
      "2022-11-08 23:48:15,630 INFO     Training average loss at step 661800: 0.145983\n",
      "2022-11-08 23:48:22,048 INFO     Training average positive_sample_loss at step 661900: 0.148182\n",
      "2022-11-08 23:48:22,048 INFO     Training average negative_sample_loss at step 661900: 0.139673\n",
      "2022-11-08 23:48:22,048 INFO     Training average loss at step 661900: 0.143928\n",
      "2022-11-08 23:48:29,715 INFO     Training average positive_sample_loss at step 662000: 0.154409\n",
      "2022-11-08 23:48:29,715 INFO     Training average negative_sample_loss at step 662000: 0.140383\n",
      "2022-11-08 23:48:29,715 INFO     Training average loss at step 662000: 0.147396\n",
      "2022-11-08 23:48:36,095 INFO     Training average positive_sample_loss at step 662100: 0.153490\n",
      "2022-11-08 23:48:36,095 INFO     Training average negative_sample_loss at step 662100: 0.139977\n",
      "2022-11-08 23:48:36,095 INFO     Training average loss at step 662100: 0.146734\n",
      "2022-11-08 23:48:43,927 INFO     Training average positive_sample_loss at step 662200: 0.149469\n",
      "2022-11-08 23:48:43,927 INFO     Training average negative_sample_loss at step 662200: 0.140798\n",
      "2022-11-08 23:48:43,927 INFO     Training average loss at step 662200: 0.145133\n",
      "2022-11-08 23:48:50,315 INFO     Training average positive_sample_loss at step 662300: 0.153375\n",
      "2022-11-08 23:48:50,315 INFO     Training average negative_sample_loss at step 662300: 0.142008\n",
      "2022-11-08 23:48:50,315 INFO     Training average loss at step 662300: 0.147691\n",
      "2022-11-08 23:48:56,711 INFO     Training average positive_sample_loss at step 662400: 0.148092\n",
      "2022-11-08 23:48:56,711 INFO     Training average negative_sample_loss at step 662400: 0.143924\n",
      "2022-11-08 23:48:56,711 INFO     Training average loss at step 662400: 0.146008\n",
      "2022-11-08 23:49:03,082 INFO     Training average positive_sample_loss at step 662500: 0.147872\n",
      "2022-11-08 23:49:03,082 INFO     Training average negative_sample_loss at step 662500: 0.142915\n",
      "2022-11-08 23:49:03,082 INFO     Training average loss at step 662500: 0.145394\n",
      "2022-11-08 23:49:09,432 INFO     Training average positive_sample_loss at step 662600: 0.146655\n",
      "2022-11-08 23:49:09,432 INFO     Training average negative_sample_loss at step 662600: 0.138825\n",
      "2022-11-08 23:49:09,432 INFO     Training average loss at step 662600: 0.142740\n",
      "2022-11-08 23:49:15,817 INFO     Training average positive_sample_loss at step 662700: 0.153017\n",
      "2022-11-08 23:49:15,817 INFO     Training average negative_sample_loss at step 662700: 0.137661\n",
      "2022-11-08 23:49:15,817 INFO     Training average loss at step 662700: 0.145339\n",
      "2022-11-08 23:49:22,202 INFO     Training average positive_sample_loss at step 662800: 0.153024\n",
      "2022-11-08 23:49:22,202 INFO     Training average negative_sample_loss at step 662800: 0.141730\n",
      "2022-11-08 23:49:22,202 INFO     Training average loss at step 662800: 0.147377\n",
      "2022-11-08 23:49:28,569 INFO     Training average positive_sample_loss at step 662900: 0.154158\n",
      "2022-11-08 23:49:28,569 INFO     Training average negative_sample_loss at step 662900: 0.144824\n",
      "2022-11-08 23:49:28,569 INFO     Training average loss at step 662900: 0.149491\n",
      "2022-11-08 23:49:34,940 INFO     Training average positive_sample_loss at step 663000: 0.150475\n",
      "2022-11-08 23:49:34,940 INFO     Training average negative_sample_loss at step 663000: 0.142806\n",
      "2022-11-08 23:49:34,940 INFO     Training average loss at step 663000: 0.146641\n",
      "2022-11-08 23:49:41,295 INFO     Training average positive_sample_loss at step 663100: 0.150723\n",
      "2022-11-08 23:49:41,295 INFO     Training average negative_sample_loss at step 663100: 0.140634\n",
      "2022-11-08 23:49:41,295 INFO     Training average loss at step 663100: 0.145679\n",
      "2022-11-08 23:49:47,672 INFO     Training average positive_sample_loss at step 663200: 0.150211\n",
      "2022-11-08 23:49:47,673 INFO     Training average negative_sample_loss at step 663200: 0.140269\n",
      "2022-11-08 23:49:47,673 INFO     Training average loss at step 663200: 0.145240\n",
      "2022-11-08 23:49:54,041 INFO     Training average positive_sample_loss at step 663300: 0.148424\n",
      "2022-11-08 23:49:54,041 INFO     Training average negative_sample_loss at step 663300: 0.145406\n",
      "2022-11-08 23:49:54,041 INFO     Training average loss at step 663300: 0.146915\n",
      "2022-11-08 23:50:00,435 INFO     Training average positive_sample_loss at step 663400: 0.151702\n",
      "2022-11-08 23:50:00,435 INFO     Training average negative_sample_loss at step 663400: 0.146423\n",
      "2022-11-08 23:50:00,435 INFO     Training average loss at step 663400: 0.149062\n",
      "2022-11-08 23:50:06,794 INFO     Training average positive_sample_loss at step 663500: 0.155908\n",
      "2022-11-08 23:50:06,795 INFO     Training average negative_sample_loss at step 663500: 0.137586\n",
      "2022-11-08 23:50:06,795 INFO     Training average loss at step 663500: 0.146747\n",
      "2022-11-08 23:50:13,147 INFO     Training average positive_sample_loss at step 663600: 0.150447\n",
      "2022-11-08 23:50:13,147 INFO     Training average negative_sample_loss at step 663600: 0.139504\n",
      "2022-11-08 23:50:13,147 INFO     Training average loss at step 663600: 0.144975\n",
      "2022-11-08 23:50:19,523 INFO     Training average positive_sample_loss at step 663700: 0.153571\n",
      "2022-11-08 23:50:19,524 INFO     Training average negative_sample_loss at step 663700: 0.139932\n",
      "2022-11-08 23:50:19,524 INFO     Training average loss at step 663700: 0.146752\n",
      "2022-11-08 23:50:25,890 INFO     Training average positive_sample_loss at step 663800: 0.153453\n",
      "2022-11-08 23:50:25,891 INFO     Training average negative_sample_loss at step 663800: 0.142025\n",
      "2022-11-08 23:50:25,891 INFO     Training average loss at step 663800: 0.147739\n",
      "2022-11-08 23:50:32,276 INFO     Training average positive_sample_loss at step 663900: 0.149739\n",
      "2022-11-08 23:50:32,276 INFO     Training average negative_sample_loss at step 663900: 0.138924\n",
      "2022-11-08 23:50:32,276 INFO     Training average loss at step 663900: 0.144332\n",
      "2022-11-08 23:50:38,681 INFO     Training average positive_sample_loss at step 664000: 0.146417\n",
      "2022-11-08 23:50:38,681 INFO     Training average negative_sample_loss at step 664000: 0.138713\n",
      "2022-11-08 23:50:38,681 INFO     Training average loss at step 664000: 0.142565\n",
      "2022-11-08 23:50:45,047 INFO     Training average positive_sample_loss at step 664100: 0.151596\n",
      "2022-11-08 23:50:45,048 INFO     Training average negative_sample_loss at step 664100: 0.139073\n",
      "2022-11-08 23:50:45,048 INFO     Training average loss at step 664100: 0.145334\n",
      "2022-11-08 23:50:50,078 INFO     Training average positive_sample_loss at step 664200: 0.148980\n",
      "2022-11-08 23:50:50,078 INFO     Training average negative_sample_loss at step 664200: 0.141694\n",
      "2022-11-08 23:50:50,078 INFO     Training average loss at step 664200: 0.145337\n",
      "2022-11-08 23:50:56,481 INFO     Training average positive_sample_loss at step 664300: 0.152962\n",
      "2022-11-08 23:50:56,481 INFO     Training average negative_sample_loss at step 664300: 0.139927\n",
      "2022-11-08 23:50:56,481 INFO     Training average loss at step 664300: 0.146444\n",
      "2022-11-08 23:51:02,852 INFO     Training average positive_sample_loss at step 664400: 0.154716\n",
      "2022-11-08 23:51:02,852 INFO     Training average negative_sample_loss at step 664400: 0.141307\n",
      "2022-11-08 23:51:02,852 INFO     Training average loss at step 664400: 0.148011\n",
      "2022-11-08 23:51:09,228 INFO     Training average positive_sample_loss at step 664500: 0.149058\n",
      "2022-11-08 23:51:09,228 INFO     Training average negative_sample_loss at step 664500: 0.137866\n",
      "2022-11-08 23:51:09,228 INFO     Training average loss at step 664500: 0.143462\n",
      "2022-11-08 23:51:15,596 INFO     Training average positive_sample_loss at step 664600: 0.151782\n",
      "2022-11-08 23:51:15,597 INFO     Training average negative_sample_loss at step 664600: 0.141385\n",
      "2022-11-08 23:51:15,597 INFO     Training average loss at step 664600: 0.146584\n",
      "2022-11-08 23:51:21,955 INFO     Training average positive_sample_loss at step 664700: 0.157697\n",
      "2022-11-08 23:51:21,955 INFO     Training average negative_sample_loss at step 664700: 0.141307\n",
      "2022-11-08 23:51:21,955 INFO     Training average loss at step 664700: 0.149502\n",
      "2022-11-08 23:51:28,338 INFO     Training average positive_sample_loss at step 664800: 0.149041\n",
      "2022-11-08 23:51:28,338 INFO     Training average negative_sample_loss at step 664800: 0.144913\n",
      "2022-11-08 23:51:28,338 INFO     Training average loss at step 664800: 0.146977\n",
      "2022-11-08 23:51:34,712 INFO     Training average positive_sample_loss at step 664900: 0.148393\n",
      "2022-11-08 23:51:34,712 INFO     Training average negative_sample_loss at step 664900: 0.138801\n",
      "2022-11-08 23:51:34,712 INFO     Training average loss at step 664900: 0.143597\n",
      "2022-11-08 23:51:41,098 INFO     Training average positive_sample_loss at step 665000: 0.148859\n",
      "2022-11-08 23:51:41,098 INFO     Training average negative_sample_loss at step 665000: 0.142519\n",
      "2022-11-08 23:51:41,098 INFO     Training average loss at step 665000: 0.145689\n",
      "2022-11-08 23:51:47,485 INFO     Training average positive_sample_loss at step 665100: 0.147873\n",
      "2022-11-08 23:51:47,485 INFO     Training average negative_sample_loss at step 665100: 0.141670\n",
      "2022-11-08 23:51:47,485 INFO     Training average loss at step 665100: 0.144772\n",
      "2022-11-08 23:51:53,876 INFO     Training average positive_sample_loss at step 665200: 0.146595\n",
      "2022-11-08 23:51:53,876 INFO     Training average negative_sample_loss at step 665200: 0.141770\n",
      "2022-11-08 23:51:53,876 INFO     Training average loss at step 665200: 0.144183\n",
      "2022-11-08 23:52:00,269 INFO     Training average positive_sample_loss at step 665300: 0.151453\n",
      "2022-11-08 23:52:00,269 INFO     Training average negative_sample_loss at step 665300: 0.143123\n",
      "2022-11-08 23:52:00,269 INFO     Training average loss at step 665300: 0.147288\n",
      "2022-11-08 23:52:06,635 INFO     Training average positive_sample_loss at step 665400: 0.152774\n",
      "2022-11-08 23:52:06,635 INFO     Training average negative_sample_loss at step 665400: 0.144618\n",
      "2022-11-08 23:52:06,635 INFO     Training average loss at step 665400: 0.148696\n",
      "2022-11-08 23:52:13,014 INFO     Training average positive_sample_loss at step 665500: 0.147746\n",
      "2022-11-08 23:52:13,014 INFO     Training average negative_sample_loss at step 665500: 0.138011\n",
      "2022-11-08 23:52:13,014 INFO     Training average loss at step 665500: 0.142879\n",
      "2022-11-08 23:52:19,399 INFO     Training average positive_sample_loss at step 665600: 0.149728\n",
      "2022-11-08 23:52:19,399 INFO     Training average negative_sample_loss at step 665600: 0.140791\n",
      "2022-11-08 23:52:19,399 INFO     Training average loss at step 665600: 0.145260\n",
      "2022-11-08 23:52:25,782 INFO     Training average positive_sample_loss at step 665700: 0.149842\n",
      "2022-11-08 23:52:25,782 INFO     Training average negative_sample_loss at step 665700: 0.139090\n",
      "2022-11-08 23:52:25,782 INFO     Training average loss at step 665700: 0.144466\n",
      "2022-11-08 23:52:32,153 INFO     Training average positive_sample_loss at step 665800: 0.153013\n",
      "2022-11-08 23:52:32,153 INFO     Training average negative_sample_loss at step 665800: 0.142513\n",
      "2022-11-08 23:52:32,153 INFO     Training average loss at step 665800: 0.147763\n",
      "2022-11-08 23:52:38,547 INFO     Training average positive_sample_loss at step 665900: 0.148941\n",
      "2022-11-08 23:52:38,547 INFO     Training average negative_sample_loss at step 665900: 0.138820\n",
      "2022-11-08 23:52:38,547 INFO     Training average loss at step 665900: 0.143881\n",
      "2022-11-08 23:52:44,917 INFO     Training average positive_sample_loss at step 666000: 0.155685\n",
      "2022-11-08 23:52:44,917 INFO     Training average negative_sample_loss at step 666000: 0.142840\n",
      "2022-11-08 23:52:44,917 INFO     Training average loss at step 666000: 0.149262\n",
      "2022-11-08 23:52:51,289 INFO     Training average positive_sample_loss at step 666100: 0.149021\n",
      "2022-11-08 23:52:51,289 INFO     Training average negative_sample_loss at step 666100: 0.138586\n",
      "2022-11-08 23:52:51,289 INFO     Training average loss at step 666100: 0.143804\n",
      "2022-11-08 23:52:57,707 INFO     Training average positive_sample_loss at step 666200: 0.149898\n",
      "2022-11-08 23:52:57,707 INFO     Training average negative_sample_loss at step 666200: 0.143385\n",
      "2022-11-08 23:52:57,707 INFO     Training average loss at step 666200: 0.146641\n",
      "2022-11-08 23:53:04,114 INFO     Training average positive_sample_loss at step 666300: 0.145727\n",
      "2022-11-08 23:53:04,114 INFO     Training average negative_sample_loss at step 666300: 0.143290\n",
      "2022-11-08 23:53:04,114 INFO     Training average loss at step 666300: 0.144509\n",
      "2022-11-08 23:53:10,497 INFO     Training average positive_sample_loss at step 666400: 0.144005\n",
      "2022-11-08 23:53:10,497 INFO     Training average negative_sample_loss at step 666400: 0.137746\n",
      "2022-11-08 23:53:10,497 INFO     Training average loss at step 666400: 0.140875\n",
      "2022-11-08 23:53:16,876 INFO     Training average positive_sample_loss at step 666500: 0.151053\n",
      "2022-11-08 23:53:16,877 INFO     Training average negative_sample_loss at step 666500: 0.140851\n",
      "2022-11-08 23:53:16,877 INFO     Training average loss at step 666500: 0.145952\n",
      "2022-11-08 23:53:23,258 INFO     Training average positive_sample_loss at step 666600: 0.148521\n",
      "2022-11-08 23:53:23,259 INFO     Training average negative_sample_loss at step 666600: 0.143049\n",
      "2022-11-08 23:53:23,259 INFO     Training average loss at step 666600: 0.145785\n",
      "2022-11-08 23:53:31,041 INFO     Training average positive_sample_loss at step 666700: 0.149056\n",
      "2022-11-08 23:53:31,041 INFO     Training average negative_sample_loss at step 666700: 0.142263\n",
      "2022-11-08 23:53:31,041 INFO     Training average loss at step 666700: 0.145660\n",
      "2022-11-08 23:53:37,433 INFO     Training average positive_sample_loss at step 666800: 0.154572\n",
      "2022-11-08 23:53:37,433 INFO     Training average negative_sample_loss at step 666800: 0.139281\n",
      "2022-11-08 23:53:37,433 INFO     Training average loss at step 666800: 0.146926\n",
      "2022-11-08 23:53:45,306 INFO     Training average positive_sample_loss at step 666900: 0.151848\n",
      "2022-11-08 23:53:45,307 INFO     Training average negative_sample_loss at step 666900: 0.140497\n",
      "2022-11-08 23:53:45,307 INFO     Training average loss at step 666900: 0.146173\n",
      "2022-11-08 23:53:51,676 INFO     Training average positive_sample_loss at step 667000: 0.153225\n",
      "2022-11-08 23:53:51,676 INFO     Training average negative_sample_loss at step 667000: 0.143616\n",
      "2022-11-08 23:53:51,676 INFO     Training average loss at step 667000: 0.148421\n",
      "2022-11-08 23:53:58,061 INFO     Training average positive_sample_loss at step 667100: 0.149630\n",
      "2022-11-08 23:53:58,061 INFO     Training average negative_sample_loss at step 667100: 0.136835\n",
      "2022-11-08 23:53:58,061 INFO     Training average loss at step 667100: 0.143232\n",
      "2022-11-08 23:54:04,457 INFO     Training average positive_sample_loss at step 667200: 0.150254\n",
      "2022-11-08 23:54:04,457 INFO     Training average negative_sample_loss at step 667200: 0.141848\n",
      "2022-11-08 23:54:04,457 INFO     Training average loss at step 667200: 0.146051\n",
      "2022-11-08 23:54:10,856 INFO     Training average positive_sample_loss at step 667300: 0.146336\n",
      "2022-11-08 23:54:10,856 INFO     Training average negative_sample_loss at step 667300: 0.139533\n",
      "2022-11-08 23:54:10,856 INFO     Training average loss at step 667300: 0.142934\n",
      "2022-11-08 23:54:17,225 INFO     Training average positive_sample_loss at step 667400: 0.146361\n",
      "2022-11-08 23:54:17,225 INFO     Training average negative_sample_loss at step 667400: 0.140919\n",
      "2022-11-08 23:54:17,225 INFO     Training average loss at step 667400: 0.143640\n",
      "2022-11-08 23:54:23,579 INFO     Training average positive_sample_loss at step 667500: 0.149092\n",
      "2022-11-08 23:54:23,579 INFO     Training average negative_sample_loss at step 667500: 0.141062\n",
      "2022-11-08 23:54:23,579 INFO     Training average loss at step 667500: 0.145077\n",
      "2022-11-08 23:54:29,921 INFO     Training average positive_sample_loss at step 667600: 0.154773\n",
      "2022-11-08 23:54:29,921 INFO     Training average negative_sample_loss at step 667600: 0.143797\n",
      "2022-11-08 23:54:29,921 INFO     Training average loss at step 667600: 0.149285\n",
      "2022-11-08 23:54:36,268 INFO     Training average positive_sample_loss at step 667700: 0.148962\n",
      "2022-11-08 23:54:36,268 INFO     Training average negative_sample_loss at step 667700: 0.145558\n",
      "2022-11-08 23:54:36,268 INFO     Training average loss at step 667700: 0.147260\n",
      "2022-11-08 23:54:42,609 INFO     Training average positive_sample_loss at step 667800: 0.159190\n",
      "2022-11-08 23:54:42,609 INFO     Training average negative_sample_loss at step 667800: 0.142884\n",
      "2022-11-08 23:54:42,609 INFO     Training average loss at step 667800: 0.151037\n",
      "2022-11-08 23:54:48,971 INFO     Training average positive_sample_loss at step 667900: 0.149512\n",
      "2022-11-08 23:54:48,972 INFO     Training average negative_sample_loss at step 667900: 0.140551\n",
      "2022-11-08 23:54:48,972 INFO     Training average loss at step 667900: 0.145031\n",
      "2022-11-08 23:54:55,341 INFO     Training average positive_sample_loss at step 668000: 0.154485\n",
      "2022-11-08 23:54:55,341 INFO     Training average negative_sample_loss at step 668000: 0.141867\n",
      "2022-11-08 23:54:55,341 INFO     Training average loss at step 668000: 0.148176\n",
      "2022-11-08 23:55:01,703 INFO     Training average positive_sample_loss at step 668100: 0.151998\n",
      "2022-11-08 23:55:01,703 INFO     Training average negative_sample_loss at step 668100: 0.142772\n",
      "2022-11-08 23:55:01,703 INFO     Training average loss at step 668100: 0.147385\n",
      "2022-11-08 23:55:08,086 INFO     Training average positive_sample_loss at step 668200: 0.153313\n",
      "2022-11-08 23:55:08,086 INFO     Training average negative_sample_loss at step 668200: 0.137811\n",
      "2022-11-08 23:55:08,086 INFO     Training average loss at step 668200: 0.145562\n",
      "2022-11-08 23:55:14,464 INFO     Training average positive_sample_loss at step 668300: 0.150026\n",
      "2022-11-08 23:55:14,464 INFO     Training average negative_sample_loss at step 668300: 0.135850\n",
      "2022-11-08 23:55:14,464 INFO     Training average loss at step 668300: 0.142938\n",
      "2022-11-08 23:55:20,848 INFO     Training average positive_sample_loss at step 668400: 0.152447\n",
      "2022-11-08 23:55:20,848 INFO     Training average negative_sample_loss at step 668400: 0.143343\n",
      "2022-11-08 23:55:20,848 INFO     Training average loss at step 668400: 0.147895\n",
      "2022-11-08 23:55:27,218 INFO     Training average positive_sample_loss at step 668500: 0.156617\n",
      "2022-11-08 23:55:27,218 INFO     Training average negative_sample_loss at step 668500: 0.141952\n",
      "2022-11-08 23:55:27,218 INFO     Training average loss at step 668500: 0.149285\n",
      "2022-11-08 23:55:33,595 INFO     Training average positive_sample_loss at step 668600: 0.152342\n",
      "2022-11-08 23:55:33,596 INFO     Training average negative_sample_loss at step 668600: 0.144035\n",
      "2022-11-08 23:55:33,596 INFO     Training average loss at step 668600: 0.148189\n",
      "2022-11-08 23:55:39,979 INFO     Training average positive_sample_loss at step 668700: 0.151407\n",
      "2022-11-08 23:55:39,979 INFO     Training average negative_sample_loss at step 668700: 0.140661\n",
      "2022-11-08 23:55:39,979 INFO     Training average loss at step 668700: 0.146034\n",
      "2022-11-08 23:55:46,369 INFO     Training average positive_sample_loss at step 668800: 0.151033\n",
      "2022-11-08 23:55:46,369 INFO     Training average negative_sample_loss at step 668800: 0.143686\n",
      "2022-11-08 23:55:46,369 INFO     Training average loss at step 668800: 0.147359\n",
      "2022-11-08 23:55:52,750 INFO     Training average positive_sample_loss at step 668900: 0.145848\n",
      "2022-11-08 23:55:52,750 INFO     Training average negative_sample_loss at step 668900: 0.141175\n",
      "2022-11-08 23:55:52,750 INFO     Training average loss at step 668900: 0.143512\n",
      "2022-11-08 23:55:59,142 INFO     Training average positive_sample_loss at step 669000: 0.150794\n",
      "2022-11-08 23:55:59,142 INFO     Training average negative_sample_loss at step 669000: 0.142494\n",
      "2022-11-08 23:55:59,142 INFO     Training average loss at step 669000: 0.146644\n",
      "2022-11-08 23:56:05,508 INFO     Training average positive_sample_loss at step 669100: 0.151785\n",
      "2022-11-08 23:56:05,508 INFO     Training average negative_sample_loss at step 669100: 0.145944\n",
      "2022-11-08 23:56:05,508 INFO     Training average loss at step 669100: 0.148864\n",
      "2022-11-08 23:56:11,870 INFO     Training average positive_sample_loss at step 669200: 0.145547\n",
      "2022-11-08 23:56:11,870 INFO     Training average negative_sample_loss at step 669200: 0.139506\n",
      "2022-11-08 23:56:11,870 INFO     Training average loss at step 669200: 0.142526\n",
      "2022-11-08 23:56:17,341 INFO     Training average positive_sample_loss at step 669300: 0.148125\n",
      "2022-11-08 23:56:17,341 INFO     Training average negative_sample_loss at step 669300: 0.142856\n",
      "2022-11-08 23:56:17,341 INFO     Training average loss at step 669300: 0.145490\n",
      "2022-11-08 23:56:21,444 INFO     Training average positive_sample_loss at step 669400: 0.158151\n",
      "2022-11-08 23:56:21,444 INFO     Training average negative_sample_loss at step 669400: 0.141236\n",
      "2022-11-08 23:56:21,444 INFO     Training average loss at step 669400: 0.149693\n",
      "2022-11-08 23:56:27,806 INFO     Training average positive_sample_loss at step 669500: 0.147624\n",
      "2022-11-08 23:56:27,806 INFO     Training average negative_sample_loss at step 669500: 0.143363\n",
      "2022-11-08 23:56:27,806 INFO     Training average loss at step 669500: 0.145493\n",
      "2022-11-08 23:56:34,165 INFO     Training average positive_sample_loss at step 669600: 0.149148\n",
      "2022-11-08 23:56:34,165 INFO     Training average negative_sample_loss at step 669600: 0.145788\n",
      "2022-11-08 23:56:34,165 INFO     Training average loss at step 669600: 0.147468\n",
      "2022-11-08 23:56:40,513 INFO     Training average positive_sample_loss at step 669700: 0.150447\n",
      "2022-11-08 23:56:40,513 INFO     Training average negative_sample_loss at step 669700: 0.144608\n",
      "2022-11-08 23:56:40,513 INFO     Training average loss at step 669700: 0.147528\n",
      "2022-11-08 23:56:46,900 INFO     Training average positive_sample_loss at step 669800: 0.148696\n",
      "2022-11-08 23:56:46,900 INFO     Training average negative_sample_loss at step 669800: 0.142680\n",
      "2022-11-08 23:56:46,900 INFO     Training average loss at step 669800: 0.145688\n",
      "2022-11-08 23:56:52,202 INFO     Training average positive_sample_loss at step 669900: 0.147156\n",
      "2022-11-08 23:56:52,202 INFO     Training average negative_sample_loss at step 669900: 0.137695\n",
      "2022-11-08 23:56:52,202 INFO     Training average loss at step 669900: 0.142425\n",
      "2022-11-08 23:57:01,276 INFO     Training average positive_sample_loss at step 670000: 0.155036\n",
      "2022-11-08 23:57:01,276 INFO     Training average negative_sample_loss at step 670000: 0.141561\n",
      "2022-11-08 23:57:01,276 INFO     Training average loss at step 670000: 0.148299\n",
      "2022-11-08 23:57:07,654 INFO     Training average positive_sample_loss at step 670100: 0.146506\n",
      "2022-11-08 23:57:07,654 INFO     Training average negative_sample_loss at step 670100: 0.141023\n",
      "2022-11-08 23:57:07,654 INFO     Training average loss at step 670100: 0.143764\n",
      "2022-11-08 23:57:14,045 INFO     Training average positive_sample_loss at step 670200: 0.148894\n",
      "2022-11-08 23:57:14,045 INFO     Training average negative_sample_loss at step 670200: 0.140808\n",
      "2022-11-08 23:57:14,045 INFO     Training average loss at step 670200: 0.144851\n",
      "2022-11-08 23:57:20,441 INFO     Training average positive_sample_loss at step 670300: 0.151190\n",
      "2022-11-08 23:57:20,441 INFO     Training average negative_sample_loss at step 670300: 0.139166\n",
      "2022-11-08 23:57:20,441 INFO     Training average loss at step 670300: 0.145178\n",
      "2022-11-08 23:57:26,845 INFO     Training average positive_sample_loss at step 670400: 0.148599\n",
      "2022-11-08 23:57:26,845 INFO     Training average negative_sample_loss at step 670400: 0.141323\n",
      "2022-11-08 23:57:26,845 INFO     Training average loss at step 670400: 0.144961\n",
      "2022-11-08 23:57:33,245 INFO     Training average positive_sample_loss at step 670500: 0.147088\n",
      "2022-11-08 23:57:33,245 INFO     Training average negative_sample_loss at step 670500: 0.138558\n",
      "2022-11-08 23:57:33,245 INFO     Training average loss at step 670500: 0.142823\n",
      "2022-11-08 23:57:39,603 INFO     Training average positive_sample_loss at step 670600: 0.148797\n",
      "2022-11-08 23:57:39,603 INFO     Training average negative_sample_loss at step 670600: 0.143518\n",
      "2022-11-08 23:57:39,603 INFO     Training average loss at step 670600: 0.146158\n",
      "2022-11-08 23:57:45,971 INFO     Training average positive_sample_loss at step 670700: 0.149436\n",
      "2022-11-08 23:57:45,971 INFO     Training average negative_sample_loss at step 670700: 0.140089\n",
      "2022-11-08 23:57:45,971 INFO     Training average loss at step 670700: 0.144763\n",
      "2022-11-08 23:57:52,341 INFO     Training average positive_sample_loss at step 670800: 0.148436\n",
      "2022-11-08 23:57:52,341 INFO     Training average negative_sample_loss at step 670800: 0.138776\n",
      "2022-11-08 23:57:52,341 INFO     Training average loss at step 670800: 0.143606\n",
      "2022-11-08 23:57:58,705 INFO     Training average positive_sample_loss at step 670900: 0.150334\n",
      "2022-11-08 23:57:58,705 INFO     Training average negative_sample_loss at step 670900: 0.140812\n",
      "2022-11-08 23:57:58,705 INFO     Training average loss at step 670900: 0.145573\n",
      "2022-11-08 23:58:05,092 INFO     Training average positive_sample_loss at step 671000: 0.156178\n",
      "2022-11-08 23:58:05,092 INFO     Training average negative_sample_loss at step 671000: 0.141766\n",
      "2022-11-08 23:58:05,093 INFO     Training average loss at step 671000: 0.148972\n",
      "2022-11-08 23:58:11,492 INFO     Training average positive_sample_loss at step 671100: 0.149220\n",
      "2022-11-08 23:58:11,493 INFO     Training average negative_sample_loss at step 671100: 0.147542\n",
      "2022-11-08 23:58:11,493 INFO     Training average loss at step 671100: 0.148381\n",
      "2022-11-08 23:58:17,860 INFO     Training average positive_sample_loss at step 671200: 0.149997\n",
      "2022-11-08 23:58:17,860 INFO     Training average negative_sample_loss at step 671200: 0.143014\n",
      "2022-11-08 23:58:17,860 INFO     Training average loss at step 671200: 0.146505\n",
      "2022-11-08 23:58:25,134 INFO     Training average positive_sample_loss at step 671300: 0.150919\n",
      "2022-11-08 23:58:25,134 INFO     Training average negative_sample_loss at step 671300: 0.142032\n",
      "2022-11-08 23:58:25,134 INFO     Training average loss at step 671300: 0.146475\n",
      "2022-11-08 23:58:32,214 INFO     Training average positive_sample_loss at step 671400: 0.151836\n",
      "2022-11-08 23:58:32,214 INFO     Training average negative_sample_loss at step 671400: 0.143191\n",
      "2022-11-08 23:58:32,214 INFO     Training average loss at step 671400: 0.147514\n",
      "2022-11-08 23:58:38,588 INFO     Training average positive_sample_loss at step 671500: 0.153140\n",
      "2022-11-08 23:58:38,588 INFO     Training average negative_sample_loss at step 671500: 0.140034\n",
      "2022-11-08 23:58:38,588 INFO     Training average loss at step 671500: 0.146587\n",
      "2022-11-08 23:58:46,353 INFO     Training average positive_sample_loss at step 671600: 0.151915\n",
      "2022-11-08 23:58:46,353 INFO     Training average negative_sample_loss at step 671600: 0.140462\n",
      "2022-11-08 23:58:46,353 INFO     Training average loss at step 671600: 0.146189\n",
      "2022-11-08 23:58:52,709 INFO     Training average positive_sample_loss at step 671700: 0.151714\n",
      "2022-11-08 23:58:52,709 INFO     Training average negative_sample_loss at step 671700: 0.143359\n",
      "2022-11-08 23:58:52,709 INFO     Training average loss at step 671700: 0.147537\n",
      "2022-11-08 23:58:59,084 INFO     Training average positive_sample_loss at step 671800: 0.154495\n",
      "2022-11-08 23:58:59,085 INFO     Training average negative_sample_loss at step 671800: 0.138831\n",
      "2022-11-08 23:58:59,085 INFO     Training average loss at step 671800: 0.146663\n",
      "2022-11-08 23:59:05,473 INFO     Training average positive_sample_loss at step 671900: 0.149862\n",
      "2022-11-08 23:59:05,473 INFO     Training average negative_sample_loss at step 671900: 0.142504\n",
      "2022-11-08 23:59:05,473 INFO     Training average loss at step 671900: 0.146183\n",
      "2022-11-08 23:59:11,865 INFO     Training average positive_sample_loss at step 672000: 0.151740\n",
      "2022-11-08 23:59:11,865 INFO     Training average negative_sample_loss at step 672000: 0.140063\n",
      "2022-11-08 23:59:11,865 INFO     Training average loss at step 672000: 0.145901\n",
      "2022-11-08 23:59:18,250 INFO     Training average positive_sample_loss at step 672100: 0.148528\n",
      "2022-11-08 23:59:18,251 INFO     Training average negative_sample_loss at step 672100: 0.140069\n",
      "2022-11-08 23:59:18,251 INFO     Training average loss at step 672100: 0.144299\n",
      "2022-11-08 23:59:24,610 INFO     Training average positive_sample_loss at step 672200: 0.150036\n",
      "2022-11-08 23:59:24,610 INFO     Training average negative_sample_loss at step 672200: 0.143553\n",
      "2022-11-08 23:59:24,610 INFO     Training average loss at step 672200: 0.146794\n",
      "2022-11-08 23:59:30,978 INFO     Training average positive_sample_loss at step 672300: 0.152099\n",
      "2022-11-08 23:59:30,978 INFO     Training average negative_sample_loss at step 672300: 0.139946\n",
      "2022-11-08 23:59:30,978 INFO     Training average loss at step 672300: 0.146022\n",
      "2022-11-08 23:59:37,328 INFO     Training average positive_sample_loss at step 672400: 0.150374\n",
      "2022-11-08 23:59:37,328 INFO     Training average negative_sample_loss at step 672400: 0.143438\n",
      "2022-11-08 23:59:37,328 INFO     Training average loss at step 672400: 0.146906\n",
      "2022-11-08 23:59:43,686 INFO     Training average positive_sample_loss at step 672500: 0.143833\n",
      "2022-11-08 23:59:43,686 INFO     Training average negative_sample_loss at step 672500: 0.141942\n",
      "2022-11-08 23:59:43,686 INFO     Training average loss at step 672500: 0.142887\n",
      "2022-11-08 23:59:50,059 INFO     Training average positive_sample_loss at step 672600: 0.152586\n",
      "2022-11-08 23:59:50,059 INFO     Training average negative_sample_loss at step 672600: 0.140720\n",
      "2022-11-08 23:59:50,059 INFO     Training average loss at step 672600: 0.146653\n",
      "2022-11-08 23:59:56,433 INFO     Training average positive_sample_loss at step 672700: 0.148092\n",
      "2022-11-08 23:59:56,433 INFO     Training average negative_sample_loss at step 672700: 0.141652\n",
      "2022-11-08 23:59:56,433 INFO     Training average loss at step 672700: 0.144872\n",
      "2022-11-09 00:00:02,825 INFO     Training average positive_sample_loss at step 672800: 0.150914\n",
      "2022-11-09 00:00:02,825 INFO     Training average negative_sample_loss at step 672800: 0.139213\n",
      "2022-11-09 00:00:02,825 INFO     Training average loss at step 672800: 0.145064\n",
      "2022-11-09 00:00:09,186 INFO     Training average positive_sample_loss at step 672900: 0.152905\n",
      "2022-11-09 00:00:09,187 INFO     Training average negative_sample_loss at step 672900: 0.142016\n",
      "2022-11-09 00:00:09,187 INFO     Training average loss at step 672900: 0.147460\n",
      "2022-11-09 00:00:15,559 INFO     Training average positive_sample_loss at step 673000: 0.148262\n",
      "2022-11-09 00:00:15,559 INFO     Training average negative_sample_loss at step 673000: 0.142395\n",
      "2022-11-09 00:00:15,559 INFO     Training average loss at step 673000: 0.145329\n",
      "2022-11-09 00:00:21,948 INFO     Training average positive_sample_loss at step 673100: 0.152676\n",
      "2022-11-09 00:00:21,948 INFO     Training average negative_sample_loss at step 673100: 0.141913\n",
      "2022-11-09 00:00:21,949 INFO     Training average loss at step 673100: 0.147295\n",
      "2022-11-09 00:00:28,373 INFO     Training average positive_sample_loss at step 673200: 0.150833\n",
      "2022-11-09 00:00:28,373 INFO     Training average negative_sample_loss at step 673200: 0.136869\n",
      "2022-11-09 00:00:28,373 INFO     Training average loss at step 673200: 0.143851\n",
      "2022-11-09 00:00:34,762 INFO     Training average positive_sample_loss at step 673300: 0.145922\n",
      "2022-11-09 00:00:34,762 INFO     Training average negative_sample_loss at step 673300: 0.143501\n",
      "2022-11-09 00:00:34,762 INFO     Training average loss at step 673300: 0.144712\n",
      "2022-11-09 00:00:41,147 INFO     Training average positive_sample_loss at step 673400: 0.150073\n",
      "2022-11-09 00:00:41,147 INFO     Training average negative_sample_loss at step 673400: 0.140380\n",
      "2022-11-09 00:00:41,147 INFO     Training average loss at step 673400: 0.145227\n",
      "2022-11-09 00:00:47,518 INFO     Training average positive_sample_loss at step 673500: 0.151480\n",
      "2022-11-09 00:00:47,518 INFO     Training average negative_sample_loss at step 673500: 0.138955\n",
      "2022-11-09 00:00:47,518 INFO     Training average loss at step 673500: 0.145218\n",
      "2022-11-09 00:00:53,902 INFO     Training average positive_sample_loss at step 673600: 0.152767\n",
      "2022-11-09 00:00:53,902 INFO     Training average negative_sample_loss at step 673600: 0.146421\n",
      "2022-11-09 00:00:53,902 INFO     Training average loss at step 673600: 0.149594\n",
      "2022-11-09 00:01:00,285 INFO     Training average positive_sample_loss at step 673700: 0.153472\n",
      "2022-11-09 00:01:00,286 INFO     Training average negative_sample_loss at step 673700: 0.145563\n",
      "2022-11-09 00:01:00,286 INFO     Training average loss at step 673700: 0.149518\n",
      "2022-11-09 00:01:06,662 INFO     Training average positive_sample_loss at step 673800: 0.148365\n",
      "2022-11-09 00:01:06,662 INFO     Training average negative_sample_loss at step 673800: 0.137014\n",
      "2022-11-09 00:01:06,662 INFO     Training average loss at step 673800: 0.142690\n",
      "2022-11-09 00:01:13,019 INFO     Training average positive_sample_loss at step 673900: 0.146007\n",
      "2022-11-09 00:01:13,019 INFO     Training average negative_sample_loss at step 673900: 0.145306\n",
      "2022-11-09 00:01:13,019 INFO     Training average loss at step 673900: 0.145657\n",
      "2022-11-09 00:01:19,397 INFO     Training average positive_sample_loss at step 674000: 0.150069\n",
      "2022-11-09 00:01:19,397 INFO     Training average negative_sample_loss at step 674000: 0.139756\n",
      "2022-11-09 00:01:19,397 INFO     Training average loss at step 674000: 0.144912\n",
      "2022-11-09 00:01:25,765 INFO     Training average positive_sample_loss at step 674100: 0.149249\n",
      "2022-11-09 00:01:25,765 INFO     Training average negative_sample_loss at step 674100: 0.139016\n",
      "2022-11-09 00:01:25,765 INFO     Training average loss at step 674100: 0.144132\n",
      "2022-11-09 00:01:32,139 INFO     Training average positive_sample_loss at step 674200: 0.147244\n",
      "2022-11-09 00:01:32,139 INFO     Training average negative_sample_loss at step 674200: 0.141857\n",
      "2022-11-09 00:01:32,139 INFO     Training average loss at step 674200: 0.144551\n",
      "2022-11-09 00:01:38,503 INFO     Training average positive_sample_loss at step 674300: 0.147957\n",
      "2022-11-09 00:01:38,503 INFO     Training average negative_sample_loss at step 674300: 0.137088\n",
      "2022-11-09 00:01:38,503 INFO     Training average loss at step 674300: 0.142522\n",
      "2022-11-09 00:01:44,871 INFO     Training average positive_sample_loss at step 674400: 0.154104\n",
      "2022-11-09 00:01:44,871 INFO     Training average negative_sample_loss at step 674400: 0.142682\n",
      "2022-11-09 00:01:44,871 INFO     Training average loss at step 674400: 0.148393\n",
      "2022-11-09 00:01:51,260 INFO     Training average positive_sample_loss at step 674500: 0.151797\n",
      "2022-11-09 00:01:51,261 INFO     Training average negative_sample_loss at step 674500: 0.143377\n",
      "2022-11-09 00:01:51,261 INFO     Training average loss at step 674500: 0.147587\n",
      "2022-11-09 00:01:57,609 INFO     Training average positive_sample_loss at step 674600: 0.152017\n",
      "2022-11-09 00:01:57,609 INFO     Training average negative_sample_loss at step 674600: 0.137863\n",
      "2022-11-09 00:01:57,609 INFO     Training average loss at step 674600: 0.144940\n",
      "2022-11-09 00:02:03,972 INFO     Training average positive_sample_loss at step 674700: 0.152371\n",
      "2022-11-09 00:02:03,972 INFO     Training average negative_sample_loss at step 674700: 0.138054\n",
      "2022-11-09 00:02:03,972 INFO     Training average loss at step 674700: 0.145212\n",
      "2022-11-09 00:02:10,357 INFO     Training average positive_sample_loss at step 674800: 0.148361\n",
      "2022-11-09 00:02:10,357 INFO     Training average negative_sample_loss at step 674800: 0.139674\n",
      "2022-11-09 00:02:10,357 INFO     Training average loss at step 674800: 0.144018\n",
      "2022-11-09 00:02:16,732 INFO     Training average positive_sample_loss at step 674900: 0.147998\n",
      "2022-11-09 00:02:16,732 INFO     Training average negative_sample_loss at step 674900: 0.142306\n",
      "2022-11-09 00:02:16,732 INFO     Training average loss at step 674900: 0.145152\n",
      "2022-11-09 00:02:23,108 INFO     Training average positive_sample_loss at step 675000: 0.148380\n",
      "2022-11-09 00:02:23,109 INFO     Training average negative_sample_loss at step 675000: 0.141570\n",
      "2022-11-09 00:02:23,109 INFO     Training average loss at step 675000: 0.144975\n",
      "2022-11-09 00:02:29,494 INFO     Training average positive_sample_loss at step 675100: 0.147500\n",
      "2022-11-09 00:02:29,494 INFO     Training average negative_sample_loss at step 675100: 0.142740\n",
      "2022-11-09 00:02:29,494 INFO     Training average loss at step 675100: 0.145120\n",
      "2022-11-09 00:02:35,859 INFO     Training average positive_sample_loss at step 675200: 0.154629\n",
      "2022-11-09 00:02:35,859 INFO     Training average negative_sample_loss at step 675200: 0.143909\n",
      "2022-11-09 00:02:35,859 INFO     Training average loss at step 675200: 0.149269\n",
      "2022-11-09 00:02:42,228 INFO     Training average positive_sample_loss at step 675300: 0.151432\n",
      "2022-11-09 00:02:42,228 INFO     Training average negative_sample_loss at step 675300: 0.137889\n",
      "2022-11-09 00:02:42,228 INFO     Training average loss at step 675300: 0.144660\n",
      "2022-11-09 00:02:48,282 INFO     Training average positive_sample_loss at step 675400: 0.148066\n",
      "2022-11-09 00:02:48,282 INFO     Training average negative_sample_loss at step 675400: 0.137587\n",
      "2022-11-09 00:02:48,282 INFO     Training average loss at step 675400: 0.142827\n",
      "2022-11-09 00:02:53,573 INFO     Training average positive_sample_loss at step 675500: 0.149456\n",
      "2022-11-09 00:02:53,573 INFO     Training average negative_sample_loss at step 675500: 0.143864\n",
      "2022-11-09 00:02:53,573 INFO     Training average loss at step 675500: 0.146660\n",
      "2022-11-09 00:02:59,952 INFO     Training average positive_sample_loss at step 675600: 0.149462\n",
      "2022-11-09 00:02:59,952 INFO     Training average negative_sample_loss at step 675600: 0.143193\n",
      "2022-11-09 00:02:59,952 INFO     Training average loss at step 675600: 0.146327\n",
      "2022-11-09 00:03:06,325 INFO     Training average positive_sample_loss at step 675700: 0.151760\n",
      "2022-11-09 00:03:06,325 INFO     Training average negative_sample_loss at step 675700: 0.141660\n",
      "2022-11-09 00:03:06,325 INFO     Training average loss at step 675700: 0.146710\n",
      "2022-11-09 00:03:13,617 INFO     Training average positive_sample_loss at step 675800: 0.148062\n",
      "2022-11-09 00:03:13,617 INFO     Training average negative_sample_loss at step 675800: 0.143511\n",
      "2022-11-09 00:03:13,617 INFO     Training average loss at step 675800: 0.145786\n",
      "2022-11-09 00:03:20,641 INFO     Training average positive_sample_loss at step 675900: 0.153871\n",
      "2022-11-09 00:03:20,641 INFO     Training average negative_sample_loss at step 675900: 0.141101\n",
      "2022-11-09 00:03:20,641 INFO     Training average loss at step 675900: 0.147486\n",
      "2022-11-09 00:03:27,020 INFO     Training average positive_sample_loss at step 676000: 0.156162\n",
      "2022-11-09 00:03:27,020 INFO     Training average negative_sample_loss at step 676000: 0.145133\n",
      "2022-11-09 00:03:27,021 INFO     Training average loss at step 676000: 0.150647\n",
      "2022-11-09 00:03:33,391 INFO     Training average positive_sample_loss at step 676100: 0.152886\n",
      "2022-11-09 00:03:33,391 INFO     Training average negative_sample_loss at step 676100: 0.142691\n",
      "2022-11-09 00:03:33,391 INFO     Training average loss at step 676100: 0.147788\n",
      "2022-11-09 00:03:39,766 INFO     Training average positive_sample_loss at step 676200: 0.151645\n",
      "2022-11-09 00:03:39,766 INFO     Training average negative_sample_loss at step 676200: 0.141281\n",
      "2022-11-09 00:03:39,766 INFO     Training average loss at step 676200: 0.146463\n",
      "2022-11-09 00:03:47,535 INFO     Training average positive_sample_loss at step 676300: 0.151449\n",
      "2022-11-09 00:03:47,535 INFO     Training average negative_sample_loss at step 676300: 0.143693\n",
      "2022-11-09 00:03:47,535 INFO     Training average loss at step 676300: 0.147571\n",
      "2022-11-09 00:03:53,894 INFO     Training average positive_sample_loss at step 676400: 0.151374\n",
      "2022-11-09 00:03:53,894 INFO     Training average negative_sample_loss at step 676400: 0.141481\n",
      "2022-11-09 00:03:53,894 INFO     Training average loss at step 676400: 0.146428\n",
      "2022-11-09 00:04:00,280 INFO     Training average positive_sample_loss at step 676500: 0.150101\n",
      "2022-11-09 00:04:00,280 INFO     Training average negative_sample_loss at step 676500: 0.140486\n",
      "2022-11-09 00:04:00,280 INFO     Training average loss at step 676500: 0.145293\n",
      "2022-11-09 00:04:06,666 INFO     Training average positive_sample_loss at step 676600: 0.146059\n",
      "2022-11-09 00:04:06,666 INFO     Training average negative_sample_loss at step 676600: 0.142634\n",
      "2022-11-09 00:04:06,666 INFO     Training average loss at step 676600: 0.144346\n",
      "2022-11-09 00:04:13,042 INFO     Training average positive_sample_loss at step 676700: 0.155562\n",
      "2022-11-09 00:04:13,042 INFO     Training average negative_sample_loss at step 676700: 0.139659\n",
      "2022-11-09 00:04:13,042 INFO     Training average loss at step 676700: 0.147611\n",
      "2022-11-09 00:04:19,421 INFO     Training average positive_sample_loss at step 676800: 0.151195\n",
      "2022-11-09 00:04:19,421 INFO     Training average negative_sample_loss at step 676800: 0.141099\n",
      "2022-11-09 00:04:19,421 INFO     Training average loss at step 676800: 0.146147\n",
      "2022-11-09 00:04:25,803 INFO     Training average positive_sample_loss at step 676900: 0.151280\n",
      "2022-11-09 00:04:25,804 INFO     Training average negative_sample_loss at step 676900: 0.140333\n",
      "2022-11-09 00:04:25,804 INFO     Training average loss at step 676900: 0.145807\n",
      "2022-11-09 00:04:32,182 INFO     Training average positive_sample_loss at step 677000: 0.157217\n",
      "2022-11-09 00:04:32,182 INFO     Training average negative_sample_loss at step 677000: 0.142573\n",
      "2022-11-09 00:04:32,182 INFO     Training average loss at step 677000: 0.149895\n",
      "2022-11-09 00:04:38,554 INFO     Training average positive_sample_loss at step 677100: 0.147442\n",
      "2022-11-09 00:04:38,554 INFO     Training average negative_sample_loss at step 677100: 0.139799\n",
      "2022-11-09 00:04:38,554 INFO     Training average loss at step 677100: 0.143620\n",
      "2022-11-09 00:04:44,937 INFO     Training average positive_sample_loss at step 677200: 0.145832\n",
      "2022-11-09 00:04:44,937 INFO     Training average negative_sample_loss at step 677200: 0.140219\n",
      "2022-11-09 00:04:44,937 INFO     Training average loss at step 677200: 0.143025\n",
      "2022-11-09 00:04:51,318 INFO     Training average positive_sample_loss at step 677300: 0.151509\n",
      "2022-11-09 00:04:51,318 INFO     Training average negative_sample_loss at step 677300: 0.139495\n",
      "2022-11-09 00:04:51,318 INFO     Training average loss at step 677300: 0.145502\n",
      "2022-11-09 00:04:57,682 INFO     Training average positive_sample_loss at step 677400: 0.150958\n",
      "2022-11-09 00:04:57,682 INFO     Training average negative_sample_loss at step 677400: 0.139489\n",
      "2022-11-09 00:04:57,682 INFO     Training average loss at step 677400: 0.145224\n",
      "2022-11-09 00:05:04,045 INFO     Training average positive_sample_loss at step 677500: 0.150751\n",
      "2022-11-09 00:05:04,046 INFO     Training average negative_sample_loss at step 677500: 0.142439\n",
      "2022-11-09 00:05:04,046 INFO     Training average loss at step 677500: 0.146595\n",
      "2022-11-09 00:05:10,395 INFO     Training average positive_sample_loss at step 677600: 0.152634\n",
      "2022-11-09 00:05:10,395 INFO     Training average negative_sample_loss at step 677600: 0.142103\n",
      "2022-11-09 00:05:10,395 INFO     Training average loss at step 677600: 0.147368\n",
      "2022-11-09 00:05:16,742 INFO     Training average positive_sample_loss at step 677700: 0.148227\n",
      "2022-11-09 00:05:16,742 INFO     Training average negative_sample_loss at step 677700: 0.137336\n",
      "2022-11-09 00:05:16,742 INFO     Training average loss at step 677700: 0.142781\n",
      "2022-11-09 00:05:23,130 INFO     Training average positive_sample_loss at step 677800: 0.152534\n",
      "2022-11-09 00:05:23,130 INFO     Training average negative_sample_loss at step 677800: 0.144074\n",
      "2022-11-09 00:05:23,130 INFO     Training average loss at step 677800: 0.148304\n",
      "2022-11-09 00:05:29,486 INFO     Training average positive_sample_loss at step 677900: 0.154749\n",
      "2022-11-09 00:05:29,486 INFO     Training average negative_sample_loss at step 677900: 0.140572\n",
      "2022-11-09 00:05:29,486 INFO     Training average loss at step 677900: 0.147660\n",
      "2022-11-09 00:05:35,865 INFO     Training average positive_sample_loss at step 678000: 0.150896\n",
      "2022-11-09 00:05:35,865 INFO     Training average negative_sample_loss at step 678000: 0.138983\n",
      "2022-11-09 00:05:35,865 INFO     Training average loss at step 678000: 0.144939\n",
      "2022-11-09 00:05:42,254 INFO     Training average positive_sample_loss at step 678100: 0.149603\n",
      "2022-11-09 00:05:42,254 INFO     Training average negative_sample_loss at step 678100: 0.143442\n",
      "2022-11-09 00:05:42,254 INFO     Training average loss at step 678100: 0.146523\n",
      "2022-11-09 00:05:48,639 INFO     Training average positive_sample_loss at step 678200: 0.154489\n",
      "2022-11-09 00:05:48,639 INFO     Training average negative_sample_loss at step 678200: 0.142592\n",
      "2022-11-09 00:05:48,639 INFO     Training average loss at step 678200: 0.148540\n",
      "2022-11-09 00:05:55,049 INFO     Training average positive_sample_loss at step 678300: 0.148500\n",
      "2022-11-09 00:05:55,049 INFO     Training average negative_sample_loss at step 678300: 0.141410\n",
      "2022-11-09 00:05:55,049 INFO     Training average loss at step 678300: 0.144955\n",
      "2022-11-09 00:06:01,423 INFO     Training average positive_sample_loss at step 678400: 0.152722\n",
      "2022-11-09 00:06:01,423 INFO     Training average negative_sample_loss at step 678400: 0.144863\n",
      "2022-11-09 00:06:01,423 INFO     Training average loss at step 678400: 0.148792\n",
      "2022-11-09 00:06:07,802 INFO     Training average positive_sample_loss at step 678500: 0.148137\n",
      "2022-11-09 00:06:07,802 INFO     Training average negative_sample_loss at step 678500: 0.138728\n",
      "2022-11-09 00:06:07,802 INFO     Training average loss at step 678500: 0.143432\n",
      "2022-11-09 00:06:14,148 INFO     Training average positive_sample_loss at step 678600: 0.147276\n",
      "2022-11-09 00:06:14,148 INFO     Training average negative_sample_loss at step 678600: 0.137235\n",
      "2022-11-09 00:06:14,148 INFO     Training average loss at step 678600: 0.142256\n",
      "2022-11-09 00:06:20,530 INFO     Training average positive_sample_loss at step 678700: 0.154783\n",
      "2022-11-09 00:06:20,530 INFO     Training average negative_sample_loss at step 678700: 0.146918\n",
      "2022-11-09 00:06:20,530 INFO     Training average loss at step 678700: 0.150851\n",
      "2022-11-09 00:06:26,916 INFO     Training average positive_sample_loss at step 678800: 0.148646\n",
      "2022-11-09 00:06:26,916 INFO     Training average negative_sample_loss at step 678800: 0.142206\n",
      "2022-11-09 00:06:26,916 INFO     Training average loss at step 678800: 0.145426\n",
      "2022-11-09 00:06:33,298 INFO     Training average positive_sample_loss at step 678900: 0.151100\n",
      "2022-11-09 00:06:33,298 INFO     Training average negative_sample_loss at step 678900: 0.138971\n",
      "2022-11-09 00:06:33,298 INFO     Training average loss at step 678900: 0.145035\n",
      "2022-11-09 00:06:39,685 INFO     Training average positive_sample_loss at step 679000: 0.148738\n",
      "2022-11-09 00:06:39,685 INFO     Training average negative_sample_loss at step 679000: 0.139403\n",
      "2022-11-09 00:06:39,685 INFO     Training average loss at step 679000: 0.144071\n",
      "2022-11-09 00:06:46,057 INFO     Training average positive_sample_loss at step 679100: 0.153772\n",
      "2022-11-09 00:06:46,057 INFO     Training average negative_sample_loss at step 679100: 0.139882\n",
      "2022-11-09 00:06:46,057 INFO     Training average loss at step 679100: 0.146827\n",
      "2022-11-09 00:06:52,436 INFO     Training average positive_sample_loss at step 679200: 0.147755\n",
      "2022-11-09 00:06:52,436 INFO     Training average negative_sample_loss at step 679200: 0.140598\n",
      "2022-11-09 00:06:52,436 INFO     Training average loss at step 679200: 0.144177\n",
      "2022-11-09 00:06:58,820 INFO     Training average positive_sample_loss at step 679300: 0.150469\n",
      "2022-11-09 00:06:58,820 INFO     Training average negative_sample_loss at step 679300: 0.144184\n",
      "2022-11-09 00:06:58,820 INFO     Training average loss at step 679300: 0.147327\n",
      "2022-11-09 00:07:05,176 INFO     Training average positive_sample_loss at step 679400: 0.153186\n",
      "2022-11-09 00:07:05,176 INFO     Training average negative_sample_loss at step 679400: 0.138189\n",
      "2022-11-09 00:07:05,176 INFO     Training average loss at step 679400: 0.145688\n",
      "2022-11-09 00:07:11,532 INFO     Training average positive_sample_loss at step 679500: 0.149081\n",
      "2022-11-09 00:07:11,532 INFO     Training average negative_sample_loss at step 679500: 0.138326\n",
      "2022-11-09 00:07:11,532 INFO     Training average loss at step 679500: 0.143703\n",
      "2022-11-09 00:07:17,901 INFO     Training average positive_sample_loss at step 679600: 0.147758\n",
      "2022-11-09 00:07:17,901 INFO     Training average negative_sample_loss at step 679600: 0.140510\n",
      "2022-11-09 00:07:17,901 INFO     Training average loss at step 679600: 0.144134\n",
      "2022-11-09 00:07:24,247 INFO     Training average positive_sample_loss at step 679700: 0.146268\n",
      "2022-11-09 00:07:24,247 INFO     Training average negative_sample_loss at step 679700: 0.143259\n",
      "2022-11-09 00:07:24,247 INFO     Training average loss at step 679700: 0.144763\n",
      "2022-11-09 00:07:30,617 INFO     Training average positive_sample_loss at step 679800: 0.152269\n",
      "2022-11-09 00:07:30,617 INFO     Training average negative_sample_loss at step 679800: 0.138567\n",
      "2022-11-09 00:07:30,617 INFO     Training average loss at step 679800: 0.145418\n",
      "2022-11-09 00:07:36,979 INFO     Training average positive_sample_loss at step 679900: 0.155141\n",
      "2022-11-09 00:07:36,979 INFO     Training average negative_sample_loss at step 679900: 0.141852\n",
      "2022-11-09 00:07:36,979 INFO     Training average loss at step 679900: 0.148497\n",
      "2022-11-09 00:07:46,327 INFO     Training average positive_sample_loss at step 680000: 0.150006\n",
      "2022-11-09 00:07:46,327 INFO     Training average negative_sample_loss at step 680000: 0.137546\n",
      "2022-11-09 00:07:46,327 INFO     Training average loss at step 680000: 0.143776\n",
      "2022-11-09 00:07:52,709 INFO     Training average positive_sample_loss at step 680100: 0.150409\n",
      "2022-11-09 00:07:52,709 INFO     Training average negative_sample_loss at step 680100: 0.142472\n",
      "2022-11-09 00:07:52,709 INFO     Training average loss at step 680100: 0.146441\n",
      "2022-11-09 00:07:59,084 INFO     Training average positive_sample_loss at step 680200: 0.149426\n",
      "2022-11-09 00:07:59,084 INFO     Training average negative_sample_loss at step 680200: 0.143478\n",
      "2022-11-09 00:07:59,084 INFO     Training average loss at step 680200: 0.146452\n",
      "2022-11-09 00:08:05,460 INFO     Training average positive_sample_loss at step 680300: 0.150778\n",
      "2022-11-09 00:08:05,460 INFO     Training average negative_sample_loss at step 680300: 0.138880\n",
      "2022-11-09 00:08:05,460 INFO     Training average loss at step 680300: 0.144829\n",
      "2022-11-09 00:08:11,829 INFO     Training average positive_sample_loss at step 680400: 0.146058\n",
      "2022-11-09 00:08:11,829 INFO     Training average negative_sample_loss at step 680400: 0.141657\n",
      "2022-11-09 00:08:11,829 INFO     Training average loss at step 680400: 0.143858\n",
      "2022-11-09 00:08:19,099 INFO     Training average positive_sample_loss at step 680500: 0.150650\n",
      "2022-11-09 00:08:19,099 INFO     Training average negative_sample_loss at step 680500: 0.140347\n",
      "2022-11-09 00:08:19,100 INFO     Training average loss at step 680500: 0.145498\n",
      "2022-11-09 00:08:26,247 INFO     Training average positive_sample_loss at step 680600: 0.149852\n",
      "2022-11-09 00:08:26,247 INFO     Training average negative_sample_loss at step 680600: 0.145307\n",
      "2022-11-09 00:08:26,247 INFO     Training average loss at step 680600: 0.147579\n",
      "2022-11-09 00:08:32,616 INFO     Training average positive_sample_loss at step 680700: 0.148073\n",
      "2022-11-09 00:08:32,616 INFO     Training average negative_sample_loss at step 680700: 0.139086\n",
      "2022-11-09 00:08:32,616 INFO     Training average loss at step 680700: 0.143579\n",
      "2022-11-09 00:08:38,967 INFO     Training average positive_sample_loss at step 680800: 0.145756\n",
      "2022-11-09 00:08:38,967 INFO     Training average negative_sample_loss at step 680800: 0.137324\n",
      "2022-11-09 00:08:38,967 INFO     Training average loss at step 680800: 0.141540\n",
      "2022-11-09 00:08:44,316 INFO     Training average positive_sample_loss at step 680900: 0.152028\n",
      "2022-11-09 00:08:44,316 INFO     Training average negative_sample_loss at step 680900: 0.139328\n",
      "2022-11-09 00:08:44,316 INFO     Training average loss at step 680900: 0.145678\n",
      "2022-11-09 00:08:51,872 INFO     Training average positive_sample_loss at step 681000: 0.152862\n",
      "2022-11-09 00:08:51,872 INFO     Training average negative_sample_loss at step 681000: 0.139818\n",
      "2022-11-09 00:08:51,872 INFO     Training average loss at step 681000: 0.146340\n",
      "2022-11-09 00:08:58,241 INFO     Training average positive_sample_loss at step 681100: 0.152082\n",
      "2022-11-09 00:08:58,242 INFO     Training average negative_sample_loss at step 681100: 0.138856\n",
      "2022-11-09 00:08:58,242 INFO     Training average loss at step 681100: 0.145469\n",
      "2022-11-09 00:09:04,610 INFO     Training average positive_sample_loss at step 681200: 0.151049\n",
      "2022-11-09 00:09:04,610 INFO     Training average negative_sample_loss at step 681200: 0.137261\n",
      "2022-11-09 00:09:04,610 INFO     Training average loss at step 681200: 0.144155\n",
      "2022-11-09 00:09:10,992 INFO     Training average positive_sample_loss at step 681300: 0.154737\n",
      "2022-11-09 00:09:10,992 INFO     Training average negative_sample_loss at step 681300: 0.139683\n",
      "2022-11-09 00:09:10,992 INFO     Training average loss at step 681300: 0.147210\n",
      "2022-11-09 00:09:17,361 INFO     Training average positive_sample_loss at step 681400: 0.152465\n",
      "2022-11-09 00:09:17,361 INFO     Training average negative_sample_loss at step 681400: 0.140557\n",
      "2022-11-09 00:09:17,361 INFO     Training average loss at step 681400: 0.146511\n",
      "2022-11-09 00:09:23,722 INFO     Training average positive_sample_loss at step 681500: 0.150113\n",
      "2022-11-09 00:09:23,722 INFO     Training average negative_sample_loss at step 681500: 0.140262\n",
      "2022-11-09 00:09:23,722 INFO     Training average loss at step 681500: 0.145187\n",
      "2022-11-09 00:09:30,102 INFO     Training average positive_sample_loss at step 681600: 0.149412\n",
      "2022-11-09 00:09:30,102 INFO     Training average negative_sample_loss at step 681600: 0.139569\n",
      "2022-11-09 00:09:30,102 INFO     Training average loss at step 681600: 0.144490\n",
      "2022-11-09 00:09:36,494 INFO     Training average positive_sample_loss at step 681700: 0.155192\n",
      "2022-11-09 00:09:36,494 INFO     Training average negative_sample_loss at step 681700: 0.139234\n",
      "2022-11-09 00:09:36,494 INFO     Training average loss at step 681700: 0.147213\n",
      "2022-11-09 00:09:42,852 INFO     Training average positive_sample_loss at step 681800: 0.150689\n",
      "2022-11-09 00:09:42,852 INFO     Training average negative_sample_loss at step 681800: 0.143606\n",
      "2022-11-09 00:09:42,852 INFO     Training average loss at step 681800: 0.147147\n",
      "2022-11-09 00:09:49,206 INFO     Training average positive_sample_loss at step 681900: 0.148431\n",
      "2022-11-09 00:09:49,206 INFO     Training average negative_sample_loss at step 681900: 0.139276\n",
      "2022-11-09 00:09:49,206 INFO     Training average loss at step 681900: 0.143854\n",
      "2022-11-09 00:09:55,567 INFO     Training average positive_sample_loss at step 682000: 0.155008\n",
      "2022-11-09 00:09:55,567 INFO     Training average negative_sample_loss at step 682000: 0.143283\n",
      "2022-11-09 00:09:55,567 INFO     Training average loss at step 682000: 0.149146\n",
      "2022-11-09 00:10:01,958 INFO     Training average positive_sample_loss at step 682100: 0.155542\n",
      "2022-11-09 00:10:01,958 INFO     Training average negative_sample_loss at step 682100: 0.138930\n",
      "2022-11-09 00:10:01,958 INFO     Training average loss at step 682100: 0.147236\n",
      "2022-11-09 00:10:08,348 INFO     Training average positive_sample_loss at step 682200: 0.154419\n",
      "2022-11-09 00:10:08,348 INFO     Training average negative_sample_loss at step 682200: 0.139539\n",
      "2022-11-09 00:10:08,348 INFO     Training average loss at step 682200: 0.146979\n",
      "2022-11-09 00:10:14,721 INFO     Training average positive_sample_loss at step 682300: 0.155255\n",
      "2022-11-09 00:10:14,721 INFO     Training average negative_sample_loss at step 682300: 0.141398\n",
      "2022-11-09 00:10:14,721 INFO     Training average loss at step 682300: 0.148327\n",
      "2022-11-09 00:10:21,092 INFO     Training average positive_sample_loss at step 682400: 0.151444\n",
      "2022-11-09 00:10:21,092 INFO     Training average negative_sample_loss at step 682400: 0.140492\n",
      "2022-11-09 00:10:21,092 INFO     Training average loss at step 682400: 0.145968\n",
      "2022-11-09 00:10:27,457 INFO     Training average positive_sample_loss at step 682500: 0.148050\n",
      "2022-11-09 00:10:27,457 INFO     Training average negative_sample_loss at step 682500: 0.144706\n",
      "2022-11-09 00:10:27,457 INFO     Training average loss at step 682500: 0.146378\n",
      "2022-11-09 00:10:33,821 INFO     Training average positive_sample_loss at step 682600: 0.147446\n",
      "2022-11-09 00:10:33,821 INFO     Training average negative_sample_loss at step 682600: 0.139107\n",
      "2022-11-09 00:10:33,821 INFO     Training average loss at step 682600: 0.143276\n",
      "2022-11-09 00:10:40,193 INFO     Training average positive_sample_loss at step 682700: 0.147650\n",
      "2022-11-09 00:10:40,193 INFO     Training average negative_sample_loss at step 682700: 0.138572\n",
      "2022-11-09 00:10:40,193 INFO     Training average loss at step 682700: 0.143111\n",
      "2022-11-09 00:10:46,576 INFO     Training average positive_sample_loss at step 682800: 0.149985\n",
      "2022-11-09 00:10:46,576 INFO     Training average negative_sample_loss at step 682800: 0.135845\n",
      "2022-11-09 00:10:46,577 INFO     Training average loss at step 682800: 0.142915\n",
      "2022-11-09 00:10:52,928 INFO     Training average positive_sample_loss at step 682900: 0.153698\n",
      "2022-11-09 00:10:52,929 INFO     Training average negative_sample_loss at step 682900: 0.143577\n",
      "2022-11-09 00:10:52,929 INFO     Training average loss at step 682900: 0.148638\n",
      "2022-11-09 00:10:59,306 INFO     Training average positive_sample_loss at step 683000: 0.154319\n",
      "2022-11-09 00:10:59,306 INFO     Training average negative_sample_loss at step 683000: 0.142113\n",
      "2022-11-09 00:10:59,306 INFO     Training average loss at step 683000: 0.148216\n",
      "2022-11-09 00:11:05,701 INFO     Training average positive_sample_loss at step 683100: 0.150402\n",
      "2022-11-09 00:11:05,701 INFO     Training average negative_sample_loss at step 683100: 0.142705\n",
      "2022-11-09 00:11:05,701 INFO     Training average loss at step 683100: 0.146553\n",
      "2022-11-09 00:11:12,079 INFO     Training average positive_sample_loss at step 683200: 0.151173\n",
      "2022-11-09 00:11:12,079 INFO     Training average negative_sample_loss at step 683200: 0.143385\n",
      "2022-11-09 00:11:12,079 INFO     Training average loss at step 683200: 0.147279\n",
      "2022-11-09 00:11:18,438 INFO     Training average positive_sample_loss at step 683300: 0.148323\n",
      "2022-11-09 00:11:18,438 INFO     Training average negative_sample_loss at step 683300: 0.136975\n",
      "2022-11-09 00:11:18,438 INFO     Training average loss at step 683300: 0.142649\n",
      "2022-11-09 00:11:24,809 INFO     Training average positive_sample_loss at step 683400: 0.150162\n",
      "2022-11-09 00:11:24,809 INFO     Training average negative_sample_loss at step 683400: 0.142693\n",
      "2022-11-09 00:11:24,809 INFO     Training average loss at step 683400: 0.146427\n",
      "2022-11-09 00:11:31,196 INFO     Training average positive_sample_loss at step 683500: 0.150242\n",
      "2022-11-09 00:11:31,196 INFO     Training average negative_sample_loss at step 683500: 0.138654\n",
      "2022-11-09 00:11:31,196 INFO     Training average loss at step 683500: 0.144448\n",
      "2022-11-09 00:11:37,557 INFO     Training average positive_sample_loss at step 683600: 0.150984\n",
      "2022-11-09 00:11:37,557 INFO     Training average negative_sample_loss at step 683600: 0.140910\n",
      "2022-11-09 00:11:37,557 INFO     Training average loss at step 683600: 0.145947\n",
      "2022-11-09 00:11:43,925 INFO     Training average positive_sample_loss at step 683700: 0.149680\n",
      "2022-11-09 00:11:43,925 INFO     Training average negative_sample_loss at step 683700: 0.144754\n",
      "2022-11-09 00:11:43,925 INFO     Training average loss at step 683700: 0.147217\n",
      "2022-11-09 00:11:50,305 INFO     Training average positive_sample_loss at step 683800: 0.151154\n",
      "2022-11-09 00:11:50,305 INFO     Training average negative_sample_loss at step 683800: 0.138332\n",
      "2022-11-09 00:11:50,305 INFO     Training average loss at step 683800: 0.144743\n",
      "2022-11-09 00:11:56,707 INFO     Training average positive_sample_loss at step 683900: 0.151702\n",
      "2022-11-09 00:11:56,707 INFO     Training average negative_sample_loss at step 683900: 0.143489\n",
      "2022-11-09 00:11:56,707 INFO     Training average loss at step 683900: 0.147595\n",
      "2022-11-09 00:12:03,078 INFO     Training average positive_sample_loss at step 684000: 0.151463\n",
      "2022-11-09 00:12:03,078 INFO     Training average negative_sample_loss at step 684000: 0.136385\n",
      "2022-11-09 00:12:03,078 INFO     Training average loss at step 684000: 0.143924\n",
      "2022-11-09 00:12:09,444 INFO     Training average positive_sample_loss at step 684100: 0.150978\n",
      "2022-11-09 00:12:09,444 INFO     Training average negative_sample_loss at step 684100: 0.140567\n",
      "2022-11-09 00:12:09,444 INFO     Training average loss at step 684100: 0.145773\n",
      "2022-11-09 00:12:15,826 INFO     Training average positive_sample_loss at step 684200: 0.156217\n",
      "2022-11-09 00:12:15,827 INFO     Training average negative_sample_loss at step 684200: 0.143618\n",
      "2022-11-09 00:12:15,827 INFO     Training average loss at step 684200: 0.149917\n",
      "2022-11-09 00:12:22,201 INFO     Training average positive_sample_loss at step 684300: 0.153334\n",
      "2022-11-09 00:12:22,201 INFO     Training average negative_sample_loss at step 684300: 0.144598\n",
      "2022-11-09 00:12:22,201 INFO     Training average loss at step 684300: 0.148966\n",
      "2022-11-09 00:12:28,554 INFO     Training average positive_sample_loss at step 684400: 0.149505\n",
      "2022-11-09 00:12:28,554 INFO     Training average negative_sample_loss at step 684400: 0.138854\n",
      "2022-11-09 00:12:28,554 INFO     Training average loss at step 684400: 0.144179\n",
      "2022-11-09 00:12:34,917 INFO     Training average positive_sample_loss at step 684500: 0.153790\n",
      "2022-11-09 00:12:34,917 INFO     Training average negative_sample_loss at step 684500: 0.143801\n",
      "2022-11-09 00:12:34,917 INFO     Training average loss at step 684500: 0.148796\n",
      "2022-11-09 00:12:41,303 INFO     Training average positive_sample_loss at step 684600: 0.150156\n",
      "2022-11-09 00:12:41,303 INFO     Training average negative_sample_loss at step 684600: 0.143724\n",
      "2022-11-09 00:12:41,303 INFO     Training average loss at step 684600: 0.146940\n",
      "2022-11-09 00:12:47,683 INFO     Training average positive_sample_loss at step 684700: 0.147885\n",
      "2022-11-09 00:12:47,683 INFO     Training average negative_sample_loss at step 684700: 0.139607\n",
      "2022-11-09 00:12:47,683 INFO     Training average loss at step 684700: 0.143746\n",
      "2022-11-09 00:12:54,069 INFO     Training average positive_sample_loss at step 684800: 0.149969\n",
      "2022-11-09 00:12:54,069 INFO     Training average negative_sample_loss at step 684800: 0.137034\n",
      "2022-11-09 00:12:54,069 INFO     Training average loss at step 684800: 0.143502\n",
      "2022-11-09 00:13:00,438 INFO     Training average positive_sample_loss at step 684900: 0.152504\n",
      "2022-11-09 00:13:00,439 INFO     Training average negative_sample_loss at step 684900: 0.139199\n",
      "2022-11-09 00:13:00,439 INFO     Training average loss at step 684900: 0.145851\n",
      "2022-11-09 00:13:06,845 INFO     Training average positive_sample_loss at step 685000: 0.154543\n",
      "2022-11-09 00:13:06,846 INFO     Training average negative_sample_loss at step 685000: 0.137127\n",
      "2022-11-09 00:13:06,846 INFO     Training average loss at step 685000: 0.145835\n",
      "2022-11-09 00:13:13,213 INFO     Training average positive_sample_loss at step 685100: 0.150930\n",
      "2022-11-09 00:13:13,213 INFO     Training average negative_sample_loss at step 685100: 0.134906\n",
      "2022-11-09 00:13:13,213 INFO     Training average loss at step 685100: 0.142918\n",
      "2022-11-09 00:13:20,545 INFO     Training average positive_sample_loss at step 685200: 0.149526\n",
      "2022-11-09 00:13:20,545 INFO     Training average negative_sample_loss at step 685200: 0.139388\n",
      "2022-11-09 00:13:20,545 INFO     Training average loss at step 685200: 0.144457\n",
      "2022-11-09 00:13:27,634 INFO     Training average positive_sample_loss at step 685300: 0.152447\n",
      "2022-11-09 00:13:27,634 INFO     Training average negative_sample_loss at step 685300: 0.138857\n",
      "2022-11-09 00:13:27,634 INFO     Training average loss at step 685300: 0.145652\n",
      "2022-11-09 00:13:34,004 INFO     Training average positive_sample_loss at step 685400: 0.146652\n",
      "2022-11-09 00:13:34,004 INFO     Training average negative_sample_loss at step 685400: 0.143078\n",
      "2022-11-09 00:13:34,004 INFO     Training average loss at step 685400: 0.144865\n",
      "2022-11-09 00:13:40,384 INFO     Training average positive_sample_loss at step 685500: 0.157133\n",
      "2022-11-09 00:13:40,384 INFO     Training average negative_sample_loss at step 685500: 0.143455\n",
      "2022-11-09 00:13:40,384 INFO     Training average loss at step 685500: 0.150294\n",
      "2022-11-09 00:13:46,786 INFO     Training average positive_sample_loss at step 685600: 0.150636\n",
      "2022-11-09 00:13:46,786 INFO     Training average negative_sample_loss at step 685600: 0.138808\n",
      "2022-11-09 00:13:46,786 INFO     Training average loss at step 685600: 0.144722\n",
      "2022-11-09 00:13:54,520 INFO     Training average positive_sample_loss at step 685700: 0.145163\n",
      "2022-11-09 00:13:54,521 INFO     Training average negative_sample_loss at step 685700: 0.138888\n",
      "2022-11-09 00:13:54,521 INFO     Training average loss at step 685700: 0.142025\n",
      "2022-11-09 00:14:00,911 INFO     Training average positive_sample_loss at step 685800: 0.151678\n",
      "2022-11-09 00:14:00,911 INFO     Training average negative_sample_loss at step 685800: 0.138237\n",
      "2022-11-09 00:14:00,911 INFO     Training average loss at step 685800: 0.144957\n",
      "2022-11-09 00:14:07,283 INFO     Training average positive_sample_loss at step 685900: 0.146340\n",
      "2022-11-09 00:14:07,283 INFO     Training average negative_sample_loss at step 685900: 0.140568\n",
      "2022-11-09 00:14:07,283 INFO     Training average loss at step 685900: 0.143454\n",
      "2022-11-09 00:14:13,667 INFO     Training average positive_sample_loss at step 686000: 0.155741\n",
      "2022-11-09 00:14:13,667 INFO     Training average negative_sample_loss at step 686000: 0.136016\n",
      "2022-11-09 00:14:13,667 INFO     Training average loss at step 686000: 0.145879\n",
      "2022-11-09 00:14:20,053 INFO     Training average positive_sample_loss at step 686100: 0.152527\n",
      "2022-11-09 00:14:20,053 INFO     Training average negative_sample_loss at step 686100: 0.139909\n",
      "2022-11-09 00:14:20,053 INFO     Training average loss at step 686100: 0.146218\n",
      "2022-11-09 00:14:26,430 INFO     Training average positive_sample_loss at step 686200: 0.145517\n",
      "2022-11-09 00:14:26,430 INFO     Training average negative_sample_loss at step 686200: 0.138955\n",
      "2022-11-09 00:14:26,430 INFO     Training average loss at step 686200: 0.142236\n",
      "2022-11-09 00:14:32,807 INFO     Training average positive_sample_loss at step 686300: 0.148091\n",
      "2022-11-09 00:14:32,808 INFO     Training average negative_sample_loss at step 686300: 0.140173\n",
      "2022-11-09 00:14:32,808 INFO     Training average loss at step 686300: 0.144132\n",
      "2022-11-09 00:14:39,186 INFO     Training average positive_sample_loss at step 686400: 0.150619\n",
      "2022-11-09 00:14:39,186 INFO     Training average negative_sample_loss at step 686400: 0.142495\n",
      "2022-11-09 00:14:39,186 INFO     Training average loss at step 686400: 0.146557\n",
      "2022-11-09 00:14:44,282 INFO     Training average positive_sample_loss at step 686500: 0.147429\n",
      "2022-11-09 00:14:44,282 INFO     Training average negative_sample_loss at step 686500: 0.141490\n",
      "2022-11-09 00:14:44,282 INFO     Training average loss at step 686500: 0.144459\n",
      "2022-11-09 00:14:50,704 INFO     Training average positive_sample_loss at step 686600: 0.150703\n",
      "2022-11-09 00:14:50,705 INFO     Training average negative_sample_loss at step 686600: 0.133703\n",
      "2022-11-09 00:14:50,705 INFO     Training average loss at step 686600: 0.142203\n",
      "2022-11-09 00:14:57,091 INFO     Training average positive_sample_loss at step 686700: 0.150683\n",
      "2022-11-09 00:14:57,091 INFO     Training average negative_sample_loss at step 686700: 0.143615\n",
      "2022-11-09 00:14:57,091 INFO     Training average loss at step 686700: 0.147149\n",
      "2022-11-09 00:15:03,452 INFO     Training average positive_sample_loss at step 686800: 0.159310\n",
      "2022-11-09 00:15:03,452 INFO     Training average negative_sample_loss at step 686800: 0.142447\n",
      "2022-11-09 00:15:03,452 INFO     Training average loss at step 686800: 0.150879\n",
      "2022-11-09 00:15:09,838 INFO     Training average positive_sample_loss at step 686900: 0.154807\n",
      "2022-11-09 00:15:09,838 INFO     Training average negative_sample_loss at step 686900: 0.143150\n",
      "2022-11-09 00:15:09,838 INFO     Training average loss at step 686900: 0.148978\n",
      "2022-11-09 00:15:16,209 INFO     Training average positive_sample_loss at step 687000: 0.148621\n",
      "2022-11-09 00:15:16,209 INFO     Training average negative_sample_loss at step 687000: 0.140731\n",
      "2022-11-09 00:15:16,209 INFO     Training average loss at step 687000: 0.144676\n",
      "2022-11-09 00:15:22,613 INFO     Training average positive_sample_loss at step 687100: 0.150327\n",
      "2022-11-09 00:15:22,613 INFO     Training average negative_sample_loss at step 687100: 0.140160\n",
      "2022-11-09 00:15:22,613 INFO     Training average loss at step 687100: 0.145244\n",
      "2022-11-09 00:15:29,024 INFO     Training average positive_sample_loss at step 687200: 0.153410\n",
      "2022-11-09 00:15:29,024 INFO     Training average negative_sample_loss at step 687200: 0.142061\n",
      "2022-11-09 00:15:29,024 INFO     Training average loss at step 687200: 0.147736\n",
      "2022-11-09 00:15:35,400 INFO     Training average positive_sample_loss at step 687300: 0.153102\n",
      "2022-11-09 00:15:35,400 INFO     Training average negative_sample_loss at step 687300: 0.138467\n",
      "2022-11-09 00:15:35,400 INFO     Training average loss at step 687300: 0.145784\n",
      "2022-11-09 00:15:41,788 INFO     Training average positive_sample_loss at step 687400: 0.150289\n",
      "2022-11-09 00:15:41,789 INFO     Training average negative_sample_loss at step 687400: 0.143339\n",
      "2022-11-09 00:15:41,789 INFO     Training average loss at step 687400: 0.146814\n",
      "2022-11-09 00:15:48,163 INFO     Training average positive_sample_loss at step 687500: 0.151040\n",
      "2022-11-09 00:15:48,163 INFO     Training average negative_sample_loss at step 687500: 0.142608\n",
      "2022-11-09 00:15:48,163 INFO     Training average loss at step 687500: 0.146824\n",
      "2022-11-09 00:15:54,543 INFO     Training average positive_sample_loss at step 687600: 0.146735\n",
      "2022-11-09 00:15:54,543 INFO     Training average negative_sample_loss at step 687600: 0.142705\n",
      "2022-11-09 00:15:54,543 INFO     Training average loss at step 687600: 0.144720\n",
      "2022-11-09 00:16:00,909 INFO     Training average positive_sample_loss at step 687700: 0.156018\n",
      "2022-11-09 00:16:00,909 INFO     Training average negative_sample_loss at step 687700: 0.139899\n",
      "2022-11-09 00:16:00,909 INFO     Training average loss at step 687700: 0.147959\n",
      "2022-11-09 00:16:07,267 INFO     Training average positive_sample_loss at step 687800: 0.150643\n",
      "2022-11-09 00:16:07,267 INFO     Training average negative_sample_loss at step 687800: 0.143955\n",
      "2022-11-09 00:16:07,267 INFO     Training average loss at step 687800: 0.147299\n",
      "2022-11-09 00:16:13,619 INFO     Training average positive_sample_loss at step 687900: 0.154616\n",
      "2022-11-09 00:16:13,619 INFO     Training average negative_sample_loss at step 687900: 0.141746\n",
      "2022-11-09 00:16:13,619 INFO     Training average loss at step 687900: 0.148181\n",
      "2022-11-09 00:16:19,985 INFO     Training average positive_sample_loss at step 688000: 0.150162\n",
      "2022-11-09 00:16:19,986 INFO     Training average negative_sample_loss at step 688000: 0.143082\n",
      "2022-11-09 00:16:19,986 INFO     Training average loss at step 688000: 0.146622\n",
      "2022-11-09 00:16:26,344 INFO     Training average positive_sample_loss at step 688100: 0.151985\n",
      "2022-11-09 00:16:26,345 INFO     Training average negative_sample_loss at step 688100: 0.143659\n",
      "2022-11-09 00:16:26,345 INFO     Training average loss at step 688100: 0.147822\n",
      "2022-11-09 00:16:32,708 INFO     Training average positive_sample_loss at step 688200: 0.147912\n",
      "2022-11-09 00:16:32,708 INFO     Training average negative_sample_loss at step 688200: 0.141098\n",
      "2022-11-09 00:16:32,708 INFO     Training average loss at step 688200: 0.144505\n",
      "2022-11-09 00:16:39,084 INFO     Training average positive_sample_loss at step 688300: 0.151854\n",
      "2022-11-09 00:16:39,084 INFO     Training average negative_sample_loss at step 688300: 0.143000\n",
      "2022-11-09 00:16:39,084 INFO     Training average loss at step 688300: 0.147427\n",
      "2022-11-09 00:16:45,464 INFO     Training average positive_sample_loss at step 688400: 0.154026\n",
      "2022-11-09 00:16:45,464 INFO     Training average negative_sample_loss at step 688400: 0.137064\n",
      "2022-11-09 00:16:45,464 INFO     Training average loss at step 688400: 0.145545\n",
      "2022-11-09 00:16:51,841 INFO     Training average positive_sample_loss at step 688500: 0.147377\n",
      "2022-11-09 00:16:51,841 INFO     Training average negative_sample_loss at step 688500: 0.144268\n",
      "2022-11-09 00:16:51,841 INFO     Training average loss at step 688500: 0.145823\n",
      "2022-11-09 00:16:58,233 INFO     Training average positive_sample_loss at step 688600: 0.151542\n",
      "2022-11-09 00:16:58,233 INFO     Training average negative_sample_loss at step 688600: 0.143178\n",
      "2022-11-09 00:16:58,233 INFO     Training average loss at step 688600: 0.147360\n",
      "2022-11-09 00:17:04,602 INFO     Training average positive_sample_loss at step 688700: 0.154530\n",
      "2022-11-09 00:17:04,602 INFO     Training average negative_sample_loss at step 688700: 0.140018\n",
      "2022-11-09 00:17:04,602 INFO     Training average loss at step 688700: 0.147274\n",
      "2022-11-09 00:17:10,976 INFO     Training average positive_sample_loss at step 688800: 0.152408\n",
      "2022-11-09 00:17:10,977 INFO     Training average negative_sample_loss at step 688800: 0.139732\n",
      "2022-11-09 00:17:10,977 INFO     Training average loss at step 688800: 0.146070\n",
      "2022-11-09 00:17:17,369 INFO     Training average positive_sample_loss at step 688900: 0.149214\n",
      "2022-11-09 00:17:17,369 INFO     Training average negative_sample_loss at step 688900: 0.139101\n",
      "2022-11-09 00:17:17,370 INFO     Training average loss at step 688900: 0.144158\n",
      "2022-11-09 00:17:23,740 INFO     Training average positive_sample_loss at step 689000: 0.148500\n",
      "2022-11-09 00:17:23,740 INFO     Training average negative_sample_loss at step 689000: 0.139707\n",
      "2022-11-09 00:17:23,740 INFO     Training average loss at step 689000: 0.144103\n",
      "2022-11-09 00:17:30,111 INFO     Training average positive_sample_loss at step 689100: 0.152904\n",
      "2022-11-09 00:17:30,111 INFO     Training average negative_sample_loss at step 689100: 0.141433\n",
      "2022-11-09 00:17:30,111 INFO     Training average loss at step 689100: 0.147168\n",
      "2022-11-09 00:17:36,461 INFO     Training average positive_sample_loss at step 689200: 0.152722\n",
      "2022-11-09 00:17:36,461 INFO     Training average negative_sample_loss at step 689200: 0.139368\n",
      "2022-11-09 00:17:36,461 INFO     Training average loss at step 689200: 0.146045\n",
      "2022-11-09 00:17:42,815 INFO     Training average positive_sample_loss at step 689300: 0.155412\n",
      "2022-11-09 00:17:42,815 INFO     Training average negative_sample_loss at step 689300: 0.140565\n",
      "2022-11-09 00:17:42,815 INFO     Training average loss at step 689300: 0.147989\n",
      "2022-11-09 00:17:49,168 INFO     Training average positive_sample_loss at step 689400: 0.149515\n",
      "2022-11-09 00:17:49,168 INFO     Training average negative_sample_loss at step 689400: 0.140532\n",
      "2022-11-09 00:17:49,168 INFO     Training average loss at step 689400: 0.145024\n",
      "2022-11-09 00:17:55,534 INFO     Training average positive_sample_loss at step 689500: 0.152898\n",
      "2022-11-09 00:17:55,534 INFO     Training average negative_sample_loss at step 689500: 0.138856\n",
      "2022-11-09 00:17:55,534 INFO     Training average loss at step 689500: 0.145877\n",
      "2022-11-09 00:18:01,883 INFO     Training average positive_sample_loss at step 689600: 0.146237\n",
      "2022-11-09 00:18:01,883 INFO     Training average negative_sample_loss at step 689600: 0.141474\n",
      "2022-11-09 00:18:01,884 INFO     Training average loss at step 689600: 0.143855\n",
      "2022-11-09 00:18:08,254 INFO     Training average positive_sample_loss at step 689700: 0.150873\n",
      "2022-11-09 00:18:08,254 INFO     Training average negative_sample_loss at step 689700: 0.141469\n",
      "2022-11-09 00:18:08,254 INFO     Training average loss at step 689700: 0.146171\n",
      "2022-11-09 00:18:14,621 INFO     Training average positive_sample_loss at step 689800: 0.147800\n",
      "2022-11-09 00:18:14,621 INFO     Training average negative_sample_loss at step 689800: 0.140704\n",
      "2022-11-09 00:18:14,621 INFO     Training average loss at step 689800: 0.144252\n",
      "2022-11-09 00:18:21,972 INFO     Training average positive_sample_loss at step 689900: 0.150975\n",
      "2022-11-09 00:18:21,972 INFO     Training average negative_sample_loss at step 689900: 0.144279\n",
      "2022-11-09 00:18:21,972 INFO     Training average loss at step 689900: 0.147627\n",
      "2022-11-09 00:18:32,043 INFO     Training average positive_sample_loss at step 690000: 0.151352\n",
      "2022-11-09 00:18:32,044 INFO     Training average negative_sample_loss at step 690000: 0.141775\n",
      "2022-11-09 00:18:32,044 INFO     Training average loss at step 690000: 0.146564\n",
      "2022-11-09 00:18:38,407 INFO     Training average positive_sample_loss at step 690100: 0.150763\n",
      "2022-11-09 00:18:38,407 INFO     Training average negative_sample_loss at step 690100: 0.145143\n",
      "2022-11-09 00:18:38,407 INFO     Training average loss at step 690100: 0.147953\n",
      "2022-11-09 00:18:44,759 INFO     Training average positive_sample_loss at step 690200: 0.151803\n",
      "2022-11-09 00:18:44,759 INFO     Training average negative_sample_loss at step 690200: 0.137347\n",
      "2022-11-09 00:18:44,759 INFO     Training average loss at step 690200: 0.144575\n",
      "2022-11-09 00:18:51,120 INFO     Training average positive_sample_loss at step 690300: 0.147993\n",
      "2022-11-09 00:18:51,120 INFO     Training average negative_sample_loss at step 690300: 0.141532\n",
      "2022-11-09 00:18:51,120 INFO     Training average loss at step 690300: 0.144763\n",
      "2022-11-09 00:18:58,856 INFO     Training average positive_sample_loss at step 690400: 0.153536\n",
      "2022-11-09 00:18:58,857 INFO     Training average negative_sample_loss at step 690400: 0.142602\n",
      "2022-11-09 00:18:58,857 INFO     Training average loss at step 690400: 0.148069\n",
      "2022-11-09 00:19:05,250 INFO     Training average positive_sample_loss at step 690500: 0.150948\n",
      "2022-11-09 00:19:05,250 INFO     Training average negative_sample_loss at step 690500: 0.137990\n",
      "2022-11-09 00:19:05,251 INFO     Training average loss at step 690500: 0.144469\n",
      "2022-11-09 00:19:11,631 INFO     Training average positive_sample_loss at step 690600: 0.157599\n",
      "2022-11-09 00:19:11,631 INFO     Training average negative_sample_loss at step 690600: 0.144092\n",
      "2022-11-09 00:19:11,631 INFO     Training average loss at step 690600: 0.150846\n",
      "2022-11-09 00:19:18,012 INFO     Training average positive_sample_loss at step 690700: 0.150419\n",
      "2022-11-09 00:19:18,012 INFO     Training average negative_sample_loss at step 690700: 0.141931\n",
      "2022-11-09 00:19:18,012 INFO     Training average loss at step 690700: 0.146175\n",
      "2022-11-09 00:19:24,399 INFO     Training average positive_sample_loss at step 690800: 0.155706\n",
      "2022-11-09 00:19:24,399 INFO     Training average negative_sample_loss at step 690800: 0.141533\n",
      "2022-11-09 00:19:24,399 INFO     Training average loss at step 690800: 0.148620\n",
      "2022-11-09 00:19:30,799 INFO     Training average positive_sample_loss at step 690900: 0.153815\n",
      "2022-11-09 00:19:30,799 INFO     Training average negative_sample_loss at step 690900: 0.144157\n",
      "2022-11-09 00:19:30,799 INFO     Training average loss at step 690900: 0.148986\n",
      "2022-11-09 00:19:37,194 INFO     Training average positive_sample_loss at step 691000: 0.151467\n",
      "2022-11-09 00:19:37,194 INFO     Training average negative_sample_loss at step 691000: 0.140787\n",
      "2022-11-09 00:19:37,194 INFO     Training average loss at step 691000: 0.146127\n",
      "2022-11-09 00:19:43,565 INFO     Training average positive_sample_loss at step 691100: 0.155252\n",
      "2022-11-09 00:19:43,565 INFO     Training average negative_sample_loss at step 691100: 0.137910\n",
      "2022-11-09 00:19:43,565 INFO     Training average loss at step 691100: 0.146581\n",
      "2022-11-09 00:19:49,962 INFO     Training average positive_sample_loss at step 691200: 0.148886\n",
      "2022-11-09 00:19:49,962 INFO     Training average negative_sample_loss at step 691200: 0.140876\n",
      "2022-11-09 00:19:49,962 INFO     Training average loss at step 691200: 0.144881\n",
      "2022-11-09 00:19:56,341 INFO     Training average positive_sample_loss at step 691300: 0.150375\n",
      "2022-11-09 00:19:56,341 INFO     Training average negative_sample_loss at step 691300: 0.141359\n",
      "2022-11-09 00:19:56,341 INFO     Training average loss at step 691300: 0.145867\n",
      "2022-11-09 00:20:02,713 INFO     Training average positive_sample_loss at step 691400: 0.151617\n",
      "2022-11-09 00:20:02,713 INFO     Training average negative_sample_loss at step 691400: 0.142973\n",
      "2022-11-09 00:20:02,713 INFO     Training average loss at step 691400: 0.147295\n",
      "2022-11-09 00:20:09,080 INFO     Training average positive_sample_loss at step 691500: 0.150220\n",
      "2022-11-09 00:20:09,080 INFO     Training average negative_sample_loss at step 691500: 0.137024\n",
      "2022-11-09 00:20:09,080 INFO     Training average loss at step 691500: 0.143622\n",
      "2022-11-09 00:20:15,483 INFO     Training average positive_sample_loss at step 691600: 0.156635\n",
      "2022-11-09 00:20:15,483 INFO     Training average negative_sample_loss at step 691600: 0.143775\n",
      "2022-11-09 00:20:15,483 INFO     Training average loss at step 691600: 0.150205\n",
      "2022-11-09 00:20:21,857 INFO     Training average positive_sample_loss at step 691700: 0.155868\n",
      "2022-11-09 00:20:21,857 INFO     Training average negative_sample_loss at step 691700: 0.139633\n",
      "2022-11-09 00:20:21,857 INFO     Training average loss at step 691700: 0.147751\n",
      "2022-11-09 00:20:28,208 INFO     Training average positive_sample_loss at step 691800: 0.147456\n",
      "2022-11-09 00:20:28,208 INFO     Training average negative_sample_loss at step 691800: 0.141513\n",
      "2022-11-09 00:20:28,208 INFO     Training average loss at step 691800: 0.144485\n",
      "2022-11-09 00:20:34,598 INFO     Training average positive_sample_loss at step 691900: 0.156338\n",
      "2022-11-09 00:20:34,598 INFO     Training average negative_sample_loss at step 691900: 0.144928\n",
      "2022-11-09 00:20:34,598 INFO     Training average loss at step 691900: 0.150633\n",
      "2022-11-09 00:20:39,697 INFO     Training average positive_sample_loss at step 692000: 0.154451\n",
      "2022-11-09 00:20:39,697 INFO     Training average negative_sample_loss at step 692000: 0.143972\n",
      "2022-11-09 00:20:39,697 INFO     Training average loss at step 692000: 0.149212\n",
      "2022-11-09 00:20:45,956 INFO     Training average positive_sample_loss at step 692100: 0.152367\n",
      "2022-11-09 00:20:45,956 INFO     Training average negative_sample_loss at step 692100: 0.144317\n",
      "2022-11-09 00:20:45,956 INFO     Training average loss at step 692100: 0.148342\n",
      "2022-11-09 00:20:52,333 INFO     Training average positive_sample_loss at step 692200: 0.151934\n",
      "2022-11-09 00:20:52,334 INFO     Training average negative_sample_loss at step 692200: 0.139233\n",
      "2022-11-09 00:20:52,334 INFO     Training average loss at step 692200: 0.145584\n",
      "2022-11-09 00:20:58,684 INFO     Training average positive_sample_loss at step 692300: 0.148925\n",
      "2022-11-09 00:20:58,684 INFO     Training average negative_sample_loss at step 692300: 0.140033\n",
      "2022-11-09 00:20:58,684 INFO     Training average loss at step 692300: 0.144479\n",
      "2022-11-09 00:21:05,048 INFO     Training average positive_sample_loss at step 692400: 0.155119\n",
      "2022-11-09 00:21:05,048 INFO     Training average negative_sample_loss at step 692400: 0.142292\n",
      "2022-11-09 00:21:05,048 INFO     Training average loss at step 692400: 0.148706\n",
      "2022-11-09 00:21:11,419 INFO     Training average positive_sample_loss at step 692500: 0.147777\n",
      "2022-11-09 00:21:11,419 INFO     Training average negative_sample_loss at step 692500: 0.141611\n",
      "2022-11-09 00:21:11,419 INFO     Training average loss at step 692500: 0.144694\n",
      "2022-11-09 00:21:17,797 INFO     Training average positive_sample_loss at step 692600: 0.151790\n",
      "2022-11-09 00:21:17,797 INFO     Training average negative_sample_loss at step 692600: 0.143161\n",
      "2022-11-09 00:21:17,797 INFO     Training average loss at step 692600: 0.147476\n",
      "2022-11-09 00:21:24,169 INFO     Training average positive_sample_loss at step 692700: 0.151854\n",
      "2022-11-09 00:21:24,169 INFO     Training average negative_sample_loss at step 692700: 0.142547\n",
      "2022-11-09 00:21:24,169 INFO     Training average loss at step 692700: 0.147201\n",
      "2022-11-09 00:21:30,534 INFO     Training average positive_sample_loss at step 692800: 0.153759\n",
      "2022-11-09 00:21:30,534 INFO     Training average negative_sample_loss at step 692800: 0.138356\n",
      "2022-11-09 00:21:30,535 INFO     Training average loss at step 692800: 0.146057\n",
      "2022-11-09 00:21:36,930 INFO     Training average positive_sample_loss at step 692900: 0.146709\n",
      "2022-11-09 00:21:36,930 INFO     Training average negative_sample_loss at step 692900: 0.138422\n",
      "2022-11-09 00:21:36,930 INFO     Training average loss at step 692900: 0.142565\n",
      "2022-11-09 00:21:43,291 INFO     Training average positive_sample_loss at step 693000: 0.153674\n",
      "2022-11-09 00:21:43,291 INFO     Training average negative_sample_loss at step 693000: 0.140186\n",
      "2022-11-09 00:21:43,291 INFO     Training average loss at step 693000: 0.146930\n",
      "2022-11-09 00:21:49,659 INFO     Training average positive_sample_loss at step 693100: 0.151154\n",
      "2022-11-09 00:21:49,660 INFO     Training average negative_sample_loss at step 693100: 0.141937\n",
      "2022-11-09 00:21:49,660 INFO     Training average loss at step 693100: 0.146545\n",
      "2022-11-09 00:21:56,039 INFO     Training average positive_sample_loss at step 693200: 0.152372\n",
      "2022-11-09 00:21:56,039 INFO     Training average negative_sample_loss at step 693200: 0.148322\n",
      "2022-11-09 00:21:56,040 INFO     Training average loss at step 693200: 0.150347\n",
      "2022-11-09 00:22:02,393 INFO     Training average positive_sample_loss at step 693300: 0.151862\n",
      "2022-11-09 00:22:02,393 INFO     Training average negative_sample_loss at step 693300: 0.140197\n",
      "2022-11-09 00:22:02,393 INFO     Training average loss at step 693300: 0.146029\n",
      "2022-11-09 00:22:08,776 INFO     Training average positive_sample_loss at step 693400: 0.156207\n",
      "2022-11-09 00:22:08,776 INFO     Training average negative_sample_loss at step 693400: 0.141268\n",
      "2022-11-09 00:22:08,776 INFO     Training average loss at step 693400: 0.148737\n",
      "2022-11-09 00:22:15,164 INFO     Training average positive_sample_loss at step 693500: 0.153595\n",
      "2022-11-09 00:22:15,165 INFO     Training average negative_sample_loss at step 693500: 0.142443\n",
      "2022-11-09 00:22:15,165 INFO     Training average loss at step 693500: 0.148019\n",
      "2022-11-09 00:22:21,551 INFO     Training average positive_sample_loss at step 693600: 0.144823\n",
      "2022-11-09 00:22:21,551 INFO     Training average negative_sample_loss at step 693600: 0.138555\n",
      "2022-11-09 00:22:21,551 INFO     Training average loss at step 693600: 0.141689\n",
      "2022-11-09 00:22:27,932 INFO     Training average positive_sample_loss at step 693700: 0.148612\n",
      "2022-11-09 00:22:27,932 INFO     Training average negative_sample_loss at step 693700: 0.138065\n",
      "2022-11-09 00:22:27,932 INFO     Training average loss at step 693700: 0.143339\n",
      "2022-11-09 00:22:34,317 INFO     Training average positive_sample_loss at step 693800: 0.150077\n",
      "2022-11-09 00:22:34,317 INFO     Training average negative_sample_loss at step 693800: 0.143073\n",
      "2022-11-09 00:22:34,317 INFO     Training average loss at step 693800: 0.146575\n",
      "2022-11-09 00:22:40,697 INFO     Training average positive_sample_loss at step 693900: 0.154506\n",
      "2022-11-09 00:22:40,697 INFO     Training average negative_sample_loss at step 693900: 0.138825\n",
      "2022-11-09 00:22:40,697 INFO     Training average loss at step 693900: 0.146665\n",
      "2022-11-09 00:22:47,074 INFO     Training average positive_sample_loss at step 694000: 0.154059\n",
      "2022-11-09 00:22:47,075 INFO     Training average negative_sample_loss at step 694000: 0.144045\n",
      "2022-11-09 00:22:47,075 INFO     Training average loss at step 694000: 0.149052\n",
      "2022-11-09 00:22:53,474 INFO     Training average positive_sample_loss at step 694100: 0.149204\n",
      "2022-11-09 00:22:53,474 INFO     Training average negative_sample_loss at step 694100: 0.135979\n",
      "2022-11-09 00:22:53,474 INFO     Training average loss at step 694100: 0.142591\n",
      "2022-11-09 00:22:59,868 INFO     Training average positive_sample_loss at step 694200: 0.152789\n",
      "2022-11-09 00:22:59,868 INFO     Training average negative_sample_loss at step 694200: 0.142873\n",
      "2022-11-09 00:22:59,868 INFO     Training average loss at step 694200: 0.147831\n",
      "2022-11-09 00:23:06,252 INFO     Training average positive_sample_loss at step 694300: 0.153861\n",
      "2022-11-09 00:23:06,252 INFO     Training average negative_sample_loss at step 694300: 0.142017\n",
      "2022-11-09 00:23:06,252 INFO     Training average loss at step 694300: 0.147939\n",
      "2022-11-09 00:23:12,628 INFO     Training average positive_sample_loss at step 694400: 0.153037\n",
      "2022-11-09 00:23:12,628 INFO     Training average negative_sample_loss at step 694400: 0.142483\n",
      "2022-11-09 00:23:12,628 INFO     Training average loss at step 694400: 0.147760\n",
      "2022-11-09 00:23:19,887 INFO     Training average positive_sample_loss at step 694500: 0.155976\n",
      "2022-11-09 00:23:19,887 INFO     Training average negative_sample_loss at step 694500: 0.143495\n",
      "2022-11-09 00:23:19,888 INFO     Training average loss at step 694500: 0.149735\n",
      "2022-11-09 00:23:26,880 INFO     Training average positive_sample_loss at step 694600: 0.154870\n",
      "2022-11-09 00:23:26,881 INFO     Training average negative_sample_loss at step 694600: 0.140509\n",
      "2022-11-09 00:23:26,881 INFO     Training average loss at step 694600: 0.147690\n",
      "2022-11-09 00:23:33,779 INFO     Training average positive_sample_loss at step 694700: 0.153869\n",
      "2022-11-09 00:23:33,779 INFO     Training average negative_sample_loss at step 694700: 0.139553\n",
      "2022-11-09 00:23:33,779 INFO     Training average loss at step 694700: 0.146711\n",
      "2022-11-09 00:23:40,139 INFO     Training average positive_sample_loss at step 694800: 0.153671\n",
      "2022-11-09 00:23:40,139 INFO     Training average negative_sample_loss at step 694800: 0.146554\n",
      "2022-11-09 00:23:40,139 INFO     Training average loss at step 694800: 0.150113\n",
      "2022-11-09 00:23:46,492 INFO     Training average positive_sample_loss at step 694900: 0.152947\n",
      "2022-11-09 00:23:46,492 INFO     Training average negative_sample_loss at step 694900: 0.144598\n",
      "2022-11-09 00:23:46,492 INFO     Training average loss at step 694900: 0.148772\n",
      "2022-11-09 00:23:52,851 INFO     Training average positive_sample_loss at step 695000: 0.153983\n",
      "2022-11-09 00:23:52,851 INFO     Training average negative_sample_loss at step 695000: 0.144300\n",
      "2022-11-09 00:23:52,851 INFO     Training average loss at step 695000: 0.149141\n",
      "2022-11-09 00:24:00,582 INFO     Training average positive_sample_loss at step 695100: 0.151761\n",
      "2022-11-09 00:24:00,582 INFO     Training average negative_sample_loss at step 695100: 0.143381\n",
      "2022-11-09 00:24:00,582 INFO     Training average loss at step 695100: 0.147571\n",
      "2022-11-09 00:24:06,963 INFO     Training average positive_sample_loss at step 695200: 0.148773\n",
      "2022-11-09 00:24:06,963 INFO     Training average negative_sample_loss at step 695200: 0.140341\n",
      "2022-11-09 00:24:06,963 INFO     Training average loss at step 695200: 0.144557\n",
      "2022-11-09 00:24:13,352 INFO     Training average positive_sample_loss at step 695300: 0.148743\n",
      "2022-11-09 00:24:13,352 INFO     Training average negative_sample_loss at step 695300: 0.144973\n",
      "2022-11-09 00:24:13,352 INFO     Training average loss at step 695300: 0.146858\n",
      "2022-11-09 00:24:19,756 INFO     Training average positive_sample_loss at step 695400: 0.151901\n",
      "2022-11-09 00:24:19,756 INFO     Training average negative_sample_loss at step 695400: 0.141632\n",
      "2022-11-09 00:24:19,756 INFO     Training average loss at step 695400: 0.146767\n",
      "2022-11-09 00:24:26,144 INFO     Training average positive_sample_loss at step 695500: 0.148329\n",
      "2022-11-09 00:24:26,144 INFO     Training average negative_sample_loss at step 695500: 0.144664\n",
      "2022-11-09 00:24:26,144 INFO     Training average loss at step 695500: 0.146497\n",
      "2022-11-09 00:24:32,526 INFO     Training average positive_sample_loss at step 695600: 0.151273\n",
      "2022-11-09 00:24:32,526 INFO     Training average negative_sample_loss at step 695600: 0.140384\n",
      "2022-11-09 00:24:32,526 INFO     Training average loss at step 695600: 0.145828\n",
      "2022-11-09 00:24:38,896 INFO     Training average positive_sample_loss at step 695700: 0.161627\n",
      "2022-11-09 00:24:38,896 INFO     Training average negative_sample_loss at step 695700: 0.143580\n",
      "2022-11-09 00:24:38,896 INFO     Training average loss at step 695700: 0.152604\n",
      "2022-11-09 00:24:45,249 INFO     Training average positive_sample_loss at step 695800: 0.148587\n",
      "2022-11-09 00:24:45,249 INFO     Training average negative_sample_loss at step 695800: 0.140607\n",
      "2022-11-09 00:24:45,249 INFO     Training average loss at step 695800: 0.144597\n",
      "2022-11-09 00:24:51,625 INFO     Training average positive_sample_loss at step 695900: 0.147764\n",
      "2022-11-09 00:24:51,625 INFO     Training average negative_sample_loss at step 695900: 0.137096\n",
      "2022-11-09 00:24:51,625 INFO     Training average loss at step 695900: 0.142430\n",
      "2022-11-09 00:24:58,006 INFO     Training average positive_sample_loss at step 696000: 0.146552\n",
      "2022-11-09 00:24:58,006 INFO     Training average negative_sample_loss at step 696000: 0.134883\n",
      "2022-11-09 00:24:58,006 INFO     Training average loss at step 696000: 0.140718\n",
      "2022-11-09 00:25:04,399 INFO     Training average positive_sample_loss at step 696100: 0.150367\n",
      "2022-11-09 00:25:04,399 INFO     Training average negative_sample_loss at step 696100: 0.139041\n",
      "2022-11-09 00:25:04,399 INFO     Training average loss at step 696100: 0.144704\n",
      "2022-11-09 00:25:10,783 INFO     Training average positive_sample_loss at step 696200: 0.151767\n",
      "2022-11-09 00:25:10,783 INFO     Training average negative_sample_loss at step 696200: 0.139329\n",
      "2022-11-09 00:25:10,783 INFO     Training average loss at step 696200: 0.145548\n",
      "2022-11-09 00:25:17,151 INFO     Training average positive_sample_loss at step 696300: 0.150340\n",
      "2022-11-09 00:25:17,151 INFO     Training average negative_sample_loss at step 696300: 0.138978\n",
      "2022-11-09 00:25:17,151 INFO     Training average loss at step 696300: 0.144659\n",
      "2022-11-09 00:25:23,523 INFO     Training average positive_sample_loss at step 696400: 0.151508\n",
      "2022-11-09 00:25:23,523 INFO     Training average negative_sample_loss at step 696400: 0.142295\n",
      "2022-11-09 00:25:23,523 INFO     Training average loss at step 696400: 0.146902\n",
      "2022-11-09 00:25:29,903 INFO     Training average positive_sample_loss at step 696500: 0.153389\n",
      "2022-11-09 00:25:29,903 INFO     Training average negative_sample_loss at step 696500: 0.138579\n",
      "2022-11-09 00:25:29,903 INFO     Training average loss at step 696500: 0.145984\n",
      "2022-11-09 00:25:36,294 INFO     Training average positive_sample_loss at step 696600: 0.154414\n",
      "2022-11-09 00:25:36,294 INFO     Training average negative_sample_loss at step 696600: 0.140244\n",
      "2022-11-09 00:25:36,294 INFO     Training average loss at step 696600: 0.147329\n",
      "2022-11-09 00:25:42,668 INFO     Training average positive_sample_loss at step 696700: 0.153004\n",
      "2022-11-09 00:25:42,668 INFO     Training average negative_sample_loss at step 696700: 0.139480\n",
      "2022-11-09 00:25:42,668 INFO     Training average loss at step 696700: 0.146242\n",
      "2022-11-09 00:25:49,041 INFO     Training average positive_sample_loss at step 696800: 0.150336\n",
      "2022-11-09 00:25:49,041 INFO     Training average negative_sample_loss at step 696800: 0.138262\n",
      "2022-11-09 00:25:49,041 INFO     Training average loss at step 696800: 0.144299\n",
      "2022-11-09 00:25:55,424 INFO     Training average positive_sample_loss at step 696900: 0.150800\n",
      "2022-11-09 00:25:55,424 INFO     Training average negative_sample_loss at step 696900: 0.145069\n",
      "2022-11-09 00:25:55,424 INFO     Training average loss at step 696900: 0.147935\n",
      "2022-11-09 00:26:01,830 INFO     Training average positive_sample_loss at step 697000: 0.154242\n",
      "2022-11-09 00:26:01,830 INFO     Training average negative_sample_loss at step 697000: 0.142731\n",
      "2022-11-09 00:26:01,831 INFO     Training average loss at step 697000: 0.148487\n",
      "2022-11-09 00:26:08,215 INFO     Training average positive_sample_loss at step 697100: 0.153683\n",
      "2022-11-09 00:26:08,215 INFO     Training average negative_sample_loss at step 697100: 0.140963\n",
      "2022-11-09 00:26:08,215 INFO     Training average loss at step 697100: 0.147323\n",
      "2022-11-09 00:26:14,566 INFO     Training average positive_sample_loss at step 697200: 0.150424\n",
      "2022-11-09 00:26:14,566 INFO     Training average negative_sample_loss at step 697200: 0.142826\n",
      "2022-11-09 00:26:14,566 INFO     Training average loss at step 697200: 0.146625\n",
      "2022-11-09 00:26:20,956 INFO     Training average positive_sample_loss at step 697300: 0.155118\n",
      "2022-11-09 00:26:20,956 INFO     Training average negative_sample_loss at step 697300: 0.146083\n",
      "2022-11-09 00:26:20,956 INFO     Training average loss at step 697300: 0.150600\n",
      "2022-11-09 00:26:27,340 INFO     Training average positive_sample_loss at step 697400: 0.150290\n",
      "2022-11-09 00:26:27,340 INFO     Training average negative_sample_loss at step 697400: 0.138690\n",
      "2022-11-09 00:26:27,340 INFO     Training average loss at step 697400: 0.144490\n",
      "2022-11-09 00:26:33,708 INFO     Training average positive_sample_loss at step 697500: 0.148535\n",
      "2022-11-09 00:26:33,708 INFO     Training average negative_sample_loss at step 697500: 0.140843\n",
      "2022-11-09 00:26:33,709 INFO     Training average loss at step 697500: 0.144689\n",
      "2022-11-09 00:26:38,971 INFO     Training average positive_sample_loss at step 697600: 0.150078\n",
      "2022-11-09 00:26:38,971 INFO     Training average negative_sample_loss at step 697600: 0.140684\n",
      "2022-11-09 00:26:38,971 INFO     Training average loss at step 697600: 0.145381\n",
      "2022-11-09 00:26:45,157 INFO     Training average positive_sample_loss at step 697700: 0.153356\n",
      "2022-11-09 00:26:45,157 INFO     Training average negative_sample_loss at step 697700: 0.143444\n",
      "2022-11-09 00:26:45,157 INFO     Training average loss at step 697700: 0.148400\n",
      "2022-11-09 00:26:51,526 INFO     Training average positive_sample_loss at step 697800: 0.148559\n",
      "2022-11-09 00:26:51,526 INFO     Training average negative_sample_loss at step 697800: 0.145032\n",
      "2022-11-09 00:26:51,526 INFO     Training average loss at step 697800: 0.146796\n",
      "2022-11-09 00:26:57,900 INFO     Training average positive_sample_loss at step 697900: 0.152413\n",
      "2022-11-09 00:26:57,900 INFO     Training average negative_sample_loss at step 697900: 0.143290\n",
      "2022-11-09 00:26:57,900 INFO     Training average loss at step 697900: 0.147852\n",
      "2022-11-09 00:27:04,285 INFO     Training average positive_sample_loss at step 698000: 0.149901\n",
      "2022-11-09 00:27:04,285 INFO     Training average negative_sample_loss at step 698000: 0.138566\n",
      "2022-11-09 00:27:04,285 INFO     Training average loss at step 698000: 0.144234\n",
      "2022-11-09 00:27:10,659 INFO     Training average positive_sample_loss at step 698100: 0.155252\n",
      "2022-11-09 00:27:10,659 INFO     Training average negative_sample_loss at step 698100: 0.148407\n",
      "2022-11-09 00:27:10,659 INFO     Training average loss at step 698100: 0.151829\n",
      "2022-11-09 00:27:17,020 INFO     Training average positive_sample_loss at step 698200: 0.150246\n",
      "2022-11-09 00:27:17,020 INFO     Training average negative_sample_loss at step 698200: 0.141307\n",
      "2022-11-09 00:27:17,020 INFO     Training average loss at step 698200: 0.145777\n",
      "2022-11-09 00:27:23,372 INFO     Training average positive_sample_loss at step 698300: 0.150310\n",
      "2022-11-09 00:27:23,372 INFO     Training average negative_sample_loss at step 698300: 0.141079\n",
      "2022-11-09 00:27:23,372 INFO     Training average loss at step 698300: 0.145695\n",
      "2022-11-09 00:27:29,717 INFO     Training average positive_sample_loss at step 698400: 0.154762\n",
      "2022-11-09 00:27:29,717 INFO     Training average negative_sample_loss at step 698400: 0.142083\n",
      "2022-11-09 00:27:29,717 INFO     Training average loss at step 698400: 0.148422\n",
      "2022-11-09 00:27:36,087 INFO     Training average positive_sample_loss at step 698500: 0.152311\n",
      "2022-11-09 00:27:36,087 INFO     Training average negative_sample_loss at step 698500: 0.140815\n",
      "2022-11-09 00:27:36,087 INFO     Training average loss at step 698500: 0.146563\n",
      "2022-11-09 00:27:42,458 INFO     Training average positive_sample_loss at step 698600: 0.150880\n",
      "2022-11-09 00:27:42,459 INFO     Training average negative_sample_loss at step 698600: 0.142894\n",
      "2022-11-09 00:27:42,459 INFO     Training average loss at step 698600: 0.146887\n",
      "2022-11-09 00:27:48,843 INFO     Training average positive_sample_loss at step 698700: 0.152143\n",
      "2022-11-09 00:27:48,843 INFO     Training average negative_sample_loss at step 698700: 0.143947\n",
      "2022-11-09 00:27:48,843 INFO     Training average loss at step 698700: 0.148045\n",
      "2022-11-09 00:27:55,229 INFO     Training average positive_sample_loss at step 698800: 0.150537\n",
      "2022-11-09 00:27:55,230 INFO     Training average negative_sample_loss at step 698800: 0.141880\n",
      "2022-11-09 00:27:55,230 INFO     Training average loss at step 698800: 0.146208\n",
      "2022-11-09 00:28:01,603 INFO     Training average positive_sample_loss at step 698900: 0.155756\n",
      "2022-11-09 00:28:01,603 INFO     Training average negative_sample_loss at step 698900: 0.144295\n",
      "2022-11-09 00:28:01,603 INFO     Training average loss at step 698900: 0.150026\n",
      "2022-11-09 00:28:07,977 INFO     Training average positive_sample_loss at step 699000: 0.152343\n",
      "2022-11-09 00:28:07,977 INFO     Training average negative_sample_loss at step 699000: 0.143287\n",
      "2022-11-09 00:28:07,977 INFO     Training average loss at step 699000: 0.147815\n",
      "2022-11-09 00:28:14,349 INFO     Training average positive_sample_loss at step 699100: 0.158333\n",
      "2022-11-09 00:28:14,349 INFO     Training average negative_sample_loss at step 699100: 0.137921\n",
      "2022-11-09 00:28:14,350 INFO     Training average loss at step 699100: 0.148127\n",
      "2022-11-09 00:28:21,740 INFO     Training average positive_sample_loss at step 699200: 0.150621\n",
      "2022-11-09 00:28:21,740 INFO     Training average negative_sample_loss at step 699200: 0.140201\n",
      "2022-11-09 00:28:21,740 INFO     Training average loss at step 699200: 0.145411\n",
      "2022-11-09 00:28:28,680 INFO     Training average positive_sample_loss at step 699300: 0.147282\n",
      "2022-11-09 00:28:28,680 INFO     Training average negative_sample_loss at step 699300: 0.139456\n",
      "2022-11-09 00:28:28,680 INFO     Training average loss at step 699300: 0.143369\n",
      "2022-11-09 00:28:35,596 INFO     Training average positive_sample_loss at step 699400: 0.156170\n",
      "2022-11-09 00:28:35,596 INFO     Training average negative_sample_loss at step 699400: 0.139123\n",
      "2022-11-09 00:28:35,596 INFO     Training average loss at step 699400: 0.147646\n",
      "2022-11-09 00:28:41,956 INFO     Training average positive_sample_loss at step 699500: 0.150816\n",
      "2022-11-09 00:28:41,956 INFO     Training average negative_sample_loss at step 699500: 0.137990\n",
      "2022-11-09 00:28:41,956 INFO     Training average loss at step 699500: 0.144403\n",
      "2022-11-09 00:28:48,331 INFO     Training average positive_sample_loss at step 699600: 0.150315\n",
      "2022-11-09 00:28:48,331 INFO     Training average negative_sample_loss at step 699600: 0.140873\n",
      "2022-11-09 00:28:48,331 INFO     Training average loss at step 699600: 0.145594\n",
      "2022-11-09 00:28:54,688 INFO     Training average positive_sample_loss at step 699700: 0.152179\n",
      "2022-11-09 00:28:54,689 INFO     Training average negative_sample_loss at step 699700: 0.140857\n",
      "2022-11-09 00:28:54,689 INFO     Training average loss at step 699700: 0.146518\n",
      "2022-11-09 00:29:02,518 INFO     Training average positive_sample_loss at step 699800: 0.154754\n",
      "2022-11-09 00:29:02,518 INFO     Training average negative_sample_loss at step 699800: 0.138881\n",
      "2022-11-09 00:29:02,518 INFO     Training average loss at step 699800: 0.146818\n",
      "2022-11-09 00:29:08,904 INFO     Training average positive_sample_loss at step 699900: 0.153539\n",
      "2022-11-09 00:29:08,904 INFO     Training average negative_sample_loss at step 699900: 0.137482\n",
      "2022-11-09 00:29:08,904 INFO     Training average loss at step 699900: 0.145511\n",
      "2022-11-09 00:29:18,202 INFO     Training average positive_sample_loss at step 700000: 0.151617\n",
      "2022-11-09 00:29:18,203 INFO     Training average negative_sample_loss at step 700000: 0.142900\n",
      "2022-11-09 00:29:18,203 INFO     Training average loss at step 700000: 0.147259\n",
      "2022-11-09 00:29:24,582 INFO     Training average positive_sample_loss at step 700100: 0.146122\n",
      "2022-11-09 00:29:24,582 INFO     Training average negative_sample_loss at step 700100: 0.141483\n",
      "2022-11-09 00:29:24,582 INFO     Training average loss at step 700100: 0.143802\n",
      "2022-11-09 00:29:30,932 INFO     Training average positive_sample_loss at step 700200: 0.154352\n",
      "2022-11-09 00:29:30,932 INFO     Training average negative_sample_loss at step 700200: 0.145513\n",
      "2022-11-09 00:29:30,932 INFO     Training average loss at step 700200: 0.149933\n",
      "2022-11-09 00:29:37,305 INFO     Training average positive_sample_loss at step 700300: 0.148265\n",
      "2022-11-09 00:29:37,305 INFO     Training average negative_sample_loss at step 700300: 0.137865\n",
      "2022-11-09 00:29:37,305 INFO     Training average loss at step 700300: 0.143065\n",
      "2022-11-09 00:29:43,688 INFO     Training average positive_sample_loss at step 700400: 0.150020\n",
      "2022-11-09 00:29:43,689 INFO     Training average negative_sample_loss at step 700400: 0.139137\n",
      "2022-11-09 00:29:43,689 INFO     Training average loss at step 700400: 0.144578\n",
      "2022-11-09 00:29:50,074 INFO     Training average positive_sample_loss at step 700500: 0.152223\n",
      "2022-11-09 00:29:50,074 INFO     Training average negative_sample_loss at step 700500: 0.142437\n",
      "2022-11-09 00:29:50,074 INFO     Training average loss at step 700500: 0.147330\n",
      "2022-11-09 00:29:56,435 INFO     Training average positive_sample_loss at step 700600: 0.149730\n",
      "2022-11-09 00:29:56,435 INFO     Training average negative_sample_loss at step 700600: 0.139771\n",
      "2022-11-09 00:29:56,435 INFO     Training average loss at step 700600: 0.144750\n",
      "2022-11-09 00:30:02,810 INFO     Training average positive_sample_loss at step 700700: 0.152659\n",
      "2022-11-09 00:30:02,810 INFO     Training average negative_sample_loss at step 700700: 0.141671\n",
      "2022-11-09 00:30:02,810 INFO     Training average loss at step 700700: 0.147165\n",
      "2022-11-09 00:30:09,223 INFO     Training average positive_sample_loss at step 700800: 0.154111\n",
      "2022-11-09 00:30:09,223 INFO     Training average negative_sample_loss at step 700800: 0.139126\n",
      "2022-11-09 00:30:09,223 INFO     Training average loss at step 700800: 0.146619\n",
      "2022-11-09 00:30:15,583 INFO     Training average positive_sample_loss at step 700900: 0.153767\n",
      "2022-11-09 00:30:15,583 INFO     Training average negative_sample_loss at step 700900: 0.144643\n",
      "2022-11-09 00:30:15,583 INFO     Training average loss at step 700900: 0.149205\n",
      "2022-11-09 00:30:21,955 INFO     Training average positive_sample_loss at step 701000: 0.152482\n",
      "2022-11-09 00:30:21,955 INFO     Training average negative_sample_loss at step 701000: 0.138727\n",
      "2022-11-09 00:30:21,956 INFO     Training average loss at step 701000: 0.145604\n",
      "2022-11-09 00:30:28,306 INFO     Training average positive_sample_loss at step 701100: 0.147894\n",
      "2022-11-09 00:30:28,306 INFO     Training average negative_sample_loss at step 701100: 0.137631\n",
      "2022-11-09 00:30:28,306 INFO     Training average loss at step 701100: 0.142763\n",
      "2022-11-09 00:30:34,673 INFO     Training average positive_sample_loss at step 701200: 0.151184\n",
      "2022-11-09 00:30:34,674 INFO     Training average negative_sample_loss at step 701200: 0.139792\n",
      "2022-11-09 00:30:34,674 INFO     Training average loss at step 701200: 0.145488\n",
      "2022-11-09 00:30:41,034 INFO     Training average positive_sample_loss at step 701300: 0.151231\n",
      "2022-11-09 00:30:41,034 INFO     Training average negative_sample_loss at step 701300: 0.139177\n",
      "2022-11-09 00:30:41,034 INFO     Training average loss at step 701300: 0.145204\n",
      "2022-11-09 00:30:47,406 INFO     Training average positive_sample_loss at step 701400: 0.149109\n",
      "2022-11-09 00:30:47,406 INFO     Training average negative_sample_loss at step 701400: 0.145114\n",
      "2022-11-09 00:30:47,406 INFO     Training average loss at step 701400: 0.147112\n",
      "2022-11-09 00:30:53,780 INFO     Training average positive_sample_loss at step 701500: 0.149406\n",
      "2022-11-09 00:30:53,780 INFO     Training average negative_sample_loss at step 701500: 0.142446\n",
      "2022-11-09 00:30:53,780 INFO     Training average loss at step 701500: 0.145926\n",
      "2022-11-09 00:31:00,165 INFO     Training average positive_sample_loss at step 701600: 0.149596\n",
      "2022-11-09 00:31:00,165 INFO     Training average negative_sample_loss at step 701600: 0.142758\n",
      "2022-11-09 00:31:00,165 INFO     Training average loss at step 701600: 0.146177\n",
      "2022-11-09 00:31:06,539 INFO     Training average positive_sample_loss at step 701700: 0.153077\n",
      "2022-11-09 00:31:06,539 INFO     Training average negative_sample_loss at step 701700: 0.147706\n",
      "2022-11-09 00:31:06,539 INFO     Training average loss at step 701700: 0.150391\n",
      "2022-11-09 00:31:12,930 INFO     Training average positive_sample_loss at step 701800: 0.156100\n",
      "2022-11-09 00:31:12,930 INFO     Training average negative_sample_loss at step 701800: 0.141013\n",
      "2022-11-09 00:31:12,930 INFO     Training average loss at step 701800: 0.148557\n",
      "2022-11-09 00:31:19,321 INFO     Training average positive_sample_loss at step 701900: 0.153709\n",
      "2022-11-09 00:31:19,321 INFO     Training average negative_sample_loss at step 701900: 0.139277\n",
      "2022-11-09 00:31:19,321 INFO     Training average loss at step 701900: 0.146493\n",
      "2022-11-09 00:31:25,710 INFO     Training average positive_sample_loss at step 702000: 0.151057\n",
      "2022-11-09 00:31:25,710 INFO     Training average negative_sample_loss at step 702000: 0.139213\n",
      "2022-11-09 00:31:25,710 INFO     Training average loss at step 702000: 0.145135\n",
      "2022-11-09 00:31:32,117 INFO     Training average positive_sample_loss at step 702100: 0.149570\n",
      "2022-11-09 00:31:32,118 INFO     Training average negative_sample_loss at step 702100: 0.138123\n",
      "2022-11-09 00:31:32,118 INFO     Training average loss at step 702100: 0.143846\n",
      "2022-11-09 00:31:38,503 INFO     Training average positive_sample_loss at step 702200: 0.149069\n",
      "2022-11-09 00:31:38,503 INFO     Training average negative_sample_loss at step 702200: 0.139684\n",
      "2022-11-09 00:31:38,503 INFO     Training average loss at step 702200: 0.144376\n",
      "2022-11-09 00:31:44,874 INFO     Training average positive_sample_loss at step 702300: 0.151184\n",
      "2022-11-09 00:31:44,874 INFO     Training average negative_sample_loss at step 702300: 0.140011\n",
      "2022-11-09 00:31:44,874 INFO     Training average loss at step 702300: 0.145598\n",
      "2022-11-09 00:31:51,267 INFO     Training average positive_sample_loss at step 702400: 0.157277\n",
      "2022-11-09 00:31:51,267 INFO     Training average negative_sample_loss at step 702400: 0.140760\n",
      "2022-11-09 00:31:51,267 INFO     Training average loss at step 702400: 0.149018\n",
      "2022-11-09 00:31:57,664 INFO     Training average positive_sample_loss at step 702500: 0.154609\n",
      "2022-11-09 00:31:57,664 INFO     Training average negative_sample_loss at step 702500: 0.138787\n",
      "2022-11-09 00:31:57,664 INFO     Training average loss at step 702500: 0.146698\n",
      "2022-11-09 00:32:04,033 INFO     Training average positive_sample_loss at step 702600: 0.153997\n",
      "2022-11-09 00:32:04,034 INFO     Training average negative_sample_loss at step 702600: 0.142629\n",
      "2022-11-09 00:32:04,034 INFO     Training average loss at step 702600: 0.148313\n",
      "2022-11-09 00:32:10,421 INFO     Training average positive_sample_loss at step 702700: 0.147773\n",
      "2022-11-09 00:32:10,422 INFO     Training average negative_sample_loss at step 702700: 0.140381\n",
      "2022-11-09 00:32:10,422 INFO     Training average loss at step 702700: 0.144077\n",
      "2022-11-09 00:32:16,779 INFO     Training average positive_sample_loss at step 702800: 0.146266\n",
      "2022-11-09 00:32:16,779 INFO     Training average negative_sample_loss at step 702800: 0.140831\n",
      "2022-11-09 00:32:16,779 INFO     Training average loss at step 702800: 0.143548\n",
      "2022-11-09 00:32:23,146 INFO     Training average positive_sample_loss at step 702900: 0.154288\n",
      "2022-11-09 00:32:23,146 INFO     Training average negative_sample_loss at step 702900: 0.141631\n",
      "2022-11-09 00:32:23,146 INFO     Training average loss at step 702900: 0.147959\n",
      "2022-11-09 00:32:29,516 INFO     Training average positive_sample_loss at step 703000: 0.152837\n",
      "2022-11-09 00:32:29,516 INFO     Training average negative_sample_loss at step 703000: 0.141472\n",
      "2022-11-09 00:32:29,516 INFO     Training average loss at step 703000: 0.147154\n",
      "2022-11-09 00:32:35,103 INFO     Training average positive_sample_loss at step 703100: 0.148906\n",
      "2022-11-09 00:32:35,103 INFO     Training average negative_sample_loss at step 703100: 0.142652\n",
      "2022-11-09 00:32:35,103 INFO     Training average loss at step 703100: 0.145779\n",
      "2022-11-09 00:32:40,903 INFO     Training average positive_sample_loss at step 703200: 0.148424\n",
      "2022-11-09 00:32:40,904 INFO     Training average negative_sample_loss at step 703200: 0.138358\n",
      "2022-11-09 00:32:40,904 INFO     Training average loss at step 703200: 0.143391\n",
      "2022-11-09 00:32:47,273 INFO     Training average positive_sample_loss at step 703300: 0.156092\n",
      "2022-11-09 00:32:47,274 INFO     Training average negative_sample_loss at step 703300: 0.140078\n",
      "2022-11-09 00:32:47,274 INFO     Training average loss at step 703300: 0.148085\n",
      "2022-11-09 00:32:53,634 INFO     Training average positive_sample_loss at step 703400: 0.147657\n",
      "2022-11-09 00:32:53,634 INFO     Training average negative_sample_loss at step 703400: 0.141601\n",
      "2022-11-09 00:32:53,634 INFO     Training average loss at step 703400: 0.144629\n",
      "2022-11-09 00:32:59,994 INFO     Training average positive_sample_loss at step 703500: 0.154934\n",
      "2022-11-09 00:32:59,994 INFO     Training average negative_sample_loss at step 703500: 0.141990\n",
      "2022-11-09 00:32:59,994 INFO     Training average loss at step 703500: 0.148462\n",
      "2022-11-09 00:33:06,335 INFO     Training average positive_sample_loss at step 703600: 0.149924\n",
      "2022-11-09 00:33:06,335 INFO     Training average negative_sample_loss at step 703600: 0.140551\n",
      "2022-11-09 00:33:06,335 INFO     Training average loss at step 703600: 0.145237\n",
      "2022-11-09 00:33:12,681 INFO     Training average positive_sample_loss at step 703700: 0.148221\n",
      "2022-11-09 00:33:12,681 INFO     Training average negative_sample_loss at step 703700: 0.143120\n",
      "2022-11-09 00:33:12,681 INFO     Training average loss at step 703700: 0.145670\n",
      "2022-11-09 00:33:20,028 INFO     Training average positive_sample_loss at step 703800: 0.150580\n",
      "2022-11-09 00:33:20,028 INFO     Training average negative_sample_loss at step 703800: 0.142886\n",
      "2022-11-09 00:33:20,028 INFO     Training average loss at step 703800: 0.146733\n",
      "2022-11-09 00:33:26,394 INFO     Training average positive_sample_loss at step 703900: 0.152633\n",
      "2022-11-09 00:33:26,394 INFO     Training average negative_sample_loss at step 703900: 0.141523\n",
      "2022-11-09 00:33:26,394 INFO     Training average loss at step 703900: 0.147078\n",
      "2022-11-09 00:33:33,294 INFO     Training average positive_sample_loss at step 704000: 0.151405\n",
      "2022-11-09 00:33:33,294 INFO     Training average negative_sample_loss at step 704000: 0.145492\n",
      "2022-11-09 00:33:33,294 INFO     Training average loss at step 704000: 0.148448\n",
      "2022-11-09 00:33:40,234 INFO     Training average positive_sample_loss at step 704100: 0.153330\n",
      "2022-11-09 00:33:40,234 INFO     Training average negative_sample_loss at step 704100: 0.145702\n",
      "2022-11-09 00:33:40,234 INFO     Training average loss at step 704100: 0.149516\n",
      "2022-11-09 00:33:46,605 INFO     Training average positive_sample_loss at step 704200: 0.152158\n",
      "2022-11-09 00:33:46,605 INFO     Training average negative_sample_loss at step 704200: 0.141013\n",
      "2022-11-09 00:33:46,605 INFO     Training average loss at step 704200: 0.146585\n",
      "2022-11-09 00:33:52,950 INFO     Training average positive_sample_loss at step 704300: 0.152277\n",
      "2022-11-09 00:33:52,950 INFO     Training average negative_sample_loss at step 704300: 0.141283\n",
      "2022-11-09 00:33:52,950 INFO     Training average loss at step 704300: 0.146780\n",
      "2022-11-09 00:34:00,776 INFO     Training average positive_sample_loss at step 704400: 0.153389\n",
      "2022-11-09 00:34:00,776 INFO     Training average negative_sample_loss at step 704400: 0.137855\n",
      "2022-11-09 00:34:00,776 INFO     Training average loss at step 704400: 0.145622\n",
      "2022-11-09 00:34:07,174 INFO     Training average positive_sample_loss at step 704500: 0.149520\n",
      "2022-11-09 00:34:07,174 INFO     Training average negative_sample_loss at step 704500: 0.142876\n",
      "2022-11-09 00:34:07,174 INFO     Training average loss at step 704500: 0.146198\n",
      "2022-11-09 00:34:13,545 INFO     Training average positive_sample_loss at step 704600: 0.151328\n",
      "2022-11-09 00:34:13,545 INFO     Training average negative_sample_loss at step 704600: 0.138574\n",
      "2022-11-09 00:34:13,545 INFO     Training average loss at step 704600: 0.144951\n",
      "2022-11-09 00:34:19,920 INFO     Training average positive_sample_loss at step 704700: 0.155966\n",
      "2022-11-09 00:34:19,920 INFO     Training average negative_sample_loss at step 704700: 0.140739\n",
      "2022-11-09 00:34:19,920 INFO     Training average loss at step 704700: 0.148352\n",
      "2022-11-09 00:34:26,310 INFO     Training average positive_sample_loss at step 704800: 0.149790\n",
      "2022-11-09 00:34:26,310 INFO     Training average negative_sample_loss at step 704800: 0.139398\n",
      "2022-11-09 00:34:26,310 INFO     Training average loss at step 704800: 0.144594\n",
      "2022-11-09 00:34:32,704 INFO     Training average positive_sample_loss at step 704900: 0.152958\n",
      "2022-11-09 00:34:32,704 INFO     Training average negative_sample_loss at step 704900: 0.139118\n",
      "2022-11-09 00:34:32,704 INFO     Training average loss at step 704900: 0.146038\n",
      "2022-11-09 00:34:39,103 INFO     Training average positive_sample_loss at step 705000: 0.152749\n",
      "2022-11-09 00:34:39,103 INFO     Training average negative_sample_loss at step 705000: 0.139287\n",
      "2022-11-09 00:34:39,103 INFO     Training average loss at step 705000: 0.146018\n",
      "2022-11-09 00:34:45,484 INFO     Training average positive_sample_loss at step 705100: 0.147025\n",
      "2022-11-09 00:34:45,484 INFO     Training average negative_sample_loss at step 705100: 0.137119\n",
      "2022-11-09 00:34:45,484 INFO     Training average loss at step 705100: 0.142072\n",
      "2022-11-09 00:34:51,859 INFO     Training average positive_sample_loss at step 705200: 0.149723\n",
      "2022-11-09 00:34:51,860 INFO     Training average negative_sample_loss at step 705200: 0.142463\n",
      "2022-11-09 00:34:51,860 INFO     Training average loss at step 705200: 0.146093\n",
      "2022-11-09 00:34:58,262 INFO     Training average positive_sample_loss at step 705300: 0.151762\n",
      "2022-11-09 00:34:58,262 INFO     Training average negative_sample_loss at step 705300: 0.138955\n",
      "2022-11-09 00:34:58,262 INFO     Training average loss at step 705300: 0.145358\n",
      "2022-11-09 00:35:04,630 INFO     Training average positive_sample_loss at step 705400: 0.150313\n",
      "2022-11-09 00:35:04,631 INFO     Training average negative_sample_loss at step 705400: 0.140430\n",
      "2022-11-09 00:35:04,631 INFO     Training average loss at step 705400: 0.145372\n",
      "2022-11-09 00:35:11,015 INFO     Training average positive_sample_loss at step 705500: 0.148545\n",
      "2022-11-09 00:35:11,015 INFO     Training average negative_sample_loss at step 705500: 0.144274\n",
      "2022-11-09 00:35:11,015 INFO     Training average loss at step 705500: 0.146410\n",
      "2022-11-09 00:35:17,387 INFO     Training average positive_sample_loss at step 705600: 0.155533\n",
      "2022-11-09 00:35:17,387 INFO     Training average negative_sample_loss at step 705600: 0.139947\n",
      "2022-11-09 00:35:17,387 INFO     Training average loss at step 705600: 0.147740\n",
      "2022-11-09 00:35:23,761 INFO     Training average positive_sample_loss at step 705700: 0.157811\n",
      "2022-11-09 00:35:23,761 INFO     Training average negative_sample_loss at step 705700: 0.140459\n",
      "2022-11-09 00:35:23,761 INFO     Training average loss at step 705700: 0.149135\n",
      "2022-11-09 00:35:30,167 INFO     Training average positive_sample_loss at step 705800: 0.145340\n",
      "2022-11-09 00:35:30,167 INFO     Training average negative_sample_loss at step 705800: 0.139085\n",
      "2022-11-09 00:35:30,167 INFO     Training average loss at step 705800: 0.142213\n",
      "2022-11-09 00:35:36,559 INFO     Training average positive_sample_loss at step 705900: 0.156496\n",
      "2022-11-09 00:35:36,559 INFO     Training average negative_sample_loss at step 705900: 0.138061\n",
      "2022-11-09 00:35:36,559 INFO     Training average loss at step 705900: 0.147278\n",
      "2022-11-09 00:35:42,933 INFO     Training average positive_sample_loss at step 706000: 0.154756\n",
      "2022-11-09 00:35:42,933 INFO     Training average negative_sample_loss at step 706000: 0.142599\n",
      "2022-11-09 00:35:42,933 INFO     Training average loss at step 706000: 0.148678\n",
      "2022-11-09 00:35:49,304 INFO     Training average positive_sample_loss at step 706100: 0.150254\n",
      "2022-11-09 00:35:49,304 INFO     Training average negative_sample_loss at step 706100: 0.142624\n",
      "2022-11-09 00:35:49,304 INFO     Training average loss at step 706100: 0.146439\n",
      "2022-11-09 00:35:55,671 INFO     Training average positive_sample_loss at step 706200: 0.151940\n",
      "2022-11-09 00:35:55,671 INFO     Training average negative_sample_loss at step 706200: 0.139418\n",
      "2022-11-09 00:35:55,671 INFO     Training average loss at step 706200: 0.145679\n",
      "2022-11-09 00:36:02,032 INFO     Training average positive_sample_loss at step 706300: 0.151198\n",
      "2022-11-09 00:36:02,032 INFO     Training average negative_sample_loss at step 706300: 0.146105\n",
      "2022-11-09 00:36:02,032 INFO     Training average loss at step 706300: 0.148651\n",
      "2022-11-09 00:36:08,403 INFO     Training average positive_sample_loss at step 706400: 0.157998\n",
      "2022-11-09 00:36:08,403 INFO     Training average negative_sample_loss at step 706400: 0.138040\n",
      "2022-11-09 00:36:08,403 INFO     Training average loss at step 706400: 0.148019\n",
      "2022-11-09 00:36:14,782 INFO     Training average positive_sample_loss at step 706500: 0.152860\n",
      "2022-11-09 00:36:14,782 INFO     Training average negative_sample_loss at step 706500: 0.141930\n",
      "2022-11-09 00:36:14,782 INFO     Training average loss at step 706500: 0.147395\n",
      "2022-11-09 00:36:21,173 INFO     Training average positive_sample_loss at step 706600: 0.148573\n",
      "2022-11-09 00:36:21,173 INFO     Training average negative_sample_loss at step 706600: 0.145318\n",
      "2022-11-09 00:36:21,173 INFO     Training average loss at step 706600: 0.146945\n",
      "2022-11-09 00:36:27,539 INFO     Training average positive_sample_loss at step 706700: 0.150372\n",
      "2022-11-09 00:36:27,539 INFO     Training average negative_sample_loss at step 706700: 0.143066\n",
      "2022-11-09 00:36:27,539 INFO     Training average loss at step 706700: 0.146719\n",
      "2022-11-09 00:36:33,928 INFO     Training average positive_sample_loss at step 706800: 0.150826\n",
      "2022-11-09 00:36:33,928 INFO     Training average negative_sample_loss at step 706800: 0.142558\n",
      "2022-11-09 00:36:33,928 INFO     Training average loss at step 706800: 0.146692\n",
      "2022-11-09 00:36:40,305 INFO     Training average positive_sample_loss at step 706900: 0.149224\n",
      "2022-11-09 00:36:40,305 INFO     Training average negative_sample_loss at step 706900: 0.138894\n",
      "2022-11-09 00:36:40,305 INFO     Training average loss at step 706900: 0.144059\n",
      "2022-11-09 00:36:46,661 INFO     Training average positive_sample_loss at step 707000: 0.153293\n",
      "2022-11-09 00:36:46,661 INFO     Training average negative_sample_loss at step 707000: 0.142092\n",
      "2022-11-09 00:36:46,661 INFO     Training average loss at step 707000: 0.147693\n",
      "2022-11-09 00:36:53,016 INFO     Training average positive_sample_loss at step 707100: 0.149441\n",
      "2022-11-09 00:36:53,016 INFO     Training average negative_sample_loss at step 707100: 0.139140\n",
      "2022-11-09 00:36:53,016 INFO     Training average loss at step 707100: 0.144291\n",
      "2022-11-09 00:36:59,371 INFO     Training average positive_sample_loss at step 707200: 0.155955\n",
      "2022-11-09 00:36:59,371 INFO     Training average negative_sample_loss at step 707200: 0.138094\n",
      "2022-11-09 00:36:59,371 INFO     Training average loss at step 707200: 0.147024\n",
      "2022-11-09 00:37:05,744 INFO     Training average positive_sample_loss at step 707300: 0.156982\n",
      "2022-11-09 00:37:05,744 INFO     Training average negative_sample_loss at step 707300: 0.145374\n",
      "2022-11-09 00:37:05,744 INFO     Training average loss at step 707300: 0.151178\n",
      "2022-11-09 00:37:12,092 INFO     Training average positive_sample_loss at step 707400: 0.155457\n",
      "2022-11-09 00:37:12,092 INFO     Training average negative_sample_loss at step 707400: 0.140321\n",
      "2022-11-09 00:37:12,092 INFO     Training average loss at step 707400: 0.147889\n",
      "2022-11-09 00:37:18,456 INFO     Training average positive_sample_loss at step 707500: 0.154748\n",
      "2022-11-09 00:37:18,456 INFO     Training average negative_sample_loss at step 707500: 0.140413\n",
      "2022-11-09 00:37:18,457 INFO     Training average loss at step 707500: 0.147581\n",
      "2022-11-09 00:37:24,842 INFO     Training average positive_sample_loss at step 707600: 0.149937\n",
      "2022-11-09 00:37:24,842 INFO     Training average negative_sample_loss at step 707600: 0.144283\n",
      "2022-11-09 00:37:24,842 INFO     Training average loss at step 707600: 0.147110\n",
      "2022-11-09 00:37:31,250 INFO     Training average positive_sample_loss at step 707700: 0.151905\n",
      "2022-11-09 00:37:31,250 INFO     Training average negative_sample_loss at step 707700: 0.139100\n",
      "2022-11-09 00:37:31,251 INFO     Training average loss at step 707700: 0.145503\n",
      "2022-11-09 00:37:37,622 INFO     Training average positive_sample_loss at step 707800: 0.152697\n",
      "2022-11-09 00:37:37,622 INFO     Training average negative_sample_loss at step 707800: 0.139257\n",
      "2022-11-09 00:37:37,622 INFO     Training average loss at step 707800: 0.145977\n",
      "2022-11-09 00:37:43,980 INFO     Training average positive_sample_loss at step 707900: 0.152918\n",
      "2022-11-09 00:37:43,980 INFO     Training average negative_sample_loss at step 707900: 0.138023\n",
      "2022-11-09 00:37:43,980 INFO     Training average loss at step 707900: 0.145471\n",
      "2022-11-09 00:37:50,348 INFO     Training average positive_sample_loss at step 708000: 0.155025\n",
      "2022-11-09 00:37:50,348 INFO     Training average negative_sample_loss at step 708000: 0.140893\n",
      "2022-11-09 00:37:50,348 INFO     Training average loss at step 708000: 0.147959\n",
      "2022-11-09 00:37:56,715 INFO     Training average positive_sample_loss at step 708100: 0.146786\n",
      "2022-11-09 00:37:56,715 INFO     Training average negative_sample_loss at step 708100: 0.140912\n",
      "2022-11-09 00:37:56,715 INFO     Training average loss at step 708100: 0.143849\n",
      "2022-11-09 00:38:03,088 INFO     Training average positive_sample_loss at step 708200: 0.151714\n",
      "2022-11-09 00:38:03,088 INFO     Training average negative_sample_loss at step 708200: 0.139087\n",
      "2022-11-09 00:38:03,088 INFO     Training average loss at step 708200: 0.145400\n",
      "2022-11-09 00:38:09,450 INFO     Training average positive_sample_loss at step 708300: 0.152740\n",
      "2022-11-09 00:38:09,450 INFO     Training average negative_sample_loss at step 708300: 0.137062\n",
      "2022-11-09 00:38:09,450 INFO     Training average loss at step 708300: 0.144901\n",
      "2022-11-09 00:38:15,832 INFO     Training average positive_sample_loss at step 708400: 0.152389\n",
      "2022-11-09 00:38:15,832 INFO     Training average negative_sample_loss at step 708400: 0.145444\n",
      "2022-11-09 00:38:15,832 INFO     Training average loss at step 708400: 0.148917\n",
      "2022-11-09 00:38:23,098 INFO     Training average positive_sample_loss at step 708500: 0.149594\n",
      "2022-11-09 00:38:23,098 INFO     Training average negative_sample_loss at step 708500: 0.142424\n",
      "2022-11-09 00:38:23,098 INFO     Training average loss at step 708500: 0.146009\n",
      "2022-11-09 00:38:29,482 INFO     Training average positive_sample_loss at step 708600: 0.151870\n",
      "2022-11-09 00:38:29,482 INFO     Training average negative_sample_loss at step 708600: 0.143503\n",
      "2022-11-09 00:38:29,482 INFO     Training average loss at step 708600: 0.147686\n",
      "2022-11-09 00:38:35,020 INFO     Training average positive_sample_loss at step 708700: 0.148916\n",
      "2022-11-09 00:38:35,020 INFO     Training average negative_sample_loss at step 708700: 0.139837\n",
      "2022-11-09 00:38:35,020 INFO     Training average loss at step 708700: 0.144376\n",
      "2022-11-09 00:38:41,962 INFO     Training average positive_sample_loss at step 708800: 0.148231\n",
      "2022-11-09 00:38:41,962 INFO     Training average negative_sample_loss at step 708800: 0.138965\n",
      "2022-11-09 00:38:41,962 INFO     Training average loss at step 708800: 0.143598\n",
      "2022-11-09 00:38:48,334 INFO     Training average positive_sample_loss at step 708900: 0.151800\n",
      "2022-11-09 00:38:48,334 INFO     Training average negative_sample_loss at step 708900: 0.137945\n",
      "2022-11-09 00:38:48,334 INFO     Training average loss at step 708900: 0.144872\n",
      "2022-11-09 00:38:54,708 INFO     Training average positive_sample_loss at step 709000: 0.151289\n",
      "2022-11-09 00:38:54,708 INFO     Training average negative_sample_loss at step 709000: 0.140634\n",
      "2022-11-09 00:38:54,708 INFO     Training average loss at step 709000: 0.145962\n",
      "2022-11-09 00:39:02,489 INFO     Training average positive_sample_loss at step 709100: 0.156410\n",
      "2022-11-09 00:39:02,489 INFO     Training average negative_sample_loss at step 709100: 0.141316\n",
      "2022-11-09 00:39:02,489 INFO     Training average loss at step 709100: 0.148863\n",
      "2022-11-09 00:39:08,876 INFO     Training average positive_sample_loss at step 709200: 0.154237\n",
      "2022-11-09 00:39:08,876 INFO     Training average negative_sample_loss at step 709200: 0.144488\n",
      "2022-11-09 00:39:08,876 INFO     Training average loss at step 709200: 0.149363\n",
      "2022-11-09 00:39:15,241 INFO     Training average positive_sample_loss at step 709300: 0.156341\n",
      "2022-11-09 00:39:15,241 INFO     Training average negative_sample_loss at step 709300: 0.141273\n",
      "2022-11-09 00:39:15,241 INFO     Training average loss at step 709300: 0.148807\n",
      "2022-11-09 00:39:21,611 INFO     Training average positive_sample_loss at step 709400: 0.150173\n",
      "2022-11-09 00:39:21,611 INFO     Training average negative_sample_loss at step 709400: 0.142993\n",
      "2022-11-09 00:39:21,611 INFO     Training average loss at step 709400: 0.146583\n",
      "2022-11-09 00:39:28,002 INFO     Training average positive_sample_loss at step 709500: 0.149452\n",
      "2022-11-09 00:39:28,002 INFO     Training average negative_sample_loss at step 709500: 0.144010\n",
      "2022-11-09 00:39:28,002 INFO     Training average loss at step 709500: 0.146731\n",
      "2022-11-09 00:39:34,391 INFO     Training average positive_sample_loss at step 709600: 0.150982\n",
      "2022-11-09 00:39:34,392 INFO     Training average negative_sample_loss at step 709600: 0.143472\n",
      "2022-11-09 00:39:34,392 INFO     Training average loss at step 709600: 0.147227\n",
      "2022-11-09 00:39:40,759 INFO     Training average positive_sample_loss at step 709700: 0.152710\n",
      "2022-11-09 00:39:40,760 INFO     Training average negative_sample_loss at step 709700: 0.141543\n",
      "2022-11-09 00:39:40,760 INFO     Training average loss at step 709700: 0.147127\n",
      "2022-11-09 00:39:47,120 INFO     Training average positive_sample_loss at step 709800: 0.152187\n",
      "2022-11-09 00:39:47,120 INFO     Training average negative_sample_loss at step 709800: 0.139777\n",
      "2022-11-09 00:39:47,120 INFO     Training average loss at step 709800: 0.145982\n",
      "2022-11-09 00:39:53,475 INFO     Training average positive_sample_loss at step 709900: 0.151240\n",
      "2022-11-09 00:39:53,475 INFO     Training average negative_sample_loss at step 709900: 0.144075\n",
      "2022-11-09 00:39:53,476 INFO     Training average loss at step 709900: 0.147658\n",
      "2022-11-09 00:40:02,717 INFO     Training average positive_sample_loss at step 710000: 0.145045\n",
      "2022-11-09 00:40:02,717 INFO     Training average negative_sample_loss at step 710000: 0.139865\n",
      "2022-11-09 00:40:02,717 INFO     Training average loss at step 710000: 0.142455\n",
      "2022-11-09 00:40:09,077 INFO     Training average positive_sample_loss at step 710100: 0.149021\n",
      "2022-11-09 00:40:09,077 INFO     Training average negative_sample_loss at step 710100: 0.141339\n",
      "2022-11-09 00:40:09,077 INFO     Training average loss at step 710100: 0.145180\n",
      "2022-11-09 00:40:15,442 INFO     Training average positive_sample_loss at step 710200: 0.151533\n",
      "2022-11-09 00:40:15,442 INFO     Training average negative_sample_loss at step 710200: 0.141000\n",
      "2022-11-09 00:40:15,442 INFO     Training average loss at step 710200: 0.146266\n",
      "2022-11-09 00:40:21,820 INFO     Training average positive_sample_loss at step 710300: 0.150085\n",
      "2022-11-09 00:40:21,820 INFO     Training average negative_sample_loss at step 710300: 0.138614\n",
      "2022-11-09 00:40:21,820 INFO     Training average loss at step 710300: 0.144349\n",
      "2022-11-09 00:40:28,206 INFO     Training average positive_sample_loss at step 710400: 0.147212\n",
      "2022-11-09 00:40:28,206 INFO     Training average negative_sample_loss at step 710400: 0.144004\n",
      "2022-11-09 00:40:28,206 INFO     Training average loss at step 710400: 0.145608\n",
      "2022-11-09 00:40:34,544 INFO     Training average positive_sample_loss at step 710500: 0.148415\n",
      "2022-11-09 00:40:34,544 INFO     Training average negative_sample_loss at step 710500: 0.142484\n",
      "2022-11-09 00:40:34,544 INFO     Training average loss at step 710500: 0.145450\n",
      "2022-11-09 00:40:40,905 INFO     Training average positive_sample_loss at step 710600: 0.152398\n",
      "2022-11-09 00:40:40,905 INFO     Training average negative_sample_loss at step 710600: 0.142333\n",
      "2022-11-09 00:40:40,905 INFO     Training average loss at step 710600: 0.147366\n",
      "2022-11-09 00:40:47,278 INFO     Training average positive_sample_loss at step 710700: 0.149657\n",
      "2022-11-09 00:40:47,279 INFO     Training average negative_sample_loss at step 710700: 0.140102\n",
      "2022-11-09 00:40:47,279 INFO     Training average loss at step 710700: 0.144880\n",
      "2022-11-09 00:40:53,678 INFO     Training average positive_sample_loss at step 710800: 0.148694\n",
      "2022-11-09 00:40:53,678 INFO     Training average negative_sample_loss at step 710800: 0.140723\n",
      "2022-11-09 00:40:53,678 INFO     Training average loss at step 710800: 0.144708\n",
      "2022-11-09 00:41:00,084 INFO     Training average positive_sample_loss at step 710900: 0.142877\n",
      "2022-11-09 00:41:00,084 INFO     Training average negative_sample_loss at step 710900: 0.139349\n",
      "2022-11-09 00:41:00,084 INFO     Training average loss at step 710900: 0.141113\n",
      "2022-11-09 00:41:06,490 INFO     Training average positive_sample_loss at step 711000: 0.155572\n",
      "2022-11-09 00:41:06,490 INFO     Training average negative_sample_loss at step 711000: 0.141337\n",
      "2022-11-09 00:41:06,490 INFO     Training average loss at step 711000: 0.148454\n",
      "2022-11-09 00:41:12,898 INFO     Training average positive_sample_loss at step 711100: 0.148396\n",
      "2022-11-09 00:41:12,898 INFO     Training average negative_sample_loss at step 711100: 0.139107\n",
      "2022-11-09 00:41:12,898 INFO     Training average loss at step 711100: 0.143751\n",
      "2022-11-09 00:41:19,267 INFO     Training average positive_sample_loss at step 711200: 0.154813\n",
      "2022-11-09 00:41:19,267 INFO     Training average negative_sample_loss at step 711200: 0.138181\n",
      "2022-11-09 00:41:19,268 INFO     Training average loss at step 711200: 0.146497\n",
      "2022-11-09 00:41:25,676 INFO     Training average positive_sample_loss at step 711300: 0.152231\n",
      "2022-11-09 00:41:25,676 INFO     Training average negative_sample_loss at step 711300: 0.139545\n",
      "2022-11-09 00:41:25,676 INFO     Training average loss at step 711300: 0.145888\n",
      "2022-11-09 00:41:32,094 INFO     Training average positive_sample_loss at step 711400: 0.152453\n",
      "2022-11-09 00:41:32,094 INFO     Training average negative_sample_loss at step 711400: 0.139114\n",
      "2022-11-09 00:41:32,094 INFO     Training average loss at step 711400: 0.145784\n",
      "2022-11-09 00:41:38,501 INFO     Training average positive_sample_loss at step 711500: 0.153368\n",
      "2022-11-09 00:41:38,501 INFO     Training average negative_sample_loss at step 711500: 0.141383\n",
      "2022-11-09 00:41:38,501 INFO     Training average loss at step 711500: 0.147376\n",
      "2022-11-09 00:41:44,871 INFO     Training average positive_sample_loss at step 711600: 0.154326\n",
      "2022-11-09 00:41:44,871 INFO     Training average negative_sample_loss at step 711600: 0.143600\n",
      "2022-11-09 00:41:44,871 INFO     Training average loss at step 711600: 0.148963\n",
      "2022-11-09 00:41:51,226 INFO     Training average positive_sample_loss at step 711700: 0.152527\n",
      "2022-11-09 00:41:51,226 INFO     Training average negative_sample_loss at step 711700: 0.140163\n",
      "2022-11-09 00:41:51,226 INFO     Training average loss at step 711700: 0.146345\n",
      "2022-11-09 00:41:57,572 INFO     Training average positive_sample_loss at step 711800: 0.148680\n",
      "2022-11-09 00:41:57,572 INFO     Training average negative_sample_loss at step 711800: 0.142774\n",
      "2022-11-09 00:41:57,572 INFO     Training average loss at step 711800: 0.145727\n",
      "2022-11-09 00:42:03,926 INFO     Training average positive_sample_loss at step 711900: 0.149437\n",
      "2022-11-09 00:42:03,926 INFO     Training average negative_sample_loss at step 711900: 0.142348\n",
      "2022-11-09 00:42:03,926 INFO     Training average loss at step 711900: 0.145893\n",
      "2022-11-09 00:42:10,285 INFO     Training average positive_sample_loss at step 712000: 0.148153\n",
      "2022-11-09 00:42:10,285 INFO     Training average negative_sample_loss at step 712000: 0.142081\n",
      "2022-11-09 00:42:10,285 INFO     Training average loss at step 712000: 0.145117\n",
      "2022-11-09 00:42:16,656 INFO     Training average positive_sample_loss at step 712100: 0.154657\n",
      "2022-11-09 00:42:16,656 INFO     Training average negative_sample_loss at step 712100: 0.140115\n",
      "2022-11-09 00:42:16,656 INFO     Training average loss at step 712100: 0.147386\n",
      "2022-11-09 00:42:23,018 INFO     Training average positive_sample_loss at step 712200: 0.148595\n",
      "2022-11-09 00:42:23,018 INFO     Training average negative_sample_loss at step 712200: 0.142906\n",
      "2022-11-09 00:42:23,018 INFO     Training average loss at step 712200: 0.145750\n",
      "2022-11-09 00:42:29,382 INFO     Training average positive_sample_loss at step 712300: 0.148147\n",
      "2022-11-09 00:42:29,382 INFO     Training average negative_sample_loss at step 712300: 0.138528\n",
      "2022-11-09 00:42:29,382 INFO     Training average loss at step 712300: 0.143338\n",
      "2022-11-09 00:42:36,336 INFO     Training average positive_sample_loss at step 712400: 0.149371\n",
      "2022-11-09 00:42:36,336 INFO     Training average negative_sample_loss at step 712400: 0.141581\n",
      "2022-11-09 00:42:36,336 INFO     Training average loss at step 712400: 0.145476\n",
      "2022-11-09 00:42:45,375 INFO     Training average positive_sample_loss at step 712500: 0.143323\n",
      "2022-11-09 00:42:45,375 INFO     Training average negative_sample_loss at step 712500: 0.142116\n",
      "2022-11-09 00:42:45,376 INFO     Training average loss at step 712500: 0.142720\n",
      "2022-11-09 00:42:51,763 INFO     Training average positive_sample_loss at step 712600: 0.146720\n",
      "2022-11-09 00:42:51,763 INFO     Training average negative_sample_loss at step 712600: 0.140274\n",
      "2022-11-09 00:42:51,763 INFO     Training average loss at step 712600: 0.143497\n",
      "2022-11-09 00:42:58,165 INFO     Training average positive_sample_loss at step 712700: 0.144317\n",
      "2022-11-09 00:42:58,165 INFO     Training average negative_sample_loss at step 712700: 0.139560\n",
      "2022-11-09 00:42:58,165 INFO     Training average loss at step 712700: 0.141938\n",
      "2022-11-09 00:43:04,521 INFO     Training average positive_sample_loss at step 712800: 0.140198\n",
      "2022-11-09 00:43:04,521 INFO     Training average negative_sample_loss at step 712800: 0.136416\n",
      "2022-11-09 00:43:04,521 INFO     Training average loss at step 712800: 0.138307\n",
      "2022-11-09 00:43:10,882 INFO     Training average positive_sample_loss at step 712900: 0.142181\n",
      "2022-11-09 00:43:10,882 INFO     Training average negative_sample_loss at step 712900: 0.140552\n",
      "2022-11-09 00:43:10,882 INFO     Training average loss at step 712900: 0.141367\n",
      "2022-11-09 00:43:17,262 INFO     Training average positive_sample_loss at step 713000: 0.145670\n",
      "2022-11-09 00:43:17,262 INFO     Training average negative_sample_loss at step 713000: 0.141971\n",
      "2022-11-09 00:43:17,262 INFO     Training average loss at step 713000: 0.143820\n",
      "2022-11-09 00:43:23,619 INFO     Training average positive_sample_loss at step 713100: 0.144775\n",
      "2022-11-09 00:43:23,619 INFO     Training average negative_sample_loss at step 713100: 0.142958\n",
      "2022-11-09 00:43:23,619 INFO     Training average loss at step 713100: 0.143866\n",
      "2022-11-09 00:43:29,989 INFO     Training average positive_sample_loss at step 713200: 0.145982\n",
      "2022-11-09 00:43:29,989 INFO     Training average negative_sample_loss at step 713200: 0.137851\n",
      "2022-11-09 00:43:29,989 INFO     Training average loss at step 713200: 0.141916\n",
      "2022-11-09 00:43:36,351 INFO     Training average positive_sample_loss at step 713300: 0.141838\n",
      "2022-11-09 00:43:36,351 INFO     Training average negative_sample_loss at step 713300: 0.134173\n",
      "2022-11-09 00:43:36,351 INFO     Training average loss at step 713300: 0.138006\n",
      "2022-11-09 00:43:42,721 INFO     Training average positive_sample_loss at step 713400: 0.144195\n",
      "2022-11-09 00:43:42,721 INFO     Training average negative_sample_loss at step 713400: 0.143788\n",
      "2022-11-09 00:43:42,721 INFO     Training average loss at step 713400: 0.143991\n",
      "2022-11-09 00:43:49,080 INFO     Training average positive_sample_loss at step 713500: 0.139481\n",
      "2022-11-09 00:43:49,080 INFO     Training average negative_sample_loss at step 713500: 0.138446\n",
      "2022-11-09 00:43:49,080 INFO     Training average loss at step 713500: 0.138964\n",
      "2022-11-09 00:43:55,434 INFO     Training average positive_sample_loss at step 713600: 0.141956\n",
      "2022-11-09 00:43:55,434 INFO     Training average negative_sample_loss at step 713600: 0.138458\n",
      "2022-11-09 00:43:55,434 INFO     Training average loss at step 713600: 0.140207\n",
      "2022-11-09 00:44:01,796 INFO     Training average positive_sample_loss at step 713700: 0.145146\n",
      "2022-11-09 00:44:01,796 INFO     Training average negative_sample_loss at step 713700: 0.138429\n",
      "2022-11-09 00:44:01,796 INFO     Training average loss at step 713700: 0.141788\n",
      "2022-11-09 00:44:08,162 INFO     Training average positive_sample_loss at step 713800: 0.147746\n",
      "2022-11-09 00:44:08,162 INFO     Training average negative_sample_loss at step 713800: 0.140614\n",
      "2022-11-09 00:44:08,162 INFO     Training average loss at step 713800: 0.144180\n",
      "2022-11-09 00:44:14,522 INFO     Training average positive_sample_loss at step 713900: 0.145946\n",
      "2022-11-09 00:44:14,522 INFO     Training average negative_sample_loss at step 713900: 0.138906\n",
      "2022-11-09 00:44:14,522 INFO     Training average loss at step 713900: 0.142426\n",
      "2022-11-09 00:44:20,871 INFO     Training average positive_sample_loss at step 714000: 0.144619\n",
      "2022-11-09 00:44:20,871 INFO     Training average negative_sample_loss at step 714000: 0.137059\n",
      "2022-11-09 00:44:20,871 INFO     Training average loss at step 714000: 0.140839\n",
      "2022-11-09 00:44:27,243 INFO     Training average positive_sample_loss at step 714100: 0.141095\n",
      "2022-11-09 00:44:27,243 INFO     Training average negative_sample_loss at step 714100: 0.140111\n",
      "2022-11-09 00:44:27,243 INFO     Training average loss at step 714100: 0.140603\n",
      "2022-11-09 00:44:32,172 INFO     Training average positive_sample_loss at step 714200: 0.145903\n",
      "2022-11-09 00:44:32,172 INFO     Training average negative_sample_loss at step 714200: 0.139906\n",
      "2022-11-09 00:44:32,173 INFO     Training average loss at step 714200: 0.142905\n",
      "2022-11-09 00:44:38,531 INFO     Training average positive_sample_loss at step 714300: 0.145095\n",
      "2022-11-09 00:44:38,531 INFO     Training average negative_sample_loss at step 714300: 0.140634\n",
      "2022-11-09 00:44:38,531 INFO     Training average loss at step 714300: 0.142865\n",
      "2022-11-09 00:44:44,883 INFO     Training average positive_sample_loss at step 714400: 0.143570\n",
      "2022-11-09 00:44:44,883 INFO     Training average negative_sample_loss at step 714400: 0.141441\n",
      "2022-11-09 00:44:44,883 INFO     Training average loss at step 714400: 0.142505\n",
      "2022-11-09 00:44:51,245 INFO     Training average positive_sample_loss at step 714500: 0.149314\n",
      "2022-11-09 00:44:51,245 INFO     Training average negative_sample_loss at step 714500: 0.137813\n",
      "2022-11-09 00:44:51,245 INFO     Training average loss at step 714500: 0.143563\n",
      "2022-11-09 00:44:57,608 INFO     Training average positive_sample_loss at step 714600: 0.150772\n",
      "2022-11-09 00:44:57,608 INFO     Training average negative_sample_loss at step 714600: 0.141428\n",
      "2022-11-09 00:44:57,608 INFO     Training average loss at step 714600: 0.146100\n",
      "2022-11-09 00:45:03,986 INFO     Training average positive_sample_loss at step 714700: 0.144733\n",
      "2022-11-09 00:45:03,987 INFO     Training average negative_sample_loss at step 714700: 0.141123\n",
      "2022-11-09 00:45:03,987 INFO     Training average loss at step 714700: 0.142928\n",
      "2022-11-09 00:45:10,353 INFO     Training average positive_sample_loss at step 714800: 0.147073\n",
      "2022-11-09 00:45:10,353 INFO     Training average negative_sample_loss at step 714800: 0.139130\n",
      "2022-11-09 00:45:10,353 INFO     Training average loss at step 714800: 0.143101\n",
      "2022-11-09 00:45:16,720 INFO     Training average positive_sample_loss at step 714900: 0.142704\n",
      "2022-11-09 00:45:16,720 INFO     Training average negative_sample_loss at step 714900: 0.140542\n",
      "2022-11-09 00:45:16,720 INFO     Training average loss at step 714900: 0.141623\n",
      "2022-11-09 00:45:23,108 INFO     Training average positive_sample_loss at step 715000: 0.140119\n",
      "2022-11-09 00:45:23,108 INFO     Training average negative_sample_loss at step 715000: 0.138051\n",
      "2022-11-09 00:45:23,108 INFO     Training average loss at step 715000: 0.139085\n",
      "2022-11-09 00:45:29,512 INFO     Training average positive_sample_loss at step 715100: 0.141899\n",
      "2022-11-09 00:45:29,513 INFO     Training average negative_sample_loss at step 715100: 0.141454\n",
      "2022-11-09 00:45:29,513 INFO     Training average loss at step 715100: 0.141677\n",
      "2022-11-09 00:45:35,886 INFO     Training average positive_sample_loss at step 715200: 0.144934\n",
      "2022-11-09 00:45:35,886 INFO     Training average negative_sample_loss at step 715200: 0.146127\n",
      "2022-11-09 00:45:35,886 INFO     Training average loss at step 715200: 0.145531\n",
      "2022-11-09 00:45:42,252 INFO     Training average positive_sample_loss at step 715300: 0.142804\n",
      "2022-11-09 00:45:42,252 INFO     Training average negative_sample_loss at step 715300: 0.140330\n",
      "2022-11-09 00:45:42,252 INFO     Training average loss at step 715300: 0.141567\n",
      "2022-11-09 00:45:48,601 INFO     Training average positive_sample_loss at step 715400: 0.145624\n",
      "2022-11-09 00:45:48,601 INFO     Training average negative_sample_loss at step 715400: 0.141143\n",
      "2022-11-09 00:45:48,601 INFO     Training average loss at step 715400: 0.143384\n",
      "2022-11-09 00:45:54,955 INFO     Training average positive_sample_loss at step 715500: 0.145862\n",
      "2022-11-09 00:45:54,955 INFO     Training average negative_sample_loss at step 715500: 0.141310\n",
      "2022-11-09 00:45:54,955 INFO     Training average loss at step 715500: 0.143586\n",
      "2022-11-09 00:46:01,339 INFO     Training average positive_sample_loss at step 715600: 0.142936\n",
      "2022-11-09 00:46:01,339 INFO     Training average negative_sample_loss at step 715600: 0.138942\n",
      "2022-11-09 00:46:01,340 INFO     Training average loss at step 715600: 0.140939\n",
      "2022-11-09 00:46:07,717 INFO     Training average positive_sample_loss at step 715700: 0.142829\n",
      "2022-11-09 00:46:07,717 INFO     Training average negative_sample_loss at step 715700: 0.136578\n",
      "2022-11-09 00:46:07,717 INFO     Training average loss at step 715700: 0.139703\n",
      "2022-11-09 00:46:14,074 INFO     Training average positive_sample_loss at step 715800: 0.143694\n",
      "2022-11-09 00:46:14,074 INFO     Training average negative_sample_loss at step 715800: 0.140593\n",
      "2022-11-09 00:46:14,074 INFO     Training average loss at step 715800: 0.142143\n",
      "2022-11-09 00:46:20,466 INFO     Training average positive_sample_loss at step 715900: 0.144283\n",
      "2022-11-09 00:46:20,466 INFO     Training average negative_sample_loss at step 715900: 0.140915\n",
      "2022-11-09 00:46:20,466 INFO     Training average loss at step 715900: 0.142599\n",
      "2022-11-09 00:46:26,835 INFO     Training average positive_sample_loss at step 716000: 0.144923\n",
      "2022-11-09 00:46:26,835 INFO     Training average negative_sample_loss at step 716000: 0.137629\n",
      "2022-11-09 00:46:26,835 INFO     Training average loss at step 716000: 0.141276\n",
      "2022-11-09 00:46:33,227 INFO     Training average positive_sample_loss at step 716100: 0.141837\n",
      "2022-11-09 00:46:33,227 INFO     Training average negative_sample_loss at step 716100: 0.139015\n",
      "2022-11-09 00:46:33,227 INFO     Training average loss at step 716100: 0.140426\n",
      "2022-11-09 00:46:39,630 INFO     Training average positive_sample_loss at step 716200: 0.144484\n",
      "2022-11-09 00:46:39,630 INFO     Training average negative_sample_loss at step 716200: 0.139593\n",
      "2022-11-09 00:46:39,630 INFO     Training average loss at step 716200: 0.142039\n",
      "2022-11-09 00:46:46,029 INFO     Training average positive_sample_loss at step 716300: 0.145887\n",
      "2022-11-09 00:46:46,029 INFO     Training average negative_sample_loss at step 716300: 0.142164\n",
      "2022-11-09 00:46:46,029 INFO     Training average loss at step 716300: 0.144025\n",
      "2022-11-09 00:46:52,417 INFO     Training average positive_sample_loss at step 716400: 0.147610\n",
      "2022-11-09 00:46:52,418 INFO     Training average negative_sample_loss at step 716400: 0.138966\n",
      "2022-11-09 00:46:52,418 INFO     Training average loss at step 716400: 0.143288\n",
      "2022-11-09 00:46:58,825 INFO     Training average positive_sample_loss at step 716500: 0.150936\n",
      "2022-11-09 00:46:58,826 INFO     Training average negative_sample_loss at step 716500: 0.138274\n",
      "2022-11-09 00:46:58,826 INFO     Training average loss at step 716500: 0.144605\n",
      "2022-11-09 00:47:05,203 INFO     Training average positive_sample_loss at step 716600: 0.139967\n",
      "2022-11-09 00:47:05,203 INFO     Training average negative_sample_loss at step 716600: 0.140153\n",
      "2022-11-09 00:47:05,203 INFO     Training average loss at step 716600: 0.140060\n",
      "2022-11-09 00:47:11,550 INFO     Training average positive_sample_loss at step 716700: 0.141806\n",
      "2022-11-09 00:47:11,550 INFO     Training average negative_sample_loss at step 716700: 0.141233\n",
      "2022-11-09 00:47:11,550 INFO     Training average loss at step 716700: 0.141520\n",
      "2022-11-09 00:47:17,912 INFO     Training average positive_sample_loss at step 716800: 0.148226\n",
      "2022-11-09 00:47:17,912 INFO     Training average negative_sample_loss at step 716800: 0.142653\n",
      "2022-11-09 00:47:17,912 INFO     Training average loss at step 716800: 0.145439\n",
      "2022-11-09 00:47:24,257 INFO     Training average positive_sample_loss at step 716900: 0.145633\n",
      "2022-11-09 00:47:24,257 INFO     Training average negative_sample_loss at step 716900: 0.140043\n",
      "2022-11-09 00:47:24,257 INFO     Training average loss at step 716900: 0.142838\n",
      "2022-11-09 00:47:30,633 INFO     Training average positive_sample_loss at step 717000: 0.144667\n",
      "2022-11-09 00:47:30,633 INFO     Training average negative_sample_loss at step 717000: 0.142087\n",
      "2022-11-09 00:47:30,633 INFO     Training average loss at step 717000: 0.143377\n",
      "2022-11-09 00:47:37,014 INFO     Training average positive_sample_loss at step 717100: 0.152912\n",
      "2022-11-09 00:47:37,014 INFO     Training average negative_sample_loss at step 717100: 0.144219\n",
      "2022-11-09 00:47:37,014 INFO     Training average loss at step 717100: 0.148566\n",
      "2022-11-09 00:47:43,371 INFO     Training average positive_sample_loss at step 717200: 0.146440\n",
      "2022-11-09 00:47:43,372 INFO     Training average negative_sample_loss at step 717200: 0.141816\n",
      "2022-11-09 00:47:43,372 INFO     Training average loss at step 717200: 0.144128\n",
      "2022-11-09 00:47:49,733 INFO     Training average positive_sample_loss at step 717300: 0.142925\n",
      "2022-11-09 00:47:49,733 INFO     Training average negative_sample_loss at step 717300: 0.141534\n",
      "2022-11-09 00:47:49,733 INFO     Training average loss at step 717300: 0.142229\n",
      "2022-11-09 00:47:56,095 INFO     Training average positive_sample_loss at step 717400: 0.140007\n",
      "2022-11-09 00:47:56,095 INFO     Training average negative_sample_loss at step 717400: 0.143084\n",
      "2022-11-09 00:47:56,095 INFO     Training average loss at step 717400: 0.141546\n",
      "2022-11-09 00:48:02,464 INFO     Training average positive_sample_loss at step 717500: 0.142458\n",
      "2022-11-09 00:48:02,464 INFO     Training average negative_sample_loss at step 717500: 0.135996\n",
      "2022-11-09 00:48:02,464 INFO     Training average loss at step 717500: 0.139227\n",
      "2022-11-09 00:48:08,819 INFO     Training average positive_sample_loss at step 717600: 0.146966\n",
      "2022-11-09 00:48:08,819 INFO     Training average negative_sample_loss at step 717600: 0.138086\n",
      "2022-11-09 00:48:08,819 INFO     Training average loss at step 717600: 0.142526\n",
      "2022-11-09 00:48:15,164 INFO     Training average positive_sample_loss at step 717700: 0.149540\n",
      "2022-11-09 00:48:15,164 INFO     Training average negative_sample_loss at step 717700: 0.142047\n",
      "2022-11-09 00:48:15,164 INFO     Training average loss at step 717700: 0.145793\n",
      "2022-11-09 00:48:21,516 INFO     Training average positive_sample_loss at step 717800: 0.148157\n",
      "2022-11-09 00:48:21,516 INFO     Training average negative_sample_loss at step 717800: 0.141320\n",
      "2022-11-09 00:48:21,516 INFO     Training average loss at step 717800: 0.144738\n",
      "2022-11-09 00:48:27,876 INFO     Training average positive_sample_loss at step 717900: 0.149047\n",
      "2022-11-09 00:48:27,876 INFO     Training average negative_sample_loss at step 717900: 0.137598\n",
      "2022-11-09 00:48:27,876 INFO     Training average loss at step 717900: 0.143322\n",
      "2022-11-09 00:48:34,254 INFO     Training average positive_sample_loss at step 718000: 0.150963\n",
      "2022-11-09 00:48:34,254 INFO     Training average negative_sample_loss at step 718000: 0.139454\n",
      "2022-11-09 00:48:34,254 INFO     Training average loss at step 718000: 0.145209\n",
      "2022-11-09 00:48:40,637 INFO     Training average positive_sample_loss at step 718100: 0.144516\n",
      "2022-11-09 00:48:40,638 INFO     Training average negative_sample_loss at step 718100: 0.140407\n",
      "2022-11-09 00:48:40,638 INFO     Training average loss at step 718100: 0.142462\n",
      "2022-11-09 00:48:47,018 INFO     Training average positive_sample_loss at step 718200: 0.148847\n",
      "2022-11-09 00:48:47,018 INFO     Training average negative_sample_loss at step 718200: 0.142804\n",
      "2022-11-09 00:48:47,018 INFO     Training average loss at step 718200: 0.145825\n",
      "2022-11-09 00:48:53,380 INFO     Training average positive_sample_loss at step 718300: 0.144351\n",
      "2022-11-09 00:48:53,380 INFO     Training average negative_sample_loss at step 718300: 0.138116\n",
      "2022-11-09 00:48:53,380 INFO     Training average loss at step 718300: 0.141233\n",
      "2022-11-09 00:48:59,742 INFO     Training average positive_sample_loss at step 718400: 0.149258\n",
      "2022-11-09 00:48:59,742 INFO     Training average negative_sample_loss at step 718400: 0.141715\n",
      "2022-11-09 00:48:59,742 INFO     Training average loss at step 718400: 0.145487\n",
      "2022-11-09 00:49:06,111 INFO     Training average positive_sample_loss at step 718500: 0.142960\n",
      "2022-11-09 00:49:06,111 INFO     Training average negative_sample_loss at step 718500: 0.141948\n",
      "2022-11-09 00:49:06,111 INFO     Training average loss at step 718500: 0.142454\n",
      "2022-11-09 00:49:12,470 INFO     Training average positive_sample_loss at step 718600: 0.146097\n",
      "2022-11-09 00:49:12,470 INFO     Training average negative_sample_loss at step 718600: 0.142296\n",
      "2022-11-09 00:49:12,470 INFO     Training average loss at step 718600: 0.144197\n",
      "2022-11-09 00:49:18,834 INFO     Training average positive_sample_loss at step 718700: 0.148470\n",
      "2022-11-09 00:49:18,834 INFO     Training average negative_sample_loss at step 718700: 0.140838\n",
      "2022-11-09 00:49:18,834 INFO     Training average loss at step 718700: 0.144654\n",
      "2022-11-09 00:49:25,182 INFO     Training average positive_sample_loss at step 718800: 0.150683\n",
      "2022-11-09 00:49:25,182 INFO     Training average negative_sample_loss at step 718800: 0.139896\n",
      "2022-11-09 00:49:25,182 INFO     Training average loss at step 718800: 0.145290\n",
      "2022-11-09 00:49:31,541 INFO     Training average positive_sample_loss at step 718900: 0.146893\n",
      "2022-11-09 00:49:31,541 INFO     Training average negative_sample_loss at step 718900: 0.140906\n",
      "2022-11-09 00:49:31,541 INFO     Training average loss at step 718900: 0.143899\n",
      "2022-11-09 00:49:37,904 INFO     Training average positive_sample_loss at step 719000: 0.148351\n",
      "2022-11-09 00:49:37,904 INFO     Training average negative_sample_loss at step 719000: 0.139268\n",
      "2022-11-09 00:49:37,904 INFO     Training average loss at step 719000: 0.143809\n",
      "2022-11-09 00:49:44,253 INFO     Training average positive_sample_loss at step 719100: 0.139695\n",
      "2022-11-09 00:49:44,253 INFO     Training average negative_sample_loss at step 719100: 0.137547\n",
      "2022-11-09 00:49:44,253 INFO     Training average loss at step 719100: 0.138621\n",
      "2022-11-09 00:49:50,605 INFO     Training average positive_sample_loss at step 719200: 0.146485\n",
      "2022-11-09 00:49:50,605 INFO     Training average negative_sample_loss at step 719200: 0.139434\n",
      "2022-11-09 00:49:50,605 INFO     Training average loss at step 719200: 0.142959\n",
      "2022-11-09 00:49:56,979 INFO     Training average positive_sample_loss at step 719300: 0.143141\n",
      "2022-11-09 00:49:56,980 INFO     Training average negative_sample_loss at step 719300: 0.140776\n",
      "2022-11-09 00:49:56,980 INFO     Training average loss at step 719300: 0.141958\n",
      "2022-11-09 00:50:03,327 INFO     Training average positive_sample_loss at step 719400: 0.143292\n",
      "2022-11-09 00:50:03,327 INFO     Training average negative_sample_loss at step 719400: 0.141151\n",
      "2022-11-09 00:50:03,327 INFO     Training average loss at step 719400: 0.142222\n",
      "2022-11-09 00:50:09,681 INFO     Training average positive_sample_loss at step 719500: 0.146543\n",
      "2022-11-09 00:50:09,681 INFO     Training average negative_sample_loss at step 719500: 0.140582\n",
      "2022-11-09 00:50:09,681 INFO     Training average loss at step 719500: 0.143563\n",
      "2022-11-09 00:50:16,023 INFO     Training average positive_sample_loss at step 719600: 0.142751\n",
      "2022-11-09 00:50:16,023 INFO     Training average negative_sample_loss at step 719600: 0.138480\n",
      "2022-11-09 00:50:16,023 INFO     Training average loss at step 719600: 0.140616\n",
      "2022-11-09 00:50:22,368 INFO     Training average positive_sample_loss at step 719700: 0.144060\n",
      "2022-11-09 00:50:22,368 INFO     Training average negative_sample_loss at step 719700: 0.136797\n",
      "2022-11-09 00:50:22,368 INFO     Training average loss at step 719700: 0.140428\n",
      "2022-11-09 00:50:28,720 INFO     Training average positive_sample_loss at step 719800: 0.146077\n",
      "2022-11-09 00:50:28,720 INFO     Training average negative_sample_loss at step 719800: 0.139338\n",
      "2022-11-09 00:50:28,720 INFO     Training average loss at step 719800: 0.142707\n",
      "2022-11-09 00:50:33,691 INFO     Training average positive_sample_loss at step 719900: 0.154488\n",
      "2022-11-09 00:50:33,691 INFO     Training average negative_sample_loss at step 719900: 0.141745\n",
      "2022-11-09 00:50:33,691 INFO     Training average loss at step 719900: 0.148117\n",
      "2022-11-09 00:50:42,887 INFO     Training average positive_sample_loss at step 720000: 0.142494\n",
      "2022-11-09 00:50:42,887 INFO     Training average negative_sample_loss at step 720000: 0.138005\n",
      "2022-11-09 00:50:42,887 INFO     Training average loss at step 720000: 0.140249\n",
      "2022-11-09 00:50:49,282 INFO     Training average positive_sample_loss at step 720100: 0.146973\n",
      "2022-11-09 00:50:49,282 INFO     Training average negative_sample_loss at step 720100: 0.137060\n",
      "2022-11-09 00:50:49,282 INFO     Training average loss at step 720100: 0.142016\n",
      "2022-11-09 00:50:55,650 INFO     Training average positive_sample_loss at step 720200: 0.146913\n",
      "2022-11-09 00:50:55,650 INFO     Training average negative_sample_loss at step 720200: 0.134669\n",
      "2022-11-09 00:50:55,650 INFO     Training average loss at step 720200: 0.140791\n",
      "2022-11-09 00:51:02,017 INFO     Training average positive_sample_loss at step 720300: 0.144307\n",
      "2022-11-09 00:51:02,018 INFO     Training average negative_sample_loss at step 720300: 0.142424\n",
      "2022-11-09 00:51:02,018 INFO     Training average loss at step 720300: 0.143366\n",
      "2022-11-09 00:51:08,382 INFO     Training average positive_sample_loss at step 720400: 0.147989\n",
      "2022-11-09 00:51:08,382 INFO     Training average negative_sample_loss at step 720400: 0.140252\n",
      "2022-11-09 00:51:08,382 INFO     Training average loss at step 720400: 0.144121\n",
      "2022-11-09 00:51:14,750 INFO     Training average positive_sample_loss at step 720500: 0.143208\n",
      "2022-11-09 00:51:14,750 INFO     Training average negative_sample_loss at step 720500: 0.138344\n",
      "2022-11-09 00:51:14,750 INFO     Training average loss at step 720500: 0.140776\n",
      "2022-11-09 00:51:21,115 INFO     Training average positive_sample_loss at step 720600: 0.146498\n",
      "2022-11-09 00:51:21,115 INFO     Training average negative_sample_loss at step 720600: 0.142008\n",
      "2022-11-09 00:51:21,115 INFO     Training average loss at step 720600: 0.144253\n",
      "2022-11-09 00:51:27,465 INFO     Training average positive_sample_loss at step 720700: 0.148406\n",
      "2022-11-09 00:51:27,466 INFO     Training average negative_sample_loss at step 720700: 0.139753\n",
      "2022-11-09 00:51:27,466 INFO     Training average loss at step 720700: 0.144079\n",
      "2022-11-09 00:51:33,859 INFO     Training average positive_sample_loss at step 720800: 0.148779\n",
      "2022-11-09 00:51:33,859 INFO     Training average negative_sample_loss at step 720800: 0.140630\n",
      "2022-11-09 00:51:33,859 INFO     Training average loss at step 720800: 0.144704\n",
      "2022-11-09 00:51:40,214 INFO     Training average positive_sample_loss at step 720900: 0.143509\n",
      "2022-11-09 00:51:40,215 INFO     Training average negative_sample_loss at step 720900: 0.139568\n",
      "2022-11-09 00:51:40,215 INFO     Training average loss at step 720900: 0.141539\n",
      "2022-11-09 00:51:46,567 INFO     Training average positive_sample_loss at step 721000: 0.145880\n",
      "2022-11-09 00:51:46,568 INFO     Training average negative_sample_loss at step 721000: 0.139588\n",
      "2022-11-09 00:51:46,568 INFO     Training average loss at step 721000: 0.142734\n",
      "2022-11-09 00:51:52,914 INFO     Training average positive_sample_loss at step 721100: 0.145247\n",
      "2022-11-09 00:51:52,915 INFO     Training average negative_sample_loss at step 721100: 0.139043\n",
      "2022-11-09 00:51:52,915 INFO     Training average loss at step 721100: 0.142145\n",
      "2022-11-09 00:51:59,267 INFO     Training average positive_sample_loss at step 721200: 0.146947\n",
      "2022-11-09 00:51:59,267 INFO     Training average negative_sample_loss at step 721200: 0.138931\n",
      "2022-11-09 00:51:59,267 INFO     Training average loss at step 721200: 0.142939\n",
      "2022-11-09 00:52:05,633 INFO     Training average positive_sample_loss at step 721300: 0.146425\n",
      "2022-11-09 00:52:05,633 INFO     Training average negative_sample_loss at step 721300: 0.142790\n",
      "2022-11-09 00:52:05,633 INFO     Training average loss at step 721300: 0.144608\n",
      "2022-11-09 00:52:12,031 INFO     Training average positive_sample_loss at step 721400: 0.147437\n",
      "2022-11-09 00:52:12,031 INFO     Training average negative_sample_loss at step 721400: 0.135991\n",
      "2022-11-09 00:52:12,031 INFO     Training average loss at step 721400: 0.141714\n",
      "2022-11-09 00:52:18,413 INFO     Training average positive_sample_loss at step 721500: 0.142996\n",
      "2022-11-09 00:52:18,413 INFO     Training average negative_sample_loss at step 721500: 0.137788\n",
      "2022-11-09 00:52:18,413 INFO     Training average loss at step 721500: 0.140392\n",
      "2022-11-09 00:52:24,767 INFO     Training average positive_sample_loss at step 721600: 0.148065\n",
      "2022-11-09 00:52:24,767 INFO     Training average negative_sample_loss at step 721600: 0.142611\n",
      "2022-11-09 00:52:24,767 INFO     Training average loss at step 721600: 0.145338\n",
      "2022-11-09 00:52:31,184 INFO     Training average positive_sample_loss at step 721700: 0.142745\n",
      "2022-11-09 00:52:31,184 INFO     Training average negative_sample_loss at step 721700: 0.140089\n",
      "2022-11-09 00:52:31,184 INFO     Training average loss at step 721700: 0.141417\n",
      "2022-11-09 00:52:37,580 INFO     Training average positive_sample_loss at step 721800: 0.142993\n",
      "2022-11-09 00:52:37,580 INFO     Training average negative_sample_loss at step 721800: 0.138725\n",
      "2022-11-09 00:52:37,580 INFO     Training average loss at step 721800: 0.140859\n",
      "2022-11-09 00:52:43,967 INFO     Training average positive_sample_loss at step 721900: 0.143810\n",
      "2022-11-09 00:52:43,967 INFO     Training average negative_sample_loss at step 721900: 0.141809\n",
      "2022-11-09 00:52:43,967 INFO     Training average loss at step 721900: 0.142809\n",
      "2022-11-09 00:52:50,393 INFO     Training average positive_sample_loss at step 722000: 0.145713\n",
      "2022-11-09 00:52:50,393 INFO     Training average negative_sample_loss at step 722000: 0.142657\n",
      "2022-11-09 00:52:50,393 INFO     Training average loss at step 722000: 0.144185\n",
      "2022-11-09 00:52:56,776 INFO     Training average positive_sample_loss at step 722100: 0.142823\n",
      "2022-11-09 00:52:56,776 INFO     Training average negative_sample_loss at step 722100: 0.140801\n",
      "2022-11-09 00:52:56,776 INFO     Training average loss at step 722100: 0.141812\n",
      "2022-11-09 00:53:03,176 INFO     Training average positive_sample_loss at step 722200: 0.143876\n",
      "2022-11-09 00:53:03,176 INFO     Training average negative_sample_loss at step 722200: 0.138931\n",
      "2022-11-09 00:53:03,176 INFO     Training average loss at step 722200: 0.141403\n",
      "2022-11-09 00:53:09,557 INFO     Training average positive_sample_loss at step 722300: 0.149581\n",
      "2022-11-09 00:53:09,557 INFO     Training average negative_sample_loss at step 722300: 0.141549\n",
      "2022-11-09 00:53:09,557 INFO     Training average loss at step 722300: 0.145565\n",
      "2022-11-09 00:53:15,920 INFO     Training average positive_sample_loss at step 722400: 0.143412\n",
      "2022-11-09 00:53:15,920 INFO     Training average negative_sample_loss at step 722400: 0.140975\n",
      "2022-11-09 00:53:15,920 INFO     Training average loss at step 722400: 0.142194\n",
      "2022-11-09 00:53:22,274 INFO     Training average positive_sample_loss at step 722500: 0.148814\n",
      "2022-11-09 00:53:22,274 INFO     Training average negative_sample_loss at step 722500: 0.142953\n",
      "2022-11-09 00:53:22,274 INFO     Training average loss at step 722500: 0.145884\n",
      "2022-11-09 00:53:31,957 INFO     Training average positive_sample_loss at step 722600: 0.142342\n",
      "2022-11-09 00:53:31,957 INFO     Training average negative_sample_loss at step 722600: 0.135088\n",
      "2022-11-09 00:53:31,957 INFO     Training average loss at step 722600: 0.138715\n",
      "2022-11-09 00:53:38,308 INFO     Training average positive_sample_loss at step 722700: 0.144794\n",
      "2022-11-09 00:53:38,309 INFO     Training average negative_sample_loss at step 722700: 0.134750\n",
      "2022-11-09 00:53:38,309 INFO     Training average loss at step 722700: 0.139772\n",
      "2022-11-09 00:53:44,668 INFO     Training average positive_sample_loss at step 722800: 0.145763\n",
      "2022-11-09 00:53:44,668 INFO     Training average negative_sample_loss at step 722800: 0.137795\n",
      "2022-11-09 00:53:44,668 INFO     Training average loss at step 722800: 0.141779\n",
      "2022-11-09 00:53:51,045 INFO     Training average positive_sample_loss at step 722900: 0.147751\n",
      "2022-11-09 00:53:51,046 INFO     Training average negative_sample_loss at step 722900: 0.141755\n",
      "2022-11-09 00:53:51,046 INFO     Training average loss at step 722900: 0.144753\n",
      "2022-11-09 00:53:55,154 INFO     Training average positive_sample_loss at step 723000: 0.147310\n",
      "2022-11-09 00:53:55,154 INFO     Training average negative_sample_loss at step 723000: 0.139422\n",
      "2022-11-09 00:53:55,154 INFO     Training average loss at step 723000: 0.143366\n",
      "2022-11-09 00:54:00,781 INFO     Training average positive_sample_loss at step 723100: 0.149550\n",
      "2022-11-09 00:54:00,781 INFO     Training average negative_sample_loss at step 723100: 0.135849\n",
      "2022-11-09 00:54:00,781 INFO     Training average loss at step 723100: 0.142699\n",
      "2022-11-09 00:54:07,162 INFO     Training average positive_sample_loss at step 723200: 0.148520\n",
      "2022-11-09 00:54:07,162 INFO     Training average negative_sample_loss at step 723200: 0.137824\n",
      "2022-11-09 00:54:07,162 INFO     Training average loss at step 723200: 0.143172\n",
      "2022-11-09 00:54:13,540 INFO     Training average positive_sample_loss at step 723300: 0.142896\n",
      "2022-11-09 00:54:13,540 INFO     Training average negative_sample_loss at step 723300: 0.137863\n",
      "2022-11-09 00:54:13,540 INFO     Training average loss at step 723300: 0.140380\n",
      "2022-11-09 00:54:19,906 INFO     Training average positive_sample_loss at step 723400: 0.150367\n",
      "2022-11-09 00:54:19,906 INFO     Training average negative_sample_loss at step 723400: 0.137569\n",
      "2022-11-09 00:54:19,906 INFO     Training average loss at step 723400: 0.143968\n",
      "2022-11-09 00:54:26,274 INFO     Training average positive_sample_loss at step 723500: 0.145407\n",
      "2022-11-09 00:54:26,274 INFO     Training average negative_sample_loss at step 723500: 0.138444\n",
      "2022-11-09 00:54:26,274 INFO     Training average loss at step 723500: 0.141925\n",
      "2022-11-09 00:54:32,618 INFO     Training average positive_sample_loss at step 723600: 0.143366\n",
      "2022-11-09 00:54:32,618 INFO     Training average negative_sample_loss at step 723600: 0.140510\n",
      "2022-11-09 00:54:32,618 INFO     Training average loss at step 723600: 0.141938\n",
      "2022-11-09 00:54:38,975 INFO     Training average positive_sample_loss at step 723700: 0.146004\n",
      "2022-11-09 00:54:38,975 INFO     Training average negative_sample_loss at step 723700: 0.137428\n",
      "2022-11-09 00:54:38,975 INFO     Training average loss at step 723700: 0.141716\n",
      "2022-11-09 00:54:45,350 INFO     Training average positive_sample_loss at step 723800: 0.147974\n",
      "2022-11-09 00:54:45,350 INFO     Training average negative_sample_loss at step 723800: 0.139620\n",
      "2022-11-09 00:54:45,350 INFO     Training average loss at step 723800: 0.143797\n",
      "2022-11-09 00:54:51,724 INFO     Training average positive_sample_loss at step 723900: 0.147591\n",
      "2022-11-09 00:54:51,724 INFO     Training average negative_sample_loss at step 723900: 0.140956\n",
      "2022-11-09 00:54:51,724 INFO     Training average loss at step 723900: 0.144273\n",
      "2022-11-09 00:54:58,128 INFO     Training average positive_sample_loss at step 724000: 0.146017\n",
      "2022-11-09 00:54:58,128 INFO     Training average negative_sample_loss at step 724000: 0.141438\n",
      "2022-11-09 00:54:58,128 INFO     Training average loss at step 724000: 0.143728\n",
      "2022-11-09 00:55:04,517 INFO     Training average positive_sample_loss at step 724100: 0.147682\n",
      "2022-11-09 00:55:04,517 INFO     Training average negative_sample_loss at step 724100: 0.136271\n",
      "2022-11-09 00:55:04,517 INFO     Training average loss at step 724100: 0.141977\n",
      "2022-11-09 00:55:10,893 INFO     Training average positive_sample_loss at step 724200: 0.145729\n",
      "2022-11-09 00:55:10,893 INFO     Training average negative_sample_loss at step 724200: 0.145126\n",
      "2022-11-09 00:55:10,893 INFO     Training average loss at step 724200: 0.145428\n",
      "2022-11-09 00:55:17,262 INFO     Training average positive_sample_loss at step 724300: 0.148538\n",
      "2022-11-09 00:55:17,262 INFO     Training average negative_sample_loss at step 724300: 0.139142\n",
      "2022-11-09 00:55:17,262 INFO     Training average loss at step 724300: 0.143840\n",
      "2022-11-09 00:55:23,599 INFO     Training average positive_sample_loss at step 724400: 0.147157\n",
      "2022-11-09 00:55:23,599 INFO     Training average negative_sample_loss at step 724400: 0.132691\n",
      "2022-11-09 00:55:23,599 INFO     Training average loss at step 724400: 0.139924\n",
      "2022-11-09 00:55:29,960 INFO     Training average positive_sample_loss at step 724500: 0.145002\n",
      "2022-11-09 00:55:29,960 INFO     Training average negative_sample_loss at step 724500: 0.145082\n",
      "2022-11-09 00:55:29,960 INFO     Training average loss at step 724500: 0.145042\n",
      "2022-11-09 00:55:36,333 INFO     Training average positive_sample_loss at step 724600: 0.142384\n",
      "2022-11-09 00:55:36,333 INFO     Training average negative_sample_loss at step 724600: 0.139283\n",
      "2022-11-09 00:55:36,333 INFO     Training average loss at step 724600: 0.140834\n",
      "2022-11-09 00:55:42,682 INFO     Training average positive_sample_loss at step 724700: 0.148086\n",
      "2022-11-09 00:55:42,682 INFO     Training average negative_sample_loss at step 724700: 0.138353\n",
      "2022-11-09 00:55:42,682 INFO     Training average loss at step 724700: 0.143220\n",
      "2022-11-09 00:55:49,028 INFO     Training average positive_sample_loss at step 724800: 0.146132\n",
      "2022-11-09 00:55:49,028 INFO     Training average negative_sample_loss at step 724800: 0.140236\n",
      "2022-11-09 00:55:49,028 INFO     Training average loss at step 724800: 0.143184\n",
      "2022-11-09 00:55:55,388 INFO     Training average positive_sample_loss at step 724900: 0.152039\n",
      "2022-11-09 00:55:55,388 INFO     Training average negative_sample_loss at step 724900: 0.138122\n",
      "2022-11-09 00:55:55,388 INFO     Training average loss at step 724900: 0.145080\n",
      "2022-11-09 00:56:01,780 INFO     Training average positive_sample_loss at step 725000: 0.145389\n",
      "2022-11-09 00:56:01,780 INFO     Training average negative_sample_loss at step 725000: 0.141885\n",
      "2022-11-09 00:56:01,780 INFO     Training average loss at step 725000: 0.143637\n",
      "2022-11-09 00:56:08,166 INFO     Training average positive_sample_loss at step 725100: 0.149817\n",
      "2022-11-09 00:56:08,166 INFO     Training average negative_sample_loss at step 725100: 0.138999\n",
      "2022-11-09 00:56:08,166 INFO     Training average loss at step 725100: 0.144408\n",
      "2022-11-09 00:56:14,529 INFO     Training average positive_sample_loss at step 725200: 0.145456\n",
      "2022-11-09 00:56:14,529 INFO     Training average negative_sample_loss at step 725200: 0.143976\n",
      "2022-11-09 00:56:14,529 INFO     Training average loss at step 725200: 0.144716\n",
      "2022-11-09 00:56:20,932 INFO     Training average positive_sample_loss at step 725300: 0.149432\n",
      "2022-11-09 00:56:20,932 INFO     Training average negative_sample_loss at step 725300: 0.138763\n",
      "2022-11-09 00:56:20,932 INFO     Training average loss at step 725300: 0.144098\n",
      "2022-11-09 00:56:27,303 INFO     Training average positive_sample_loss at step 725400: 0.146097\n",
      "2022-11-09 00:56:27,303 INFO     Training average negative_sample_loss at step 725400: 0.141238\n",
      "2022-11-09 00:56:27,303 INFO     Training average loss at step 725400: 0.143668\n",
      "2022-11-09 00:56:32,369 INFO     Training average positive_sample_loss at step 725500: 0.149992\n",
      "2022-11-09 00:56:32,369 INFO     Training average negative_sample_loss at step 725500: 0.135454\n",
      "2022-11-09 00:56:32,369 INFO     Training average loss at step 725500: 0.142723\n",
      "2022-11-09 00:56:38,730 INFO     Training average positive_sample_loss at step 725600: 0.145063\n",
      "2022-11-09 00:56:38,730 INFO     Training average negative_sample_loss at step 725600: 0.140116\n",
      "2022-11-09 00:56:38,730 INFO     Training average loss at step 725600: 0.142590\n",
      "2022-11-09 00:56:45,080 INFO     Training average positive_sample_loss at step 725700: 0.149641\n",
      "2022-11-09 00:56:45,080 INFO     Training average negative_sample_loss at step 725700: 0.136182\n",
      "2022-11-09 00:56:45,080 INFO     Training average loss at step 725700: 0.142911\n",
      "2022-11-09 00:56:51,451 INFO     Training average positive_sample_loss at step 725800: 0.143727\n",
      "2022-11-09 00:56:51,451 INFO     Training average negative_sample_loss at step 725800: 0.138806\n",
      "2022-11-09 00:56:51,451 INFO     Training average loss at step 725800: 0.141266\n",
      "2022-11-09 00:56:57,827 INFO     Training average positive_sample_loss at step 725900: 0.145367\n",
      "2022-11-09 00:56:57,827 INFO     Training average negative_sample_loss at step 725900: 0.135673\n",
      "2022-11-09 00:56:57,827 INFO     Training average loss at step 725900: 0.140520\n",
      "2022-11-09 00:57:04,172 INFO     Training average positive_sample_loss at step 726000: 0.147788\n",
      "2022-11-09 00:57:04,172 INFO     Training average negative_sample_loss at step 726000: 0.135232\n",
      "2022-11-09 00:57:04,172 INFO     Training average loss at step 726000: 0.141510\n",
      "2022-11-09 00:57:10,542 INFO     Training average positive_sample_loss at step 726100: 0.145778\n",
      "2022-11-09 00:57:10,542 INFO     Training average negative_sample_loss at step 726100: 0.140707\n",
      "2022-11-09 00:57:10,542 INFO     Training average loss at step 726100: 0.143243\n",
      "2022-11-09 00:57:16,934 INFO     Training average positive_sample_loss at step 726200: 0.148792\n",
      "2022-11-09 00:57:16,934 INFO     Training average negative_sample_loss at step 726200: 0.139054\n",
      "2022-11-09 00:57:16,934 INFO     Training average loss at step 726200: 0.143923\n",
      "2022-11-09 00:57:23,311 INFO     Training average positive_sample_loss at step 726300: 0.145290\n",
      "2022-11-09 00:57:23,311 INFO     Training average negative_sample_loss at step 726300: 0.143367\n",
      "2022-11-09 00:57:23,311 INFO     Training average loss at step 726300: 0.144329\n",
      "2022-11-09 00:57:29,693 INFO     Training average positive_sample_loss at step 726400: 0.149460\n",
      "2022-11-09 00:57:29,693 INFO     Training average negative_sample_loss at step 726400: 0.140533\n",
      "2022-11-09 00:57:29,693 INFO     Training average loss at step 726400: 0.144996\n",
      "2022-11-09 00:57:36,041 INFO     Training average positive_sample_loss at step 726500: 0.146825\n",
      "2022-11-09 00:57:36,041 INFO     Training average negative_sample_loss at step 726500: 0.141093\n",
      "2022-11-09 00:57:36,041 INFO     Training average loss at step 726500: 0.143959\n",
      "2022-11-09 00:57:42,392 INFO     Training average positive_sample_loss at step 726600: 0.145701\n",
      "2022-11-09 00:57:42,392 INFO     Training average negative_sample_loss at step 726600: 0.137828\n",
      "2022-11-09 00:57:42,392 INFO     Training average loss at step 726600: 0.141764\n",
      "2022-11-09 00:57:48,768 INFO     Training average positive_sample_loss at step 726700: 0.144522\n",
      "2022-11-09 00:57:48,768 INFO     Training average negative_sample_loss at step 726700: 0.141604\n",
      "2022-11-09 00:57:48,769 INFO     Training average loss at step 726700: 0.143063\n",
      "2022-11-09 00:57:55,115 INFO     Training average positive_sample_loss at step 726800: 0.145932\n",
      "2022-11-09 00:57:55,115 INFO     Training average negative_sample_loss at step 726800: 0.139675\n",
      "2022-11-09 00:57:55,115 INFO     Training average loss at step 726800: 0.142803\n",
      "2022-11-09 00:58:01,472 INFO     Training average positive_sample_loss at step 726900: 0.143490\n",
      "2022-11-09 00:58:01,472 INFO     Training average negative_sample_loss at step 726900: 0.141389\n",
      "2022-11-09 00:58:01,472 INFO     Training average loss at step 726900: 0.142440\n",
      "2022-11-09 00:58:07,818 INFO     Training average positive_sample_loss at step 727000: 0.142520\n",
      "2022-11-09 00:58:07,818 INFO     Training average negative_sample_loss at step 727000: 0.142727\n",
      "2022-11-09 00:58:07,818 INFO     Training average loss at step 727000: 0.142623\n",
      "2022-11-09 00:58:14,168 INFO     Training average positive_sample_loss at step 727100: 0.150698\n",
      "2022-11-09 00:58:14,168 INFO     Training average negative_sample_loss at step 727100: 0.141161\n",
      "2022-11-09 00:58:14,168 INFO     Training average loss at step 727100: 0.145929\n",
      "2022-11-09 00:58:20,517 INFO     Training average positive_sample_loss at step 727200: 0.144566\n",
      "2022-11-09 00:58:20,517 INFO     Training average negative_sample_loss at step 727200: 0.140887\n",
      "2022-11-09 00:58:20,517 INFO     Training average loss at step 727200: 0.142727\n",
      "2022-11-09 00:58:29,982 INFO     Training average positive_sample_loss at step 727300: 0.150959\n",
      "2022-11-09 00:58:29,982 INFO     Training average negative_sample_loss at step 727300: 0.137911\n",
      "2022-11-09 00:58:29,982 INFO     Training average loss at step 727300: 0.144435\n",
      "2022-11-09 00:58:36,327 INFO     Training average positive_sample_loss at step 727400: 0.145356\n",
      "2022-11-09 00:58:36,327 INFO     Training average negative_sample_loss at step 727400: 0.139443\n",
      "2022-11-09 00:58:36,327 INFO     Training average loss at step 727400: 0.142399\n",
      "2022-11-09 00:58:42,723 INFO     Training average positive_sample_loss at step 727500: 0.146998\n",
      "2022-11-09 00:58:42,723 INFO     Training average negative_sample_loss at step 727500: 0.141050\n",
      "2022-11-09 00:58:42,723 INFO     Training average loss at step 727500: 0.144024\n",
      "2022-11-09 00:58:49,110 INFO     Training average positive_sample_loss at step 727600: 0.147239\n",
      "2022-11-09 00:58:49,110 INFO     Training average negative_sample_loss at step 727600: 0.137883\n",
      "2022-11-09 00:58:49,110 INFO     Training average loss at step 727600: 0.142561\n",
      "2022-11-09 00:58:55,503 INFO     Training average positive_sample_loss at step 727700: 0.148407\n",
      "2022-11-09 00:58:55,503 INFO     Training average negative_sample_loss at step 727700: 0.137563\n",
      "2022-11-09 00:58:55,503 INFO     Training average loss at step 727700: 0.142985\n",
      "2022-11-09 00:59:01,864 INFO     Training average positive_sample_loss at step 727800: 0.145934\n",
      "2022-11-09 00:59:01,864 INFO     Training average negative_sample_loss at step 727800: 0.137542\n",
      "2022-11-09 00:59:01,864 INFO     Training average loss at step 727800: 0.141738\n",
      "2022-11-09 00:59:08,234 INFO     Training average positive_sample_loss at step 727900: 0.142350\n",
      "2022-11-09 00:59:08,234 INFO     Training average negative_sample_loss at step 727900: 0.140865\n",
      "2022-11-09 00:59:08,234 INFO     Training average loss at step 727900: 0.141608\n",
      "2022-11-09 00:59:14,611 INFO     Training average positive_sample_loss at step 728000: 0.148238\n",
      "2022-11-09 00:59:14,611 INFO     Training average negative_sample_loss at step 728000: 0.137700\n",
      "2022-11-09 00:59:14,611 INFO     Training average loss at step 728000: 0.142969\n",
      "2022-11-09 00:59:20,972 INFO     Training average positive_sample_loss at step 728100: 0.151422\n",
      "2022-11-09 00:59:20,972 INFO     Training average negative_sample_loss at step 728100: 0.146993\n",
      "2022-11-09 00:59:20,972 INFO     Training average loss at step 728100: 0.149207\n",
      "2022-11-09 00:59:27,339 INFO     Training average positive_sample_loss at step 728200: 0.143767\n",
      "2022-11-09 00:59:27,339 INFO     Training average negative_sample_loss at step 728200: 0.140127\n",
      "2022-11-09 00:59:27,339 INFO     Training average loss at step 728200: 0.141947\n",
      "2022-11-09 00:59:33,719 INFO     Training average positive_sample_loss at step 728300: 0.142124\n",
      "2022-11-09 00:59:33,719 INFO     Training average negative_sample_loss at step 728300: 0.139435\n",
      "2022-11-09 00:59:33,719 INFO     Training average loss at step 728300: 0.140780\n",
      "2022-11-09 00:59:40,095 INFO     Training average positive_sample_loss at step 728400: 0.146689\n",
      "2022-11-09 00:59:40,095 INFO     Training average negative_sample_loss at step 728400: 0.138826\n",
      "2022-11-09 00:59:40,095 INFO     Training average loss at step 728400: 0.142757\n",
      "2022-11-09 00:59:46,467 INFO     Training average positive_sample_loss at step 728500: 0.146778\n",
      "2022-11-09 00:59:46,467 INFO     Training average negative_sample_loss at step 728500: 0.136196\n",
      "2022-11-09 00:59:46,467 INFO     Training average loss at step 728500: 0.141487\n",
      "2022-11-09 00:59:52,862 INFO     Training average positive_sample_loss at step 728600: 0.147032\n",
      "2022-11-09 00:59:52,862 INFO     Training average negative_sample_loss at step 728600: 0.141887\n",
      "2022-11-09 00:59:52,862 INFO     Training average loss at step 728600: 0.144459\n",
      "2022-11-09 00:59:59,240 INFO     Training average positive_sample_loss at step 728700: 0.141292\n",
      "2022-11-09 00:59:59,240 INFO     Training average negative_sample_loss at step 728700: 0.137143\n",
      "2022-11-09 00:59:59,240 INFO     Training average loss at step 728700: 0.139218\n",
      "2022-11-09 01:00:05,610 INFO     Training average positive_sample_loss at step 728800: 0.147826\n",
      "2022-11-09 01:00:05,611 INFO     Training average negative_sample_loss at step 728800: 0.137177\n",
      "2022-11-09 01:00:05,611 INFO     Training average loss at step 728800: 0.142501\n",
      "2022-11-09 01:00:12,001 INFO     Training average positive_sample_loss at step 728900: 0.150685\n",
      "2022-11-09 01:00:12,001 INFO     Training average negative_sample_loss at step 728900: 0.140283\n",
      "2022-11-09 01:00:12,001 INFO     Training average loss at step 728900: 0.145484\n",
      "2022-11-09 01:00:18,363 INFO     Training average positive_sample_loss at step 729000: 0.140847\n",
      "2022-11-09 01:00:18,363 INFO     Training average negative_sample_loss at step 729000: 0.137683\n",
      "2022-11-09 01:00:18,363 INFO     Training average loss at step 729000: 0.139265\n",
      "2022-11-09 01:00:24,753 INFO     Training average positive_sample_loss at step 729100: 0.148570\n",
      "2022-11-09 01:00:24,753 INFO     Training average negative_sample_loss at step 729100: 0.138563\n",
      "2022-11-09 01:00:24,753 INFO     Training average loss at step 729100: 0.143567\n",
      "2022-11-09 01:00:31,132 INFO     Training average positive_sample_loss at step 729200: 0.145762\n",
      "2022-11-09 01:00:31,132 INFO     Training average negative_sample_loss at step 729200: 0.137021\n",
      "2022-11-09 01:00:31,132 INFO     Training average loss at step 729200: 0.141392\n",
      "2022-11-09 01:00:37,521 INFO     Training average positive_sample_loss at step 729300: 0.145366\n",
      "2022-11-09 01:00:37,521 INFO     Training average negative_sample_loss at step 729300: 0.139771\n",
      "2022-11-09 01:00:37,521 INFO     Training average loss at step 729300: 0.142568\n",
      "2022-11-09 01:00:43,877 INFO     Training average positive_sample_loss at step 729400: 0.148867\n",
      "2022-11-09 01:00:43,878 INFO     Training average negative_sample_loss at step 729400: 0.142679\n",
      "2022-11-09 01:00:43,878 INFO     Training average loss at step 729400: 0.145773\n",
      "2022-11-09 01:00:50,276 INFO     Training average positive_sample_loss at step 729500: 0.143737\n",
      "2022-11-09 01:00:50,276 INFO     Training average negative_sample_loss at step 729500: 0.141610\n",
      "2022-11-09 01:00:50,276 INFO     Training average loss at step 729500: 0.142674\n",
      "2022-11-09 01:00:56,677 INFO     Training average positive_sample_loss at step 729600: 0.147205\n",
      "2022-11-09 01:00:56,678 INFO     Training average negative_sample_loss at step 729600: 0.140584\n",
      "2022-11-09 01:00:56,678 INFO     Training average loss at step 729600: 0.143895\n",
      "2022-11-09 01:01:03,041 INFO     Training average positive_sample_loss at step 729700: 0.146958\n",
      "2022-11-09 01:01:03,041 INFO     Training average negative_sample_loss at step 729700: 0.136147\n",
      "2022-11-09 01:01:03,041 INFO     Training average loss at step 729700: 0.141552\n",
      "2022-11-09 01:01:09,391 INFO     Training average positive_sample_loss at step 729800: 0.151828\n",
      "2022-11-09 01:01:09,391 INFO     Training average negative_sample_loss at step 729800: 0.138892\n",
      "2022-11-09 01:01:09,391 INFO     Training average loss at step 729800: 0.145360\n",
      "2022-11-09 01:01:15,761 INFO     Training average positive_sample_loss at step 729900: 0.150330\n",
      "2022-11-09 01:01:15,761 INFO     Training average negative_sample_loss at step 729900: 0.141325\n",
      "2022-11-09 01:01:15,761 INFO     Training average loss at step 729900: 0.145827\n",
      "2022-11-09 01:01:25,001 INFO     Training average positive_sample_loss at step 730000: 0.145311\n",
      "2022-11-09 01:01:25,001 INFO     Training average negative_sample_loss at step 730000: 0.133800\n",
      "2022-11-09 01:01:25,001 INFO     Training average loss at step 730000: 0.139555\n",
      "2022-11-09 01:01:31,351 INFO     Training average positive_sample_loss at step 730100: 0.143120\n",
      "2022-11-09 01:01:31,351 INFO     Training average negative_sample_loss at step 730100: 0.142994\n",
      "2022-11-09 01:01:31,352 INFO     Training average loss at step 730100: 0.143057\n",
      "2022-11-09 01:01:37,700 INFO     Training average positive_sample_loss at step 730200: 0.144959\n",
      "2022-11-09 01:01:37,700 INFO     Training average negative_sample_loss at step 730200: 0.142320\n",
      "2022-11-09 01:01:37,700 INFO     Training average loss at step 730200: 0.143639\n",
      "2022-11-09 01:01:44,100 INFO     Training average positive_sample_loss at step 730300: 0.145669\n",
      "2022-11-09 01:01:44,100 INFO     Training average negative_sample_loss at step 730300: 0.133667\n",
      "2022-11-09 01:01:44,100 INFO     Training average loss at step 730300: 0.139668\n",
      "2022-11-09 01:01:50,472 INFO     Training average positive_sample_loss at step 730400: 0.149331\n",
      "2022-11-09 01:01:50,473 INFO     Training average negative_sample_loss at step 730400: 0.143714\n",
      "2022-11-09 01:01:50,473 INFO     Training average loss at step 730400: 0.146523\n",
      "2022-11-09 01:01:56,823 INFO     Training average positive_sample_loss at step 730500: 0.146069\n",
      "2022-11-09 01:01:56,823 INFO     Training average negative_sample_loss at step 730500: 0.142627\n",
      "2022-11-09 01:01:56,823 INFO     Training average loss at step 730500: 0.144348\n",
      "2022-11-09 01:02:03,193 INFO     Training average positive_sample_loss at step 730600: 0.141688\n",
      "2022-11-09 01:02:03,193 INFO     Training average negative_sample_loss at step 730600: 0.134467\n",
      "2022-11-09 01:02:03,193 INFO     Training average loss at step 730600: 0.138077\n",
      "2022-11-09 01:02:09,564 INFO     Training average positive_sample_loss at step 730700: 0.149865\n",
      "2022-11-09 01:02:09,564 INFO     Training average negative_sample_loss at step 730700: 0.142251\n",
      "2022-11-09 01:02:09,564 INFO     Training average loss at step 730700: 0.146058\n",
      "2022-11-09 01:02:15,928 INFO     Training average positive_sample_loss at step 730800: 0.138786\n",
      "2022-11-09 01:02:15,929 INFO     Training average negative_sample_loss at step 730800: 0.138466\n",
      "2022-11-09 01:02:15,929 INFO     Training average loss at step 730800: 0.138626\n",
      "2022-11-09 01:02:22,281 INFO     Training average positive_sample_loss at step 730900: 0.146052\n",
      "2022-11-09 01:02:22,281 INFO     Training average negative_sample_loss at step 730900: 0.138952\n",
      "2022-11-09 01:02:22,281 INFO     Training average loss at step 730900: 0.142502\n",
      "2022-11-09 01:02:28,385 INFO     Training average positive_sample_loss at step 731000: 0.146247\n",
      "2022-11-09 01:02:28,385 INFO     Training average negative_sample_loss at step 731000: 0.139707\n",
      "2022-11-09 01:02:28,385 INFO     Training average loss at step 731000: 0.142977\n",
      "2022-11-09 01:02:33,600 INFO     Training average positive_sample_loss at step 731100: 0.145832\n",
      "2022-11-09 01:02:33,600 INFO     Training average negative_sample_loss at step 731100: 0.141748\n",
      "2022-11-09 01:02:33,600 INFO     Training average loss at step 731100: 0.143790\n",
      "2022-11-09 01:02:39,971 INFO     Training average positive_sample_loss at step 731200: 0.144556\n",
      "2022-11-09 01:02:39,971 INFO     Training average negative_sample_loss at step 731200: 0.138840\n",
      "2022-11-09 01:02:39,971 INFO     Training average loss at step 731200: 0.141698\n",
      "2022-11-09 01:02:46,352 INFO     Training average positive_sample_loss at step 731300: 0.140361\n",
      "2022-11-09 01:02:46,352 INFO     Training average negative_sample_loss at step 731300: 0.136818\n",
      "2022-11-09 01:02:46,353 INFO     Training average loss at step 731300: 0.138589\n",
      "2022-11-09 01:02:52,719 INFO     Training average positive_sample_loss at step 731400: 0.144801\n",
      "2022-11-09 01:02:52,719 INFO     Training average negative_sample_loss at step 731400: 0.142159\n",
      "2022-11-09 01:02:52,719 INFO     Training average loss at step 731400: 0.143480\n",
      "2022-11-09 01:02:59,100 INFO     Training average positive_sample_loss at step 731500: 0.143327\n",
      "2022-11-09 01:02:59,101 INFO     Training average negative_sample_loss at step 731500: 0.137637\n",
      "2022-11-09 01:02:59,101 INFO     Training average loss at step 731500: 0.140482\n",
      "2022-11-09 01:03:05,474 INFO     Training average positive_sample_loss at step 731600: 0.144947\n",
      "2022-11-09 01:03:05,474 INFO     Training average negative_sample_loss at step 731600: 0.142554\n",
      "2022-11-09 01:03:05,474 INFO     Training average loss at step 731600: 0.143751\n",
      "2022-11-09 01:03:11,845 INFO     Training average positive_sample_loss at step 731700: 0.149705\n",
      "2022-11-09 01:03:11,845 INFO     Training average negative_sample_loss at step 731700: 0.140873\n",
      "2022-11-09 01:03:11,845 INFO     Training average loss at step 731700: 0.145289\n",
      "2022-11-09 01:03:18,211 INFO     Training average positive_sample_loss at step 731800: 0.145168\n",
      "2022-11-09 01:03:18,211 INFO     Training average negative_sample_loss at step 731800: 0.139901\n",
      "2022-11-09 01:03:18,211 INFO     Training average loss at step 731800: 0.142535\n",
      "2022-11-09 01:03:24,576 INFO     Training average positive_sample_loss at step 731900: 0.145711\n",
      "2022-11-09 01:03:24,576 INFO     Training average negative_sample_loss at step 731900: 0.137161\n",
      "2022-11-09 01:03:24,576 INFO     Training average loss at step 731900: 0.141436\n",
      "2022-11-09 01:03:33,942 INFO     Training average positive_sample_loss at step 732000: 0.148357\n",
      "2022-11-09 01:03:33,943 INFO     Training average negative_sample_loss at step 732000: 0.136185\n",
      "2022-11-09 01:03:33,943 INFO     Training average loss at step 732000: 0.142271\n",
      "2022-11-09 01:03:40,329 INFO     Training average positive_sample_loss at step 732100: 0.143705\n",
      "2022-11-09 01:03:40,329 INFO     Training average negative_sample_loss at step 732100: 0.143730\n",
      "2022-11-09 01:03:40,329 INFO     Training average loss at step 732100: 0.143718\n",
      "2022-11-09 01:03:46,712 INFO     Training average positive_sample_loss at step 732200: 0.150083\n",
      "2022-11-09 01:03:46,712 INFO     Training average negative_sample_loss at step 732200: 0.144100\n",
      "2022-11-09 01:03:46,712 INFO     Training average loss at step 732200: 0.147091\n",
      "2022-11-09 01:03:53,104 INFO     Training average positive_sample_loss at step 732300: 0.143404\n",
      "2022-11-09 01:03:53,104 INFO     Training average negative_sample_loss at step 732300: 0.138744\n",
      "2022-11-09 01:03:53,104 INFO     Training average loss at step 732300: 0.141074\n",
      "2022-11-09 01:03:59,475 INFO     Training average positive_sample_loss at step 732400: 0.146736\n",
      "2022-11-09 01:03:59,475 INFO     Training average negative_sample_loss at step 732400: 0.139039\n",
      "2022-11-09 01:03:59,475 INFO     Training average loss at step 732400: 0.142888\n",
      "2022-11-09 01:04:05,819 INFO     Training average positive_sample_loss at step 732500: 0.146922\n",
      "2022-11-09 01:04:05,819 INFO     Training average negative_sample_loss at step 732500: 0.137998\n",
      "2022-11-09 01:04:05,819 INFO     Training average loss at step 732500: 0.142460\n",
      "2022-11-09 01:04:12,186 INFO     Training average positive_sample_loss at step 732600: 0.151019\n",
      "2022-11-09 01:04:12,186 INFO     Training average negative_sample_loss at step 732600: 0.140816\n",
      "2022-11-09 01:04:12,186 INFO     Training average loss at step 732600: 0.145918\n",
      "2022-11-09 01:04:18,544 INFO     Training average positive_sample_loss at step 732700: 0.149949\n",
      "2022-11-09 01:04:18,544 INFO     Training average negative_sample_loss at step 732700: 0.144271\n",
      "2022-11-09 01:04:18,544 INFO     Training average loss at step 732700: 0.147110\n",
      "2022-11-09 01:04:24,896 INFO     Training average positive_sample_loss at step 732800: 0.145742\n",
      "2022-11-09 01:04:24,897 INFO     Training average negative_sample_loss at step 732800: 0.140457\n",
      "2022-11-09 01:04:24,897 INFO     Training average loss at step 732800: 0.143099\n",
      "2022-11-09 01:04:31,260 INFO     Training average positive_sample_loss at step 732900: 0.149553\n",
      "2022-11-09 01:04:31,260 INFO     Training average negative_sample_loss at step 732900: 0.137244\n",
      "2022-11-09 01:04:31,260 INFO     Training average loss at step 732900: 0.143398\n",
      "2022-11-09 01:04:37,629 INFO     Training average positive_sample_loss at step 733000: 0.144982\n",
      "2022-11-09 01:04:37,630 INFO     Training average negative_sample_loss at step 733000: 0.140015\n",
      "2022-11-09 01:04:37,630 INFO     Training average loss at step 733000: 0.142498\n",
      "2022-11-09 01:04:43,992 INFO     Training average positive_sample_loss at step 733100: 0.148204\n",
      "2022-11-09 01:04:43,992 INFO     Training average negative_sample_loss at step 733100: 0.137655\n",
      "2022-11-09 01:04:43,992 INFO     Training average loss at step 733100: 0.142929\n",
      "2022-11-09 01:04:50,349 INFO     Training average positive_sample_loss at step 733200: 0.145512\n",
      "2022-11-09 01:04:50,349 INFO     Training average negative_sample_loss at step 733200: 0.142469\n",
      "2022-11-09 01:04:50,349 INFO     Training average loss at step 733200: 0.143991\n",
      "2022-11-09 01:04:56,693 INFO     Training average positive_sample_loss at step 733300: 0.144071\n",
      "2022-11-09 01:04:56,693 INFO     Training average negative_sample_loss at step 733300: 0.136980\n",
      "2022-11-09 01:04:56,693 INFO     Training average loss at step 733300: 0.140526\n",
      "2022-11-09 01:05:03,057 INFO     Training average positive_sample_loss at step 733400: 0.152763\n",
      "2022-11-09 01:05:03,057 INFO     Training average negative_sample_loss at step 733400: 0.140745\n",
      "2022-11-09 01:05:03,057 INFO     Training average loss at step 733400: 0.146754\n",
      "2022-11-09 01:05:09,427 INFO     Training average positive_sample_loss at step 733500: 0.144568\n",
      "2022-11-09 01:05:09,427 INFO     Training average negative_sample_loss at step 733500: 0.142117\n",
      "2022-11-09 01:05:09,427 INFO     Training average loss at step 733500: 0.143342\n",
      "2022-11-09 01:05:15,784 INFO     Training average positive_sample_loss at step 733600: 0.148126\n",
      "2022-11-09 01:05:15,784 INFO     Training average negative_sample_loss at step 733600: 0.139259\n",
      "2022-11-09 01:05:15,784 INFO     Training average loss at step 733600: 0.143693\n",
      "2022-11-09 01:05:22,164 INFO     Training average positive_sample_loss at step 733700: 0.144654\n",
      "2022-11-09 01:05:22,164 INFO     Training average negative_sample_loss at step 733700: 0.137508\n",
      "2022-11-09 01:05:22,164 INFO     Training average loss at step 733700: 0.141081\n",
      "2022-11-09 01:05:28,538 INFO     Training average positive_sample_loss at step 733800: 0.146014\n",
      "2022-11-09 01:05:28,538 INFO     Training average negative_sample_loss at step 733800: 0.141021\n",
      "2022-11-09 01:05:28,538 INFO     Training average loss at step 733800: 0.143518\n",
      "2022-11-09 01:05:34,910 INFO     Training average positive_sample_loss at step 733900: 0.139197\n",
      "2022-11-09 01:05:34,910 INFO     Training average negative_sample_loss at step 733900: 0.143142\n",
      "2022-11-09 01:05:34,910 INFO     Training average loss at step 733900: 0.141169\n",
      "2022-11-09 01:05:41,263 INFO     Training average positive_sample_loss at step 734000: 0.143518\n",
      "2022-11-09 01:05:41,263 INFO     Training average negative_sample_loss at step 734000: 0.136307\n",
      "2022-11-09 01:05:41,263 INFO     Training average loss at step 734000: 0.139913\n",
      "2022-11-09 01:05:47,608 INFO     Training average positive_sample_loss at step 734100: 0.144880\n",
      "2022-11-09 01:05:47,608 INFO     Training average negative_sample_loss at step 734100: 0.139832\n",
      "2022-11-09 01:05:47,608 INFO     Training average loss at step 734100: 0.142356\n",
      "2022-11-09 01:05:53,977 INFO     Training average positive_sample_loss at step 734200: 0.144194\n",
      "2022-11-09 01:05:53,977 INFO     Training average negative_sample_loss at step 734200: 0.136635\n",
      "2022-11-09 01:05:53,977 INFO     Training average loss at step 734200: 0.140415\n",
      "2022-11-09 01:06:00,325 INFO     Training average positive_sample_loss at step 734300: 0.147132\n",
      "2022-11-09 01:06:00,325 INFO     Training average negative_sample_loss at step 734300: 0.140883\n",
      "2022-11-09 01:06:00,325 INFO     Training average loss at step 734300: 0.144007\n",
      "2022-11-09 01:06:06,673 INFO     Training average positive_sample_loss at step 734400: 0.147145\n",
      "2022-11-09 01:06:06,673 INFO     Training average negative_sample_loss at step 734400: 0.138299\n",
      "2022-11-09 01:06:06,673 INFO     Training average loss at step 734400: 0.142722\n",
      "2022-11-09 01:06:13,027 INFO     Training average positive_sample_loss at step 734500: 0.145871\n",
      "2022-11-09 01:06:13,027 INFO     Training average negative_sample_loss at step 734500: 0.136701\n",
      "2022-11-09 01:06:13,027 INFO     Training average loss at step 734500: 0.141286\n",
      "2022-11-09 01:06:19,398 INFO     Training average positive_sample_loss at step 734600: 0.147092\n",
      "2022-11-09 01:06:19,398 INFO     Training average negative_sample_loss at step 734600: 0.141998\n",
      "2022-11-09 01:06:19,398 INFO     Training average loss at step 734600: 0.144545\n",
      "2022-11-09 01:06:25,760 INFO     Training average positive_sample_loss at step 734700: 0.143844\n",
      "2022-11-09 01:06:25,760 INFO     Training average negative_sample_loss at step 734700: 0.138927\n",
      "2022-11-09 01:06:25,760 INFO     Training average loss at step 734700: 0.141385\n",
      "2022-11-09 01:06:32,119 INFO     Training average positive_sample_loss at step 734800: 0.144143\n",
      "2022-11-09 01:06:32,119 INFO     Training average negative_sample_loss at step 734800: 0.142208\n",
      "2022-11-09 01:06:32,119 INFO     Training average loss at step 734800: 0.143175\n",
      "2022-11-09 01:06:38,495 INFO     Training average positive_sample_loss at step 734900: 0.153202\n",
      "2022-11-09 01:06:38,495 INFO     Training average negative_sample_loss at step 734900: 0.138723\n",
      "2022-11-09 01:06:38,495 INFO     Training average loss at step 734900: 0.145963\n",
      "2022-11-09 01:06:44,855 INFO     Training average positive_sample_loss at step 735000: 0.148278\n",
      "2022-11-09 01:06:44,855 INFO     Training average negative_sample_loss at step 735000: 0.132543\n",
      "2022-11-09 01:06:44,855 INFO     Training average loss at step 735000: 0.140411\n",
      "2022-11-09 01:06:51,215 INFO     Training average positive_sample_loss at step 735100: 0.150413\n",
      "2022-11-09 01:06:51,216 INFO     Training average negative_sample_loss at step 735100: 0.144977\n",
      "2022-11-09 01:06:51,216 INFO     Training average loss at step 735100: 0.147695\n",
      "2022-11-09 01:06:57,561 INFO     Training average positive_sample_loss at step 735200: 0.144573\n",
      "2022-11-09 01:06:57,561 INFO     Training average negative_sample_loss at step 735200: 0.137497\n",
      "2022-11-09 01:06:57,561 INFO     Training average loss at step 735200: 0.141035\n",
      "2022-11-09 01:07:03,934 INFO     Training average positive_sample_loss at step 735300: 0.150167\n",
      "2022-11-09 01:07:03,934 INFO     Training average negative_sample_loss at step 735300: 0.142672\n",
      "2022-11-09 01:07:03,934 INFO     Training average loss at step 735300: 0.146420\n",
      "2022-11-09 01:07:10,311 INFO     Training average positive_sample_loss at step 735400: 0.147611\n",
      "2022-11-09 01:07:10,311 INFO     Training average negative_sample_loss at step 735400: 0.138372\n",
      "2022-11-09 01:07:10,311 INFO     Training average loss at step 735400: 0.142992\n",
      "2022-11-09 01:07:16,670 INFO     Training average positive_sample_loss at step 735500: 0.141619\n",
      "2022-11-09 01:07:16,670 INFO     Training average negative_sample_loss at step 735500: 0.138197\n",
      "2022-11-09 01:07:16,670 INFO     Training average loss at step 735500: 0.139908\n",
      "2022-11-09 01:07:23,070 INFO     Training average positive_sample_loss at step 735600: 0.147487\n",
      "2022-11-09 01:07:23,070 INFO     Training average negative_sample_loss at step 735600: 0.140515\n",
      "2022-11-09 01:07:23,070 INFO     Training average loss at step 735600: 0.144001\n",
      "2022-11-09 01:07:29,448 INFO     Training average positive_sample_loss at step 735700: 0.146546\n",
      "2022-11-09 01:07:29,448 INFO     Training average negative_sample_loss at step 735700: 0.140745\n",
      "2022-11-09 01:07:29,448 INFO     Training average loss at step 735700: 0.143645\n",
      "2022-11-09 01:07:35,833 INFO     Training average positive_sample_loss at step 735800: 0.145580\n",
      "2022-11-09 01:07:35,833 INFO     Training average negative_sample_loss at step 735800: 0.144625\n",
      "2022-11-09 01:07:35,833 INFO     Training average loss at step 735800: 0.145103\n",
      "2022-11-09 01:07:42,228 INFO     Training average positive_sample_loss at step 735900: 0.143102\n",
      "2022-11-09 01:07:42,228 INFO     Training average negative_sample_loss at step 735900: 0.136510\n",
      "2022-11-09 01:07:42,228 INFO     Training average loss at step 735900: 0.139806\n",
      "2022-11-09 01:07:48,619 INFO     Training average positive_sample_loss at step 736000: 0.153942\n",
      "2022-11-09 01:07:48,620 INFO     Training average negative_sample_loss at step 736000: 0.145574\n",
      "2022-11-09 01:07:48,620 INFO     Training average loss at step 736000: 0.149758\n",
      "2022-11-09 01:07:54,973 INFO     Training average positive_sample_loss at step 736100: 0.148044\n",
      "2022-11-09 01:07:54,974 INFO     Training average negative_sample_loss at step 736100: 0.135842\n",
      "2022-11-09 01:07:54,974 INFO     Training average loss at step 736100: 0.141943\n",
      "2022-11-09 01:08:01,329 INFO     Training average positive_sample_loss at step 736200: 0.145726\n",
      "2022-11-09 01:08:01,329 INFO     Training average negative_sample_loss at step 736200: 0.136646\n",
      "2022-11-09 01:08:01,329 INFO     Training average loss at step 736200: 0.141186\n",
      "2022-11-09 01:08:07,714 INFO     Training average positive_sample_loss at step 736300: 0.150946\n",
      "2022-11-09 01:08:07,714 INFO     Training average negative_sample_loss at step 736300: 0.141051\n",
      "2022-11-09 01:08:07,714 INFO     Training average loss at step 736300: 0.145998\n",
      "2022-11-09 01:08:14,105 INFO     Training average positive_sample_loss at step 736400: 0.144718\n",
      "2022-11-09 01:08:14,105 INFO     Training average negative_sample_loss at step 736400: 0.137551\n",
      "2022-11-09 01:08:14,105 INFO     Training average loss at step 736400: 0.141135\n",
      "2022-11-09 01:08:20,497 INFO     Training average positive_sample_loss at step 736500: 0.143628\n",
      "2022-11-09 01:08:20,498 INFO     Training average negative_sample_loss at step 736500: 0.136612\n",
      "2022-11-09 01:08:20,498 INFO     Training average loss at step 736500: 0.140120\n",
      "2022-11-09 01:08:27,794 INFO     Training average positive_sample_loss at step 736600: 0.144588\n",
      "2022-11-09 01:08:27,794 INFO     Training average negative_sample_loss at step 736600: 0.137784\n",
      "2022-11-09 01:08:27,794 INFO     Training average loss at step 736600: 0.141186\n",
      "2022-11-09 01:08:34,581 INFO     Training average positive_sample_loss at step 736700: 0.147667\n",
      "2022-11-09 01:08:34,581 INFO     Training average negative_sample_loss at step 736700: 0.137219\n",
      "2022-11-09 01:08:34,581 INFO     Training average loss at step 736700: 0.142443\n",
      "2022-11-09 01:08:40,970 INFO     Training average positive_sample_loss at step 736800: 0.145513\n",
      "2022-11-09 01:08:40,971 INFO     Training average negative_sample_loss at step 736800: 0.138012\n",
      "2022-11-09 01:08:40,971 INFO     Training average loss at step 736800: 0.141763\n",
      "2022-11-09 01:08:47,334 INFO     Training average positive_sample_loss at step 736900: 0.143929\n",
      "2022-11-09 01:08:47,334 INFO     Training average negative_sample_loss at step 736900: 0.141482\n",
      "2022-11-09 01:08:47,334 INFO     Training average loss at step 736900: 0.142705\n",
      "2022-11-09 01:08:53,707 INFO     Training average positive_sample_loss at step 737000: 0.147394\n",
      "2022-11-09 01:08:53,707 INFO     Training average negative_sample_loss at step 737000: 0.142228\n",
      "2022-11-09 01:08:53,707 INFO     Training average loss at step 737000: 0.144811\n",
      "2022-11-09 01:09:00,087 INFO     Training average positive_sample_loss at step 737100: 0.144373\n",
      "2022-11-09 01:09:00,088 INFO     Training average negative_sample_loss at step 737100: 0.138206\n",
      "2022-11-09 01:09:00,088 INFO     Training average loss at step 737100: 0.141290\n",
      "2022-11-09 01:09:06,487 INFO     Training average positive_sample_loss at step 737200: 0.143811\n",
      "2022-11-09 01:09:06,487 INFO     Training average negative_sample_loss at step 737200: 0.138361\n",
      "2022-11-09 01:09:06,487 INFO     Training average loss at step 737200: 0.141086\n",
      "2022-11-09 01:09:12,879 INFO     Training average positive_sample_loss at step 737300: 0.147732\n",
      "2022-11-09 01:09:12,879 INFO     Training average negative_sample_loss at step 737300: 0.139505\n",
      "2022-11-09 01:09:12,879 INFO     Training average loss at step 737300: 0.143618\n",
      "2022-11-09 01:09:19,264 INFO     Training average positive_sample_loss at step 737400: 0.146252\n",
      "2022-11-09 01:09:19,264 INFO     Training average negative_sample_loss at step 737400: 0.139426\n",
      "2022-11-09 01:09:19,264 INFO     Training average loss at step 737400: 0.142839\n",
      "2022-11-09 01:09:25,635 INFO     Training average positive_sample_loss at step 737500: 0.145239\n",
      "2022-11-09 01:09:25,635 INFO     Training average negative_sample_loss at step 737500: 0.138901\n",
      "2022-11-09 01:09:25,635 INFO     Training average loss at step 737500: 0.142070\n",
      "2022-11-09 01:09:32,018 INFO     Training average positive_sample_loss at step 737600: 0.147659\n",
      "2022-11-09 01:09:32,018 INFO     Training average negative_sample_loss at step 737600: 0.136585\n",
      "2022-11-09 01:09:32,018 INFO     Training average loss at step 737600: 0.142122\n",
      "2022-11-09 01:09:38,418 INFO     Training average positive_sample_loss at step 737700: 0.148838\n",
      "2022-11-09 01:09:38,418 INFO     Training average negative_sample_loss at step 737700: 0.140710\n",
      "2022-11-09 01:09:38,418 INFO     Training average loss at step 737700: 0.144774\n",
      "2022-11-09 01:09:44,773 INFO     Training average positive_sample_loss at step 737800: 0.147317\n",
      "2022-11-09 01:09:44,773 INFO     Training average negative_sample_loss at step 737800: 0.136516\n",
      "2022-11-09 01:09:44,773 INFO     Training average loss at step 737800: 0.141917\n",
      "2022-11-09 01:09:51,134 INFO     Training average positive_sample_loss at step 737900: 0.149783\n",
      "2022-11-09 01:09:51,134 INFO     Training average negative_sample_loss at step 737900: 0.141727\n",
      "2022-11-09 01:09:51,134 INFO     Training average loss at step 737900: 0.145755\n",
      "2022-11-09 01:09:57,523 INFO     Training average positive_sample_loss at step 738000: 0.148295\n",
      "2022-11-09 01:09:57,523 INFO     Training average negative_sample_loss at step 738000: 0.138470\n",
      "2022-11-09 01:09:57,523 INFO     Training average loss at step 738000: 0.143383\n",
      "2022-11-09 01:10:03,883 INFO     Training average positive_sample_loss at step 738100: 0.140218\n",
      "2022-11-09 01:10:03,883 INFO     Training average negative_sample_loss at step 738100: 0.137677\n",
      "2022-11-09 01:10:03,883 INFO     Training average loss at step 738100: 0.138948\n",
      "2022-11-09 01:10:10,280 INFO     Training average positive_sample_loss at step 738200: 0.146953\n",
      "2022-11-09 01:10:10,280 INFO     Training average negative_sample_loss at step 738200: 0.138696\n",
      "2022-11-09 01:10:10,280 INFO     Training average loss at step 738200: 0.142824\n",
      "2022-11-09 01:10:16,657 INFO     Training average positive_sample_loss at step 738300: 0.146291\n",
      "2022-11-09 01:10:16,657 INFO     Training average negative_sample_loss at step 738300: 0.139113\n",
      "2022-11-09 01:10:16,657 INFO     Training average loss at step 738300: 0.142702\n",
      "2022-11-09 01:10:23,027 INFO     Training average positive_sample_loss at step 738400: 0.148278\n",
      "2022-11-09 01:10:23,027 INFO     Training average negative_sample_loss at step 738400: 0.138129\n",
      "2022-11-09 01:10:23,027 INFO     Training average loss at step 738400: 0.143204\n",
      "2022-11-09 01:10:29,401 INFO     Training average positive_sample_loss at step 738500: 0.145262\n",
      "2022-11-09 01:10:29,401 INFO     Training average negative_sample_loss at step 738500: 0.140492\n",
      "2022-11-09 01:10:29,401 INFO     Training average loss at step 738500: 0.142877\n",
      "2022-11-09 01:10:35,761 INFO     Training average positive_sample_loss at step 738600: 0.142014\n",
      "2022-11-09 01:10:35,761 INFO     Training average negative_sample_loss at step 738600: 0.136241\n",
      "2022-11-09 01:10:35,761 INFO     Training average loss at step 738600: 0.139127\n",
      "2022-11-09 01:10:42,098 INFO     Training average positive_sample_loss at step 738700: 0.148543\n",
      "2022-11-09 01:10:42,098 INFO     Training average negative_sample_loss at step 738700: 0.141109\n",
      "2022-11-09 01:10:42,098 INFO     Training average loss at step 738700: 0.144826\n",
      "2022-11-09 01:10:48,443 INFO     Training average positive_sample_loss at step 738800: 0.144953\n",
      "2022-11-09 01:10:48,443 INFO     Training average negative_sample_loss at step 738800: 0.140382\n",
      "2022-11-09 01:10:48,443 INFO     Training average loss at step 738800: 0.142668\n",
      "2022-11-09 01:10:54,810 INFO     Training average positive_sample_loss at step 738900: 0.143906\n",
      "2022-11-09 01:10:54,810 INFO     Training average negative_sample_loss at step 738900: 0.141490\n",
      "2022-11-09 01:10:54,810 INFO     Training average loss at step 738900: 0.142698\n",
      "2022-11-09 01:11:01,194 INFO     Training average positive_sample_loss at step 739000: 0.146627\n",
      "2022-11-09 01:11:01,195 INFO     Training average negative_sample_loss at step 739000: 0.142548\n",
      "2022-11-09 01:11:01,195 INFO     Training average loss at step 739000: 0.144588\n",
      "2022-11-09 01:11:07,560 INFO     Training average positive_sample_loss at step 739100: 0.147894\n",
      "2022-11-09 01:11:07,560 INFO     Training average negative_sample_loss at step 739100: 0.141390\n",
      "2022-11-09 01:11:07,560 INFO     Training average loss at step 739100: 0.144642\n",
      "2022-11-09 01:11:13,935 INFO     Training average positive_sample_loss at step 739200: 0.148103\n",
      "2022-11-09 01:11:13,936 INFO     Training average negative_sample_loss at step 739200: 0.139237\n",
      "2022-11-09 01:11:13,936 INFO     Training average loss at step 739200: 0.143670\n",
      "2022-11-09 01:11:20,302 INFO     Training average positive_sample_loss at step 739300: 0.148158\n",
      "2022-11-09 01:11:20,302 INFO     Training average negative_sample_loss at step 739300: 0.139068\n",
      "2022-11-09 01:11:20,302 INFO     Training average loss at step 739300: 0.143613\n",
      "2022-11-09 01:11:26,686 INFO     Training average positive_sample_loss at step 739400: 0.150080\n",
      "2022-11-09 01:11:26,686 INFO     Training average negative_sample_loss at step 739400: 0.141927\n",
      "2022-11-09 01:11:26,686 INFO     Training average loss at step 739400: 0.146003\n",
      "2022-11-09 01:11:33,052 INFO     Training average positive_sample_loss at step 739500: 0.146820\n",
      "2022-11-09 01:11:33,053 INFO     Training average negative_sample_loss at step 739500: 0.138560\n",
      "2022-11-09 01:11:33,053 INFO     Training average loss at step 739500: 0.142690\n",
      "2022-11-09 01:11:39,406 INFO     Training average positive_sample_loss at step 739600: 0.145546\n",
      "2022-11-09 01:11:39,406 INFO     Training average negative_sample_loss at step 739600: 0.136378\n",
      "2022-11-09 01:11:39,406 INFO     Training average loss at step 739600: 0.140962\n",
      "2022-11-09 01:11:45,762 INFO     Training average positive_sample_loss at step 739700: 0.148200\n",
      "2022-11-09 01:11:45,762 INFO     Training average negative_sample_loss at step 739700: 0.136401\n",
      "2022-11-09 01:11:45,762 INFO     Training average loss at step 739700: 0.142300\n",
      "2022-11-09 01:11:52,133 INFO     Training average positive_sample_loss at step 739800: 0.148881\n",
      "2022-11-09 01:11:52,133 INFO     Training average negative_sample_loss at step 739800: 0.139449\n",
      "2022-11-09 01:11:52,133 INFO     Training average loss at step 739800: 0.144165\n",
      "2022-11-09 01:11:58,530 INFO     Training average positive_sample_loss at step 739900: 0.150044\n",
      "2022-11-09 01:11:58,530 INFO     Training average negative_sample_loss at step 739900: 0.142069\n",
      "2022-11-09 01:11:58,530 INFO     Training average loss at step 739900: 0.146056\n",
      "2022-11-09 01:12:07,899 INFO     Training average positive_sample_loss at step 740000: 0.149038\n",
      "2022-11-09 01:12:07,899 INFO     Training average negative_sample_loss at step 740000: 0.135582\n",
      "2022-11-09 01:12:07,899 INFO     Training average loss at step 740000: 0.142310\n",
      "2022-11-09 01:12:14,298 INFO     Training average positive_sample_loss at step 740100: 0.144593\n",
      "2022-11-09 01:12:14,298 INFO     Training average negative_sample_loss at step 740100: 0.139665\n",
      "2022-11-09 01:12:14,298 INFO     Training average loss at step 740100: 0.142129\n",
      "2022-11-09 01:12:20,651 INFO     Training average positive_sample_loss at step 740200: 0.151291\n",
      "2022-11-09 01:12:20,651 INFO     Training average negative_sample_loss at step 740200: 0.139979\n",
      "2022-11-09 01:12:20,651 INFO     Training average loss at step 740200: 0.145635\n",
      "2022-11-09 01:12:27,011 INFO     Training average positive_sample_loss at step 740300: 0.149828\n",
      "2022-11-09 01:12:27,011 INFO     Training average negative_sample_loss at step 740300: 0.139385\n",
      "2022-11-09 01:12:27,011 INFO     Training average loss at step 740300: 0.144606\n",
      "2022-11-09 01:12:33,370 INFO     Training average positive_sample_loss at step 740400: 0.146002\n",
      "2022-11-09 01:12:33,370 INFO     Training average negative_sample_loss at step 740400: 0.143814\n",
      "2022-11-09 01:12:33,370 INFO     Training average loss at step 740400: 0.144908\n",
      "2022-11-09 01:12:39,760 INFO     Training average positive_sample_loss at step 740500: 0.148596\n",
      "2022-11-09 01:12:39,760 INFO     Training average negative_sample_loss at step 740500: 0.137680\n",
      "2022-11-09 01:12:39,760 INFO     Training average loss at step 740500: 0.143138\n",
      "2022-11-09 01:12:46,149 INFO     Training average positive_sample_loss at step 740600: 0.143036\n",
      "2022-11-09 01:12:46,149 INFO     Training average negative_sample_loss at step 740600: 0.141214\n",
      "2022-11-09 01:12:46,149 INFO     Training average loss at step 740600: 0.142125\n",
      "2022-11-09 01:12:52,535 INFO     Training average positive_sample_loss at step 740700: 0.149656\n",
      "2022-11-09 01:12:52,535 INFO     Training average negative_sample_loss at step 740700: 0.139283\n",
      "2022-11-09 01:12:52,535 INFO     Training average loss at step 740700: 0.144469\n",
      "2022-11-09 01:12:58,899 INFO     Training average positive_sample_loss at step 740800: 0.150056\n",
      "2022-11-09 01:12:58,899 INFO     Training average negative_sample_loss at step 740800: 0.135600\n",
      "2022-11-09 01:12:58,899 INFO     Training average loss at step 740800: 0.142828\n",
      "2022-11-09 01:13:05,285 INFO     Training average positive_sample_loss at step 740900: 0.152330\n",
      "2022-11-09 01:13:05,285 INFO     Training average negative_sample_loss at step 740900: 0.138558\n",
      "2022-11-09 01:13:05,285 INFO     Training average loss at step 740900: 0.145444\n",
      "2022-11-09 01:13:11,649 INFO     Training average positive_sample_loss at step 741000: 0.141562\n",
      "2022-11-09 01:13:11,650 INFO     Training average negative_sample_loss at step 741000: 0.141177\n",
      "2022-11-09 01:13:11,650 INFO     Training average loss at step 741000: 0.141369\n",
      "2022-11-09 01:13:18,034 INFO     Training average positive_sample_loss at step 741100: 0.143756\n",
      "2022-11-09 01:13:18,034 INFO     Training average negative_sample_loss at step 741100: 0.139801\n",
      "2022-11-09 01:13:18,034 INFO     Training average loss at step 741100: 0.141779\n",
      "2022-11-09 01:13:24,418 INFO     Training average positive_sample_loss at step 741200: 0.147072\n",
      "2022-11-09 01:13:24,418 INFO     Training average negative_sample_loss at step 741200: 0.137439\n",
      "2022-11-09 01:13:24,418 INFO     Training average loss at step 741200: 0.142255\n",
      "2022-11-09 01:13:32,150 INFO     Training average positive_sample_loss at step 741300: 0.147614\n",
      "2022-11-09 01:13:32,151 INFO     Training average negative_sample_loss at step 741300: 0.141211\n",
      "2022-11-09 01:13:32,151 INFO     Training average loss at step 741300: 0.144413\n",
      "2022-11-09 01:13:40,066 INFO     Training average positive_sample_loss at step 741400: 0.147873\n",
      "2022-11-09 01:13:40,066 INFO     Training average negative_sample_loss at step 741400: 0.140222\n",
      "2022-11-09 01:13:40,066 INFO     Training average loss at step 741400: 0.144047\n",
      "2022-11-09 01:13:46,442 INFO     Training average positive_sample_loss at step 741500: 0.142678\n",
      "2022-11-09 01:13:46,442 INFO     Training average negative_sample_loss at step 741500: 0.134670\n",
      "2022-11-09 01:13:46,442 INFO     Training average loss at step 741500: 0.138674\n",
      "2022-11-09 01:13:52,823 INFO     Training average positive_sample_loss at step 741600: 0.143269\n",
      "2022-11-09 01:13:52,823 INFO     Training average negative_sample_loss at step 741600: 0.141465\n",
      "2022-11-09 01:13:52,823 INFO     Training average loss at step 741600: 0.142367\n",
      "2022-11-09 01:13:59,178 INFO     Training average positive_sample_loss at step 741700: 0.145045\n",
      "2022-11-09 01:13:59,178 INFO     Training average negative_sample_loss at step 741700: 0.140692\n",
      "2022-11-09 01:13:59,178 INFO     Training average loss at step 741700: 0.142868\n",
      "2022-11-09 01:14:05,541 INFO     Training average positive_sample_loss at step 741800: 0.144793\n",
      "2022-11-09 01:14:05,541 INFO     Training average negative_sample_loss at step 741800: 0.136187\n",
      "2022-11-09 01:14:05,541 INFO     Training average loss at step 741800: 0.140490\n",
      "2022-11-09 01:14:11,906 INFO     Training average positive_sample_loss at step 741900: 0.147142\n",
      "2022-11-09 01:14:11,906 INFO     Training average negative_sample_loss at step 741900: 0.141082\n",
      "2022-11-09 01:14:11,906 INFO     Training average loss at step 741900: 0.144112\n",
      "2022-11-09 01:14:18,259 INFO     Training average positive_sample_loss at step 742000: 0.147910\n",
      "2022-11-09 01:14:18,259 INFO     Training average negative_sample_loss at step 742000: 0.141633\n",
      "2022-11-09 01:14:18,259 INFO     Training average loss at step 742000: 0.144772\n",
      "2022-11-09 01:14:23,838 INFO     Training average positive_sample_loss at step 742100: 0.147411\n",
      "2022-11-09 01:14:23,838 INFO     Training average negative_sample_loss at step 742100: 0.134700\n",
      "2022-11-09 01:14:23,838 INFO     Training average loss at step 742100: 0.141055\n",
      "2022-11-09 01:14:26,936 INFO     Training average positive_sample_loss at step 742200: 0.146366\n",
      "2022-11-09 01:14:26,936 INFO     Training average negative_sample_loss at step 742200: 0.138509\n",
      "2022-11-09 01:14:26,936 INFO     Training average loss at step 742200: 0.142437\n",
      "2022-11-09 01:14:30,121 INFO     Training average positive_sample_loss at step 742300: 0.146592\n",
      "2022-11-09 01:14:30,121 INFO     Training average negative_sample_loss at step 742300: 0.141157\n",
      "2022-11-09 01:14:30,121 INFO     Training average loss at step 742300: 0.143874\n",
      "2022-11-09 01:14:33,330 INFO     Training average positive_sample_loss at step 742400: 0.147329\n",
      "2022-11-09 01:14:33,331 INFO     Training average negative_sample_loss at step 742400: 0.137773\n",
      "2022-11-09 01:14:33,331 INFO     Training average loss at step 742400: 0.142551\n",
      "2022-11-09 01:14:36,494 INFO     Training average positive_sample_loss at step 742500: 0.144860\n",
      "2022-11-09 01:14:36,494 INFO     Training average negative_sample_loss at step 742500: 0.139759\n",
      "2022-11-09 01:14:36,494 INFO     Training average loss at step 742500: 0.142310\n",
      "2022-11-09 01:14:39,604 INFO     Training average positive_sample_loss at step 742600: 0.150266\n",
      "2022-11-09 01:14:39,604 INFO     Training average negative_sample_loss at step 742600: 0.137695\n",
      "2022-11-09 01:14:39,604 INFO     Training average loss at step 742600: 0.143981\n",
      "2022-11-09 01:14:42,706 INFO     Training average positive_sample_loss at step 742700: 0.146424\n",
      "2022-11-09 01:14:42,706 INFO     Training average negative_sample_loss at step 742700: 0.138957\n",
      "2022-11-09 01:14:42,706 INFO     Training average loss at step 742700: 0.142690\n",
      "2022-11-09 01:14:45,789 INFO     Training average positive_sample_loss at step 742800: 0.145942\n",
      "2022-11-09 01:14:45,789 INFO     Training average negative_sample_loss at step 742800: 0.138150\n",
      "2022-11-09 01:14:45,789 INFO     Training average loss at step 742800: 0.142046\n",
      "2022-11-09 01:14:48,907 INFO     Training average positive_sample_loss at step 742900: 0.149839\n",
      "2022-11-09 01:14:48,907 INFO     Training average negative_sample_loss at step 742900: 0.142122\n",
      "2022-11-09 01:14:48,907 INFO     Training average loss at step 742900: 0.145981\n",
      "2022-11-09 01:14:52,008 INFO     Training average positive_sample_loss at step 743000: 0.148927\n",
      "2022-11-09 01:14:52,008 INFO     Training average negative_sample_loss at step 743000: 0.141205\n",
      "2022-11-09 01:14:52,008 INFO     Training average loss at step 743000: 0.145066\n",
      "2022-11-09 01:14:55,107 INFO     Training average positive_sample_loss at step 743100: 0.147238\n",
      "2022-11-09 01:14:55,107 INFO     Training average negative_sample_loss at step 743100: 0.139628\n",
      "2022-11-09 01:14:55,107 INFO     Training average loss at step 743100: 0.143433\n",
      "2022-11-09 01:14:58,212 INFO     Training average positive_sample_loss at step 743200: 0.152547\n",
      "2022-11-09 01:14:58,212 INFO     Training average negative_sample_loss at step 743200: 0.138879\n",
      "2022-11-09 01:14:58,212 INFO     Training average loss at step 743200: 0.145713\n",
      "2022-11-09 01:15:01,305 INFO     Training average positive_sample_loss at step 743300: 0.147082\n",
      "2022-11-09 01:15:01,305 INFO     Training average negative_sample_loss at step 743300: 0.137570\n",
      "2022-11-09 01:15:01,305 INFO     Training average loss at step 743300: 0.142326\n",
      "2022-11-09 01:15:04,395 INFO     Training average positive_sample_loss at step 743400: 0.150791\n",
      "2022-11-09 01:15:04,395 INFO     Training average negative_sample_loss at step 743400: 0.137163\n",
      "2022-11-09 01:15:04,395 INFO     Training average loss at step 743400: 0.143977\n",
      "2022-11-09 01:15:07,502 INFO     Training average positive_sample_loss at step 743500: 0.144790\n",
      "2022-11-09 01:15:07,502 INFO     Training average negative_sample_loss at step 743500: 0.141399\n",
      "2022-11-09 01:15:07,502 INFO     Training average loss at step 743500: 0.143094\n",
      "2022-11-09 01:15:10,592 INFO     Training average positive_sample_loss at step 743600: 0.149444\n",
      "2022-11-09 01:15:10,592 INFO     Training average negative_sample_loss at step 743600: 0.136443\n",
      "2022-11-09 01:15:10,592 INFO     Training average loss at step 743600: 0.142943\n",
      "2022-11-09 01:15:13,678 INFO     Training average positive_sample_loss at step 743700: 0.144190\n",
      "2022-11-09 01:15:13,678 INFO     Training average negative_sample_loss at step 743700: 0.135518\n",
      "2022-11-09 01:15:13,678 INFO     Training average loss at step 743700: 0.139854\n",
      "2022-11-09 01:15:16,768 INFO     Training average positive_sample_loss at step 743800: 0.146112\n",
      "2022-11-09 01:15:16,769 INFO     Training average negative_sample_loss at step 743800: 0.137507\n",
      "2022-11-09 01:15:16,769 INFO     Training average loss at step 743800: 0.141810\n",
      "2022-11-09 01:15:19,860 INFO     Training average positive_sample_loss at step 743900: 0.147777\n",
      "2022-11-09 01:15:19,861 INFO     Training average negative_sample_loss at step 743900: 0.137383\n",
      "2022-11-09 01:15:19,861 INFO     Training average loss at step 743900: 0.142580\n",
      "2022-11-09 01:15:22,956 INFO     Training average positive_sample_loss at step 744000: 0.140383\n",
      "2022-11-09 01:15:22,956 INFO     Training average negative_sample_loss at step 744000: 0.141321\n",
      "2022-11-09 01:15:22,956 INFO     Training average loss at step 744000: 0.140852\n",
      "2022-11-09 01:15:26,051 INFO     Training average positive_sample_loss at step 744100: 0.148606\n",
      "2022-11-09 01:15:26,051 INFO     Training average negative_sample_loss at step 744100: 0.139766\n",
      "2022-11-09 01:15:26,051 INFO     Training average loss at step 744100: 0.144186\n",
      "2022-11-09 01:15:29,149 INFO     Training average positive_sample_loss at step 744200: 0.143942\n",
      "2022-11-09 01:15:29,149 INFO     Training average negative_sample_loss at step 744200: 0.139007\n",
      "2022-11-09 01:15:29,149 INFO     Training average loss at step 744200: 0.141475\n",
      "2022-11-09 01:15:32,255 INFO     Training average positive_sample_loss at step 744300: 0.142612\n",
      "2022-11-09 01:15:32,255 INFO     Training average negative_sample_loss at step 744300: 0.141325\n",
      "2022-11-09 01:15:32,255 INFO     Training average loss at step 744300: 0.141968\n",
      "2022-11-09 01:15:35,353 INFO     Training average positive_sample_loss at step 744400: 0.147403\n",
      "2022-11-09 01:15:35,353 INFO     Training average negative_sample_loss at step 744400: 0.135379\n",
      "2022-11-09 01:15:35,353 INFO     Training average loss at step 744400: 0.141391\n",
      "2022-11-09 01:15:38,451 INFO     Training average positive_sample_loss at step 744500: 0.144133\n",
      "2022-11-09 01:15:38,451 INFO     Training average negative_sample_loss at step 744500: 0.142331\n",
      "2022-11-09 01:15:38,451 INFO     Training average loss at step 744500: 0.143232\n",
      "2022-11-09 01:15:41,558 INFO     Training average positive_sample_loss at step 744600: 0.148010\n",
      "2022-11-09 01:15:41,558 INFO     Training average negative_sample_loss at step 744600: 0.137515\n",
      "2022-11-09 01:15:41,558 INFO     Training average loss at step 744600: 0.142762\n",
      "2022-11-09 01:15:44,652 INFO     Training average positive_sample_loss at step 744700: 0.144737\n",
      "2022-11-09 01:15:44,652 INFO     Training average negative_sample_loss at step 744700: 0.136862\n",
      "2022-11-09 01:15:44,652 INFO     Training average loss at step 744700: 0.140800\n",
      "2022-11-09 01:15:47,742 INFO     Training average positive_sample_loss at step 744800: 0.146813\n",
      "2022-11-09 01:15:47,742 INFO     Training average negative_sample_loss at step 744800: 0.141166\n",
      "2022-11-09 01:15:47,742 INFO     Training average loss at step 744800: 0.143990\n",
      "2022-11-09 01:15:50,833 INFO     Training average positive_sample_loss at step 744900: 0.146953\n",
      "2022-11-09 01:15:50,833 INFO     Training average negative_sample_loss at step 744900: 0.137937\n",
      "2022-11-09 01:15:50,833 INFO     Training average loss at step 744900: 0.142445\n",
      "2022-11-09 01:15:53,948 INFO     Training average positive_sample_loss at step 745000: 0.142183\n",
      "2022-11-09 01:15:53,948 INFO     Training average negative_sample_loss at step 745000: 0.141453\n",
      "2022-11-09 01:15:53,949 INFO     Training average loss at step 745000: 0.141818\n",
      "2022-11-09 01:15:57,034 INFO     Training average positive_sample_loss at step 745100: 0.148525\n",
      "2022-11-09 01:15:57,034 INFO     Training average negative_sample_loss at step 745100: 0.141250\n",
      "2022-11-09 01:15:57,034 INFO     Training average loss at step 745100: 0.144887\n",
      "2022-11-09 01:16:00,122 INFO     Training average positive_sample_loss at step 745200: 0.149721\n",
      "2022-11-09 01:16:00,123 INFO     Training average negative_sample_loss at step 745200: 0.138893\n",
      "2022-11-09 01:16:00,123 INFO     Training average loss at step 745200: 0.144307\n",
      "2022-11-09 01:16:03,212 INFO     Training average positive_sample_loss at step 745300: 0.143324\n",
      "2022-11-09 01:16:03,212 INFO     Training average negative_sample_loss at step 745300: 0.137734\n",
      "2022-11-09 01:16:03,212 INFO     Training average loss at step 745300: 0.140529\n",
      "2022-11-09 01:16:06,309 INFO     Training average positive_sample_loss at step 745400: 0.147230\n",
      "2022-11-09 01:16:06,309 INFO     Training average negative_sample_loss at step 745400: 0.139970\n",
      "2022-11-09 01:16:06,309 INFO     Training average loss at step 745400: 0.143600\n",
      "2022-11-09 01:16:09,398 INFO     Training average positive_sample_loss at step 745500: 0.149350\n",
      "2022-11-09 01:16:09,398 INFO     Training average negative_sample_loss at step 745500: 0.137827\n",
      "2022-11-09 01:16:09,398 INFO     Training average loss at step 745500: 0.143588\n",
      "2022-11-09 01:16:12,475 INFO     Training average positive_sample_loss at step 745600: 0.151251\n",
      "2022-11-09 01:16:12,475 INFO     Training average negative_sample_loss at step 745600: 0.142528\n",
      "2022-11-09 01:16:12,475 INFO     Training average loss at step 745600: 0.146889\n",
      "2022-11-09 01:16:15,559 INFO     Training average positive_sample_loss at step 745700: 0.152088\n",
      "2022-11-09 01:16:15,559 INFO     Training average negative_sample_loss at step 745700: 0.140538\n",
      "2022-11-09 01:16:15,559 INFO     Training average loss at step 745700: 0.146313\n",
      "2022-11-09 01:16:18,647 INFO     Training average positive_sample_loss at step 745800: 0.143664\n",
      "2022-11-09 01:16:18,647 INFO     Training average negative_sample_loss at step 745800: 0.138291\n",
      "2022-11-09 01:16:18,647 INFO     Training average loss at step 745800: 0.140977\n",
      "2022-11-09 01:16:21,738 INFO     Training average positive_sample_loss at step 745900: 0.142776\n",
      "2022-11-09 01:16:21,738 INFO     Training average negative_sample_loss at step 745900: 0.139508\n",
      "2022-11-09 01:16:21,738 INFO     Training average loss at step 745900: 0.141142\n",
      "2022-11-09 01:16:26,326 INFO     Training average positive_sample_loss at step 746000: 0.150303\n",
      "2022-11-09 01:16:26,326 INFO     Training average negative_sample_loss at step 746000: 0.139792\n",
      "2022-11-09 01:16:26,326 INFO     Training average loss at step 746000: 0.145047\n",
      "2022-11-09 01:16:30,966 INFO     Training average positive_sample_loss at step 746100: 0.151480\n",
      "2022-11-09 01:16:30,966 INFO     Training average negative_sample_loss at step 746100: 0.139713\n",
      "2022-11-09 01:16:30,966 INFO     Training average loss at step 746100: 0.145596\n",
      "2022-11-09 01:16:34,063 INFO     Training average positive_sample_loss at step 746200: 0.146130\n",
      "2022-11-09 01:16:34,064 INFO     Training average negative_sample_loss at step 746200: 0.139079\n",
      "2022-11-09 01:16:34,064 INFO     Training average loss at step 746200: 0.142604\n",
      "2022-11-09 01:16:37,161 INFO     Training average positive_sample_loss at step 746300: 0.149176\n",
      "2022-11-09 01:16:37,161 INFO     Training average negative_sample_loss at step 746300: 0.141384\n",
      "2022-11-09 01:16:37,161 INFO     Training average loss at step 746300: 0.145280\n",
      "2022-11-09 01:16:40,256 INFO     Training average positive_sample_loss at step 746400: 0.145721\n",
      "2022-11-09 01:16:40,256 INFO     Training average negative_sample_loss at step 746400: 0.143650\n",
      "2022-11-09 01:16:40,256 INFO     Training average loss at step 746400: 0.144685\n",
      "2022-11-09 01:16:43,363 INFO     Training average positive_sample_loss at step 746500: 0.144857\n",
      "2022-11-09 01:16:43,363 INFO     Training average negative_sample_loss at step 746500: 0.137354\n",
      "2022-11-09 01:16:43,363 INFO     Training average loss at step 746500: 0.141105\n",
      "2022-11-09 01:16:46,468 INFO     Training average positive_sample_loss at step 746600: 0.141920\n",
      "2022-11-09 01:16:46,468 INFO     Training average negative_sample_loss at step 746600: 0.140821\n",
      "2022-11-09 01:16:46,468 INFO     Training average loss at step 746600: 0.141370\n",
      "2022-11-09 01:16:49,593 INFO     Training average positive_sample_loss at step 746700: 0.149847\n",
      "2022-11-09 01:16:49,593 INFO     Training average negative_sample_loss at step 746700: 0.136351\n",
      "2022-11-09 01:16:49,593 INFO     Training average loss at step 746700: 0.143099\n",
      "2022-11-09 01:16:52,714 INFO     Training average positive_sample_loss at step 746800: 0.149717\n",
      "2022-11-09 01:16:52,714 INFO     Training average negative_sample_loss at step 746800: 0.143481\n",
      "2022-11-09 01:16:52,714 INFO     Training average loss at step 746800: 0.146599\n",
      "2022-11-09 01:16:55,833 INFO     Training average positive_sample_loss at step 746900: 0.148651\n",
      "2022-11-09 01:16:55,833 INFO     Training average negative_sample_loss at step 746900: 0.139321\n",
      "2022-11-09 01:16:55,833 INFO     Training average loss at step 746900: 0.143986\n",
      "2022-11-09 01:16:58,957 INFO     Training average positive_sample_loss at step 747000: 0.144477\n",
      "2022-11-09 01:16:58,957 INFO     Training average negative_sample_loss at step 747000: 0.137698\n",
      "2022-11-09 01:16:58,957 INFO     Training average loss at step 747000: 0.141088\n",
      "2022-11-09 01:17:02,073 INFO     Training average positive_sample_loss at step 747100: 0.147800\n",
      "2022-11-09 01:17:02,073 INFO     Training average negative_sample_loss at step 747100: 0.137789\n",
      "2022-11-09 01:17:02,073 INFO     Training average loss at step 747100: 0.142795\n",
      "2022-11-09 01:17:05,171 INFO     Training average positive_sample_loss at step 747200: 0.147406\n",
      "2022-11-09 01:17:05,171 INFO     Training average negative_sample_loss at step 747200: 0.138426\n",
      "2022-11-09 01:17:05,171 INFO     Training average loss at step 747200: 0.142916\n",
      "2022-11-09 01:17:08,274 INFO     Training average positive_sample_loss at step 747300: 0.149414\n",
      "2022-11-09 01:17:08,274 INFO     Training average negative_sample_loss at step 747300: 0.139780\n",
      "2022-11-09 01:17:08,274 INFO     Training average loss at step 747300: 0.144597\n",
      "2022-11-09 01:17:11,374 INFO     Training average positive_sample_loss at step 747400: 0.144888\n",
      "2022-11-09 01:17:11,374 INFO     Training average negative_sample_loss at step 747400: 0.141172\n",
      "2022-11-09 01:17:11,374 INFO     Training average loss at step 747400: 0.143030\n",
      "2022-11-09 01:17:14,464 INFO     Training average positive_sample_loss at step 747500: 0.143105\n",
      "2022-11-09 01:17:14,464 INFO     Training average negative_sample_loss at step 747500: 0.140909\n",
      "2022-11-09 01:17:14,464 INFO     Training average loss at step 747500: 0.142007\n",
      "2022-11-09 01:17:17,570 INFO     Training average positive_sample_loss at step 747600: 0.142526\n",
      "2022-11-09 01:17:17,570 INFO     Training average negative_sample_loss at step 747600: 0.141818\n",
      "2022-11-09 01:17:17,570 INFO     Training average loss at step 747600: 0.142172\n",
      "2022-11-09 01:17:20,672 INFO     Training average positive_sample_loss at step 747700: 0.146498\n",
      "2022-11-09 01:17:20,672 INFO     Training average negative_sample_loss at step 747700: 0.139926\n",
      "2022-11-09 01:17:20,672 INFO     Training average loss at step 747700: 0.143212\n",
      "2022-11-09 01:17:23,775 INFO     Training average positive_sample_loss at step 747800: 0.148690\n",
      "2022-11-09 01:17:23,775 INFO     Training average negative_sample_loss at step 747800: 0.135478\n",
      "2022-11-09 01:17:23,775 INFO     Training average loss at step 747800: 0.142084\n",
      "2022-11-09 01:17:26,866 INFO     Training average positive_sample_loss at step 747900: 0.146554\n",
      "2022-11-09 01:17:26,866 INFO     Training average negative_sample_loss at step 747900: 0.139523\n",
      "2022-11-09 01:17:26,867 INFO     Training average loss at step 747900: 0.143039\n",
      "2022-11-09 01:17:29,975 INFO     Training average positive_sample_loss at step 748000: 0.147681\n",
      "2022-11-09 01:17:29,975 INFO     Training average negative_sample_loss at step 748000: 0.139117\n",
      "2022-11-09 01:17:29,975 INFO     Training average loss at step 748000: 0.143399\n",
      "2022-11-09 01:17:33,056 INFO     Training average positive_sample_loss at step 748100: 0.153279\n",
      "2022-11-09 01:17:33,056 INFO     Training average negative_sample_loss at step 748100: 0.138406\n",
      "2022-11-09 01:17:33,056 INFO     Training average loss at step 748100: 0.145843\n",
      "2022-11-09 01:17:36,136 INFO     Training average positive_sample_loss at step 748200: 0.145657\n",
      "2022-11-09 01:17:36,136 INFO     Training average negative_sample_loss at step 748200: 0.138123\n",
      "2022-11-09 01:17:36,136 INFO     Training average loss at step 748200: 0.141890\n",
      "2022-11-09 01:17:39,238 INFO     Training average positive_sample_loss at step 748300: 0.150636\n",
      "2022-11-09 01:17:39,238 INFO     Training average negative_sample_loss at step 748300: 0.140399\n",
      "2022-11-09 01:17:39,239 INFO     Training average loss at step 748300: 0.145517\n",
      "2022-11-09 01:17:42,329 INFO     Training average positive_sample_loss at step 748400: 0.152725\n",
      "2022-11-09 01:17:42,329 INFO     Training average negative_sample_loss at step 748400: 0.143609\n",
      "2022-11-09 01:17:42,330 INFO     Training average loss at step 748400: 0.148167\n",
      "2022-11-09 01:17:45,425 INFO     Training average positive_sample_loss at step 748500: 0.151842\n",
      "2022-11-09 01:17:45,425 INFO     Training average negative_sample_loss at step 748500: 0.138536\n",
      "2022-11-09 01:17:45,425 INFO     Training average loss at step 748500: 0.145189\n",
      "2022-11-09 01:17:48,525 INFO     Training average positive_sample_loss at step 748600: 0.148079\n",
      "2022-11-09 01:17:48,525 INFO     Training average negative_sample_loss at step 748600: 0.140161\n",
      "2022-11-09 01:17:48,525 INFO     Training average loss at step 748600: 0.144120\n",
      "2022-11-09 01:17:51,598 INFO     Training average positive_sample_loss at step 748700: 0.147902\n",
      "2022-11-09 01:17:51,598 INFO     Training average negative_sample_loss at step 748700: 0.142060\n",
      "2022-11-09 01:17:51,598 INFO     Training average loss at step 748700: 0.144981\n",
      "2022-11-09 01:17:54,685 INFO     Training average positive_sample_loss at step 748800: 0.146873\n",
      "2022-11-09 01:17:54,685 INFO     Training average negative_sample_loss at step 748800: 0.136961\n",
      "2022-11-09 01:17:54,685 INFO     Training average loss at step 748800: 0.141917\n",
      "2022-11-09 01:17:57,799 INFO     Training average positive_sample_loss at step 748900: 0.146383\n",
      "2022-11-09 01:17:57,799 INFO     Training average negative_sample_loss at step 748900: 0.139667\n",
      "2022-11-09 01:17:57,799 INFO     Training average loss at step 748900: 0.143025\n",
      "2022-11-09 01:18:00,907 INFO     Training average positive_sample_loss at step 749000: 0.152215\n",
      "2022-11-09 01:18:00,907 INFO     Training average negative_sample_loss at step 749000: 0.136987\n",
      "2022-11-09 01:18:00,907 INFO     Training average loss at step 749000: 0.144601\n",
      "2022-11-09 01:18:04,012 INFO     Training average positive_sample_loss at step 749100: 0.145346\n",
      "2022-11-09 01:18:04,012 INFO     Training average negative_sample_loss at step 749100: 0.142224\n",
      "2022-11-09 01:18:04,012 INFO     Training average loss at step 749100: 0.143785\n",
      "2022-11-09 01:18:07,112 INFO     Training average positive_sample_loss at step 749200: 0.153304\n",
      "2022-11-09 01:18:07,112 INFO     Training average negative_sample_loss at step 749200: 0.137898\n",
      "2022-11-09 01:18:07,113 INFO     Training average loss at step 749200: 0.145601\n",
      "2022-11-09 01:18:10,211 INFO     Training average positive_sample_loss at step 749300: 0.147667\n",
      "2022-11-09 01:18:10,211 INFO     Training average negative_sample_loss at step 749300: 0.142476\n",
      "2022-11-09 01:18:10,211 INFO     Training average loss at step 749300: 0.145072\n",
      "2022-11-09 01:18:13,296 INFO     Training average positive_sample_loss at step 749400: 0.148566\n",
      "2022-11-09 01:18:13,296 INFO     Training average negative_sample_loss at step 749400: 0.139144\n",
      "2022-11-09 01:18:13,296 INFO     Training average loss at step 749400: 0.143855\n",
      "2022-11-09 01:18:16,377 INFO     Training average positive_sample_loss at step 749500: 0.146332\n",
      "2022-11-09 01:18:16,377 INFO     Training average negative_sample_loss at step 749500: 0.141179\n",
      "2022-11-09 01:18:16,377 INFO     Training average loss at step 749500: 0.143755\n",
      "2022-11-09 01:18:19,466 INFO     Training average positive_sample_loss at step 749600: 0.146397\n",
      "2022-11-09 01:18:19,466 INFO     Training average negative_sample_loss at step 749600: 0.142071\n",
      "2022-11-09 01:18:19,466 INFO     Training average loss at step 749600: 0.144234\n",
      "2022-11-09 01:18:22,557 INFO     Training average positive_sample_loss at step 749700: 0.143297\n",
      "2022-11-09 01:18:22,558 INFO     Training average negative_sample_loss at step 749700: 0.141053\n",
      "2022-11-09 01:18:22,558 INFO     Training average loss at step 749700: 0.142175\n",
      "2022-11-09 01:18:25,648 INFO     Training average positive_sample_loss at step 749800: 0.150545\n",
      "2022-11-09 01:18:25,648 INFO     Training average negative_sample_loss at step 749800: 0.142738\n",
      "2022-11-09 01:18:25,648 INFO     Training average loss at step 749800: 0.146642\n",
      "2022-11-09 01:18:28,732 INFO     Training average positive_sample_loss at step 749900: 0.145698\n",
      "2022-11-09 01:18:28,732 INFO     Training average negative_sample_loss at step 749900: 0.139110\n",
      "2022-11-09 01:18:28,732 INFO     Training average loss at step 749900: 0.142404\n",
      "2022-11-09 01:18:34,736 INFO     Training average positive_sample_loss at step 750000: 0.149056\n",
      "2022-11-09 01:18:34,736 INFO     Training average negative_sample_loss at step 750000: 0.141999\n",
      "2022-11-09 01:18:34,736 INFO     Training average loss at step 750000: 0.145528\n",
      "2022-11-09 01:18:37,829 INFO     Training average positive_sample_loss at step 750100: 0.142414\n",
      "2022-11-09 01:18:37,829 INFO     Training average negative_sample_loss at step 750100: 0.137388\n",
      "2022-11-09 01:18:37,829 INFO     Training average loss at step 750100: 0.139901\n",
      "2022-11-09 01:18:40,912 INFO     Training average positive_sample_loss at step 750200: 0.150352\n",
      "2022-11-09 01:18:40,913 INFO     Training average negative_sample_loss at step 750200: 0.140142\n",
      "2022-11-09 01:18:40,913 INFO     Training average loss at step 750200: 0.145247\n",
      "2022-11-09 01:18:43,996 INFO     Training average positive_sample_loss at step 750300: 0.146382\n",
      "2022-11-09 01:18:43,996 INFO     Training average negative_sample_loss at step 750300: 0.137271\n",
      "2022-11-09 01:18:43,996 INFO     Training average loss at step 750300: 0.141827\n",
      "2022-11-09 01:18:47,098 INFO     Training average positive_sample_loss at step 750400: 0.149233\n",
      "2022-11-09 01:18:47,098 INFO     Training average negative_sample_loss at step 750400: 0.136711\n",
      "2022-11-09 01:18:47,098 INFO     Training average loss at step 750400: 0.142972\n",
      "2022-11-09 01:18:51,137 INFO     Training average positive_sample_loss at step 750500: 0.151181\n",
      "2022-11-09 01:18:51,137 INFO     Training average negative_sample_loss at step 750500: 0.138991\n",
      "2022-11-09 01:18:51,137 INFO     Training average loss at step 750500: 0.145086\n",
      "2022-11-09 01:18:55,353 INFO     Training average positive_sample_loss at step 750600: 0.147692\n",
      "2022-11-09 01:18:55,353 INFO     Training average negative_sample_loss at step 750600: 0.140162\n",
      "2022-11-09 01:18:55,353 INFO     Training average loss at step 750600: 0.143927\n",
      "2022-11-09 01:18:58,440 INFO     Training average positive_sample_loss at step 750700: 0.147959\n",
      "2022-11-09 01:18:58,440 INFO     Training average negative_sample_loss at step 750700: 0.140837\n",
      "2022-11-09 01:18:58,440 INFO     Training average loss at step 750700: 0.144398\n",
      "2022-11-09 01:19:03,102 INFO     Training average positive_sample_loss at step 750800: 0.150639\n",
      "2022-11-09 01:19:03,102 INFO     Training average negative_sample_loss at step 750800: 0.136453\n",
      "2022-11-09 01:19:03,102 INFO     Training average loss at step 750800: 0.143546\n",
      "2022-11-09 01:19:06,216 INFO     Training average positive_sample_loss at step 750900: 0.142867\n",
      "2022-11-09 01:19:06,216 INFO     Training average negative_sample_loss at step 750900: 0.142259\n",
      "2022-11-09 01:19:06,216 INFO     Training average loss at step 750900: 0.142563\n",
      "2022-11-09 01:19:09,335 INFO     Training average positive_sample_loss at step 751000: 0.148628\n",
      "2022-11-09 01:19:09,335 INFO     Training average negative_sample_loss at step 751000: 0.138530\n",
      "2022-11-09 01:19:09,335 INFO     Training average loss at step 751000: 0.143579\n",
      "2022-11-09 01:19:12,431 INFO     Training average positive_sample_loss at step 751100: 0.144561\n",
      "2022-11-09 01:19:12,431 INFO     Training average negative_sample_loss at step 751100: 0.139913\n",
      "2022-11-09 01:19:12,431 INFO     Training average loss at step 751100: 0.142237\n",
      "2022-11-09 01:19:15,534 INFO     Training average positive_sample_loss at step 751200: 0.151451\n",
      "2022-11-09 01:19:15,534 INFO     Training average negative_sample_loss at step 751200: 0.139062\n",
      "2022-11-09 01:19:15,534 INFO     Training average loss at step 751200: 0.145256\n",
      "2022-11-09 01:19:18,637 INFO     Training average positive_sample_loss at step 751300: 0.157163\n",
      "2022-11-09 01:19:18,637 INFO     Training average negative_sample_loss at step 751300: 0.135077\n",
      "2022-11-09 01:19:18,637 INFO     Training average loss at step 751300: 0.146120\n",
      "2022-11-09 01:19:21,739 INFO     Training average positive_sample_loss at step 751400: 0.142368\n",
      "2022-11-09 01:19:21,739 INFO     Training average negative_sample_loss at step 751400: 0.137509\n",
      "2022-11-09 01:19:21,739 INFO     Training average loss at step 751400: 0.139938\n",
      "2022-11-09 01:19:24,839 INFO     Training average positive_sample_loss at step 751500: 0.150939\n",
      "2022-11-09 01:19:24,840 INFO     Training average negative_sample_loss at step 751500: 0.140262\n",
      "2022-11-09 01:19:24,840 INFO     Training average loss at step 751500: 0.145601\n",
      "2022-11-09 01:19:27,938 INFO     Training average positive_sample_loss at step 751600: 0.139687\n",
      "2022-11-09 01:19:27,938 INFO     Training average negative_sample_loss at step 751600: 0.136924\n",
      "2022-11-09 01:19:27,938 INFO     Training average loss at step 751600: 0.138305\n",
      "2022-11-09 01:19:31,039 INFO     Training average positive_sample_loss at step 751700: 0.149024\n",
      "2022-11-09 01:19:31,039 INFO     Training average negative_sample_loss at step 751700: 0.138934\n",
      "2022-11-09 01:19:31,039 INFO     Training average loss at step 751700: 0.143979\n",
      "2022-11-09 01:19:34,155 INFO     Training average positive_sample_loss at step 751800: 0.140983\n",
      "2022-11-09 01:19:34,156 INFO     Training average negative_sample_loss at step 751800: 0.139966\n",
      "2022-11-09 01:19:34,156 INFO     Training average loss at step 751800: 0.140475\n",
      "2022-11-09 01:19:37,252 INFO     Training average positive_sample_loss at step 751900: 0.149331\n",
      "2022-11-09 01:19:37,252 INFO     Training average negative_sample_loss at step 751900: 0.141188\n",
      "2022-11-09 01:19:37,252 INFO     Training average loss at step 751900: 0.145260\n",
      "2022-11-09 01:19:40,343 INFO     Training average positive_sample_loss at step 752000: 0.149492\n",
      "2022-11-09 01:19:40,343 INFO     Training average negative_sample_loss at step 752000: 0.141867\n",
      "2022-11-09 01:19:40,343 INFO     Training average loss at step 752000: 0.145679\n",
      "2022-11-09 01:19:43,439 INFO     Training average positive_sample_loss at step 752100: 0.144700\n",
      "2022-11-09 01:19:43,439 INFO     Training average negative_sample_loss at step 752100: 0.140243\n",
      "2022-11-09 01:19:43,439 INFO     Training average loss at step 752100: 0.142472\n",
      "2022-11-09 01:19:46,525 INFO     Training average positive_sample_loss at step 752200: 0.146755\n",
      "2022-11-09 01:19:46,525 INFO     Training average negative_sample_loss at step 752200: 0.138132\n",
      "2022-11-09 01:19:46,525 INFO     Training average loss at step 752200: 0.142443\n",
      "2022-11-09 01:19:49,628 INFO     Training average positive_sample_loss at step 752300: 0.147991\n",
      "2022-11-09 01:19:49,629 INFO     Training average negative_sample_loss at step 752300: 0.137513\n",
      "2022-11-09 01:19:49,629 INFO     Training average loss at step 752300: 0.142752\n",
      "2022-11-09 01:19:52,713 INFO     Training average positive_sample_loss at step 752400: 0.152788\n",
      "2022-11-09 01:19:52,713 INFO     Training average negative_sample_loss at step 752400: 0.141263\n",
      "2022-11-09 01:19:52,713 INFO     Training average loss at step 752400: 0.147025\n",
      "2022-11-09 01:19:55,805 INFO     Training average positive_sample_loss at step 752500: 0.147959\n",
      "2022-11-09 01:19:55,805 INFO     Training average negative_sample_loss at step 752500: 0.141609\n",
      "2022-11-09 01:19:55,805 INFO     Training average loss at step 752500: 0.144784\n",
      "2022-11-09 01:19:58,892 INFO     Training average positive_sample_loss at step 752600: 0.149766\n",
      "2022-11-09 01:19:58,893 INFO     Training average negative_sample_loss at step 752600: 0.135671\n",
      "2022-11-09 01:19:58,893 INFO     Training average loss at step 752600: 0.142719\n",
      "2022-11-09 01:20:01,986 INFO     Training average positive_sample_loss at step 752700: 0.143585\n",
      "2022-11-09 01:20:01,986 INFO     Training average negative_sample_loss at step 752700: 0.138571\n",
      "2022-11-09 01:20:01,986 INFO     Training average loss at step 752700: 0.141078\n",
      "2022-11-09 01:20:05,064 INFO     Training average positive_sample_loss at step 752800: 0.146463\n",
      "2022-11-09 01:20:05,064 INFO     Training average negative_sample_loss at step 752800: 0.142243\n",
      "2022-11-09 01:20:05,064 INFO     Training average loss at step 752800: 0.144353\n",
      "2022-11-09 01:20:08,147 INFO     Training average positive_sample_loss at step 752900: 0.147641\n",
      "2022-11-09 01:20:08,147 INFO     Training average negative_sample_loss at step 752900: 0.139851\n",
      "2022-11-09 01:20:08,147 INFO     Training average loss at step 752900: 0.143746\n",
      "2022-11-09 01:20:11,232 INFO     Training average positive_sample_loss at step 753000: 0.147390\n",
      "2022-11-09 01:20:11,232 INFO     Training average negative_sample_loss at step 753000: 0.139226\n",
      "2022-11-09 01:20:11,232 INFO     Training average loss at step 753000: 0.143308\n",
      "2022-11-09 01:20:14,322 INFO     Training average positive_sample_loss at step 753100: 0.145325\n",
      "2022-11-09 01:20:14,322 INFO     Training average negative_sample_loss at step 753100: 0.138962\n",
      "2022-11-09 01:20:14,322 INFO     Training average loss at step 753100: 0.142144\n",
      "2022-11-09 01:20:17,411 INFO     Training average positive_sample_loss at step 753200: 0.148303\n",
      "2022-11-09 01:20:17,411 INFO     Training average negative_sample_loss at step 753200: 0.134598\n",
      "2022-11-09 01:20:17,411 INFO     Training average loss at step 753200: 0.141451\n",
      "2022-11-09 01:20:20,504 INFO     Training average positive_sample_loss at step 753300: 0.144687\n",
      "2022-11-09 01:20:20,504 INFO     Training average negative_sample_loss at step 753300: 0.134113\n",
      "2022-11-09 01:20:20,504 INFO     Training average loss at step 753300: 0.139400\n",
      "2022-11-09 01:20:23,610 INFO     Training average positive_sample_loss at step 753400: 0.152267\n",
      "2022-11-09 01:20:23,610 INFO     Training average negative_sample_loss at step 753400: 0.140067\n",
      "2022-11-09 01:20:23,610 INFO     Training average loss at step 753400: 0.146167\n",
      "2022-11-09 01:20:26,730 INFO     Training average positive_sample_loss at step 753500: 0.147967\n",
      "2022-11-09 01:20:26,730 INFO     Training average negative_sample_loss at step 753500: 0.138350\n",
      "2022-11-09 01:20:26,730 INFO     Training average loss at step 753500: 0.143158\n",
      "2022-11-09 01:20:29,836 INFO     Training average positive_sample_loss at step 753600: 0.148609\n",
      "2022-11-09 01:20:29,836 INFO     Training average negative_sample_loss at step 753600: 0.139512\n",
      "2022-11-09 01:20:29,836 INFO     Training average loss at step 753600: 0.144060\n",
      "2022-11-09 01:20:32,935 INFO     Training average positive_sample_loss at step 753700: 0.150113\n",
      "2022-11-09 01:20:32,935 INFO     Training average negative_sample_loss at step 753700: 0.138320\n",
      "2022-11-09 01:20:32,936 INFO     Training average loss at step 753700: 0.144217\n",
      "2022-11-09 01:20:36,039 INFO     Training average positive_sample_loss at step 753800: 0.146572\n",
      "2022-11-09 01:20:36,039 INFO     Training average negative_sample_loss at step 753800: 0.136104\n",
      "2022-11-09 01:20:36,039 INFO     Training average loss at step 753800: 0.141338\n",
      "2022-11-09 01:20:39,154 INFO     Training average positive_sample_loss at step 753900: 0.147812\n",
      "2022-11-09 01:20:39,154 INFO     Training average negative_sample_loss at step 753900: 0.141241\n",
      "2022-11-09 01:20:39,154 INFO     Training average loss at step 753900: 0.144527\n",
      "2022-11-09 01:20:42,265 INFO     Training average positive_sample_loss at step 754000: 0.150542\n",
      "2022-11-09 01:20:42,265 INFO     Training average negative_sample_loss at step 754000: 0.138368\n",
      "2022-11-09 01:20:42,265 INFO     Training average loss at step 754000: 0.144455\n",
      "2022-11-09 01:20:45,367 INFO     Training average positive_sample_loss at step 754100: 0.147807\n",
      "2022-11-09 01:20:45,367 INFO     Training average negative_sample_loss at step 754100: 0.141501\n",
      "2022-11-09 01:20:45,367 INFO     Training average loss at step 754100: 0.144654\n",
      "2022-11-09 01:20:48,455 INFO     Training average positive_sample_loss at step 754200: 0.141662\n",
      "2022-11-09 01:20:48,455 INFO     Training average negative_sample_loss at step 754200: 0.140744\n",
      "2022-11-09 01:20:48,455 INFO     Training average loss at step 754200: 0.141203\n",
      "2022-11-09 01:20:51,549 INFO     Training average positive_sample_loss at step 754300: 0.143030\n",
      "2022-11-09 01:20:51,549 INFO     Training average negative_sample_loss at step 754300: 0.138844\n",
      "2022-11-09 01:20:51,549 INFO     Training average loss at step 754300: 0.140937\n",
      "2022-11-09 01:20:54,633 INFO     Training average positive_sample_loss at step 754400: 0.149439\n",
      "2022-11-09 01:20:54,633 INFO     Training average negative_sample_loss at step 754400: 0.143054\n",
      "2022-11-09 01:20:54,633 INFO     Training average loss at step 754400: 0.146246\n",
      "2022-11-09 01:20:57,751 INFO     Training average positive_sample_loss at step 754500: 0.148584\n",
      "2022-11-09 01:20:57,752 INFO     Training average negative_sample_loss at step 754500: 0.140873\n",
      "2022-11-09 01:20:57,752 INFO     Training average loss at step 754500: 0.144728\n",
      "2022-11-09 01:21:00,871 INFO     Training average positive_sample_loss at step 754600: 0.145438\n",
      "2022-11-09 01:21:00,872 INFO     Training average negative_sample_loss at step 754600: 0.135590\n",
      "2022-11-09 01:21:00,872 INFO     Training average loss at step 754600: 0.140514\n",
      "2022-11-09 01:21:03,964 INFO     Training average positive_sample_loss at step 754700: 0.149712\n",
      "2022-11-09 01:21:03,964 INFO     Training average negative_sample_loss at step 754700: 0.140913\n",
      "2022-11-09 01:21:03,964 INFO     Training average loss at step 754700: 0.145312\n",
      "2022-11-09 01:21:07,056 INFO     Training average positive_sample_loss at step 754800: 0.151905\n",
      "2022-11-09 01:21:07,056 INFO     Training average negative_sample_loss at step 754800: 0.138184\n",
      "2022-11-09 01:21:07,056 INFO     Training average loss at step 754800: 0.145044\n",
      "2022-11-09 01:21:10,147 INFO     Training average positive_sample_loss at step 754900: 0.152267\n",
      "2022-11-09 01:21:10,147 INFO     Training average negative_sample_loss at step 754900: 0.140499\n",
      "2022-11-09 01:21:10,147 INFO     Training average loss at step 754900: 0.146383\n",
      "2022-11-09 01:21:13,256 INFO     Training average positive_sample_loss at step 755000: 0.147603\n",
      "2022-11-09 01:21:13,256 INFO     Training average negative_sample_loss at step 755000: 0.139441\n",
      "2022-11-09 01:21:13,256 INFO     Training average loss at step 755000: 0.143522\n",
      "2022-11-09 01:21:17,328 INFO     Training average positive_sample_loss at step 755100: 0.146984\n",
      "2022-11-09 01:21:17,328 INFO     Training average negative_sample_loss at step 755100: 0.142404\n",
      "2022-11-09 01:21:17,328 INFO     Training average loss at step 755100: 0.144694\n",
      "2022-11-09 01:21:21,245 INFO     Training average positive_sample_loss at step 755200: 0.142607\n",
      "2022-11-09 01:21:21,245 INFO     Training average negative_sample_loss at step 755200: 0.141301\n",
      "2022-11-09 01:21:21,245 INFO     Training average loss at step 755200: 0.141954\n",
      "2022-11-09 01:21:25,302 INFO     Training average positive_sample_loss at step 755300: 0.144765\n",
      "2022-11-09 01:21:25,303 INFO     Training average negative_sample_loss at step 755300: 0.140742\n",
      "2022-11-09 01:21:25,303 INFO     Training average loss at step 755300: 0.142754\n",
      "2022-11-09 01:21:28,396 INFO     Training average positive_sample_loss at step 755400: 0.145040\n",
      "2022-11-09 01:21:28,396 INFO     Training average negative_sample_loss at step 755400: 0.136157\n",
      "2022-11-09 01:21:28,396 INFO     Training average loss at step 755400: 0.140598\n",
      "2022-11-09 01:21:33,016 INFO     Training average positive_sample_loss at step 755500: 0.143430\n",
      "2022-11-09 01:21:33,016 INFO     Training average negative_sample_loss at step 755500: 0.133252\n",
      "2022-11-09 01:21:33,016 INFO     Training average loss at step 755500: 0.138341\n",
      "2022-11-09 01:21:36,137 INFO     Training average positive_sample_loss at step 755600: 0.148602\n",
      "2022-11-09 01:21:36,137 INFO     Training average negative_sample_loss at step 755600: 0.141558\n",
      "2022-11-09 01:21:36,138 INFO     Training average loss at step 755600: 0.145080\n",
      "2022-11-09 01:21:39,254 INFO     Training average positive_sample_loss at step 755700: 0.142076\n",
      "2022-11-09 01:21:39,254 INFO     Training average negative_sample_loss at step 755700: 0.143185\n",
      "2022-11-09 01:21:39,254 INFO     Training average loss at step 755700: 0.142631\n",
      "2022-11-09 01:21:42,380 INFO     Training average positive_sample_loss at step 755800: 0.145580\n",
      "2022-11-09 01:21:42,380 INFO     Training average negative_sample_loss at step 755800: 0.141456\n",
      "2022-11-09 01:21:42,380 INFO     Training average loss at step 755800: 0.143518\n",
      "2022-11-09 01:21:45,485 INFO     Training average positive_sample_loss at step 755900: 0.147408\n",
      "2022-11-09 01:21:45,485 INFO     Training average negative_sample_loss at step 755900: 0.135381\n",
      "2022-11-09 01:21:45,485 INFO     Training average loss at step 755900: 0.141394\n",
      "2022-11-09 01:21:48,610 INFO     Training average positive_sample_loss at step 756000: 0.146108\n",
      "2022-11-09 01:21:48,610 INFO     Training average negative_sample_loss at step 756000: 0.138779\n",
      "2022-11-09 01:21:48,610 INFO     Training average loss at step 756000: 0.142443\n",
      "2022-11-09 01:21:51,722 INFO     Training average positive_sample_loss at step 756100: 0.149979\n",
      "2022-11-09 01:21:51,722 INFO     Training average negative_sample_loss at step 756100: 0.140278\n",
      "2022-11-09 01:21:51,722 INFO     Training average loss at step 756100: 0.145128\n",
      "2022-11-09 01:21:54,833 INFO     Training average positive_sample_loss at step 756200: 0.151553\n",
      "2022-11-09 01:21:54,833 INFO     Training average negative_sample_loss at step 756200: 0.142656\n",
      "2022-11-09 01:21:54,833 INFO     Training average loss at step 756200: 0.147105\n",
      "2022-11-09 01:21:57,948 INFO     Training average positive_sample_loss at step 756300: 0.147093\n",
      "2022-11-09 01:21:57,948 INFO     Training average negative_sample_loss at step 756300: 0.138681\n",
      "2022-11-09 01:21:57,948 INFO     Training average loss at step 756300: 0.142887\n",
      "2022-11-09 01:22:01,067 INFO     Training average positive_sample_loss at step 756400: 0.148372\n",
      "2022-11-09 01:22:01,067 INFO     Training average negative_sample_loss at step 756400: 0.142673\n",
      "2022-11-09 01:22:01,067 INFO     Training average loss at step 756400: 0.145523\n",
      "2022-11-09 01:22:04,195 INFO     Training average positive_sample_loss at step 756500: 0.141295\n",
      "2022-11-09 01:22:04,195 INFO     Training average negative_sample_loss at step 756500: 0.140905\n",
      "2022-11-09 01:22:04,195 INFO     Training average loss at step 756500: 0.141100\n",
      "2022-11-09 01:22:07,314 INFO     Training average positive_sample_loss at step 756600: 0.150922\n",
      "2022-11-09 01:22:07,315 INFO     Training average negative_sample_loss at step 756600: 0.139449\n",
      "2022-11-09 01:22:07,315 INFO     Training average loss at step 756600: 0.145186\n",
      "2022-11-09 01:22:10,435 INFO     Training average positive_sample_loss at step 756700: 0.145627\n",
      "2022-11-09 01:22:10,435 INFO     Training average negative_sample_loss at step 756700: 0.140701\n",
      "2022-11-09 01:22:10,435 INFO     Training average loss at step 756700: 0.143164\n",
      "2022-11-09 01:22:13,536 INFO     Training average positive_sample_loss at step 756800: 0.147072\n",
      "2022-11-09 01:22:13,536 INFO     Training average negative_sample_loss at step 756800: 0.141614\n",
      "2022-11-09 01:22:13,536 INFO     Training average loss at step 756800: 0.144343\n",
      "2022-11-09 01:22:16,645 INFO     Training average positive_sample_loss at step 756900: 0.140701\n",
      "2022-11-09 01:22:16,645 INFO     Training average negative_sample_loss at step 756900: 0.137961\n",
      "2022-11-09 01:22:16,645 INFO     Training average loss at step 756900: 0.139331\n",
      "2022-11-09 01:22:19,750 INFO     Training average positive_sample_loss at step 757000: 0.147554\n",
      "2022-11-09 01:22:19,750 INFO     Training average negative_sample_loss at step 757000: 0.138258\n",
      "2022-11-09 01:22:19,750 INFO     Training average loss at step 757000: 0.142906\n",
      "2022-11-09 01:22:22,852 INFO     Training average positive_sample_loss at step 757100: 0.144744\n",
      "2022-11-09 01:22:22,852 INFO     Training average negative_sample_loss at step 757100: 0.137599\n",
      "2022-11-09 01:22:22,852 INFO     Training average loss at step 757100: 0.141171\n",
      "2022-11-09 01:22:25,958 INFO     Training average positive_sample_loss at step 757200: 0.147281\n",
      "2022-11-09 01:22:25,958 INFO     Training average negative_sample_loss at step 757200: 0.133107\n",
      "2022-11-09 01:22:25,958 INFO     Training average loss at step 757200: 0.140194\n",
      "2022-11-09 01:22:29,070 INFO     Training average positive_sample_loss at step 757300: 0.146441\n",
      "2022-11-09 01:22:29,070 INFO     Training average negative_sample_loss at step 757300: 0.137104\n",
      "2022-11-09 01:22:29,071 INFO     Training average loss at step 757300: 0.141772\n",
      "2022-11-09 01:22:32,183 INFO     Training average positive_sample_loss at step 757400: 0.146502\n",
      "2022-11-09 01:22:32,183 INFO     Training average negative_sample_loss at step 757400: 0.137223\n",
      "2022-11-09 01:22:32,183 INFO     Training average loss at step 757400: 0.141863\n",
      "2022-11-09 01:22:35,306 INFO     Training average positive_sample_loss at step 757500: 0.152486\n",
      "2022-11-09 01:22:35,306 INFO     Training average negative_sample_loss at step 757500: 0.135670\n",
      "2022-11-09 01:22:35,306 INFO     Training average loss at step 757500: 0.144078\n",
      "2022-11-09 01:22:38,406 INFO     Training average positive_sample_loss at step 757600: 0.146300\n",
      "2022-11-09 01:22:38,406 INFO     Training average negative_sample_loss at step 757600: 0.137456\n",
      "2022-11-09 01:22:38,406 INFO     Training average loss at step 757600: 0.141878\n",
      "2022-11-09 01:22:41,502 INFO     Training average positive_sample_loss at step 757700: 0.148856\n",
      "2022-11-09 01:22:41,503 INFO     Training average negative_sample_loss at step 757700: 0.138297\n",
      "2022-11-09 01:22:41,503 INFO     Training average loss at step 757700: 0.143576\n",
      "2022-11-09 01:22:44,613 INFO     Training average positive_sample_loss at step 757800: 0.147294\n",
      "2022-11-09 01:22:44,613 INFO     Training average negative_sample_loss at step 757800: 0.138838\n",
      "2022-11-09 01:22:44,613 INFO     Training average loss at step 757800: 0.143066\n",
      "2022-11-09 01:22:47,705 INFO     Training average positive_sample_loss at step 757900: 0.146209\n",
      "2022-11-09 01:22:47,705 INFO     Training average negative_sample_loss at step 757900: 0.143837\n",
      "2022-11-09 01:22:47,705 INFO     Training average loss at step 757900: 0.145023\n",
      "2022-11-09 01:22:50,803 INFO     Training average positive_sample_loss at step 758000: 0.144514\n",
      "2022-11-09 01:22:50,803 INFO     Training average negative_sample_loss at step 758000: 0.138362\n",
      "2022-11-09 01:22:50,803 INFO     Training average loss at step 758000: 0.141438\n",
      "2022-11-09 01:22:53,911 INFO     Training average positive_sample_loss at step 758100: 0.153162\n",
      "2022-11-09 01:22:53,911 INFO     Training average negative_sample_loss at step 758100: 0.141740\n",
      "2022-11-09 01:22:53,911 INFO     Training average loss at step 758100: 0.147451\n",
      "2022-11-09 01:22:57,021 INFO     Training average positive_sample_loss at step 758200: 0.145148\n",
      "2022-11-09 01:22:57,021 INFO     Training average negative_sample_loss at step 758200: 0.141748\n",
      "2022-11-09 01:22:57,021 INFO     Training average loss at step 758200: 0.143448\n",
      "2022-11-09 01:23:00,121 INFO     Training average positive_sample_loss at step 758300: 0.147798\n",
      "2022-11-09 01:23:00,121 INFO     Training average negative_sample_loss at step 758300: 0.142934\n",
      "2022-11-09 01:23:00,121 INFO     Training average loss at step 758300: 0.145366\n",
      "2022-11-09 01:23:03,226 INFO     Training average positive_sample_loss at step 758400: 0.144321\n",
      "2022-11-09 01:23:03,226 INFO     Training average negative_sample_loss at step 758400: 0.139022\n",
      "2022-11-09 01:23:03,226 INFO     Training average loss at step 758400: 0.141672\n",
      "2022-11-09 01:23:06,322 INFO     Training average positive_sample_loss at step 758500: 0.150517\n",
      "2022-11-09 01:23:06,322 INFO     Training average negative_sample_loss at step 758500: 0.141744\n",
      "2022-11-09 01:23:06,322 INFO     Training average loss at step 758500: 0.146131\n",
      "2022-11-09 01:23:09,427 INFO     Training average positive_sample_loss at step 758600: 0.143734\n",
      "2022-11-09 01:23:09,428 INFO     Training average negative_sample_loss at step 758600: 0.142847\n",
      "2022-11-09 01:23:09,428 INFO     Training average loss at step 758600: 0.143291\n",
      "2022-11-09 01:23:12,536 INFO     Training average positive_sample_loss at step 758700: 0.150569\n",
      "2022-11-09 01:23:12,536 INFO     Training average negative_sample_loss at step 758700: 0.137857\n",
      "2022-11-09 01:23:12,536 INFO     Training average loss at step 758700: 0.144213\n",
      "2022-11-09 01:23:15,623 INFO     Training average positive_sample_loss at step 758800: 0.146985\n",
      "2022-11-09 01:23:15,623 INFO     Training average negative_sample_loss at step 758800: 0.141596\n",
      "2022-11-09 01:23:15,623 INFO     Training average loss at step 758800: 0.144291\n",
      "2022-11-09 01:23:18,705 INFO     Training average positive_sample_loss at step 758900: 0.145986\n",
      "2022-11-09 01:23:18,705 INFO     Training average negative_sample_loss at step 758900: 0.138736\n",
      "2022-11-09 01:23:18,705 INFO     Training average loss at step 758900: 0.142361\n",
      "2022-11-09 01:23:21,799 INFO     Training average positive_sample_loss at step 759000: 0.145610\n",
      "2022-11-09 01:23:21,800 INFO     Training average negative_sample_loss at step 759000: 0.135827\n",
      "2022-11-09 01:23:21,800 INFO     Training average loss at step 759000: 0.140719\n",
      "2022-11-09 01:23:24,898 INFO     Training average positive_sample_loss at step 759100: 0.150728\n",
      "2022-11-09 01:23:24,898 INFO     Training average negative_sample_loss at step 759100: 0.138258\n",
      "2022-11-09 01:23:24,898 INFO     Training average loss at step 759100: 0.144493\n",
      "2022-11-09 01:23:27,997 INFO     Training average positive_sample_loss at step 759200: 0.146549\n",
      "2022-11-09 01:23:27,997 INFO     Training average negative_sample_loss at step 759200: 0.140882\n",
      "2022-11-09 01:23:27,997 INFO     Training average loss at step 759200: 0.143716\n",
      "2022-11-09 01:23:31,118 INFO     Training average positive_sample_loss at step 759300: 0.148624\n",
      "2022-11-09 01:23:31,118 INFO     Training average negative_sample_loss at step 759300: 0.141175\n",
      "2022-11-09 01:23:31,118 INFO     Training average loss at step 759300: 0.144900\n",
      "2022-11-09 01:23:34,228 INFO     Training average positive_sample_loss at step 759400: 0.147669\n",
      "2022-11-09 01:23:34,228 INFO     Training average negative_sample_loss at step 759400: 0.138577\n",
      "2022-11-09 01:23:34,228 INFO     Training average loss at step 759400: 0.143123\n",
      "2022-11-09 01:23:37,342 INFO     Training average positive_sample_loss at step 759500: 0.140692\n",
      "2022-11-09 01:23:37,342 INFO     Training average negative_sample_loss at step 759500: 0.136692\n",
      "2022-11-09 01:23:37,342 INFO     Training average loss at step 759500: 0.138692\n",
      "2022-11-09 01:23:40,441 INFO     Training average positive_sample_loss at step 759600: 0.143676\n",
      "2022-11-09 01:23:40,441 INFO     Training average negative_sample_loss at step 759600: 0.140118\n",
      "2022-11-09 01:23:40,441 INFO     Training average loss at step 759600: 0.141897\n",
      "2022-11-09 01:23:43,543 INFO     Training average positive_sample_loss at step 759700: 0.147328\n",
      "2022-11-09 01:23:43,543 INFO     Training average negative_sample_loss at step 759700: 0.135228\n",
      "2022-11-09 01:23:43,543 INFO     Training average loss at step 759700: 0.141278\n",
      "2022-11-09 01:23:47,572 INFO     Training average positive_sample_loss at step 759800: 0.147581\n",
      "2022-11-09 01:23:47,572 INFO     Training average negative_sample_loss at step 759800: 0.141856\n",
      "2022-11-09 01:23:47,572 INFO     Training average loss at step 759800: 0.144719\n",
      "2022-11-09 01:23:51,499 INFO     Training average positive_sample_loss at step 759900: 0.149196\n",
      "2022-11-09 01:23:51,499 INFO     Training average negative_sample_loss at step 759900: 0.135026\n",
      "2022-11-09 01:23:51,499 INFO     Training average loss at step 759900: 0.142111\n",
      "2022-11-09 01:23:58,481 INFO     Training average positive_sample_loss at step 760000: 0.147894\n",
      "2022-11-09 01:23:58,481 INFO     Training average negative_sample_loss at step 760000: 0.134105\n",
      "2022-11-09 01:23:58,481 INFO     Training average loss at step 760000: 0.141000\n",
      "2022-11-09 01:24:03,135 INFO     Training average positive_sample_loss at step 760100: 0.146369\n",
      "2022-11-09 01:24:03,135 INFO     Training average negative_sample_loss at step 760100: 0.139312\n",
      "2022-11-09 01:24:03,135 INFO     Training average loss at step 760100: 0.142841\n",
      "2022-11-09 01:24:06,231 INFO     Training average positive_sample_loss at step 760200: 0.141769\n",
      "2022-11-09 01:24:06,231 INFO     Training average negative_sample_loss at step 760200: 0.136017\n",
      "2022-11-09 01:24:06,231 INFO     Training average loss at step 760200: 0.138893\n",
      "2022-11-09 01:24:09,348 INFO     Training average positive_sample_loss at step 760300: 0.143186\n",
      "2022-11-09 01:24:09,348 INFO     Training average negative_sample_loss at step 760300: 0.135440\n",
      "2022-11-09 01:24:09,348 INFO     Training average loss at step 760300: 0.139313\n",
      "2022-11-09 01:24:12,461 INFO     Training average positive_sample_loss at step 760400: 0.148304\n",
      "2022-11-09 01:24:12,461 INFO     Training average negative_sample_loss at step 760400: 0.138764\n",
      "2022-11-09 01:24:12,461 INFO     Training average loss at step 760400: 0.143534\n",
      "2022-11-09 01:24:15,586 INFO     Training average positive_sample_loss at step 760500: 0.150416\n",
      "2022-11-09 01:24:15,586 INFO     Training average negative_sample_loss at step 760500: 0.137769\n",
      "2022-11-09 01:24:15,586 INFO     Training average loss at step 760500: 0.144093\n",
      "2022-11-09 01:24:18,695 INFO     Training average positive_sample_loss at step 760600: 0.147220\n",
      "2022-11-09 01:24:18,695 INFO     Training average negative_sample_loss at step 760600: 0.141057\n",
      "2022-11-09 01:24:18,695 INFO     Training average loss at step 760600: 0.144138\n",
      "2022-11-09 01:24:21,802 INFO     Training average positive_sample_loss at step 760700: 0.143102\n",
      "2022-11-09 01:24:21,802 INFO     Training average negative_sample_loss at step 760700: 0.137631\n",
      "2022-11-09 01:24:21,802 INFO     Training average loss at step 760700: 0.140366\n",
      "2022-11-09 01:24:24,914 INFO     Training average positive_sample_loss at step 760800: 0.146674\n",
      "2022-11-09 01:24:24,914 INFO     Training average negative_sample_loss at step 760800: 0.141301\n",
      "2022-11-09 01:24:24,914 INFO     Training average loss at step 760800: 0.143987\n",
      "2022-11-09 01:24:28,023 INFO     Training average positive_sample_loss at step 760900: 0.148026\n",
      "2022-11-09 01:24:28,023 INFO     Training average negative_sample_loss at step 760900: 0.138301\n",
      "2022-11-09 01:24:28,023 INFO     Training average loss at step 760900: 0.143163\n",
      "2022-11-09 01:24:31,136 INFO     Training average positive_sample_loss at step 761000: 0.149200\n",
      "2022-11-09 01:24:31,136 INFO     Training average negative_sample_loss at step 761000: 0.136733\n",
      "2022-11-09 01:24:31,136 INFO     Training average loss at step 761000: 0.142967\n",
      "2022-11-09 01:24:34,238 INFO     Training average positive_sample_loss at step 761100: 0.148143\n",
      "2022-11-09 01:24:34,238 INFO     Training average negative_sample_loss at step 761100: 0.140450\n",
      "2022-11-09 01:24:34,238 INFO     Training average loss at step 761100: 0.144297\n",
      "2022-11-09 01:24:37,347 INFO     Training average positive_sample_loss at step 761200: 0.149690\n",
      "2022-11-09 01:24:37,347 INFO     Training average negative_sample_loss at step 761200: 0.140938\n",
      "2022-11-09 01:24:37,347 INFO     Training average loss at step 761200: 0.145314\n",
      "2022-11-09 01:24:40,453 INFO     Training average positive_sample_loss at step 761300: 0.148113\n",
      "2022-11-09 01:24:40,453 INFO     Training average negative_sample_loss at step 761300: 0.141669\n",
      "2022-11-09 01:24:40,453 INFO     Training average loss at step 761300: 0.144891\n",
      "2022-11-09 01:24:43,572 INFO     Training average positive_sample_loss at step 761400: 0.144639\n",
      "2022-11-09 01:24:43,572 INFO     Training average negative_sample_loss at step 761400: 0.137790\n",
      "2022-11-09 01:24:43,572 INFO     Training average loss at step 761400: 0.141214\n",
      "2022-11-09 01:24:46,663 INFO     Training average positive_sample_loss at step 761500: 0.148528\n",
      "2022-11-09 01:24:46,663 INFO     Training average negative_sample_loss at step 761500: 0.142420\n",
      "2022-11-09 01:24:46,663 INFO     Training average loss at step 761500: 0.145474\n",
      "2022-11-09 01:24:49,794 INFO     Training average positive_sample_loss at step 761600: 0.149065\n",
      "2022-11-09 01:24:49,794 INFO     Training average negative_sample_loss at step 761600: 0.135588\n",
      "2022-11-09 01:24:49,794 INFO     Training average loss at step 761600: 0.142326\n",
      "2022-11-09 01:24:52,911 INFO     Training average positive_sample_loss at step 761700: 0.155094\n",
      "2022-11-09 01:24:52,911 INFO     Training average negative_sample_loss at step 761700: 0.143516\n",
      "2022-11-09 01:24:52,911 INFO     Training average loss at step 761700: 0.149305\n",
      "2022-11-09 01:24:56,026 INFO     Training average positive_sample_loss at step 761800: 0.143638\n",
      "2022-11-09 01:24:56,026 INFO     Training average negative_sample_loss at step 761800: 0.140191\n",
      "2022-11-09 01:24:56,026 INFO     Training average loss at step 761800: 0.141914\n",
      "2022-11-09 01:24:59,132 INFO     Training average positive_sample_loss at step 761900: 0.146299\n",
      "2022-11-09 01:24:59,132 INFO     Training average negative_sample_loss at step 761900: 0.138771\n",
      "2022-11-09 01:24:59,132 INFO     Training average loss at step 761900: 0.142535\n",
      "2022-11-09 01:25:02,229 INFO     Training average positive_sample_loss at step 762000: 0.147377\n",
      "2022-11-09 01:25:02,229 INFO     Training average negative_sample_loss at step 762000: 0.139803\n",
      "2022-11-09 01:25:02,229 INFO     Training average loss at step 762000: 0.143590\n",
      "2022-11-09 01:25:05,324 INFO     Training average positive_sample_loss at step 762100: 0.147626\n",
      "2022-11-09 01:25:05,324 INFO     Training average negative_sample_loss at step 762100: 0.135426\n",
      "2022-11-09 01:25:05,324 INFO     Training average loss at step 762100: 0.141526\n",
      "2022-11-09 01:25:08,438 INFO     Training average positive_sample_loss at step 762200: 0.147743\n",
      "2022-11-09 01:25:08,438 INFO     Training average negative_sample_loss at step 762200: 0.142959\n",
      "2022-11-09 01:25:08,438 INFO     Training average loss at step 762200: 0.145351\n",
      "2022-11-09 01:25:11,549 INFO     Training average positive_sample_loss at step 762300: 0.141448\n",
      "2022-11-09 01:25:11,549 INFO     Training average negative_sample_loss at step 762300: 0.139297\n",
      "2022-11-09 01:25:11,549 INFO     Training average loss at step 762300: 0.140372\n",
      "2022-11-09 01:25:14,668 INFO     Training average positive_sample_loss at step 762400: 0.148468\n",
      "2022-11-09 01:25:14,668 INFO     Training average negative_sample_loss at step 762400: 0.138266\n",
      "2022-11-09 01:25:14,668 INFO     Training average loss at step 762400: 0.143367\n",
      "2022-11-09 01:25:17,778 INFO     Training average positive_sample_loss at step 762500: 0.140608\n",
      "2022-11-09 01:25:17,778 INFO     Training average negative_sample_loss at step 762500: 0.139467\n",
      "2022-11-09 01:25:17,778 INFO     Training average loss at step 762500: 0.140037\n",
      "2022-11-09 01:25:20,886 INFO     Training average positive_sample_loss at step 762600: 0.149347\n",
      "2022-11-09 01:25:20,886 INFO     Training average negative_sample_loss at step 762600: 0.139812\n",
      "2022-11-09 01:25:20,886 INFO     Training average loss at step 762600: 0.144579\n",
      "2022-11-09 01:25:24,006 INFO     Training average positive_sample_loss at step 762700: 0.153485\n",
      "2022-11-09 01:25:24,006 INFO     Training average negative_sample_loss at step 762700: 0.138756\n",
      "2022-11-09 01:25:24,006 INFO     Training average loss at step 762700: 0.146120\n",
      "2022-11-09 01:25:27,118 INFO     Training average positive_sample_loss at step 762800: 0.149086\n",
      "2022-11-09 01:25:27,118 INFO     Training average negative_sample_loss at step 762800: 0.138766\n",
      "2022-11-09 01:25:27,118 INFO     Training average loss at step 762800: 0.143926\n",
      "2022-11-09 01:25:30,212 INFO     Training average positive_sample_loss at step 762900: 0.144422\n",
      "2022-11-09 01:25:30,212 INFO     Training average negative_sample_loss at step 762900: 0.142445\n",
      "2022-11-09 01:25:30,212 INFO     Training average loss at step 762900: 0.143433\n",
      "2022-11-09 01:25:33,303 INFO     Training average positive_sample_loss at step 763000: 0.148667\n",
      "2022-11-09 01:25:33,304 INFO     Training average negative_sample_loss at step 763000: 0.143521\n",
      "2022-11-09 01:25:33,304 INFO     Training average loss at step 763000: 0.146094\n",
      "2022-11-09 01:25:36,415 INFO     Training average positive_sample_loss at step 763100: 0.149185\n",
      "2022-11-09 01:25:36,415 INFO     Training average negative_sample_loss at step 763100: 0.138799\n",
      "2022-11-09 01:25:36,415 INFO     Training average loss at step 763100: 0.143992\n",
      "2022-11-09 01:25:39,529 INFO     Training average positive_sample_loss at step 763200: 0.145290\n",
      "2022-11-09 01:25:39,529 INFO     Training average negative_sample_loss at step 763200: 0.140249\n",
      "2022-11-09 01:25:39,529 INFO     Training average loss at step 763200: 0.142769\n",
      "2022-11-09 01:25:42,638 INFO     Training average positive_sample_loss at step 763300: 0.145788\n",
      "2022-11-09 01:25:42,638 INFO     Training average negative_sample_loss at step 763300: 0.133846\n",
      "2022-11-09 01:25:42,638 INFO     Training average loss at step 763300: 0.139817\n",
      "2022-11-09 01:25:45,740 INFO     Training average positive_sample_loss at step 763400: 0.151265\n",
      "2022-11-09 01:25:45,740 INFO     Training average negative_sample_loss at step 763400: 0.141671\n",
      "2022-11-09 01:25:45,740 INFO     Training average loss at step 763400: 0.146468\n",
      "2022-11-09 01:25:48,834 INFO     Training average positive_sample_loss at step 763500: 0.147886\n",
      "2022-11-09 01:25:48,834 INFO     Training average negative_sample_loss at step 763500: 0.135967\n",
      "2022-11-09 01:25:48,834 INFO     Training average loss at step 763500: 0.141926\n",
      "2022-11-09 01:25:51,946 INFO     Training average positive_sample_loss at step 763600: 0.147062\n",
      "2022-11-09 01:25:51,946 INFO     Training average negative_sample_loss at step 763600: 0.134270\n",
      "2022-11-09 01:25:51,946 INFO     Training average loss at step 763600: 0.140666\n",
      "2022-11-09 01:25:55,050 INFO     Training average positive_sample_loss at step 763700: 0.150774\n",
      "2022-11-09 01:25:55,050 INFO     Training average negative_sample_loss at step 763700: 0.142677\n",
      "2022-11-09 01:25:55,050 INFO     Training average loss at step 763700: 0.146725\n",
      "2022-11-09 01:25:58,159 INFO     Training average positive_sample_loss at step 763800: 0.145177\n",
      "2022-11-09 01:25:58,159 INFO     Training average negative_sample_loss at step 763800: 0.141293\n",
      "2022-11-09 01:25:58,159 INFO     Training average loss at step 763800: 0.143235\n",
      "2022-11-09 01:26:01,258 INFO     Training average positive_sample_loss at step 763900: 0.145674\n",
      "2022-11-09 01:26:01,258 INFO     Training average negative_sample_loss at step 763900: 0.141786\n",
      "2022-11-09 01:26:01,258 INFO     Training average loss at step 763900: 0.143730\n",
      "2022-11-09 01:26:04,355 INFO     Training average positive_sample_loss at step 764000: 0.154098\n",
      "2022-11-09 01:26:04,355 INFO     Training average negative_sample_loss at step 764000: 0.137578\n",
      "2022-11-09 01:26:04,355 INFO     Training average loss at step 764000: 0.145838\n",
      "2022-11-09 01:26:07,460 INFO     Training average positive_sample_loss at step 764100: 0.149681\n",
      "2022-11-09 01:26:07,460 INFO     Training average negative_sample_loss at step 764100: 0.134592\n",
      "2022-11-09 01:26:07,461 INFO     Training average loss at step 764100: 0.142136\n",
      "2022-11-09 01:26:10,564 INFO     Training average positive_sample_loss at step 764200: 0.144669\n",
      "2022-11-09 01:26:10,564 INFO     Training average negative_sample_loss at step 764200: 0.134144\n",
      "2022-11-09 01:26:10,564 INFO     Training average loss at step 764200: 0.139407\n",
      "2022-11-09 01:26:13,659 INFO     Training average positive_sample_loss at step 764300: 0.145908\n",
      "2022-11-09 01:26:13,659 INFO     Training average negative_sample_loss at step 764300: 0.140710\n",
      "2022-11-09 01:26:13,659 INFO     Training average loss at step 764300: 0.143309\n",
      "2022-11-09 01:26:16,750 INFO     Training average positive_sample_loss at step 764400: 0.147047\n",
      "2022-11-09 01:26:16,750 INFO     Training average negative_sample_loss at step 764400: 0.135042\n",
      "2022-11-09 01:26:16,750 INFO     Training average loss at step 764400: 0.141044\n",
      "2022-11-09 01:26:20,762 INFO     Training average positive_sample_loss at step 764500: 0.148621\n",
      "2022-11-09 01:26:20,762 INFO     Training average negative_sample_loss at step 764500: 0.139516\n",
      "2022-11-09 01:26:20,762 INFO     Training average loss at step 764500: 0.144068\n",
      "2022-11-09 01:26:24,704 INFO     Training average positive_sample_loss at step 764600: 0.145177\n",
      "2022-11-09 01:26:24,704 INFO     Training average negative_sample_loss at step 764600: 0.138738\n",
      "2022-11-09 01:26:24,704 INFO     Training average loss at step 764600: 0.141957\n",
      "2022-11-09 01:26:28,742 INFO     Training average positive_sample_loss at step 764700: 0.146830\n",
      "2022-11-09 01:26:28,742 INFO     Training average negative_sample_loss at step 764700: 0.140023\n",
      "2022-11-09 01:26:28,742 INFO     Training average loss at step 764700: 0.143427\n",
      "2022-11-09 01:26:33,378 INFO     Training average positive_sample_loss at step 764800: 0.148499\n",
      "2022-11-09 01:26:33,378 INFO     Training average negative_sample_loss at step 764800: 0.143342\n",
      "2022-11-09 01:26:33,378 INFO     Training average loss at step 764800: 0.145920\n",
      "2022-11-09 01:26:36,484 INFO     Training average positive_sample_loss at step 764900: 0.146875\n",
      "2022-11-09 01:26:36,484 INFO     Training average negative_sample_loss at step 764900: 0.136398\n",
      "2022-11-09 01:26:36,484 INFO     Training average loss at step 764900: 0.141637\n",
      "2022-11-09 01:26:39,584 INFO     Training average positive_sample_loss at step 765000: 0.146213\n",
      "2022-11-09 01:26:39,584 INFO     Training average negative_sample_loss at step 765000: 0.138425\n",
      "2022-11-09 01:26:39,584 INFO     Training average loss at step 765000: 0.142319\n",
      "2022-11-09 01:26:42,687 INFO     Training average positive_sample_loss at step 765100: 0.150612\n",
      "2022-11-09 01:26:42,687 INFO     Training average negative_sample_loss at step 765100: 0.140547\n",
      "2022-11-09 01:26:42,687 INFO     Training average loss at step 765100: 0.145579\n",
      "2022-11-09 01:26:45,795 INFO     Training average positive_sample_loss at step 765200: 0.144752\n",
      "2022-11-09 01:26:45,795 INFO     Training average negative_sample_loss at step 765200: 0.141180\n",
      "2022-11-09 01:26:45,795 INFO     Training average loss at step 765200: 0.142966\n",
      "2022-11-09 01:26:48,912 INFO     Training average positive_sample_loss at step 765300: 0.147159\n",
      "2022-11-09 01:26:48,912 INFO     Training average negative_sample_loss at step 765300: 0.139298\n",
      "2022-11-09 01:26:48,912 INFO     Training average loss at step 765300: 0.143228\n",
      "2022-11-09 01:26:52,017 INFO     Training average positive_sample_loss at step 765400: 0.148897\n",
      "2022-11-09 01:26:52,017 INFO     Training average negative_sample_loss at step 765400: 0.138716\n",
      "2022-11-09 01:26:52,017 INFO     Training average loss at step 765400: 0.143807\n",
      "2022-11-09 01:26:55,119 INFO     Training average positive_sample_loss at step 765500: 0.144099\n",
      "2022-11-09 01:26:55,119 INFO     Training average negative_sample_loss at step 765500: 0.140776\n",
      "2022-11-09 01:26:55,119 INFO     Training average loss at step 765500: 0.142438\n",
      "2022-11-09 01:26:58,227 INFO     Training average positive_sample_loss at step 765600: 0.144557\n",
      "2022-11-09 01:26:58,227 INFO     Training average negative_sample_loss at step 765600: 0.134502\n",
      "2022-11-09 01:26:58,227 INFO     Training average loss at step 765600: 0.139529\n",
      "2022-11-09 01:27:01,343 INFO     Training average positive_sample_loss at step 765700: 0.147353\n",
      "2022-11-09 01:27:01,343 INFO     Training average negative_sample_loss at step 765700: 0.142144\n",
      "2022-11-09 01:27:01,343 INFO     Training average loss at step 765700: 0.144748\n",
      "2022-11-09 01:27:04,437 INFO     Training average positive_sample_loss at step 765800: 0.143564\n",
      "2022-11-09 01:27:04,437 INFO     Training average negative_sample_loss at step 765800: 0.137746\n",
      "2022-11-09 01:27:04,437 INFO     Training average loss at step 765800: 0.140655\n",
      "2022-11-09 01:27:07,540 INFO     Training average positive_sample_loss at step 765900: 0.145556\n",
      "2022-11-09 01:27:07,540 INFO     Training average negative_sample_loss at step 765900: 0.140524\n",
      "2022-11-09 01:27:07,540 INFO     Training average loss at step 765900: 0.143040\n",
      "2022-11-09 01:27:10,639 INFO     Training average positive_sample_loss at step 766000: 0.146003\n",
      "2022-11-09 01:27:10,639 INFO     Training average negative_sample_loss at step 766000: 0.139477\n",
      "2022-11-09 01:27:10,639 INFO     Training average loss at step 766000: 0.142740\n",
      "2022-11-09 01:27:13,741 INFO     Training average positive_sample_loss at step 766100: 0.147319\n",
      "2022-11-09 01:27:13,741 INFO     Training average negative_sample_loss at step 766100: 0.135416\n",
      "2022-11-09 01:27:13,741 INFO     Training average loss at step 766100: 0.141368\n",
      "2022-11-09 01:27:16,850 INFO     Training average positive_sample_loss at step 766200: 0.147023\n",
      "2022-11-09 01:27:16,850 INFO     Training average negative_sample_loss at step 766200: 0.137293\n",
      "2022-11-09 01:27:16,850 INFO     Training average loss at step 766200: 0.142158\n",
      "2022-11-09 01:27:19,953 INFO     Training average positive_sample_loss at step 766300: 0.149439\n",
      "2022-11-09 01:27:19,953 INFO     Training average negative_sample_loss at step 766300: 0.138593\n",
      "2022-11-09 01:27:19,954 INFO     Training average loss at step 766300: 0.144016\n",
      "2022-11-09 01:27:23,070 INFO     Training average positive_sample_loss at step 766400: 0.145549\n",
      "2022-11-09 01:27:23,070 INFO     Training average negative_sample_loss at step 766400: 0.137876\n",
      "2022-11-09 01:27:23,070 INFO     Training average loss at step 766400: 0.141713\n",
      "2022-11-09 01:27:26,191 INFO     Training average positive_sample_loss at step 766500: 0.146839\n",
      "2022-11-09 01:27:26,191 INFO     Training average negative_sample_loss at step 766500: 0.135022\n",
      "2022-11-09 01:27:26,191 INFO     Training average loss at step 766500: 0.140930\n",
      "2022-11-09 01:27:29,309 INFO     Training average positive_sample_loss at step 766600: 0.143208\n",
      "2022-11-09 01:27:29,309 INFO     Training average negative_sample_loss at step 766600: 0.136030\n",
      "2022-11-09 01:27:29,309 INFO     Training average loss at step 766600: 0.139619\n",
      "2022-11-09 01:27:32,428 INFO     Training average positive_sample_loss at step 766700: 0.151473\n",
      "2022-11-09 01:27:32,428 INFO     Training average negative_sample_loss at step 766700: 0.139999\n",
      "2022-11-09 01:27:32,428 INFO     Training average loss at step 766700: 0.145736\n",
      "2022-11-09 01:27:35,535 INFO     Training average positive_sample_loss at step 766800: 0.145579\n",
      "2022-11-09 01:27:35,535 INFO     Training average negative_sample_loss at step 766800: 0.140073\n",
      "2022-11-09 01:27:35,535 INFO     Training average loss at step 766800: 0.142826\n",
      "2022-11-09 01:27:38,642 INFO     Training average positive_sample_loss at step 766900: 0.140756\n",
      "2022-11-09 01:27:38,643 INFO     Training average negative_sample_loss at step 766900: 0.135935\n",
      "2022-11-09 01:27:38,643 INFO     Training average loss at step 766900: 0.138346\n",
      "2022-11-09 01:27:41,757 INFO     Training average positive_sample_loss at step 767000: 0.145510\n",
      "2022-11-09 01:27:41,757 INFO     Training average negative_sample_loss at step 767000: 0.136617\n",
      "2022-11-09 01:27:41,757 INFO     Training average loss at step 767000: 0.141063\n",
      "2022-11-09 01:27:44,868 INFO     Training average positive_sample_loss at step 767100: 0.146095\n",
      "2022-11-09 01:27:44,868 INFO     Training average negative_sample_loss at step 767100: 0.138896\n",
      "2022-11-09 01:27:44,868 INFO     Training average loss at step 767100: 0.142495\n",
      "2022-11-09 01:27:47,977 INFO     Training average positive_sample_loss at step 767200: 0.146859\n",
      "2022-11-09 01:27:47,977 INFO     Training average negative_sample_loss at step 767200: 0.137029\n",
      "2022-11-09 01:27:47,977 INFO     Training average loss at step 767200: 0.141944\n",
      "2022-11-09 01:27:51,095 INFO     Training average positive_sample_loss at step 767300: 0.143294\n",
      "2022-11-09 01:27:51,095 INFO     Training average negative_sample_loss at step 767300: 0.139610\n",
      "2022-11-09 01:27:51,096 INFO     Training average loss at step 767300: 0.141452\n",
      "2022-11-09 01:27:54,213 INFO     Training average positive_sample_loss at step 767400: 0.147402\n",
      "2022-11-09 01:27:54,213 INFO     Training average negative_sample_loss at step 767400: 0.141163\n",
      "2022-11-09 01:27:54,213 INFO     Training average loss at step 767400: 0.144282\n",
      "2022-11-09 01:27:57,335 INFO     Training average positive_sample_loss at step 767500: 0.143312\n",
      "2022-11-09 01:27:57,335 INFO     Training average negative_sample_loss at step 767500: 0.137879\n",
      "2022-11-09 01:27:57,335 INFO     Training average loss at step 767500: 0.140596\n",
      "2022-11-09 01:28:00,445 INFO     Training average positive_sample_loss at step 767600: 0.146138\n",
      "2022-11-09 01:28:00,445 INFO     Training average negative_sample_loss at step 767600: 0.141919\n",
      "2022-11-09 01:28:00,445 INFO     Training average loss at step 767600: 0.144029\n",
      "2022-11-09 01:28:03,557 INFO     Training average positive_sample_loss at step 767700: 0.146918\n",
      "2022-11-09 01:28:03,557 INFO     Training average negative_sample_loss at step 767700: 0.141010\n",
      "2022-11-09 01:28:03,557 INFO     Training average loss at step 767700: 0.143964\n",
      "2022-11-09 01:28:06,663 INFO     Training average positive_sample_loss at step 767800: 0.149143\n",
      "2022-11-09 01:28:06,663 INFO     Training average negative_sample_loss at step 767800: 0.141898\n",
      "2022-11-09 01:28:06,663 INFO     Training average loss at step 767800: 0.145521\n",
      "2022-11-09 01:28:09,777 INFO     Training average positive_sample_loss at step 767900: 0.145867\n",
      "2022-11-09 01:28:09,777 INFO     Training average negative_sample_loss at step 767900: 0.136697\n",
      "2022-11-09 01:28:09,777 INFO     Training average loss at step 767900: 0.141282\n",
      "2022-11-09 01:28:12,893 INFO     Training average positive_sample_loss at step 768000: 0.144031\n",
      "2022-11-09 01:28:12,893 INFO     Training average negative_sample_loss at step 768000: 0.137650\n",
      "2022-11-09 01:28:12,893 INFO     Training average loss at step 768000: 0.140840\n",
      "2022-11-09 01:28:15,997 INFO     Training average positive_sample_loss at step 768100: 0.150045\n",
      "2022-11-09 01:28:15,997 INFO     Training average negative_sample_loss at step 768100: 0.144655\n",
      "2022-11-09 01:28:15,997 INFO     Training average loss at step 768100: 0.147350\n",
      "2022-11-09 01:28:19,112 INFO     Training average positive_sample_loss at step 768200: 0.151541\n",
      "2022-11-09 01:28:19,112 INFO     Training average negative_sample_loss at step 768200: 0.138305\n",
      "2022-11-09 01:28:19,112 INFO     Training average loss at step 768200: 0.144923\n",
      "2022-11-09 01:28:22,219 INFO     Training average positive_sample_loss at step 768300: 0.147649\n",
      "2022-11-09 01:28:22,219 INFO     Training average negative_sample_loss at step 768300: 0.133883\n",
      "2022-11-09 01:28:22,219 INFO     Training average loss at step 768300: 0.140766\n",
      "2022-11-09 01:28:25,323 INFO     Training average positive_sample_loss at step 768400: 0.148299\n",
      "2022-11-09 01:28:25,323 INFO     Training average negative_sample_loss at step 768400: 0.143357\n",
      "2022-11-09 01:28:25,323 INFO     Training average loss at step 768400: 0.145828\n",
      "2022-11-09 01:28:28,416 INFO     Training average positive_sample_loss at step 768500: 0.147494\n",
      "2022-11-09 01:28:28,416 INFO     Training average negative_sample_loss at step 768500: 0.141312\n",
      "2022-11-09 01:28:28,416 INFO     Training average loss at step 768500: 0.144403\n",
      "2022-11-09 01:28:31,530 INFO     Training average positive_sample_loss at step 768600: 0.145489\n",
      "2022-11-09 01:28:31,530 INFO     Training average negative_sample_loss at step 768600: 0.137919\n",
      "2022-11-09 01:28:31,531 INFO     Training average loss at step 768600: 0.141704\n",
      "2022-11-09 01:28:34,644 INFO     Training average positive_sample_loss at step 768700: 0.152538\n",
      "2022-11-09 01:28:34,644 INFO     Training average negative_sample_loss at step 768700: 0.140070\n",
      "2022-11-09 01:28:34,644 INFO     Training average loss at step 768700: 0.146304\n",
      "2022-11-09 01:28:37,758 INFO     Training average positive_sample_loss at step 768800: 0.150916\n",
      "2022-11-09 01:28:37,758 INFO     Training average negative_sample_loss at step 768800: 0.139642\n",
      "2022-11-09 01:28:37,758 INFO     Training average loss at step 768800: 0.145279\n",
      "2022-11-09 01:28:40,863 INFO     Training average positive_sample_loss at step 768900: 0.145758\n",
      "2022-11-09 01:28:40,863 INFO     Training average negative_sample_loss at step 768900: 0.140884\n",
      "2022-11-09 01:28:40,864 INFO     Training average loss at step 768900: 0.143321\n",
      "2022-11-09 01:28:43,968 INFO     Training average positive_sample_loss at step 769000: 0.149996\n",
      "2022-11-09 01:28:43,968 INFO     Training average negative_sample_loss at step 769000: 0.138983\n",
      "2022-11-09 01:28:43,968 INFO     Training average loss at step 769000: 0.144490\n",
      "2022-11-09 01:28:47,079 INFO     Training average positive_sample_loss at step 769100: 0.149797\n",
      "2022-11-09 01:28:47,079 INFO     Training average negative_sample_loss at step 769100: 0.140838\n",
      "2022-11-09 01:28:47,079 INFO     Training average loss at step 769100: 0.145318\n",
      "2022-11-09 01:28:51,109 INFO     Training average positive_sample_loss at step 769200: 0.145688\n",
      "2022-11-09 01:28:51,109 INFO     Training average negative_sample_loss at step 769200: 0.139791\n",
      "2022-11-09 01:28:51,109 INFO     Training average loss at step 769200: 0.142739\n",
      "2022-11-09 01:28:55,337 INFO     Training average positive_sample_loss at step 769300: 0.150420\n",
      "2022-11-09 01:28:55,338 INFO     Training average negative_sample_loss at step 769300: 0.134282\n",
      "2022-11-09 01:28:55,338 INFO     Training average loss at step 769300: 0.142351\n",
      "2022-11-09 01:28:58,449 INFO     Training average positive_sample_loss at step 769400: 0.147464\n",
      "2022-11-09 01:28:58,449 INFO     Training average negative_sample_loss at step 769400: 0.135950\n",
      "2022-11-09 01:28:58,449 INFO     Training average loss at step 769400: 0.141707\n",
      "2022-11-09 01:29:03,120 INFO     Training average positive_sample_loss at step 769500: 0.144597\n",
      "2022-11-09 01:29:03,120 INFO     Training average negative_sample_loss at step 769500: 0.139630\n",
      "2022-11-09 01:29:03,120 INFO     Training average loss at step 769500: 0.142113\n",
      "2022-11-09 01:29:06,240 INFO     Training average positive_sample_loss at step 769600: 0.149412\n",
      "2022-11-09 01:29:06,240 INFO     Training average negative_sample_loss at step 769600: 0.137950\n",
      "2022-11-09 01:29:06,240 INFO     Training average loss at step 769600: 0.143681\n",
      "2022-11-09 01:29:09,356 INFO     Training average positive_sample_loss at step 769700: 0.148880\n",
      "2022-11-09 01:29:09,356 INFO     Training average negative_sample_loss at step 769700: 0.138011\n",
      "2022-11-09 01:29:09,356 INFO     Training average loss at step 769700: 0.143446\n",
      "2022-11-09 01:29:12,472 INFO     Training average positive_sample_loss at step 769800: 0.147617\n",
      "2022-11-09 01:29:12,472 INFO     Training average negative_sample_loss at step 769800: 0.144796\n",
      "2022-11-09 01:29:12,472 INFO     Training average loss at step 769800: 0.146207\n",
      "2022-11-09 01:29:15,587 INFO     Training average positive_sample_loss at step 769900: 0.145752\n",
      "2022-11-09 01:29:15,587 INFO     Training average negative_sample_loss at step 769900: 0.143101\n",
      "2022-11-09 01:29:15,587 INFO     Training average loss at step 769900: 0.144426\n",
      "2022-11-09 01:29:21,650 INFO     Training average positive_sample_loss at step 770000: 0.144556\n",
      "2022-11-09 01:29:21,650 INFO     Training average negative_sample_loss at step 770000: 0.143277\n",
      "2022-11-09 01:29:21,650 INFO     Training average loss at step 770000: 0.143917\n",
      "2022-11-09 01:29:24,771 INFO     Training average positive_sample_loss at step 770100: 0.144705\n",
      "2022-11-09 01:29:24,771 INFO     Training average negative_sample_loss at step 770100: 0.136152\n",
      "2022-11-09 01:29:24,771 INFO     Training average loss at step 770100: 0.140428\n",
      "2022-11-09 01:29:27,899 INFO     Training average positive_sample_loss at step 770200: 0.144298\n",
      "2022-11-09 01:29:27,899 INFO     Training average negative_sample_loss at step 770200: 0.140905\n",
      "2022-11-09 01:29:27,899 INFO     Training average loss at step 770200: 0.142601\n",
      "2022-11-09 01:29:31,018 INFO     Training average positive_sample_loss at step 770300: 0.145594\n",
      "2022-11-09 01:29:31,019 INFO     Training average negative_sample_loss at step 770300: 0.137852\n",
      "2022-11-09 01:29:31,019 INFO     Training average loss at step 770300: 0.141723\n",
      "2022-11-09 01:29:34,124 INFO     Training average positive_sample_loss at step 770400: 0.147117\n",
      "2022-11-09 01:29:34,124 INFO     Training average negative_sample_loss at step 770400: 0.139087\n",
      "2022-11-09 01:29:34,124 INFO     Training average loss at step 770400: 0.143102\n",
      "2022-11-09 01:29:37,225 INFO     Training average positive_sample_loss at step 770500: 0.144377\n",
      "2022-11-09 01:29:37,225 INFO     Training average negative_sample_loss at step 770500: 0.138882\n",
      "2022-11-09 01:29:37,225 INFO     Training average loss at step 770500: 0.141630\n",
      "2022-11-09 01:29:40,347 INFO     Training average positive_sample_loss at step 770600: 0.142294\n",
      "2022-11-09 01:29:40,348 INFO     Training average negative_sample_loss at step 770600: 0.139916\n",
      "2022-11-09 01:29:40,348 INFO     Training average loss at step 770600: 0.141105\n",
      "2022-11-09 01:29:43,439 INFO     Training average positive_sample_loss at step 770700: 0.145877\n",
      "2022-11-09 01:29:43,439 INFO     Training average negative_sample_loss at step 770700: 0.137768\n",
      "2022-11-09 01:29:43,439 INFO     Training average loss at step 770700: 0.141822\n",
      "2022-11-09 01:29:46,536 INFO     Training average positive_sample_loss at step 770800: 0.144630\n",
      "2022-11-09 01:29:46,537 INFO     Training average negative_sample_loss at step 770800: 0.138855\n",
      "2022-11-09 01:29:46,537 INFO     Training average loss at step 770800: 0.141743\n",
      "2022-11-09 01:29:49,649 INFO     Training average positive_sample_loss at step 770900: 0.153390\n",
      "2022-11-09 01:29:49,649 INFO     Training average negative_sample_loss at step 770900: 0.140751\n",
      "2022-11-09 01:29:49,649 INFO     Training average loss at step 770900: 0.147070\n",
      "2022-11-09 01:29:52,760 INFO     Training average positive_sample_loss at step 771000: 0.150494\n",
      "2022-11-09 01:29:52,760 INFO     Training average negative_sample_loss at step 771000: 0.142402\n",
      "2022-11-09 01:29:52,760 INFO     Training average loss at step 771000: 0.146448\n",
      "2022-11-09 01:29:55,865 INFO     Training average positive_sample_loss at step 771100: 0.146450\n",
      "2022-11-09 01:29:55,865 INFO     Training average negative_sample_loss at step 771100: 0.142327\n",
      "2022-11-09 01:29:55,865 INFO     Training average loss at step 771100: 0.144389\n",
      "2022-11-09 01:29:58,967 INFO     Training average positive_sample_loss at step 771200: 0.144277\n",
      "2022-11-09 01:29:58,967 INFO     Training average negative_sample_loss at step 771200: 0.135829\n",
      "2022-11-09 01:29:58,967 INFO     Training average loss at step 771200: 0.140053\n",
      "2022-11-09 01:30:02,080 INFO     Training average positive_sample_loss at step 771300: 0.145845\n",
      "2022-11-09 01:30:02,080 INFO     Training average negative_sample_loss at step 771300: 0.136756\n",
      "2022-11-09 01:30:02,080 INFO     Training average loss at step 771300: 0.141300\n",
      "2022-11-09 01:30:05,172 INFO     Training average positive_sample_loss at step 771400: 0.149432\n",
      "2022-11-09 01:30:05,172 INFO     Training average negative_sample_loss at step 771400: 0.138395\n",
      "2022-11-09 01:30:05,172 INFO     Training average loss at step 771400: 0.143914\n",
      "2022-11-09 01:30:08,259 INFO     Training average positive_sample_loss at step 771500: 0.143367\n",
      "2022-11-09 01:30:08,260 INFO     Training average negative_sample_loss at step 771500: 0.140706\n",
      "2022-11-09 01:30:08,260 INFO     Training average loss at step 771500: 0.142036\n",
      "2022-11-09 01:30:11,375 INFO     Training average positive_sample_loss at step 771600: 0.145912\n",
      "2022-11-09 01:30:11,375 INFO     Training average negative_sample_loss at step 771600: 0.137455\n",
      "2022-11-09 01:30:11,375 INFO     Training average loss at step 771600: 0.141684\n",
      "2022-11-09 01:30:14,480 INFO     Training average positive_sample_loss at step 771700: 0.141673\n",
      "2022-11-09 01:30:14,480 INFO     Training average negative_sample_loss at step 771700: 0.134591\n",
      "2022-11-09 01:30:14,480 INFO     Training average loss at step 771700: 0.138132\n",
      "2022-11-09 01:30:17,578 INFO     Training average positive_sample_loss at step 771800: 0.147085\n",
      "2022-11-09 01:30:17,579 INFO     Training average negative_sample_loss at step 771800: 0.143313\n",
      "2022-11-09 01:30:17,579 INFO     Training average loss at step 771800: 0.145199\n",
      "2022-11-09 01:30:20,691 INFO     Training average positive_sample_loss at step 771900: 0.146908\n",
      "2022-11-09 01:30:20,691 INFO     Training average negative_sample_loss at step 771900: 0.137975\n",
      "2022-11-09 01:30:20,691 INFO     Training average loss at step 771900: 0.142442\n",
      "2022-11-09 01:30:23,788 INFO     Training average positive_sample_loss at step 772000: 0.143101\n",
      "2022-11-09 01:30:23,789 INFO     Training average negative_sample_loss at step 772000: 0.139000\n",
      "2022-11-09 01:30:23,789 INFO     Training average loss at step 772000: 0.141051\n",
      "2022-11-09 01:30:26,884 INFO     Training average positive_sample_loss at step 772100: 0.142778\n",
      "2022-11-09 01:30:26,884 INFO     Training average negative_sample_loss at step 772100: 0.141170\n",
      "2022-11-09 01:30:26,884 INFO     Training average loss at step 772100: 0.141974\n",
      "2022-11-09 01:30:29,989 INFO     Training average positive_sample_loss at step 772200: 0.147615\n",
      "2022-11-09 01:30:29,989 INFO     Training average negative_sample_loss at step 772200: 0.141483\n",
      "2022-11-09 01:30:29,989 INFO     Training average loss at step 772200: 0.144549\n",
      "2022-11-09 01:30:33,102 INFO     Training average positive_sample_loss at step 772300: 0.143016\n",
      "2022-11-09 01:30:33,102 INFO     Training average negative_sample_loss at step 772300: 0.140275\n",
      "2022-11-09 01:30:33,102 INFO     Training average loss at step 772300: 0.141646\n",
      "2022-11-09 01:30:36,214 INFO     Training average positive_sample_loss at step 772400: 0.149561\n",
      "2022-11-09 01:30:36,214 INFO     Training average negative_sample_loss at step 772400: 0.137870\n",
      "2022-11-09 01:30:36,214 INFO     Training average loss at step 772400: 0.143715\n",
      "2022-11-09 01:30:39,329 INFO     Training average positive_sample_loss at step 772500: 0.145950\n",
      "2022-11-09 01:30:39,330 INFO     Training average negative_sample_loss at step 772500: 0.142427\n",
      "2022-11-09 01:30:39,330 INFO     Training average loss at step 772500: 0.144189\n",
      "2022-11-09 01:30:42,437 INFO     Training average positive_sample_loss at step 772600: 0.144568\n",
      "2022-11-09 01:30:42,437 INFO     Training average negative_sample_loss at step 772600: 0.138505\n",
      "2022-11-09 01:30:42,437 INFO     Training average loss at step 772600: 0.141536\n",
      "2022-11-09 01:30:45,543 INFO     Training average positive_sample_loss at step 772700: 0.150052\n",
      "2022-11-09 01:30:45,543 INFO     Training average negative_sample_loss at step 772700: 0.139079\n",
      "2022-11-09 01:30:45,543 INFO     Training average loss at step 772700: 0.144565\n",
      "2022-11-09 01:30:48,647 INFO     Training average positive_sample_loss at step 772800: 0.145914\n",
      "2022-11-09 01:30:48,647 INFO     Training average negative_sample_loss at step 772800: 0.137337\n",
      "2022-11-09 01:30:48,648 INFO     Training average loss at step 772800: 0.141625\n",
      "2022-11-09 01:30:51,741 INFO     Training average positive_sample_loss at step 772900: 0.142183\n",
      "2022-11-09 01:30:51,742 INFO     Training average negative_sample_loss at step 772900: 0.141077\n",
      "2022-11-09 01:30:51,742 INFO     Training average loss at step 772900: 0.141630\n",
      "2022-11-09 01:30:54,840 INFO     Training average positive_sample_loss at step 773000: 0.146534\n",
      "2022-11-09 01:30:54,840 INFO     Training average negative_sample_loss at step 773000: 0.134530\n",
      "2022-11-09 01:30:54,840 INFO     Training average loss at step 773000: 0.140532\n",
      "2022-11-09 01:30:57,943 INFO     Training average positive_sample_loss at step 773100: 0.151619\n",
      "2022-11-09 01:30:57,943 INFO     Training average negative_sample_loss at step 773100: 0.137560\n",
      "2022-11-09 01:30:57,943 INFO     Training average loss at step 773100: 0.144589\n",
      "2022-11-09 01:31:01,060 INFO     Training average positive_sample_loss at step 773200: 0.146067\n",
      "2022-11-09 01:31:01,060 INFO     Training average negative_sample_loss at step 773200: 0.140682\n",
      "2022-11-09 01:31:01,060 INFO     Training average loss at step 773200: 0.143375\n",
      "2022-11-09 01:31:04,162 INFO     Training average positive_sample_loss at step 773300: 0.150483\n",
      "2022-11-09 01:31:04,162 INFO     Training average negative_sample_loss at step 773300: 0.140658\n",
      "2022-11-09 01:31:04,162 INFO     Training average loss at step 773300: 0.145571\n",
      "2022-11-09 01:31:07,285 INFO     Training average positive_sample_loss at step 773400: 0.150445\n",
      "2022-11-09 01:31:07,285 INFO     Training average negative_sample_loss at step 773400: 0.135385\n",
      "2022-11-09 01:31:07,285 INFO     Training average loss at step 773400: 0.142915\n",
      "2022-11-09 01:31:10,408 INFO     Training average positive_sample_loss at step 773500: 0.149943\n",
      "2022-11-09 01:31:10,408 INFO     Training average negative_sample_loss at step 773500: 0.137747\n",
      "2022-11-09 01:31:10,408 INFO     Training average loss at step 773500: 0.143845\n",
      "2022-11-09 01:31:13,525 INFO     Training average positive_sample_loss at step 773600: 0.145260\n",
      "2022-11-09 01:31:13,525 INFO     Training average negative_sample_loss at step 773600: 0.135473\n",
      "2022-11-09 01:31:13,525 INFO     Training average loss at step 773600: 0.140367\n",
      "2022-11-09 01:31:17,546 INFO     Training average positive_sample_loss at step 773700: 0.142920\n",
      "2022-11-09 01:31:17,547 INFO     Training average negative_sample_loss at step 773700: 0.140140\n",
      "2022-11-09 01:31:17,547 INFO     Training average loss at step 773700: 0.141530\n",
      "2022-11-09 01:31:20,653 INFO     Training average positive_sample_loss at step 773800: 0.149234\n",
      "2022-11-09 01:31:20,653 INFO     Training average negative_sample_loss at step 773800: 0.138522\n",
      "2022-11-09 01:31:20,653 INFO     Training average loss at step 773800: 0.143878\n",
      "2022-11-09 01:31:24,938 INFO     Training average positive_sample_loss at step 773900: 0.143311\n",
      "2022-11-09 01:31:24,939 INFO     Training average negative_sample_loss at step 773900: 0.139877\n",
      "2022-11-09 01:31:24,939 INFO     Training average loss at step 773900: 0.141594\n",
      "2022-11-09 01:31:28,055 INFO     Training average positive_sample_loss at step 774000: 0.143338\n",
      "2022-11-09 01:31:28,055 INFO     Training average negative_sample_loss at step 774000: 0.137928\n",
      "2022-11-09 01:31:28,055 INFO     Training average loss at step 774000: 0.140633\n",
      "2022-11-09 01:31:31,158 INFO     Training average positive_sample_loss at step 774100: 0.146688\n",
      "2022-11-09 01:31:31,158 INFO     Training average negative_sample_loss at step 774100: 0.138277\n",
      "2022-11-09 01:31:31,159 INFO     Training average loss at step 774100: 0.142482\n",
      "2022-11-09 01:31:35,814 INFO     Training average positive_sample_loss at step 774200: 0.147977\n",
      "2022-11-09 01:31:35,814 INFO     Training average negative_sample_loss at step 774200: 0.139747\n",
      "2022-11-09 01:31:35,814 INFO     Training average loss at step 774200: 0.143862\n",
      "2022-11-09 01:31:38,917 INFO     Training average positive_sample_loss at step 774300: 0.150373\n",
      "2022-11-09 01:31:38,917 INFO     Training average negative_sample_loss at step 774300: 0.144179\n",
      "2022-11-09 01:31:38,917 INFO     Training average loss at step 774300: 0.147276\n",
      "2022-11-09 01:31:42,017 INFO     Training average positive_sample_loss at step 774400: 0.146311\n",
      "2022-11-09 01:31:42,017 INFO     Training average negative_sample_loss at step 774400: 0.136192\n",
      "2022-11-09 01:31:42,017 INFO     Training average loss at step 774400: 0.141252\n",
      "2022-11-09 01:31:45,115 INFO     Training average positive_sample_loss at step 774500: 0.151034\n",
      "2022-11-09 01:31:45,115 INFO     Training average negative_sample_loss at step 774500: 0.139227\n",
      "2022-11-09 01:31:45,115 INFO     Training average loss at step 774500: 0.145130\n",
      "2022-11-09 01:31:48,211 INFO     Training average positive_sample_loss at step 774600: 0.145965\n",
      "2022-11-09 01:31:48,211 INFO     Training average negative_sample_loss at step 774600: 0.142626\n",
      "2022-11-09 01:31:48,211 INFO     Training average loss at step 774600: 0.144296\n",
      "2022-11-09 01:31:51,312 INFO     Training average positive_sample_loss at step 774700: 0.147378\n",
      "2022-11-09 01:31:51,312 INFO     Training average negative_sample_loss at step 774700: 0.141701\n",
      "2022-11-09 01:31:51,312 INFO     Training average loss at step 774700: 0.144539\n",
      "2022-11-09 01:31:54,418 INFO     Training average positive_sample_loss at step 774800: 0.149111\n",
      "2022-11-09 01:31:54,418 INFO     Training average negative_sample_loss at step 774800: 0.143010\n",
      "2022-11-09 01:31:54,418 INFO     Training average loss at step 774800: 0.146061\n",
      "2022-11-09 01:31:57,537 INFO     Training average positive_sample_loss at step 774900: 0.147480\n",
      "2022-11-09 01:31:57,537 INFO     Training average negative_sample_loss at step 774900: 0.131395\n",
      "2022-11-09 01:31:57,537 INFO     Training average loss at step 774900: 0.139438\n",
      "2022-11-09 01:32:00,651 INFO     Training average positive_sample_loss at step 775000: 0.150270\n",
      "2022-11-09 01:32:00,651 INFO     Training average negative_sample_loss at step 775000: 0.137558\n",
      "2022-11-09 01:32:00,651 INFO     Training average loss at step 775000: 0.143914\n",
      "2022-11-09 01:32:03,749 INFO     Training average positive_sample_loss at step 775100: 0.145228\n",
      "2022-11-09 01:32:03,749 INFO     Training average negative_sample_loss at step 775100: 0.138184\n",
      "2022-11-09 01:32:03,749 INFO     Training average loss at step 775100: 0.141706\n",
      "2022-11-09 01:32:06,851 INFO     Training average positive_sample_loss at step 775200: 0.143937\n",
      "2022-11-09 01:32:06,851 INFO     Training average negative_sample_loss at step 775200: 0.139586\n",
      "2022-11-09 01:32:06,851 INFO     Training average loss at step 775200: 0.141761\n",
      "2022-11-09 01:32:09,963 INFO     Training average positive_sample_loss at step 775300: 0.147014\n",
      "2022-11-09 01:32:09,963 INFO     Training average negative_sample_loss at step 775300: 0.140826\n",
      "2022-11-09 01:32:09,963 INFO     Training average loss at step 775300: 0.143920\n",
      "2022-11-09 01:32:13,065 INFO     Training average positive_sample_loss at step 775400: 0.144387\n",
      "2022-11-09 01:32:13,065 INFO     Training average negative_sample_loss at step 775400: 0.136154\n",
      "2022-11-09 01:32:13,065 INFO     Training average loss at step 775400: 0.140271\n",
      "2022-11-09 01:32:16,171 INFO     Training average positive_sample_loss at step 775500: 0.147209\n",
      "2022-11-09 01:32:16,171 INFO     Training average negative_sample_loss at step 775500: 0.136685\n",
      "2022-11-09 01:32:16,171 INFO     Training average loss at step 775500: 0.141947\n",
      "2022-11-09 01:32:19,263 INFO     Training average positive_sample_loss at step 775600: 0.147492\n",
      "2022-11-09 01:32:19,264 INFO     Training average negative_sample_loss at step 775600: 0.140381\n",
      "2022-11-09 01:32:19,264 INFO     Training average loss at step 775600: 0.143937\n",
      "2022-11-09 01:32:22,398 INFO     Training average positive_sample_loss at step 775700: 0.146518\n",
      "2022-11-09 01:32:22,398 INFO     Training average negative_sample_loss at step 775700: 0.140251\n",
      "2022-11-09 01:32:22,398 INFO     Training average loss at step 775700: 0.143384\n",
      "2022-11-09 01:32:25,530 INFO     Training average positive_sample_loss at step 775800: 0.144625\n",
      "2022-11-09 01:32:25,530 INFO     Training average negative_sample_loss at step 775800: 0.139295\n",
      "2022-11-09 01:32:25,530 INFO     Training average loss at step 775800: 0.141960\n",
      "2022-11-09 01:32:28,648 INFO     Training average positive_sample_loss at step 775900: 0.149097\n",
      "2022-11-09 01:32:28,648 INFO     Training average negative_sample_loss at step 775900: 0.143702\n",
      "2022-11-09 01:32:28,648 INFO     Training average loss at step 775900: 0.146400\n",
      "2022-11-09 01:32:31,779 INFO     Training average positive_sample_loss at step 776000: 0.144081\n",
      "2022-11-09 01:32:31,779 INFO     Training average negative_sample_loss at step 776000: 0.137930\n",
      "2022-11-09 01:32:31,779 INFO     Training average loss at step 776000: 0.141006\n",
      "2022-11-09 01:32:34,899 INFO     Training average positive_sample_loss at step 776100: 0.154630\n",
      "2022-11-09 01:32:34,899 INFO     Training average negative_sample_loss at step 776100: 0.139285\n",
      "2022-11-09 01:32:34,899 INFO     Training average loss at step 776100: 0.146958\n",
      "2022-11-09 01:32:38,024 INFO     Training average positive_sample_loss at step 776200: 0.151061\n",
      "2022-11-09 01:32:38,024 INFO     Training average negative_sample_loss at step 776200: 0.139352\n",
      "2022-11-09 01:32:38,024 INFO     Training average loss at step 776200: 0.145207\n",
      "2022-11-09 01:32:41,139 INFO     Training average positive_sample_loss at step 776300: 0.142501\n",
      "2022-11-09 01:32:41,139 INFO     Training average negative_sample_loss at step 776300: 0.142831\n",
      "2022-11-09 01:32:41,140 INFO     Training average loss at step 776300: 0.142666\n",
      "2022-11-09 01:32:44,264 INFO     Training average positive_sample_loss at step 776400: 0.148367\n",
      "2022-11-09 01:32:44,264 INFO     Training average negative_sample_loss at step 776400: 0.139049\n",
      "2022-11-09 01:32:44,264 INFO     Training average loss at step 776400: 0.143708\n",
      "2022-11-09 01:32:47,378 INFO     Training average positive_sample_loss at step 776500: 0.147458\n",
      "2022-11-09 01:32:47,379 INFO     Training average negative_sample_loss at step 776500: 0.140328\n",
      "2022-11-09 01:32:47,379 INFO     Training average loss at step 776500: 0.143893\n",
      "2022-11-09 01:32:50,499 INFO     Training average positive_sample_loss at step 776600: 0.150638\n",
      "2022-11-09 01:32:50,499 INFO     Training average negative_sample_loss at step 776600: 0.142960\n",
      "2022-11-09 01:32:50,499 INFO     Training average loss at step 776600: 0.146799\n",
      "2022-11-09 01:32:53,615 INFO     Training average positive_sample_loss at step 776700: 0.149793\n",
      "2022-11-09 01:32:53,615 INFO     Training average negative_sample_loss at step 776700: 0.141132\n",
      "2022-11-09 01:32:53,615 INFO     Training average loss at step 776700: 0.145463\n",
      "2022-11-09 01:32:56,739 INFO     Training average positive_sample_loss at step 776800: 0.155767\n",
      "2022-11-09 01:32:56,739 INFO     Training average negative_sample_loss at step 776800: 0.141296\n",
      "2022-11-09 01:32:56,739 INFO     Training average loss at step 776800: 0.148531\n",
      "2022-11-09 01:32:59,852 INFO     Training average positive_sample_loss at step 776900: 0.147845\n",
      "2022-11-09 01:32:59,852 INFO     Training average negative_sample_loss at step 776900: 0.139500\n",
      "2022-11-09 01:32:59,852 INFO     Training average loss at step 776900: 0.143673\n",
      "2022-11-09 01:33:02,960 INFO     Training average positive_sample_loss at step 777000: 0.145420\n",
      "2022-11-09 01:33:02,960 INFO     Training average negative_sample_loss at step 777000: 0.134508\n",
      "2022-11-09 01:33:02,960 INFO     Training average loss at step 777000: 0.139964\n",
      "2022-11-09 01:33:06,071 INFO     Training average positive_sample_loss at step 777100: 0.147150\n",
      "2022-11-09 01:33:06,071 INFO     Training average negative_sample_loss at step 777100: 0.138938\n",
      "2022-11-09 01:33:06,071 INFO     Training average loss at step 777100: 0.143044\n",
      "2022-11-09 01:33:09,191 INFO     Training average positive_sample_loss at step 777200: 0.144957\n",
      "2022-11-09 01:33:09,191 INFO     Training average negative_sample_loss at step 777200: 0.141183\n",
      "2022-11-09 01:33:09,191 INFO     Training average loss at step 777200: 0.143070\n",
      "2022-11-09 01:33:12,311 INFO     Training average positive_sample_loss at step 777300: 0.147630\n",
      "2022-11-09 01:33:12,311 INFO     Training average negative_sample_loss at step 777300: 0.139172\n",
      "2022-11-09 01:33:12,311 INFO     Training average loss at step 777300: 0.143401\n",
      "2022-11-09 01:33:15,443 INFO     Training average positive_sample_loss at step 777400: 0.150076\n",
      "2022-11-09 01:33:15,443 INFO     Training average negative_sample_loss at step 777400: 0.136845\n",
      "2022-11-09 01:33:15,443 INFO     Training average loss at step 777400: 0.143460\n",
      "2022-11-09 01:33:18,549 INFO     Training average positive_sample_loss at step 777500: 0.146058\n",
      "2022-11-09 01:33:18,549 INFO     Training average negative_sample_loss at step 777500: 0.140085\n",
      "2022-11-09 01:33:18,549 INFO     Training average loss at step 777500: 0.143071\n",
      "2022-11-09 01:33:21,669 INFO     Training average positive_sample_loss at step 777600: 0.148126\n",
      "2022-11-09 01:33:21,669 INFO     Training average negative_sample_loss at step 777600: 0.139774\n",
      "2022-11-09 01:33:21,669 INFO     Training average loss at step 777600: 0.143950\n",
      "2022-11-09 01:33:24,787 INFO     Training average positive_sample_loss at step 777700: 0.148452\n",
      "2022-11-09 01:33:24,787 INFO     Training average negative_sample_loss at step 777700: 0.134976\n",
      "2022-11-09 01:33:24,787 INFO     Training average loss at step 777700: 0.141714\n",
      "2022-11-09 01:33:27,920 INFO     Training average positive_sample_loss at step 777800: 0.147815\n",
      "2022-11-09 01:33:27,920 INFO     Training average negative_sample_loss at step 777800: 0.140360\n",
      "2022-11-09 01:33:27,920 INFO     Training average loss at step 777800: 0.144087\n",
      "2022-11-09 01:33:31,057 INFO     Training average positive_sample_loss at step 777900: 0.144003\n",
      "2022-11-09 01:33:31,057 INFO     Training average negative_sample_loss at step 777900: 0.139833\n",
      "2022-11-09 01:33:31,057 INFO     Training average loss at step 777900: 0.141918\n",
      "2022-11-09 01:33:34,183 INFO     Training average positive_sample_loss at step 778000: 0.145993\n",
      "2022-11-09 01:33:34,183 INFO     Training average negative_sample_loss at step 778000: 0.139846\n",
      "2022-11-09 01:33:34,183 INFO     Training average loss at step 778000: 0.142919\n",
      "2022-11-09 01:33:37,312 INFO     Training average positive_sample_loss at step 778100: 0.148104\n",
      "2022-11-09 01:33:37,313 INFO     Training average negative_sample_loss at step 778100: 0.136956\n",
      "2022-11-09 01:33:37,313 INFO     Training average loss at step 778100: 0.142530\n",
      "2022-11-09 01:33:40,409 INFO     Training average positive_sample_loss at step 778200: 0.148382\n",
      "2022-11-09 01:33:40,409 INFO     Training average negative_sample_loss at step 778200: 0.142078\n",
      "2022-11-09 01:33:40,409 INFO     Training average loss at step 778200: 0.145230\n",
      "2022-11-09 01:33:43,507 INFO     Training average positive_sample_loss at step 778300: 0.147241\n",
      "2022-11-09 01:33:43,507 INFO     Training average negative_sample_loss at step 778300: 0.141567\n",
      "2022-11-09 01:33:43,507 INFO     Training average loss at step 778300: 0.144404\n",
      "2022-11-09 01:33:47,540 INFO     Training average positive_sample_loss at step 778400: 0.143719\n",
      "2022-11-09 01:33:47,540 INFO     Training average negative_sample_loss at step 778400: 0.138981\n",
      "2022-11-09 01:33:47,540 INFO     Training average loss at step 778400: 0.141350\n",
      "2022-11-09 01:33:51,775 INFO     Training average positive_sample_loss at step 778500: 0.142893\n",
      "2022-11-09 01:33:51,775 INFO     Training average negative_sample_loss at step 778500: 0.138262\n",
      "2022-11-09 01:33:51,775 INFO     Training average loss at step 778500: 0.140577\n",
      "2022-11-09 01:33:54,894 INFO     Training average positive_sample_loss at step 778600: 0.145419\n",
      "2022-11-09 01:33:54,894 INFO     Training average negative_sample_loss at step 778600: 0.137408\n",
      "2022-11-09 01:33:54,894 INFO     Training average loss at step 778600: 0.141413\n",
      "2022-11-09 01:33:58,015 INFO     Training average positive_sample_loss at step 778700: 0.147506\n",
      "2022-11-09 01:33:58,015 INFO     Training average negative_sample_loss at step 778700: 0.138856\n",
      "2022-11-09 01:33:58,015 INFO     Training average loss at step 778700: 0.143181\n",
      "2022-11-09 01:34:01,142 INFO     Training average positive_sample_loss at step 778800: 0.150727\n",
      "2022-11-09 01:34:01,143 INFO     Training average negative_sample_loss at step 778800: 0.139400\n",
      "2022-11-09 01:34:01,143 INFO     Training average loss at step 778800: 0.145063\n",
      "2022-11-09 01:34:05,768 INFO     Training average positive_sample_loss at step 778900: 0.142404\n",
      "2022-11-09 01:34:05,768 INFO     Training average negative_sample_loss at step 778900: 0.141799\n",
      "2022-11-09 01:34:05,768 INFO     Training average loss at step 778900: 0.142102\n",
      "2022-11-09 01:34:08,879 INFO     Training average positive_sample_loss at step 779000: 0.147336\n",
      "2022-11-09 01:34:08,879 INFO     Training average negative_sample_loss at step 779000: 0.139543\n",
      "2022-11-09 01:34:08,879 INFO     Training average loss at step 779000: 0.143439\n",
      "2022-11-09 01:34:11,986 INFO     Training average positive_sample_loss at step 779100: 0.147577\n",
      "2022-11-09 01:34:11,986 INFO     Training average negative_sample_loss at step 779100: 0.136336\n",
      "2022-11-09 01:34:11,987 INFO     Training average loss at step 779100: 0.141957\n",
      "2022-11-09 01:34:15,093 INFO     Training average positive_sample_loss at step 779200: 0.152674\n",
      "2022-11-09 01:34:15,094 INFO     Training average negative_sample_loss at step 779200: 0.141803\n",
      "2022-11-09 01:34:15,094 INFO     Training average loss at step 779200: 0.147239\n",
      "2022-11-09 01:34:18,197 INFO     Training average positive_sample_loss at step 779300: 0.146452\n",
      "2022-11-09 01:34:18,197 INFO     Training average negative_sample_loss at step 779300: 0.137522\n",
      "2022-11-09 01:34:18,197 INFO     Training average loss at step 779300: 0.141987\n",
      "2022-11-09 01:34:21,310 INFO     Training average positive_sample_loss at step 779400: 0.147884\n",
      "2022-11-09 01:34:21,310 INFO     Training average negative_sample_loss at step 779400: 0.141215\n",
      "2022-11-09 01:34:21,310 INFO     Training average loss at step 779400: 0.144550\n",
      "2022-11-09 01:34:24,417 INFO     Training average positive_sample_loss at step 779500: 0.147424\n",
      "2022-11-09 01:34:24,417 INFO     Training average negative_sample_loss at step 779500: 0.137318\n",
      "2022-11-09 01:34:24,418 INFO     Training average loss at step 779500: 0.142371\n",
      "2022-11-09 01:34:27,521 INFO     Training average positive_sample_loss at step 779600: 0.146505\n",
      "2022-11-09 01:34:27,521 INFO     Training average negative_sample_loss at step 779600: 0.137708\n",
      "2022-11-09 01:34:27,521 INFO     Training average loss at step 779600: 0.142107\n",
      "2022-11-09 01:34:30,643 INFO     Training average positive_sample_loss at step 779700: 0.148112\n",
      "2022-11-09 01:34:30,643 INFO     Training average negative_sample_loss at step 779700: 0.138767\n",
      "2022-11-09 01:34:30,643 INFO     Training average loss at step 779700: 0.143439\n",
      "2022-11-09 01:34:33,764 INFO     Training average positive_sample_loss at step 779800: 0.149072\n",
      "2022-11-09 01:34:33,764 INFO     Training average negative_sample_loss at step 779800: 0.135868\n",
      "2022-11-09 01:34:33,764 INFO     Training average loss at step 779800: 0.142470\n",
      "2022-11-09 01:34:36,882 INFO     Training average positive_sample_loss at step 779900: 0.147277\n",
      "2022-11-09 01:34:36,882 INFO     Training average negative_sample_loss at step 779900: 0.140005\n",
      "2022-11-09 01:34:36,882 INFO     Training average loss at step 779900: 0.143641\n",
      "2022-11-09 01:34:42,939 INFO     Training average positive_sample_loss at step 780000: 0.151511\n",
      "2022-11-09 01:34:42,939 INFO     Training average negative_sample_loss at step 780000: 0.139727\n",
      "2022-11-09 01:34:42,939 INFO     Training average loss at step 780000: 0.145619\n",
      "2022-11-09 01:34:46,053 INFO     Training average positive_sample_loss at step 780100: 0.147625\n",
      "2022-11-09 01:34:46,053 INFO     Training average negative_sample_loss at step 780100: 0.142296\n",
      "2022-11-09 01:34:46,053 INFO     Training average loss at step 780100: 0.144961\n",
      "2022-11-09 01:34:49,154 INFO     Training average positive_sample_loss at step 780200: 0.147327\n",
      "2022-11-09 01:34:49,154 INFO     Training average negative_sample_loss at step 780200: 0.138217\n",
      "2022-11-09 01:34:49,154 INFO     Training average loss at step 780200: 0.142772\n",
      "2022-11-09 01:34:52,262 INFO     Training average positive_sample_loss at step 780300: 0.146526\n",
      "2022-11-09 01:34:52,262 INFO     Training average negative_sample_loss at step 780300: 0.139760\n",
      "2022-11-09 01:34:52,262 INFO     Training average loss at step 780300: 0.143143\n",
      "2022-11-09 01:34:55,366 INFO     Training average positive_sample_loss at step 780400: 0.149682\n",
      "2022-11-09 01:34:55,366 INFO     Training average negative_sample_loss at step 780400: 0.136396\n",
      "2022-11-09 01:34:55,366 INFO     Training average loss at step 780400: 0.143039\n",
      "2022-11-09 01:34:58,473 INFO     Training average positive_sample_loss at step 780500: 0.143796\n",
      "2022-11-09 01:34:58,473 INFO     Training average negative_sample_loss at step 780500: 0.138538\n",
      "2022-11-09 01:34:58,473 INFO     Training average loss at step 780500: 0.141167\n",
      "2022-11-09 01:35:01,578 INFO     Training average positive_sample_loss at step 780600: 0.143089\n",
      "2022-11-09 01:35:01,578 INFO     Training average negative_sample_loss at step 780600: 0.139028\n",
      "2022-11-09 01:35:01,578 INFO     Training average loss at step 780600: 0.141058\n",
      "2022-11-09 01:35:04,656 INFO     Training average positive_sample_loss at step 780700: 0.144219\n",
      "2022-11-09 01:35:04,657 INFO     Training average negative_sample_loss at step 780700: 0.138371\n",
      "2022-11-09 01:35:04,657 INFO     Training average loss at step 780700: 0.141295\n",
      "2022-11-09 01:35:07,749 INFO     Training average positive_sample_loss at step 780800: 0.147688\n",
      "2022-11-09 01:35:07,749 INFO     Training average negative_sample_loss at step 780800: 0.140079\n",
      "2022-11-09 01:35:07,749 INFO     Training average loss at step 780800: 0.143884\n",
      "2022-11-09 01:35:10,848 INFO     Training average positive_sample_loss at step 780900: 0.146880\n",
      "2022-11-09 01:35:10,848 INFO     Training average negative_sample_loss at step 780900: 0.140758\n",
      "2022-11-09 01:35:10,848 INFO     Training average loss at step 780900: 0.143819\n",
      "2022-11-09 01:35:13,945 INFO     Training average positive_sample_loss at step 781000: 0.148743\n",
      "2022-11-09 01:35:13,945 INFO     Training average negative_sample_loss at step 781000: 0.137944\n",
      "2022-11-09 01:35:13,945 INFO     Training average loss at step 781000: 0.143343\n",
      "2022-11-09 01:35:17,034 INFO     Training average positive_sample_loss at step 781100: 0.149350\n",
      "2022-11-09 01:35:17,034 INFO     Training average negative_sample_loss at step 781100: 0.141164\n",
      "2022-11-09 01:35:17,034 INFO     Training average loss at step 781100: 0.145257\n",
      "2022-11-09 01:35:20,125 INFO     Training average positive_sample_loss at step 781200: 0.143582\n",
      "2022-11-09 01:35:20,125 INFO     Training average negative_sample_loss at step 781200: 0.138662\n",
      "2022-11-09 01:35:20,125 INFO     Training average loss at step 781200: 0.141122\n",
      "2022-11-09 01:35:23,230 INFO     Training average positive_sample_loss at step 781300: 0.147673\n",
      "2022-11-09 01:35:23,231 INFO     Training average negative_sample_loss at step 781300: 0.137897\n",
      "2022-11-09 01:35:23,231 INFO     Training average loss at step 781300: 0.142785\n",
      "2022-11-09 01:35:26,335 INFO     Training average positive_sample_loss at step 781400: 0.145447\n",
      "2022-11-09 01:35:26,335 INFO     Training average negative_sample_loss at step 781400: 0.137180\n",
      "2022-11-09 01:35:26,335 INFO     Training average loss at step 781400: 0.141314\n",
      "2022-11-09 01:35:29,444 INFO     Training average positive_sample_loss at step 781500: 0.144242\n",
      "2022-11-09 01:35:29,444 INFO     Training average negative_sample_loss at step 781500: 0.141170\n",
      "2022-11-09 01:35:29,444 INFO     Training average loss at step 781500: 0.142706\n",
      "2022-11-09 01:35:32,550 INFO     Training average positive_sample_loss at step 781600: 0.150597\n",
      "2022-11-09 01:35:32,550 INFO     Training average negative_sample_loss at step 781600: 0.142261\n",
      "2022-11-09 01:35:32,550 INFO     Training average loss at step 781600: 0.146429\n",
      "2022-11-09 01:35:35,656 INFO     Training average positive_sample_loss at step 781700: 0.142192\n",
      "2022-11-09 01:35:35,656 INFO     Training average negative_sample_loss at step 781700: 0.140276\n",
      "2022-11-09 01:35:35,656 INFO     Training average loss at step 781700: 0.141234\n",
      "2022-11-09 01:35:38,777 INFO     Training average positive_sample_loss at step 781800: 0.152133\n",
      "2022-11-09 01:35:38,777 INFO     Training average negative_sample_loss at step 781800: 0.137889\n",
      "2022-11-09 01:35:38,777 INFO     Training average loss at step 781800: 0.145011\n",
      "2022-11-09 01:35:41,883 INFO     Training average positive_sample_loss at step 781900: 0.148702\n",
      "2022-11-09 01:35:41,883 INFO     Training average negative_sample_loss at step 781900: 0.137154\n",
      "2022-11-09 01:35:41,883 INFO     Training average loss at step 781900: 0.142928\n",
      "2022-11-09 01:35:44,973 INFO     Training average positive_sample_loss at step 782000: 0.146394\n",
      "2022-11-09 01:35:44,973 INFO     Training average negative_sample_loss at step 782000: 0.137171\n",
      "2022-11-09 01:35:44,973 INFO     Training average loss at step 782000: 0.141783\n",
      "2022-11-09 01:35:48,068 INFO     Training average positive_sample_loss at step 782100: 0.144569\n",
      "2022-11-09 01:35:48,068 INFO     Training average negative_sample_loss at step 782100: 0.142498\n",
      "2022-11-09 01:35:48,068 INFO     Training average loss at step 782100: 0.143533\n",
      "2022-11-09 01:35:51,166 INFO     Training average positive_sample_loss at step 782200: 0.146927\n",
      "2022-11-09 01:35:51,166 INFO     Training average negative_sample_loss at step 782200: 0.135976\n",
      "2022-11-09 01:35:51,166 INFO     Training average loss at step 782200: 0.141452\n",
      "2022-11-09 01:35:54,280 INFO     Training average positive_sample_loss at step 782300: 0.149227\n",
      "2022-11-09 01:35:54,281 INFO     Training average negative_sample_loss at step 782300: 0.140345\n",
      "2022-11-09 01:35:54,281 INFO     Training average loss at step 782300: 0.144786\n",
      "2022-11-09 01:35:57,382 INFO     Training average positive_sample_loss at step 782400: 0.149335\n",
      "2022-11-09 01:35:57,382 INFO     Training average negative_sample_loss at step 782400: 0.139011\n",
      "2022-11-09 01:35:57,382 INFO     Training average loss at step 782400: 0.144173\n",
      "2022-11-09 01:36:00,481 INFO     Training average positive_sample_loss at step 782500: 0.141884\n",
      "2022-11-09 01:36:00,481 INFO     Training average negative_sample_loss at step 782500: 0.133395\n",
      "2022-11-09 01:36:00,481 INFO     Training average loss at step 782500: 0.137640\n",
      "2022-11-09 01:36:03,580 INFO     Training average positive_sample_loss at step 782600: 0.149179\n",
      "2022-11-09 01:36:03,580 INFO     Training average negative_sample_loss at step 782600: 0.139229\n",
      "2022-11-09 01:36:03,580 INFO     Training average loss at step 782600: 0.144204\n",
      "2022-11-09 01:36:06,680 INFO     Training average positive_sample_loss at step 782700: 0.145702\n",
      "2022-11-09 01:36:06,680 INFO     Training average negative_sample_loss at step 782700: 0.138613\n",
      "2022-11-09 01:36:06,680 INFO     Training average loss at step 782700: 0.142157\n",
      "2022-11-09 01:36:09,791 INFO     Training average positive_sample_loss at step 782800: 0.150633\n",
      "2022-11-09 01:36:09,791 INFO     Training average negative_sample_loss at step 782800: 0.139597\n",
      "2022-11-09 01:36:09,791 INFO     Training average loss at step 782800: 0.145115\n",
      "2022-11-09 01:36:12,916 INFO     Training average positive_sample_loss at step 782900: 0.151434\n",
      "2022-11-09 01:36:12,916 INFO     Training average negative_sample_loss at step 782900: 0.140368\n",
      "2022-11-09 01:36:12,916 INFO     Training average loss at step 782900: 0.145901\n",
      "2022-11-09 01:36:16,024 INFO     Training average positive_sample_loss at step 783000: 0.149080\n",
      "2022-11-09 01:36:16,024 INFO     Training average negative_sample_loss at step 783000: 0.140931\n",
      "2022-11-09 01:36:16,024 INFO     Training average loss at step 783000: 0.145005\n",
      "2022-11-09 01:36:20,059 INFO     Training average positive_sample_loss at step 783100: 0.152321\n",
      "2022-11-09 01:36:20,059 INFO     Training average negative_sample_loss at step 783100: 0.136512\n",
      "2022-11-09 01:36:20,059 INFO     Training average loss at step 783100: 0.144416\n",
      "2022-11-09 01:36:24,340 INFO     Training average positive_sample_loss at step 783200: 0.147650\n",
      "2022-11-09 01:36:24,340 INFO     Training average negative_sample_loss at step 783200: 0.142027\n",
      "2022-11-09 01:36:24,340 INFO     Training average loss at step 783200: 0.144839\n",
      "2022-11-09 01:36:27,445 INFO     Training average positive_sample_loss at step 783300: 0.145280\n",
      "2022-11-09 01:36:27,445 INFO     Training average negative_sample_loss at step 783300: 0.142527\n",
      "2022-11-09 01:36:27,445 INFO     Training average loss at step 783300: 0.143903\n",
      "2022-11-09 01:36:30,550 INFO     Training average positive_sample_loss at step 783400: 0.149581\n",
      "2022-11-09 01:36:30,550 INFO     Training average negative_sample_loss at step 783400: 0.135337\n",
      "2022-11-09 01:36:30,550 INFO     Training average loss at step 783400: 0.142459\n",
      "2022-11-09 01:36:33,665 INFO     Training average positive_sample_loss at step 783500: 0.149274\n",
      "2022-11-09 01:36:33,665 INFO     Training average negative_sample_loss at step 783500: 0.140742\n",
      "2022-11-09 01:36:33,665 INFO     Training average loss at step 783500: 0.145008\n",
      "2022-11-09 01:36:38,331 INFO     Training average positive_sample_loss at step 783600: 0.147505\n",
      "2022-11-09 01:36:38,331 INFO     Training average negative_sample_loss at step 783600: 0.140723\n",
      "2022-11-09 01:36:38,331 INFO     Training average loss at step 783600: 0.144114\n",
      "2022-11-09 01:36:41,441 INFO     Training average positive_sample_loss at step 783700: 0.145863\n",
      "2022-11-09 01:36:41,441 INFO     Training average negative_sample_loss at step 783700: 0.138503\n",
      "2022-11-09 01:36:41,442 INFO     Training average loss at step 783700: 0.142183\n",
      "2022-11-09 01:36:44,554 INFO     Training average positive_sample_loss at step 783800: 0.150110\n",
      "2022-11-09 01:36:44,554 INFO     Training average negative_sample_loss at step 783800: 0.143552\n",
      "2022-11-09 01:36:44,555 INFO     Training average loss at step 783800: 0.146831\n",
      "2022-11-09 01:36:47,677 INFO     Training average positive_sample_loss at step 783900: 0.146589\n",
      "2022-11-09 01:36:47,677 INFO     Training average negative_sample_loss at step 783900: 0.139047\n",
      "2022-11-09 01:36:47,677 INFO     Training average loss at step 783900: 0.142818\n",
      "2022-11-09 01:36:50,797 INFO     Training average positive_sample_loss at step 784000: 0.144680\n",
      "2022-11-09 01:36:50,797 INFO     Training average negative_sample_loss at step 784000: 0.137446\n",
      "2022-11-09 01:36:50,797 INFO     Training average loss at step 784000: 0.141063\n",
      "2022-11-09 01:36:53,912 INFO     Training average positive_sample_loss at step 784100: 0.146670\n",
      "2022-11-09 01:36:53,912 INFO     Training average negative_sample_loss at step 784100: 0.137027\n",
      "2022-11-09 01:36:53,912 INFO     Training average loss at step 784100: 0.141849\n",
      "2022-11-09 01:36:57,027 INFO     Training average positive_sample_loss at step 784200: 0.150542\n",
      "2022-11-09 01:36:57,027 INFO     Training average negative_sample_loss at step 784200: 0.145899\n",
      "2022-11-09 01:36:57,027 INFO     Training average loss at step 784200: 0.148221\n",
      "2022-11-09 01:37:00,149 INFO     Training average positive_sample_loss at step 784300: 0.145467\n",
      "2022-11-09 01:37:00,149 INFO     Training average negative_sample_loss at step 784300: 0.141936\n",
      "2022-11-09 01:37:00,149 INFO     Training average loss at step 784300: 0.143701\n",
      "2022-11-09 01:37:03,268 INFO     Training average positive_sample_loss at step 784400: 0.148034\n",
      "2022-11-09 01:37:03,268 INFO     Training average negative_sample_loss at step 784400: 0.140321\n",
      "2022-11-09 01:37:03,268 INFO     Training average loss at step 784400: 0.144177\n",
      "2022-11-09 01:37:06,383 INFO     Training average positive_sample_loss at step 784500: 0.147646\n",
      "2022-11-09 01:37:06,383 INFO     Training average negative_sample_loss at step 784500: 0.140796\n",
      "2022-11-09 01:37:06,383 INFO     Training average loss at step 784500: 0.144221\n",
      "2022-11-09 01:37:09,490 INFO     Training average positive_sample_loss at step 784600: 0.148498\n",
      "2022-11-09 01:37:09,491 INFO     Training average negative_sample_loss at step 784600: 0.141223\n",
      "2022-11-09 01:37:09,491 INFO     Training average loss at step 784600: 0.144861\n",
      "2022-11-09 01:37:12,590 INFO     Training average positive_sample_loss at step 784700: 0.147947\n",
      "2022-11-09 01:37:12,590 INFO     Training average negative_sample_loss at step 784700: 0.135404\n",
      "2022-11-09 01:37:12,590 INFO     Training average loss at step 784700: 0.141675\n",
      "2022-11-09 01:37:15,694 INFO     Training average positive_sample_loss at step 784800: 0.146691\n",
      "2022-11-09 01:37:15,694 INFO     Training average negative_sample_loss at step 784800: 0.139854\n",
      "2022-11-09 01:37:15,694 INFO     Training average loss at step 784800: 0.143272\n",
      "2022-11-09 01:37:18,809 INFO     Training average positive_sample_loss at step 784900: 0.146842\n",
      "2022-11-09 01:37:18,809 INFO     Training average negative_sample_loss at step 784900: 0.144081\n",
      "2022-11-09 01:37:18,809 INFO     Training average loss at step 784900: 0.145462\n",
      "2022-11-09 01:37:21,910 INFO     Training average positive_sample_loss at step 785000: 0.144832\n",
      "2022-11-09 01:37:21,910 INFO     Training average negative_sample_loss at step 785000: 0.139381\n",
      "2022-11-09 01:37:21,910 INFO     Training average loss at step 785000: 0.142106\n",
      "2022-11-09 01:37:25,012 INFO     Training average positive_sample_loss at step 785100: 0.148577\n",
      "2022-11-09 01:37:25,012 INFO     Training average negative_sample_loss at step 785100: 0.144198\n",
      "2022-11-09 01:37:25,012 INFO     Training average loss at step 785100: 0.146387\n",
      "2022-11-09 01:37:28,112 INFO     Training average positive_sample_loss at step 785200: 0.144559\n",
      "2022-11-09 01:37:28,112 INFO     Training average negative_sample_loss at step 785200: 0.143200\n",
      "2022-11-09 01:37:28,112 INFO     Training average loss at step 785200: 0.143880\n",
      "2022-11-09 01:37:31,216 INFO     Training average positive_sample_loss at step 785300: 0.149356\n",
      "2022-11-09 01:37:31,216 INFO     Training average negative_sample_loss at step 785300: 0.139900\n",
      "2022-11-09 01:37:31,216 INFO     Training average loss at step 785300: 0.144628\n",
      "2022-11-09 01:37:34,325 INFO     Training average positive_sample_loss at step 785400: 0.144035\n",
      "2022-11-09 01:37:34,325 INFO     Training average negative_sample_loss at step 785400: 0.138259\n",
      "2022-11-09 01:37:34,325 INFO     Training average loss at step 785400: 0.141147\n",
      "2022-11-09 01:37:37,428 INFO     Training average positive_sample_loss at step 785500: 0.144659\n",
      "2022-11-09 01:37:37,428 INFO     Training average negative_sample_loss at step 785500: 0.135349\n",
      "2022-11-09 01:37:37,428 INFO     Training average loss at step 785500: 0.140004\n",
      "2022-11-09 01:37:40,531 INFO     Training average positive_sample_loss at step 785600: 0.142261\n",
      "2022-11-09 01:37:40,531 INFO     Training average negative_sample_loss at step 785600: 0.141074\n",
      "2022-11-09 01:37:40,531 INFO     Training average loss at step 785600: 0.141668\n",
      "2022-11-09 01:37:43,625 INFO     Training average positive_sample_loss at step 785700: 0.145519\n",
      "2022-11-09 01:37:43,625 INFO     Training average negative_sample_loss at step 785700: 0.137873\n",
      "2022-11-09 01:37:43,625 INFO     Training average loss at step 785700: 0.141696\n",
      "2022-11-09 01:37:46,738 INFO     Training average positive_sample_loss at step 785800: 0.150359\n",
      "2022-11-09 01:37:46,738 INFO     Training average negative_sample_loss at step 785800: 0.142378\n",
      "2022-11-09 01:37:46,738 INFO     Training average loss at step 785800: 0.146369\n",
      "2022-11-09 01:37:49,842 INFO     Training average positive_sample_loss at step 785900: 0.148663\n",
      "2022-11-09 01:37:49,843 INFO     Training average negative_sample_loss at step 785900: 0.138080\n",
      "2022-11-09 01:37:49,843 INFO     Training average loss at step 785900: 0.143372\n",
      "2022-11-09 01:37:52,949 INFO     Training average positive_sample_loss at step 786000: 0.149781\n",
      "2022-11-09 01:37:52,949 INFO     Training average negative_sample_loss at step 786000: 0.140505\n",
      "2022-11-09 01:37:52,949 INFO     Training average loss at step 786000: 0.145143\n",
      "2022-11-09 01:37:56,064 INFO     Training average positive_sample_loss at step 786100: 0.149261\n",
      "2022-11-09 01:37:56,065 INFO     Training average negative_sample_loss at step 786100: 0.139899\n",
      "2022-11-09 01:37:56,065 INFO     Training average loss at step 786100: 0.144580\n",
      "2022-11-09 01:37:59,174 INFO     Training average positive_sample_loss at step 786200: 0.144300\n",
      "2022-11-09 01:37:59,174 INFO     Training average negative_sample_loss at step 786200: 0.140316\n",
      "2022-11-09 01:37:59,174 INFO     Training average loss at step 786200: 0.142308\n",
      "2022-11-09 01:38:02,293 INFO     Training average positive_sample_loss at step 786300: 0.150756\n",
      "2022-11-09 01:38:02,293 INFO     Training average negative_sample_loss at step 786300: 0.134149\n",
      "2022-11-09 01:38:02,293 INFO     Training average loss at step 786300: 0.142453\n",
      "2022-11-09 01:38:05,401 INFO     Training average positive_sample_loss at step 786400: 0.148490\n",
      "2022-11-09 01:38:05,401 INFO     Training average negative_sample_loss at step 786400: 0.138797\n",
      "2022-11-09 01:38:05,401 INFO     Training average loss at step 786400: 0.143644\n",
      "2022-11-09 01:38:08,515 INFO     Training average positive_sample_loss at step 786500: 0.151175\n",
      "2022-11-09 01:38:08,515 INFO     Training average negative_sample_loss at step 786500: 0.138832\n",
      "2022-11-09 01:38:08,515 INFO     Training average loss at step 786500: 0.145003\n",
      "2022-11-09 01:38:11,622 INFO     Training average positive_sample_loss at step 786600: 0.146453\n",
      "2022-11-09 01:38:11,622 INFO     Training average negative_sample_loss at step 786600: 0.139605\n",
      "2022-11-09 01:38:11,622 INFO     Training average loss at step 786600: 0.143029\n",
      "2022-11-09 01:38:14,718 INFO     Training average positive_sample_loss at step 786700: 0.145343\n",
      "2022-11-09 01:38:14,718 INFO     Training average negative_sample_loss at step 786700: 0.139994\n",
      "2022-11-09 01:38:14,718 INFO     Training average loss at step 786700: 0.142669\n",
      "2022-11-09 01:38:17,805 INFO     Training average positive_sample_loss at step 786800: 0.151138\n",
      "2022-11-09 01:38:17,805 INFO     Training average negative_sample_loss at step 786800: 0.135068\n",
      "2022-11-09 01:38:17,805 INFO     Training average loss at step 786800: 0.143103\n",
      "2022-11-09 01:38:20,886 INFO     Training average positive_sample_loss at step 786900: 0.140510\n",
      "2022-11-09 01:38:20,886 INFO     Training average negative_sample_loss at step 786900: 0.140110\n",
      "2022-11-09 01:38:20,886 INFO     Training average loss at step 786900: 0.140310\n",
      "2022-11-09 01:38:23,982 INFO     Training average positive_sample_loss at step 787000: 0.148882\n",
      "2022-11-09 01:38:23,982 INFO     Training average negative_sample_loss at step 787000: 0.136365\n",
      "2022-11-09 01:38:23,982 INFO     Training average loss at step 787000: 0.142623\n",
      "2022-11-09 01:38:27,079 INFO     Training average positive_sample_loss at step 787100: 0.150402\n",
      "2022-11-09 01:38:27,079 INFO     Training average negative_sample_loss at step 787100: 0.139789\n",
      "2022-11-09 01:38:27,079 INFO     Training average loss at step 787100: 0.145095\n",
      "2022-11-09 01:38:30,180 INFO     Training average positive_sample_loss at step 787200: 0.145607\n",
      "2022-11-09 01:38:30,180 INFO     Training average negative_sample_loss at step 787200: 0.138131\n",
      "2022-11-09 01:38:30,181 INFO     Training average loss at step 787200: 0.141869\n",
      "2022-11-09 01:38:33,275 INFO     Training average positive_sample_loss at step 787300: 0.142428\n",
      "2022-11-09 01:38:33,275 INFO     Training average negative_sample_loss at step 787300: 0.143093\n",
      "2022-11-09 01:38:33,275 INFO     Training average loss at step 787300: 0.142760\n",
      "2022-11-09 01:38:36,365 INFO     Training average positive_sample_loss at step 787400: 0.151107\n",
      "2022-11-09 01:38:36,365 INFO     Training average negative_sample_loss at step 787400: 0.140280\n",
      "2022-11-09 01:38:36,365 INFO     Training average loss at step 787400: 0.145694\n",
      "2022-11-09 01:38:39,457 INFO     Training average positive_sample_loss at step 787500: 0.146849\n",
      "2022-11-09 01:38:39,457 INFO     Training average negative_sample_loss at step 787500: 0.138522\n",
      "2022-11-09 01:38:39,457 INFO     Training average loss at step 787500: 0.142686\n",
      "2022-11-09 01:38:42,550 INFO     Training average positive_sample_loss at step 787600: 0.148292\n",
      "2022-11-09 01:38:42,550 INFO     Training average negative_sample_loss at step 787600: 0.139306\n",
      "2022-11-09 01:38:42,550 INFO     Training average loss at step 787600: 0.143799\n",
      "2022-11-09 01:38:46,613 INFO     Training average positive_sample_loss at step 787700: 0.146830\n",
      "2022-11-09 01:38:46,613 INFO     Training average negative_sample_loss at step 787700: 0.141268\n",
      "2022-11-09 01:38:46,613 INFO     Training average loss at step 787700: 0.144049\n",
      "2022-11-09 01:38:50,500 INFO     Training average positive_sample_loss at step 787800: 0.144787\n",
      "2022-11-09 01:38:50,500 INFO     Training average negative_sample_loss at step 787800: 0.135329\n",
      "2022-11-09 01:38:50,500 INFO     Training average loss at step 787800: 0.140058\n",
      "2022-11-09 01:38:54,531 INFO     Training average positive_sample_loss at step 787900: 0.147655\n",
      "2022-11-09 01:38:54,531 INFO     Training average negative_sample_loss at step 787900: 0.137509\n",
      "2022-11-09 01:38:54,531 INFO     Training average loss at step 787900: 0.142582\n",
      "2022-11-09 01:38:57,631 INFO     Training average positive_sample_loss at step 788000: 0.146139\n",
      "2022-11-09 01:38:57,631 INFO     Training average negative_sample_loss at step 788000: 0.139628\n",
      "2022-11-09 01:38:57,631 INFO     Training average loss at step 788000: 0.142883\n",
      "2022-11-09 01:39:00,734 INFO     Training average positive_sample_loss at step 788100: 0.144143\n",
      "2022-11-09 01:39:00,734 INFO     Training average negative_sample_loss at step 788100: 0.141726\n",
      "2022-11-09 01:39:00,734 INFO     Training average loss at step 788100: 0.142935\n",
      "2022-11-09 01:39:03,831 INFO     Training average positive_sample_loss at step 788200: 0.144701\n",
      "2022-11-09 01:39:03,831 INFO     Training average negative_sample_loss at step 788200: 0.138178\n",
      "2022-11-09 01:39:03,831 INFO     Training average loss at step 788200: 0.141440\n",
      "2022-11-09 01:39:08,443 INFO     Training average positive_sample_loss at step 788300: 0.154914\n",
      "2022-11-09 01:39:08,444 INFO     Training average negative_sample_loss at step 788300: 0.137526\n",
      "2022-11-09 01:39:08,444 INFO     Training average loss at step 788300: 0.146220\n",
      "2022-11-09 01:39:11,545 INFO     Training average positive_sample_loss at step 788400: 0.148022\n",
      "2022-11-09 01:39:11,545 INFO     Training average negative_sample_loss at step 788400: 0.141549\n",
      "2022-11-09 01:39:11,545 INFO     Training average loss at step 788400: 0.144786\n",
      "2022-11-09 01:39:14,641 INFO     Training average positive_sample_loss at step 788500: 0.149471\n",
      "2022-11-09 01:39:14,642 INFO     Training average negative_sample_loss at step 788500: 0.137841\n",
      "2022-11-09 01:39:14,642 INFO     Training average loss at step 788500: 0.143656\n",
      "2022-11-09 01:39:17,732 INFO     Training average positive_sample_loss at step 788600: 0.148094\n",
      "2022-11-09 01:39:17,732 INFO     Training average negative_sample_loss at step 788600: 0.135685\n",
      "2022-11-09 01:39:17,732 INFO     Training average loss at step 788600: 0.141889\n",
      "2022-11-09 01:39:20,812 INFO     Training average positive_sample_loss at step 788700: 0.149441\n",
      "2022-11-09 01:39:20,813 INFO     Training average negative_sample_loss at step 788700: 0.135907\n",
      "2022-11-09 01:39:20,813 INFO     Training average loss at step 788700: 0.142674\n",
      "2022-11-09 01:39:23,906 INFO     Training average positive_sample_loss at step 788800: 0.145688\n",
      "2022-11-09 01:39:23,906 INFO     Training average negative_sample_loss at step 788800: 0.138394\n",
      "2022-11-09 01:39:23,906 INFO     Training average loss at step 788800: 0.142041\n",
      "2022-11-09 01:39:27,010 INFO     Training average positive_sample_loss at step 788900: 0.149134\n",
      "2022-11-09 01:39:27,010 INFO     Training average negative_sample_loss at step 788900: 0.140474\n",
      "2022-11-09 01:39:27,010 INFO     Training average loss at step 788900: 0.144804\n",
      "2022-11-09 01:39:30,114 INFO     Training average positive_sample_loss at step 789000: 0.148867\n",
      "2022-11-09 01:39:30,114 INFO     Training average negative_sample_loss at step 789000: 0.136843\n",
      "2022-11-09 01:39:30,114 INFO     Training average loss at step 789000: 0.142855\n",
      "2022-11-09 01:39:33,214 INFO     Training average positive_sample_loss at step 789100: 0.148481\n",
      "2022-11-09 01:39:33,214 INFO     Training average negative_sample_loss at step 789100: 0.138134\n",
      "2022-11-09 01:39:33,214 INFO     Training average loss at step 789100: 0.143307\n",
      "2022-11-09 01:39:36,328 INFO     Training average positive_sample_loss at step 789200: 0.151495\n",
      "2022-11-09 01:39:36,329 INFO     Training average negative_sample_loss at step 789200: 0.142768\n",
      "2022-11-09 01:39:36,329 INFO     Training average loss at step 789200: 0.147132\n",
      "2022-11-09 01:39:39,422 INFO     Training average positive_sample_loss at step 789300: 0.149849\n",
      "2022-11-09 01:39:39,422 INFO     Training average negative_sample_loss at step 789300: 0.138075\n",
      "2022-11-09 01:39:39,422 INFO     Training average loss at step 789300: 0.143962\n",
      "2022-11-09 01:39:42,535 INFO     Training average positive_sample_loss at step 789400: 0.144340\n",
      "2022-11-09 01:39:42,536 INFO     Training average negative_sample_loss at step 789400: 0.141396\n",
      "2022-11-09 01:39:42,536 INFO     Training average loss at step 789400: 0.142868\n",
      "2022-11-09 01:39:45,647 INFO     Training average positive_sample_loss at step 789500: 0.147252\n",
      "2022-11-09 01:39:45,647 INFO     Training average negative_sample_loss at step 789500: 0.137468\n",
      "2022-11-09 01:39:45,647 INFO     Training average loss at step 789500: 0.142360\n",
      "2022-11-09 01:39:48,752 INFO     Training average positive_sample_loss at step 789600: 0.146026\n",
      "2022-11-09 01:39:48,752 INFO     Training average negative_sample_loss at step 789600: 0.141200\n",
      "2022-11-09 01:39:48,752 INFO     Training average loss at step 789600: 0.143613\n",
      "2022-11-09 01:39:51,851 INFO     Training average positive_sample_loss at step 789700: 0.146505\n",
      "2022-11-09 01:39:51,851 INFO     Training average negative_sample_loss at step 789700: 0.137026\n",
      "2022-11-09 01:39:51,851 INFO     Training average loss at step 789700: 0.141765\n",
      "2022-11-09 01:39:54,964 INFO     Training average positive_sample_loss at step 789800: 0.149900\n",
      "2022-11-09 01:39:54,964 INFO     Training average negative_sample_loss at step 789800: 0.139378\n",
      "2022-11-09 01:39:54,964 INFO     Training average loss at step 789800: 0.144639\n",
      "2022-11-09 01:39:58,074 INFO     Training average positive_sample_loss at step 789900: 0.148832\n",
      "2022-11-09 01:39:58,074 INFO     Training average negative_sample_loss at step 789900: 0.138581\n",
      "2022-11-09 01:39:58,074 INFO     Training average loss at step 789900: 0.143706\n",
      "2022-11-09 01:40:04,073 INFO     Training average positive_sample_loss at step 790000: 0.141828\n",
      "2022-11-09 01:40:04,073 INFO     Training average negative_sample_loss at step 790000: 0.138848\n",
      "2022-11-09 01:40:04,073 INFO     Training average loss at step 790000: 0.140338\n",
      "2022-11-09 01:40:07,180 INFO     Training average positive_sample_loss at step 790100: 0.147519\n",
      "2022-11-09 01:40:07,180 INFO     Training average negative_sample_loss at step 790100: 0.136901\n",
      "2022-11-09 01:40:07,180 INFO     Training average loss at step 790100: 0.142210\n",
      "2022-11-09 01:40:10,303 INFO     Training average positive_sample_loss at step 790200: 0.147822\n",
      "2022-11-09 01:40:10,303 INFO     Training average negative_sample_loss at step 790200: 0.138294\n",
      "2022-11-09 01:40:10,303 INFO     Training average loss at step 790200: 0.143058\n",
      "2022-11-09 01:40:13,409 INFO     Training average positive_sample_loss at step 790300: 0.151575\n",
      "2022-11-09 01:40:13,409 INFO     Training average negative_sample_loss at step 790300: 0.138150\n",
      "2022-11-09 01:40:13,409 INFO     Training average loss at step 790300: 0.144863\n",
      "2022-11-09 01:40:16,515 INFO     Training average positive_sample_loss at step 790400: 0.147366\n",
      "2022-11-09 01:40:16,515 INFO     Training average negative_sample_loss at step 790400: 0.141549\n",
      "2022-11-09 01:40:16,515 INFO     Training average loss at step 790400: 0.144457\n",
      "2022-11-09 01:40:19,623 INFO     Training average positive_sample_loss at step 790500: 0.149496\n",
      "2022-11-09 01:40:19,623 INFO     Training average negative_sample_loss at step 790500: 0.143324\n",
      "2022-11-09 01:40:19,623 INFO     Training average loss at step 790500: 0.146410\n",
      "2022-11-09 01:40:22,726 INFO     Training average positive_sample_loss at step 790600: 0.150216\n",
      "2022-11-09 01:40:22,726 INFO     Training average negative_sample_loss at step 790600: 0.144603\n",
      "2022-11-09 01:40:22,726 INFO     Training average loss at step 790600: 0.147410\n",
      "2022-11-09 01:40:25,825 INFO     Training average positive_sample_loss at step 790700: 0.153301\n",
      "2022-11-09 01:40:25,825 INFO     Training average negative_sample_loss at step 790700: 0.142336\n",
      "2022-11-09 01:40:25,825 INFO     Training average loss at step 790700: 0.147818\n",
      "2022-11-09 01:40:28,938 INFO     Training average positive_sample_loss at step 790800: 0.149041\n",
      "2022-11-09 01:40:28,939 INFO     Training average negative_sample_loss at step 790800: 0.138858\n",
      "2022-11-09 01:40:28,939 INFO     Training average loss at step 790800: 0.143949\n",
      "2022-11-09 01:40:32,035 INFO     Training average positive_sample_loss at step 790900: 0.144113\n",
      "2022-11-09 01:40:32,035 INFO     Training average negative_sample_loss at step 790900: 0.141490\n",
      "2022-11-09 01:40:32,035 INFO     Training average loss at step 790900: 0.142801\n",
      "2022-11-09 01:40:35,150 INFO     Training average positive_sample_loss at step 791000: 0.147432\n",
      "2022-11-09 01:40:35,150 INFO     Training average negative_sample_loss at step 791000: 0.138635\n",
      "2022-11-09 01:40:35,150 INFO     Training average loss at step 791000: 0.143034\n",
      "2022-11-09 01:40:38,269 INFO     Training average positive_sample_loss at step 791100: 0.148256\n",
      "2022-11-09 01:40:38,269 INFO     Training average negative_sample_loss at step 791100: 0.137746\n",
      "2022-11-09 01:40:38,269 INFO     Training average loss at step 791100: 0.143001\n",
      "2022-11-09 01:40:41,379 INFO     Training average positive_sample_loss at step 791200: 0.154249\n",
      "2022-11-09 01:40:41,379 INFO     Training average negative_sample_loss at step 791200: 0.136430\n",
      "2022-11-09 01:40:41,380 INFO     Training average loss at step 791200: 0.145339\n",
      "2022-11-09 01:40:44,486 INFO     Training average positive_sample_loss at step 791300: 0.152236\n",
      "2022-11-09 01:40:44,487 INFO     Training average negative_sample_loss at step 791300: 0.138589\n",
      "2022-11-09 01:40:44,487 INFO     Training average loss at step 791300: 0.145413\n",
      "2022-11-09 01:40:47,585 INFO     Training average positive_sample_loss at step 791400: 0.149494\n",
      "2022-11-09 01:40:47,585 INFO     Training average negative_sample_loss at step 791400: 0.139884\n",
      "2022-11-09 01:40:47,585 INFO     Training average loss at step 791400: 0.144689\n",
      "2022-11-09 01:40:50,694 INFO     Training average positive_sample_loss at step 791500: 0.148367\n",
      "2022-11-09 01:40:50,694 INFO     Training average negative_sample_loss at step 791500: 0.136226\n",
      "2022-11-09 01:40:50,694 INFO     Training average loss at step 791500: 0.142296\n",
      "2022-11-09 01:40:56,839 INFO     Training average positive_sample_loss at step 791600: 0.148227\n",
      "2022-11-09 01:40:56,839 INFO     Training average negative_sample_loss at step 791600: 0.138187\n",
      "2022-11-09 01:40:56,839 INFO     Training average loss at step 791600: 0.143207\n",
      "2022-11-09 01:40:59,951 INFO     Training average positive_sample_loss at step 791700: 0.143605\n",
      "2022-11-09 01:40:59,951 INFO     Training average negative_sample_loss at step 791700: 0.135049\n",
      "2022-11-09 01:40:59,951 INFO     Training average loss at step 791700: 0.139327\n",
      "2022-11-09 01:41:03,050 INFO     Training average positive_sample_loss at step 791800: 0.137967\n",
      "2022-11-09 01:41:03,050 INFO     Training average negative_sample_loss at step 791800: 0.137378\n",
      "2022-11-09 01:41:03,050 INFO     Training average loss at step 791800: 0.137673\n",
      "2022-11-09 01:41:06,166 INFO     Training average positive_sample_loss at step 791900: 0.137884\n",
      "2022-11-09 01:41:06,167 INFO     Training average negative_sample_loss at step 791900: 0.136752\n",
      "2022-11-09 01:41:06,167 INFO     Training average loss at step 791900: 0.137318\n",
      "2022-11-09 01:41:09,286 INFO     Training average positive_sample_loss at step 792000: 0.142330\n",
      "2022-11-09 01:41:09,286 INFO     Training average negative_sample_loss at step 792000: 0.139224\n",
      "2022-11-09 01:41:09,286 INFO     Training average loss at step 792000: 0.140777\n",
      "2022-11-09 01:41:12,406 INFO     Training average positive_sample_loss at step 792100: 0.139858\n",
      "2022-11-09 01:41:12,406 INFO     Training average negative_sample_loss at step 792100: 0.137937\n",
      "2022-11-09 01:41:12,406 INFO     Training average loss at step 792100: 0.138897\n",
      "2022-11-09 01:41:15,514 INFO     Training average positive_sample_loss at step 792200: 0.139349\n",
      "2022-11-09 01:41:15,514 INFO     Training average negative_sample_loss at step 792200: 0.143187\n",
      "2022-11-09 01:41:15,514 INFO     Training average loss at step 792200: 0.141268\n",
      "2022-11-09 01:41:18,630 INFO     Training average positive_sample_loss at step 792300: 0.137736\n",
      "2022-11-09 01:41:18,631 INFO     Training average negative_sample_loss at step 792300: 0.138227\n",
      "2022-11-09 01:41:18,631 INFO     Training average loss at step 792300: 0.137982\n",
      "2022-11-09 01:41:21,746 INFO     Training average positive_sample_loss at step 792400: 0.142885\n",
      "2022-11-09 01:41:21,747 INFO     Training average negative_sample_loss at step 792400: 0.133566\n",
      "2022-11-09 01:41:21,747 INFO     Training average loss at step 792400: 0.138226\n",
      "2022-11-09 01:41:24,868 INFO     Training average positive_sample_loss at step 792500: 0.142828\n",
      "2022-11-09 01:41:24,868 INFO     Training average negative_sample_loss at step 792500: 0.137081\n",
      "2022-11-09 01:41:24,868 INFO     Training average loss at step 792500: 0.139954\n",
      "2022-11-09 01:41:27,987 INFO     Training average positive_sample_loss at step 792600: 0.143176\n",
      "2022-11-09 01:41:27,987 INFO     Training average negative_sample_loss at step 792600: 0.140862\n",
      "2022-11-09 01:41:27,987 INFO     Training average loss at step 792600: 0.142019\n",
      "2022-11-09 01:41:31,083 INFO     Training average positive_sample_loss at step 792700: 0.139858\n",
      "2022-11-09 01:41:31,083 INFO     Training average negative_sample_loss at step 792700: 0.142818\n",
      "2022-11-09 01:41:31,083 INFO     Training average loss at step 792700: 0.141338\n",
      "2022-11-09 01:41:34,197 INFO     Training average positive_sample_loss at step 792800: 0.136386\n",
      "2022-11-09 01:41:34,198 INFO     Training average negative_sample_loss at step 792800: 0.137478\n",
      "2022-11-09 01:41:34,198 INFO     Training average loss at step 792800: 0.136932\n",
      "2022-11-09 01:41:37,328 INFO     Training average positive_sample_loss at step 792900: 0.143681\n",
      "2022-11-09 01:41:37,328 INFO     Training average negative_sample_loss at step 792900: 0.139605\n",
      "2022-11-09 01:41:37,328 INFO     Training average loss at step 792900: 0.141643\n",
      "2022-11-09 01:41:40,463 INFO     Training average positive_sample_loss at step 793000: 0.142887\n",
      "2022-11-09 01:41:40,463 INFO     Training average negative_sample_loss at step 793000: 0.137269\n",
      "2022-11-09 01:41:40,463 INFO     Training average loss at step 793000: 0.140078\n",
      "2022-11-09 01:41:43,584 INFO     Training average positive_sample_loss at step 793100: 0.139988\n",
      "2022-11-09 01:41:43,584 INFO     Training average negative_sample_loss at step 793100: 0.136010\n",
      "2022-11-09 01:41:43,584 INFO     Training average loss at step 793100: 0.137999\n",
      "2022-11-09 01:41:46,702 INFO     Training average positive_sample_loss at step 793200: 0.142996\n",
      "2022-11-09 01:41:46,702 INFO     Training average negative_sample_loss at step 793200: 0.143039\n",
      "2022-11-09 01:41:46,703 INFO     Training average loss at step 793200: 0.143018\n",
      "2022-11-09 01:41:49,798 INFO     Training average positive_sample_loss at step 793300: 0.147355\n",
      "2022-11-09 01:41:49,798 INFO     Training average negative_sample_loss at step 793300: 0.139396\n",
      "2022-11-09 01:41:49,798 INFO     Training average loss at step 793300: 0.143376\n",
      "2022-11-09 01:41:52,900 INFO     Training average positive_sample_loss at step 793400: 0.141123\n",
      "2022-11-09 01:41:52,900 INFO     Training average negative_sample_loss at step 793400: 0.140573\n",
      "2022-11-09 01:41:52,900 INFO     Training average loss at step 793400: 0.140848\n",
      "2022-11-09 01:41:56,007 INFO     Training average positive_sample_loss at step 793500: 0.144737\n",
      "2022-11-09 01:41:56,007 INFO     Training average negative_sample_loss at step 793500: 0.140091\n",
      "2022-11-09 01:41:56,007 INFO     Training average loss at step 793500: 0.142414\n",
      "2022-11-09 01:41:59,120 INFO     Training average positive_sample_loss at step 793600: 0.141919\n",
      "2022-11-09 01:41:59,120 INFO     Training average negative_sample_loss at step 793600: 0.142690\n",
      "2022-11-09 01:41:59,120 INFO     Training average loss at step 793600: 0.142304\n",
      "2022-11-09 01:42:02,245 INFO     Training average positive_sample_loss at step 793700: 0.140994\n",
      "2022-11-09 01:42:02,245 INFO     Training average negative_sample_loss at step 793700: 0.137526\n",
      "2022-11-09 01:42:02,245 INFO     Training average loss at step 793700: 0.139260\n",
      "2022-11-09 01:42:05,362 INFO     Training average positive_sample_loss at step 793800: 0.144781\n",
      "2022-11-09 01:42:05,362 INFO     Training average negative_sample_loss at step 793800: 0.136809\n",
      "2022-11-09 01:42:05,362 INFO     Training average loss at step 793800: 0.140795\n",
      "2022-11-09 01:42:08,478 INFO     Training average positive_sample_loss at step 793900: 0.140372\n",
      "2022-11-09 01:42:08,478 INFO     Training average negative_sample_loss at step 793900: 0.140126\n",
      "2022-11-09 01:42:08,478 INFO     Training average loss at step 793900: 0.140249\n",
      "2022-11-09 01:42:11,593 INFO     Training average positive_sample_loss at step 794000: 0.145221\n",
      "2022-11-09 01:42:11,593 INFO     Training average negative_sample_loss at step 794000: 0.141304\n",
      "2022-11-09 01:42:11,593 INFO     Training average loss at step 794000: 0.143262\n",
      "2022-11-09 01:42:14,710 INFO     Training average positive_sample_loss at step 794100: 0.147098\n",
      "2022-11-09 01:42:14,710 INFO     Training average negative_sample_loss at step 794100: 0.137519\n",
      "2022-11-09 01:42:14,710 INFO     Training average loss at step 794100: 0.142309\n",
      "2022-11-09 01:42:17,820 INFO     Training average positive_sample_loss at step 794200: 0.143502\n",
      "2022-11-09 01:42:17,820 INFO     Training average negative_sample_loss at step 794200: 0.138289\n",
      "2022-11-09 01:42:17,820 INFO     Training average loss at step 794200: 0.140896\n",
      "2022-11-09 01:42:20,914 INFO     Training average positive_sample_loss at step 794300: 0.140144\n",
      "2022-11-09 01:42:20,914 INFO     Training average negative_sample_loss at step 794300: 0.134176\n",
      "2022-11-09 01:42:20,914 INFO     Training average loss at step 794300: 0.137160\n",
      "2022-11-09 01:42:24,019 INFO     Training average positive_sample_loss at step 794400: 0.142845\n",
      "2022-11-09 01:42:24,019 INFO     Training average negative_sample_loss at step 794400: 0.140400\n",
      "2022-11-09 01:42:24,019 INFO     Training average loss at step 794400: 0.141622\n",
      "2022-11-09 01:42:27,118 INFO     Training average positive_sample_loss at step 794500: 0.141892\n",
      "2022-11-09 01:42:27,118 INFO     Training average negative_sample_loss at step 794500: 0.140715\n",
      "2022-11-09 01:42:27,118 INFO     Training average loss at step 794500: 0.141304\n",
      "2022-11-09 01:42:30,223 INFO     Training average positive_sample_loss at step 794600: 0.141054\n",
      "2022-11-09 01:42:30,224 INFO     Training average negative_sample_loss at step 794600: 0.141947\n",
      "2022-11-09 01:42:30,224 INFO     Training average loss at step 794600: 0.141500\n",
      "2022-11-09 01:42:33,341 INFO     Training average positive_sample_loss at step 794700: 0.143116\n",
      "2022-11-09 01:42:33,341 INFO     Training average negative_sample_loss at step 794700: 0.137515\n",
      "2022-11-09 01:42:33,341 INFO     Training average loss at step 794700: 0.140316\n",
      "2022-11-09 01:42:36,444 INFO     Training average positive_sample_loss at step 794800: 0.143022\n",
      "2022-11-09 01:42:36,444 INFO     Training average negative_sample_loss at step 794800: 0.136076\n",
      "2022-11-09 01:42:36,444 INFO     Training average loss at step 794800: 0.139549\n",
      "2022-11-09 01:42:39,558 INFO     Training average positive_sample_loss at step 794900: 0.139533\n",
      "2022-11-09 01:42:39,558 INFO     Training average negative_sample_loss at step 794900: 0.138955\n",
      "2022-11-09 01:42:39,558 INFO     Training average loss at step 794900: 0.139244\n",
      "2022-11-09 01:42:42,678 INFO     Training average positive_sample_loss at step 795000: 0.142124\n",
      "2022-11-09 01:42:42,678 INFO     Training average negative_sample_loss at step 795000: 0.137105\n",
      "2022-11-09 01:42:42,678 INFO     Training average loss at step 795000: 0.139614\n",
      "2022-11-09 01:42:45,789 INFO     Training average positive_sample_loss at step 795100: 0.139347\n",
      "2022-11-09 01:42:45,790 INFO     Training average negative_sample_loss at step 795100: 0.139008\n",
      "2022-11-09 01:42:45,790 INFO     Training average loss at step 795100: 0.139177\n",
      "2022-11-09 01:42:48,894 INFO     Training average positive_sample_loss at step 795200: 0.143983\n",
      "2022-11-09 01:42:48,895 INFO     Training average negative_sample_loss at step 795200: 0.138501\n",
      "2022-11-09 01:42:48,895 INFO     Training average loss at step 795200: 0.141242\n",
      "2022-11-09 01:42:52,023 INFO     Training average positive_sample_loss at step 795300: 0.143900\n",
      "2022-11-09 01:42:52,023 INFO     Training average negative_sample_loss at step 795300: 0.140339\n",
      "2022-11-09 01:42:52,023 INFO     Training average loss at step 795300: 0.142119\n",
      "2022-11-09 01:42:55,147 INFO     Training average positive_sample_loss at step 795400: 0.141121\n",
      "2022-11-09 01:42:55,147 INFO     Training average negative_sample_loss at step 795400: 0.135959\n",
      "2022-11-09 01:42:55,147 INFO     Training average loss at step 795400: 0.138540\n",
      "2022-11-09 01:42:58,272 INFO     Training average positive_sample_loss at step 795500: 0.141802\n",
      "2022-11-09 01:42:58,272 INFO     Training average negative_sample_loss at step 795500: 0.136181\n",
      "2022-11-09 01:42:58,272 INFO     Training average loss at step 795500: 0.138992\n",
      "2022-11-09 01:43:01,381 INFO     Training average positive_sample_loss at step 795600: 0.139504\n",
      "2022-11-09 01:43:01,381 INFO     Training average negative_sample_loss at step 795600: 0.135644\n",
      "2022-11-09 01:43:01,381 INFO     Training average loss at step 795600: 0.137574\n",
      "2022-11-09 01:43:04,486 INFO     Training average positive_sample_loss at step 795700: 0.142197\n",
      "2022-11-09 01:43:04,486 INFO     Training average negative_sample_loss at step 795700: 0.136628\n",
      "2022-11-09 01:43:04,486 INFO     Training average loss at step 795700: 0.139412\n",
      "2022-11-09 01:43:07,607 INFO     Training average positive_sample_loss at step 795800: 0.141142\n",
      "2022-11-09 01:43:07,607 INFO     Training average negative_sample_loss at step 795800: 0.137997\n",
      "2022-11-09 01:43:07,607 INFO     Training average loss at step 795800: 0.139570\n",
      "2022-11-09 01:43:10,721 INFO     Training average positive_sample_loss at step 795900: 0.143520\n",
      "2022-11-09 01:43:10,721 INFO     Training average negative_sample_loss at step 795900: 0.138153\n",
      "2022-11-09 01:43:10,721 INFO     Training average loss at step 795900: 0.140836\n",
      "2022-11-09 01:43:13,836 INFO     Training average positive_sample_loss at step 796000: 0.144191\n",
      "2022-11-09 01:43:13,837 INFO     Training average negative_sample_loss at step 796000: 0.136184\n",
      "2022-11-09 01:43:13,837 INFO     Training average loss at step 796000: 0.140188\n",
      "2022-11-09 01:43:16,944 INFO     Training average positive_sample_loss at step 796100: 0.145216\n",
      "2022-11-09 01:43:16,944 INFO     Training average negative_sample_loss at step 796100: 0.138777\n",
      "2022-11-09 01:43:16,944 INFO     Training average loss at step 796100: 0.141997\n",
      "2022-11-09 01:43:20,045 INFO     Training average positive_sample_loss at step 796200: 0.142856\n",
      "2022-11-09 01:43:20,045 INFO     Training average negative_sample_loss at step 796200: 0.137530\n",
      "2022-11-09 01:43:20,045 INFO     Training average loss at step 796200: 0.140193\n",
      "2022-11-09 01:43:23,162 INFO     Training average positive_sample_loss at step 796300: 0.139520\n",
      "2022-11-09 01:43:23,162 INFO     Training average negative_sample_loss at step 796300: 0.137924\n",
      "2022-11-09 01:43:23,162 INFO     Training average loss at step 796300: 0.138722\n",
      "2022-11-09 01:43:26,275 INFO     Training average positive_sample_loss at step 796400: 0.143727\n",
      "2022-11-09 01:43:26,275 INFO     Training average negative_sample_loss at step 796400: 0.139394\n",
      "2022-11-09 01:43:26,275 INFO     Training average loss at step 796400: 0.141561\n",
      "2022-11-09 01:43:29,393 INFO     Training average positive_sample_loss at step 796500: 0.144900\n",
      "2022-11-09 01:43:29,393 INFO     Training average negative_sample_loss at step 796500: 0.138467\n",
      "2022-11-09 01:43:29,393 INFO     Training average loss at step 796500: 0.141683\n",
      "2022-11-09 01:43:32,502 INFO     Training average positive_sample_loss at step 796600: 0.142102\n",
      "2022-11-09 01:43:32,503 INFO     Training average negative_sample_loss at step 796600: 0.134924\n",
      "2022-11-09 01:43:32,503 INFO     Training average loss at step 796600: 0.138513\n",
      "2022-11-09 01:43:35,598 INFO     Training average positive_sample_loss at step 796700: 0.142806\n",
      "2022-11-09 01:43:35,598 INFO     Training average negative_sample_loss at step 796700: 0.138810\n",
      "2022-11-09 01:43:35,598 INFO     Training average loss at step 796700: 0.140808\n",
      "2022-11-09 01:43:38,708 INFO     Training average positive_sample_loss at step 796800: 0.139884\n",
      "2022-11-09 01:43:38,708 INFO     Training average negative_sample_loss at step 796800: 0.138542\n",
      "2022-11-09 01:43:38,708 INFO     Training average loss at step 796800: 0.139213\n",
      "2022-11-09 01:43:41,799 INFO     Training average positive_sample_loss at step 796900: 0.138553\n",
      "2022-11-09 01:43:41,799 INFO     Training average negative_sample_loss at step 796900: 0.140919\n",
      "2022-11-09 01:43:41,799 INFO     Training average loss at step 796900: 0.139736\n",
      "2022-11-09 01:43:44,911 INFO     Training average positive_sample_loss at step 797000: 0.140771\n",
      "2022-11-09 01:43:44,911 INFO     Training average negative_sample_loss at step 797000: 0.140726\n",
      "2022-11-09 01:43:44,911 INFO     Training average loss at step 797000: 0.140748\n",
      "2022-11-09 01:43:48,026 INFO     Training average positive_sample_loss at step 797100: 0.139504\n",
      "2022-11-09 01:43:48,026 INFO     Training average negative_sample_loss at step 797100: 0.135417\n",
      "2022-11-09 01:43:48,026 INFO     Training average loss at step 797100: 0.137461\n",
      "2022-11-09 01:43:51,127 INFO     Training average positive_sample_loss at step 797200: 0.140326\n",
      "2022-11-09 01:43:51,127 INFO     Training average negative_sample_loss at step 797200: 0.138863\n",
      "2022-11-09 01:43:51,127 INFO     Training average loss at step 797200: 0.139595\n",
      "2022-11-09 01:43:54,244 INFO     Training average positive_sample_loss at step 797300: 0.141640\n",
      "2022-11-09 01:43:54,245 INFO     Training average negative_sample_loss at step 797300: 0.139274\n",
      "2022-11-09 01:43:54,245 INFO     Training average loss at step 797300: 0.140457\n",
      "2022-11-09 01:43:57,349 INFO     Training average positive_sample_loss at step 797400: 0.144365\n",
      "2022-11-09 01:43:57,349 INFO     Training average negative_sample_loss at step 797400: 0.139211\n",
      "2022-11-09 01:43:57,349 INFO     Training average loss at step 797400: 0.141788\n",
      "2022-11-09 01:44:00,464 INFO     Training average positive_sample_loss at step 797500: 0.143212\n",
      "2022-11-09 01:44:00,464 INFO     Training average negative_sample_loss at step 797500: 0.138150\n",
      "2022-11-09 01:44:00,464 INFO     Training average loss at step 797500: 0.140681\n",
      "2022-11-09 01:44:03,564 INFO     Training average positive_sample_loss at step 797600: 0.144601\n",
      "2022-11-09 01:44:03,564 INFO     Training average negative_sample_loss at step 797600: 0.135091\n",
      "2022-11-09 01:44:03,564 INFO     Training average loss at step 797600: 0.139846\n",
      "2022-11-09 01:44:06,674 INFO     Training average positive_sample_loss at step 797700: 0.142535\n",
      "2022-11-09 01:44:06,674 INFO     Training average negative_sample_loss at step 797700: 0.135306\n",
      "2022-11-09 01:44:06,674 INFO     Training average loss at step 797700: 0.138921\n",
      "2022-11-09 01:44:09,782 INFO     Training average positive_sample_loss at step 797800: 0.142784\n",
      "2022-11-09 01:44:09,783 INFO     Training average negative_sample_loss at step 797800: 0.142792\n",
      "2022-11-09 01:44:09,783 INFO     Training average loss at step 797800: 0.142788\n",
      "2022-11-09 01:44:12,876 INFO     Training average positive_sample_loss at step 797900: 0.143899\n",
      "2022-11-09 01:44:12,876 INFO     Training average negative_sample_loss at step 797900: 0.139547\n",
      "2022-11-09 01:44:12,876 INFO     Training average loss at step 797900: 0.141723\n",
      "2022-11-09 01:44:15,990 INFO     Training average positive_sample_loss at step 798000: 0.139236\n",
      "2022-11-09 01:44:15,990 INFO     Training average negative_sample_loss at step 798000: 0.139036\n",
      "2022-11-09 01:44:15,990 INFO     Training average loss at step 798000: 0.139136\n",
      "2022-11-09 01:44:19,106 INFO     Training average positive_sample_loss at step 798100: 0.144703\n",
      "2022-11-09 01:44:19,106 INFO     Training average negative_sample_loss at step 798100: 0.139800\n",
      "2022-11-09 01:44:19,106 INFO     Training average loss at step 798100: 0.142252\n",
      "2022-11-09 01:44:22,226 INFO     Training average positive_sample_loss at step 798200: 0.144001\n",
      "2022-11-09 01:44:22,226 INFO     Training average negative_sample_loss at step 798200: 0.134116\n",
      "2022-11-09 01:44:22,226 INFO     Training average loss at step 798200: 0.139058\n",
      "2022-11-09 01:44:25,316 INFO     Training average positive_sample_loss at step 798300: 0.142829\n",
      "2022-11-09 01:44:25,316 INFO     Training average negative_sample_loss at step 798300: 0.138527\n",
      "2022-11-09 01:44:25,316 INFO     Training average loss at step 798300: 0.140678\n",
      "2022-11-09 01:44:28,420 INFO     Training average positive_sample_loss at step 798400: 0.142187\n",
      "2022-11-09 01:44:28,420 INFO     Training average negative_sample_loss at step 798400: 0.136292\n",
      "2022-11-09 01:44:28,420 INFO     Training average loss at step 798400: 0.139239\n",
      "2022-11-09 01:44:31,524 INFO     Training average positive_sample_loss at step 798500: 0.140153\n",
      "2022-11-09 01:44:31,524 INFO     Training average negative_sample_loss at step 798500: 0.141896\n",
      "2022-11-09 01:44:31,524 INFO     Training average loss at step 798500: 0.141025\n",
      "2022-11-09 01:44:34,635 INFO     Training average positive_sample_loss at step 798600: 0.141337\n",
      "2022-11-09 01:44:34,635 INFO     Training average negative_sample_loss at step 798600: 0.139223\n",
      "2022-11-09 01:44:34,636 INFO     Training average loss at step 798600: 0.140280\n",
      "2022-11-09 01:44:37,758 INFO     Training average positive_sample_loss at step 798700: 0.141841\n",
      "2022-11-09 01:44:37,759 INFO     Training average negative_sample_loss at step 798700: 0.139763\n",
      "2022-11-09 01:44:37,759 INFO     Training average loss at step 798700: 0.140802\n",
      "2022-11-09 01:44:40,876 INFO     Training average positive_sample_loss at step 798800: 0.143771\n",
      "2022-11-09 01:44:40,876 INFO     Training average negative_sample_loss at step 798800: 0.137746\n",
      "2022-11-09 01:44:40,876 INFO     Training average loss at step 798800: 0.140758\n",
      "2022-11-09 01:44:43,988 INFO     Training average positive_sample_loss at step 798900: 0.139993\n",
      "2022-11-09 01:44:43,988 INFO     Training average negative_sample_loss at step 798900: 0.143215\n",
      "2022-11-09 01:44:43,988 INFO     Training average loss at step 798900: 0.141604\n",
      "2022-11-09 01:44:47,099 INFO     Training average positive_sample_loss at step 799000: 0.139190\n",
      "2022-11-09 01:44:47,099 INFO     Training average negative_sample_loss at step 799000: 0.139937\n",
      "2022-11-09 01:44:47,099 INFO     Training average loss at step 799000: 0.139563\n",
      "2022-11-09 01:44:50,196 INFO     Training average positive_sample_loss at step 799100: 0.142978\n",
      "2022-11-09 01:44:50,197 INFO     Training average negative_sample_loss at step 799100: 0.136089\n",
      "2022-11-09 01:44:50,197 INFO     Training average loss at step 799100: 0.139533\n",
      "2022-11-09 01:44:53,300 INFO     Training average positive_sample_loss at step 799200: 0.144701\n",
      "2022-11-09 01:44:53,300 INFO     Training average negative_sample_loss at step 799200: 0.138679\n",
      "2022-11-09 01:44:53,300 INFO     Training average loss at step 799200: 0.141690\n",
      "2022-11-09 01:44:56,411 INFO     Training average positive_sample_loss at step 799300: 0.145693\n",
      "2022-11-09 01:44:56,411 INFO     Training average negative_sample_loss at step 799300: 0.139551\n",
      "2022-11-09 01:44:56,411 INFO     Training average loss at step 799300: 0.142622\n",
      "2022-11-09 01:44:59,521 INFO     Training average positive_sample_loss at step 799400: 0.144375\n",
      "2022-11-09 01:44:59,522 INFO     Training average negative_sample_loss at step 799400: 0.137139\n",
      "2022-11-09 01:44:59,522 INFO     Training average loss at step 799400: 0.140757\n",
      "2022-11-09 01:45:02,619 INFO     Training average positive_sample_loss at step 799500: 0.140157\n",
      "2022-11-09 01:45:02,619 INFO     Training average negative_sample_loss at step 799500: 0.135850\n",
      "2022-11-09 01:45:02,619 INFO     Training average loss at step 799500: 0.138003\n",
      "2022-11-09 01:45:05,718 INFO     Training average positive_sample_loss at step 799600: 0.145339\n",
      "2022-11-09 01:45:05,718 INFO     Training average negative_sample_loss at step 799600: 0.138893\n",
      "2022-11-09 01:45:05,718 INFO     Training average loss at step 799600: 0.142116\n",
      "2022-11-09 01:45:08,825 INFO     Training average positive_sample_loss at step 799700: 0.143239\n",
      "2022-11-09 01:45:08,825 INFO     Training average negative_sample_loss at step 799700: 0.135700\n",
      "2022-11-09 01:45:08,825 INFO     Training average loss at step 799700: 0.139470\n",
      "2022-11-09 01:45:11,935 INFO     Training average positive_sample_loss at step 799800: 0.143534\n",
      "2022-11-09 01:45:11,935 INFO     Training average negative_sample_loss at step 799800: 0.135614\n",
      "2022-11-09 01:45:11,935 INFO     Training average loss at step 799800: 0.139574\n",
      "2022-11-09 01:45:15,049 INFO     Training average positive_sample_loss at step 799900: 0.138848\n",
      "2022-11-09 01:45:15,049 INFO     Training average negative_sample_loss at step 799900: 0.139519\n",
      "2022-11-09 01:45:15,049 INFO     Training average loss at step 799900: 0.139184\n",
      "2022-11-09 01:45:21,076 INFO     Training average positive_sample_loss at step 800000: 0.139693\n",
      "2022-11-09 01:45:21,076 INFO     Training average negative_sample_loss at step 800000: 0.138250\n",
      "2022-11-09 01:45:21,076 INFO     Training average loss at step 800000: 0.138972\n",
      "2022-11-09 01:45:24,203 INFO     Training average positive_sample_loss at step 800100: 0.135865\n",
      "2022-11-09 01:45:24,203 INFO     Training average negative_sample_loss at step 800100: 0.139309\n",
      "2022-11-09 01:45:24,203 INFO     Training average loss at step 800100: 0.137587\n",
      "2022-11-09 01:45:27,316 INFO     Training average positive_sample_loss at step 800200: 0.139488\n",
      "2022-11-09 01:45:27,316 INFO     Training average negative_sample_loss at step 800200: 0.134962\n",
      "2022-11-09 01:45:27,316 INFO     Training average loss at step 800200: 0.137225\n",
      "2022-11-09 01:45:30,433 INFO     Training average positive_sample_loss at step 800300: 0.145273\n",
      "2022-11-09 01:45:30,433 INFO     Training average negative_sample_loss at step 800300: 0.138895\n",
      "2022-11-09 01:45:30,433 INFO     Training average loss at step 800300: 0.142084\n",
      "2022-11-09 01:45:33,545 INFO     Training average positive_sample_loss at step 800400: 0.141860\n",
      "2022-11-09 01:45:33,545 INFO     Training average negative_sample_loss at step 800400: 0.138754\n",
      "2022-11-09 01:45:33,545 INFO     Training average loss at step 800400: 0.140307\n",
      "2022-11-09 01:45:36,647 INFO     Training average positive_sample_loss at step 800500: 0.141540\n",
      "2022-11-09 01:45:36,647 INFO     Training average negative_sample_loss at step 800500: 0.134330\n",
      "2022-11-09 01:45:36,647 INFO     Training average loss at step 800500: 0.137935\n",
      "2022-11-09 01:45:39,760 INFO     Training average positive_sample_loss at step 800600: 0.141001\n",
      "2022-11-09 01:45:39,760 INFO     Training average negative_sample_loss at step 800600: 0.141199\n",
      "2022-11-09 01:45:39,760 INFO     Training average loss at step 800600: 0.141100\n",
      "2022-11-09 01:45:42,874 INFO     Training average positive_sample_loss at step 800700: 0.142169\n",
      "2022-11-09 01:45:42,874 INFO     Training average negative_sample_loss at step 800700: 0.138250\n",
      "2022-11-09 01:45:42,874 INFO     Training average loss at step 800700: 0.140209\n",
      "2022-11-09 01:45:46,002 INFO     Training average positive_sample_loss at step 800800: 0.139993\n",
      "2022-11-09 01:45:46,002 INFO     Training average negative_sample_loss at step 800800: 0.138621\n",
      "2022-11-09 01:45:46,002 INFO     Training average loss at step 800800: 0.139307\n",
      "2022-11-09 01:45:49,103 INFO     Training average positive_sample_loss at step 800900: 0.143658\n",
      "2022-11-09 01:45:49,103 INFO     Training average negative_sample_loss at step 800900: 0.142739\n",
      "2022-11-09 01:45:49,103 INFO     Training average loss at step 800900: 0.143199\n",
      "2022-11-09 01:45:52,230 INFO     Training average positive_sample_loss at step 801000: 0.138724\n",
      "2022-11-09 01:45:52,230 INFO     Training average negative_sample_loss at step 801000: 0.138534\n",
      "2022-11-09 01:45:52,231 INFO     Training average loss at step 801000: 0.138629\n",
      "2022-11-09 01:45:55,342 INFO     Training average positive_sample_loss at step 801100: 0.134389\n",
      "2022-11-09 01:45:55,342 INFO     Training average negative_sample_loss at step 801100: 0.134185\n",
      "2022-11-09 01:45:55,342 INFO     Training average loss at step 801100: 0.134287\n",
      "2022-11-09 01:45:58,458 INFO     Training average positive_sample_loss at step 801200: 0.142198\n",
      "2022-11-09 01:45:58,458 INFO     Training average negative_sample_loss at step 801200: 0.138205\n",
      "2022-11-09 01:45:58,458 INFO     Training average loss at step 801200: 0.140202\n",
      "2022-11-09 01:46:01,577 INFO     Training average positive_sample_loss at step 801300: 0.143876\n",
      "2022-11-09 01:46:01,577 INFO     Training average negative_sample_loss at step 801300: 0.135411\n",
      "2022-11-09 01:46:01,577 INFO     Training average loss at step 801300: 0.139643\n",
      "2022-11-09 01:46:04,681 INFO     Training average positive_sample_loss at step 801400: 0.143202\n",
      "2022-11-09 01:46:04,681 INFO     Training average negative_sample_loss at step 801400: 0.138600\n",
      "2022-11-09 01:46:04,681 INFO     Training average loss at step 801400: 0.140901\n",
      "2022-11-09 01:46:07,791 INFO     Training average positive_sample_loss at step 801500: 0.143079\n",
      "2022-11-09 01:46:07,791 INFO     Training average negative_sample_loss at step 801500: 0.140871\n",
      "2022-11-09 01:46:07,791 INFO     Training average loss at step 801500: 0.141975\n",
      "2022-11-09 01:46:10,896 INFO     Training average positive_sample_loss at step 801600: 0.142933\n",
      "2022-11-09 01:46:10,896 INFO     Training average negative_sample_loss at step 801600: 0.140047\n",
      "2022-11-09 01:46:10,896 INFO     Training average loss at step 801600: 0.141490\n",
      "2022-11-09 01:46:13,995 INFO     Training average positive_sample_loss at step 801700: 0.142101\n",
      "2022-11-09 01:46:13,995 INFO     Training average negative_sample_loss at step 801700: 0.137862\n",
      "2022-11-09 01:46:13,995 INFO     Training average loss at step 801700: 0.139981\n",
      "2022-11-09 01:46:18,734 INFO     Training average positive_sample_loss at step 801800: 0.140747\n",
      "2022-11-09 01:46:18,734 INFO     Training average negative_sample_loss at step 801800: 0.135493\n",
      "2022-11-09 01:46:18,734 INFO     Training average loss at step 801800: 0.138120\n",
      "2022-11-09 01:46:23,517 INFO     Training average positive_sample_loss at step 801900: 0.144816\n",
      "2022-11-09 01:46:23,517 INFO     Training average negative_sample_loss at step 801900: 0.138747\n",
      "2022-11-09 01:46:23,517 INFO     Training average loss at step 801900: 0.141781\n",
      "2022-11-09 01:46:26,622 INFO     Training average positive_sample_loss at step 802000: 0.142080\n",
      "2022-11-09 01:46:26,622 INFO     Training average negative_sample_loss at step 802000: 0.136547\n",
      "2022-11-09 01:46:26,622 INFO     Training average loss at step 802000: 0.139314\n",
      "2022-11-09 01:46:29,729 INFO     Training average positive_sample_loss at step 802100: 0.144205\n",
      "2022-11-09 01:46:29,729 INFO     Training average negative_sample_loss at step 802100: 0.132289\n",
      "2022-11-09 01:46:29,729 INFO     Training average loss at step 802100: 0.138247\n",
      "2022-11-09 01:46:32,838 INFO     Training average positive_sample_loss at step 802200: 0.144945\n",
      "2022-11-09 01:46:32,838 INFO     Training average negative_sample_loss at step 802200: 0.141726\n",
      "2022-11-09 01:46:32,838 INFO     Training average loss at step 802200: 0.143335\n",
      "2022-11-09 01:46:35,940 INFO     Training average positive_sample_loss at step 802300: 0.139055\n",
      "2022-11-09 01:46:35,940 INFO     Training average negative_sample_loss at step 802300: 0.135048\n",
      "2022-11-09 01:46:35,940 INFO     Training average loss at step 802300: 0.137052\n",
      "2022-11-09 01:46:39,038 INFO     Training average positive_sample_loss at step 802400: 0.143414\n",
      "2022-11-09 01:46:39,038 INFO     Training average negative_sample_loss at step 802400: 0.137666\n",
      "2022-11-09 01:46:39,038 INFO     Training average loss at step 802400: 0.140540\n",
      "2022-11-09 01:46:42,148 INFO     Training average positive_sample_loss at step 802500: 0.143404\n",
      "2022-11-09 01:46:42,149 INFO     Training average negative_sample_loss at step 802500: 0.134753\n",
      "2022-11-09 01:46:42,149 INFO     Training average loss at step 802500: 0.139079\n",
      "2022-11-09 01:46:45,255 INFO     Training average positive_sample_loss at step 802600: 0.141723\n",
      "2022-11-09 01:46:45,256 INFO     Training average negative_sample_loss at step 802600: 0.135764\n",
      "2022-11-09 01:46:45,256 INFO     Training average loss at step 802600: 0.138744\n",
      "2022-11-09 01:46:48,384 INFO     Training average positive_sample_loss at step 802700: 0.141507\n",
      "2022-11-09 01:46:48,384 INFO     Training average negative_sample_loss at step 802700: 0.131837\n",
      "2022-11-09 01:46:48,384 INFO     Training average loss at step 802700: 0.136672\n",
      "2022-11-09 01:46:51,496 INFO     Training average positive_sample_loss at step 802800: 0.140693\n",
      "2022-11-09 01:46:51,496 INFO     Training average negative_sample_loss at step 802800: 0.139849\n",
      "2022-11-09 01:46:51,496 INFO     Training average loss at step 802800: 0.140271\n",
      "2022-11-09 01:46:54,583 INFO     Training average positive_sample_loss at step 802900: 0.141432\n",
      "2022-11-09 01:46:54,583 INFO     Training average negative_sample_loss at step 802900: 0.137749\n",
      "2022-11-09 01:46:54,583 INFO     Training average loss at step 802900: 0.139590\n",
      "2022-11-09 01:46:57,697 INFO     Training average positive_sample_loss at step 803000: 0.143628\n",
      "2022-11-09 01:46:57,697 INFO     Training average negative_sample_loss at step 803000: 0.138072\n",
      "2022-11-09 01:46:57,697 INFO     Training average loss at step 803000: 0.140850\n",
      "2022-11-09 01:47:00,821 INFO     Training average positive_sample_loss at step 803100: 0.143419\n",
      "2022-11-09 01:47:00,821 INFO     Training average negative_sample_loss at step 803100: 0.139141\n",
      "2022-11-09 01:47:00,821 INFO     Training average loss at step 803100: 0.141280\n",
      "2022-11-09 01:47:03,923 INFO     Training average positive_sample_loss at step 803200: 0.136641\n",
      "2022-11-09 01:47:03,923 INFO     Training average negative_sample_loss at step 803200: 0.141573\n",
      "2022-11-09 01:47:03,923 INFO     Training average loss at step 803200: 0.139107\n",
      "2022-11-09 01:47:07,012 INFO     Training average positive_sample_loss at step 803300: 0.141720\n",
      "2022-11-09 01:47:07,012 INFO     Training average negative_sample_loss at step 803300: 0.129783\n",
      "2022-11-09 01:47:07,012 INFO     Training average loss at step 803300: 0.135752\n",
      "2022-11-09 01:47:10,116 INFO     Training average positive_sample_loss at step 803400: 0.143257\n",
      "2022-11-09 01:47:10,116 INFO     Training average negative_sample_loss at step 803400: 0.139049\n",
      "2022-11-09 01:47:10,116 INFO     Training average loss at step 803400: 0.141153\n",
      "2022-11-09 01:47:13,235 INFO     Training average positive_sample_loss at step 803500: 0.144340\n",
      "2022-11-09 01:47:13,235 INFO     Training average negative_sample_loss at step 803500: 0.137897\n",
      "2022-11-09 01:47:13,235 INFO     Training average loss at step 803500: 0.141119\n",
      "2022-11-09 01:47:16,354 INFO     Training average positive_sample_loss at step 803600: 0.144221\n",
      "2022-11-09 01:47:16,354 INFO     Training average negative_sample_loss at step 803600: 0.141282\n",
      "2022-11-09 01:47:16,354 INFO     Training average loss at step 803600: 0.142751\n",
      "2022-11-09 01:47:19,479 INFO     Training average positive_sample_loss at step 803700: 0.146701\n",
      "2022-11-09 01:47:19,479 INFO     Training average negative_sample_loss at step 803700: 0.139325\n",
      "2022-11-09 01:47:19,479 INFO     Training average loss at step 803700: 0.143013\n",
      "2022-11-09 01:47:22,609 INFO     Training average positive_sample_loss at step 803800: 0.139405\n",
      "2022-11-09 01:47:22,609 INFO     Training average negative_sample_loss at step 803800: 0.138050\n",
      "2022-11-09 01:47:22,609 INFO     Training average loss at step 803800: 0.138727\n",
      "2022-11-09 01:47:25,732 INFO     Training average positive_sample_loss at step 803900: 0.141723\n",
      "2022-11-09 01:47:25,732 INFO     Training average negative_sample_loss at step 803900: 0.138319\n",
      "2022-11-09 01:47:25,732 INFO     Training average loss at step 803900: 0.140021\n",
      "2022-11-09 01:47:28,857 INFO     Training average positive_sample_loss at step 804000: 0.139821\n",
      "2022-11-09 01:47:28,857 INFO     Training average negative_sample_loss at step 804000: 0.138568\n",
      "2022-11-09 01:47:28,857 INFO     Training average loss at step 804000: 0.139195\n",
      "2022-11-09 01:47:31,977 INFO     Training average positive_sample_loss at step 804100: 0.140918\n",
      "2022-11-09 01:47:31,977 INFO     Training average negative_sample_loss at step 804100: 0.138103\n",
      "2022-11-09 01:47:31,977 INFO     Training average loss at step 804100: 0.139511\n",
      "2022-11-09 01:47:35,085 INFO     Training average positive_sample_loss at step 804200: 0.147596\n",
      "2022-11-09 01:47:35,085 INFO     Training average negative_sample_loss at step 804200: 0.136791\n",
      "2022-11-09 01:47:35,085 INFO     Training average loss at step 804200: 0.142194\n",
      "2022-11-09 01:47:38,209 INFO     Training average positive_sample_loss at step 804300: 0.138667\n",
      "2022-11-09 01:47:38,209 INFO     Training average negative_sample_loss at step 804300: 0.136050\n",
      "2022-11-09 01:47:38,209 INFO     Training average loss at step 804300: 0.137359\n",
      "2022-11-09 01:47:41,324 INFO     Training average positive_sample_loss at step 804400: 0.142417\n",
      "2022-11-09 01:47:41,324 INFO     Training average negative_sample_loss at step 804400: 0.137277\n",
      "2022-11-09 01:47:41,324 INFO     Training average loss at step 804400: 0.139847\n",
      "2022-11-09 01:47:44,438 INFO     Training average positive_sample_loss at step 804500: 0.146483\n",
      "2022-11-09 01:47:44,438 INFO     Training average negative_sample_loss at step 804500: 0.138787\n",
      "2022-11-09 01:47:44,438 INFO     Training average loss at step 804500: 0.142635\n",
      "2022-11-09 01:47:47,534 INFO     Training average positive_sample_loss at step 804600: 0.142403\n",
      "2022-11-09 01:47:47,534 INFO     Training average negative_sample_loss at step 804600: 0.134154\n",
      "2022-11-09 01:47:47,534 INFO     Training average loss at step 804600: 0.138278\n",
      "2022-11-09 01:47:50,633 INFO     Training average positive_sample_loss at step 804700: 0.135883\n",
      "2022-11-09 01:47:50,633 INFO     Training average negative_sample_loss at step 804700: 0.138041\n",
      "2022-11-09 01:47:50,633 INFO     Training average loss at step 804700: 0.136962\n",
      "2022-11-09 01:47:53,747 INFO     Training average positive_sample_loss at step 804800: 0.143745\n",
      "2022-11-09 01:47:53,747 INFO     Training average negative_sample_loss at step 804800: 0.134943\n",
      "2022-11-09 01:47:53,747 INFO     Training average loss at step 804800: 0.139344\n",
      "2022-11-09 01:47:56,840 INFO     Training average positive_sample_loss at step 804900: 0.145860\n",
      "2022-11-09 01:47:56,840 INFO     Training average negative_sample_loss at step 804900: 0.137804\n",
      "2022-11-09 01:47:56,840 INFO     Training average loss at step 804900: 0.141832\n",
      "2022-11-09 01:47:59,955 INFO     Training average positive_sample_loss at step 805000: 0.138501\n",
      "2022-11-09 01:47:59,955 INFO     Training average negative_sample_loss at step 805000: 0.134033\n",
      "2022-11-09 01:47:59,955 INFO     Training average loss at step 805000: 0.136267\n",
      "2022-11-09 01:48:03,073 INFO     Training average positive_sample_loss at step 805100: 0.144346\n",
      "2022-11-09 01:48:03,074 INFO     Training average negative_sample_loss at step 805100: 0.134881\n",
      "2022-11-09 01:48:03,074 INFO     Training average loss at step 805100: 0.139613\n",
      "2022-11-09 01:48:06,191 INFO     Training average positive_sample_loss at step 805200: 0.145294\n",
      "2022-11-09 01:48:06,191 INFO     Training average negative_sample_loss at step 805200: 0.140563\n",
      "2022-11-09 01:48:06,191 INFO     Training average loss at step 805200: 0.142928\n",
      "2022-11-09 01:48:09,306 INFO     Training average positive_sample_loss at step 805300: 0.140914\n",
      "2022-11-09 01:48:09,306 INFO     Training average negative_sample_loss at step 805300: 0.138708\n",
      "2022-11-09 01:48:09,306 INFO     Training average loss at step 805300: 0.139811\n",
      "2022-11-09 01:48:12,421 INFO     Training average positive_sample_loss at step 805400: 0.138178\n",
      "2022-11-09 01:48:12,421 INFO     Training average negative_sample_loss at step 805400: 0.136220\n",
      "2022-11-09 01:48:12,421 INFO     Training average loss at step 805400: 0.137199\n",
      "2022-11-09 01:48:15,546 INFO     Training average positive_sample_loss at step 805500: 0.145959\n",
      "2022-11-09 01:48:15,546 INFO     Training average negative_sample_loss at step 805500: 0.137156\n",
      "2022-11-09 01:48:15,546 INFO     Training average loss at step 805500: 0.141557\n",
      "2022-11-09 01:48:18,674 INFO     Training average positive_sample_loss at step 805600: 0.142376\n",
      "2022-11-09 01:48:18,674 INFO     Training average negative_sample_loss at step 805600: 0.134050\n",
      "2022-11-09 01:48:18,674 INFO     Training average loss at step 805600: 0.138213\n",
      "2022-11-09 01:48:21,792 INFO     Training average positive_sample_loss at step 805700: 0.141059\n",
      "2022-11-09 01:48:21,792 INFO     Training average negative_sample_loss at step 805700: 0.140382\n",
      "2022-11-09 01:48:21,792 INFO     Training average loss at step 805700: 0.140721\n",
      "2022-11-09 01:48:24,915 INFO     Training average positive_sample_loss at step 805800: 0.138322\n",
      "2022-11-09 01:48:24,915 INFO     Training average negative_sample_loss at step 805800: 0.135709\n",
      "2022-11-09 01:48:24,915 INFO     Training average loss at step 805800: 0.137015\n",
      "2022-11-09 01:48:28,024 INFO     Training average positive_sample_loss at step 805900: 0.145350\n",
      "2022-11-09 01:48:28,024 INFO     Training average negative_sample_loss at step 805900: 0.138888\n",
      "2022-11-09 01:48:28,024 INFO     Training average loss at step 805900: 0.142119\n",
      "2022-11-09 01:48:31,123 INFO     Training average positive_sample_loss at step 806000: 0.139589\n",
      "2022-11-09 01:48:31,123 INFO     Training average negative_sample_loss at step 806000: 0.141864\n",
      "2022-11-09 01:48:31,123 INFO     Training average loss at step 806000: 0.140726\n",
      "2022-11-09 01:48:34,239 INFO     Training average positive_sample_loss at step 806100: 0.137331\n",
      "2022-11-09 01:48:34,239 INFO     Training average negative_sample_loss at step 806100: 0.138381\n",
      "2022-11-09 01:48:34,239 INFO     Training average loss at step 806100: 0.137856\n",
      "2022-11-09 01:48:37,357 INFO     Training average positive_sample_loss at step 806200: 0.142697\n",
      "2022-11-09 01:48:37,357 INFO     Training average negative_sample_loss at step 806200: 0.139812\n",
      "2022-11-09 01:48:37,357 INFO     Training average loss at step 806200: 0.141255\n",
      "2022-11-09 01:48:41,397 INFO     Training average positive_sample_loss at step 806300: 0.141052\n",
      "2022-11-09 01:48:41,397 INFO     Training average negative_sample_loss at step 806300: 0.139340\n",
      "2022-11-09 01:48:41,397 INFO     Training average loss at step 806300: 0.140196\n",
      "2022-11-09 01:48:44,516 INFO     Training average positive_sample_loss at step 806400: 0.141516\n",
      "2022-11-09 01:48:44,516 INFO     Training average negative_sample_loss at step 806400: 0.137726\n",
      "2022-11-09 01:48:44,516 INFO     Training average loss at step 806400: 0.139621\n",
      "2022-11-09 01:48:48,786 INFO     Training average positive_sample_loss at step 806500: 0.148245\n",
      "2022-11-09 01:48:48,787 INFO     Training average negative_sample_loss at step 806500: 0.138557\n",
      "2022-11-09 01:48:48,787 INFO     Training average loss at step 806500: 0.143401\n",
      "2022-11-09 01:48:53,409 INFO     Training average positive_sample_loss at step 806600: 0.143163\n",
      "2022-11-09 01:48:53,409 INFO     Training average negative_sample_loss at step 806600: 0.141280\n",
      "2022-11-09 01:48:53,409 INFO     Training average loss at step 806600: 0.142221\n",
      "2022-11-09 01:48:56,509 INFO     Training average positive_sample_loss at step 806700: 0.139598\n",
      "2022-11-09 01:48:56,509 INFO     Training average negative_sample_loss at step 806700: 0.138836\n",
      "2022-11-09 01:48:56,509 INFO     Training average loss at step 806700: 0.139217\n",
      "2022-11-09 01:48:59,608 INFO     Training average positive_sample_loss at step 806800: 0.146547\n",
      "2022-11-09 01:48:59,608 INFO     Training average negative_sample_loss at step 806800: 0.138512\n",
      "2022-11-09 01:48:59,608 INFO     Training average loss at step 806800: 0.142530\n",
      "2022-11-09 01:49:02,708 INFO     Training average positive_sample_loss at step 806900: 0.142569\n",
      "2022-11-09 01:49:02,708 INFO     Training average negative_sample_loss at step 806900: 0.132822\n",
      "2022-11-09 01:49:02,708 INFO     Training average loss at step 806900: 0.137695\n",
      "2022-11-09 01:49:05,803 INFO     Training average positive_sample_loss at step 807000: 0.146396\n",
      "2022-11-09 01:49:05,803 INFO     Training average negative_sample_loss at step 807000: 0.136918\n",
      "2022-11-09 01:49:05,803 INFO     Training average loss at step 807000: 0.141657\n",
      "2022-11-09 01:49:08,899 INFO     Training average positive_sample_loss at step 807100: 0.142723\n",
      "2022-11-09 01:49:08,899 INFO     Training average negative_sample_loss at step 807100: 0.139365\n",
      "2022-11-09 01:49:08,899 INFO     Training average loss at step 807100: 0.141044\n",
      "2022-11-09 01:49:12,003 INFO     Training average positive_sample_loss at step 807200: 0.140363\n",
      "2022-11-09 01:49:12,003 INFO     Training average negative_sample_loss at step 807200: 0.139034\n",
      "2022-11-09 01:49:12,003 INFO     Training average loss at step 807200: 0.139698\n",
      "2022-11-09 01:49:15,101 INFO     Training average positive_sample_loss at step 807300: 0.141762\n",
      "2022-11-09 01:49:15,102 INFO     Training average negative_sample_loss at step 807300: 0.135460\n",
      "2022-11-09 01:49:15,102 INFO     Training average loss at step 807300: 0.138611\n",
      "2022-11-09 01:49:18,196 INFO     Training average positive_sample_loss at step 807400: 0.141215\n",
      "2022-11-09 01:49:18,197 INFO     Training average negative_sample_loss at step 807400: 0.137186\n",
      "2022-11-09 01:49:18,197 INFO     Training average loss at step 807400: 0.139200\n",
      "2022-11-09 01:49:21,302 INFO     Training average positive_sample_loss at step 807500: 0.141580\n",
      "2022-11-09 01:49:21,302 INFO     Training average negative_sample_loss at step 807500: 0.145556\n",
      "2022-11-09 01:49:21,302 INFO     Training average loss at step 807500: 0.143568\n",
      "2022-11-09 01:49:24,401 INFO     Training average positive_sample_loss at step 807600: 0.146468\n",
      "2022-11-09 01:49:24,401 INFO     Training average negative_sample_loss at step 807600: 0.137488\n",
      "2022-11-09 01:49:24,401 INFO     Training average loss at step 807600: 0.141978\n",
      "2022-11-09 01:49:27,497 INFO     Training average positive_sample_loss at step 807700: 0.139609\n",
      "2022-11-09 01:49:27,497 INFO     Training average negative_sample_loss at step 807700: 0.138335\n",
      "2022-11-09 01:49:27,497 INFO     Training average loss at step 807700: 0.138972\n",
      "2022-11-09 01:49:30,601 INFO     Training average positive_sample_loss at step 807800: 0.142434\n",
      "2022-11-09 01:49:30,602 INFO     Training average negative_sample_loss at step 807800: 0.139169\n",
      "2022-11-09 01:49:30,602 INFO     Training average loss at step 807800: 0.140801\n",
      "2022-11-09 01:49:33,704 INFO     Training average positive_sample_loss at step 807900: 0.141792\n",
      "2022-11-09 01:49:33,705 INFO     Training average negative_sample_loss at step 807900: 0.141136\n",
      "2022-11-09 01:49:33,705 INFO     Training average loss at step 807900: 0.141464\n",
      "2022-11-09 01:49:36,799 INFO     Training average positive_sample_loss at step 808000: 0.147599\n",
      "2022-11-09 01:49:36,799 INFO     Training average negative_sample_loss at step 808000: 0.136023\n",
      "2022-11-09 01:49:36,800 INFO     Training average loss at step 808000: 0.141811\n",
      "2022-11-09 01:49:39,896 INFO     Training average positive_sample_loss at step 808100: 0.144260\n",
      "2022-11-09 01:49:39,896 INFO     Training average negative_sample_loss at step 808100: 0.141155\n",
      "2022-11-09 01:49:39,896 INFO     Training average loss at step 808100: 0.142707\n",
      "2022-11-09 01:49:42,991 INFO     Training average positive_sample_loss at step 808200: 0.144503\n",
      "2022-11-09 01:49:42,991 INFO     Training average negative_sample_loss at step 808200: 0.133509\n",
      "2022-11-09 01:49:42,991 INFO     Training average loss at step 808200: 0.139006\n",
      "2022-11-09 01:49:46,077 INFO     Training average positive_sample_loss at step 808300: 0.145999\n",
      "2022-11-09 01:49:46,077 INFO     Training average negative_sample_loss at step 808300: 0.142567\n",
      "2022-11-09 01:49:46,077 INFO     Training average loss at step 808300: 0.144283\n",
      "2022-11-09 01:49:49,182 INFO     Training average positive_sample_loss at step 808400: 0.144155\n",
      "2022-11-09 01:49:49,182 INFO     Training average negative_sample_loss at step 808400: 0.136095\n",
      "2022-11-09 01:49:49,183 INFO     Training average loss at step 808400: 0.140125\n",
      "2022-11-09 01:49:52,295 INFO     Training average positive_sample_loss at step 808500: 0.142746\n",
      "2022-11-09 01:49:52,295 INFO     Training average negative_sample_loss at step 808500: 0.137376\n",
      "2022-11-09 01:49:52,295 INFO     Training average loss at step 808500: 0.140061\n",
      "2022-11-09 01:49:55,413 INFO     Training average positive_sample_loss at step 808600: 0.145270\n",
      "2022-11-09 01:49:55,413 INFO     Training average negative_sample_loss at step 808600: 0.135933\n",
      "2022-11-09 01:49:55,413 INFO     Training average loss at step 808600: 0.140602\n",
      "2022-11-09 01:49:58,522 INFO     Training average positive_sample_loss at step 808700: 0.141390\n",
      "2022-11-09 01:49:58,523 INFO     Training average negative_sample_loss at step 808700: 0.136792\n",
      "2022-11-09 01:49:58,523 INFO     Training average loss at step 808700: 0.139091\n",
      "2022-11-09 01:50:01,641 INFO     Training average positive_sample_loss at step 808800: 0.145637\n",
      "2022-11-09 01:50:01,641 INFO     Training average negative_sample_loss at step 808800: 0.137103\n",
      "2022-11-09 01:50:01,641 INFO     Training average loss at step 808800: 0.141370\n",
      "2022-11-09 01:50:04,757 INFO     Training average positive_sample_loss at step 808900: 0.141729\n",
      "2022-11-09 01:50:04,757 INFO     Training average negative_sample_loss at step 808900: 0.135847\n",
      "2022-11-09 01:50:04,757 INFO     Training average loss at step 808900: 0.138788\n",
      "2022-11-09 01:50:07,884 INFO     Training average positive_sample_loss at step 809000: 0.139544\n",
      "2022-11-09 01:50:07,884 INFO     Training average negative_sample_loss at step 809000: 0.133323\n",
      "2022-11-09 01:50:07,884 INFO     Training average loss at step 809000: 0.136433\n",
      "2022-11-09 01:50:11,005 INFO     Training average positive_sample_loss at step 809100: 0.144685\n",
      "2022-11-09 01:50:11,005 INFO     Training average negative_sample_loss at step 809100: 0.133160\n",
      "2022-11-09 01:50:11,005 INFO     Training average loss at step 809100: 0.138922\n",
      "2022-11-09 01:50:14,121 INFO     Training average positive_sample_loss at step 809200: 0.145885\n",
      "2022-11-09 01:50:14,121 INFO     Training average negative_sample_loss at step 809200: 0.137514\n",
      "2022-11-09 01:50:14,121 INFO     Training average loss at step 809200: 0.141699\n",
      "2022-11-09 01:50:17,245 INFO     Training average positive_sample_loss at step 809300: 0.142079\n",
      "2022-11-09 01:50:17,245 INFO     Training average negative_sample_loss at step 809300: 0.142683\n",
      "2022-11-09 01:50:17,245 INFO     Training average loss at step 809300: 0.142381\n",
      "2022-11-09 01:50:20,368 INFO     Training average positive_sample_loss at step 809400: 0.142278\n",
      "2022-11-09 01:50:20,368 INFO     Training average negative_sample_loss at step 809400: 0.134933\n",
      "2022-11-09 01:50:20,368 INFO     Training average loss at step 809400: 0.138605\n",
      "2022-11-09 01:50:23,492 INFO     Training average positive_sample_loss at step 809500: 0.145141\n",
      "2022-11-09 01:50:23,492 INFO     Training average negative_sample_loss at step 809500: 0.137925\n",
      "2022-11-09 01:50:23,492 INFO     Training average loss at step 809500: 0.141533\n",
      "2022-11-09 01:50:26,622 INFO     Training average positive_sample_loss at step 809600: 0.140423\n",
      "2022-11-09 01:50:26,622 INFO     Training average negative_sample_loss at step 809600: 0.137597\n",
      "2022-11-09 01:50:26,622 INFO     Training average loss at step 809600: 0.139010\n",
      "2022-11-09 01:50:29,739 INFO     Training average positive_sample_loss at step 809700: 0.141699\n",
      "2022-11-09 01:50:29,739 INFO     Training average negative_sample_loss at step 809700: 0.135272\n",
      "2022-11-09 01:50:29,739 INFO     Training average loss at step 809700: 0.138485\n",
      "2022-11-09 01:50:32,863 INFO     Training average positive_sample_loss at step 809800: 0.146091\n",
      "2022-11-09 01:50:32,863 INFO     Training average negative_sample_loss at step 809800: 0.135612\n",
      "2022-11-09 01:50:32,863 INFO     Training average loss at step 809800: 0.140851\n",
      "2022-11-09 01:50:35,998 INFO     Training average positive_sample_loss at step 809900: 0.146487\n",
      "2022-11-09 01:50:35,998 INFO     Training average negative_sample_loss at step 809900: 0.138022\n",
      "2022-11-09 01:50:35,998 INFO     Training average loss at step 809900: 0.142255\n",
      "2022-11-09 01:50:41,923 INFO     Training average positive_sample_loss at step 810000: 0.142474\n",
      "2022-11-09 01:50:41,923 INFO     Training average negative_sample_loss at step 810000: 0.137051\n",
      "2022-11-09 01:50:41,923 INFO     Training average loss at step 810000: 0.139762\n",
      "2022-11-09 01:50:45,120 INFO     Training average positive_sample_loss at step 810100: 0.141762\n",
      "2022-11-09 01:50:45,120 INFO     Training average negative_sample_loss at step 810100: 0.138708\n",
      "2022-11-09 01:50:45,120 INFO     Training average loss at step 810100: 0.140235\n",
      "2022-11-09 01:50:48,241 INFO     Training average positive_sample_loss at step 810200: 0.141429\n",
      "2022-11-09 01:50:48,242 INFO     Training average negative_sample_loss at step 810200: 0.137277\n",
      "2022-11-09 01:50:48,242 INFO     Training average loss at step 810200: 0.139353\n",
      "2022-11-09 01:50:51,367 INFO     Training average positive_sample_loss at step 810300: 0.141886\n",
      "2022-11-09 01:50:51,367 INFO     Training average negative_sample_loss at step 810300: 0.139535\n",
      "2022-11-09 01:50:51,367 INFO     Training average loss at step 810300: 0.140710\n",
      "2022-11-09 01:50:54,496 INFO     Training average positive_sample_loss at step 810400: 0.144408\n",
      "2022-11-09 01:50:54,496 INFO     Training average negative_sample_loss at step 810400: 0.140194\n",
      "2022-11-09 01:50:54,496 INFO     Training average loss at step 810400: 0.142301\n",
      "2022-11-09 01:50:57,621 INFO     Training average positive_sample_loss at step 810500: 0.144837\n",
      "2022-11-09 01:50:57,621 INFO     Training average negative_sample_loss at step 810500: 0.137970\n",
      "2022-11-09 01:50:57,621 INFO     Training average loss at step 810500: 0.141404\n",
      "2022-11-09 01:51:00,740 INFO     Training average positive_sample_loss at step 810600: 0.139433\n",
      "2022-11-09 01:51:00,740 INFO     Training average negative_sample_loss at step 810600: 0.138614\n",
      "2022-11-09 01:51:00,740 INFO     Training average loss at step 810600: 0.139023\n",
      "2022-11-09 01:51:03,841 INFO     Training average positive_sample_loss at step 810700: 0.141441\n",
      "2022-11-09 01:51:03,842 INFO     Training average negative_sample_loss at step 810700: 0.139216\n",
      "2022-11-09 01:51:03,842 INFO     Training average loss at step 810700: 0.140329\n",
      "2022-11-09 01:51:06,959 INFO     Training average positive_sample_loss at step 810800: 0.141376\n",
      "2022-11-09 01:51:06,959 INFO     Training average negative_sample_loss at step 810800: 0.135710\n",
      "2022-11-09 01:51:06,959 INFO     Training average loss at step 810800: 0.138543\n",
      "2022-11-09 01:51:10,989 INFO     Training average positive_sample_loss at step 810900: 0.144279\n",
      "2022-11-09 01:51:10,989 INFO     Training average negative_sample_loss at step 810900: 0.138837\n",
      "2022-11-09 01:51:10,989 INFO     Training average loss at step 810900: 0.141558\n",
      "2022-11-09 01:51:14,910 INFO     Training average positive_sample_loss at step 811000: 0.140142\n",
      "2022-11-09 01:51:14,910 INFO     Training average negative_sample_loss at step 811000: 0.137787\n",
      "2022-11-09 01:51:14,910 INFO     Training average loss at step 811000: 0.138964\n",
      "2022-11-09 01:51:18,007 INFO     Training average positive_sample_loss at step 811100: 0.141707\n",
      "2022-11-09 01:51:18,007 INFO     Training average negative_sample_loss at step 811100: 0.134542\n",
      "2022-11-09 01:51:18,007 INFO     Training average loss at step 811100: 0.138124\n",
      "2022-11-09 01:51:22,049 INFO     Training average positive_sample_loss at step 811200: 0.140208\n",
      "2022-11-09 01:51:22,049 INFO     Training average negative_sample_loss at step 811200: 0.134383\n",
      "2022-11-09 01:51:22,049 INFO     Training average loss at step 811200: 0.137295\n",
      "2022-11-09 01:51:26,691 INFO     Training average positive_sample_loss at step 811300: 0.142980\n",
      "2022-11-09 01:51:26,691 INFO     Training average negative_sample_loss at step 811300: 0.136564\n",
      "2022-11-09 01:51:26,691 INFO     Training average loss at step 811300: 0.139772\n",
      "2022-11-09 01:51:29,786 INFO     Training average positive_sample_loss at step 811400: 0.145596\n",
      "2022-11-09 01:51:29,786 INFO     Training average negative_sample_loss at step 811400: 0.137960\n",
      "2022-11-09 01:51:29,786 INFO     Training average loss at step 811400: 0.141778\n",
      "2022-11-09 01:51:32,888 INFO     Training average positive_sample_loss at step 811500: 0.144305\n",
      "2022-11-09 01:51:32,888 INFO     Training average negative_sample_loss at step 811500: 0.137920\n",
      "2022-11-09 01:51:32,888 INFO     Training average loss at step 811500: 0.141112\n",
      "2022-11-09 01:51:35,999 INFO     Training average positive_sample_loss at step 811600: 0.149595\n",
      "2022-11-09 01:51:35,999 INFO     Training average negative_sample_loss at step 811600: 0.135193\n",
      "2022-11-09 01:51:35,999 INFO     Training average loss at step 811600: 0.142394\n",
      "2022-11-09 01:51:39,111 INFO     Training average positive_sample_loss at step 811700: 0.140238\n",
      "2022-11-09 01:51:39,111 INFO     Training average negative_sample_loss at step 811700: 0.135124\n",
      "2022-11-09 01:51:39,111 INFO     Training average loss at step 811700: 0.137681\n",
      "2022-11-09 01:51:42,223 INFO     Training average positive_sample_loss at step 811800: 0.142803\n",
      "2022-11-09 01:51:42,223 INFO     Training average negative_sample_loss at step 811800: 0.139738\n",
      "2022-11-09 01:51:42,223 INFO     Training average loss at step 811800: 0.141271\n",
      "2022-11-09 01:51:45,330 INFO     Training average positive_sample_loss at step 811900: 0.140394\n",
      "2022-11-09 01:51:45,330 INFO     Training average negative_sample_loss at step 811900: 0.136226\n",
      "2022-11-09 01:51:45,330 INFO     Training average loss at step 811900: 0.138310\n",
      "2022-11-09 01:51:48,416 INFO     Training average positive_sample_loss at step 812000: 0.140769\n",
      "2022-11-09 01:51:48,416 INFO     Training average negative_sample_loss at step 812000: 0.141178\n",
      "2022-11-09 01:51:48,416 INFO     Training average loss at step 812000: 0.140973\n",
      "2022-11-09 01:51:51,506 INFO     Training average positive_sample_loss at step 812100: 0.142015\n",
      "2022-11-09 01:51:51,506 INFO     Training average negative_sample_loss at step 812100: 0.132358\n",
      "2022-11-09 01:51:51,506 INFO     Training average loss at step 812100: 0.137186\n",
      "2022-11-09 01:51:54,597 INFO     Training average positive_sample_loss at step 812200: 0.144685\n",
      "2022-11-09 01:51:54,597 INFO     Training average negative_sample_loss at step 812200: 0.138310\n",
      "2022-11-09 01:51:54,597 INFO     Training average loss at step 812200: 0.141497\n",
      "2022-11-09 01:51:57,687 INFO     Training average positive_sample_loss at step 812300: 0.142896\n",
      "2022-11-09 01:51:57,688 INFO     Training average negative_sample_loss at step 812300: 0.144117\n",
      "2022-11-09 01:51:57,688 INFO     Training average loss at step 812300: 0.143506\n",
      "2022-11-09 01:52:00,775 INFO     Training average positive_sample_loss at step 812400: 0.141816\n",
      "2022-11-09 01:52:00,775 INFO     Training average negative_sample_loss at step 812400: 0.139243\n",
      "2022-11-09 01:52:00,775 INFO     Training average loss at step 812400: 0.140529\n",
      "2022-11-09 01:52:03,853 INFO     Training average positive_sample_loss at step 812500: 0.141375\n",
      "2022-11-09 01:52:03,854 INFO     Training average negative_sample_loss at step 812500: 0.134842\n",
      "2022-11-09 01:52:03,854 INFO     Training average loss at step 812500: 0.138109\n",
      "2022-11-09 01:52:06,953 INFO     Training average positive_sample_loss at step 812600: 0.144132\n",
      "2022-11-09 01:52:06,953 INFO     Training average negative_sample_loss at step 812600: 0.137587\n",
      "2022-11-09 01:52:06,953 INFO     Training average loss at step 812600: 0.140860\n",
      "2022-11-09 01:52:10,044 INFO     Training average positive_sample_loss at step 812700: 0.136251\n",
      "2022-11-09 01:52:10,044 INFO     Training average negative_sample_loss at step 812700: 0.135481\n",
      "2022-11-09 01:52:10,044 INFO     Training average loss at step 812700: 0.135866\n",
      "2022-11-09 01:52:13,139 INFO     Training average positive_sample_loss at step 812800: 0.145347\n",
      "2022-11-09 01:52:13,139 INFO     Training average negative_sample_loss at step 812800: 0.136672\n",
      "2022-11-09 01:52:13,139 INFO     Training average loss at step 812800: 0.141010\n",
      "2022-11-09 01:52:16,245 INFO     Training average positive_sample_loss at step 812900: 0.142870\n",
      "2022-11-09 01:52:16,245 INFO     Training average negative_sample_loss at step 812900: 0.135660\n",
      "2022-11-09 01:52:16,245 INFO     Training average loss at step 812900: 0.139265\n",
      "2022-11-09 01:52:19,349 INFO     Training average positive_sample_loss at step 813000: 0.143696\n",
      "2022-11-09 01:52:19,349 INFO     Training average negative_sample_loss at step 813000: 0.138919\n",
      "2022-11-09 01:52:19,349 INFO     Training average loss at step 813000: 0.141307\n",
      "2022-11-09 01:52:22,450 INFO     Training average positive_sample_loss at step 813100: 0.140434\n",
      "2022-11-09 01:52:22,450 INFO     Training average negative_sample_loss at step 813100: 0.139767\n",
      "2022-11-09 01:52:22,450 INFO     Training average loss at step 813100: 0.140100\n",
      "2022-11-09 01:52:25,538 INFO     Training average positive_sample_loss at step 813200: 0.143809\n",
      "2022-11-09 01:52:25,538 INFO     Training average negative_sample_loss at step 813200: 0.137776\n",
      "2022-11-09 01:52:25,539 INFO     Training average loss at step 813200: 0.140792\n",
      "2022-11-09 01:52:28,646 INFO     Training average positive_sample_loss at step 813300: 0.144642\n",
      "2022-11-09 01:52:28,646 INFO     Training average negative_sample_loss at step 813300: 0.141551\n",
      "2022-11-09 01:52:28,646 INFO     Training average loss at step 813300: 0.143097\n",
      "2022-11-09 01:52:31,764 INFO     Training average positive_sample_loss at step 813400: 0.141824\n",
      "2022-11-09 01:52:31,764 INFO     Training average negative_sample_loss at step 813400: 0.137329\n",
      "2022-11-09 01:52:31,764 INFO     Training average loss at step 813400: 0.139576\n",
      "2022-11-09 01:52:34,864 INFO     Training average positive_sample_loss at step 813500: 0.144148\n",
      "2022-11-09 01:52:34,864 INFO     Training average negative_sample_loss at step 813500: 0.133786\n",
      "2022-11-09 01:52:34,864 INFO     Training average loss at step 813500: 0.138967\n",
      "2022-11-09 01:52:37,968 INFO     Training average positive_sample_loss at step 813600: 0.143829\n",
      "2022-11-09 01:52:37,968 INFO     Training average negative_sample_loss at step 813600: 0.138573\n",
      "2022-11-09 01:52:37,968 INFO     Training average loss at step 813600: 0.141201\n",
      "2022-11-09 01:52:41,074 INFO     Training average positive_sample_loss at step 813700: 0.144458\n",
      "2022-11-09 01:52:41,074 INFO     Training average negative_sample_loss at step 813700: 0.136733\n",
      "2022-11-09 01:52:41,074 INFO     Training average loss at step 813700: 0.140595\n",
      "2022-11-09 01:52:44,184 INFO     Training average positive_sample_loss at step 813800: 0.139823\n",
      "2022-11-09 01:52:44,184 INFO     Training average negative_sample_loss at step 813800: 0.136024\n",
      "2022-11-09 01:52:44,184 INFO     Training average loss at step 813800: 0.137924\n",
      "2022-11-09 01:52:47,300 INFO     Training average positive_sample_loss at step 813900: 0.141070\n",
      "2022-11-09 01:52:47,300 INFO     Training average negative_sample_loss at step 813900: 0.137406\n",
      "2022-11-09 01:52:47,300 INFO     Training average loss at step 813900: 0.139238\n",
      "2022-11-09 01:52:50,421 INFO     Training average positive_sample_loss at step 814000: 0.142078\n",
      "2022-11-09 01:52:50,421 INFO     Training average negative_sample_loss at step 814000: 0.136105\n",
      "2022-11-09 01:52:50,421 INFO     Training average loss at step 814000: 0.139092\n",
      "2022-11-09 01:52:53,524 INFO     Training average positive_sample_loss at step 814100: 0.141233\n",
      "2022-11-09 01:52:53,524 INFO     Training average negative_sample_loss at step 814100: 0.139495\n",
      "2022-11-09 01:52:53,524 INFO     Training average loss at step 814100: 0.140364\n",
      "2022-11-09 01:52:56,608 INFO     Training average positive_sample_loss at step 814200: 0.146274\n",
      "2022-11-09 01:52:56,608 INFO     Training average negative_sample_loss at step 814200: 0.139260\n",
      "2022-11-09 01:52:56,608 INFO     Training average loss at step 814200: 0.142767\n",
      "2022-11-09 01:52:59,691 INFO     Training average positive_sample_loss at step 814300: 0.143944\n",
      "2022-11-09 01:52:59,691 INFO     Training average negative_sample_loss at step 814300: 0.139611\n",
      "2022-11-09 01:52:59,691 INFO     Training average loss at step 814300: 0.141778\n",
      "2022-11-09 01:53:02,778 INFO     Training average positive_sample_loss at step 814400: 0.144309\n",
      "2022-11-09 01:53:02,778 INFO     Training average negative_sample_loss at step 814400: 0.139777\n",
      "2022-11-09 01:53:02,778 INFO     Training average loss at step 814400: 0.142043\n",
      "2022-11-09 01:53:05,871 INFO     Training average positive_sample_loss at step 814500: 0.144178\n",
      "2022-11-09 01:53:05,871 INFO     Training average negative_sample_loss at step 814500: 0.131060\n",
      "2022-11-09 01:53:05,871 INFO     Training average loss at step 814500: 0.137619\n",
      "2022-11-09 01:53:08,965 INFO     Training average positive_sample_loss at step 814600: 0.144860\n",
      "2022-11-09 01:53:08,965 INFO     Training average negative_sample_loss at step 814600: 0.136073\n",
      "2022-11-09 01:53:08,965 INFO     Training average loss at step 814600: 0.140466\n",
      "2022-11-09 01:53:12,058 INFO     Training average positive_sample_loss at step 814700: 0.141678\n",
      "2022-11-09 01:53:12,058 INFO     Training average negative_sample_loss at step 814700: 0.137555\n",
      "2022-11-09 01:53:12,058 INFO     Training average loss at step 814700: 0.139617\n",
      "2022-11-09 01:53:15,141 INFO     Training average positive_sample_loss at step 814800: 0.145225\n",
      "2022-11-09 01:53:15,141 INFO     Training average negative_sample_loss at step 814800: 0.135106\n",
      "2022-11-09 01:53:15,141 INFO     Training average loss at step 814800: 0.140165\n",
      "2022-11-09 01:53:18,226 INFO     Training average positive_sample_loss at step 814900: 0.144078\n",
      "2022-11-09 01:53:18,226 INFO     Training average negative_sample_loss at step 814900: 0.139164\n",
      "2022-11-09 01:53:18,226 INFO     Training average loss at step 814900: 0.141621\n",
      "2022-11-09 01:53:21,320 INFO     Training average positive_sample_loss at step 815000: 0.141204\n",
      "2022-11-09 01:53:21,321 INFO     Training average negative_sample_loss at step 815000: 0.135600\n",
      "2022-11-09 01:53:21,321 INFO     Training average loss at step 815000: 0.138402\n",
      "2022-11-09 01:53:24,413 INFO     Training average positive_sample_loss at step 815100: 0.142604\n",
      "2022-11-09 01:53:24,413 INFO     Training average negative_sample_loss at step 815100: 0.138186\n",
      "2022-11-09 01:53:24,413 INFO     Training average loss at step 815100: 0.140395\n",
      "2022-11-09 01:53:27,503 INFO     Training average positive_sample_loss at step 815200: 0.145777\n",
      "2022-11-09 01:53:27,503 INFO     Training average negative_sample_loss at step 815200: 0.137632\n",
      "2022-11-09 01:53:27,503 INFO     Training average loss at step 815200: 0.141705\n",
      "2022-11-09 01:53:30,597 INFO     Training average positive_sample_loss at step 815300: 0.143011\n",
      "2022-11-09 01:53:30,597 INFO     Training average negative_sample_loss at step 815300: 0.141785\n",
      "2022-11-09 01:53:30,597 INFO     Training average loss at step 815300: 0.142398\n",
      "2022-11-09 01:53:33,708 INFO     Training average positive_sample_loss at step 815400: 0.141743\n",
      "2022-11-09 01:53:33,708 INFO     Training average negative_sample_loss at step 815400: 0.141571\n",
      "2022-11-09 01:53:33,708 INFO     Training average loss at step 815400: 0.141657\n",
      "2022-11-09 01:53:36,826 INFO     Training average positive_sample_loss at step 815500: 0.143045\n",
      "2022-11-09 01:53:36,826 INFO     Training average negative_sample_loss at step 815500: 0.137155\n",
      "2022-11-09 01:53:36,826 INFO     Training average loss at step 815500: 0.140100\n",
      "2022-11-09 01:53:40,907 INFO     Training average positive_sample_loss at step 815600: 0.146275\n",
      "2022-11-09 01:53:40,907 INFO     Training average negative_sample_loss at step 815600: 0.134926\n",
      "2022-11-09 01:53:40,907 INFO     Training average loss at step 815600: 0.140600\n",
      "2022-11-09 01:53:44,859 INFO     Training average positive_sample_loss at step 815700: 0.144088\n",
      "2022-11-09 01:53:44,860 INFO     Training average negative_sample_loss at step 815700: 0.135068\n",
      "2022-11-09 01:53:44,860 INFO     Training average loss at step 815700: 0.139578\n",
      "2022-11-09 01:53:48,921 INFO     Training average positive_sample_loss at step 815800: 0.143854\n",
      "2022-11-09 01:53:48,921 INFO     Training average negative_sample_loss at step 815800: 0.134399\n",
      "2022-11-09 01:53:48,921 INFO     Training average loss at step 815800: 0.139126\n",
      "2022-11-09 01:53:52,053 INFO     Training average positive_sample_loss at step 815900: 0.142103\n",
      "2022-11-09 01:53:52,053 INFO     Training average negative_sample_loss at step 815900: 0.133769\n",
      "2022-11-09 01:53:52,053 INFO     Training average loss at step 815900: 0.137936\n",
      "2022-11-09 01:53:56,729 INFO     Training average positive_sample_loss at step 816000: 0.144214\n",
      "2022-11-09 01:53:56,729 INFO     Training average negative_sample_loss at step 816000: 0.139348\n",
      "2022-11-09 01:53:56,729 INFO     Training average loss at step 816000: 0.141781\n",
      "2022-11-09 01:53:59,819 INFO     Training average positive_sample_loss at step 816100: 0.141865\n",
      "2022-11-09 01:53:59,819 INFO     Training average negative_sample_loss at step 816100: 0.133471\n",
      "2022-11-09 01:53:59,819 INFO     Training average loss at step 816100: 0.137668\n",
      "2022-11-09 01:54:02,922 INFO     Training average positive_sample_loss at step 816200: 0.146077\n",
      "2022-11-09 01:54:02,922 INFO     Training average negative_sample_loss at step 816200: 0.137487\n",
      "2022-11-09 01:54:02,922 INFO     Training average loss at step 816200: 0.141782\n",
      "2022-11-09 01:54:06,029 INFO     Training average positive_sample_loss at step 816300: 0.144016\n",
      "2022-11-09 01:54:06,029 INFO     Training average negative_sample_loss at step 816300: 0.135218\n",
      "2022-11-09 01:54:06,029 INFO     Training average loss at step 816300: 0.139617\n",
      "2022-11-09 01:54:09,140 INFO     Training average positive_sample_loss at step 816400: 0.148047\n",
      "2022-11-09 01:54:09,140 INFO     Training average negative_sample_loss at step 816400: 0.135489\n",
      "2022-11-09 01:54:09,140 INFO     Training average loss at step 816400: 0.141768\n",
      "2022-11-09 01:54:12,237 INFO     Training average positive_sample_loss at step 816500: 0.144220\n",
      "2022-11-09 01:54:12,237 INFO     Training average negative_sample_loss at step 816500: 0.138872\n",
      "2022-11-09 01:54:12,237 INFO     Training average loss at step 816500: 0.141546\n",
      "2022-11-09 01:54:15,326 INFO     Training average positive_sample_loss at step 816600: 0.141568\n",
      "2022-11-09 01:54:15,326 INFO     Training average negative_sample_loss at step 816600: 0.138282\n",
      "2022-11-09 01:54:15,327 INFO     Training average loss at step 816600: 0.139925\n",
      "2022-11-09 01:54:18,424 INFO     Training average positive_sample_loss at step 816700: 0.141455\n",
      "2022-11-09 01:54:18,424 INFO     Training average negative_sample_loss at step 816700: 0.140876\n",
      "2022-11-09 01:54:18,424 INFO     Training average loss at step 816700: 0.141165\n",
      "2022-11-09 01:54:21,520 INFO     Training average positive_sample_loss at step 816800: 0.139057\n",
      "2022-11-09 01:54:21,520 INFO     Training average negative_sample_loss at step 816800: 0.140274\n",
      "2022-11-09 01:54:21,520 INFO     Training average loss at step 816800: 0.139666\n",
      "2022-11-09 01:54:24,640 INFO     Training average positive_sample_loss at step 816900: 0.140813\n",
      "2022-11-09 01:54:24,640 INFO     Training average negative_sample_loss at step 816900: 0.134068\n",
      "2022-11-09 01:54:24,640 INFO     Training average loss at step 816900: 0.137440\n",
      "2022-11-09 01:54:27,741 INFO     Training average positive_sample_loss at step 817000: 0.138872\n",
      "2022-11-09 01:54:27,741 INFO     Training average negative_sample_loss at step 817000: 0.135377\n",
      "2022-11-09 01:54:27,741 INFO     Training average loss at step 817000: 0.137124\n",
      "2022-11-09 01:54:30,842 INFO     Training average positive_sample_loss at step 817100: 0.139972\n",
      "2022-11-09 01:54:30,842 INFO     Training average negative_sample_loss at step 817100: 0.134305\n",
      "2022-11-09 01:54:30,842 INFO     Training average loss at step 817100: 0.137138\n",
      "2022-11-09 01:54:33,937 INFO     Training average positive_sample_loss at step 817200: 0.140391\n",
      "2022-11-09 01:54:33,937 INFO     Training average negative_sample_loss at step 817200: 0.140556\n",
      "2022-11-09 01:54:33,937 INFO     Training average loss at step 817200: 0.140474\n",
      "2022-11-09 01:54:37,014 INFO     Training average positive_sample_loss at step 817300: 0.142331\n",
      "2022-11-09 01:54:37,014 INFO     Training average negative_sample_loss at step 817300: 0.140620\n",
      "2022-11-09 01:54:37,014 INFO     Training average loss at step 817300: 0.141475\n",
      "2022-11-09 01:54:40,107 INFO     Training average positive_sample_loss at step 817400: 0.147677\n",
      "2022-11-09 01:54:40,107 INFO     Training average negative_sample_loss at step 817400: 0.138355\n",
      "2022-11-09 01:54:40,107 INFO     Training average loss at step 817400: 0.143016\n",
      "2022-11-09 01:54:43,194 INFO     Training average positive_sample_loss at step 817500: 0.140834\n",
      "2022-11-09 01:54:43,194 INFO     Training average negative_sample_loss at step 817500: 0.138710\n",
      "2022-11-09 01:54:43,194 INFO     Training average loss at step 817500: 0.139772\n",
      "2022-11-09 01:54:46,285 INFO     Training average positive_sample_loss at step 817600: 0.142997\n",
      "2022-11-09 01:54:46,285 INFO     Training average negative_sample_loss at step 817600: 0.141245\n",
      "2022-11-09 01:54:46,285 INFO     Training average loss at step 817600: 0.142121\n",
      "2022-11-09 01:54:49,377 INFO     Training average positive_sample_loss at step 817700: 0.145556\n",
      "2022-11-09 01:54:49,377 INFO     Training average negative_sample_loss at step 817700: 0.140600\n",
      "2022-11-09 01:54:49,377 INFO     Training average loss at step 817700: 0.143078\n",
      "2022-11-09 01:54:52,469 INFO     Training average positive_sample_loss at step 817800: 0.142471\n",
      "2022-11-09 01:54:52,469 INFO     Training average negative_sample_loss at step 817800: 0.136771\n",
      "2022-11-09 01:54:52,469 INFO     Training average loss at step 817800: 0.139621\n",
      "2022-11-09 01:54:55,562 INFO     Training average positive_sample_loss at step 817900: 0.141224\n",
      "2022-11-09 01:54:55,562 INFO     Training average negative_sample_loss at step 817900: 0.139048\n",
      "2022-11-09 01:54:55,562 INFO     Training average loss at step 817900: 0.140136\n",
      "2022-11-09 01:54:58,643 INFO     Training average positive_sample_loss at step 818000: 0.137002\n",
      "2022-11-09 01:54:58,643 INFO     Training average negative_sample_loss at step 818000: 0.136987\n",
      "2022-11-09 01:54:58,643 INFO     Training average loss at step 818000: 0.136994\n",
      "2022-11-09 01:55:01,732 INFO     Training average positive_sample_loss at step 818100: 0.148430\n",
      "2022-11-09 01:55:01,732 INFO     Training average negative_sample_loss at step 818100: 0.134193\n",
      "2022-11-09 01:55:01,732 INFO     Training average loss at step 818100: 0.141311\n",
      "2022-11-09 01:55:04,821 INFO     Training average positive_sample_loss at step 818200: 0.141661\n",
      "2022-11-09 01:55:04,821 INFO     Training average negative_sample_loss at step 818200: 0.137834\n",
      "2022-11-09 01:55:04,821 INFO     Training average loss at step 818200: 0.139747\n",
      "2022-11-09 01:55:07,914 INFO     Training average positive_sample_loss at step 818300: 0.145549\n",
      "2022-11-09 01:55:07,914 INFO     Training average negative_sample_loss at step 818300: 0.139694\n",
      "2022-11-09 01:55:07,914 INFO     Training average loss at step 818300: 0.142621\n",
      "2022-11-09 01:55:11,017 INFO     Training average positive_sample_loss at step 818400: 0.145133\n",
      "2022-11-09 01:55:11,017 INFO     Training average negative_sample_loss at step 818400: 0.138322\n",
      "2022-11-09 01:55:11,017 INFO     Training average loss at step 818400: 0.141727\n",
      "2022-11-09 01:55:14,102 INFO     Training average positive_sample_loss at step 818500: 0.142901\n",
      "2022-11-09 01:55:14,102 INFO     Training average negative_sample_loss at step 818500: 0.137211\n",
      "2022-11-09 01:55:14,102 INFO     Training average loss at step 818500: 0.140056\n",
      "2022-11-09 01:55:17,193 INFO     Training average positive_sample_loss at step 818600: 0.140753\n",
      "2022-11-09 01:55:17,193 INFO     Training average negative_sample_loss at step 818600: 0.141595\n",
      "2022-11-09 01:55:17,193 INFO     Training average loss at step 818600: 0.141174\n",
      "2022-11-09 01:55:20,284 INFO     Training average positive_sample_loss at step 818700: 0.145749\n",
      "2022-11-09 01:55:20,285 INFO     Training average negative_sample_loss at step 818700: 0.140481\n",
      "2022-11-09 01:55:20,285 INFO     Training average loss at step 818700: 0.143115\n",
      "2022-11-09 01:55:23,378 INFO     Training average positive_sample_loss at step 818800: 0.141885\n",
      "2022-11-09 01:55:23,378 INFO     Training average negative_sample_loss at step 818800: 0.137351\n",
      "2022-11-09 01:55:23,378 INFO     Training average loss at step 818800: 0.139618\n",
      "2022-11-09 01:55:26,471 INFO     Training average positive_sample_loss at step 818900: 0.140871\n",
      "2022-11-09 01:55:26,471 INFO     Training average negative_sample_loss at step 818900: 0.138980\n",
      "2022-11-09 01:55:26,471 INFO     Training average loss at step 818900: 0.139925\n",
      "2022-11-09 01:55:29,560 INFO     Training average positive_sample_loss at step 819000: 0.143132\n",
      "2022-11-09 01:55:29,560 INFO     Training average negative_sample_loss at step 819000: 0.139221\n",
      "2022-11-09 01:55:29,560 INFO     Training average loss at step 819000: 0.141177\n",
      "2022-11-09 01:55:32,674 INFO     Training average positive_sample_loss at step 819100: 0.143810\n",
      "2022-11-09 01:55:32,674 INFO     Training average negative_sample_loss at step 819100: 0.138351\n",
      "2022-11-09 01:55:32,674 INFO     Training average loss at step 819100: 0.141081\n",
      "2022-11-09 01:55:35,764 INFO     Training average positive_sample_loss at step 819200: 0.142425\n",
      "2022-11-09 01:55:35,764 INFO     Training average negative_sample_loss at step 819200: 0.138910\n",
      "2022-11-09 01:55:35,764 INFO     Training average loss at step 819200: 0.140668\n",
      "2022-11-09 01:55:38,859 INFO     Training average positive_sample_loss at step 819300: 0.143446\n",
      "2022-11-09 01:55:38,859 INFO     Training average negative_sample_loss at step 819300: 0.137869\n",
      "2022-11-09 01:55:38,859 INFO     Training average loss at step 819300: 0.140658\n",
      "2022-11-09 01:55:41,947 INFO     Training average positive_sample_loss at step 819400: 0.142037\n",
      "2022-11-09 01:55:41,947 INFO     Training average negative_sample_loss at step 819400: 0.137132\n",
      "2022-11-09 01:55:41,947 INFO     Training average loss at step 819400: 0.139585\n",
      "2022-11-09 01:55:45,047 INFO     Training average positive_sample_loss at step 819500: 0.147321\n",
      "2022-11-09 01:55:45,047 INFO     Training average negative_sample_loss at step 819500: 0.134428\n",
      "2022-11-09 01:55:45,047 INFO     Training average loss at step 819500: 0.140874\n",
      "2022-11-09 01:55:48,137 INFO     Training average positive_sample_loss at step 819600: 0.140819\n",
      "2022-11-09 01:55:48,137 INFO     Training average negative_sample_loss at step 819600: 0.138456\n",
      "2022-11-09 01:55:48,137 INFO     Training average loss at step 819600: 0.139637\n",
      "2022-11-09 01:55:51,231 INFO     Training average positive_sample_loss at step 819700: 0.143097\n",
      "2022-11-09 01:55:51,231 INFO     Training average negative_sample_loss at step 819700: 0.141736\n",
      "2022-11-09 01:55:51,231 INFO     Training average loss at step 819700: 0.142417\n",
      "2022-11-09 01:55:54,338 INFO     Training average positive_sample_loss at step 819800: 0.143220\n",
      "2022-11-09 01:55:54,338 INFO     Training average negative_sample_loss at step 819800: 0.134620\n",
      "2022-11-09 01:55:54,338 INFO     Training average loss at step 819800: 0.138920\n",
      "2022-11-09 01:55:57,445 INFO     Training average positive_sample_loss at step 819900: 0.141810\n",
      "2022-11-09 01:55:57,445 INFO     Training average negative_sample_loss at step 819900: 0.137036\n",
      "2022-11-09 01:55:57,445 INFO     Training average loss at step 819900: 0.139423\n",
      "2022-11-09 01:56:03,438 INFO     Training average positive_sample_loss at step 820000: 0.144791\n",
      "2022-11-09 01:56:03,438 INFO     Training average negative_sample_loss at step 820000: 0.139929\n",
      "2022-11-09 01:56:03,438 INFO     Training average loss at step 820000: 0.142360\n",
      "2022-11-09 01:56:06,529 INFO     Training average positive_sample_loss at step 820100: 0.143826\n",
      "2022-11-09 01:56:06,529 INFO     Training average negative_sample_loss at step 820100: 0.139461\n",
      "2022-11-09 01:56:06,529 INFO     Training average loss at step 820100: 0.141643\n",
      "2022-11-09 01:56:09,611 INFO     Training average positive_sample_loss at step 820200: 0.148141\n",
      "2022-11-09 01:56:09,611 INFO     Training average negative_sample_loss at step 820200: 0.134989\n",
      "2022-11-09 01:56:09,611 INFO     Training average loss at step 820200: 0.141565\n",
      "2022-11-09 01:56:13,595 INFO     Training average positive_sample_loss at step 820300: 0.142705\n",
      "2022-11-09 01:56:13,596 INFO     Training average negative_sample_loss at step 820300: 0.138719\n",
      "2022-11-09 01:56:13,596 INFO     Training average loss at step 820300: 0.140712\n",
      "2022-11-09 01:56:17,499 INFO     Training average positive_sample_loss at step 820400: 0.144677\n",
      "2022-11-09 01:56:17,499 INFO     Training average negative_sample_loss at step 820400: 0.138765\n",
      "2022-11-09 01:56:17,499 INFO     Training average loss at step 820400: 0.141721\n",
      "2022-11-09 01:56:21,513 INFO     Training average positive_sample_loss at step 820500: 0.144976\n",
      "2022-11-09 01:56:21,513 INFO     Training average negative_sample_loss at step 820500: 0.135041\n",
      "2022-11-09 01:56:21,514 INFO     Training average loss at step 820500: 0.140008\n",
      "2022-11-09 01:56:24,606 INFO     Training average positive_sample_loss at step 820600: 0.143592\n",
      "2022-11-09 01:56:24,607 INFO     Training average negative_sample_loss at step 820600: 0.137092\n",
      "2022-11-09 01:56:24,607 INFO     Training average loss at step 820600: 0.140342\n",
      "2022-11-09 01:56:29,252 INFO     Training average positive_sample_loss at step 820700: 0.142131\n",
      "2022-11-09 01:56:29,252 INFO     Training average negative_sample_loss at step 820700: 0.133047\n",
      "2022-11-09 01:56:29,252 INFO     Training average loss at step 820700: 0.137589\n",
      "2022-11-09 01:56:32,357 INFO     Training average positive_sample_loss at step 820800: 0.139360\n",
      "2022-11-09 01:56:32,357 INFO     Training average negative_sample_loss at step 820800: 0.137793\n",
      "2022-11-09 01:56:32,357 INFO     Training average loss at step 820800: 0.138577\n",
      "2022-11-09 01:56:35,470 INFO     Training average positive_sample_loss at step 820900: 0.145261\n",
      "2022-11-09 01:56:35,470 INFO     Training average negative_sample_loss at step 820900: 0.137631\n",
      "2022-11-09 01:56:35,470 INFO     Training average loss at step 820900: 0.141446\n",
      "2022-11-09 01:56:38,583 INFO     Training average positive_sample_loss at step 821000: 0.145746\n",
      "2022-11-09 01:56:38,583 INFO     Training average negative_sample_loss at step 821000: 0.133216\n",
      "2022-11-09 01:56:38,583 INFO     Training average loss at step 821000: 0.139481\n",
      "2022-11-09 01:56:41,698 INFO     Training average positive_sample_loss at step 821100: 0.145990\n",
      "2022-11-09 01:56:41,698 INFO     Training average negative_sample_loss at step 821100: 0.142606\n",
      "2022-11-09 01:56:41,698 INFO     Training average loss at step 821100: 0.144298\n",
      "2022-11-09 01:56:44,815 INFO     Training average positive_sample_loss at step 821200: 0.145478\n",
      "2022-11-09 01:56:44,816 INFO     Training average negative_sample_loss at step 821200: 0.135646\n",
      "2022-11-09 01:56:44,816 INFO     Training average loss at step 821200: 0.140562\n",
      "2022-11-09 01:56:47,933 INFO     Training average positive_sample_loss at step 821300: 0.141347\n",
      "2022-11-09 01:56:47,933 INFO     Training average negative_sample_loss at step 821300: 0.140447\n",
      "2022-11-09 01:56:47,933 INFO     Training average loss at step 821300: 0.140897\n",
      "2022-11-09 01:56:51,040 INFO     Training average positive_sample_loss at step 821400: 0.148494\n",
      "2022-11-09 01:56:51,040 INFO     Training average negative_sample_loss at step 821400: 0.137996\n",
      "2022-11-09 01:56:51,040 INFO     Training average loss at step 821400: 0.143245\n",
      "2022-11-09 01:56:54,161 INFO     Training average positive_sample_loss at step 821500: 0.143754\n",
      "2022-11-09 01:56:54,161 INFO     Training average negative_sample_loss at step 821500: 0.138644\n",
      "2022-11-09 01:56:54,161 INFO     Training average loss at step 821500: 0.141199\n",
      "2022-11-09 01:56:57,271 INFO     Training average positive_sample_loss at step 821600: 0.147926\n",
      "2022-11-09 01:56:57,271 INFO     Training average negative_sample_loss at step 821600: 0.138692\n",
      "2022-11-09 01:56:57,271 INFO     Training average loss at step 821600: 0.143309\n",
      "2022-11-09 01:57:00,390 INFO     Training average positive_sample_loss at step 821700: 0.140984\n",
      "2022-11-09 01:57:00,390 INFO     Training average negative_sample_loss at step 821700: 0.139833\n",
      "2022-11-09 01:57:00,390 INFO     Training average loss at step 821700: 0.140409\n",
      "2022-11-09 01:57:03,500 INFO     Training average positive_sample_loss at step 821800: 0.141140\n",
      "2022-11-09 01:57:03,500 INFO     Training average negative_sample_loss at step 821800: 0.135213\n",
      "2022-11-09 01:57:03,500 INFO     Training average loss at step 821800: 0.138177\n",
      "2022-11-09 01:57:06,623 INFO     Training average positive_sample_loss at step 821900: 0.139996\n",
      "2022-11-09 01:57:06,623 INFO     Training average negative_sample_loss at step 821900: 0.142508\n",
      "2022-11-09 01:57:06,623 INFO     Training average loss at step 821900: 0.141252\n",
      "2022-11-09 01:57:09,735 INFO     Training average positive_sample_loss at step 822000: 0.143381\n",
      "2022-11-09 01:57:09,735 INFO     Training average negative_sample_loss at step 822000: 0.139425\n",
      "2022-11-09 01:57:09,735 INFO     Training average loss at step 822000: 0.141403\n",
      "2022-11-09 01:57:12,850 INFO     Training average positive_sample_loss at step 822100: 0.144087\n",
      "2022-11-09 01:57:12,850 INFO     Training average negative_sample_loss at step 822100: 0.140037\n",
      "2022-11-09 01:57:12,850 INFO     Training average loss at step 822100: 0.142062\n",
      "2022-11-09 01:57:15,970 INFO     Training average positive_sample_loss at step 822200: 0.144177\n",
      "2022-11-09 01:57:15,970 INFO     Training average negative_sample_loss at step 822200: 0.133521\n",
      "2022-11-09 01:57:15,970 INFO     Training average loss at step 822200: 0.138849\n",
      "2022-11-09 01:57:19,085 INFO     Training average positive_sample_loss at step 822300: 0.140869\n",
      "2022-11-09 01:57:19,085 INFO     Training average negative_sample_loss at step 822300: 0.137284\n",
      "2022-11-09 01:57:19,085 INFO     Training average loss at step 822300: 0.139077\n",
      "2022-11-09 01:57:22,196 INFO     Training average positive_sample_loss at step 822400: 0.146983\n",
      "2022-11-09 01:57:22,196 INFO     Training average negative_sample_loss at step 822400: 0.137579\n",
      "2022-11-09 01:57:22,196 INFO     Training average loss at step 822400: 0.142281\n",
      "2022-11-09 01:57:25,308 INFO     Training average positive_sample_loss at step 822500: 0.143945\n",
      "2022-11-09 01:57:25,308 INFO     Training average negative_sample_loss at step 822500: 0.137065\n",
      "2022-11-09 01:57:25,308 INFO     Training average loss at step 822500: 0.140505\n",
      "2022-11-09 01:57:28,424 INFO     Training average positive_sample_loss at step 822600: 0.144794\n",
      "2022-11-09 01:57:28,424 INFO     Training average negative_sample_loss at step 822600: 0.139014\n",
      "2022-11-09 01:57:28,424 INFO     Training average loss at step 822600: 0.141904\n",
      "2022-11-09 01:57:31,528 INFO     Training average positive_sample_loss at step 822700: 0.146651\n",
      "2022-11-09 01:57:31,528 INFO     Training average negative_sample_loss at step 822700: 0.136828\n",
      "2022-11-09 01:57:31,528 INFO     Training average loss at step 822700: 0.141739\n",
      "2022-11-09 01:57:34,645 INFO     Training average positive_sample_loss at step 822800: 0.145975\n",
      "2022-11-09 01:57:34,645 INFO     Training average negative_sample_loss at step 822800: 0.137417\n",
      "2022-11-09 01:57:34,645 INFO     Training average loss at step 822800: 0.141696\n",
      "2022-11-09 01:57:37,765 INFO     Training average positive_sample_loss at step 822900: 0.146628\n",
      "2022-11-09 01:57:37,765 INFO     Training average negative_sample_loss at step 822900: 0.138834\n",
      "2022-11-09 01:57:37,765 INFO     Training average loss at step 822900: 0.142731\n",
      "2022-11-09 01:57:40,881 INFO     Training average positive_sample_loss at step 823000: 0.142709\n",
      "2022-11-09 01:57:40,881 INFO     Training average negative_sample_loss at step 823000: 0.142580\n",
      "2022-11-09 01:57:40,881 INFO     Training average loss at step 823000: 0.142645\n",
      "2022-11-09 01:57:43,991 INFO     Training average positive_sample_loss at step 823100: 0.145411\n",
      "2022-11-09 01:57:43,991 INFO     Training average negative_sample_loss at step 823100: 0.136948\n",
      "2022-11-09 01:57:43,991 INFO     Training average loss at step 823100: 0.141180\n",
      "2022-11-09 01:57:47,105 INFO     Training average positive_sample_loss at step 823200: 0.145714\n",
      "2022-11-09 01:57:47,105 INFO     Training average negative_sample_loss at step 823200: 0.135967\n",
      "2022-11-09 01:57:47,105 INFO     Training average loss at step 823200: 0.140840\n",
      "2022-11-09 01:57:50,213 INFO     Training average positive_sample_loss at step 823300: 0.142140\n",
      "2022-11-09 01:57:50,213 INFO     Training average negative_sample_loss at step 823300: 0.140127\n",
      "2022-11-09 01:57:50,213 INFO     Training average loss at step 823300: 0.141133\n",
      "2022-11-09 01:57:53,328 INFO     Training average positive_sample_loss at step 823400: 0.143224\n",
      "2022-11-09 01:57:53,329 INFO     Training average negative_sample_loss at step 823400: 0.136918\n",
      "2022-11-09 01:57:53,329 INFO     Training average loss at step 823400: 0.140071\n",
      "2022-11-09 01:57:56,442 INFO     Training average positive_sample_loss at step 823500: 0.142801\n",
      "2022-11-09 01:57:56,442 INFO     Training average negative_sample_loss at step 823500: 0.134877\n",
      "2022-11-09 01:57:56,442 INFO     Training average loss at step 823500: 0.138839\n",
      "2022-11-09 01:57:59,555 INFO     Training average positive_sample_loss at step 823600: 0.140864\n",
      "2022-11-09 01:57:59,555 INFO     Training average negative_sample_loss at step 823600: 0.134187\n",
      "2022-11-09 01:57:59,555 INFO     Training average loss at step 823600: 0.137525\n",
      "2022-11-09 01:58:02,657 INFO     Training average positive_sample_loss at step 823700: 0.143055\n",
      "2022-11-09 01:58:02,657 INFO     Training average negative_sample_loss at step 823700: 0.134493\n",
      "2022-11-09 01:58:02,657 INFO     Training average loss at step 823700: 0.138774\n",
      "2022-11-09 01:58:05,775 INFO     Training average positive_sample_loss at step 823800: 0.147033\n",
      "2022-11-09 01:58:05,775 INFO     Training average negative_sample_loss at step 823800: 0.138830\n",
      "2022-11-09 01:58:05,775 INFO     Training average loss at step 823800: 0.142932\n",
      "2022-11-09 01:58:08,894 INFO     Training average positive_sample_loss at step 823900: 0.145122\n",
      "2022-11-09 01:58:08,894 INFO     Training average negative_sample_loss at step 823900: 0.134587\n",
      "2022-11-09 01:58:08,895 INFO     Training average loss at step 823900: 0.139854\n",
      "2022-11-09 01:58:12,016 INFO     Training average positive_sample_loss at step 824000: 0.145032\n",
      "2022-11-09 01:58:12,016 INFO     Training average negative_sample_loss at step 824000: 0.141985\n",
      "2022-11-09 01:58:12,016 INFO     Training average loss at step 824000: 0.143509\n",
      "2022-11-09 01:58:15,137 INFO     Training average positive_sample_loss at step 824100: 0.141781\n",
      "2022-11-09 01:58:15,137 INFO     Training average negative_sample_loss at step 824100: 0.135553\n",
      "2022-11-09 01:58:15,137 INFO     Training average loss at step 824100: 0.138667\n",
      "2022-11-09 01:58:18,254 INFO     Training average positive_sample_loss at step 824200: 0.148370\n",
      "2022-11-09 01:58:18,254 INFO     Training average negative_sample_loss at step 824200: 0.139583\n",
      "2022-11-09 01:58:18,254 INFO     Training average loss at step 824200: 0.143976\n",
      "2022-11-09 01:58:21,362 INFO     Training average positive_sample_loss at step 824300: 0.140253\n",
      "2022-11-09 01:58:21,363 INFO     Training average negative_sample_loss at step 824300: 0.136734\n",
      "2022-11-09 01:58:21,363 INFO     Training average loss at step 824300: 0.138494\n",
      "2022-11-09 01:58:24,478 INFO     Training average positive_sample_loss at step 824400: 0.143302\n",
      "2022-11-09 01:58:24,478 INFO     Training average negative_sample_loss at step 824400: 0.136783\n",
      "2022-11-09 01:58:24,478 INFO     Training average loss at step 824400: 0.140042\n",
      "2022-11-09 01:58:27,602 INFO     Training average positive_sample_loss at step 824500: 0.139096\n",
      "2022-11-09 01:58:27,602 INFO     Training average negative_sample_loss at step 824500: 0.138757\n",
      "2022-11-09 01:58:27,602 INFO     Training average loss at step 824500: 0.138927\n",
      "2022-11-09 01:58:30,713 INFO     Training average positive_sample_loss at step 824600: 0.146778\n",
      "2022-11-09 01:58:30,713 INFO     Training average negative_sample_loss at step 824600: 0.136548\n",
      "2022-11-09 01:58:30,713 INFO     Training average loss at step 824600: 0.141663\n",
      "2022-11-09 01:58:33,816 INFO     Training average positive_sample_loss at step 824700: 0.145958\n",
      "2022-11-09 01:58:33,816 INFO     Training average negative_sample_loss at step 824700: 0.133891\n",
      "2022-11-09 01:58:33,816 INFO     Training average loss at step 824700: 0.139924\n",
      "2022-11-09 01:58:36,925 INFO     Training average positive_sample_loss at step 824800: 0.144224\n",
      "2022-11-09 01:58:36,925 INFO     Training average negative_sample_loss at step 824800: 0.138773\n",
      "2022-11-09 01:58:36,925 INFO     Training average loss at step 824800: 0.141498\n",
      "2022-11-09 01:58:40,043 INFO     Training average positive_sample_loss at step 824900: 0.142860\n",
      "2022-11-09 01:58:40,043 INFO     Training average negative_sample_loss at step 824900: 0.135604\n",
      "2022-11-09 01:58:40,044 INFO     Training average loss at step 824900: 0.139232\n",
      "2022-11-09 01:58:44,080 INFO     Training average positive_sample_loss at step 825000: 0.140735\n",
      "2022-11-09 01:58:44,080 INFO     Training average negative_sample_loss at step 825000: 0.136551\n",
      "2022-11-09 01:58:44,080 INFO     Training average loss at step 825000: 0.138643\n",
      "2022-11-09 01:58:48,280 INFO     Training average positive_sample_loss at step 825100: 0.144546\n",
      "2022-11-09 01:58:48,280 INFO     Training average negative_sample_loss at step 825100: 0.137761\n",
      "2022-11-09 01:58:48,280 INFO     Training average loss at step 825100: 0.141153\n",
      "2022-11-09 01:58:52,370 INFO     Training average positive_sample_loss at step 825200: 0.145495\n",
      "2022-11-09 01:58:52,370 INFO     Training average negative_sample_loss at step 825200: 0.140172\n",
      "2022-11-09 01:58:52,370 INFO     Training average loss at step 825200: 0.142833\n",
      "2022-11-09 01:58:56,675 INFO     Training average positive_sample_loss at step 825300: 0.141201\n",
      "2022-11-09 01:58:56,675 INFO     Training average negative_sample_loss at step 825300: 0.136882\n",
      "2022-11-09 01:58:56,675 INFO     Training average loss at step 825300: 0.139042\n",
      "2022-11-09 01:58:59,791 INFO     Training average positive_sample_loss at step 825400: 0.143091\n",
      "2022-11-09 01:58:59,791 INFO     Training average negative_sample_loss at step 825400: 0.140785\n",
      "2022-11-09 01:58:59,791 INFO     Training average loss at step 825400: 0.141938\n",
      "2022-11-09 01:59:02,899 INFO     Training average positive_sample_loss at step 825500: 0.145440\n",
      "2022-11-09 01:59:02,899 INFO     Training average negative_sample_loss at step 825500: 0.134421\n",
      "2022-11-09 01:59:02,900 INFO     Training average loss at step 825500: 0.139930\n",
      "2022-11-09 01:59:06,008 INFO     Training average positive_sample_loss at step 825600: 0.140828\n",
      "2022-11-09 01:59:06,008 INFO     Training average negative_sample_loss at step 825600: 0.140183\n",
      "2022-11-09 01:59:06,008 INFO     Training average loss at step 825600: 0.140506\n",
      "2022-11-09 01:59:09,124 INFO     Training average positive_sample_loss at step 825700: 0.147407\n",
      "2022-11-09 01:59:09,124 INFO     Training average negative_sample_loss at step 825700: 0.136122\n",
      "2022-11-09 01:59:09,124 INFO     Training average loss at step 825700: 0.141764\n",
      "2022-11-09 01:59:12,245 INFO     Training average positive_sample_loss at step 825800: 0.144632\n",
      "2022-11-09 01:59:12,246 INFO     Training average negative_sample_loss at step 825800: 0.135658\n",
      "2022-11-09 01:59:12,246 INFO     Training average loss at step 825800: 0.140145\n",
      "2022-11-09 01:59:15,356 INFO     Training average positive_sample_loss at step 825900: 0.141407\n",
      "2022-11-09 01:59:15,357 INFO     Training average negative_sample_loss at step 825900: 0.139762\n",
      "2022-11-09 01:59:15,357 INFO     Training average loss at step 825900: 0.140585\n",
      "2022-11-09 01:59:18,476 INFO     Training average positive_sample_loss at step 826000: 0.142258\n",
      "2022-11-09 01:59:18,476 INFO     Training average negative_sample_loss at step 826000: 0.140680\n",
      "2022-11-09 01:59:18,476 INFO     Training average loss at step 826000: 0.141469\n",
      "2022-11-09 01:59:21,592 INFO     Training average positive_sample_loss at step 826100: 0.147452\n",
      "2022-11-09 01:59:21,592 INFO     Training average negative_sample_loss at step 826100: 0.138337\n",
      "2022-11-09 01:59:21,592 INFO     Training average loss at step 826100: 0.142894\n",
      "2022-11-09 01:59:24,702 INFO     Training average positive_sample_loss at step 826200: 0.143521\n",
      "2022-11-09 01:59:24,702 INFO     Training average negative_sample_loss at step 826200: 0.138188\n",
      "2022-11-09 01:59:24,702 INFO     Training average loss at step 826200: 0.140855\n",
      "2022-11-09 01:59:27,816 INFO     Training average positive_sample_loss at step 826300: 0.141721\n",
      "2022-11-09 01:59:27,816 INFO     Training average negative_sample_loss at step 826300: 0.134965\n",
      "2022-11-09 01:59:27,816 INFO     Training average loss at step 826300: 0.138343\n",
      "2022-11-09 01:59:30,932 INFO     Training average positive_sample_loss at step 826400: 0.141811\n",
      "2022-11-09 01:59:30,932 INFO     Training average negative_sample_loss at step 826400: 0.140015\n",
      "2022-11-09 01:59:30,933 INFO     Training average loss at step 826400: 0.140913\n",
      "2022-11-09 01:59:34,053 INFO     Training average positive_sample_loss at step 826500: 0.145557\n",
      "2022-11-09 01:59:34,053 INFO     Training average negative_sample_loss at step 826500: 0.142150\n",
      "2022-11-09 01:59:34,053 INFO     Training average loss at step 826500: 0.143854\n",
      "2022-11-09 01:59:37,155 INFO     Training average positive_sample_loss at step 826600: 0.138608\n",
      "2022-11-09 01:59:37,156 INFO     Training average negative_sample_loss at step 826600: 0.138433\n",
      "2022-11-09 01:59:37,156 INFO     Training average loss at step 826600: 0.138521\n",
      "2022-11-09 01:59:40,268 INFO     Training average positive_sample_loss at step 826700: 0.143208\n",
      "2022-11-09 01:59:40,268 INFO     Training average negative_sample_loss at step 826700: 0.138080\n",
      "2022-11-09 01:59:40,268 INFO     Training average loss at step 826700: 0.140644\n",
      "2022-11-09 01:59:43,383 INFO     Training average positive_sample_loss at step 826800: 0.145076\n",
      "2022-11-09 01:59:43,383 INFO     Training average negative_sample_loss at step 826800: 0.140088\n",
      "2022-11-09 01:59:43,383 INFO     Training average loss at step 826800: 0.142582\n",
      "2022-11-09 01:59:46,496 INFO     Training average positive_sample_loss at step 826900: 0.146693\n",
      "2022-11-09 01:59:46,496 INFO     Training average negative_sample_loss at step 826900: 0.134542\n",
      "2022-11-09 01:59:46,496 INFO     Training average loss at step 826900: 0.140617\n",
      "2022-11-09 01:59:49,601 INFO     Training average positive_sample_loss at step 827000: 0.144673\n",
      "2022-11-09 01:59:49,601 INFO     Training average negative_sample_loss at step 827000: 0.136888\n",
      "2022-11-09 01:59:49,601 INFO     Training average loss at step 827000: 0.140781\n",
      "2022-11-09 01:59:52,726 INFO     Training average positive_sample_loss at step 827100: 0.145693\n",
      "2022-11-09 01:59:52,726 INFO     Training average negative_sample_loss at step 827100: 0.141188\n",
      "2022-11-09 01:59:52,726 INFO     Training average loss at step 827100: 0.143440\n",
      "2022-11-09 01:59:55,840 INFO     Training average positive_sample_loss at step 827200: 0.143261\n",
      "2022-11-09 01:59:55,840 INFO     Training average negative_sample_loss at step 827200: 0.139273\n",
      "2022-11-09 01:59:55,840 INFO     Training average loss at step 827200: 0.141267\n",
      "2022-11-09 01:59:58,953 INFO     Training average positive_sample_loss at step 827300: 0.144520\n",
      "2022-11-09 01:59:58,953 INFO     Training average negative_sample_loss at step 827300: 0.133721\n",
      "2022-11-09 01:59:58,953 INFO     Training average loss at step 827300: 0.139120\n",
      "2022-11-09 02:00:02,052 INFO     Training average positive_sample_loss at step 827400: 0.138703\n",
      "2022-11-09 02:00:02,053 INFO     Training average negative_sample_loss at step 827400: 0.138115\n",
      "2022-11-09 02:00:02,053 INFO     Training average loss at step 827400: 0.138409\n",
      "2022-11-09 02:00:05,161 INFO     Training average positive_sample_loss at step 827500: 0.139846\n",
      "2022-11-09 02:00:05,161 INFO     Training average negative_sample_loss at step 827500: 0.138032\n",
      "2022-11-09 02:00:05,161 INFO     Training average loss at step 827500: 0.138939\n",
      "2022-11-09 02:00:08,288 INFO     Training average positive_sample_loss at step 827600: 0.143551\n",
      "2022-11-09 02:00:08,288 INFO     Training average negative_sample_loss at step 827600: 0.135799\n",
      "2022-11-09 02:00:08,288 INFO     Training average loss at step 827600: 0.139675\n",
      "2022-11-09 02:00:11,401 INFO     Training average positive_sample_loss at step 827700: 0.144585\n",
      "2022-11-09 02:00:11,401 INFO     Training average negative_sample_loss at step 827700: 0.136311\n",
      "2022-11-09 02:00:11,401 INFO     Training average loss at step 827700: 0.140448\n",
      "2022-11-09 02:00:14,515 INFO     Training average positive_sample_loss at step 827800: 0.143233\n",
      "2022-11-09 02:00:14,515 INFO     Training average negative_sample_loss at step 827800: 0.140360\n",
      "2022-11-09 02:00:14,515 INFO     Training average loss at step 827800: 0.141796\n",
      "2022-11-09 02:00:17,620 INFO     Training average positive_sample_loss at step 827900: 0.144678\n",
      "2022-11-09 02:00:17,620 INFO     Training average negative_sample_loss at step 827900: 0.138966\n",
      "2022-11-09 02:00:17,620 INFO     Training average loss at step 827900: 0.141822\n",
      "2022-11-09 02:00:20,733 INFO     Training average positive_sample_loss at step 828000: 0.148032\n",
      "2022-11-09 02:00:20,734 INFO     Training average negative_sample_loss at step 828000: 0.138963\n",
      "2022-11-09 02:00:20,734 INFO     Training average loss at step 828000: 0.143497\n",
      "2022-11-09 02:00:23,863 INFO     Training average positive_sample_loss at step 828100: 0.141552\n",
      "2022-11-09 02:00:23,863 INFO     Training average negative_sample_loss at step 828100: 0.133920\n",
      "2022-11-09 02:00:23,863 INFO     Training average loss at step 828100: 0.137736\n",
      "2022-11-09 02:00:26,980 INFO     Training average positive_sample_loss at step 828200: 0.139480\n",
      "2022-11-09 02:00:26,980 INFO     Training average negative_sample_loss at step 828200: 0.135182\n",
      "2022-11-09 02:00:26,980 INFO     Training average loss at step 828200: 0.137331\n",
      "2022-11-09 02:00:30,082 INFO     Training average positive_sample_loss at step 828300: 0.138670\n",
      "2022-11-09 02:00:30,082 INFO     Training average negative_sample_loss at step 828300: 0.135533\n",
      "2022-11-09 02:00:30,082 INFO     Training average loss at step 828300: 0.137102\n",
      "2022-11-09 02:00:33,174 INFO     Training average positive_sample_loss at step 828400: 0.140985\n",
      "2022-11-09 02:00:33,174 INFO     Training average negative_sample_loss at step 828400: 0.130910\n",
      "2022-11-09 02:00:33,174 INFO     Training average loss at step 828400: 0.135947\n",
      "2022-11-09 02:00:36,285 INFO     Training average positive_sample_loss at step 828500: 0.145298\n",
      "2022-11-09 02:00:36,286 INFO     Training average negative_sample_loss at step 828500: 0.136535\n",
      "2022-11-09 02:00:36,286 INFO     Training average loss at step 828500: 0.140917\n",
      "2022-11-09 02:00:39,396 INFO     Training average positive_sample_loss at step 828600: 0.147996\n",
      "2022-11-09 02:00:39,396 INFO     Training average negative_sample_loss at step 828600: 0.140250\n",
      "2022-11-09 02:00:39,396 INFO     Training average loss at step 828600: 0.144123\n",
      "2022-11-09 02:00:42,511 INFO     Training average positive_sample_loss at step 828700: 0.143862\n",
      "2022-11-09 02:00:42,511 INFO     Training average negative_sample_loss at step 828700: 0.139619\n",
      "2022-11-09 02:00:42,511 INFO     Training average loss at step 828700: 0.141741\n",
      "2022-11-09 02:00:45,625 INFO     Training average positive_sample_loss at step 828800: 0.150351\n",
      "2022-11-09 02:00:45,625 INFO     Training average negative_sample_loss at step 828800: 0.139867\n",
      "2022-11-09 02:00:45,625 INFO     Training average loss at step 828800: 0.145109\n",
      "2022-11-09 02:00:48,732 INFO     Training average positive_sample_loss at step 828900: 0.140942\n",
      "2022-11-09 02:00:48,732 INFO     Training average negative_sample_loss at step 828900: 0.137896\n",
      "2022-11-09 02:00:48,732 INFO     Training average loss at step 828900: 0.139419\n",
      "2022-11-09 02:00:51,836 INFO     Training average positive_sample_loss at step 829000: 0.146438\n",
      "2022-11-09 02:00:51,836 INFO     Training average negative_sample_loss at step 829000: 0.137862\n",
      "2022-11-09 02:00:51,836 INFO     Training average loss at step 829000: 0.142150\n",
      "2022-11-09 02:00:54,945 INFO     Training average positive_sample_loss at step 829100: 0.145976\n",
      "2022-11-09 02:00:54,945 INFO     Training average negative_sample_loss at step 829100: 0.140256\n",
      "2022-11-09 02:00:54,945 INFO     Training average loss at step 829100: 0.143116\n",
      "2022-11-09 02:00:58,051 INFO     Training average positive_sample_loss at step 829200: 0.144519\n",
      "2022-11-09 02:00:58,051 INFO     Training average negative_sample_loss at step 829200: 0.138614\n",
      "2022-11-09 02:00:58,051 INFO     Training average loss at step 829200: 0.141566\n",
      "2022-11-09 02:01:01,162 INFO     Training average positive_sample_loss at step 829300: 0.139019\n",
      "2022-11-09 02:01:01,162 INFO     Training average negative_sample_loss at step 829300: 0.137597\n",
      "2022-11-09 02:01:01,162 INFO     Training average loss at step 829300: 0.138308\n",
      "2022-11-09 02:01:04,269 INFO     Training average positive_sample_loss at step 829400: 0.142850\n",
      "2022-11-09 02:01:04,269 INFO     Training average negative_sample_loss at step 829400: 0.135883\n",
      "2022-11-09 02:01:04,269 INFO     Training average loss at step 829400: 0.139367\n",
      "2022-11-09 02:01:08,299 INFO     Training average positive_sample_loss at step 829500: 0.140672\n",
      "2022-11-09 02:01:08,299 INFO     Training average negative_sample_loss at step 829500: 0.137011\n",
      "2022-11-09 02:01:08,299 INFO     Training average loss at step 829500: 0.138841\n",
      "2022-11-09 02:01:11,435 INFO     Training average positive_sample_loss at step 829600: 0.147950\n",
      "2022-11-09 02:01:11,435 INFO     Training average negative_sample_loss at step 829600: 0.143725\n",
      "2022-11-09 02:01:11,435 INFO     Training average loss at step 829600: 0.145837\n",
      "2022-11-09 02:01:15,673 INFO     Training average positive_sample_loss at step 829700: 0.138635\n",
      "2022-11-09 02:01:15,673 INFO     Training average negative_sample_loss at step 829700: 0.133961\n",
      "2022-11-09 02:01:15,673 INFO     Training average loss at step 829700: 0.136298\n",
      "2022-11-09 02:01:19,799 INFO     Training average positive_sample_loss at step 829800: 0.143903\n",
      "2022-11-09 02:01:19,800 INFO     Training average negative_sample_loss at step 829800: 0.139559\n",
      "2022-11-09 02:01:19,800 INFO     Training average loss at step 829800: 0.141731\n",
      "2022-11-09 02:01:24,075 INFO     Training average positive_sample_loss at step 829900: 0.143840\n",
      "2022-11-09 02:01:24,075 INFO     Training average negative_sample_loss at step 829900: 0.140085\n",
      "2022-11-09 02:01:24,075 INFO     Training average loss at step 829900: 0.141963\n",
      "2022-11-09 02:01:30,092 INFO     Training average positive_sample_loss at step 830000: 0.141796\n",
      "2022-11-09 02:01:30,092 INFO     Training average negative_sample_loss at step 830000: 0.140748\n",
      "2022-11-09 02:01:30,092 INFO     Training average loss at step 830000: 0.141272\n",
      "2022-11-09 02:01:33,206 INFO     Training average positive_sample_loss at step 830100: 0.143600\n",
      "2022-11-09 02:01:33,206 INFO     Training average negative_sample_loss at step 830100: 0.136167\n",
      "2022-11-09 02:01:33,206 INFO     Training average loss at step 830100: 0.139883\n",
      "2022-11-09 02:01:36,315 INFO     Training average positive_sample_loss at step 830200: 0.143469\n",
      "2022-11-09 02:01:36,315 INFO     Training average negative_sample_loss at step 830200: 0.133170\n",
      "2022-11-09 02:01:36,315 INFO     Training average loss at step 830200: 0.138320\n",
      "2022-11-09 02:01:39,438 INFO     Training average positive_sample_loss at step 830300: 0.139106\n",
      "2022-11-09 02:01:39,438 INFO     Training average negative_sample_loss at step 830300: 0.135165\n",
      "2022-11-09 02:01:39,438 INFO     Training average loss at step 830300: 0.137136\n",
      "2022-11-09 02:01:42,539 INFO     Training average positive_sample_loss at step 830400: 0.145916\n",
      "2022-11-09 02:01:42,539 INFO     Training average negative_sample_loss at step 830400: 0.137312\n",
      "2022-11-09 02:01:42,539 INFO     Training average loss at step 830400: 0.141614\n",
      "2022-11-09 02:01:45,656 INFO     Training average positive_sample_loss at step 830500: 0.142352\n",
      "2022-11-09 02:01:45,656 INFO     Training average negative_sample_loss at step 830500: 0.141171\n",
      "2022-11-09 02:01:45,656 INFO     Training average loss at step 830500: 0.141761\n",
      "2022-11-09 02:01:48,766 INFO     Training average positive_sample_loss at step 830600: 0.148685\n",
      "2022-11-09 02:01:48,766 INFO     Training average negative_sample_loss at step 830600: 0.140607\n",
      "2022-11-09 02:01:48,766 INFO     Training average loss at step 830600: 0.144646\n",
      "2022-11-09 02:01:51,878 INFO     Training average positive_sample_loss at step 830700: 0.143469\n",
      "2022-11-09 02:01:51,878 INFO     Training average negative_sample_loss at step 830700: 0.137919\n",
      "2022-11-09 02:01:51,878 INFO     Training average loss at step 830700: 0.140694\n",
      "2022-11-09 02:01:54,995 INFO     Training average positive_sample_loss at step 830800: 0.146782\n",
      "2022-11-09 02:01:54,995 INFO     Training average negative_sample_loss at step 830800: 0.138138\n",
      "2022-11-09 02:01:54,995 INFO     Training average loss at step 830800: 0.142460\n",
      "2022-11-09 02:01:58,104 INFO     Training average positive_sample_loss at step 830900: 0.143416\n",
      "2022-11-09 02:01:58,104 INFO     Training average negative_sample_loss at step 830900: 0.140182\n",
      "2022-11-09 02:01:58,104 INFO     Training average loss at step 830900: 0.141799\n",
      "2022-11-09 02:02:01,195 INFO     Training average positive_sample_loss at step 831000: 0.144691\n",
      "2022-11-09 02:02:01,195 INFO     Training average negative_sample_loss at step 831000: 0.142937\n",
      "2022-11-09 02:02:01,195 INFO     Training average loss at step 831000: 0.143814\n",
      "2022-11-09 02:02:04,288 INFO     Training average positive_sample_loss at step 831100: 0.141808\n",
      "2022-11-09 02:02:04,288 INFO     Training average negative_sample_loss at step 831100: 0.137349\n",
      "2022-11-09 02:02:04,288 INFO     Training average loss at step 831100: 0.139578\n",
      "2022-11-09 02:02:07,404 INFO     Training average positive_sample_loss at step 831200: 0.146672\n",
      "2022-11-09 02:02:07,404 INFO     Training average negative_sample_loss at step 831200: 0.141228\n",
      "2022-11-09 02:02:07,404 INFO     Training average loss at step 831200: 0.143950\n",
      "2022-11-09 02:02:10,505 INFO     Training average positive_sample_loss at step 831300: 0.144008\n",
      "2022-11-09 02:02:10,505 INFO     Training average negative_sample_loss at step 831300: 0.136919\n",
      "2022-11-09 02:02:10,505 INFO     Training average loss at step 831300: 0.140464\n",
      "2022-11-09 02:02:13,603 INFO     Training average positive_sample_loss at step 831400: 0.144168\n",
      "2022-11-09 02:02:13,603 INFO     Training average negative_sample_loss at step 831400: 0.139797\n",
      "2022-11-09 02:02:13,603 INFO     Training average loss at step 831400: 0.141983\n",
      "2022-11-09 02:02:16,696 INFO     Training average positive_sample_loss at step 831500: 0.141784\n",
      "2022-11-09 02:02:16,696 INFO     Training average negative_sample_loss at step 831500: 0.137888\n",
      "2022-11-09 02:02:16,696 INFO     Training average loss at step 831500: 0.139836\n",
      "2022-11-09 02:02:19,805 INFO     Training average positive_sample_loss at step 831600: 0.148724\n",
      "2022-11-09 02:02:19,805 INFO     Training average negative_sample_loss at step 831600: 0.139586\n",
      "2022-11-09 02:02:19,805 INFO     Training average loss at step 831600: 0.144155\n",
      "2022-11-09 02:02:22,918 INFO     Training average positive_sample_loss at step 831700: 0.146909\n",
      "2022-11-09 02:02:22,918 INFO     Training average negative_sample_loss at step 831700: 0.138849\n",
      "2022-11-09 02:02:22,918 INFO     Training average loss at step 831700: 0.142879\n",
      "2022-11-09 02:02:26,027 INFO     Training average positive_sample_loss at step 831800: 0.145694\n",
      "2022-11-09 02:02:26,027 INFO     Training average negative_sample_loss at step 831800: 0.135591\n",
      "2022-11-09 02:02:26,027 INFO     Training average loss at step 831800: 0.140643\n",
      "2022-11-09 02:02:29,138 INFO     Training average positive_sample_loss at step 831900: 0.144042\n",
      "2022-11-09 02:02:29,138 INFO     Training average negative_sample_loss at step 831900: 0.140277\n",
      "2022-11-09 02:02:29,138 INFO     Training average loss at step 831900: 0.142160\n",
      "2022-11-09 02:02:32,244 INFO     Training average positive_sample_loss at step 832000: 0.141685\n",
      "2022-11-09 02:02:32,245 INFO     Training average negative_sample_loss at step 832000: 0.140925\n",
      "2022-11-09 02:02:32,245 INFO     Training average loss at step 832000: 0.141305\n",
      "2022-11-09 02:02:35,363 INFO     Training average positive_sample_loss at step 832100: 0.141777\n",
      "2022-11-09 02:02:35,363 INFO     Training average negative_sample_loss at step 832100: 0.135251\n",
      "2022-11-09 02:02:35,363 INFO     Training average loss at step 832100: 0.138514\n",
      "2022-11-09 02:02:38,477 INFO     Training average positive_sample_loss at step 832200: 0.144026\n",
      "2022-11-09 02:02:38,477 INFO     Training average negative_sample_loss at step 832200: 0.137050\n",
      "2022-11-09 02:02:38,477 INFO     Training average loss at step 832200: 0.140538\n",
      "2022-11-09 02:02:41,581 INFO     Training average positive_sample_loss at step 832300: 0.144774\n",
      "2022-11-09 02:02:41,581 INFO     Training average negative_sample_loss at step 832300: 0.141756\n",
      "2022-11-09 02:02:41,581 INFO     Training average loss at step 832300: 0.143265\n",
      "2022-11-09 02:02:44,690 INFO     Training average positive_sample_loss at step 832400: 0.139457\n",
      "2022-11-09 02:02:44,690 INFO     Training average negative_sample_loss at step 832400: 0.135795\n",
      "2022-11-09 02:02:44,690 INFO     Training average loss at step 832400: 0.137626\n",
      "2022-11-09 02:02:47,801 INFO     Training average positive_sample_loss at step 832500: 0.145798\n",
      "2022-11-09 02:02:47,801 INFO     Training average negative_sample_loss at step 832500: 0.136477\n",
      "2022-11-09 02:02:47,801 INFO     Training average loss at step 832500: 0.141137\n",
      "2022-11-09 02:02:50,903 INFO     Training average positive_sample_loss at step 832600: 0.142158\n",
      "2022-11-09 02:02:50,903 INFO     Training average negative_sample_loss at step 832600: 0.136962\n",
      "2022-11-09 02:02:50,903 INFO     Training average loss at step 832600: 0.139560\n",
      "2022-11-09 02:02:54,004 INFO     Training average positive_sample_loss at step 832700: 0.145048\n",
      "2022-11-09 02:02:54,004 INFO     Training average negative_sample_loss at step 832700: 0.138278\n",
      "2022-11-09 02:02:54,004 INFO     Training average loss at step 832700: 0.141663\n",
      "2022-11-09 02:02:57,111 INFO     Training average positive_sample_loss at step 832800: 0.148311\n",
      "2022-11-09 02:02:57,111 INFO     Training average negative_sample_loss at step 832800: 0.139605\n",
      "2022-11-09 02:02:57,111 INFO     Training average loss at step 832800: 0.143958\n",
      "2022-11-09 02:03:00,210 INFO     Training average positive_sample_loss at step 832900: 0.138512\n",
      "2022-11-09 02:03:00,210 INFO     Training average negative_sample_loss at step 832900: 0.138504\n",
      "2022-11-09 02:03:00,210 INFO     Training average loss at step 832900: 0.138508\n",
      "2022-11-09 02:03:03,317 INFO     Training average positive_sample_loss at step 833000: 0.141110\n",
      "2022-11-09 02:03:03,317 INFO     Training average negative_sample_loss at step 833000: 0.136042\n",
      "2022-11-09 02:03:03,317 INFO     Training average loss at step 833000: 0.138576\n",
      "2022-11-09 02:03:06,429 INFO     Training average positive_sample_loss at step 833100: 0.146406\n",
      "2022-11-09 02:03:06,429 INFO     Training average negative_sample_loss at step 833100: 0.138799\n",
      "2022-11-09 02:03:06,429 INFO     Training average loss at step 833100: 0.142603\n",
      "2022-11-09 02:03:09,535 INFO     Training average positive_sample_loss at step 833200: 0.147007\n",
      "2022-11-09 02:03:09,536 INFO     Training average negative_sample_loss at step 833200: 0.140562\n",
      "2022-11-09 02:03:09,536 INFO     Training average loss at step 833200: 0.143784\n",
      "2022-11-09 02:03:12,637 INFO     Training average positive_sample_loss at step 833300: 0.140760\n",
      "2022-11-09 02:03:12,637 INFO     Training average negative_sample_loss at step 833300: 0.136727\n",
      "2022-11-09 02:03:12,637 INFO     Training average loss at step 833300: 0.138743\n",
      "2022-11-09 02:03:15,751 INFO     Training average positive_sample_loss at step 833400: 0.143621\n",
      "2022-11-09 02:03:15,751 INFO     Training average negative_sample_loss at step 833400: 0.134891\n",
      "2022-11-09 02:03:15,751 INFO     Training average loss at step 833400: 0.139256\n",
      "2022-11-09 02:03:18,856 INFO     Training average positive_sample_loss at step 833500: 0.143473\n",
      "2022-11-09 02:03:18,857 INFO     Training average negative_sample_loss at step 833500: 0.139122\n",
      "2022-11-09 02:03:18,857 INFO     Training average loss at step 833500: 0.141298\n",
      "2022-11-09 02:03:21,967 INFO     Training average positive_sample_loss at step 833600: 0.140565\n",
      "2022-11-09 02:03:21,967 INFO     Training average negative_sample_loss at step 833600: 0.134818\n",
      "2022-11-09 02:03:21,967 INFO     Training average loss at step 833600: 0.137692\n",
      "2022-11-09 02:03:25,074 INFO     Training average positive_sample_loss at step 833700: 0.142571\n",
      "2022-11-09 02:03:25,074 INFO     Training average negative_sample_loss at step 833700: 0.135629\n",
      "2022-11-09 02:03:25,074 INFO     Training average loss at step 833700: 0.139100\n",
      "2022-11-09 02:03:28,185 INFO     Training average positive_sample_loss at step 833800: 0.145220\n",
      "2022-11-09 02:03:28,185 INFO     Training average negative_sample_loss at step 833800: 0.137476\n",
      "2022-11-09 02:03:28,185 INFO     Training average loss at step 833800: 0.141348\n",
      "2022-11-09 02:03:31,297 INFO     Training average positive_sample_loss at step 833900: 0.148043\n",
      "2022-11-09 02:03:31,297 INFO     Training average negative_sample_loss at step 833900: 0.134710\n",
      "2022-11-09 02:03:31,297 INFO     Training average loss at step 833900: 0.141377\n",
      "2022-11-09 02:03:34,411 INFO     Training average positive_sample_loss at step 834000: 0.143960\n",
      "2022-11-09 02:03:34,411 INFO     Training average negative_sample_loss at step 834000: 0.135321\n",
      "2022-11-09 02:03:34,411 INFO     Training average loss at step 834000: 0.139640\n",
      "2022-11-09 02:03:37,514 INFO     Training average positive_sample_loss at step 834100: 0.140673\n",
      "2022-11-09 02:03:37,514 INFO     Training average negative_sample_loss at step 834100: 0.135929\n",
      "2022-11-09 02:03:37,514 INFO     Training average loss at step 834100: 0.138301\n",
      "2022-11-09 02:03:41,620 INFO     Training average positive_sample_loss at step 834200: 0.143852\n",
      "2022-11-09 02:03:41,620 INFO     Training average negative_sample_loss at step 834200: 0.135776\n",
      "2022-11-09 02:03:41,620 INFO     Training average loss at step 834200: 0.139814\n",
      "2022-11-09 02:03:44,734 INFO     Training average positive_sample_loss at step 834300: 0.145185\n",
      "2022-11-09 02:03:44,734 INFO     Training average negative_sample_loss at step 834300: 0.135274\n",
      "2022-11-09 02:03:44,734 INFO     Training average loss at step 834300: 0.140230\n",
      "2022-11-09 02:03:49,328 INFO     Training average positive_sample_loss at step 834400: 0.143826\n",
      "2022-11-09 02:03:49,328 INFO     Training average negative_sample_loss at step 834400: 0.134748\n",
      "2022-11-09 02:03:49,328 INFO     Training average loss at step 834400: 0.139287\n",
      "2022-11-09 02:03:53,605 INFO     Training average positive_sample_loss at step 834500: 0.142172\n",
      "2022-11-09 02:03:53,605 INFO     Training average negative_sample_loss at step 834500: 0.132116\n",
      "2022-11-09 02:03:53,605 INFO     Training average loss at step 834500: 0.137144\n",
      "2022-11-09 02:03:56,715 INFO     Training average positive_sample_loss at step 834600: 0.143865\n",
      "2022-11-09 02:03:56,715 INFO     Training average negative_sample_loss at step 834600: 0.138306\n",
      "2022-11-09 02:03:56,715 INFO     Training average loss at step 834600: 0.141086\n",
      "2022-11-09 02:03:59,834 INFO     Training average positive_sample_loss at step 834700: 0.145977\n",
      "2022-11-09 02:03:59,834 INFO     Training average negative_sample_loss at step 834700: 0.140244\n",
      "2022-11-09 02:03:59,834 INFO     Training average loss at step 834700: 0.143111\n",
      "2022-11-09 02:04:02,945 INFO     Training average positive_sample_loss at step 834800: 0.147786\n",
      "2022-11-09 02:04:02,945 INFO     Training average negative_sample_loss at step 834800: 0.136652\n",
      "2022-11-09 02:04:02,945 INFO     Training average loss at step 834800: 0.142219\n",
      "2022-11-09 02:04:06,050 INFO     Training average positive_sample_loss at step 834900: 0.141071\n",
      "2022-11-09 02:04:06,050 INFO     Training average negative_sample_loss at step 834900: 0.142566\n",
      "2022-11-09 02:04:06,050 INFO     Training average loss at step 834900: 0.141819\n",
      "2022-11-09 02:04:09,165 INFO     Training average positive_sample_loss at step 835000: 0.144612\n",
      "2022-11-09 02:04:09,165 INFO     Training average negative_sample_loss at step 835000: 0.133185\n",
      "2022-11-09 02:04:09,165 INFO     Training average loss at step 835000: 0.138898\n",
      "2022-11-09 02:04:12,274 INFO     Training average positive_sample_loss at step 835100: 0.146266\n",
      "2022-11-09 02:04:12,274 INFO     Training average negative_sample_loss at step 835100: 0.137015\n",
      "2022-11-09 02:04:12,275 INFO     Training average loss at step 835100: 0.141640\n",
      "2022-11-09 02:04:15,389 INFO     Training average positive_sample_loss at step 835200: 0.144241\n",
      "2022-11-09 02:04:15,389 INFO     Training average negative_sample_loss at step 835200: 0.136692\n",
      "2022-11-09 02:04:15,389 INFO     Training average loss at step 835200: 0.140466\n",
      "2022-11-09 02:04:18,485 INFO     Training average positive_sample_loss at step 835300: 0.146009\n",
      "2022-11-09 02:04:18,485 INFO     Training average negative_sample_loss at step 835300: 0.138063\n",
      "2022-11-09 02:04:18,485 INFO     Training average loss at step 835300: 0.142036\n",
      "2022-11-09 02:04:21,600 INFO     Training average positive_sample_loss at step 835400: 0.144300\n",
      "2022-11-09 02:04:21,600 INFO     Training average negative_sample_loss at step 835400: 0.136655\n",
      "2022-11-09 02:04:21,600 INFO     Training average loss at step 835400: 0.140477\n",
      "2022-11-09 02:04:24,721 INFO     Training average positive_sample_loss at step 835500: 0.140453\n",
      "2022-11-09 02:04:24,721 INFO     Training average negative_sample_loss at step 835500: 0.135999\n",
      "2022-11-09 02:04:24,721 INFO     Training average loss at step 835500: 0.138226\n",
      "2022-11-09 02:04:27,836 INFO     Training average positive_sample_loss at step 835600: 0.140068\n",
      "2022-11-09 02:04:27,836 INFO     Training average negative_sample_loss at step 835600: 0.137513\n",
      "2022-11-09 02:04:27,836 INFO     Training average loss at step 835600: 0.138791\n",
      "2022-11-09 02:04:30,959 INFO     Training average positive_sample_loss at step 835700: 0.143732\n",
      "2022-11-09 02:04:30,959 INFO     Training average negative_sample_loss at step 835700: 0.135257\n",
      "2022-11-09 02:04:30,959 INFO     Training average loss at step 835700: 0.139494\n",
      "2022-11-09 02:04:34,073 INFO     Training average positive_sample_loss at step 835800: 0.142850\n",
      "2022-11-09 02:04:34,073 INFO     Training average negative_sample_loss at step 835800: 0.135114\n",
      "2022-11-09 02:04:34,073 INFO     Training average loss at step 835800: 0.138982\n",
      "2022-11-09 02:04:37,186 INFO     Training average positive_sample_loss at step 835900: 0.141946\n",
      "2022-11-09 02:04:37,186 INFO     Training average negative_sample_loss at step 835900: 0.137035\n",
      "2022-11-09 02:04:37,186 INFO     Training average loss at step 835900: 0.139490\n",
      "2022-11-09 02:04:40,287 INFO     Training average positive_sample_loss at step 836000: 0.145315\n",
      "2022-11-09 02:04:40,287 INFO     Training average negative_sample_loss at step 836000: 0.137467\n",
      "2022-11-09 02:04:40,287 INFO     Training average loss at step 836000: 0.141391\n",
      "2022-11-09 02:04:43,405 INFO     Training average positive_sample_loss at step 836100: 0.142684\n",
      "2022-11-09 02:04:43,405 INFO     Training average negative_sample_loss at step 836100: 0.133544\n",
      "2022-11-09 02:04:43,405 INFO     Training average loss at step 836100: 0.138114\n",
      "2022-11-09 02:04:46,524 INFO     Training average positive_sample_loss at step 836200: 0.143113\n",
      "2022-11-09 02:04:46,524 INFO     Training average negative_sample_loss at step 836200: 0.139447\n",
      "2022-11-09 02:04:46,524 INFO     Training average loss at step 836200: 0.141280\n",
      "2022-11-09 02:04:49,632 INFO     Training average positive_sample_loss at step 836300: 0.143387\n",
      "2022-11-09 02:04:49,632 INFO     Training average negative_sample_loss at step 836300: 0.135379\n",
      "2022-11-09 02:04:49,632 INFO     Training average loss at step 836300: 0.139383\n",
      "2022-11-09 02:04:52,724 INFO     Training average positive_sample_loss at step 836400: 0.142411\n",
      "2022-11-09 02:04:52,724 INFO     Training average negative_sample_loss at step 836400: 0.138441\n",
      "2022-11-09 02:04:52,724 INFO     Training average loss at step 836400: 0.140426\n",
      "2022-11-09 02:04:55,845 INFO     Training average positive_sample_loss at step 836500: 0.141623\n",
      "2022-11-09 02:04:55,845 INFO     Training average negative_sample_loss at step 836500: 0.134088\n",
      "2022-11-09 02:04:55,845 INFO     Training average loss at step 836500: 0.137856\n",
      "2022-11-09 02:04:58,960 INFO     Training average positive_sample_loss at step 836600: 0.141104\n",
      "2022-11-09 02:04:58,961 INFO     Training average negative_sample_loss at step 836600: 0.134935\n",
      "2022-11-09 02:04:58,961 INFO     Training average loss at step 836600: 0.138020\n",
      "2022-11-09 02:05:02,079 INFO     Training average positive_sample_loss at step 836700: 0.143075\n",
      "2022-11-09 02:05:02,079 INFO     Training average negative_sample_loss at step 836700: 0.138399\n",
      "2022-11-09 02:05:02,079 INFO     Training average loss at step 836700: 0.140737\n",
      "2022-11-09 02:05:05,178 INFO     Training average positive_sample_loss at step 836800: 0.139870\n",
      "2022-11-09 02:05:05,178 INFO     Training average negative_sample_loss at step 836800: 0.137048\n",
      "2022-11-09 02:05:05,178 INFO     Training average loss at step 836800: 0.138459\n",
      "2022-11-09 02:05:08,292 INFO     Training average positive_sample_loss at step 836900: 0.144352\n",
      "2022-11-09 02:05:08,292 INFO     Training average negative_sample_loss at step 836900: 0.137528\n",
      "2022-11-09 02:05:08,292 INFO     Training average loss at step 836900: 0.140940\n",
      "2022-11-09 02:05:11,400 INFO     Training average positive_sample_loss at step 837000: 0.143359\n",
      "2022-11-09 02:05:11,400 INFO     Training average negative_sample_loss at step 837000: 0.134560\n",
      "2022-11-09 02:05:11,400 INFO     Training average loss at step 837000: 0.138959\n",
      "2022-11-09 02:05:14,503 INFO     Training average positive_sample_loss at step 837100: 0.141783\n",
      "2022-11-09 02:05:14,503 INFO     Training average negative_sample_loss at step 837100: 0.136718\n",
      "2022-11-09 02:05:14,503 INFO     Training average loss at step 837100: 0.139251\n",
      "2022-11-09 02:05:17,626 INFO     Training average positive_sample_loss at step 837200: 0.144812\n",
      "2022-11-09 02:05:17,626 INFO     Training average negative_sample_loss at step 837200: 0.139654\n",
      "2022-11-09 02:05:17,626 INFO     Training average loss at step 837200: 0.142233\n",
      "2022-11-09 02:05:20,735 INFO     Training average positive_sample_loss at step 837300: 0.139836\n",
      "2022-11-09 02:05:20,735 INFO     Training average negative_sample_loss at step 837300: 0.136148\n",
      "2022-11-09 02:05:20,735 INFO     Training average loss at step 837300: 0.137992\n",
      "2022-11-09 02:05:23,848 INFO     Training average positive_sample_loss at step 837400: 0.140814\n",
      "2022-11-09 02:05:23,848 INFO     Training average negative_sample_loss at step 837400: 0.135457\n",
      "2022-11-09 02:05:23,848 INFO     Training average loss at step 837400: 0.138136\n",
      "2022-11-09 02:05:26,962 INFO     Training average positive_sample_loss at step 837500: 0.145509\n",
      "2022-11-09 02:05:26,962 INFO     Training average negative_sample_loss at step 837500: 0.140814\n",
      "2022-11-09 02:05:26,962 INFO     Training average loss at step 837500: 0.143162\n",
      "2022-11-09 02:05:30,075 INFO     Training average positive_sample_loss at step 837600: 0.142450\n",
      "2022-11-09 02:05:30,075 INFO     Training average negative_sample_loss at step 837600: 0.139731\n",
      "2022-11-09 02:05:30,075 INFO     Training average loss at step 837600: 0.141090\n",
      "2022-11-09 02:05:33,179 INFO     Training average positive_sample_loss at step 837700: 0.146331\n",
      "2022-11-09 02:05:33,179 INFO     Training average negative_sample_loss at step 837700: 0.133392\n",
      "2022-11-09 02:05:33,179 INFO     Training average loss at step 837700: 0.139861\n",
      "2022-11-09 02:05:36,277 INFO     Training average positive_sample_loss at step 837800: 0.138741\n",
      "2022-11-09 02:05:36,277 INFO     Training average negative_sample_loss at step 837800: 0.137623\n",
      "2022-11-09 02:05:36,277 INFO     Training average loss at step 837800: 0.138182\n",
      "2022-11-09 02:05:39,393 INFO     Training average positive_sample_loss at step 837900: 0.148677\n",
      "2022-11-09 02:05:39,393 INFO     Training average negative_sample_loss at step 837900: 0.136901\n",
      "2022-11-09 02:05:39,393 INFO     Training average loss at step 837900: 0.142789\n",
      "2022-11-09 02:05:42,509 INFO     Training average positive_sample_loss at step 838000: 0.146364\n",
      "2022-11-09 02:05:42,509 INFO     Training average negative_sample_loss at step 838000: 0.135440\n",
      "2022-11-09 02:05:42,509 INFO     Training average loss at step 838000: 0.140902\n",
      "2022-11-09 02:05:45,604 INFO     Training average positive_sample_loss at step 838100: 0.141704\n",
      "2022-11-09 02:05:45,604 INFO     Training average negative_sample_loss at step 838100: 0.138122\n",
      "2022-11-09 02:05:45,604 INFO     Training average loss at step 838100: 0.139913\n",
      "2022-11-09 02:05:48,714 INFO     Training average positive_sample_loss at step 838200: 0.145784\n",
      "2022-11-09 02:05:48,714 INFO     Training average negative_sample_loss at step 838200: 0.136255\n",
      "2022-11-09 02:05:48,714 INFO     Training average loss at step 838200: 0.141019\n",
      "2022-11-09 02:05:51,828 INFO     Training average positive_sample_loss at step 838300: 0.138544\n",
      "2022-11-09 02:05:51,828 INFO     Training average negative_sample_loss at step 838300: 0.137463\n",
      "2022-11-09 02:05:51,828 INFO     Training average loss at step 838300: 0.138004\n",
      "2022-11-09 02:05:54,935 INFO     Training average positive_sample_loss at step 838400: 0.141734\n",
      "2022-11-09 02:05:54,936 INFO     Training average negative_sample_loss at step 838400: 0.136582\n",
      "2022-11-09 02:05:54,936 INFO     Training average loss at step 838400: 0.139158\n",
      "2022-11-09 02:05:58,046 INFO     Training average positive_sample_loss at step 838500: 0.146767\n",
      "2022-11-09 02:05:58,046 INFO     Training average negative_sample_loss at step 838500: 0.136882\n",
      "2022-11-09 02:05:58,046 INFO     Training average loss at step 838500: 0.141824\n",
      "2022-11-09 02:06:01,151 INFO     Training average positive_sample_loss at step 838600: 0.147320\n",
      "2022-11-09 02:06:01,151 INFO     Training average negative_sample_loss at step 838600: 0.139783\n",
      "2022-11-09 02:06:01,151 INFO     Training average loss at step 838600: 0.143551\n",
      "2022-11-09 02:06:04,242 INFO     Training average positive_sample_loss at step 838700: 0.143659\n",
      "2022-11-09 02:06:04,242 INFO     Training average negative_sample_loss at step 838700: 0.141231\n",
      "2022-11-09 02:06:04,242 INFO     Training average loss at step 838700: 0.142445\n",
      "2022-11-09 02:06:07,355 INFO     Training average positive_sample_loss at step 838800: 0.146318\n",
      "2022-11-09 02:06:07,355 INFO     Training average negative_sample_loss at step 838800: 0.134626\n",
      "2022-11-09 02:06:07,356 INFO     Training average loss at step 838800: 0.140472\n",
      "2022-11-09 02:06:11,746 INFO     Training average positive_sample_loss at step 838900: 0.144830\n",
      "2022-11-09 02:06:11,746 INFO     Training average negative_sample_loss at step 838900: 0.134385\n",
      "2022-11-09 02:06:11,746 INFO     Training average loss at step 838900: 0.139607\n",
      "2022-11-09 02:06:14,858 INFO     Training average positive_sample_loss at step 839000: 0.144910\n",
      "2022-11-09 02:06:14,858 INFO     Training average negative_sample_loss at step 839000: 0.137056\n",
      "2022-11-09 02:06:14,858 INFO     Training average loss at step 839000: 0.140983\n",
      "2022-11-09 02:06:19,665 INFO     Training average positive_sample_loss at step 839100: 0.143540\n",
      "2022-11-09 02:06:19,665 INFO     Training average negative_sample_loss at step 839100: 0.133634\n",
      "2022-11-09 02:06:19,665 INFO     Training average loss at step 839100: 0.138587\n",
      "2022-11-09 02:06:22,780 INFO     Training average positive_sample_loss at step 839200: 0.144199\n",
      "2022-11-09 02:06:22,780 INFO     Training average negative_sample_loss at step 839200: 0.133365\n",
      "2022-11-09 02:06:22,780 INFO     Training average loss at step 839200: 0.138782\n",
      "2022-11-09 02:06:25,878 INFO     Training average positive_sample_loss at step 839300: 0.140233\n",
      "2022-11-09 02:06:25,879 INFO     Training average negative_sample_loss at step 839300: 0.134669\n",
      "2022-11-09 02:06:25,879 INFO     Training average loss at step 839300: 0.137451\n",
      "2022-11-09 02:06:28,981 INFO     Training average positive_sample_loss at step 839400: 0.147675\n",
      "2022-11-09 02:06:28,981 INFO     Training average negative_sample_loss at step 839400: 0.138159\n",
      "2022-11-09 02:06:28,981 INFO     Training average loss at step 839400: 0.142917\n",
      "2022-11-09 02:06:32,085 INFO     Training average positive_sample_loss at step 839500: 0.143895\n",
      "2022-11-09 02:06:32,085 INFO     Training average negative_sample_loss at step 839500: 0.138477\n",
      "2022-11-09 02:06:32,085 INFO     Training average loss at step 839500: 0.141186\n",
      "2022-11-09 02:06:35,192 INFO     Training average positive_sample_loss at step 839600: 0.141908\n",
      "2022-11-09 02:06:35,192 INFO     Training average negative_sample_loss at step 839600: 0.138920\n",
      "2022-11-09 02:06:35,192 INFO     Training average loss at step 839600: 0.140414\n",
      "2022-11-09 02:06:38,307 INFO     Training average positive_sample_loss at step 839700: 0.147029\n",
      "2022-11-09 02:06:38,307 INFO     Training average negative_sample_loss at step 839700: 0.136310\n",
      "2022-11-09 02:06:38,307 INFO     Training average loss at step 839700: 0.141669\n",
      "2022-11-09 02:06:41,410 INFO     Training average positive_sample_loss at step 839800: 0.142999\n",
      "2022-11-09 02:06:41,411 INFO     Training average negative_sample_loss at step 839800: 0.133520\n",
      "2022-11-09 02:06:41,411 INFO     Training average loss at step 839800: 0.138259\n",
      "2022-11-09 02:06:44,496 INFO     Training average positive_sample_loss at step 839900: 0.143034\n",
      "2022-11-09 02:06:44,496 INFO     Training average negative_sample_loss at step 839900: 0.138052\n",
      "2022-11-09 02:06:44,496 INFO     Training average loss at step 839900: 0.140543\n",
      "2022-11-09 02:06:50,428 INFO     Training average positive_sample_loss at step 840000: 0.141943\n",
      "2022-11-09 02:06:50,428 INFO     Training average negative_sample_loss at step 840000: 0.141016\n",
      "2022-11-09 02:06:50,428 INFO     Training average loss at step 840000: 0.141479\n",
      "2022-11-09 02:06:53,543 INFO     Training average positive_sample_loss at step 840100: 0.147308\n",
      "2022-11-09 02:06:53,543 INFO     Training average negative_sample_loss at step 840100: 0.134386\n",
      "2022-11-09 02:06:53,543 INFO     Training average loss at step 840100: 0.140847\n",
      "2022-11-09 02:06:56,655 INFO     Training average positive_sample_loss at step 840200: 0.140913\n",
      "2022-11-09 02:06:56,655 INFO     Training average negative_sample_loss at step 840200: 0.135583\n",
      "2022-11-09 02:06:56,655 INFO     Training average loss at step 840200: 0.138248\n",
      "2022-11-09 02:06:59,765 INFO     Training average positive_sample_loss at step 840300: 0.142285\n",
      "2022-11-09 02:06:59,765 INFO     Training average negative_sample_loss at step 840300: 0.135895\n",
      "2022-11-09 02:06:59,765 INFO     Training average loss at step 840300: 0.139090\n",
      "2022-11-09 02:07:02,867 INFO     Training average positive_sample_loss at step 840400: 0.142747\n",
      "2022-11-09 02:07:02,867 INFO     Training average negative_sample_loss at step 840400: 0.139070\n",
      "2022-11-09 02:07:02,867 INFO     Training average loss at step 840400: 0.140908\n",
      "2022-11-09 02:07:05,959 INFO     Training average positive_sample_loss at step 840500: 0.147669\n",
      "2022-11-09 02:07:05,959 INFO     Training average negative_sample_loss at step 840500: 0.134672\n",
      "2022-11-09 02:07:05,959 INFO     Training average loss at step 840500: 0.141170\n",
      "2022-11-09 02:07:09,049 INFO     Training average positive_sample_loss at step 840600: 0.145717\n",
      "2022-11-09 02:07:09,049 INFO     Training average negative_sample_loss at step 840600: 0.135377\n",
      "2022-11-09 02:07:09,049 INFO     Training average loss at step 840600: 0.140547\n",
      "2022-11-09 02:07:12,150 INFO     Training average positive_sample_loss at step 840700: 0.144167\n",
      "2022-11-09 02:07:12,150 INFO     Training average negative_sample_loss at step 840700: 0.138798\n",
      "2022-11-09 02:07:12,150 INFO     Training average loss at step 840700: 0.141483\n",
      "2022-11-09 02:07:15,257 INFO     Training average positive_sample_loss at step 840800: 0.140714\n",
      "2022-11-09 02:07:15,257 INFO     Training average negative_sample_loss at step 840800: 0.139499\n",
      "2022-11-09 02:07:15,257 INFO     Training average loss at step 840800: 0.140106\n",
      "2022-11-09 02:07:18,359 INFO     Training average positive_sample_loss at step 840900: 0.145385\n",
      "2022-11-09 02:07:18,359 INFO     Training average negative_sample_loss at step 840900: 0.137582\n",
      "2022-11-09 02:07:18,359 INFO     Training average loss at step 840900: 0.141483\n",
      "2022-11-09 02:07:21,454 INFO     Training average positive_sample_loss at step 841000: 0.139828\n",
      "2022-11-09 02:07:21,454 INFO     Training average negative_sample_loss at step 841000: 0.133917\n",
      "2022-11-09 02:07:21,454 INFO     Training average loss at step 841000: 0.136873\n",
      "2022-11-09 02:07:24,562 INFO     Training average positive_sample_loss at step 841100: 0.143993\n",
      "2022-11-09 02:07:24,562 INFO     Training average negative_sample_loss at step 841100: 0.138623\n",
      "2022-11-09 02:07:24,562 INFO     Training average loss at step 841100: 0.141308\n",
      "2022-11-09 02:07:27,680 INFO     Training average positive_sample_loss at step 841200: 0.145376\n",
      "2022-11-09 02:07:27,680 INFO     Training average negative_sample_loss at step 841200: 0.129707\n",
      "2022-11-09 02:07:27,680 INFO     Training average loss at step 841200: 0.137542\n",
      "2022-11-09 02:07:30,784 INFO     Training average positive_sample_loss at step 841300: 0.148678\n",
      "2022-11-09 02:07:30,784 INFO     Training average negative_sample_loss at step 841300: 0.138558\n",
      "2022-11-09 02:07:30,784 INFO     Training average loss at step 841300: 0.143618\n",
      "2022-11-09 02:07:33,894 INFO     Training average positive_sample_loss at step 841400: 0.146285\n",
      "2022-11-09 02:07:33,894 INFO     Training average negative_sample_loss at step 841400: 0.133709\n",
      "2022-11-09 02:07:33,894 INFO     Training average loss at step 841400: 0.139997\n",
      "2022-11-09 02:07:36,992 INFO     Training average positive_sample_loss at step 841500: 0.146126\n",
      "2022-11-09 02:07:36,992 INFO     Training average negative_sample_loss at step 841500: 0.140808\n",
      "2022-11-09 02:07:36,992 INFO     Training average loss at step 841500: 0.143467\n",
      "2022-11-09 02:07:40,092 INFO     Training average positive_sample_loss at step 841600: 0.142419\n",
      "2022-11-09 02:07:40,092 INFO     Training average negative_sample_loss at step 841600: 0.139398\n",
      "2022-11-09 02:07:40,092 INFO     Training average loss at step 841600: 0.140909\n",
      "2022-11-09 02:07:43,192 INFO     Training average positive_sample_loss at step 841700: 0.140721\n",
      "2022-11-09 02:07:43,192 INFO     Training average negative_sample_loss at step 841700: 0.138128\n",
      "2022-11-09 02:07:43,192 INFO     Training average loss at step 841700: 0.139425\n",
      "2022-11-09 02:07:46,291 INFO     Training average positive_sample_loss at step 841800: 0.142244\n",
      "2022-11-09 02:07:46,292 INFO     Training average negative_sample_loss at step 841800: 0.135938\n",
      "2022-11-09 02:07:46,292 INFO     Training average loss at step 841800: 0.139091\n",
      "2022-11-09 02:07:49,406 INFO     Training average positive_sample_loss at step 841900: 0.148169\n",
      "2022-11-09 02:07:49,406 INFO     Training average negative_sample_loss at step 841900: 0.138027\n",
      "2022-11-09 02:07:49,406 INFO     Training average loss at step 841900: 0.143098\n",
      "2022-11-09 02:07:52,510 INFO     Training average positive_sample_loss at step 842000: 0.141857\n",
      "2022-11-09 02:07:52,510 INFO     Training average negative_sample_loss at step 842000: 0.133932\n",
      "2022-11-09 02:07:52,510 INFO     Training average loss at step 842000: 0.137895\n",
      "2022-11-09 02:07:55,621 INFO     Training average positive_sample_loss at step 842100: 0.147284\n",
      "2022-11-09 02:07:55,621 INFO     Training average negative_sample_loss at step 842100: 0.139568\n",
      "2022-11-09 02:07:55,621 INFO     Training average loss at step 842100: 0.143426\n",
      "2022-11-09 02:07:58,726 INFO     Training average positive_sample_loss at step 842200: 0.139102\n",
      "2022-11-09 02:07:58,726 INFO     Training average negative_sample_loss at step 842200: 0.139373\n",
      "2022-11-09 02:07:58,726 INFO     Training average loss at step 842200: 0.139237\n",
      "2022-11-09 02:08:01,832 INFO     Training average positive_sample_loss at step 842300: 0.144860\n",
      "2022-11-09 02:08:01,832 INFO     Training average negative_sample_loss at step 842300: 0.137339\n",
      "2022-11-09 02:08:01,832 INFO     Training average loss at step 842300: 0.141100\n",
      "2022-11-09 02:08:04,933 INFO     Training average positive_sample_loss at step 842400: 0.147781\n",
      "2022-11-09 02:08:04,933 INFO     Training average negative_sample_loss at step 842400: 0.136234\n",
      "2022-11-09 02:08:04,933 INFO     Training average loss at step 842400: 0.142007\n",
      "2022-11-09 02:08:08,042 INFO     Training average positive_sample_loss at step 842500: 0.142648\n",
      "2022-11-09 02:08:08,042 INFO     Training average negative_sample_loss at step 842500: 0.140815\n",
      "2022-11-09 02:08:08,042 INFO     Training average loss at step 842500: 0.141732\n",
      "2022-11-09 02:08:11,145 INFO     Training average positive_sample_loss at step 842600: 0.146300\n",
      "2022-11-09 02:08:11,145 INFO     Training average negative_sample_loss at step 842600: 0.139122\n",
      "2022-11-09 02:08:11,145 INFO     Training average loss at step 842600: 0.142711\n",
      "2022-11-09 02:08:14,261 INFO     Training average positive_sample_loss at step 842700: 0.140594\n",
      "2022-11-09 02:08:14,261 INFO     Training average negative_sample_loss at step 842700: 0.132002\n",
      "2022-11-09 02:08:14,261 INFO     Training average loss at step 842700: 0.136298\n",
      "2022-11-09 02:08:17,376 INFO     Training average positive_sample_loss at step 842800: 0.141621\n",
      "2022-11-09 02:08:17,377 INFO     Training average negative_sample_loss at step 842800: 0.138461\n",
      "2022-11-09 02:08:17,377 INFO     Training average loss at step 842800: 0.140041\n",
      "2022-11-09 02:08:20,485 INFO     Training average positive_sample_loss at step 842900: 0.144870\n",
      "2022-11-09 02:08:20,486 INFO     Training average negative_sample_loss at step 842900: 0.136667\n",
      "2022-11-09 02:08:20,486 INFO     Training average loss at step 842900: 0.140768\n",
      "2022-11-09 02:08:23,604 INFO     Training average positive_sample_loss at step 843000: 0.141133\n",
      "2022-11-09 02:08:23,604 INFO     Training average negative_sample_loss at step 843000: 0.137646\n",
      "2022-11-09 02:08:23,604 INFO     Training average loss at step 843000: 0.139390\n",
      "2022-11-09 02:08:26,715 INFO     Training average positive_sample_loss at step 843100: 0.145069\n",
      "2022-11-09 02:08:26,715 INFO     Training average negative_sample_loss at step 843100: 0.139081\n",
      "2022-11-09 02:08:26,715 INFO     Training average loss at step 843100: 0.142075\n",
      "2022-11-09 02:08:29,821 INFO     Training average positive_sample_loss at step 843200: 0.144416\n",
      "2022-11-09 02:08:29,821 INFO     Training average negative_sample_loss at step 843200: 0.132935\n",
      "2022-11-09 02:08:29,821 INFO     Training average loss at step 843200: 0.138676\n",
      "2022-11-09 02:08:32,927 INFO     Training average positive_sample_loss at step 843300: 0.141587\n",
      "2022-11-09 02:08:32,927 INFO     Training average negative_sample_loss at step 843300: 0.141170\n",
      "2022-11-09 02:08:32,927 INFO     Training average loss at step 843300: 0.141378\n",
      "2022-11-09 02:08:36,027 INFO     Training average positive_sample_loss at step 843400: 0.139953\n",
      "2022-11-09 02:08:36,027 INFO     Training average negative_sample_loss at step 843400: 0.136298\n",
      "2022-11-09 02:08:36,028 INFO     Training average loss at step 843400: 0.138125\n",
      "2022-11-09 02:08:40,381 INFO     Training average positive_sample_loss at step 843500: 0.144086\n",
      "2022-11-09 02:08:40,381 INFO     Training average negative_sample_loss at step 843500: 0.137554\n",
      "2022-11-09 02:08:40,381 INFO     Training average loss at step 843500: 0.140820\n",
      "2022-11-09 02:08:44,782 INFO     Training average positive_sample_loss at step 843600: 0.149473\n",
      "2022-11-09 02:08:44,783 INFO     Training average negative_sample_loss at step 843600: 0.136105\n",
      "2022-11-09 02:08:44,783 INFO     Training average loss at step 843600: 0.142789\n",
      "2022-11-09 02:08:48,832 INFO     Training average positive_sample_loss at step 843700: 0.143765\n",
      "2022-11-09 02:08:48,832 INFO     Training average negative_sample_loss at step 843700: 0.139582\n",
      "2022-11-09 02:08:48,832 INFO     Training average loss at step 843700: 0.141674\n",
      "2022-11-09 02:08:51,926 INFO     Training average positive_sample_loss at step 843800: 0.143523\n",
      "2022-11-09 02:08:51,926 INFO     Training average negative_sample_loss at step 843800: 0.138045\n",
      "2022-11-09 02:08:51,926 INFO     Training average loss at step 843800: 0.140784\n",
      "2022-11-09 02:08:55,039 INFO     Training average positive_sample_loss at step 843900: 0.143067\n",
      "2022-11-09 02:08:55,039 INFO     Training average negative_sample_loss at step 843900: 0.138857\n",
      "2022-11-09 02:08:55,039 INFO     Training average loss at step 843900: 0.140962\n",
      "2022-11-09 02:08:58,149 INFO     Training average positive_sample_loss at step 844000: 0.145774\n",
      "2022-11-09 02:08:58,149 INFO     Training average negative_sample_loss at step 844000: 0.137153\n",
      "2022-11-09 02:08:58,149 INFO     Training average loss at step 844000: 0.141463\n",
      "2022-11-09 02:09:01,240 INFO     Training average positive_sample_loss at step 844100: 0.147050\n",
      "2022-11-09 02:09:01,240 INFO     Training average negative_sample_loss at step 844100: 0.136053\n",
      "2022-11-09 02:09:01,241 INFO     Training average loss at step 844100: 0.141551\n",
      "2022-11-09 02:09:04,349 INFO     Training average positive_sample_loss at step 844200: 0.145096\n",
      "2022-11-09 02:09:04,349 INFO     Training average negative_sample_loss at step 844200: 0.140928\n",
      "2022-11-09 02:09:04,349 INFO     Training average loss at step 844200: 0.143012\n",
      "2022-11-09 02:09:07,454 INFO     Training average positive_sample_loss at step 844300: 0.143933\n",
      "2022-11-09 02:09:07,454 INFO     Training average negative_sample_loss at step 844300: 0.138541\n",
      "2022-11-09 02:09:07,454 INFO     Training average loss at step 844300: 0.141237\n",
      "2022-11-09 02:09:10,564 INFO     Training average positive_sample_loss at step 844400: 0.146950\n",
      "2022-11-09 02:09:10,564 INFO     Training average negative_sample_loss at step 844400: 0.140417\n",
      "2022-11-09 02:09:10,564 INFO     Training average loss at step 844400: 0.143683\n",
      "2022-11-09 02:09:13,669 INFO     Training average positive_sample_loss at step 844500: 0.144266\n",
      "2022-11-09 02:09:13,669 INFO     Training average negative_sample_loss at step 844500: 0.137314\n",
      "2022-11-09 02:09:13,669 INFO     Training average loss at step 844500: 0.140790\n",
      "2022-11-09 02:09:16,771 INFO     Training average positive_sample_loss at step 844600: 0.145102\n",
      "2022-11-09 02:09:16,772 INFO     Training average negative_sample_loss at step 844600: 0.137250\n",
      "2022-11-09 02:09:16,772 INFO     Training average loss at step 844600: 0.141176\n",
      "2022-11-09 02:09:19,867 INFO     Training average positive_sample_loss at step 844700: 0.143833\n",
      "2022-11-09 02:09:19,867 INFO     Training average negative_sample_loss at step 844700: 0.136513\n",
      "2022-11-09 02:09:19,867 INFO     Training average loss at step 844700: 0.140173\n",
      "2022-11-09 02:09:22,966 INFO     Training average positive_sample_loss at step 844800: 0.140220\n",
      "2022-11-09 02:09:22,966 INFO     Training average negative_sample_loss at step 844800: 0.139695\n",
      "2022-11-09 02:09:22,966 INFO     Training average loss at step 844800: 0.139958\n",
      "2022-11-09 02:09:26,061 INFO     Training average positive_sample_loss at step 844900: 0.144250\n",
      "2022-11-09 02:09:26,061 INFO     Training average negative_sample_loss at step 844900: 0.134806\n",
      "2022-11-09 02:09:26,061 INFO     Training average loss at step 844900: 0.139528\n",
      "2022-11-09 02:09:29,168 INFO     Training average positive_sample_loss at step 845000: 0.142994\n",
      "2022-11-09 02:09:29,168 INFO     Training average negative_sample_loss at step 845000: 0.137187\n",
      "2022-11-09 02:09:29,168 INFO     Training average loss at step 845000: 0.140090\n",
      "2022-11-09 02:09:32,274 INFO     Training average positive_sample_loss at step 845100: 0.143151\n",
      "2022-11-09 02:09:32,274 INFO     Training average negative_sample_loss at step 845100: 0.139179\n",
      "2022-11-09 02:09:32,274 INFO     Training average loss at step 845100: 0.141165\n",
      "2022-11-09 02:09:35,378 INFO     Training average positive_sample_loss at step 845200: 0.139056\n",
      "2022-11-09 02:09:35,378 INFO     Training average negative_sample_loss at step 845200: 0.137125\n",
      "2022-11-09 02:09:35,378 INFO     Training average loss at step 845200: 0.138091\n",
      "2022-11-09 02:09:38,478 INFO     Training average positive_sample_loss at step 845300: 0.142551\n",
      "2022-11-09 02:09:38,478 INFO     Training average negative_sample_loss at step 845300: 0.136826\n",
      "2022-11-09 02:09:38,478 INFO     Training average loss at step 845300: 0.139689\n",
      "2022-11-09 02:09:41,575 INFO     Training average positive_sample_loss at step 845400: 0.141648\n",
      "2022-11-09 02:09:41,575 INFO     Training average negative_sample_loss at step 845400: 0.134672\n",
      "2022-11-09 02:09:41,575 INFO     Training average loss at step 845400: 0.138160\n",
      "2022-11-09 02:09:44,674 INFO     Training average positive_sample_loss at step 845500: 0.146331\n",
      "2022-11-09 02:09:44,674 INFO     Training average negative_sample_loss at step 845500: 0.135561\n",
      "2022-11-09 02:09:44,674 INFO     Training average loss at step 845500: 0.140946\n",
      "2022-11-09 02:09:47,775 INFO     Training average positive_sample_loss at step 845600: 0.141527\n",
      "2022-11-09 02:09:47,775 INFO     Training average negative_sample_loss at step 845600: 0.133976\n",
      "2022-11-09 02:09:47,775 INFO     Training average loss at step 845600: 0.137752\n",
      "2022-11-09 02:09:50,881 INFO     Training average positive_sample_loss at step 845700: 0.142963\n",
      "2022-11-09 02:09:50,882 INFO     Training average negative_sample_loss at step 845700: 0.140946\n",
      "2022-11-09 02:09:50,882 INFO     Training average loss at step 845700: 0.141955\n",
      "2022-11-09 02:09:53,990 INFO     Training average positive_sample_loss at step 845800: 0.140336\n",
      "2022-11-09 02:09:53,990 INFO     Training average negative_sample_loss at step 845800: 0.140013\n",
      "2022-11-09 02:09:53,990 INFO     Training average loss at step 845800: 0.140174\n",
      "2022-11-09 02:09:57,098 INFO     Training average positive_sample_loss at step 845900: 0.151907\n",
      "2022-11-09 02:09:57,098 INFO     Training average negative_sample_loss at step 845900: 0.140232\n",
      "2022-11-09 02:09:57,098 INFO     Training average loss at step 845900: 0.146069\n",
      "2022-11-09 02:10:00,177 INFO     Training average positive_sample_loss at step 846000: 0.139892\n",
      "2022-11-09 02:10:00,177 INFO     Training average negative_sample_loss at step 846000: 0.135147\n",
      "2022-11-09 02:10:00,177 INFO     Training average loss at step 846000: 0.137519\n",
      "2022-11-09 02:10:03,269 INFO     Training average positive_sample_loss at step 846100: 0.143609\n",
      "2022-11-09 02:10:03,269 INFO     Training average negative_sample_loss at step 846100: 0.136883\n",
      "2022-11-09 02:10:03,269 INFO     Training average loss at step 846100: 0.140246\n",
      "2022-11-09 02:10:06,387 INFO     Training average positive_sample_loss at step 846200: 0.145036\n",
      "2022-11-09 02:10:06,387 INFO     Training average negative_sample_loss at step 846200: 0.139836\n",
      "2022-11-09 02:10:06,387 INFO     Training average loss at step 846200: 0.142436\n",
      "2022-11-09 02:10:09,498 INFO     Training average positive_sample_loss at step 846300: 0.142288\n",
      "2022-11-09 02:10:09,498 INFO     Training average negative_sample_loss at step 846300: 0.140321\n",
      "2022-11-09 02:10:09,498 INFO     Training average loss at step 846300: 0.141305\n",
      "2022-11-09 02:10:12,609 INFO     Training average positive_sample_loss at step 846400: 0.143119\n",
      "2022-11-09 02:10:12,609 INFO     Training average negative_sample_loss at step 846400: 0.139859\n",
      "2022-11-09 02:10:12,609 INFO     Training average loss at step 846400: 0.141489\n",
      "2022-11-09 02:10:15,720 INFO     Training average positive_sample_loss at step 846500: 0.142709\n",
      "2022-11-09 02:10:15,720 INFO     Training average negative_sample_loss at step 846500: 0.132514\n",
      "2022-11-09 02:10:15,720 INFO     Training average loss at step 846500: 0.137611\n",
      "2022-11-09 02:10:18,826 INFO     Training average positive_sample_loss at step 846600: 0.146610\n",
      "2022-11-09 02:10:18,826 INFO     Training average negative_sample_loss at step 846600: 0.136093\n",
      "2022-11-09 02:10:18,826 INFO     Training average loss at step 846600: 0.141351\n",
      "2022-11-09 02:10:21,940 INFO     Training average positive_sample_loss at step 846700: 0.140019\n",
      "2022-11-09 02:10:21,940 INFO     Training average negative_sample_loss at step 846700: 0.138526\n",
      "2022-11-09 02:10:21,940 INFO     Training average loss at step 846700: 0.139273\n",
      "2022-11-09 02:10:25,053 INFO     Training average positive_sample_loss at step 846800: 0.146251\n",
      "2022-11-09 02:10:25,053 INFO     Training average negative_sample_loss at step 846800: 0.141057\n",
      "2022-11-09 02:10:25,053 INFO     Training average loss at step 846800: 0.143654\n",
      "2022-11-09 02:10:28,161 INFO     Training average positive_sample_loss at step 846900: 0.144905\n",
      "2022-11-09 02:10:28,161 INFO     Training average negative_sample_loss at step 846900: 0.142366\n",
      "2022-11-09 02:10:28,161 INFO     Training average loss at step 846900: 0.143635\n",
      "2022-11-09 02:10:31,254 INFO     Training average positive_sample_loss at step 847000: 0.144358\n",
      "2022-11-09 02:10:31,254 INFO     Training average negative_sample_loss at step 847000: 0.140919\n",
      "2022-11-09 02:10:31,254 INFO     Training average loss at step 847000: 0.142638\n",
      "2022-11-09 02:10:34,367 INFO     Training average positive_sample_loss at step 847100: 0.150050\n",
      "2022-11-09 02:10:34,367 INFO     Training average negative_sample_loss at step 847100: 0.140980\n",
      "2022-11-09 02:10:34,367 INFO     Training average loss at step 847100: 0.145515\n",
      "2022-11-09 02:10:37,478 INFO     Training average positive_sample_loss at step 847200: 0.143632\n",
      "2022-11-09 02:10:37,478 INFO     Training average negative_sample_loss at step 847200: 0.134458\n",
      "2022-11-09 02:10:37,478 INFO     Training average loss at step 847200: 0.139045\n",
      "2022-11-09 02:10:40,586 INFO     Training average positive_sample_loss at step 847300: 0.140483\n",
      "2022-11-09 02:10:40,586 INFO     Training average negative_sample_loss at step 847300: 0.140794\n",
      "2022-11-09 02:10:40,586 INFO     Training average loss at step 847300: 0.140638\n",
      "2022-11-09 02:10:43,688 INFO     Training average positive_sample_loss at step 847400: 0.143184\n",
      "2022-11-09 02:10:43,689 INFO     Training average negative_sample_loss at step 847400: 0.140242\n",
      "2022-11-09 02:10:43,689 INFO     Training average loss at step 847400: 0.141713\n",
      "2022-11-09 02:10:46,790 INFO     Training average positive_sample_loss at step 847500: 0.142245\n",
      "2022-11-09 02:10:46,790 INFO     Training average negative_sample_loss at step 847500: 0.134763\n",
      "2022-11-09 02:10:46,790 INFO     Training average loss at step 847500: 0.138504\n",
      "2022-11-09 02:10:49,891 INFO     Training average positive_sample_loss at step 847600: 0.145082\n",
      "2022-11-09 02:10:49,891 INFO     Training average negative_sample_loss at step 847600: 0.139664\n",
      "2022-11-09 02:10:49,891 INFO     Training average loss at step 847600: 0.142373\n",
      "2022-11-09 02:10:53,007 INFO     Training average positive_sample_loss at step 847700: 0.147669\n",
      "2022-11-09 02:10:53,007 INFO     Training average negative_sample_loss at step 847700: 0.140717\n",
      "2022-11-09 02:10:53,007 INFO     Training average loss at step 847700: 0.144193\n",
      "2022-11-09 02:10:56,101 INFO     Training average positive_sample_loss at step 847800: 0.139565\n",
      "2022-11-09 02:10:56,101 INFO     Training average negative_sample_loss at step 847800: 0.137214\n",
      "2022-11-09 02:10:56,102 INFO     Training average loss at step 847800: 0.138389\n",
      "2022-11-09 02:10:59,203 INFO     Training average positive_sample_loss at step 847900: 0.145586\n",
      "2022-11-09 02:10:59,203 INFO     Training average negative_sample_loss at step 847900: 0.139935\n",
      "2022-11-09 02:10:59,204 INFO     Training average loss at step 847900: 0.142760\n",
      "2022-11-09 02:11:02,310 INFO     Training average positive_sample_loss at step 848000: 0.142090\n",
      "2022-11-09 02:11:02,311 INFO     Training average negative_sample_loss at step 848000: 0.136528\n",
      "2022-11-09 02:11:02,311 INFO     Training average loss at step 848000: 0.139309\n",
      "2022-11-09 02:11:06,324 INFO     Training average positive_sample_loss at step 848100: 0.152508\n",
      "2022-11-09 02:11:06,324 INFO     Training average negative_sample_loss at step 848100: 0.135499\n",
      "2022-11-09 02:11:06,324 INFO     Training average loss at step 848100: 0.144004\n",
      "2022-11-09 02:11:10,570 INFO     Training average positive_sample_loss at step 848200: 0.142898\n",
      "2022-11-09 02:11:10,570 INFO     Training average negative_sample_loss at step 848200: 0.141686\n",
      "2022-11-09 02:11:10,570 INFO     Training average loss at step 848200: 0.142292\n",
      "2022-11-09 02:11:15,202 INFO     Training average positive_sample_loss at step 848300: 0.143823\n",
      "2022-11-09 02:11:15,202 INFO     Training average negative_sample_loss at step 848300: 0.137529\n",
      "2022-11-09 02:11:15,202 INFO     Training average loss at step 848300: 0.140676\n",
      "2022-11-09 02:11:18,320 INFO     Training average positive_sample_loss at step 848400: 0.148169\n",
      "2022-11-09 02:11:18,320 INFO     Training average negative_sample_loss at step 848400: 0.135537\n",
      "2022-11-09 02:11:18,320 INFO     Training average loss at step 848400: 0.141853\n",
      "2022-11-09 02:11:21,440 INFO     Training average positive_sample_loss at step 848500: 0.144827\n",
      "2022-11-09 02:11:21,440 INFO     Training average negative_sample_loss at step 848500: 0.137338\n",
      "2022-11-09 02:11:21,440 INFO     Training average loss at step 848500: 0.141082\n",
      "2022-11-09 02:11:24,559 INFO     Training average positive_sample_loss at step 848600: 0.140123\n",
      "2022-11-09 02:11:24,559 INFO     Training average negative_sample_loss at step 848600: 0.139834\n",
      "2022-11-09 02:11:24,559 INFO     Training average loss at step 848600: 0.139978\n",
      "2022-11-09 02:11:27,675 INFO     Training average positive_sample_loss at step 848700: 0.146770\n",
      "2022-11-09 02:11:27,675 INFO     Training average negative_sample_loss at step 848700: 0.135014\n",
      "2022-11-09 02:11:27,675 INFO     Training average loss at step 848700: 0.140892\n",
      "2022-11-09 02:11:30,783 INFO     Training average positive_sample_loss at step 848800: 0.144274\n",
      "2022-11-09 02:11:30,784 INFO     Training average negative_sample_loss at step 848800: 0.135731\n",
      "2022-11-09 02:11:30,784 INFO     Training average loss at step 848800: 0.140003\n",
      "2022-11-09 02:11:33,897 INFO     Training average positive_sample_loss at step 848900: 0.148933\n",
      "2022-11-09 02:11:33,897 INFO     Training average negative_sample_loss at step 848900: 0.141597\n",
      "2022-11-09 02:11:33,897 INFO     Training average loss at step 848900: 0.145265\n",
      "2022-11-09 02:11:37,019 INFO     Training average positive_sample_loss at step 849000: 0.141582\n",
      "2022-11-09 02:11:37,019 INFO     Training average negative_sample_loss at step 849000: 0.136732\n",
      "2022-11-09 02:11:37,019 INFO     Training average loss at step 849000: 0.139157\n",
      "2022-11-09 02:11:40,137 INFO     Training average positive_sample_loss at step 849100: 0.145314\n",
      "2022-11-09 02:11:40,137 INFO     Training average negative_sample_loss at step 849100: 0.136100\n",
      "2022-11-09 02:11:40,138 INFO     Training average loss at step 849100: 0.140707\n",
      "2022-11-09 02:11:43,250 INFO     Training average positive_sample_loss at step 849200: 0.146302\n",
      "2022-11-09 02:11:43,250 INFO     Training average negative_sample_loss at step 849200: 0.135494\n",
      "2022-11-09 02:11:43,250 INFO     Training average loss at step 849200: 0.140898\n",
      "2022-11-09 02:11:46,361 INFO     Training average positive_sample_loss at step 849300: 0.144089\n",
      "2022-11-09 02:11:46,361 INFO     Training average negative_sample_loss at step 849300: 0.138450\n",
      "2022-11-09 02:11:46,361 INFO     Training average loss at step 849300: 0.141269\n",
      "2022-11-09 02:11:49,475 INFO     Training average positive_sample_loss at step 849400: 0.143094\n",
      "2022-11-09 02:11:49,475 INFO     Training average negative_sample_loss at step 849400: 0.135721\n",
      "2022-11-09 02:11:49,475 INFO     Training average loss at step 849400: 0.139407\n",
      "2022-11-09 02:11:52,597 INFO     Training average positive_sample_loss at step 849500: 0.141642\n",
      "2022-11-09 02:11:52,597 INFO     Training average negative_sample_loss at step 849500: 0.135429\n",
      "2022-11-09 02:11:52,597 INFO     Training average loss at step 849500: 0.138536\n",
      "2022-11-09 02:11:55,719 INFO     Training average positive_sample_loss at step 849600: 0.143323\n",
      "2022-11-09 02:11:55,719 INFO     Training average negative_sample_loss at step 849600: 0.136648\n",
      "2022-11-09 02:11:55,719 INFO     Training average loss at step 849600: 0.139986\n",
      "2022-11-09 02:11:58,827 INFO     Training average positive_sample_loss at step 849700: 0.145322\n",
      "2022-11-09 02:11:58,827 INFO     Training average negative_sample_loss at step 849700: 0.137722\n",
      "2022-11-09 02:11:58,827 INFO     Training average loss at step 849700: 0.141522\n",
      "2022-11-09 02:12:01,941 INFO     Training average positive_sample_loss at step 849800: 0.144073\n",
      "2022-11-09 02:12:01,941 INFO     Training average negative_sample_loss at step 849800: 0.136776\n",
      "2022-11-09 02:12:01,941 INFO     Training average loss at step 849800: 0.140425\n",
      "2022-11-09 02:12:05,058 INFO     Training average positive_sample_loss at step 849900: 0.144868\n",
      "2022-11-09 02:12:05,058 INFO     Training average negative_sample_loss at step 849900: 0.139217\n",
      "2022-11-09 02:12:05,058 INFO     Training average loss at step 849900: 0.142042\n",
      "2022-11-09 02:12:11,041 INFO     Training average positive_sample_loss at step 850000: 0.143533\n",
      "2022-11-09 02:12:11,041 INFO     Training average negative_sample_loss at step 850000: 0.131890\n",
      "2022-11-09 02:12:11,041 INFO     Training average loss at step 850000: 0.137711\n",
      "2022-11-09 02:12:14,159 INFO     Training average positive_sample_loss at step 850100: 0.143286\n",
      "2022-11-09 02:12:14,159 INFO     Training average negative_sample_loss at step 850100: 0.136878\n",
      "2022-11-09 02:12:14,159 INFO     Training average loss at step 850100: 0.140082\n",
      "2022-11-09 02:12:17,273 INFO     Training average positive_sample_loss at step 850200: 0.143047\n",
      "2022-11-09 02:12:17,273 INFO     Training average negative_sample_loss at step 850200: 0.137311\n",
      "2022-11-09 02:12:17,273 INFO     Training average loss at step 850200: 0.140179\n",
      "2022-11-09 02:12:20,383 INFO     Training average positive_sample_loss at step 850300: 0.146523\n",
      "2022-11-09 02:12:20,383 INFO     Training average negative_sample_loss at step 850300: 0.138834\n",
      "2022-11-09 02:12:20,383 INFO     Training average loss at step 850300: 0.142678\n",
      "2022-11-09 02:12:23,507 INFO     Training average positive_sample_loss at step 850400: 0.147305\n",
      "2022-11-09 02:12:23,507 INFO     Training average negative_sample_loss at step 850400: 0.141672\n",
      "2022-11-09 02:12:23,507 INFO     Training average loss at step 850400: 0.144489\n",
      "2022-11-09 02:12:26,615 INFO     Training average positive_sample_loss at step 850500: 0.145276\n",
      "2022-11-09 02:12:26,615 INFO     Training average negative_sample_loss at step 850500: 0.140338\n",
      "2022-11-09 02:12:26,615 INFO     Training average loss at step 850500: 0.142807\n",
      "2022-11-09 02:12:29,735 INFO     Training average positive_sample_loss at step 850600: 0.139068\n",
      "2022-11-09 02:12:29,735 INFO     Training average negative_sample_loss at step 850600: 0.137830\n",
      "2022-11-09 02:12:29,735 INFO     Training average loss at step 850600: 0.138449\n",
      "2022-11-09 02:12:32,819 INFO     Training average positive_sample_loss at step 850700: 0.147350\n",
      "2022-11-09 02:12:32,819 INFO     Training average negative_sample_loss at step 850700: 0.134926\n",
      "2022-11-09 02:12:32,819 INFO     Training average loss at step 850700: 0.141138\n",
      "2022-11-09 02:12:35,926 INFO     Training average positive_sample_loss at step 850800: 0.141854\n",
      "2022-11-09 02:12:35,926 INFO     Training average negative_sample_loss at step 850800: 0.138416\n",
      "2022-11-09 02:12:35,926 INFO     Training average loss at step 850800: 0.140135\n",
      "2022-11-09 02:12:39,041 INFO     Training average positive_sample_loss at step 850900: 0.144648\n",
      "2022-11-09 02:12:39,041 INFO     Training average negative_sample_loss at step 850900: 0.137303\n",
      "2022-11-09 02:12:39,041 INFO     Training average loss at step 850900: 0.140976\n",
      "2022-11-09 02:12:42,151 INFO     Training average positive_sample_loss at step 851000: 0.141396\n",
      "2022-11-09 02:12:42,151 INFO     Training average negative_sample_loss at step 851000: 0.134154\n",
      "2022-11-09 02:12:42,151 INFO     Training average loss at step 851000: 0.137775\n",
      "2022-11-09 02:12:45,251 INFO     Training average positive_sample_loss at step 851100: 0.144886\n",
      "2022-11-09 02:12:45,251 INFO     Training average negative_sample_loss at step 851100: 0.140126\n",
      "2022-11-09 02:12:45,251 INFO     Training average loss at step 851100: 0.142506\n",
      "2022-11-09 02:12:48,358 INFO     Training average positive_sample_loss at step 851200: 0.138908\n",
      "2022-11-09 02:12:48,358 INFO     Training average negative_sample_loss at step 851200: 0.136140\n",
      "2022-11-09 02:12:48,358 INFO     Training average loss at step 851200: 0.137524\n",
      "2022-11-09 02:12:51,461 INFO     Training average positive_sample_loss at step 851300: 0.146984\n",
      "2022-11-09 02:12:51,461 INFO     Training average negative_sample_loss at step 851300: 0.139410\n",
      "2022-11-09 02:12:51,461 INFO     Training average loss at step 851300: 0.143197\n",
      "2022-11-09 02:12:54,570 INFO     Training average positive_sample_loss at step 851400: 0.146760\n",
      "2022-11-09 02:12:54,570 INFO     Training average negative_sample_loss at step 851400: 0.138254\n",
      "2022-11-09 02:12:54,570 INFO     Training average loss at step 851400: 0.142507\n",
      "2022-11-09 02:12:57,672 INFO     Training average positive_sample_loss at step 851500: 0.141422\n",
      "2022-11-09 02:12:57,672 INFO     Training average negative_sample_loss at step 851500: 0.138945\n",
      "2022-11-09 02:12:57,672 INFO     Training average loss at step 851500: 0.140184\n",
      "2022-11-09 02:13:00,774 INFO     Training average positive_sample_loss at step 851600: 0.143856\n",
      "2022-11-09 02:13:00,775 INFO     Training average negative_sample_loss at step 851600: 0.136867\n",
      "2022-11-09 02:13:00,775 INFO     Training average loss at step 851600: 0.140361\n",
      "2022-11-09 02:13:03,904 INFO     Training average positive_sample_loss at step 851700: 0.146321\n",
      "2022-11-09 02:13:03,904 INFO     Training average negative_sample_loss at step 851700: 0.139419\n",
      "2022-11-09 02:13:03,904 INFO     Training average loss at step 851700: 0.142870\n",
      "2022-11-09 02:13:07,030 INFO     Training average positive_sample_loss at step 851800: 0.146138\n",
      "2022-11-09 02:13:07,030 INFO     Training average negative_sample_loss at step 851800: 0.136609\n",
      "2022-11-09 02:13:07,030 INFO     Training average loss at step 851800: 0.141373\n",
      "2022-11-09 02:13:10,142 INFO     Training average positive_sample_loss at step 851900: 0.151281\n",
      "2022-11-09 02:13:10,142 INFO     Training average negative_sample_loss at step 851900: 0.134764\n",
      "2022-11-09 02:13:10,142 INFO     Training average loss at step 851900: 0.143023\n",
      "2022-11-09 02:13:13,244 INFO     Training average positive_sample_loss at step 852000: 0.141924\n",
      "2022-11-09 02:13:13,244 INFO     Training average negative_sample_loss at step 852000: 0.134459\n",
      "2022-11-09 02:13:13,244 INFO     Training average loss at step 852000: 0.138191\n",
      "2022-11-09 02:13:16,338 INFO     Training average positive_sample_loss at step 852100: 0.148913\n",
      "2022-11-09 02:13:16,338 INFO     Training average negative_sample_loss at step 852100: 0.134696\n",
      "2022-11-09 02:13:16,338 INFO     Training average loss at step 852100: 0.141805\n",
      "2022-11-09 02:13:19,444 INFO     Training average positive_sample_loss at step 852200: 0.146429\n",
      "2022-11-09 02:13:19,444 INFO     Training average negative_sample_loss at step 852200: 0.134971\n",
      "2022-11-09 02:13:19,444 INFO     Training average loss at step 852200: 0.140700\n",
      "2022-11-09 02:13:22,561 INFO     Training average positive_sample_loss at step 852300: 0.143385\n",
      "2022-11-09 02:13:22,561 INFO     Training average negative_sample_loss at step 852300: 0.137980\n",
      "2022-11-09 02:13:22,561 INFO     Training average loss at step 852300: 0.140683\n",
      "2022-11-09 02:13:25,667 INFO     Training average positive_sample_loss at step 852400: 0.145709\n",
      "2022-11-09 02:13:25,667 INFO     Training average negative_sample_loss at step 852400: 0.137871\n",
      "2022-11-09 02:13:25,667 INFO     Training average loss at step 852400: 0.141790\n",
      "2022-11-09 02:13:28,784 INFO     Training average positive_sample_loss at step 852500: 0.142029\n",
      "2022-11-09 02:13:28,784 INFO     Training average negative_sample_loss at step 852500: 0.134882\n",
      "2022-11-09 02:13:28,784 INFO     Training average loss at step 852500: 0.138456\n",
      "2022-11-09 02:13:31,906 INFO     Training average positive_sample_loss at step 852600: 0.143665\n",
      "2022-11-09 02:13:31,906 INFO     Training average negative_sample_loss at step 852600: 0.136766\n",
      "2022-11-09 02:13:31,906 INFO     Training average loss at step 852600: 0.140215\n",
      "2022-11-09 02:13:35,021 INFO     Training average positive_sample_loss at step 852700: 0.145651\n",
      "2022-11-09 02:13:35,021 INFO     Training average negative_sample_loss at step 852700: 0.133809\n",
      "2022-11-09 02:13:35,021 INFO     Training average loss at step 852700: 0.139730\n",
      "2022-11-09 02:13:39,093 INFO     Training average positive_sample_loss at step 852800: 0.143812\n",
      "2022-11-09 02:13:39,093 INFO     Training average negative_sample_loss at step 852800: 0.139785\n",
      "2022-11-09 02:13:39,093 INFO     Training average loss at step 852800: 0.141799\n",
      "2022-11-09 02:13:43,369 INFO     Training average positive_sample_loss at step 852900: 0.151219\n",
      "2022-11-09 02:13:43,369 INFO     Training average negative_sample_loss at step 852900: 0.135698\n",
      "2022-11-09 02:13:43,369 INFO     Training average loss at step 852900: 0.143458\n",
      "2022-11-09 02:13:48,014 INFO     Training average positive_sample_loss at step 853000: 0.142124\n",
      "2022-11-09 02:13:48,014 INFO     Training average negative_sample_loss at step 853000: 0.137288\n",
      "2022-11-09 02:13:48,014 INFO     Training average loss at step 853000: 0.139706\n",
      "2022-11-09 02:13:51,133 INFO     Training average positive_sample_loss at step 853100: 0.142962\n",
      "2022-11-09 02:13:51,134 INFO     Training average negative_sample_loss at step 853100: 0.139831\n",
      "2022-11-09 02:13:51,134 INFO     Training average loss at step 853100: 0.141396\n",
      "2022-11-09 02:13:54,254 INFO     Training average positive_sample_loss at step 853200: 0.144043\n",
      "2022-11-09 02:13:54,254 INFO     Training average negative_sample_loss at step 853200: 0.136652\n",
      "2022-11-09 02:13:54,255 INFO     Training average loss at step 853200: 0.140348\n",
      "2022-11-09 02:13:57,374 INFO     Training average positive_sample_loss at step 853300: 0.140034\n",
      "2022-11-09 02:13:57,374 INFO     Training average negative_sample_loss at step 853300: 0.141722\n",
      "2022-11-09 02:13:57,374 INFO     Training average loss at step 853300: 0.140878\n",
      "2022-11-09 02:14:00,490 INFO     Training average positive_sample_loss at step 853400: 0.141619\n",
      "2022-11-09 02:14:00,490 INFO     Training average negative_sample_loss at step 853400: 0.138342\n",
      "2022-11-09 02:14:00,490 INFO     Training average loss at step 853400: 0.139980\n",
      "2022-11-09 02:14:03,586 INFO     Training average positive_sample_loss at step 853500: 0.141704\n",
      "2022-11-09 02:14:03,586 INFO     Training average negative_sample_loss at step 853500: 0.138513\n",
      "2022-11-09 02:14:03,586 INFO     Training average loss at step 853500: 0.140108\n",
      "2022-11-09 02:14:06,695 INFO     Training average positive_sample_loss at step 853600: 0.144211\n",
      "2022-11-09 02:14:06,695 INFO     Training average negative_sample_loss at step 853600: 0.137352\n",
      "2022-11-09 02:14:06,695 INFO     Training average loss at step 853600: 0.140782\n",
      "2022-11-09 02:14:09,810 INFO     Training average positive_sample_loss at step 853700: 0.141336\n",
      "2022-11-09 02:14:09,810 INFO     Training average negative_sample_loss at step 853700: 0.141268\n",
      "2022-11-09 02:14:09,810 INFO     Training average loss at step 853700: 0.141302\n",
      "2022-11-09 02:14:12,916 INFO     Training average positive_sample_loss at step 853800: 0.149215\n",
      "2022-11-09 02:14:12,916 INFO     Training average negative_sample_loss at step 853800: 0.142508\n",
      "2022-11-09 02:14:12,916 INFO     Training average loss at step 853800: 0.145862\n",
      "2022-11-09 02:14:16,022 INFO     Training average positive_sample_loss at step 853900: 0.140517\n",
      "2022-11-09 02:14:16,022 INFO     Training average negative_sample_loss at step 853900: 0.139425\n",
      "2022-11-09 02:14:16,022 INFO     Training average loss at step 853900: 0.139971\n",
      "2022-11-09 02:14:19,139 INFO     Training average positive_sample_loss at step 854000: 0.142078\n",
      "2022-11-09 02:14:19,139 INFO     Training average negative_sample_loss at step 854000: 0.136760\n",
      "2022-11-09 02:14:19,139 INFO     Training average loss at step 854000: 0.139419\n",
      "2022-11-09 02:14:22,251 INFO     Training average positive_sample_loss at step 854100: 0.143923\n",
      "2022-11-09 02:14:22,251 INFO     Training average negative_sample_loss at step 854100: 0.137844\n",
      "2022-11-09 02:14:22,251 INFO     Training average loss at step 854100: 0.140883\n",
      "2022-11-09 02:14:25,365 INFO     Training average positive_sample_loss at step 854200: 0.142559\n",
      "2022-11-09 02:14:25,365 INFO     Training average negative_sample_loss at step 854200: 0.133045\n",
      "2022-11-09 02:14:25,365 INFO     Training average loss at step 854200: 0.137802\n",
      "2022-11-09 02:14:28,493 INFO     Training average positive_sample_loss at step 854300: 0.143773\n",
      "2022-11-09 02:14:28,494 INFO     Training average negative_sample_loss at step 854300: 0.135037\n",
      "2022-11-09 02:14:28,494 INFO     Training average loss at step 854300: 0.139405\n",
      "2022-11-09 02:14:31,600 INFO     Training average positive_sample_loss at step 854400: 0.143870\n",
      "2022-11-09 02:14:31,600 INFO     Training average negative_sample_loss at step 854400: 0.139152\n",
      "2022-11-09 02:14:31,600 INFO     Training average loss at step 854400: 0.141511\n",
      "2022-11-09 02:14:34,714 INFO     Training average positive_sample_loss at step 854500: 0.144434\n",
      "2022-11-09 02:14:34,714 INFO     Training average negative_sample_loss at step 854500: 0.135842\n",
      "2022-11-09 02:14:34,714 INFO     Training average loss at step 854500: 0.140138\n",
      "2022-11-09 02:14:37,831 INFO     Training average positive_sample_loss at step 854600: 0.143310\n",
      "2022-11-09 02:14:37,832 INFO     Training average negative_sample_loss at step 854600: 0.133046\n",
      "2022-11-09 02:14:37,832 INFO     Training average loss at step 854600: 0.138178\n",
      "2022-11-09 02:14:40,940 INFO     Training average positive_sample_loss at step 854700: 0.141659\n",
      "2022-11-09 02:14:40,940 INFO     Training average negative_sample_loss at step 854700: 0.140026\n",
      "2022-11-09 02:14:40,940 INFO     Training average loss at step 854700: 0.140843\n",
      "2022-11-09 02:14:44,048 INFO     Training average positive_sample_loss at step 854800: 0.140871\n",
      "2022-11-09 02:14:44,049 INFO     Training average negative_sample_loss at step 854800: 0.134554\n",
      "2022-11-09 02:14:44,049 INFO     Training average loss at step 854800: 0.137713\n",
      "2022-11-09 02:14:47,159 INFO     Training average positive_sample_loss at step 854900: 0.146188\n",
      "2022-11-09 02:14:47,160 INFO     Training average negative_sample_loss at step 854900: 0.140078\n",
      "2022-11-09 02:14:47,160 INFO     Training average loss at step 854900: 0.143133\n",
      "2022-11-09 02:14:50,274 INFO     Training average positive_sample_loss at step 855000: 0.145562\n",
      "2022-11-09 02:14:50,274 INFO     Training average negative_sample_loss at step 855000: 0.135565\n",
      "2022-11-09 02:14:50,274 INFO     Training average loss at step 855000: 0.140564\n",
      "2022-11-09 02:14:53,373 INFO     Training average positive_sample_loss at step 855100: 0.142720\n",
      "2022-11-09 02:14:53,373 INFO     Training average negative_sample_loss at step 855100: 0.133929\n",
      "2022-11-09 02:14:53,373 INFO     Training average loss at step 855100: 0.138325\n",
      "2022-11-09 02:14:56,465 INFO     Training average positive_sample_loss at step 855200: 0.148020\n",
      "2022-11-09 02:14:56,465 INFO     Training average negative_sample_loss at step 855200: 0.136601\n",
      "2022-11-09 02:14:56,465 INFO     Training average loss at step 855200: 0.142311\n",
      "2022-11-09 02:14:59,558 INFO     Training average positive_sample_loss at step 855300: 0.142757\n",
      "2022-11-09 02:14:59,558 INFO     Training average negative_sample_loss at step 855300: 0.135314\n",
      "2022-11-09 02:14:59,558 INFO     Training average loss at step 855300: 0.139036\n",
      "2022-11-09 02:15:02,677 INFO     Training average positive_sample_loss at step 855400: 0.141316\n",
      "2022-11-09 02:15:02,677 INFO     Training average negative_sample_loss at step 855400: 0.134059\n",
      "2022-11-09 02:15:02,677 INFO     Training average loss at step 855400: 0.137688\n",
      "2022-11-09 02:15:05,795 INFO     Training average positive_sample_loss at step 855500: 0.144263\n",
      "2022-11-09 02:15:05,795 INFO     Training average negative_sample_loss at step 855500: 0.135336\n",
      "2022-11-09 02:15:05,795 INFO     Training average loss at step 855500: 0.139799\n",
      "2022-11-09 02:15:08,905 INFO     Training average positive_sample_loss at step 855600: 0.145489\n",
      "2022-11-09 02:15:08,905 INFO     Training average negative_sample_loss at step 855600: 0.138051\n",
      "2022-11-09 02:15:08,905 INFO     Training average loss at step 855600: 0.141770\n",
      "2022-11-09 02:15:12,009 INFO     Training average positive_sample_loss at step 855700: 0.140557\n",
      "2022-11-09 02:15:12,009 INFO     Training average negative_sample_loss at step 855700: 0.137882\n",
      "2022-11-09 02:15:12,009 INFO     Training average loss at step 855700: 0.139220\n",
      "2022-11-09 02:15:15,112 INFO     Training average positive_sample_loss at step 855800: 0.144069\n",
      "2022-11-09 02:15:15,112 INFO     Training average negative_sample_loss at step 855800: 0.139310\n",
      "2022-11-09 02:15:15,112 INFO     Training average loss at step 855800: 0.141690\n",
      "2022-11-09 02:15:18,197 INFO     Training average positive_sample_loss at step 855900: 0.142349\n",
      "2022-11-09 02:15:18,197 INFO     Training average negative_sample_loss at step 855900: 0.136862\n",
      "2022-11-09 02:15:18,197 INFO     Training average loss at step 855900: 0.139606\n",
      "2022-11-09 02:15:21,292 INFO     Training average positive_sample_loss at step 856000: 0.143757\n",
      "2022-11-09 02:15:21,292 INFO     Training average negative_sample_loss at step 856000: 0.136678\n",
      "2022-11-09 02:15:21,292 INFO     Training average loss at step 856000: 0.140218\n",
      "2022-11-09 02:15:24,404 INFO     Training average positive_sample_loss at step 856100: 0.142972\n",
      "2022-11-09 02:15:24,404 INFO     Training average negative_sample_loss at step 856100: 0.137435\n",
      "2022-11-09 02:15:24,404 INFO     Training average loss at step 856100: 0.140204\n",
      "2022-11-09 02:15:27,510 INFO     Training average positive_sample_loss at step 856200: 0.144649\n",
      "2022-11-09 02:15:27,510 INFO     Training average negative_sample_loss at step 856200: 0.140460\n",
      "2022-11-09 02:15:27,510 INFO     Training average loss at step 856200: 0.142555\n",
      "2022-11-09 02:15:30,616 INFO     Training average positive_sample_loss at step 856300: 0.140085\n",
      "2022-11-09 02:15:30,616 INFO     Training average negative_sample_loss at step 856300: 0.138354\n",
      "2022-11-09 02:15:30,616 INFO     Training average loss at step 856300: 0.139220\n",
      "2022-11-09 02:15:33,717 INFO     Training average positive_sample_loss at step 856400: 0.145841\n",
      "2022-11-09 02:15:33,718 INFO     Training average negative_sample_loss at step 856400: 0.141204\n",
      "2022-11-09 02:15:33,718 INFO     Training average loss at step 856400: 0.143522\n",
      "2022-11-09 02:15:36,833 INFO     Training average positive_sample_loss at step 856500: 0.142995\n",
      "2022-11-09 02:15:36,833 INFO     Training average negative_sample_loss at step 856500: 0.141829\n",
      "2022-11-09 02:15:36,833 INFO     Training average loss at step 856500: 0.142412\n",
      "2022-11-09 02:15:39,938 INFO     Training average positive_sample_loss at step 856600: 0.145952\n",
      "2022-11-09 02:15:39,938 INFO     Training average negative_sample_loss at step 856600: 0.135052\n",
      "2022-11-09 02:15:39,939 INFO     Training average loss at step 856600: 0.140502\n",
      "2022-11-09 02:15:43,039 INFO     Training average positive_sample_loss at step 856700: 0.144206\n",
      "2022-11-09 02:15:43,039 INFO     Training average negative_sample_loss at step 856700: 0.134372\n",
      "2022-11-09 02:15:43,039 INFO     Training average loss at step 856700: 0.139289\n",
      "2022-11-09 02:15:46,144 INFO     Training average positive_sample_loss at step 856800: 0.144061\n",
      "2022-11-09 02:15:46,144 INFO     Training average negative_sample_loss at step 856800: 0.137599\n",
      "2022-11-09 02:15:46,144 INFO     Training average loss at step 856800: 0.140830\n",
      "2022-11-09 02:15:49,244 INFO     Training average positive_sample_loss at step 856900: 0.141480\n",
      "2022-11-09 02:15:49,244 INFO     Training average negative_sample_loss at step 856900: 0.141035\n",
      "2022-11-09 02:15:49,244 INFO     Training average loss at step 856900: 0.141258\n",
      "2022-11-09 02:15:52,349 INFO     Training average positive_sample_loss at step 857000: 0.144838\n",
      "2022-11-09 02:15:52,349 INFO     Training average negative_sample_loss at step 857000: 0.139890\n",
      "2022-11-09 02:15:52,349 INFO     Training average loss at step 857000: 0.142364\n",
      "2022-11-09 02:15:55,457 INFO     Training average positive_sample_loss at step 857100: 0.143099\n",
      "2022-11-09 02:15:55,458 INFO     Training average negative_sample_loss at step 857100: 0.134848\n",
      "2022-11-09 02:15:55,458 INFO     Training average loss at step 857100: 0.138974\n",
      "2022-11-09 02:15:58,559 INFO     Training average positive_sample_loss at step 857200: 0.149900\n",
      "2022-11-09 02:15:58,559 INFO     Training average negative_sample_loss at step 857200: 0.139151\n",
      "2022-11-09 02:15:58,559 INFO     Training average loss at step 857200: 0.144525\n",
      "2022-11-09 02:16:01,670 INFO     Training average positive_sample_loss at step 857300: 0.143842\n",
      "2022-11-09 02:16:01,670 INFO     Training average negative_sample_loss at step 857300: 0.136644\n",
      "2022-11-09 02:16:01,670 INFO     Training average loss at step 857300: 0.140243\n",
      "2022-11-09 02:16:05,684 INFO     Training average positive_sample_loss at step 857400: 0.141605\n",
      "2022-11-09 02:16:05,684 INFO     Training average negative_sample_loss at step 857400: 0.140507\n",
      "2022-11-09 02:16:05,684 INFO     Training average loss at step 857400: 0.141056\n",
      "2022-11-09 02:16:08,802 INFO     Training average positive_sample_loss at step 857500: 0.143299\n",
      "2022-11-09 02:16:08,802 INFO     Training average negative_sample_loss at step 857500: 0.141534\n",
      "2022-11-09 02:16:08,802 INFO     Training average loss at step 857500: 0.142416\n",
      "2022-11-09 02:16:13,104 INFO     Training average positive_sample_loss at step 857600: 0.145722\n",
      "2022-11-09 02:16:13,104 INFO     Training average negative_sample_loss at step 857600: 0.136156\n",
      "2022-11-09 02:16:13,104 INFO     Training average loss at step 857600: 0.140939\n",
      "2022-11-09 02:16:17,723 INFO     Training average positive_sample_loss at step 857700: 0.145242\n",
      "2022-11-09 02:16:17,723 INFO     Training average negative_sample_loss at step 857700: 0.135501\n",
      "2022-11-09 02:16:17,723 INFO     Training average loss at step 857700: 0.140371\n",
      "2022-11-09 02:16:20,823 INFO     Training average positive_sample_loss at step 857800: 0.139637\n",
      "2022-11-09 02:16:20,823 INFO     Training average negative_sample_loss at step 857800: 0.139188\n",
      "2022-11-09 02:16:20,823 INFO     Training average loss at step 857800: 0.139413\n",
      "2022-11-09 02:16:23,935 INFO     Training average positive_sample_loss at step 857900: 0.141153\n",
      "2022-11-09 02:16:23,935 INFO     Training average negative_sample_loss at step 857900: 0.136919\n",
      "2022-11-09 02:16:23,935 INFO     Training average loss at step 857900: 0.139036\n",
      "2022-11-09 02:16:27,048 INFO     Training average positive_sample_loss at step 858000: 0.143839\n",
      "2022-11-09 02:16:27,048 INFO     Training average negative_sample_loss at step 858000: 0.139393\n",
      "2022-11-09 02:16:27,048 INFO     Training average loss at step 858000: 0.141616\n",
      "2022-11-09 02:16:30,158 INFO     Training average positive_sample_loss at step 858100: 0.141878\n",
      "2022-11-09 02:16:30,158 INFO     Training average negative_sample_loss at step 858100: 0.141227\n",
      "2022-11-09 02:16:30,158 INFO     Training average loss at step 858100: 0.141552\n",
      "2022-11-09 02:16:33,272 INFO     Training average positive_sample_loss at step 858200: 0.145217\n",
      "2022-11-09 02:16:33,272 INFO     Training average negative_sample_loss at step 858200: 0.135173\n",
      "2022-11-09 02:16:33,272 INFO     Training average loss at step 858200: 0.140195\n",
      "2022-11-09 02:16:36,376 INFO     Training average positive_sample_loss at step 858300: 0.142322\n",
      "2022-11-09 02:16:36,376 INFO     Training average negative_sample_loss at step 858300: 0.135744\n",
      "2022-11-09 02:16:36,376 INFO     Training average loss at step 858300: 0.139033\n",
      "2022-11-09 02:16:39,487 INFO     Training average positive_sample_loss at step 858400: 0.146176\n",
      "2022-11-09 02:16:39,487 INFO     Training average negative_sample_loss at step 858400: 0.136046\n",
      "2022-11-09 02:16:39,487 INFO     Training average loss at step 858400: 0.141111\n",
      "2022-11-09 02:16:42,583 INFO     Training average positive_sample_loss at step 858500: 0.141748\n",
      "2022-11-09 02:16:42,583 INFO     Training average negative_sample_loss at step 858500: 0.137000\n",
      "2022-11-09 02:16:42,583 INFO     Training average loss at step 858500: 0.139374\n",
      "2022-11-09 02:16:45,679 INFO     Training average positive_sample_loss at step 858600: 0.143187\n",
      "2022-11-09 02:16:45,679 INFO     Training average negative_sample_loss at step 858600: 0.135847\n",
      "2022-11-09 02:16:45,679 INFO     Training average loss at step 858600: 0.139517\n",
      "2022-11-09 02:16:48,764 INFO     Training average positive_sample_loss at step 858700: 0.146891\n",
      "2022-11-09 02:16:48,764 INFO     Training average negative_sample_loss at step 858700: 0.136498\n",
      "2022-11-09 02:16:48,764 INFO     Training average loss at step 858700: 0.141695\n",
      "2022-11-09 02:16:51,861 INFO     Training average positive_sample_loss at step 858800: 0.138735\n",
      "2022-11-09 02:16:51,861 INFO     Training average negative_sample_loss at step 858800: 0.136014\n",
      "2022-11-09 02:16:51,861 INFO     Training average loss at step 858800: 0.137374\n",
      "2022-11-09 02:16:54,962 INFO     Training average positive_sample_loss at step 858900: 0.144588\n",
      "2022-11-09 02:16:54,963 INFO     Training average negative_sample_loss at step 858900: 0.135120\n",
      "2022-11-09 02:16:54,963 INFO     Training average loss at step 858900: 0.139854\n",
      "2022-11-09 02:16:58,052 INFO     Training average positive_sample_loss at step 859000: 0.145219\n",
      "2022-11-09 02:16:58,052 INFO     Training average negative_sample_loss at step 859000: 0.136170\n",
      "2022-11-09 02:16:58,052 INFO     Training average loss at step 859000: 0.140695\n",
      "2022-11-09 02:17:01,144 INFO     Training average positive_sample_loss at step 859100: 0.144497\n",
      "2022-11-09 02:17:01,144 INFO     Training average negative_sample_loss at step 859100: 0.137639\n",
      "2022-11-09 02:17:01,144 INFO     Training average loss at step 859100: 0.141068\n",
      "2022-11-09 02:17:04,244 INFO     Training average positive_sample_loss at step 859200: 0.146381\n",
      "2022-11-09 02:17:04,244 INFO     Training average negative_sample_loss at step 859200: 0.138332\n",
      "2022-11-09 02:17:04,244 INFO     Training average loss at step 859200: 0.142356\n",
      "2022-11-09 02:17:07,342 INFO     Training average positive_sample_loss at step 859300: 0.144140\n",
      "2022-11-09 02:17:07,342 INFO     Training average negative_sample_loss at step 859300: 0.137514\n",
      "2022-11-09 02:17:07,342 INFO     Training average loss at step 859300: 0.140827\n",
      "2022-11-09 02:17:10,442 INFO     Training average positive_sample_loss at step 859400: 0.150397\n",
      "2022-11-09 02:17:10,443 INFO     Training average negative_sample_loss at step 859400: 0.139565\n",
      "2022-11-09 02:17:10,443 INFO     Training average loss at step 859400: 0.144981\n",
      "2022-11-09 02:17:13,545 INFO     Training average positive_sample_loss at step 859500: 0.150293\n",
      "2022-11-09 02:17:13,546 INFO     Training average negative_sample_loss at step 859500: 0.137004\n",
      "2022-11-09 02:17:13,546 INFO     Training average loss at step 859500: 0.143649\n",
      "2022-11-09 02:17:16,663 INFO     Training average positive_sample_loss at step 859600: 0.153233\n",
      "2022-11-09 02:17:16,663 INFO     Training average negative_sample_loss at step 859600: 0.137088\n",
      "2022-11-09 02:17:16,663 INFO     Training average loss at step 859600: 0.145160\n",
      "2022-11-09 02:17:19,760 INFO     Training average positive_sample_loss at step 859700: 0.144096\n",
      "2022-11-09 02:17:19,760 INFO     Training average negative_sample_loss at step 859700: 0.139819\n",
      "2022-11-09 02:17:19,761 INFO     Training average loss at step 859700: 0.141957\n",
      "2022-11-09 02:17:22,860 INFO     Training average positive_sample_loss at step 859800: 0.148174\n",
      "2022-11-09 02:17:22,860 INFO     Training average negative_sample_loss at step 859800: 0.140045\n",
      "2022-11-09 02:17:22,860 INFO     Training average loss at step 859800: 0.144110\n",
      "2022-11-09 02:17:25,952 INFO     Training average positive_sample_loss at step 859900: 0.141805\n",
      "2022-11-09 02:17:25,952 INFO     Training average negative_sample_loss at step 859900: 0.141876\n",
      "2022-11-09 02:17:25,952 INFO     Training average loss at step 859900: 0.141841\n",
      "2022-11-09 02:17:31,894 INFO     Training average positive_sample_loss at step 860000: 0.145143\n",
      "2022-11-09 02:17:31,894 INFO     Training average negative_sample_loss at step 860000: 0.141027\n",
      "2022-11-09 02:17:31,894 INFO     Training average loss at step 860000: 0.143085\n",
      "2022-11-09 02:17:35,008 INFO     Training average positive_sample_loss at step 860100: 0.145974\n",
      "2022-11-09 02:17:35,008 INFO     Training average negative_sample_loss at step 860100: 0.136553\n",
      "2022-11-09 02:17:35,008 INFO     Training average loss at step 860100: 0.141264\n",
      "2022-11-09 02:17:38,102 INFO     Training average positive_sample_loss at step 860200: 0.141172\n",
      "2022-11-09 02:17:38,103 INFO     Training average negative_sample_loss at step 860200: 0.138474\n",
      "2022-11-09 02:17:38,103 INFO     Training average loss at step 860200: 0.139823\n",
      "2022-11-09 02:17:41,186 INFO     Training average positive_sample_loss at step 860300: 0.145076\n",
      "2022-11-09 02:17:41,186 INFO     Training average negative_sample_loss at step 860300: 0.134313\n",
      "2022-11-09 02:17:41,186 INFO     Training average loss at step 860300: 0.139694\n",
      "2022-11-09 02:17:44,277 INFO     Training average positive_sample_loss at step 860400: 0.144505\n",
      "2022-11-09 02:17:44,278 INFO     Training average negative_sample_loss at step 860400: 0.137977\n",
      "2022-11-09 02:17:44,278 INFO     Training average loss at step 860400: 0.141241\n",
      "2022-11-09 02:17:47,371 INFO     Training average positive_sample_loss at step 860500: 0.143865\n",
      "2022-11-09 02:17:47,371 INFO     Training average negative_sample_loss at step 860500: 0.139363\n",
      "2022-11-09 02:17:47,371 INFO     Training average loss at step 860500: 0.141614\n",
      "2022-11-09 02:17:50,468 INFO     Training average positive_sample_loss at step 860600: 0.143577\n",
      "2022-11-09 02:17:50,469 INFO     Training average negative_sample_loss at step 860600: 0.137426\n",
      "2022-11-09 02:17:50,469 INFO     Training average loss at step 860600: 0.140502\n",
      "2022-11-09 02:17:53,567 INFO     Training average positive_sample_loss at step 860700: 0.140449\n",
      "2022-11-09 02:17:53,567 INFO     Training average negative_sample_loss at step 860700: 0.136533\n",
      "2022-11-09 02:17:53,567 INFO     Training average loss at step 860700: 0.138491\n",
      "2022-11-09 02:17:56,667 INFO     Training average positive_sample_loss at step 860800: 0.139396\n",
      "2022-11-09 02:17:56,667 INFO     Training average negative_sample_loss at step 860800: 0.136346\n",
      "2022-11-09 02:17:56,667 INFO     Training average loss at step 860800: 0.137871\n",
      "2022-11-09 02:17:59,753 INFO     Training average positive_sample_loss at step 860900: 0.147182\n",
      "2022-11-09 02:17:59,753 INFO     Training average negative_sample_loss at step 860900: 0.140574\n",
      "2022-11-09 02:17:59,753 INFO     Training average loss at step 860900: 0.143878\n",
      "2022-11-09 02:18:02,851 INFO     Training average positive_sample_loss at step 861000: 0.141772\n",
      "2022-11-09 02:18:02,851 INFO     Training average negative_sample_loss at step 861000: 0.135618\n",
      "2022-11-09 02:18:02,851 INFO     Training average loss at step 861000: 0.138695\n",
      "2022-11-09 02:18:05,951 INFO     Training average positive_sample_loss at step 861100: 0.147916\n",
      "2022-11-09 02:18:05,952 INFO     Training average negative_sample_loss at step 861100: 0.140435\n",
      "2022-11-09 02:18:05,952 INFO     Training average loss at step 861100: 0.144175\n",
      "2022-11-09 02:18:09,064 INFO     Training average positive_sample_loss at step 861200: 0.145142\n",
      "2022-11-09 02:18:09,064 INFO     Training average negative_sample_loss at step 861200: 0.131942\n",
      "2022-11-09 02:18:09,064 INFO     Training average loss at step 861200: 0.138542\n",
      "2022-11-09 02:18:12,170 INFO     Training average positive_sample_loss at step 861300: 0.143402\n",
      "2022-11-09 02:18:12,170 INFO     Training average negative_sample_loss at step 861300: 0.134787\n",
      "2022-11-09 02:18:12,170 INFO     Training average loss at step 861300: 0.139095\n",
      "2022-11-09 02:18:15,264 INFO     Training average positive_sample_loss at step 861400: 0.148671\n",
      "2022-11-09 02:18:15,264 INFO     Training average negative_sample_loss at step 861400: 0.135007\n",
      "2022-11-09 02:18:15,264 INFO     Training average loss at step 861400: 0.141839\n",
      "2022-11-09 02:18:18,357 INFO     Training average positive_sample_loss at step 861500: 0.149279\n",
      "2022-11-09 02:18:18,357 INFO     Training average negative_sample_loss at step 861500: 0.133787\n",
      "2022-11-09 02:18:18,357 INFO     Training average loss at step 861500: 0.141533\n",
      "2022-11-09 02:18:21,458 INFO     Training average positive_sample_loss at step 861600: 0.142608\n",
      "2022-11-09 02:18:21,458 INFO     Training average negative_sample_loss at step 861600: 0.138771\n",
      "2022-11-09 02:18:21,458 INFO     Training average loss at step 861600: 0.140690\n",
      "2022-11-09 02:18:24,549 INFO     Training average positive_sample_loss at step 861700: 0.142301\n",
      "2022-11-09 02:18:24,549 INFO     Training average negative_sample_loss at step 861700: 0.135665\n",
      "2022-11-09 02:18:24,549 INFO     Training average loss at step 861700: 0.138983\n",
      "2022-11-09 02:18:27,655 INFO     Training average positive_sample_loss at step 861800: 0.143663\n",
      "2022-11-09 02:18:27,656 INFO     Training average negative_sample_loss at step 861800: 0.137996\n",
      "2022-11-09 02:18:27,656 INFO     Training average loss at step 861800: 0.140830\n",
      "2022-11-09 02:18:30,746 INFO     Training average positive_sample_loss at step 861900: 0.146106\n",
      "2022-11-09 02:18:30,746 INFO     Training average negative_sample_loss at step 861900: 0.135902\n",
      "2022-11-09 02:18:30,746 INFO     Training average loss at step 861900: 0.141004\n",
      "2022-11-09 02:18:34,785 INFO     Training average positive_sample_loss at step 862000: 0.145720\n",
      "2022-11-09 02:18:34,785 INFO     Training average negative_sample_loss at step 862000: 0.138761\n",
      "2022-11-09 02:18:34,785 INFO     Training average loss at step 862000: 0.142240\n",
      "2022-11-09 02:18:37,890 INFO     Training average positive_sample_loss at step 862100: 0.143055\n",
      "2022-11-09 02:18:37,890 INFO     Training average negative_sample_loss at step 862100: 0.136667\n",
      "2022-11-09 02:18:37,890 INFO     Training average loss at step 862100: 0.139861\n",
      "2022-11-09 02:18:41,004 INFO     Training average positive_sample_loss at step 862200: 0.139567\n",
      "2022-11-09 02:18:41,004 INFO     Training average negative_sample_loss at step 862200: 0.136822\n",
      "2022-11-09 02:18:41,004 INFO     Training average loss at step 862200: 0.138195\n",
      "2022-11-09 02:18:45,324 INFO     Training average positive_sample_loss at step 862300: 0.145374\n",
      "2022-11-09 02:18:45,324 INFO     Training average negative_sample_loss at step 862300: 0.136865\n",
      "2022-11-09 02:18:45,324 INFO     Training average loss at step 862300: 0.141119\n",
      "2022-11-09 02:18:49,980 INFO     Training average positive_sample_loss at step 862400: 0.146154\n",
      "2022-11-09 02:18:49,981 INFO     Training average negative_sample_loss at step 862400: 0.141646\n",
      "2022-11-09 02:18:49,981 INFO     Training average loss at step 862400: 0.143900\n",
      "2022-11-09 02:18:53,099 INFO     Training average positive_sample_loss at step 862500: 0.144018\n",
      "2022-11-09 02:18:53,099 INFO     Training average negative_sample_loss at step 862500: 0.137355\n",
      "2022-11-09 02:18:53,099 INFO     Training average loss at step 862500: 0.140687\n",
      "2022-11-09 02:18:56,211 INFO     Training average positive_sample_loss at step 862600: 0.141902\n",
      "2022-11-09 02:18:56,211 INFO     Training average negative_sample_loss at step 862600: 0.135270\n",
      "2022-11-09 02:18:56,211 INFO     Training average loss at step 862600: 0.138586\n",
      "2022-11-09 02:18:59,328 INFO     Training average positive_sample_loss at step 862700: 0.142358\n",
      "2022-11-09 02:18:59,328 INFO     Training average negative_sample_loss at step 862700: 0.139158\n",
      "2022-11-09 02:18:59,328 INFO     Training average loss at step 862700: 0.140758\n",
      "2022-11-09 02:19:02,425 INFO     Training average positive_sample_loss at step 862800: 0.141041\n",
      "2022-11-09 02:19:02,425 INFO     Training average negative_sample_loss at step 862800: 0.138721\n",
      "2022-11-09 02:19:02,425 INFO     Training average loss at step 862800: 0.139881\n",
      "2022-11-09 02:19:05,526 INFO     Training average positive_sample_loss at step 862900: 0.148118\n",
      "2022-11-09 02:19:05,526 INFO     Training average negative_sample_loss at step 862900: 0.135488\n",
      "2022-11-09 02:19:05,526 INFO     Training average loss at step 862900: 0.141803\n",
      "2022-11-09 02:19:08,626 INFO     Training average positive_sample_loss at step 863000: 0.145531\n",
      "2022-11-09 02:19:08,626 INFO     Training average negative_sample_loss at step 863000: 0.139598\n",
      "2022-11-09 02:19:08,626 INFO     Training average loss at step 863000: 0.142564\n",
      "2022-11-09 02:19:11,731 INFO     Training average positive_sample_loss at step 863100: 0.146336\n",
      "2022-11-09 02:19:11,731 INFO     Training average negative_sample_loss at step 863100: 0.139170\n",
      "2022-11-09 02:19:11,731 INFO     Training average loss at step 863100: 0.142753\n",
      "2022-11-09 02:19:14,834 INFO     Training average positive_sample_loss at step 863200: 0.144639\n",
      "2022-11-09 02:19:14,834 INFO     Training average negative_sample_loss at step 863200: 0.139145\n",
      "2022-11-09 02:19:14,834 INFO     Training average loss at step 863200: 0.141892\n",
      "2022-11-09 02:19:17,933 INFO     Training average positive_sample_loss at step 863300: 0.144025\n",
      "2022-11-09 02:19:17,933 INFO     Training average negative_sample_loss at step 863300: 0.138885\n",
      "2022-11-09 02:19:17,933 INFO     Training average loss at step 863300: 0.141455\n",
      "2022-11-09 02:19:21,049 INFO     Training average positive_sample_loss at step 863400: 0.146597\n",
      "2022-11-09 02:19:21,050 INFO     Training average negative_sample_loss at step 863400: 0.138484\n",
      "2022-11-09 02:19:21,050 INFO     Training average loss at step 863400: 0.142541\n",
      "2022-11-09 02:19:24,169 INFO     Training average positive_sample_loss at step 863500: 0.144814\n",
      "2022-11-09 02:19:24,169 INFO     Training average negative_sample_loss at step 863500: 0.133942\n",
      "2022-11-09 02:19:24,169 INFO     Training average loss at step 863500: 0.139378\n",
      "2022-11-09 02:19:27,292 INFO     Training average positive_sample_loss at step 863600: 0.140647\n",
      "2022-11-09 02:19:27,292 INFO     Training average negative_sample_loss at step 863600: 0.141949\n",
      "2022-11-09 02:19:27,292 INFO     Training average loss at step 863600: 0.141298\n",
      "2022-11-09 02:19:30,393 INFO     Training average positive_sample_loss at step 863700: 0.143184\n",
      "2022-11-09 02:19:30,393 INFO     Training average negative_sample_loss at step 863700: 0.138817\n",
      "2022-11-09 02:19:30,393 INFO     Training average loss at step 863700: 0.141000\n",
      "2022-11-09 02:19:33,494 INFO     Training average positive_sample_loss at step 863800: 0.145645\n",
      "2022-11-09 02:19:33,494 INFO     Training average negative_sample_loss at step 863800: 0.135374\n",
      "2022-11-09 02:19:33,494 INFO     Training average loss at step 863800: 0.140510\n",
      "2022-11-09 02:19:36,606 INFO     Training average positive_sample_loss at step 863900: 0.141121\n",
      "2022-11-09 02:19:36,606 INFO     Training average negative_sample_loss at step 863900: 0.138054\n",
      "2022-11-09 02:19:36,606 INFO     Training average loss at step 863900: 0.139588\n",
      "2022-11-09 02:19:39,716 INFO     Training average positive_sample_loss at step 864000: 0.146850\n",
      "2022-11-09 02:19:39,716 INFO     Training average negative_sample_loss at step 864000: 0.140988\n",
      "2022-11-09 02:19:39,716 INFO     Training average loss at step 864000: 0.143919\n",
      "2022-11-09 02:19:42,832 INFO     Training average positive_sample_loss at step 864100: 0.140500\n",
      "2022-11-09 02:19:42,832 INFO     Training average negative_sample_loss at step 864100: 0.140324\n",
      "2022-11-09 02:19:42,832 INFO     Training average loss at step 864100: 0.140412\n",
      "2022-11-09 02:19:45,939 INFO     Training average positive_sample_loss at step 864200: 0.143110\n",
      "2022-11-09 02:19:45,940 INFO     Training average negative_sample_loss at step 864200: 0.142423\n",
      "2022-11-09 02:19:45,940 INFO     Training average loss at step 864200: 0.142767\n",
      "2022-11-09 02:19:49,059 INFO     Training average positive_sample_loss at step 864300: 0.146823\n",
      "2022-11-09 02:19:49,059 INFO     Training average negative_sample_loss at step 864300: 0.136577\n",
      "2022-11-09 02:19:49,059 INFO     Training average loss at step 864300: 0.141700\n",
      "2022-11-09 02:19:52,174 INFO     Training average positive_sample_loss at step 864400: 0.147430\n",
      "2022-11-09 02:19:52,174 INFO     Training average negative_sample_loss at step 864400: 0.138463\n",
      "2022-11-09 02:19:52,174 INFO     Training average loss at step 864400: 0.142946\n",
      "2022-11-09 02:19:55,292 INFO     Training average positive_sample_loss at step 864500: 0.149307\n",
      "2022-11-09 02:19:55,292 INFO     Training average negative_sample_loss at step 864500: 0.137842\n",
      "2022-11-09 02:19:55,292 INFO     Training average loss at step 864500: 0.143575\n",
      "2022-11-09 02:19:58,405 INFO     Training average positive_sample_loss at step 864600: 0.147896\n",
      "2022-11-09 02:19:58,405 INFO     Training average negative_sample_loss at step 864600: 0.135717\n",
      "2022-11-09 02:19:58,405 INFO     Training average loss at step 864600: 0.141806\n",
      "2022-11-09 02:20:01,499 INFO     Training average positive_sample_loss at step 864700: 0.147306\n",
      "2022-11-09 02:20:01,499 INFO     Training average negative_sample_loss at step 864700: 0.138297\n",
      "2022-11-09 02:20:01,500 INFO     Training average loss at step 864700: 0.142802\n",
      "2022-11-09 02:20:04,592 INFO     Training average positive_sample_loss at step 864800: 0.142151\n",
      "2022-11-09 02:20:04,592 INFO     Training average negative_sample_loss at step 864800: 0.140372\n",
      "2022-11-09 02:20:04,592 INFO     Training average loss at step 864800: 0.141261\n",
      "2022-11-09 02:20:07,702 INFO     Training average positive_sample_loss at step 864900: 0.147184\n",
      "2022-11-09 02:20:07,702 INFO     Training average negative_sample_loss at step 864900: 0.134172\n",
      "2022-11-09 02:20:07,702 INFO     Training average loss at step 864900: 0.140678\n",
      "2022-11-09 02:20:10,811 INFO     Training average positive_sample_loss at step 865000: 0.147228\n",
      "2022-11-09 02:20:10,812 INFO     Training average negative_sample_loss at step 865000: 0.140059\n",
      "2022-11-09 02:20:10,812 INFO     Training average loss at step 865000: 0.143644\n",
      "2022-11-09 02:20:13,927 INFO     Training average positive_sample_loss at step 865100: 0.143244\n",
      "2022-11-09 02:20:13,927 INFO     Training average negative_sample_loss at step 865100: 0.137882\n",
      "2022-11-09 02:20:13,927 INFO     Training average loss at step 865100: 0.140563\n",
      "2022-11-09 02:20:17,036 INFO     Training average positive_sample_loss at step 865200: 0.142550\n",
      "2022-11-09 02:20:17,036 INFO     Training average negative_sample_loss at step 865200: 0.134807\n",
      "2022-11-09 02:20:17,036 INFO     Training average loss at step 865200: 0.138678\n",
      "2022-11-09 02:20:20,151 INFO     Training average positive_sample_loss at step 865300: 0.146942\n",
      "2022-11-09 02:20:20,152 INFO     Training average negative_sample_loss at step 865300: 0.139540\n",
      "2022-11-09 02:20:20,152 INFO     Training average loss at step 865300: 0.143241\n",
      "2022-11-09 02:20:23,274 INFO     Training average positive_sample_loss at step 865400: 0.143130\n",
      "2022-11-09 02:20:23,275 INFO     Training average negative_sample_loss at step 865400: 0.138586\n",
      "2022-11-09 02:20:23,275 INFO     Training average loss at step 865400: 0.140858\n",
      "2022-11-09 02:20:26,394 INFO     Training average positive_sample_loss at step 865500: 0.146370\n",
      "2022-11-09 02:20:26,394 INFO     Training average negative_sample_loss at step 865500: 0.140136\n",
      "2022-11-09 02:20:26,394 INFO     Training average loss at step 865500: 0.143253\n",
      "2022-11-09 02:20:29,508 INFO     Training average positive_sample_loss at step 865600: 0.146449\n",
      "2022-11-09 02:20:29,508 INFO     Training average negative_sample_loss at step 865600: 0.138225\n",
      "2022-11-09 02:20:29,508 INFO     Training average loss at step 865600: 0.142337\n",
      "2022-11-09 02:20:32,619 INFO     Training average positive_sample_loss at step 865700: 0.144710\n",
      "2022-11-09 02:20:32,619 INFO     Training average negative_sample_loss at step 865700: 0.135074\n",
      "2022-11-09 02:20:32,619 INFO     Training average loss at step 865700: 0.139892\n",
      "2022-11-09 02:20:35,731 INFO     Training average positive_sample_loss at step 865800: 0.145417\n",
      "2022-11-09 02:20:35,731 INFO     Training average negative_sample_loss at step 865800: 0.139816\n",
      "2022-11-09 02:20:35,732 INFO     Training average loss at step 865800: 0.142617\n",
      "2022-11-09 02:20:38,844 INFO     Training average positive_sample_loss at step 865900: 0.141701\n",
      "2022-11-09 02:20:38,845 INFO     Training average negative_sample_loss at step 865900: 0.134662\n",
      "2022-11-09 02:20:38,845 INFO     Training average loss at step 865900: 0.138182\n",
      "2022-11-09 02:20:41,940 INFO     Training average positive_sample_loss at step 866000: 0.148737\n",
      "2022-11-09 02:20:41,940 INFO     Training average negative_sample_loss at step 866000: 0.135408\n",
      "2022-11-09 02:20:41,940 INFO     Training average loss at step 866000: 0.142073\n",
      "2022-11-09 02:20:45,050 INFO     Training average positive_sample_loss at step 866100: 0.145673\n",
      "2022-11-09 02:20:45,050 INFO     Training average negative_sample_loss at step 866100: 0.141567\n",
      "2022-11-09 02:20:45,050 INFO     Training average loss at step 866100: 0.143620\n",
      "2022-11-09 02:20:48,169 INFO     Training average positive_sample_loss at step 866200: 0.145911\n",
      "2022-11-09 02:20:48,169 INFO     Training average negative_sample_loss at step 866200: 0.135916\n",
      "2022-11-09 02:20:48,169 INFO     Training average loss at step 866200: 0.140914\n",
      "2022-11-09 02:20:51,295 INFO     Training average positive_sample_loss at step 866300: 0.142235\n",
      "2022-11-09 02:20:51,295 INFO     Training average negative_sample_loss at step 866300: 0.139437\n",
      "2022-11-09 02:20:51,295 INFO     Training average loss at step 866300: 0.140836\n",
      "2022-11-09 02:20:54,428 INFO     Training average positive_sample_loss at step 866400: 0.145477\n",
      "2022-11-09 02:20:54,428 INFO     Training average negative_sample_loss at step 866400: 0.139895\n",
      "2022-11-09 02:20:54,428 INFO     Training average loss at step 866400: 0.142686\n",
      "2022-11-09 02:20:57,548 INFO     Training average positive_sample_loss at step 866500: 0.143817\n",
      "2022-11-09 02:20:57,549 INFO     Training average negative_sample_loss at step 866500: 0.137169\n",
      "2022-11-09 02:20:57,549 INFO     Training average loss at step 866500: 0.140493\n",
      "2022-11-09 02:21:01,677 INFO     Training average positive_sample_loss at step 866600: 0.143181\n",
      "2022-11-09 02:21:01,677 INFO     Training average negative_sample_loss at step 866600: 0.137841\n",
      "2022-11-09 02:21:01,677 INFO     Training average loss at step 866600: 0.140511\n",
      "2022-11-09 02:21:04,792 INFO     Training average positive_sample_loss at step 866700: 0.142384\n",
      "2022-11-09 02:21:04,792 INFO     Training average negative_sample_loss at step 866700: 0.135839\n",
      "2022-11-09 02:21:04,792 INFO     Training average loss at step 866700: 0.139111\n",
      "2022-11-09 02:21:08,729 INFO     Training average positive_sample_loss at step 866800: 0.142915\n",
      "2022-11-09 02:21:08,729 INFO     Training average negative_sample_loss at step 866800: 0.136759\n",
      "2022-11-09 02:21:08,729 INFO     Training average loss at step 866800: 0.139837\n",
      "2022-11-09 02:21:11,843 INFO     Training average positive_sample_loss at step 866900: 0.147134\n",
      "2022-11-09 02:21:11,843 INFO     Training average negative_sample_loss at step 866900: 0.136780\n",
      "2022-11-09 02:21:11,843 INFO     Training average loss at step 866900: 0.141957\n",
      "2022-11-09 02:21:16,157 INFO     Training average positive_sample_loss at step 867000: 0.139655\n",
      "2022-11-09 02:21:16,157 INFO     Training average negative_sample_loss at step 867000: 0.138817\n",
      "2022-11-09 02:21:16,157 INFO     Training average loss at step 867000: 0.139236\n",
      "2022-11-09 02:21:20,593 INFO     Training average positive_sample_loss at step 867100: 0.143527\n",
      "2022-11-09 02:21:20,593 INFO     Training average negative_sample_loss at step 867100: 0.135431\n",
      "2022-11-09 02:21:20,593 INFO     Training average loss at step 867100: 0.139479\n",
      "2022-11-09 02:21:23,714 INFO     Training average positive_sample_loss at step 867200: 0.143866\n",
      "2022-11-09 02:21:23,714 INFO     Training average negative_sample_loss at step 867200: 0.139522\n",
      "2022-11-09 02:21:23,714 INFO     Training average loss at step 867200: 0.141694\n",
      "2022-11-09 02:21:26,831 INFO     Training average positive_sample_loss at step 867300: 0.137489\n",
      "2022-11-09 02:21:26,831 INFO     Training average negative_sample_loss at step 867300: 0.138084\n",
      "2022-11-09 02:21:26,831 INFO     Training average loss at step 867300: 0.137786\n",
      "2022-11-09 02:21:29,928 INFO     Training average positive_sample_loss at step 867400: 0.151108\n",
      "2022-11-09 02:21:29,928 INFO     Training average negative_sample_loss at step 867400: 0.137919\n",
      "2022-11-09 02:21:29,928 INFO     Training average loss at step 867400: 0.144514\n",
      "2022-11-09 02:21:33,042 INFO     Training average positive_sample_loss at step 867500: 0.145605\n",
      "2022-11-09 02:21:33,042 INFO     Training average negative_sample_loss at step 867500: 0.138212\n",
      "2022-11-09 02:21:33,042 INFO     Training average loss at step 867500: 0.141909\n",
      "2022-11-09 02:21:36,163 INFO     Training average positive_sample_loss at step 867600: 0.148348\n",
      "2022-11-09 02:21:36,163 INFO     Training average negative_sample_loss at step 867600: 0.137669\n",
      "2022-11-09 02:21:36,163 INFO     Training average loss at step 867600: 0.143009\n",
      "2022-11-09 02:21:39,282 INFO     Training average positive_sample_loss at step 867700: 0.141240\n",
      "2022-11-09 02:21:39,282 INFO     Training average negative_sample_loss at step 867700: 0.137606\n",
      "2022-11-09 02:21:39,282 INFO     Training average loss at step 867700: 0.139423\n",
      "2022-11-09 02:21:42,402 INFO     Training average positive_sample_loss at step 867800: 0.143162\n",
      "2022-11-09 02:21:42,402 INFO     Training average negative_sample_loss at step 867800: 0.138390\n",
      "2022-11-09 02:21:42,402 INFO     Training average loss at step 867800: 0.140776\n",
      "2022-11-09 02:21:45,524 INFO     Training average positive_sample_loss at step 867900: 0.146003\n",
      "2022-11-09 02:21:45,524 INFO     Training average negative_sample_loss at step 867900: 0.140894\n",
      "2022-11-09 02:21:45,524 INFO     Training average loss at step 867900: 0.143449\n",
      "2022-11-09 02:21:48,637 INFO     Training average positive_sample_loss at step 868000: 0.144499\n",
      "2022-11-09 02:21:48,637 INFO     Training average negative_sample_loss at step 868000: 0.137444\n",
      "2022-11-09 02:21:48,637 INFO     Training average loss at step 868000: 0.140971\n",
      "2022-11-09 02:21:51,761 INFO     Training average positive_sample_loss at step 868100: 0.145861\n",
      "2022-11-09 02:21:51,761 INFO     Training average negative_sample_loss at step 868100: 0.140151\n",
      "2022-11-09 02:21:51,761 INFO     Training average loss at step 868100: 0.143006\n",
      "2022-11-09 02:21:54,852 INFO     Training average positive_sample_loss at step 868200: 0.151244\n",
      "2022-11-09 02:21:54,852 INFO     Training average negative_sample_loss at step 868200: 0.138646\n",
      "2022-11-09 02:21:54,852 INFO     Training average loss at step 868200: 0.144945\n",
      "2022-11-09 02:21:57,967 INFO     Training average positive_sample_loss at step 868300: 0.141698\n",
      "2022-11-09 02:21:57,967 INFO     Training average negative_sample_loss at step 868300: 0.136141\n",
      "2022-11-09 02:21:57,967 INFO     Training average loss at step 868300: 0.138919\n",
      "2022-11-09 02:22:01,085 INFO     Training average positive_sample_loss at step 868400: 0.142073\n",
      "2022-11-09 02:22:01,085 INFO     Training average negative_sample_loss at step 868400: 0.134505\n",
      "2022-11-09 02:22:01,085 INFO     Training average loss at step 868400: 0.138289\n",
      "2022-11-09 02:22:04,200 INFO     Training average positive_sample_loss at step 868500: 0.141166\n",
      "2022-11-09 02:22:04,200 INFO     Training average negative_sample_loss at step 868500: 0.134800\n",
      "2022-11-09 02:22:04,200 INFO     Training average loss at step 868500: 0.137983\n",
      "2022-11-09 02:22:07,326 INFO     Training average positive_sample_loss at step 868600: 0.142602\n",
      "2022-11-09 02:22:07,326 INFO     Training average negative_sample_loss at step 868600: 0.136310\n",
      "2022-11-09 02:22:07,326 INFO     Training average loss at step 868600: 0.139456\n",
      "2022-11-09 02:22:10,453 INFO     Training average positive_sample_loss at step 868700: 0.144383\n",
      "2022-11-09 02:22:10,453 INFO     Training average negative_sample_loss at step 868700: 0.137510\n",
      "2022-11-09 02:22:10,453 INFO     Training average loss at step 868700: 0.140946\n",
      "2022-11-09 02:22:13,551 INFO     Training average positive_sample_loss at step 868800: 0.147688\n",
      "2022-11-09 02:22:13,551 INFO     Training average negative_sample_loss at step 868800: 0.138295\n",
      "2022-11-09 02:22:13,551 INFO     Training average loss at step 868800: 0.142991\n",
      "2022-11-09 02:22:16,655 INFO     Training average positive_sample_loss at step 868900: 0.144816\n",
      "2022-11-09 02:22:16,655 INFO     Training average negative_sample_loss at step 868900: 0.135830\n",
      "2022-11-09 02:22:16,655 INFO     Training average loss at step 868900: 0.140323\n",
      "2022-11-09 02:22:19,760 INFO     Training average positive_sample_loss at step 869000: 0.139577\n",
      "2022-11-09 02:22:19,760 INFO     Training average negative_sample_loss at step 869000: 0.134908\n",
      "2022-11-09 02:22:19,760 INFO     Training average loss at step 869000: 0.137243\n",
      "2022-11-09 02:22:22,872 INFO     Training average positive_sample_loss at step 869100: 0.143051\n",
      "2022-11-09 02:22:22,872 INFO     Training average negative_sample_loss at step 869100: 0.139603\n",
      "2022-11-09 02:22:22,872 INFO     Training average loss at step 869100: 0.141327\n",
      "2022-11-09 02:22:25,986 INFO     Training average positive_sample_loss at step 869200: 0.149394\n",
      "2022-11-09 02:22:25,986 INFO     Training average negative_sample_loss at step 869200: 0.141062\n",
      "2022-11-09 02:22:25,986 INFO     Training average loss at step 869200: 0.145228\n",
      "2022-11-09 02:22:29,101 INFO     Training average positive_sample_loss at step 869300: 0.142816\n",
      "2022-11-09 02:22:29,101 INFO     Training average negative_sample_loss at step 869300: 0.137884\n",
      "2022-11-09 02:22:29,101 INFO     Training average loss at step 869300: 0.140350\n",
      "2022-11-09 02:22:32,211 INFO     Training average positive_sample_loss at step 869400: 0.140073\n",
      "2022-11-09 02:22:32,211 INFO     Training average negative_sample_loss at step 869400: 0.138324\n",
      "2022-11-09 02:22:32,211 INFO     Training average loss at step 869400: 0.139199\n",
      "2022-11-09 02:22:35,327 INFO     Training average positive_sample_loss at step 869500: 0.140590\n",
      "2022-11-09 02:22:35,327 INFO     Training average negative_sample_loss at step 869500: 0.136399\n",
      "2022-11-09 02:22:35,327 INFO     Training average loss at step 869500: 0.138495\n",
      "2022-11-09 02:22:38,443 INFO     Training average positive_sample_loss at step 869600: 0.144858\n",
      "2022-11-09 02:22:38,443 INFO     Training average negative_sample_loss at step 869600: 0.138129\n",
      "2022-11-09 02:22:38,443 INFO     Training average loss at step 869600: 0.141493\n",
      "2022-11-09 02:22:41,558 INFO     Training average positive_sample_loss at step 869700: 0.141123\n",
      "2022-11-09 02:22:41,558 INFO     Training average negative_sample_loss at step 869700: 0.138162\n",
      "2022-11-09 02:22:41,558 INFO     Training average loss at step 869700: 0.139643\n",
      "2022-11-09 02:22:44,676 INFO     Training average positive_sample_loss at step 869800: 0.147234\n",
      "2022-11-09 02:22:44,676 INFO     Training average negative_sample_loss at step 869800: 0.138215\n",
      "2022-11-09 02:22:44,676 INFO     Training average loss at step 869800: 0.142725\n",
      "2022-11-09 02:22:47,781 INFO     Training average positive_sample_loss at step 869900: 0.142376\n",
      "2022-11-09 02:22:47,782 INFO     Training average negative_sample_loss at step 869900: 0.138935\n",
      "2022-11-09 02:22:47,782 INFO     Training average loss at step 869900: 0.140655\n",
      "2022-11-09 02:22:53,648 INFO     Training average positive_sample_loss at step 870000: 0.139013\n",
      "2022-11-09 02:22:53,648 INFO     Training average negative_sample_loss at step 870000: 0.134947\n",
      "2022-11-09 02:22:53,648 INFO     Training average loss at step 870000: 0.136980\n",
      "2022-11-09 02:22:56,771 INFO     Training average positive_sample_loss at step 870100: 0.143121\n",
      "2022-11-09 02:22:56,771 INFO     Training average negative_sample_loss at step 870100: 0.142135\n",
      "2022-11-09 02:22:56,771 INFO     Training average loss at step 870100: 0.142628\n",
      "2022-11-09 02:22:59,864 INFO     Training average positive_sample_loss at step 870200: 0.144470\n",
      "2022-11-09 02:22:59,864 INFO     Training average negative_sample_loss at step 870200: 0.138039\n",
      "2022-11-09 02:22:59,864 INFO     Training average loss at step 870200: 0.141254\n",
      "2022-11-09 02:23:02,955 INFO     Training average positive_sample_loss at step 870300: 0.144964\n",
      "2022-11-09 02:23:02,955 INFO     Training average negative_sample_loss at step 870300: 0.139042\n",
      "2022-11-09 02:23:02,955 INFO     Training average loss at step 870300: 0.142003\n",
      "2022-11-09 02:23:06,056 INFO     Training average positive_sample_loss at step 870400: 0.142702\n",
      "2022-11-09 02:23:06,056 INFO     Training average negative_sample_loss at step 870400: 0.136908\n",
      "2022-11-09 02:23:06,056 INFO     Training average loss at step 870400: 0.139805\n",
      "2022-11-09 02:23:09,175 INFO     Training average positive_sample_loss at step 870500: 0.148284\n",
      "2022-11-09 02:23:09,175 INFO     Training average negative_sample_loss at step 870500: 0.141013\n",
      "2022-11-09 02:23:09,175 INFO     Training average loss at step 870500: 0.144649\n",
      "2022-11-09 02:23:12,278 INFO     Training average positive_sample_loss at step 870600: 0.142049\n",
      "2022-11-09 02:23:12,278 INFO     Training average negative_sample_loss at step 870600: 0.135998\n",
      "2022-11-09 02:23:12,278 INFO     Training average loss at step 870600: 0.139024\n",
      "2022-11-09 02:23:15,378 INFO     Training average positive_sample_loss at step 870700: 0.141293\n",
      "2022-11-09 02:23:15,378 INFO     Training average negative_sample_loss at step 870700: 0.136437\n",
      "2022-11-09 02:23:15,378 INFO     Training average loss at step 870700: 0.138865\n",
      "2022-11-09 02:23:21,458 INFO     Training average positive_sample_loss at step 870800: 0.139884\n",
      "2022-11-09 02:23:21,458 INFO     Training average negative_sample_loss at step 870800: 0.138387\n",
      "2022-11-09 02:23:21,458 INFO     Training average loss at step 870800: 0.139135\n",
      "2022-11-09 02:23:24,566 INFO     Training average positive_sample_loss at step 870900: 0.139521\n",
      "2022-11-09 02:23:24,566 INFO     Training average negative_sample_loss at step 870900: 0.138253\n",
      "2022-11-09 02:23:24,566 INFO     Training average loss at step 870900: 0.138887\n",
      "2022-11-09 02:23:27,680 INFO     Training average positive_sample_loss at step 871000: 0.133779\n",
      "2022-11-09 02:23:27,680 INFO     Training average negative_sample_loss at step 871000: 0.136207\n",
      "2022-11-09 02:23:27,680 INFO     Training average loss at step 871000: 0.134993\n",
      "2022-11-09 02:23:30,805 INFO     Training average positive_sample_loss at step 871100: 0.136384\n",
      "2022-11-09 02:23:30,805 INFO     Training average negative_sample_loss at step 871100: 0.134475\n",
      "2022-11-09 02:23:30,805 INFO     Training average loss at step 871100: 0.135430\n",
      "2022-11-09 02:23:33,938 INFO     Training average positive_sample_loss at step 871200: 0.133216\n",
      "2022-11-09 02:23:33,938 INFO     Training average negative_sample_loss at step 871200: 0.134848\n",
      "2022-11-09 02:23:33,938 INFO     Training average loss at step 871200: 0.134032\n",
      "2022-11-09 02:23:37,057 INFO     Training average positive_sample_loss at step 871300: 0.137362\n",
      "2022-11-09 02:23:37,057 INFO     Training average negative_sample_loss at step 871300: 0.140443\n",
      "2022-11-09 02:23:37,057 INFO     Training average loss at step 871300: 0.138903\n",
      "2022-11-09 02:23:40,164 INFO     Training average positive_sample_loss at step 871400: 0.135259\n",
      "2022-11-09 02:23:40,165 INFO     Training average negative_sample_loss at step 871400: 0.135293\n",
      "2022-11-09 02:23:40,165 INFO     Training average loss at step 871400: 0.135276\n",
      "2022-11-09 02:23:43,272 INFO     Training average positive_sample_loss at step 871500: 0.135515\n",
      "2022-11-09 02:23:43,272 INFO     Training average negative_sample_loss at step 871500: 0.139269\n",
      "2022-11-09 02:23:43,272 INFO     Training average loss at step 871500: 0.137392\n",
      "2022-11-09 02:23:46,374 INFO     Training average positive_sample_loss at step 871600: 0.136684\n",
      "2022-11-09 02:23:46,374 INFO     Training average negative_sample_loss at step 871600: 0.133937\n",
      "2022-11-09 02:23:46,374 INFO     Training average loss at step 871600: 0.135310\n",
      "2022-11-09 02:23:49,486 INFO     Training average positive_sample_loss at step 871700: 0.139457\n",
      "2022-11-09 02:23:49,486 INFO     Training average negative_sample_loss at step 871700: 0.136826\n",
      "2022-11-09 02:23:49,486 INFO     Training average loss at step 871700: 0.138142\n",
      "2022-11-09 02:23:52,607 INFO     Training average positive_sample_loss at step 871800: 0.137761\n",
      "2022-11-09 02:23:52,607 INFO     Training average negative_sample_loss at step 871800: 0.138862\n",
      "2022-11-09 02:23:52,607 INFO     Training average loss at step 871800: 0.138311\n",
      "2022-11-09 02:23:55,722 INFO     Training average positive_sample_loss at step 871900: 0.140679\n",
      "2022-11-09 02:23:55,722 INFO     Training average negative_sample_loss at step 871900: 0.136585\n",
      "2022-11-09 02:23:55,722 INFO     Training average loss at step 871900: 0.138632\n",
      "2022-11-09 02:23:58,838 INFO     Training average positive_sample_loss at step 872000: 0.138715\n",
      "2022-11-09 02:23:58,838 INFO     Training average negative_sample_loss at step 872000: 0.137987\n",
      "2022-11-09 02:23:58,838 INFO     Training average loss at step 872000: 0.138351\n",
      "2022-11-09 02:24:01,950 INFO     Training average positive_sample_loss at step 872100: 0.138985\n",
      "2022-11-09 02:24:01,950 INFO     Training average negative_sample_loss at step 872100: 0.137010\n",
      "2022-11-09 02:24:01,950 INFO     Training average loss at step 872100: 0.137997\n",
      "2022-11-09 02:24:05,058 INFO     Training average positive_sample_loss at step 872200: 0.144272\n",
      "2022-11-09 02:24:05,058 INFO     Training average negative_sample_loss at step 872200: 0.135106\n",
      "2022-11-09 02:24:05,058 INFO     Training average loss at step 872200: 0.139689\n",
      "2022-11-09 02:24:08,161 INFO     Training average positive_sample_loss at step 872300: 0.137940\n",
      "2022-11-09 02:24:08,161 INFO     Training average negative_sample_loss at step 872300: 0.138366\n",
      "2022-11-09 02:24:08,161 INFO     Training average loss at step 872300: 0.138153\n",
      "2022-11-09 02:24:11,255 INFO     Training average positive_sample_loss at step 872400: 0.140311\n",
      "2022-11-09 02:24:11,255 INFO     Training average negative_sample_loss at step 872400: 0.138397\n",
      "2022-11-09 02:24:11,255 INFO     Training average loss at step 872400: 0.139354\n",
      "2022-11-09 02:24:14,368 INFO     Training average positive_sample_loss at step 872500: 0.138365\n",
      "2022-11-09 02:24:14,368 INFO     Training average negative_sample_loss at step 872500: 0.138628\n",
      "2022-11-09 02:24:14,368 INFO     Training average loss at step 872500: 0.138496\n",
      "2022-11-09 02:24:17,491 INFO     Training average positive_sample_loss at step 872600: 0.142659\n",
      "2022-11-09 02:24:17,491 INFO     Training average negative_sample_loss at step 872600: 0.135243\n",
      "2022-11-09 02:24:17,491 INFO     Training average loss at step 872600: 0.138951\n",
      "2022-11-09 02:24:20,599 INFO     Training average positive_sample_loss at step 872700: 0.140227\n",
      "2022-11-09 02:24:20,599 INFO     Training average negative_sample_loss at step 872700: 0.133628\n",
      "2022-11-09 02:24:20,599 INFO     Training average loss at step 872700: 0.136927\n",
      "2022-11-09 02:24:23,706 INFO     Training average positive_sample_loss at step 872800: 0.137998\n",
      "2022-11-09 02:24:23,706 INFO     Training average negative_sample_loss at step 872800: 0.136575\n",
      "2022-11-09 02:24:23,706 INFO     Training average loss at step 872800: 0.137286\n",
      "2022-11-09 02:24:26,812 INFO     Training average positive_sample_loss at step 872900: 0.138395\n",
      "2022-11-09 02:24:26,812 INFO     Training average negative_sample_loss at step 872900: 0.138698\n",
      "2022-11-09 02:24:26,812 INFO     Training average loss at step 872900: 0.138547\n",
      "2022-11-09 02:24:29,910 INFO     Training average positive_sample_loss at step 873000: 0.137474\n",
      "2022-11-09 02:24:29,910 INFO     Training average negative_sample_loss at step 873000: 0.140281\n",
      "2022-11-09 02:24:29,910 INFO     Training average loss at step 873000: 0.138878\n",
      "2022-11-09 02:24:33,024 INFO     Training average positive_sample_loss at step 873100: 0.138227\n",
      "2022-11-09 02:24:33,024 INFO     Training average negative_sample_loss at step 873100: 0.134390\n",
      "2022-11-09 02:24:33,024 INFO     Training average loss at step 873100: 0.136309\n",
      "2022-11-09 02:24:36,136 INFO     Training average positive_sample_loss at step 873200: 0.135110\n",
      "2022-11-09 02:24:36,136 INFO     Training average negative_sample_loss at step 873200: 0.135094\n",
      "2022-11-09 02:24:36,136 INFO     Training average loss at step 873200: 0.135102\n",
      "2022-11-09 02:24:39,251 INFO     Training average positive_sample_loss at step 873300: 0.138126\n",
      "2022-11-09 02:24:39,251 INFO     Training average negative_sample_loss at step 873300: 0.134531\n",
      "2022-11-09 02:24:39,251 INFO     Training average loss at step 873300: 0.136328\n",
      "2022-11-09 02:24:42,376 INFO     Training average positive_sample_loss at step 873400: 0.137370\n",
      "2022-11-09 02:24:42,377 INFO     Training average negative_sample_loss at step 873400: 0.136994\n",
      "2022-11-09 02:24:42,377 INFO     Training average loss at step 873400: 0.137182\n",
      "2022-11-09 02:24:45,502 INFO     Training average positive_sample_loss at step 873500: 0.142937\n",
      "2022-11-09 02:24:45,503 INFO     Training average negative_sample_loss at step 873500: 0.138097\n",
      "2022-11-09 02:24:45,503 INFO     Training average loss at step 873500: 0.140517\n",
      "2022-11-09 02:24:48,626 INFO     Training average positive_sample_loss at step 873600: 0.139164\n",
      "2022-11-09 02:24:48,626 INFO     Training average negative_sample_loss at step 873600: 0.134685\n",
      "2022-11-09 02:24:48,626 INFO     Training average loss at step 873600: 0.136925\n",
      "2022-11-09 02:24:51,736 INFO     Training average positive_sample_loss at step 873700: 0.136472\n",
      "2022-11-09 02:24:51,736 INFO     Training average negative_sample_loss at step 873700: 0.133531\n",
      "2022-11-09 02:24:51,736 INFO     Training average loss at step 873700: 0.135001\n",
      "2022-11-09 02:24:54,847 INFO     Training average positive_sample_loss at step 873800: 0.135757\n",
      "2022-11-09 02:24:54,848 INFO     Training average negative_sample_loss at step 873800: 0.131099\n",
      "2022-11-09 02:24:54,848 INFO     Training average loss at step 873800: 0.133428\n",
      "2022-11-09 02:24:57,946 INFO     Training average positive_sample_loss at step 873900: 0.136494\n",
      "2022-11-09 02:24:57,946 INFO     Training average negative_sample_loss at step 873900: 0.130389\n",
      "2022-11-09 02:24:57,946 INFO     Training average loss at step 873900: 0.133441\n",
      "2022-11-09 02:25:01,042 INFO     Training average positive_sample_loss at step 874000: 0.143923\n",
      "2022-11-09 02:25:01,043 INFO     Training average negative_sample_loss at step 874000: 0.134909\n",
      "2022-11-09 02:25:01,043 INFO     Training average loss at step 874000: 0.139416\n",
      "2022-11-09 02:25:04,149 INFO     Training average positive_sample_loss at step 874100: 0.140523\n",
      "2022-11-09 02:25:04,149 INFO     Training average negative_sample_loss at step 874100: 0.134242\n",
      "2022-11-09 02:25:04,149 INFO     Training average loss at step 874100: 0.137383\n",
      "2022-11-09 02:25:07,265 INFO     Training average positive_sample_loss at step 874200: 0.142272\n",
      "2022-11-09 02:25:07,265 INFO     Training average negative_sample_loss at step 874200: 0.139212\n",
      "2022-11-09 02:25:07,265 INFO     Training average loss at step 874200: 0.140742\n",
      "2022-11-09 02:25:10,371 INFO     Training average positive_sample_loss at step 874300: 0.139214\n",
      "2022-11-09 02:25:10,371 INFO     Training average negative_sample_loss at step 874300: 0.137076\n",
      "2022-11-09 02:25:10,371 INFO     Training average loss at step 874300: 0.138145\n",
      "2022-11-09 02:25:13,477 INFO     Training average positive_sample_loss at step 874400: 0.135731\n",
      "2022-11-09 02:25:13,477 INFO     Training average negative_sample_loss at step 874400: 0.136943\n",
      "2022-11-09 02:25:13,477 INFO     Training average loss at step 874400: 0.136337\n",
      "2022-11-09 02:25:16,584 INFO     Training average positive_sample_loss at step 874500: 0.140572\n",
      "2022-11-09 02:25:16,584 INFO     Training average negative_sample_loss at step 874500: 0.135095\n",
      "2022-11-09 02:25:16,584 INFO     Training average loss at step 874500: 0.137834\n",
      "2022-11-09 02:25:19,701 INFO     Training average positive_sample_loss at step 874600: 0.137032\n",
      "2022-11-09 02:25:19,701 INFO     Training average negative_sample_loss at step 874600: 0.134195\n",
      "2022-11-09 02:25:19,701 INFO     Training average loss at step 874600: 0.135613\n",
      "2022-11-09 02:25:22,811 INFO     Training average positive_sample_loss at step 874700: 0.135005\n",
      "2022-11-09 02:25:22,812 INFO     Training average negative_sample_loss at step 874700: 0.135439\n",
      "2022-11-09 02:25:22,812 INFO     Training average loss at step 874700: 0.135222\n",
      "2022-11-09 02:25:25,929 INFO     Training average positive_sample_loss at step 874800: 0.136459\n",
      "2022-11-09 02:25:25,930 INFO     Training average negative_sample_loss at step 874800: 0.137554\n",
      "2022-11-09 02:25:25,930 INFO     Training average loss at step 874800: 0.137007\n",
      "2022-11-09 02:25:29,054 INFO     Training average positive_sample_loss at step 874900: 0.139566\n",
      "2022-11-09 02:25:29,054 INFO     Training average negative_sample_loss at step 874900: 0.130502\n",
      "2022-11-09 02:25:29,054 INFO     Training average loss at step 874900: 0.135034\n",
      "2022-11-09 02:25:32,166 INFO     Training average positive_sample_loss at step 875000: 0.137121\n",
      "2022-11-09 02:25:32,166 INFO     Training average negative_sample_loss at step 875000: 0.134014\n",
      "2022-11-09 02:25:32,166 INFO     Training average loss at step 875000: 0.135568\n",
      "2022-11-09 02:25:35,277 INFO     Training average positive_sample_loss at step 875100: 0.139584\n",
      "2022-11-09 02:25:35,277 INFO     Training average negative_sample_loss at step 875100: 0.135056\n",
      "2022-11-09 02:25:35,277 INFO     Training average loss at step 875100: 0.137320\n",
      "2022-11-09 02:25:38,385 INFO     Training average positive_sample_loss at step 875200: 0.136448\n",
      "2022-11-09 02:25:38,385 INFO     Training average negative_sample_loss at step 875200: 0.136120\n",
      "2022-11-09 02:25:38,385 INFO     Training average loss at step 875200: 0.136284\n",
      "2022-11-09 02:25:41,483 INFO     Training average positive_sample_loss at step 875300: 0.141691\n",
      "2022-11-09 02:25:41,483 INFO     Training average negative_sample_loss at step 875300: 0.135690\n",
      "2022-11-09 02:25:41,483 INFO     Training average loss at step 875300: 0.138690\n",
      "2022-11-09 02:25:44,584 INFO     Training average positive_sample_loss at step 875400: 0.140135\n",
      "2022-11-09 02:25:44,584 INFO     Training average negative_sample_loss at step 875400: 0.137057\n",
      "2022-11-09 02:25:44,584 INFO     Training average loss at step 875400: 0.138596\n",
      "2022-11-09 02:25:47,675 INFO     Training average positive_sample_loss at step 875500: 0.140938\n",
      "2022-11-09 02:25:47,675 INFO     Training average negative_sample_loss at step 875500: 0.136600\n",
      "2022-11-09 02:25:47,675 INFO     Training average loss at step 875500: 0.138769\n",
      "2022-11-09 02:25:50,770 INFO     Training average positive_sample_loss at step 875600: 0.140839\n",
      "2022-11-09 02:25:50,770 INFO     Training average negative_sample_loss at step 875600: 0.134272\n",
      "2022-11-09 02:25:50,770 INFO     Training average loss at step 875600: 0.137555\n",
      "2022-11-09 02:25:53,889 INFO     Training average positive_sample_loss at step 875700: 0.141566\n",
      "2022-11-09 02:25:53,889 INFO     Training average negative_sample_loss at step 875700: 0.132686\n",
      "2022-11-09 02:25:53,889 INFO     Training average loss at step 875700: 0.137126\n",
      "2022-11-09 02:25:56,997 INFO     Training average positive_sample_loss at step 875800: 0.135135\n",
      "2022-11-09 02:25:56,997 INFO     Training average negative_sample_loss at step 875800: 0.131467\n",
      "2022-11-09 02:25:56,997 INFO     Training average loss at step 875800: 0.133301\n",
      "2022-11-09 02:26:00,124 INFO     Training average positive_sample_loss at step 875900: 0.137863\n",
      "2022-11-09 02:26:00,125 INFO     Training average negative_sample_loss at step 875900: 0.133433\n",
      "2022-11-09 02:26:00,125 INFO     Training average loss at step 875900: 0.135648\n",
      "2022-11-09 02:26:03,236 INFO     Training average positive_sample_loss at step 876000: 0.142713\n",
      "2022-11-09 02:26:03,236 INFO     Training average negative_sample_loss at step 876000: 0.142824\n",
      "2022-11-09 02:26:03,236 INFO     Training average loss at step 876000: 0.142768\n",
      "2022-11-09 02:26:06,348 INFO     Training average positive_sample_loss at step 876100: 0.137834\n",
      "2022-11-09 02:26:06,348 INFO     Training average negative_sample_loss at step 876100: 0.135353\n",
      "2022-11-09 02:26:06,348 INFO     Training average loss at step 876100: 0.136594\n",
      "2022-11-09 02:26:09,474 INFO     Training average positive_sample_loss at step 876200: 0.135902\n",
      "2022-11-09 02:26:09,474 INFO     Training average negative_sample_loss at step 876200: 0.138736\n",
      "2022-11-09 02:26:09,474 INFO     Training average loss at step 876200: 0.137319\n",
      "2022-11-09 02:26:12,597 INFO     Training average positive_sample_loss at step 876300: 0.140337\n",
      "2022-11-09 02:26:12,597 INFO     Training average negative_sample_loss at step 876300: 0.137632\n",
      "2022-11-09 02:26:12,597 INFO     Training average loss at step 876300: 0.138985\n",
      "2022-11-09 02:26:15,704 INFO     Training average positive_sample_loss at step 876400: 0.138657\n",
      "2022-11-09 02:26:15,704 INFO     Training average negative_sample_loss at step 876400: 0.136503\n",
      "2022-11-09 02:26:15,704 INFO     Training average loss at step 876400: 0.137580\n",
      "2022-11-09 02:26:18,825 INFO     Training average positive_sample_loss at step 876500: 0.139166\n",
      "2022-11-09 02:26:18,826 INFO     Training average negative_sample_loss at step 876500: 0.134275\n",
      "2022-11-09 02:26:18,826 INFO     Training average loss at step 876500: 0.136721\n",
      "2022-11-09 02:26:21,935 INFO     Training average positive_sample_loss at step 876600: 0.139394\n",
      "2022-11-09 02:26:21,935 INFO     Training average negative_sample_loss at step 876600: 0.137565\n",
      "2022-11-09 02:26:21,935 INFO     Training average loss at step 876600: 0.138479\n",
      "2022-11-09 02:26:25,050 INFO     Training average positive_sample_loss at step 876700: 0.136999\n",
      "2022-11-09 02:26:25,050 INFO     Training average negative_sample_loss at step 876700: 0.134843\n",
      "2022-11-09 02:26:25,050 INFO     Training average loss at step 876700: 0.135921\n",
      "2022-11-09 02:26:28,163 INFO     Training average positive_sample_loss at step 876800: 0.140423\n",
      "2022-11-09 02:26:28,163 INFO     Training average negative_sample_loss at step 876800: 0.132463\n",
      "2022-11-09 02:26:28,163 INFO     Training average loss at step 876800: 0.136443\n",
      "2022-11-09 02:26:31,280 INFO     Training average positive_sample_loss at step 876900: 0.137907\n",
      "2022-11-09 02:26:31,280 INFO     Training average negative_sample_loss at step 876900: 0.137329\n",
      "2022-11-09 02:26:31,280 INFO     Training average loss at step 876900: 0.137618\n",
      "2022-11-09 02:26:34,391 INFO     Training average positive_sample_loss at step 877000: 0.140561\n",
      "2022-11-09 02:26:34,391 INFO     Training average negative_sample_loss at step 877000: 0.141344\n",
      "2022-11-09 02:26:34,391 INFO     Training average loss at step 877000: 0.140953\n",
      "2022-11-09 02:26:37,486 INFO     Training average positive_sample_loss at step 877100: 0.144267\n",
      "2022-11-09 02:26:37,486 INFO     Training average negative_sample_loss at step 877100: 0.138793\n",
      "2022-11-09 02:26:37,486 INFO     Training average loss at step 877100: 0.141530\n",
      "2022-11-09 02:26:40,589 INFO     Training average positive_sample_loss at step 877200: 0.142490\n",
      "2022-11-09 02:26:40,589 INFO     Training average negative_sample_loss at step 877200: 0.138653\n",
      "2022-11-09 02:26:40,590 INFO     Training average loss at step 877200: 0.140571\n",
      "2022-11-09 02:26:43,687 INFO     Training average positive_sample_loss at step 877300: 0.140100\n",
      "2022-11-09 02:26:43,687 INFO     Training average negative_sample_loss at step 877300: 0.140283\n",
      "2022-11-09 02:26:43,688 INFO     Training average loss at step 877300: 0.140192\n",
      "2022-11-09 02:26:46,796 INFO     Training average positive_sample_loss at step 877400: 0.133044\n",
      "2022-11-09 02:26:46,796 INFO     Training average negative_sample_loss at step 877400: 0.132810\n",
      "2022-11-09 02:26:46,796 INFO     Training average loss at step 877400: 0.132927\n",
      "2022-11-09 02:26:49,919 INFO     Training average positive_sample_loss at step 877500: 0.141172\n",
      "2022-11-09 02:26:49,919 INFO     Training average negative_sample_loss at step 877500: 0.134668\n",
      "2022-11-09 02:26:49,919 INFO     Training average loss at step 877500: 0.137920\n",
      "2022-11-09 02:26:53,039 INFO     Training average positive_sample_loss at step 877600: 0.140156\n",
      "2022-11-09 02:26:53,039 INFO     Training average negative_sample_loss at step 877600: 0.133961\n",
      "2022-11-09 02:26:53,040 INFO     Training average loss at step 877600: 0.137059\n",
      "2022-11-09 02:26:56,165 INFO     Training average positive_sample_loss at step 877700: 0.135283\n",
      "2022-11-09 02:26:56,165 INFO     Training average negative_sample_loss at step 877700: 0.134696\n",
      "2022-11-09 02:26:56,165 INFO     Training average loss at step 877700: 0.134989\n",
      "2022-11-09 02:26:59,286 INFO     Training average positive_sample_loss at step 877800: 0.140918\n",
      "2022-11-09 02:26:59,286 INFO     Training average negative_sample_loss at step 877800: 0.137847\n",
      "2022-11-09 02:26:59,286 INFO     Training average loss at step 877800: 0.139382\n",
      "2022-11-09 02:27:02,395 INFO     Training average positive_sample_loss at step 877900: 0.138962\n",
      "2022-11-09 02:27:02,395 INFO     Training average negative_sample_loss at step 877900: 0.138826\n",
      "2022-11-09 02:27:02,395 INFO     Training average loss at step 877900: 0.138894\n",
      "2022-11-09 02:27:05,506 INFO     Training average positive_sample_loss at step 878000: 0.138315\n",
      "2022-11-09 02:27:05,506 INFO     Training average negative_sample_loss at step 878000: 0.136822\n",
      "2022-11-09 02:27:05,506 INFO     Training average loss at step 878000: 0.137568\n",
      "2022-11-09 02:27:08,611 INFO     Training average positive_sample_loss at step 878100: 0.136516\n",
      "2022-11-09 02:27:08,612 INFO     Training average negative_sample_loss at step 878100: 0.134096\n",
      "2022-11-09 02:27:08,612 INFO     Training average loss at step 878100: 0.135306\n",
      "2022-11-09 02:27:11,733 INFO     Training average positive_sample_loss at step 878200: 0.140148\n",
      "2022-11-09 02:27:11,733 INFO     Training average negative_sample_loss at step 878200: 0.139039\n",
      "2022-11-09 02:27:11,733 INFO     Training average loss at step 878200: 0.139594\n",
      "2022-11-09 02:27:14,844 INFO     Training average positive_sample_loss at step 878300: 0.138387\n",
      "2022-11-09 02:27:14,844 INFO     Training average negative_sample_loss at step 878300: 0.138916\n",
      "2022-11-09 02:27:14,844 INFO     Training average loss at step 878300: 0.138652\n",
      "2022-11-09 02:27:17,947 INFO     Training average positive_sample_loss at step 878400: 0.142739\n",
      "2022-11-09 02:27:17,947 INFO     Training average negative_sample_loss at step 878400: 0.136206\n",
      "2022-11-09 02:27:17,947 INFO     Training average loss at step 878400: 0.139472\n",
      "2022-11-09 02:27:21,051 INFO     Training average positive_sample_loss at step 878500: 0.140731\n",
      "2022-11-09 02:27:21,051 INFO     Training average negative_sample_loss at step 878500: 0.133518\n",
      "2022-11-09 02:27:21,051 INFO     Training average loss at step 878500: 0.137124\n",
      "2022-11-09 02:27:24,145 INFO     Training average positive_sample_loss at step 878600: 0.140046\n",
      "2022-11-09 02:27:24,145 INFO     Training average negative_sample_loss at step 878600: 0.133070\n",
      "2022-11-09 02:27:24,145 INFO     Training average loss at step 878600: 0.136558\n",
      "2022-11-09 02:27:27,254 INFO     Training average positive_sample_loss at step 878700: 0.140605\n",
      "2022-11-09 02:27:27,255 INFO     Training average negative_sample_loss at step 878700: 0.137373\n",
      "2022-11-09 02:27:27,255 INFO     Training average loss at step 878700: 0.138989\n",
      "2022-11-09 02:27:30,363 INFO     Training average positive_sample_loss at step 878800: 0.138202\n",
      "2022-11-09 02:27:30,363 INFO     Training average negative_sample_loss at step 878800: 0.132931\n",
      "2022-11-09 02:27:30,363 INFO     Training average loss at step 878800: 0.135567\n",
      "2022-11-09 02:27:33,476 INFO     Training average positive_sample_loss at step 878900: 0.137731\n",
      "2022-11-09 02:27:33,476 INFO     Training average negative_sample_loss at step 878900: 0.133989\n",
      "2022-11-09 02:27:33,476 INFO     Training average loss at step 878900: 0.135860\n",
      "2022-11-09 02:27:36,574 INFO     Training average positive_sample_loss at step 879000: 0.138919\n",
      "2022-11-09 02:27:36,574 INFO     Training average negative_sample_loss at step 879000: 0.136901\n",
      "2022-11-09 02:27:36,574 INFO     Training average loss at step 879000: 0.137910\n",
      "2022-11-09 02:27:39,682 INFO     Training average positive_sample_loss at step 879100: 0.138811\n",
      "2022-11-09 02:27:39,682 INFO     Training average negative_sample_loss at step 879100: 0.135801\n",
      "2022-11-09 02:27:39,682 INFO     Training average loss at step 879100: 0.137306\n",
      "2022-11-09 02:27:42,787 INFO     Training average positive_sample_loss at step 879200: 0.138760\n",
      "2022-11-09 02:27:42,788 INFO     Training average negative_sample_loss at step 879200: 0.135940\n",
      "2022-11-09 02:27:42,788 INFO     Training average loss at step 879200: 0.137350\n",
      "2022-11-09 02:27:45,882 INFO     Training average positive_sample_loss at step 879300: 0.136815\n",
      "2022-11-09 02:27:45,882 INFO     Training average negative_sample_loss at step 879300: 0.137883\n",
      "2022-11-09 02:27:45,882 INFO     Training average loss at step 879300: 0.137349\n",
      "2022-11-09 02:27:48,975 INFO     Training average positive_sample_loss at step 879400: 0.137489\n",
      "2022-11-09 02:27:48,975 INFO     Training average negative_sample_loss at step 879400: 0.134700\n",
      "2022-11-09 02:27:48,975 INFO     Training average loss at step 879400: 0.136094\n",
      "2022-11-09 02:27:52,086 INFO     Training average positive_sample_loss at step 879500: 0.141875\n",
      "2022-11-09 02:27:52,086 INFO     Training average negative_sample_loss at step 879500: 0.135200\n",
      "2022-11-09 02:27:52,086 INFO     Training average loss at step 879500: 0.138538\n",
      "2022-11-09 02:27:55,193 INFO     Training average positive_sample_loss at step 879600: 0.139293\n",
      "2022-11-09 02:27:55,193 INFO     Training average negative_sample_loss at step 879600: 0.133460\n",
      "2022-11-09 02:27:55,193 INFO     Training average loss at step 879600: 0.136377\n",
      "2022-11-09 02:27:58,308 INFO     Training average positive_sample_loss at step 879700: 0.136491\n",
      "2022-11-09 02:27:58,308 INFO     Training average negative_sample_loss at step 879700: 0.138032\n",
      "2022-11-09 02:27:58,308 INFO     Training average loss at step 879700: 0.137261\n",
      "2022-11-09 02:28:01,430 INFO     Training average positive_sample_loss at step 879800: 0.145008\n",
      "2022-11-09 02:28:01,430 INFO     Training average negative_sample_loss at step 879800: 0.139637\n",
      "2022-11-09 02:28:01,430 INFO     Training average loss at step 879800: 0.142322\n",
      "2022-11-09 02:28:04,543 INFO     Training average positive_sample_loss at step 879900: 0.133054\n",
      "2022-11-09 02:28:04,543 INFO     Training average negative_sample_loss at step 879900: 0.136494\n",
      "2022-11-09 02:28:04,543 INFO     Training average loss at step 879900: 0.134774\n",
      "2022-11-09 02:28:10,504 INFO     Training average positive_sample_loss at step 880000: 0.139856\n",
      "2022-11-09 02:28:10,504 INFO     Training average negative_sample_loss at step 880000: 0.134530\n",
      "2022-11-09 02:28:10,504 INFO     Training average loss at step 880000: 0.137193\n",
      "2022-11-09 02:28:13,625 INFO     Training average positive_sample_loss at step 880100: 0.140491\n",
      "2022-11-09 02:28:13,625 INFO     Training average negative_sample_loss at step 880100: 0.137257\n",
      "2022-11-09 02:28:13,625 INFO     Training average loss at step 880100: 0.138874\n",
      "2022-11-09 02:28:16,742 INFO     Training average positive_sample_loss at step 880200: 0.140069\n",
      "2022-11-09 02:28:16,742 INFO     Training average negative_sample_loss at step 880200: 0.133211\n",
      "2022-11-09 02:28:16,742 INFO     Training average loss at step 880200: 0.136640\n",
      "2022-11-09 02:28:19,855 INFO     Training average positive_sample_loss at step 880300: 0.140280\n",
      "2022-11-09 02:28:19,855 INFO     Training average negative_sample_loss at step 880300: 0.133187\n",
      "2022-11-09 02:28:19,855 INFO     Training average loss at step 880300: 0.136733\n",
      "2022-11-09 02:28:22,976 INFO     Training average positive_sample_loss at step 880400: 0.142521\n",
      "2022-11-09 02:28:22,976 INFO     Training average negative_sample_loss at step 880400: 0.135754\n",
      "2022-11-09 02:28:22,976 INFO     Training average loss at step 880400: 0.139138\n",
      "2022-11-09 02:28:26,100 INFO     Training average positive_sample_loss at step 880500: 0.143616\n",
      "2022-11-09 02:28:26,100 INFO     Training average negative_sample_loss at step 880500: 0.139062\n",
      "2022-11-09 02:28:26,100 INFO     Training average loss at step 880500: 0.141339\n",
      "2022-11-09 02:28:29,224 INFO     Training average positive_sample_loss at step 880600: 0.136290\n",
      "2022-11-09 02:28:29,224 INFO     Training average negative_sample_loss at step 880600: 0.137299\n",
      "2022-11-09 02:28:29,224 INFO     Training average loss at step 880600: 0.136795\n",
      "2022-11-09 02:28:32,352 INFO     Training average positive_sample_loss at step 880700: 0.139626\n",
      "2022-11-09 02:28:32,353 INFO     Training average negative_sample_loss at step 880700: 0.135212\n",
      "2022-11-09 02:28:32,353 INFO     Training average loss at step 880700: 0.137419\n",
      "2022-11-09 02:28:36,732 INFO     Training average positive_sample_loss at step 880800: 0.135523\n",
      "2022-11-09 02:28:36,732 INFO     Training average negative_sample_loss at step 880800: 0.140311\n",
      "2022-11-09 02:28:36,732 INFO     Training average loss at step 880800: 0.137917\n",
      "2022-11-09 02:28:42,050 INFO     Training average positive_sample_loss at step 880900: 0.138643\n",
      "2022-11-09 02:28:42,050 INFO     Training average negative_sample_loss at step 880900: 0.136237\n",
      "2022-11-09 02:28:42,050 INFO     Training average loss at step 880900: 0.137440\n",
      "2022-11-09 02:28:45,160 INFO     Training average positive_sample_loss at step 881000: 0.136714\n",
      "2022-11-09 02:28:45,160 INFO     Training average negative_sample_loss at step 881000: 0.133096\n",
      "2022-11-09 02:28:45,160 INFO     Training average loss at step 881000: 0.134905\n",
      "2022-11-09 02:28:48,267 INFO     Training average positive_sample_loss at step 881100: 0.142524\n",
      "2022-11-09 02:28:48,267 INFO     Training average negative_sample_loss at step 881100: 0.135948\n",
      "2022-11-09 02:28:48,267 INFO     Training average loss at step 881100: 0.139236\n",
      "2022-11-09 02:28:51,378 INFO     Training average positive_sample_loss at step 881200: 0.140637\n",
      "2022-11-09 02:28:51,379 INFO     Training average negative_sample_loss at step 881200: 0.136412\n",
      "2022-11-09 02:28:51,379 INFO     Training average loss at step 881200: 0.138524\n",
      "2022-11-09 02:28:54,486 INFO     Training average positive_sample_loss at step 881300: 0.138884\n",
      "2022-11-09 02:28:54,486 INFO     Training average negative_sample_loss at step 881300: 0.136425\n",
      "2022-11-09 02:28:54,486 INFO     Training average loss at step 881300: 0.137655\n",
      "2022-11-09 02:28:57,596 INFO     Training average positive_sample_loss at step 881400: 0.138679\n",
      "2022-11-09 02:28:57,596 INFO     Training average negative_sample_loss at step 881400: 0.132179\n",
      "2022-11-09 02:28:57,596 INFO     Training average loss at step 881400: 0.135429\n",
      "2022-11-09 02:29:00,695 INFO     Training average positive_sample_loss at step 881500: 0.141065\n",
      "2022-11-09 02:29:00,695 INFO     Training average negative_sample_loss at step 881500: 0.140767\n",
      "2022-11-09 02:29:00,695 INFO     Training average loss at step 881500: 0.140916\n",
      "2022-11-09 02:29:03,798 INFO     Training average positive_sample_loss at step 881600: 0.137579\n",
      "2022-11-09 02:29:03,798 INFO     Training average negative_sample_loss at step 881600: 0.137193\n",
      "2022-11-09 02:29:03,798 INFO     Training average loss at step 881600: 0.137386\n",
      "2022-11-09 02:29:06,895 INFO     Training average positive_sample_loss at step 881700: 0.143423\n",
      "2022-11-09 02:29:06,895 INFO     Training average negative_sample_loss at step 881700: 0.137988\n",
      "2022-11-09 02:29:06,895 INFO     Training average loss at step 881700: 0.140705\n",
      "2022-11-09 02:29:10,009 INFO     Training average positive_sample_loss at step 881800: 0.142557\n",
      "2022-11-09 02:29:10,009 INFO     Training average negative_sample_loss at step 881800: 0.133289\n",
      "2022-11-09 02:29:10,009 INFO     Training average loss at step 881800: 0.137923\n",
      "2022-11-09 02:29:13,104 INFO     Training average positive_sample_loss at step 881900: 0.138093\n",
      "2022-11-09 02:29:13,104 INFO     Training average negative_sample_loss at step 881900: 0.135132\n",
      "2022-11-09 02:29:13,104 INFO     Training average loss at step 881900: 0.136612\n",
      "2022-11-09 02:29:16,203 INFO     Training average positive_sample_loss at step 882000: 0.136427\n",
      "2022-11-09 02:29:16,204 INFO     Training average negative_sample_loss at step 882000: 0.133087\n",
      "2022-11-09 02:29:16,204 INFO     Training average loss at step 882000: 0.134757\n",
      "2022-11-09 02:29:19,310 INFO     Training average positive_sample_loss at step 882100: 0.140799\n",
      "2022-11-09 02:29:19,310 INFO     Training average negative_sample_loss at step 882100: 0.135485\n",
      "2022-11-09 02:29:19,310 INFO     Training average loss at step 882100: 0.138142\n",
      "2022-11-09 02:29:22,431 INFO     Training average positive_sample_loss at step 882200: 0.139978\n",
      "2022-11-09 02:29:22,431 INFO     Training average negative_sample_loss at step 882200: 0.137013\n",
      "2022-11-09 02:29:22,431 INFO     Training average loss at step 882200: 0.138496\n",
      "2022-11-09 02:29:25,556 INFO     Training average positive_sample_loss at step 882300: 0.141732\n",
      "2022-11-09 02:29:25,556 INFO     Training average negative_sample_loss at step 882300: 0.142810\n",
      "2022-11-09 02:29:25,556 INFO     Training average loss at step 882300: 0.142271\n",
      "2022-11-09 02:29:28,667 INFO     Training average positive_sample_loss at step 882400: 0.137526\n",
      "2022-11-09 02:29:28,667 INFO     Training average negative_sample_loss at step 882400: 0.138986\n",
      "2022-11-09 02:29:28,667 INFO     Training average loss at step 882400: 0.138256\n",
      "2022-11-09 02:29:31,775 INFO     Training average positive_sample_loss at step 882500: 0.139300\n",
      "2022-11-09 02:29:31,775 INFO     Training average negative_sample_loss at step 882500: 0.137216\n",
      "2022-11-09 02:29:31,775 INFO     Training average loss at step 882500: 0.138258\n",
      "2022-11-09 02:29:34,896 INFO     Training average positive_sample_loss at step 882600: 0.138667\n",
      "2022-11-09 02:29:34,896 INFO     Training average negative_sample_loss at step 882600: 0.135027\n",
      "2022-11-09 02:29:34,896 INFO     Training average loss at step 882600: 0.136847\n",
      "2022-11-09 02:29:38,023 INFO     Training average positive_sample_loss at step 882700: 0.140232\n",
      "2022-11-09 02:29:38,023 INFO     Training average negative_sample_loss at step 882700: 0.136859\n",
      "2022-11-09 02:29:38,023 INFO     Training average loss at step 882700: 0.138546\n",
      "2022-11-09 02:29:41,146 INFO     Training average positive_sample_loss at step 882800: 0.140423\n",
      "2022-11-09 02:29:41,146 INFO     Training average negative_sample_loss at step 882800: 0.135577\n",
      "2022-11-09 02:29:41,146 INFO     Training average loss at step 882800: 0.138000\n",
      "2022-11-09 02:29:44,244 INFO     Training average positive_sample_loss at step 882900: 0.141728\n",
      "2022-11-09 02:29:44,244 INFO     Training average negative_sample_loss at step 882900: 0.136242\n",
      "2022-11-09 02:29:44,244 INFO     Training average loss at step 882900: 0.138985\n",
      "2022-11-09 02:29:47,359 INFO     Training average positive_sample_loss at step 883000: 0.140448\n",
      "2022-11-09 02:29:47,359 INFO     Training average negative_sample_loss at step 883000: 0.139579\n",
      "2022-11-09 02:29:47,359 INFO     Training average loss at step 883000: 0.140014\n",
      "2022-11-09 02:29:50,482 INFO     Training average positive_sample_loss at step 883100: 0.137215\n",
      "2022-11-09 02:29:50,482 INFO     Training average negative_sample_loss at step 883100: 0.138676\n",
      "2022-11-09 02:29:50,482 INFO     Training average loss at step 883100: 0.137946\n",
      "2022-11-09 02:29:53,606 INFO     Training average positive_sample_loss at step 883200: 0.140571\n",
      "2022-11-09 02:29:53,606 INFO     Training average negative_sample_loss at step 883200: 0.134340\n",
      "2022-11-09 02:29:53,606 INFO     Training average loss at step 883200: 0.137456\n",
      "2022-11-09 02:29:56,704 INFO     Training average positive_sample_loss at step 883300: 0.140150\n",
      "2022-11-09 02:29:56,704 INFO     Training average negative_sample_loss at step 883300: 0.139987\n",
      "2022-11-09 02:29:56,704 INFO     Training average loss at step 883300: 0.140069\n",
      "2022-11-09 02:29:59,805 INFO     Training average positive_sample_loss at step 883400: 0.141657\n",
      "2022-11-09 02:29:59,805 INFO     Training average negative_sample_loss at step 883400: 0.138169\n",
      "2022-11-09 02:29:59,805 INFO     Training average loss at step 883400: 0.139913\n",
      "2022-11-09 02:30:02,905 INFO     Training average positive_sample_loss at step 883500: 0.141062\n",
      "2022-11-09 02:30:02,905 INFO     Training average negative_sample_loss at step 883500: 0.135180\n",
      "2022-11-09 02:30:02,905 INFO     Training average loss at step 883500: 0.138121\n",
      "2022-11-09 02:30:06,004 INFO     Training average positive_sample_loss at step 883600: 0.139104\n",
      "2022-11-09 02:30:06,004 INFO     Training average negative_sample_loss at step 883600: 0.131387\n",
      "2022-11-09 02:30:06,005 INFO     Training average loss at step 883600: 0.135246\n",
      "2022-11-09 02:30:09,112 INFO     Training average positive_sample_loss at step 883700: 0.136679\n",
      "2022-11-09 02:30:09,112 INFO     Training average negative_sample_loss at step 883700: 0.134480\n",
      "2022-11-09 02:30:09,112 INFO     Training average loss at step 883700: 0.135579\n",
      "2022-11-09 02:30:12,223 INFO     Training average positive_sample_loss at step 883800: 0.140934\n",
      "2022-11-09 02:30:12,223 INFO     Training average negative_sample_loss at step 883800: 0.133656\n",
      "2022-11-09 02:30:12,223 INFO     Training average loss at step 883800: 0.137295\n",
      "2022-11-09 02:30:15,322 INFO     Training average positive_sample_loss at step 883900: 0.136992\n",
      "2022-11-09 02:30:15,322 INFO     Training average negative_sample_loss at step 883900: 0.131888\n",
      "2022-11-09 02:30:15,322 INFO     Training average loss at step 883900: 0.134440\n",
      "2022-11-09 02:30:18,426 INFO     Training average positive_sample_loss at step 884000: 0.135096\n",
      "2022-11-09 02:30:18,426 INFO     Training average negative_sample_loss at step 884000: 0.135926\n",
      "2022-11-09 02:30:18,426 INFO     Training average loss at step 884000: 0.135511\n",
      "2022-11-09 02:30:21,527 INFO     Training average positive_sample_loss at step 884100: 0.141343\n",
      "2022-11-09 02:30:21,527 INFO     Training average negative_sample_loss at step 884100: 0.134757\n",
      "2022-11-09 02:30:21,527 INFO     Training average loss at step 884100: 0.138050\n",
      "2022-11-09 02:30:24,648 INFO     Training average positive_sample_loss at step 884200: 0.137262\n",
      "2022-11-09 02:30:24,648 INFO     Training average negative_sample_loss at step 884200: 0.132738\n",
      "2022-11-09 02:30:24,648 INFO     Training average loss at step 884200: 0.135000\n",
      "2022-11-09 02:30:27,768 INFO     Training average positive_sample_loss at step 884300: 0.138550\n",
      "2022-11-09 02:30:27,769 INFO     Training average negative_sample_loss at step 884300: 0.134442\n",
      "2022-11-09 02:30:27,769 INFO     Training average loss at step 884300: 0.136496\n",
      "2022-11-09 02:30:30,885 INFO     Training average positive_sample_loss at step 884400: 0.138840\n",
      "2022-11-09 02:30:30,885 INFO     Training average negative_sample_loss at step 884400: 0.138620\n",
      "2022-11-09 02:30:30,885 INFO     Training average loss at step 884400: 0.138730\n",
      "2022-11-09 02:30:33,987 INFO     Training average positive_sample_loss at step 884500: 0.136309\n",
      "2022-11-09 02:30:33,987 INFO     Training average negative_sample_loss at step 884500: 0.133506\n",
      "2022-11-09 02:30:33,987 INFO     Training average loss at step 884500: 0.134908\n",
      "2022-11-09 02:30:37,092 INFO     Training average positive_sample_loss at step 884600: 0.141720\n",
      "2022-11-09 02:30:37,092 INFO     Training average negative_sample_loss at step 884600: 0.135603\n",
      "2022-11-09 02:30:37,092 INFO     Training average loss at step 884600: 0.138661\n",
      "2022-11-09 02:30:40,191 INFO     Training average positive_sample_loss at step 884700: 0.139598\n",
      "2022-11-09 02:30:40,191 INFO     Training average negative_sample_loss at step 884700: 0.135363\n",
      "2022-11-09 02:30:40,191 INFO     Training average loss at step 884700: 0.137480\n",
      "2022-11-09 02:30:43,296 INFO     Training average positive_sample_loss at step 884800: 0.138247\n",
      "2022-11-09 02:30:43,296 INFO     Training average negative_sample_loss at step 884800: 0.132081\n",
      "2022-11-09 02:30:43,296 INFO     Training average loss at step 884800: 0.135164\n",
      "2022-11-09 02:30:46,392 INFO     Training average positive_sample_loss at step 884900: 0.139664\n",
      "2022-11-09 02:30:46,392 INFO     Training average negative_sample_loss at step 884900: 0.135784\n",
      "2022-11-09 02:30:46,392 INFO     Training average loss at step 884900: 0.137724\n",
      "2022-11-09 02:30:49,497 INFO     Training average positive_sample_loss at step 885000: 0.138845\n",
      "2022-11-09 02:30:49,498 INFO     Training average negative_sample_loss at step 885000: 0.136390\n",
      "2022-11-09 02:30:49,498 INFO     Training average loss at step 885000: 0.137618\n",
      "2022-11-09 02:30:52,602 INFO     Training average positive_sample_loss at step 885100: 0.138546\n",
      "2022-11-09 02:30:52,602 INFO     Training average negative_sample_loss at step 885100: 0.137245\n",
      "2022-11-09 02:30:52,602 INFO     Training average loss at step 885100: 0.137896\n",
      "2022-11-09 02:30:55,712 INFO     Training average positive_sample_loss at step 885200: 0.141885\n",
      "2022-11-09 02:30:55,712 INFO     Training average negative_sample_loss at step 885200: 0.137374\n",
      "2022-11-09 02:30:55,712 INFO     Training average loss at step 885200: 0.139629\n",
      "2022-11-09 02:30:58,835 INFO     Training average positive_sample_loss at step 885300: 0.142952\n",
      "2022-11-09 02:30:58,835 INFO     Training average negative_sample_loss at step 885300: 0.137732\n",
      "2022-11-09 02:30:58,835 INFO     Training average loss at step 885300: 0.140342\n",
      "2022-11-09 02:31:01,952 INFO     Training average positive_sample_loss at step 885400: 0.139013\n",
      "2022-11-09 02:31:01,953 INFO     Training average negative_sample_loss at step 885400: 0.138479\n",
      "2022-11-09 02:31:01,953 INFO     Training average loss at step 885400: 0.138746\n",
      "2022-11-09 02:31:06,134 INFO     Training average positive_sample_loss at step 885500: 0.139016\n",
      "2022-11-09 02:31:06,134 INFO     Training average negative_sample_loss at step 885500: 0.133316\n",
      "2022-11-09 02:31:06,134 INFO     Training average loss at step 885500: 0.136166\n",
      "2022-11-09 02:31:11,172 INFO     Training average positive_sample_loss at step 885600: 0.136440\n",
      "2022-11-09 02:31:11,172 INFO     Training average negative_sample_loss at step 885600: 0.137475\n",
      "2022-11-09 02:31:11,172 INFO     Training average loss at step 885600: 0.136958\n",
      "2022-11-09 02:31:14,287 INFO     Training average positive_sample_loss at step 885700: 0.144831\n",
      "2022-11-09 02:31:14,287 INFO     Training average negative_sample_loss at step 885700: 0.136891\n",
      "2022-11-09 02:31:14,287 INFO     Training average loss at step 885700: 0.140861\n",
      "2022-11-09 02:31:17,399 INFO     Training average positive_sample_loss at step 885800: 0.144920\n",
      "2022-11-09 02:31:17,400 INFO     Training average negative_sample_loss at step 885800: 0.139158\n",
      "2022-11-09 02:31:17,400 INFO     Training average loss at step 885800: 0.142039\n",
      "2022-11-09 02:31:20,517 INFO     Training average positive_sample_loss at step 885900: 0.138413\n",
      "2022-11-09 02:31:20,518 INFO     Training average negative_sample_loss at step 885900: 0.132869\n",
      "2022-11-09 02:31:20,518 INFO     Training average loss at step 885900: 0.135641\n",
      "2022-11-09 02:31:23,629 INFO     Training average positive_sample_loss at step 886000: 0.144696\n",
      "2022-11-09 02:31:23,629 INFO     Training average negative_sample_loss at step 886000: 0.138428\n",
      "2022-11-09 02:31:23,629 INFO     Training average loss at step 886000: 0.141562\n",
      "2022-11-09 02:31:26,746 INFO     Training average positive_sample_loss at step 886100: 0.142617\n",
      "2022-11-09 02:31:26,746 INFO     Training average negative_sample_loss at step 886100: 0.135603\n",
      "2022-11-09 02:31:26,746 INFO     Training average loss at step 886100: 0.139110\n",
      "2022-11-09 02:31:29,848 INFO     Training average positive_sample_loss at step 886200: 0.139595\n",
      "2022-11-09 02:31:29,848 INFO     Training average negative_sample_loss at step 886200: 0.136423\n",
      "2022-11-09 02:31:29,848 INFO     Training average loss at step 886200: 0.138009\n",
      "2022-11-09 02:31:32,952 INFO     Training average positive_sample_loss at step 886300: 0.135957\n",
      "2022-11-09 02:31:32,952 INFO     Training average negative_sample_loss at step 886300: 0.136834\n",
      "2022-11-09 02:31:32,952 INFO     Training average loss at step 886300: 0.136395\n",
      "2022-11-09 02:31:36,046 INFO     Training average positive_sample_loss at step 886400: 0.141003\n",
      "2022-11-09 02:31:36,046 INFO     Training average negative_sample_loss at step 886400: 0.138750\n",
      "2022-11-09 02:31:36,046 INFO     Training average loss at step 886400: 0.139876\n",
      "2022-11-09 02:31:39,145 INFO     Training average positive_sample_loss at step 886500: 0.139463\n",
      "2022-11-09 02:31:39,145 INFO     Training average negative_sample_loss at step 886500: 0.139599\n",
      "2022-11-09 02:31:39,146 INFO     Training average loss at step 886500: 0.139531\n",
      "2022-11-09 02:31:42,254 INFO     Training average positive_sample_loss at step 886600: 0.134412\n",
      "2022-11-09 02:31:42,255 INFO     Training average negative_sample_loss at step 886600: 0.137138\n",
      "2022-11-09 02:31:42,255 INFO     Training average loss at step 886600: 0.135775\n",
      "2022-11-09 02:31:45,360 INFO     Training average positive_sample_loss at step 886700: 0.142188\n",
      "2022-11-09 02:31:45,360 INFO     Training average negative_sample_loss at step 886700: 0.135220\n",
      "2022-11-09 02:31:45,360 INFO     Training average loss at step 886700: 0.138704\n",
      "2022-11-09 02:31:48,471 INFO     Training average positive_sample_loss at step 886800: 0.138532\n",
      "2022-11-09 02:31:48,471 INFO     Training average negative_sample_loss at step 886800: 0.135435\n",
      "2022-11-09 02:31:48,471 INFO     Training average loss at step 886800: 0.136983\n",
      "2022-11-09 02:31:51,583 INFO     Training average positive_sample_loss at step 886900: 0.142517\n",
      "2022-11-09 02:31:51,583 INFO     Training average negative_sample_loss at step 886900: 0.131671\n",
      "2022-11-09 02:31:51,583 INFO     Training average loss at step 886900: 0.137094\n",
      "2022-11-09 02:31:54,697 INFO     Training average positive_sample_loss at step 887000: 0.139908\n",
      "2022-11-09 02:31:54,697 INFO     Training average negative_sample_loss at step 887000: 0.141336\n",
      "2022-11-09 02:31:54,697 INFO     Training average loss at step 887000: 0.140622\n",
      "2022-11-09 02:31:57,806 INFO     Training average positive_sample_loss at step 887100: 0.139037\n",
      "2022-11-09 02:31:57,806 INFO     Training average negative_sample_loss at step 887100: 0.135800\n",
      "2022-11-09 02:31:57,807 INFO     Training average loss at step 887100: 0.137419\n",
      "2022-11-09 02:32:00,910 INFO     Training average positive_sample_loss at step 887200: 0.142314\n",
      "2022-11-09 02:32:00,910 INFO     Training average negative_sample_loss at step 887200: 0.139914\n",
      "2022-11-09 02:32:00,910 INFO     Training average loss at step 887200: 0.141114\n",
      "2022-11-09 02:32:04,012 INFO     Training average positive_sample_loss at step 887300: 0.138751\n",
      "2022-11-09 02:32:04,012 INFO     Training average negative_sample_loss at step 887300: 0.137255\n",
      "2022-11-09 02:32:04,012 INFO     Training average loss at step 887300: 0.138003\n",
      "2022-11-09 02:32:07,110 INFO     Training average positive_sample_loss at step 887400: 0.136633\n",
      "2022-11-09 02:32:07,110 INFO     Training average negative_sample_loss at step 887400: 0.134105\n",
      "2022-11-09 02:32:07,110 INFO     Training average loss at step 887400: 0.135369\n",
      "2022-11-09 02:32:10,225 INFO     Training average positive_sample_loss at step 887500: 0.137910\n",
      "2022-11-09 02:32:10,226 INFO     Training average negative_sample_loss at step 887500: 0.132574\n",
      "2022-11-09 02:32:10,226 INFO     Training average loss at step 887500: 0.135242\n",
      "2022-11-09 02:32:13,328 INFO     Training average positive_sample_loss at step 887600: 0.139123\n",
      "2022-11-09 02:32:13,328 INFO     Training average negative_sample_loss at step 887600: 0.137637\n",
      "2022-11-09 02:32:13,328 INFO     Training average loss at step 887600: 0.138380\n",
      "2022-11-09 02:32:16,435 INFO     Training average positive_sample_loss at step 887700: 0.138488\n",
      "2022-11-09 02:32:16,435 INFO     Training average negative_sample_loss at step 887700: 0.133548\n",
      "2022-11-09 02:32:16,435 INFO     Training average loss at step 887700: 0.136018\n",
      "2022-11-09 02:32:19,550 INFO     Training average positive_sample_loss at step 887800: 0.138470\n",
      "2022-11-09 02:32:19,550 INFO     Training average negative_sample_loss at step 887800: 0.135602\n",
      "2022-11-09 02:32:19,550 INFO     Training average loss at step 887800: 0.137036\n",
      "2022-11-09 02:32:22,663 INFO     Training average positive_sample_loss at step 887900: 0.139367\n",
      "2022-11-09 02:32:22,663 INFO     Training average negative_sample_loss at step 887900: 0.136301\n",
      "2022-11-09 02:32:22,663 INFO     Training average loss at step 887900: 0.137834\n",
      "2022-11-09 02:32:25,780 INFO     Training average positive_sample_loss at step 888000: 0.138397\n",
      "2022-11-09 02:32:25,780 INFO     Training average negative_sample_loss at step 888000: 0.134066\n",
      "2022-11-09 02:32:25,780 INFO     Training average loss at step 888000: 0.136232\n",
      "2022-11-09 02:32:28,899 INFO     Training average positive_sample_loss at step 888100: 0.137609\n",
      "2022-11-09 02:32:28,899 INFO     Training average negative_sample_loss at step 888100: 0.135103\n",
      "2022-11-09 02:32:28,899 INFO     Training average loss at step 888100: 0.136356\n",
      "2022-11-09 02:32:32,010 INFO     Training average positive_sample_loss at step 888200: 0.141738\n",
      "2022-11-09 02:32:32,010 INFO     Training average negative_sample_loss at step 888200: 0.137103\n",
      "2022-11-09 02:32:32,010 INFO     Training average loss at step 888200: 0.139420\n",
      "2022-11-09 02:32:35,112 INFO     Training average positive_sample_loss at step 888300: 0.138180\n",
      "2022-11-09 02:32:35,112 INFO     Training average negative_sample_loss at step 888300: 0.137749\n",
      "2022-11-09 02:32:35,112 INFO     Training average loss at step 888300: 0.137964\n",
      "2022-11-09 02:32:38,215 INFO     Training average positive_sample_loss at step 888400: 0.139146\n",
      "2022-11-09 02:32:38,215 INFO     Training average negative_sample_loss at step 888400: 0.133625\n",
      "2022-11-09 02:32:38,215 INFO     Training average loss at step 888400: 0.136386\n",
      "2022-11-09 02:32:41,329 INFO     Training average positive_sample_loss at step 888500: 0.140183\n",
      "2022-11-09 02:32:41,329 INFO     Training average negative_sample_loss at step 888500: 0.137108\n",
      "2022-11-09 02:32:41,329 INFO     Training average loss at step 888500: 0.138646\n",
      "2022-11-09 02:32:44,421 INFO     Training average positive_sample_loss at step 888600: 0.139584\n",
      "2022-11-09 02:32:44,421 INFO     Training average negative_sample_loss at step 888600: 0.137552\n",
      "2022-11-09 02:32:44,422 INFO     Training average loss at step 888600: 0.138568\n",
      "2022-11-09 02:32:47,509 INFO     Training average positive_sample_loss at step 888700: 0.136997\n",
      "2022-11-09 02:32:47,509 INFO     Training average negative_sample_loss at step 888700: 0.135837\n",
      "2022-11-09 02:32:47,509 INFO     Training average loss at step 888700: 0.136417\n",
      "2022-11-09 02:32:50,607 INFO     Training average positive_sample_loss at step 888800: 0.137716\n",
      "2022-11-09 02:32:50,607 INFO     Training average negative_sample_loss at step 888800: 0.138883\n",
      "2022-11-09 02:32:50,607 INFO     Training average loss at step 888800: 0.138299\n",
      "2022-11-09 02:32:53,712 INFO     Training average positive_sample_loss at step 888900: 0.138412\n",
      "2022-11-09 02:32:53,712 INFO     Training average negative_sample_loss at step 888900: 0.135920\n",
      "2022-11-09 02:32:53,712 INFO     Training average loss at step 888900: 0.137166\n",
      "2022-11-09 02:32:56,819 INFO     Training average positive_sample_loss at step 889000: 0.136316\n",
      "2022-11-09 02:32:56,819 INFO     Training average negative_sample_loss at step 889000: 0.134486\n",
      "2022-11-09 02:32:56,819 INFO     Training average loss at step 889000: 0.135401\n",
      "2022-11-09 02:32:59,928 INFO     Training average positive_sample_loss at step 889100: 0.138515\n",
      "2022-11-09 02:32:59,928 INFO     Training average negative_sample_loss at step 889100: 0.135851\n",
      "2022-11-09 02:32:59,928 INFO     Training average loss at step 889100: 0.137183\n",
      "2022-11-09 02:33:03,038 INFO     Training average positive_sample_loss at step 889200: 0.138205\n",
      "2022-11-09 02:33:03,039 INFO     Training average negative_sample_loss at step 889200: 0.137950\n",
      "2022-11-09 02:33:03,039 INFO     Training average loss at step 889200: 0.138077\n",
      "2022-11-09 02:33:06,146 INFO     Training average positive_sample_loss at step 889300: 0.137429\n",
      "2022-11-09 02:33:06,146 INFO     Training average negative_sample_loss at step 889300: 0.134640\n",
      "2022-11-09 02:33:06,147 INFO     Training average loss at step 889300: 0.136035\n",
      "2022-11-09 02:33:09,257 INFO     Training average positive_sample_loss at step 889400: 0.138076\n",
      "2022-11-09 02:33:09,257 INFO     Training average negative_sample_loss at step 889400: 0.136862\n",
      "2022-11-09 02:33:09,257 INFO     Training average loss at step 889400: 0.137469\n",
      "2022-11-09 02:33:12,358 INFO     Training average positive_sample_loss at step 889500: 0.139021\n",
      "2022-11-09 02:33:12,358 INFO     Training average negative_sample_loss at step 889500: 0.135707\n",
      "2022-11-09 02:33:12,358 INFO     Training average loss at step 889500: 0.137364\n",
      "2022-11-09 02:33:15,456 INFO     Training average positive_sample_loss at step 889600: 0.142591\n",
      "2022-11-09 02:33:15,456 INFO     Training average negative_sample_loss at step 889600: 0.139164\n",
      "2022-11-09 02:33:15,456 INFO     Training average loss at step 889600: 0.140877\n",
      "2022-11-09 02:33:18,565 INFO     Training average positive_sample_loss at step 889700: 0.140091\n",
      "2022-11-09 02:33:18,565 INFO     Training average negative_sample_loss at step 889700: 0.134525\n",
      "2022-11-09 02:33:18,565 INFO     Training average loss at step 889700: 0.137308\n",
      "2022-11-09 02:33:21,672 INFO     Training average positive_sample_loss at step 889800: 0.140155\n",
      "2022-11-09 02:33:21,672 INFO     Training average negative_sample_loss at step 889800: 0.136749\n",
      "2022-11-09 02:33:21,672 INFO     Training average loss at step 889800: 0.138452\n",
      "2022-11-09 02:33:24,778 INFO     Training average positive_sample_loss at step 889900: 0.139205\n",
      "2022-11-09 02:33:24,778 INFO     Training average negative_sample_loss at step 889900: 0.137590\n",
      "2022-11-09 02:33:24,778 INFO     Training average loss at step 889900: 0.138398\n",
      "2022-11-09 02:33:30,743 INFO     Training average positive_sample_loss at step 890000: 0.137257\n",
      "2022-11-09 02:33:30,743 INFO     Training average negative_sample_loss at step 890000: 0.134234\n",
      "2022-11-09 02:33:30,743 INFO     Training average loss at step 890000: 0.135746\n",
      "2022-11-09 02:33:33,857 INFO     Training average positive_sample_loss at step 890100: 0.138807\n",
      "2022-11-09 02:33:33,857 INFO     Training average negative_sample_loss at step 890100: 0.139870\n",
      "2022-11-09 02:33:33,857 INFO     Training average loss at step 890100: 0.139338\n",
      "2022-11-09 02:33:38,056 INFO     Training average positive_sample_loss at step 890200: 0.139843\n",
      "2022-11-09 02:33:38,056 INFO     Training average negative_sample_loss at step 890200: 0.136488\n",
      "2022-11-09 02:33:38,056 INFO     Training average loss at step 890200: 0.138165\n",
      "2022-11-09 02:33:43,192 INFO     Training average positive_sample_loss at step 890300: 0.135792\n",
      "2022-11-09 02:33:43,192 INFO     Training average negative_sample_loss at step 890300: 0.133490\n",
      "2022-11-09 02:33:43,192 INFO     Training average loss at step 890300: 0.134641\n",
      "2022-11-09 02:33:46,292 INFO     Training average positive_sample_loss at step 890400: 0.137076\n",
      "2022-11-09 02:33:46,292 INFO     Training average negative_sample_loss at step 890400: 0.137396\n",
      "2022-11-09 02:33:46,292 INFO     Training average loss at step 890400: 0.137236\n",
      "2022-11-09 02:33:49,390 INFO     Training average positive_sample_loss at step 890500: 0.137435\n",
      "2022-11-09 02:33:49,390 INFO     Training average negative_sample_loss at step 890500: 0.138944\n",
      "2022-11-09 02:33:49,390 INFO     Training average loss at step 890500: 0.138190\n",
      "2022-11-09 02:33:52,501 INFO     Training average positive_sample_loss at step 890600: 0.139348\n",
      "2022-11-09 02:33:52,501 INFO     Training average negative_sample_loss at step 890600: 0.138461\n",
      "2022-11-09 02:33:52,501 INFO     Training average loss at step 890600: 0.138905\n",
      "2022-11-09 02:33:55,616 INFO     Training average positive_sample_loss at step 890700: 0.144072\n",
      "2022-11-09 02:33:55,616 INFO     Training average negative_sample_loss at step 890700: 0.134777\n",
      "2022-11-09 02:33:55,616 INFO     Training average loss at step 890700: 0.139425\n",
      "2022-11-09 02:33:58,717 INFO     Training average positive_sample_loss at step 890800: 0.139450\n",
      "2022-11-09 02:33:58,717 INFO     Training average negative_sample_loss at step 890800: 0.134846\n",
      "2022-11-09 02:33:58,718 INFO     Training average loss at step 890800: 0.137148\n",
      "2022-11-09 02:34:01,830 INFO     Training average positive_sample_loss at step 890900: 0.139375\n",
      "2022-11-09 02:34:01,830 INFO     Training average negative_sample_loss at step 890900: 0.132517\n",
      "2022-11-09 02:34:01,830 INFO     Training average loss at step 890900: 0.135946\n",
      "2022-11-09 02:34:04,951 INFO     Training average positive_sample_loss at step 891000: 0.137077\n",
      "2022-11-09 02:34:04,951 INFO     Training average negative_sample_loss at step 891000: 0.136197\n",
      "2022-11-09 02:34:04,951 INFO     Training average loss at step 891000: 0.136637\n",
      "2022-11-09 02:34:08,061 INFO     Training average positive_sample_loss at step 891100: 0.139848\n",
      "2022-11-09 02:34:08,061 INFO     Training average negative_sample_loss at step 891100: 0.133423\n",
      "2022-11-09 02:34:08,061 INFO     Training average loss at step 891100: 0.136636\n",
      "2022-11-09 02:34:11,178 INFO     Training average positive_sample_loss at step 891200: 0.142098\n",
      "2022-11-09 02:34:11,178 INFO     Training average negative_sample_loss at step 891200: 0.131914\n",
      "2022-11-09 02:34:11,178 INFO     Training average loss at step 891200: 0.137006\n",
      "2022-11-09 02:34:14,286 INFO     Training average positive_sample_loss at step 891300: 0.143030\n",
      "2022-11-09 02:34:14,286 INFO     Training average negative_sample_loss at step 891300: 0.139730\n",
      "2022-11-09 02:34:14,286 INFO     Training average loss at step 891300: 0.141380\n",
      "2022-11-09 02:34:17,411 INFO     Training average positive_sample_loss at step 891400: 0.144909\n",
      "2022-11-09 02:34:17,411 INFO     Training average negative_sample_loss at step 891400: 0.139111\n",
      "2022-11-09 02:34:17,411 INFO     Training average loss at step 891400: 0.142010\n",
      "2022-11-09 02:34:20,509 INFO     Training average positive_sample_loss at step 891500: 0.136383\n",
      "2022-11-09 02:34:20,509 INFO     Training average negative_sample_loss at step 891500: 0.135063\n",
      "2022-11-09 02:34:20,509 INFO     Training average loss at step 891500: 0.135723\n",
      "2022-11-09 02:34:23,615 INFO     Training average positive_sample_loss at step 891600: 0.140201\n",
      "2022-11-09 02:34:23,615 INFO     Training average negative_sample_loss at step 891600: 0.134118\n",
      "2022-11-09 02:34:23,615 INFO     Training average loss at step 891600: 0.137159\n",
      "2022-11-09 02:34:26,734 INFO     Training average positive_sample_loss at step 891700: 0.141876\n",
      "2022-11-09 02:34:26,734 INFO     Training average negative_sample_loss at step 891700: 0.134032\n",
      "2022-11-09 02:34:26,734 INFO     Training average loss at step 891700: 0.137954\n",
      "2022-11-09 02:34:29,851 INFO     Training average positive_sample_loss at step 891800: 0.137650\n",
      "2022-11-09 02:34:29,851 INFO     Training average negative_sample_loss at step 891800: 0.133765\n",
      "2022-11-09 02:34:29,851 INFO     Training average loss at step 891800: 0.135708\n",
      "2022-11-09 02:34:32,973 INFO     Training average positive_sample_loss at step 891900: 0.142517\n",
      "2022-11-09 02:34:32,973 INFO     Training average negative_sample_loss at step 891900: 0.132920\n",
      "2022-11-09 02:34:32,973 INFO     Training average loss at step 891900: 0.137719\n",
      "2022-11-09 02:34:36,075 INFO     Training average positive_sample_loss at step 892000: 0.141774\n",
      "2022-11-09 02:34:36,075 INFO     Training average negative_sample_loss at step 892000: 0.133698\n",
      "2022-11-09 02:34:36,075 INFO     Training average loss at step 892000: 0.137736\n",
      "2022-11-09 02:34:39,174 INFO     Training average positive_sample_loss at step 892100: 0.138791\n",
      "2022-11-09 02:34:39,174 INFO     Training average negative_sample_loss at step 892100: 0.140018\n",
      "2022-11-09 02:34:39,174 INFO     Training average loss at step 892100: 0.139405\n",
      "2022-11-09 02:34:42,291 INFO     Training average positive_sample_loss at step 892200: 0.149372\n",
      "2022-11-09 02:34:42,291 INFO     Training average negative_sample_loss at step 892200: 0.136724\n",
      "2022-11-09 02:34:42,291 INFO     Training average loss at step 892200: 0.143048\n",
      "2022-11-09 02:34:45,394 INFO     Training average positive_sample_loss at step 892300: 0.137740\n",
      "2022-11-09 02:34:45,394 INFO     Training average negative_sample_loss at step 892300: 0.134538\n",
      "2022-11-09 02:34:45,394 INFO     Training average loss at step 892300: 0.136139\n",
      "2022-11-09 02:34:48,491 INFO     Training average positive_sample_loss at step 892400: 0.140438\n",
      "2022-11-09 02:34:48,491 INFO     Training average negative_sample_loss at step 892400: 0.139448\n",
      "2022-11-09 02:34:48,491 INFO     Training average loss at step 892400: 0.139943\n",
      "2022-11-09 02:34:51,615 INFO     Training average positive_sample_loss at step 892500: 0.139321\n",
      "2022-11-09 02:34:51,615 INFO     Training average negative_sample_loss at step 892500: 0.133813\n",
      "2022-11-09 02:34:51,615 INFO     Training average loss at step 892500: 0.136567\n",
      "2022-11-09 02:34:54,729 INFO     Training average positive_sample_loss at step 892600: 0.140816\n",
      "2022-11-09 02:34:54,729 INFO     Training average negative_sample_loss at step 892600: 0.133261\n",
      "2022-11-09 02:34:54,729 INFO     Training average loss at step 892600: 0.137039\n",
      "2022-11-09 02:34:57,842 INFO     Training average positive_sample_loss at step 892700: 0.141349\n",
      "2022-11-09 02:34:57,842 INFO     Training average negative_sample_loss at step 892700: 0.136416\n",
      "2022-11-09 02:34:57,842 INFO     Training average loss at step 892700: 0.138882\n",
      "2022-11-09 02:35:00,947 INFO     Training average positive_sample_loss at step 892800: 0.140255\n",
      "2022-11-09 02:35:00,947 INFO     Training average negative_sample_loss at step 892800: 0.136063\n",
      "2022-11-09 02:35:00,947 INFO     Training average loss at step 892800: 0.138159\n",
      "2022-11-09 02:35:04,067 INFO     Training average positive_sample_loss at step 892900: 0.140017\n",
      "2022-11-09 02:35:04,067 INFO     Training average negative_sample_loss at step 892900: 0.136940\n",
      "2022-11-09 02:35:04,067 INFO     Training average loss at step 892900: 0.138478\n",
      "2022-11-09 02:35:07,174 INFO     Training average positive_sample_loss at step 893000: 0.142160\n",
      "2022-11-09 02:35:07,174 INFO     Training average negative_sample_loss at step 893000: 0.139961\n",
      "2022-11-09 02:35:07,174 INFO     Training average loss at step 893000: 0.141061\n",
      "2022-11-09 02:35:10,271 INFO     Training average positive_sample_loss at step 893100: 0.138959\n",
      "2022-11-09 02:35:10,271 INFO     Training average negative_sample_loss at step 893100: 0.135236\n",
      "2022-11-09 02:35:10,271 INFO     Training average loss at step 893100: 0.137097\n",
      "2022-11-09 02:35:13,383 INFO     Training average positive_sample_loss at step 893200: 0.144362\n",
      "2022-11-09 02:35:13,383 INFO     Training average negative_sample_loss at step 893200: 0.137258\n",
      "2022-11-09 02:35:13,383 INFO     Training average loss at step 893200: 0.140810\n",
      "2022-11-09 02:35:16,502 INFO     Training average positive_sample_loss at step 893300: 0.137453\n",
      "2022-11-09 02:35:16,502 INFO     Training average negative_sample_loss at step 893300: 0.133820\n",
      "2022-11-09 02:35:16,502 INFO     Training average loss at step 893300: 0.135637\n",
      "2022-11-09 02:35:19,618 INFO     Training average positive_sample_loss at step 893400: 0.142365\n",
      "2022-11-09 02:35:19,618 INFO     Training average negative_sample_loss at step 893400: 0.133357\n",
      "2022-11-09 02:35:19,618 INFO     Training average loss at step 893400: 0.137861\n",
      "2022-11-09 02:35:22,735 INFO     Training average positive_sample_loss at step 893500: 0.136710\n",
      "2022-11-09 02:35:22,735 INFO     Training average negative_sample_loss at step 893500: 0.138315\n",
      "2022-11-09 02:35:22,735 INFO     Training average loss at step 893500: 0.137512\n",
      "2022-11-09 02:35:25,861 INFO     Training average positive_sample_loss at step 893600: 0.139358\n",
      "2022-11-09 02:35:25,861 INFO     Training average negative_sample_loss at step 893600: 0.134764\n",
      "2022-11-09 02:35:25,861 INFO     Training average loss at step 893600: 0.137061\n",
      "2022-11-09 02:35:28,980 INFO     Training average positive_sample_loss at step 893700: 0.140020\n",
      "2022-11-09 02:35:28,980 INFO     Training average negative_sample_loss at step 893700: 0.134982\n",
      "2022-11-09 02:35:28,980 INFO     Training average loss at step 893700: 0.137501\n",
      "2022-11-09 02:35:32,098 INFO     Training average positive_sample_loss at step 893800: 0.140874\n",
      "2022-11-09 02:35:32,098 INFO     Training average negative_sample_loss at step 893800: 0.133391\n",
      "2022-11-09 02:35:32,098 INFO     Training average loss at step 893800: 0.137133\n",
      "2022-11-09 02:35:35,202 INFO     Training average positive_sample_loss at step 893900: 0.140494\n",
      "2022-11-09 02:35:35,202 INFO     Training average negative_sample_loss at step 893900: 0.132778\n",
      "2022-11-09 02:35:35,202 INFO     Training average loss at step 893900: 0.136636\n",
      "2022-11-09 02:35:38,330 INFO     Training average positive_sample_loss at step 894000: 0.140915\n",
      "2022-11-09 02:35:38,330 INFO     Training average negative_sample_loss at step 894000: 0.144429\n",
      "2022-11-09 02:35:38,330 INFO     Training average loss at step 894000: 0.142672\n",
      "2022-11-09 02:35:41,459 INFO     Training average positive_sample_loss at step 894100: 0.140792\n",
      "2022-11-09 02:35:41,459 INFO     Training average negative_sample_loss at step 894100: 0.134393\n",
      "2022-11-09 02:35:41,459 INFO     Training average loss at step 894100: 0.137593\n",
      "2022-11-09 02:35:44,561 INFO     Training average positive_sample_loss at step 894200: 0.138309\n",
      "2022-11-09 02:35:44,561 INFO     Training average negative_sample_loss at step 894200: 0.137785\n",
      "2022-11-09 02:35:44,561 INFO     Training average loss at step 894200: 0.138047\n",
      "2022-11-09 02:35:47,664 INFO     Training average positive_sample_loss at step 894300: 0.137958\n",
      "2022-11-09 02:35:47,664 INFO     Training average negative_sample_loss at step 894300: 0.136183\n",
      "2022-11-09 02:35:47,664 INFO     Training average loss at step 894300: 0.137071\n",
      "2022-11-09 02:35:50,775 INFO     Training average positive_sample_loss at step 894400: 0.139402\n",
      "2022-11-09 02:35:50,775 INFO     Training average negative_sample_loss at step 894400: 0.139468\n",
      "2022-11-09 02:35:50,775 INFO     Training average loss at step 894400: 0.139435\n",
      "2022-11-09 02:35:53,875 INFO     Training average positive_sample_loss at step 894500: 0.142419\n",
      "2022-11-09 02:35:53,876 INFO     Training average negative_sample_loss at step 894500: 0.136773\n",
      "2022-11-09 02:35:53,876 INFO     Training average loss at step 894500: 0.139596\n",
      "2022-11-09 02:35:56,976 INFO     Training average positive_sample_loss at step 894600: 0.141747\n",
      "2022-11-09 02:35:56,976 INFO     Training average negative_sample_loss at step 894600: 0.132676\n",
      "2022-11-09 02:35:56,976 INFO     Training average loss at step 894600: 0.137211\n",
      "2022-11-09 02:36:00,080 INFO     Training average positive_sample_loss at step 894700: 0.147077\n",
      "2022-11-09 02:36:00,080 INFO     Training average negative_sample_loss at step 894700: 0.140230\n",
      "2022-11-09 02:36:00,080 INFO     Training average loss at step 894700: 0.143653\n",
      "2022-11-09 02:36:03,178 INFO     Training average positive_sample_loss at step 894800: 0.139250\n",
      "2022-11-09 02:36:03,178 INFO     Training average negative_sample_loss at step 894800: 0.137243\n",
      "2022-11-09 02:36:03,178 INFO     Training average loss at step 894800: 0.138247\n",
      "2022-11-09 02:36:07,376 INFO     Training average positive_sample_loss at step 894900: 0.139860\n",
      "2022-11-09 02:36:07,376 INFO     Training average negative_sample_loss at step 894900: 0.132500\n",
      "2022-11-09 02:36:07,376 INFO     Training average loss at step 894900: 0.136180\n",
      "2022-11-09 02:36:12,447 INFO     Training average positive_sample_loss at step 895000: 0.139576\n",
      "2022-11-09 02:36:12,447 INFO     Training average negative_sample_loss at step 895000: 0.137723\n",
      "2022-11-09 02:36:12,447 INFO     Training average loss at step 895000: 0.138650\n",
      "2022-11-09 02:36:15,551 INFO     Training average positive_sample_loss at step 895100: 0.136904\n",
      "2022-11-09 02:36:15,551 INFO     Training average negative_sample_loss at step 895100: 0.132380\n",
      "2022-11-09 02:36:15,551 INFO     Training average loss at step 895100: 0.134642\n",
      "2022-11-09 02:36:18,655 INFO     Training average positive_sample_loss at step 895200: 0.142181\n",
      "2022-11-09 02:36:18,656 INFO     Training average negative_sample_loss at step 895200: 0.133297\n",
      "2022-11-09 02:36:18,656 INFO     Training average loss at step 895200: 0.137739\n",
      "2022-11-09 02:36:21,757 INFO     Training average positive_sample_loss at step 895300: 0.138375\n",
      "2022-11-09 02:36:21,757 INFO     Training average negative_sample_loss at step 895300: 0.133146\n",
      "2022-11-09 02:36:21,757 INFO     Training average loss at step 895300: 0.135760\n",
      "2022-11-09 02:36:24,860 INFO     Training average positive_sample_loss at step 895400: 0.143278\n",
      "2022-11-09 02:36:24,860 INFO     Training average negative_sample_loss at step 895400: 0.134861\n",
      "2022-11-09 02:36:24,860 INFO     Training average loss at step 895400: 0.139069\n",
      "2022-11-09 02:36:27,961 INFO     Training average positive_sample_loss at step 895500: 0.142165\n",
      "2022-11-09 02:36:27,961 INFO     Training average negative_sample_loss at step 895500: 0.137714\n",
      "2022-11-09 02:36:27,961 INFO     Training average loss at step 895500: 0.139940\n",
      "2022-11-09 02:36:31,060 INFO     Training average positive_sample_loss at step 895600: 0.138600\n",
      "2022-11-09 02:36:31,060 INFO     Training average negative_sample_loss at step 895600: 0.136608\n",
      "2022-11-09 02:36:31,060 INFO     Training average loss at step 895600: 0.137604\n",
      "2022-11-09 02:36:34,168 INFO     Training average positive_sample_loss at step 895700: 0.139536\n",
      "2022-11-09 02:36:34,168 INFO     Training average negative_sample_loss at step 895700: 0.138162\n",
      "2022-11-09 02:36:34,168 INFO     Training average loss at step 895700: 0.138849\n",
      "2022-11-09 02:36:37,282 INFO     Training average positive_sample_loss at step 895800: 0.137837\n",
      "2022-11-09 02:36:37,282 INFO     Training average negative_sample_loss at step 895800: 0.138021\n",
      "2022-11-09 02:36:37,282 INFO     Training average loss at step 895800: 0.137929\n",
      "2022-11-09 02:36:40,393 INFO     Training average positive_sample_loss at step 895900: 0.142149\n",
      "2022-11-09 02:36:40,393 INFO     Training average negative_sample_loss at step 895900: 0.140699\n",
      "2022-11-09 02:36:40,393 INFO     Training average loss at step 895900: 0.141424\n",
      "2022-11-09 02:36:43,514 INFO     Training average positive_sample_loss at step 896000: 0.141211\n",
      "2022-11-09 02:36:43,514 INFO     Training average negative_sample_loss at step 896000: 0.136266\n",
      "2022-11-09 02:36:43,514 INFO     Training average loss at step 896000: 0.138738\n",
      "2022-11-09 02:36:46,624 INFO     Training average positive_sample_loss at step 896100: 0.140290\n",
      "2022-11-09 02:36:46,624 INFO     Training average negative_sample_loss at step 896100: 0.132225\n",
      "2022-11-09 02:36:46,624 INFO     Training average loss at step 896100: 0.136257\n",
      "2022-11-09 02:36:49,734 INFO     Training average positive_sample_loss at step 896200: 0.140498\n",
      "2022-11-09 02:36:49,734 INFO     Training average negative_sample_loss at step 896200: 0.135338\n",
      "2022-11-09 02:36:49,734 INFO     Training average loss at step 896200: 0.137918\n",
      "2022-11-09 02:36:52,848 INFO     Training average positive_sample_loss at step 896300: 0.140374\n",
      "2022-11-09 02:36:52,849 INFO     Training average negative_sample_loss at step 896300: 0.134683\n",
      "2022-11-09 02:36:52,849 INFO     Training average loss at step 896300: 0.137528\n",
      "2022-11-09 02:36:55,965 INFO     Training average positive_sample_loss at step 896400: 0.138598\n",
      "2022-11-09 02:36:55,965 INFO     Training average negative_sample_loss at step 896400: 0.135112\n",
      "2022-11-09 02:36:55,965 INFO     Training average loss at step 896400: 0.136855\n",
      "2022-11-09 02:36:59,082 INFO     Training average positive_sample_loss at step 896500: 0.134523\n",
      "2022-11-09 02:36:59,083 INFO     Training average negative_sample_loss at step 896500: 0.136534\n",
      "2022-11-09 02:36:59,083 INFO     Training average loss at step 896500: 0.135528\n",
      "2022-11-09 02:37:02,185 INFO     Training average positive_sample_loss at step 896600: 0.140877\n",
      "2022-11-09 02:37:02,185 INFO     Training average negative_sample_loss at step 896600: 0.134615\n",
      "2022-11-09 02:37:02,185 INFO     Training average loss at step 896600: 0.137746\n",
      "2022-11-09 02:37:05,285 INFO     Training average positive_sample_loss at step 896700: 0.140048\n",
      "2022-11-09 02:37:05,286 INFO     Training average negative_sample_loss at step 896700: 0.138972\n",
      "2022-11-09 02:37:05,286 INFO     Training average loss at step 896700: 0.139510\n",
      "2022-11-09 02:37:08,410 INFO     Training average positive_sample_loss at step 896800: 0.140588\n",
      "2022-11-09 02:37:08,410 INFO     Training average negative_sample_loss at step 896800: 0.131754\n",
      "2022-11-09 02:37:08,410 INFO     Training average loss at step 896800: 0.136171\n",
      "2022-11-09 02:37:11,526 INFO     Training average positive_sample_loss at step 896900: 0.147595\n",
      "2022-11-09 02:37:11,526 INFO     Training average negative_sample_loss at step 896900: 0.134632\n",
      "2022-11-09 02:37:11,526 INFO     Training average loss at step 896900: 0.141113\n",
      "2022-11-09 02:37:14,640 INFO     Training average positive_sample_loss at step 897000: 0.137077\n",
      "2022-11-09 02:37:14,640 INFO     Training average negative_sample_loss at step 897000: 0.133633\n",
      "2022-11-09 02:37:14,641 INFO     Training average loss at step 897000: 0.135355\n",
      "2022-11-09 02:37:17,750 INFO     Training average positive_sample_loss at step 897100: 0.140131\n",
      "2022-11-09 02:37:17,750 INFO     Training average negative_sample_loss at step 897100: 0.138818\n",
      "2022-11-09 02:37:17,750 INFO     Training average loss at step 897100: 0.139475\n",
      "2022-11-09 02:37:20,871 INFO     Training average positive_sample_loss at step 897200: 0.140515\n",
      "2022-11-09 02:37:20,871 INFO     Training average negative_sample_loss at step 897200: 0.134416\n",
      "2022-11-09 02:37:20,871 INFO     Training average loss at step 897200: 0.137465\n",
      "2022-11-09 02:37:23,994 INFO     Training average positive_sample_loss at step 897300: 0.143084\n",
      "2022-11-09 02:37:23,994 INFO     Training average negative_sample_loss at step 897300: 0.138069\n",
      "2022-11-09 02:37:23,994 INFO     Training average loss at step 897300: 0.140577\n",
      "2022-11-09 02:37:27,108 INFO     Training average positive_sample_loss at step 897400: 0.138868\n",
      "2022-11-09 02:37:27,108 INFO     Training average negative_sample_loss at step 897400: 0.135610\n",
      "2022-11-09 02:37:27,108 INFO     Training average loss at step 897400: 0.137239\n",
      "2022-11-09 02:37:30,214 INFO     Training average positive_sample_loss at step 897500: 0.142134\n",
      "2022-11-09 02:37:30,214 INFO     Training average negative_sample_loss at step 897500: 0.135795\n",
      "2022-11-09 02:37:30,214 INFO     Training average loss at step 897500: 0.138964\n",
      "2022-11-09 02:37:33,325 INFO     Training average positive_sample_loss at step 897600: 0.140135\n",
      "2022-11-09 02:37:33,325 INFO     Training average negative_sample_loss at step 897600: 0.132683\n",
      "2022-11-09 02:37:33,325 INFO     Training average loss at step 897600: 0.136409\n",
      "2022-11-09 02:37:36,443 INFO     Training average positive_sample_loss at step 897700: 0.139482\n",
      "2022-11-09 02:37:36,443 INFO     Training average negative_sample_loss at step 897700: 0.135371\n",
      "2022-11-09 02:37:36,443 INFO     Training average loss at step 897700: 0.137427\n",
      "2022-11-09 02:37:39,547 INFO     Training average positive_sample_loss at step 897800: 0.134251\n",
      "2022-11-09 02:37:39,547 INFO     Training average negative_sample_loss at step 897800: 0.137543\n",
      "2022-11-09 02:37:39,547 INFO     Training average loss at step 897800: 0.135897\n",
      "2022-11-09 02:37:42,674 INFO     Training average positive_sample_loss at step 897900: 0.140029\n",
      "2022-11-09 02:37:42,674 INFO     Training average negative_sample_loss at step 897900: 0.133793\n",
      "2022-11-09 02:37:42,674 INFO     Training average loss at step 897900: 0.136911\n",
      "2022-11-09 02:37:45,773 INFO     Training average positive_sample_loss at step 898000: 0.137221\n",
      "2022-11-09 02:37:45,774 INFO     Training average negative_sample_loss at step 898000: 0.138031\n",
      "2022-11-09 02:37:45,774 INFO     Training average loss at step 898000: 0.137626\n",
      "2022-11-09 02:37:48,874 INFO     Training average positive_sample_loss at step 898100: 0.138061\n",
      "2022-11-09 02:37:48,874 INFO     Training average negative_sample_loss at step 898100: 0.132983\n",
      "2022-11-09 02:37:48,874 INFO     Training average loss at step 898100: 0.135522\n",
      "2022-11-09 02:37:51,982 INFO     Training average positive_sample_loss at step 898200: 0.136805\n",
      "2022-11-09 02:37:51,982 INFO     Training average negative_sample_loss at step 898200: 0.135567\n",
      "2022-11-09 02:37:51,982 INFO     Training average loss at step 898200: 0.136186\n",
      "2022-11-09 02:37:55,091 INFO     Training average positive_sample_loss at step 898300: 0.144517\n",
      "2022-11-09 02:37:55,091 INFO     Training average negative_sample_loss at step 898300: 0.136122\n",
      "2022-11-09 02:37:55,091 INFO     Training average loss at step 898300: 0.140319\n",
      "2022-11-09 02:37:58,212 INFO     Training average positive_sample_loss at step 898400: 0.138818\n",
      "2022-11-09 02:37:58,212 INFO     Training average negative_sample_loss at step 898400: 0.131978\n",
      "2022-11-09 02:37:58,212 INFO     Training average loss at step 898400: 0.135398\n",
      "2022-11-09 02:38:01,319 INFO     Training average positive_sample_loss at step 898500: 0.145130\n",
      "2022-11-09 02:38:01,319 INFO     Training average negative_sample_loss at step 898500: 0.134112\n",
      "2022-11-09 02:38:01,319 INFO     Training average loss at step 898500: 0.139621\n",
      "2022-11-09 02:38:04,428 INFO     Training average positive_sample_loss at step 898600: 0.134615\n",
      "2022-11-09 02:38:04,428 INFO     Training average negative_sample_loss at step 898600: 0.140516\n",
      "2022-11-09 02:38:04,428 INFO     Training average loss at step 898600: 0.137566\n",
      "2022-11-09 02:38:07,542 INFO     Training average positive_sample_loss at step 898700: 0.141629\n",
      "2022-11-09 02:38:07,543 INFO     Training average negative_sample_loss at step 898700: 0.135817\n",
      "2022-11-09 02:38:07,543 INFO     Training average loss at step 898700: 0.138723\n",
      "2022-11-09 02:38:10,647 INFO     Training average positive_sample_loss at step 898800: 0.144160\n",
      "2022-11-09 02:38:10,647 INFO     Training average negative_sample_loss at step 898800: 0.131406\n",
      "2022-11-09 02:38:10,647 INFO     Training average loss at step 898800: 0.137783\n",
      "2022-11-09 02:38:13,746 INFO     Training average positive_sample_loss at step 898900: 0.135960\n",
      "2022-11-09 02:38:13,746 INFO     Training average negative_sample_loss at step 898900: 0.137971\n",
      "2022-11-09 02:38:13,747 INFO     Training average loss at step 898900: 0.136965\n",
      "2022-11-09 02:38:16,853 INFO     Training average positive_sample_loss at step 899000: 0.143267\n",
      "2022-11-09 02:38:16,854 INFO     Training average negative_sample_loss at step 899000: 0.132995\n",
      "2022-11-09 02:38:16,854 INFO     Training average loss at step 899000: 0.138131\n",
      "2022-11-09 02:38:19,972 INFO     Training average positive_sample_loss at step 899100: 0.135228\n",
      "2022-11-09 02:38:19,972 INFO     Training average negative_sample_loss at step 899100: 0.132971\n",
      "2022-11-09 02:38:19,972 INFO     Training average loss at step 899100: 0.134100\n",
      "2022-11-09 02:38:23,076 INFO     Training average positive_sample_loss at step 899200: 0.136304\n",
      "2022-11-09 02:38:23,076 INFO     Training average negative_sample_loss at step 899200: 0.134561\n",
      "2022-11-09 02:38:23,076 INFO     Training average loss at step 899200: 0.135433\n",
      "2022-11-09 02:38:26,177 INFO     Training average positive_sample_loss at step 899300: 0.141287\n",
      "2022-11-09 02:38:26,177 INFO     Training average negative_sample_loss at step 899300: 0.135768\n",
      "2022-11-09 02:38:26,177 INFO     Training average loss at step 899300: 0.138528\n",
      "2022-11-09 02:38:30,133 INFO     Training average positive_sample_loss at step 899400: 0.139816\n",
      "2022-11-09 02:38:30,133 INFO     Training average negative_sample_loss at step 899400: 0.136833\n",
      "2022-11-09 02:38:30,133 INFO     Training average loss at step 899400: 0.138325\n",
      "2022-11-09 02:38:33,252 INFO     Training average positive_sample_loss at step 899500: 0.137841\n",
      "2022-11-09 02:38:33,252 INFO     Training average negative_sample_loss at step 899500: 0.139814\n",
      "2022-11-09 02:38:33,252 INFO     Training average loss at step 899500: 0.138827\n",
      "2022-11-09 02:38:37,602 INFO     Training average positive_sample_loss at step 899600: 0.137777\n",
      "2022-11-09 02:38:37,603 INFO     Training average negative_sample_loss at step 899600: 0.134865\n",
      "2022-11-09 02:38:37,603 INFO     Training average loss at step 899600: 0.136321\n",
      "2022-11-09 02:38:42,232 INFO     Training average positive_sample_loss at step 899700: 0.138576\n",
      "2022-11-09 02:38:42,232 INFO     Training average negative_sample_loss at step 899700: 0.132840\n",
      "2022-11-09 02:38:42,232 INFO     Training average loss at step 899700: 0.135708\n",
      "2022-11-09 02:38:45,352 INFO     Training average positive_sample_loss at step 899800: 0.139659\n",
      "2022-11-09 02:38:45,352 INFO     Training average negative_sample_loss at step 899800: 0.133300\n",
      "2022-11-09 02:38:45,352 INFO     Training average loss at step 899800: 0.136480\n",
      "2022-11-09 02:38:48,476 INFO     Training average positive_sample_loss at step 899900: 0.142517\n",
      "2022-11-09 02:38:48,476 INFO     Training average negative_sample_loss at step 899900: 0.133459\n",
      "2022-11-09 02:38:48,476 INFO     Training average loss at step 899900: 0.137988\n",
      "2022-11-09 02:38:54,410 INFO     Training average positive_sample_loss at step 900000: 0.138634\n",
      "2022-11-09 02:38:54,410 INFO     Training average negative_sample_loss at step 900000: 0.133458\n",
      "2022-11-09 02:38:54,410 INFO     Training average loss at step 900000: 0.136046\n",
      "2022-11-09 02:38:57,517 INFO     Training average positive_sample_loss at step 900100: 0.139720\n",
      "2022-11-09 02:38:57,518 INFO     Training average negative_sample_loss at step 900100: 0.135552\n",
      "2022-11-09 02:38:57,518 INFO     Training average loss at step 900100: 0.137636\n",
      "2022-11-09 02:39:00,626 INFO     Training average positive_sample_loss at step 900200: 0.141641\n",
      "2022-11-09 02:39:00,626 INFO     Training average negative_sample_loss at step 900200: 0.133267\n",
      "2022-11-09 02:39:00,626 INFO     Training average loss at step 900200: 0.137454\n",
      "2022-11-09 02:39:03,732 INFO     Training average positive_sample_loss at step 900300: 0.140319\n",
      "2022-11-09 02:39:03,732 INFO     Training average negative_sample_loss at step 900300: 0.134481\n",
      "2022-11-09 02:39:03,732 INFO     Training average loss at step 900300: 0.137400\n",
      "2022-11-09 02:39:06,835 INFO     Training average positive_sample_loss at step 900400: 0.142386\n",
      "2022-11-09 02:39:06,836 INFO     Training average negative_sample_loss at step 900400: 0.135482\n",
      "2022-11-09 02:39:06,836 INFO     Training average loss at step 900400: 0.138934\n",
      "2022-11-09 02:39:09,923 INFO     Training average positive_sample_loss at step 900500: 0.141951\n",
      "2022-11-09 02:39:09,923 INFO     Training average negative_sample_loss at step 900500: 0.136651\n",
      "2022-11-09 02:39:09,923 INFO     Training average loss at step 900500: 0.139301\n",
      "2022-11-09 02:39:13,025 INFO     Training average positive_sample_loss at step 900600: 0.137917\n",
      "2022-11-09 02:39:13,025 INFO     Training average negative_sample_loss at step 900600: 0.133828\n",
      "2022-11-09 02:39:13,025 INFO     Training average loss at step 900600: 0.135872\n",
      "2022-11-09 02:39:16,131 INFO     Training average positive_sample_loss at step 900700: 0.138431\n",
      "2022-11-09 02:39:16,131 INFO     Training average negative_sample_loss at step 900700: 0.128550\n",
      "2022-11-09 02:39:16,131 INFO     Training average loss at step 900700: 0.133490\n",
      "2022-11-09 02:39:19,241 INFO     Training average positive_sample_loss at step 900800: 0.139115\n",
      "2022-11-09 02:39:19,241 INFO     Training average negative_sample_loss at step 900800: 0.134299\n",
      "2022-11-09 02:39:19,241 INFO     Training average loss at step 900800: 0.136707\n",
      "2022-11-09 02:39:22,340 INFO     Training average positive_sample_loss at step 900900: 0.135241\n",
      "2022-11-09 02:39:22,340 INFO     Training average negative_sample_loss at step 900900: 0.133694\n",
      "2022-11-09 02:39:22,340 INFO     Training average loss at step 900900: 0.134467\n",
      "2022-11-09 02:39:25,439 INFO     Training average positive_sample_loss at step 901000: 0.138843\n",
      "2022-11-09 02:39:25,439 INFO     Training average negative_sample_loss at step 901000: 0.134422\n",
      "2022-11-09 02:39:25,439 INFO     Training average loss at step 901000: 0.136632\n",
      "2022-11-09 02:39:28,540 INFO     Training average positive_sample_loss at step 901100: 0.138213\n",
      "2022-11-09 02:39:28,540 INFO     Training average negative_sample_loss at step 901100: 0.131029\n",
      "2022-11-09 02:39:28,540 INFO     Training average loss at step 901100: 0.134621\n",
      "2022-11-09 02:39:31,651 INFO     Training average positive_sample_loss at step 901200: 0.142209\n",
      "2022-11-09 02:39:31,651 INFO     Training average negative_sample_loss at step 901200: 0.133325\n",
      "2022-11-09 02:39:31,651 INFO     Training average loss at step 901200: 0.137767\n",
      "2022-11-09 02:39:34,760 INFO     Training average positive_sample_loss at step 901300: 0.138949\n",
      "2022-11-09 02:39:34,760 INFO     Training average negative_sample_loss at step 901300: 0.137805\n",
      "2022-11-09 02:39:34,760 INFO     Training average loss at step 901300: 0.138377\n",
      "2022-11-09 02:39:37,855 INFO     Training average positive_sample_loss at step 901400: 0.141471\n",
      "2022-11-09 02:39:37,855 INFO     Training average negative_sample_loss at step 901400: 0.135226\n",
      "2022-11-09 02:39:37,855 INFO     Training average loss at step 901400: 0.138348\n",
      "2022-11-09 02:39:40,951 INFO     Training average positive_sample_loss at step 901500: 0.138929\n",
      "2022-11-09 02:39:40,951 INFO     Training average negative_sample_loss at step 901500: 0.133988\n",
      "2022-11-09 02:39:40,951 INFO     Training average loss at step 901500: 0.136458\n",
      "2022-11-09 02:39:44,044 INFO     Training average positive_sample_loss at step 901600: 0.137599\n",
      "2022-11-09 02:39:44,044 INFO     Training average negative_sample_loss at step 901600: 0.134322\n",
      "2022-11-09 02:39:44,044 INFO     Training average loss at step 901600: 0.135961\n",
      "2022-11-09 02:39:47,144 INFO     Training average positive_sample_loss at step 901700: 0.140499\n",
      "2022-11-09 02:39:47,144 INFO     Training average negative_sample_loss at step 901700: 0.138366\n",
      "2022-11-09 02:39:47,144 INFO     Training average loss at step 901700: 0.139433\n",
      "2022-11-09 02:39:50,254 INFO     Training average positive_sample_loss at step 901800: 0.136378\n",
      "2022-11-09 02:39:50,254 INFO     Training average negative_sample_loss at step 901800: 0.132692\n",
      "2022-11-09 02:39:50,254 INFO     Training average loss at step 901800: 0.134535\n",
      "2022-11-09 02:39:53,372 INFO     Training average positive_sample_loss at step 901900: 0.140128\n",
      "2022-11-09 02:39:53,372 INFO     Training average negative_sample_loss at step 901900: 0.139688\n",
      "2022-11-09 02:39:53,372 INFO     Training average loss at step 901900: 0.139908\n",
      "2022-11-09 02:39:56,478 INFO     Training average positive_sample_loss at step 902000: 0.142251\n",
      "2022-11-09 02:39:56,478 INFO     Training average negative_sample_loss at step 902000: 0.133277\n",
      "2022-11-09 02:39:56,478 INFO     Training average loss at step 902000: 0.137764\n",
      "2022-11-09 02:39:59,603 INFO     Training average positive_sample_loss at step 902100: 0.143211\n",
      "2022-11-09 02:39:59,603 INFO     Training average negative_sample_loss at step 902100: 0.139523\n",
      "2022-11-09 02:39:59,603 INFO     Training average loss at step 902100: 0.141367\n",
      "2022-11-09 02:40:02,720 INFO     Training average positive_sample_loss at step 902200: 0.142886\n",
      "2022-11-09 02:40:02,720 INFO     Training average negative_sample_loss at step 902200: 0.137072\n",
      "2022-11-09 02:40:02,720 INFO     Training average loss at step 902200: 0.139979\n",
      "2022-11-09 02:40:05,834 INFO     Training average positive_sample_loss at step 902300: 0.139713\n",
      "2022-11-09 02:40:05,834 INFO     Training average negative_sample_loss at step 902300: 0.135434\n",
      "2022-11-09 02:40:05,834 INFO     Training average loss at step 902300: 0.137573\n",
      "2022-11-09 02:40:08,954 INFO     Training average positive_sample_loss at step 902400: 0.141508\n",
      "2022-11-09 02:40:08,954 INFO     Training average negative_sample_loss at step 902400: 0.137439\n",
      "2022-11-09 02:40:08,954 INFO     Training average loss at step 902400: 0.139473\n",
      "2022-11-09 02:40:12,060 INFO     Training average positive_sample_loss at step 902500: 0.138336\n",
      "2022-11-09 02:40:12,060 INFO     Training average negative_sample_loss at step 902500: 0.132231\n",
      "2022-11-09 02:40:12,060 INFO     Training average loss at step 902500: 0.135284\n",
      "2022-11-09 02:40:15,168 INFO     Training average positive_sample_loss at step 902600: 0.138198\n",
      "2022-11-09 02:40:15,169 INFO     Training average negative_sample_loss at step 902600: 0.131317\n",
      "2022-11-09 02:40:15,169 INFO     Training average loss at step 902600: 0.134758\n",
      "2022-11-09 02:40:18,256 INFO     Training average positive_sample_loss at step 902700: 0.137519\n",
      "2022-11-09 02:40:18,257 INFO     Training average negative_sample_loss at step 902700: 0.140595\n",
      "2022-11-09 02:40:18,257 INFO     Training average loss at step 902700: 0.139057\n",
      "2022-11-09 02:40:21,356 INFO     Training average positive_sample_loss at step 902800: 0.139278\n",
      "2022-11-09 02:40:21,356 INFO     Training average negative_sample_loss at step 902800: 0.137689\n",
      "2022-11-09 02:40:21,356 INFO     Training average loss at step 902800: 0.138483\n",
      "2022-11-09 02:40:24,461 INFO     Training average positive_sample_loss at step 902900: 0.137180\n",
      "2022-11-09 02:40:24,461 INFO     Training average negative_sample_loss at step 902900: 0.139881\n",
      "2022-11-09 02:40:24,461 INFO     Training average loss at step 902900: 0.138530\n",
      "2022-11-09 02:40:27,567 INFO     Training average positive_sample_loss at step 903000: 0.137855\n",
      "2022-11-09 02:40:27,567 INFO     Training average negative_sample_loss at step 903000: 0.137112\n",
      "2022-11-09 02:40:27,567 INFO     Training average loss at step 903000: 0.137484\n",
      "2022-11-09 02:40:30,692 INFO     Training average positive_sample_loss at step 903100: 0.140147\n",
      "2022-11-09 02:40:30,692 INFO     Training average negative_sample_loss at step 903100: 0.139529\n",
      "2022-11-09 02:40:30,692 INFO     Training average loss at step 903100: 0.139838\n",
      "2022-11-09 02:40:33,816 INFO     Training average positive_sample_loss at step 903200: 0.139349\n",
      "2022-11-09 02:40:33,816 INFO     Training average negative_sample_loss at step 903200: 0.137617\n",
      "2022-11-09 02:40:33,816 INFO     Training average loss at step 903200: 0.138483\n",
      "2022-11-09 02:40:36,929 INFO     Training average positive_sample_loss at step 903300: 0.135837\n",
      "2022-11-09 02:40:36,929 INFO     Training average negative_sample_loss at step 903300: 0.134572\n",
      "2022-11-09 02:40:36,929 INFO     Training average loss at step 903300: 0.135205\n",
      "2022-11-09 02:40:40,016 INFO     Training average positive_sample_loss at step 903400: 0.141669\n",
      "2022-11-09 02:40:40,016 INFO     Training average negative_sample_loss at step 903400: 0.137802\n",
      "2022-11-09 02:40:40,016 INFO     Training average loss at step 903400: 0.139736\n",
      "2022-11-09 02:40:43,114 INFO     Training average positive_sample_loss at step 903500: 0.137429\n",
      "2022-11-09 02:40:43,114 INFO     Training average negative_sample_loss at step 903500: 0.134372\n",
      "2022-11-09 02:40:43,114 INFO     Training average loss at step 903500: 0.135901\n",
      "2022-11-09 02:40:46,227 INFO     Training average positive_sample_loss at step 903600: 0.141718\n",
      "2022-11-09 02:40:46,227 INFO     Training average negative_sample_loss at step 903600: 0.140715\n",
      "2022-11-09 02:40:46,227 INFO     Training average loss at step 903600: 0.141216\n",
      "2022-11-09 02:40:49,343 INFO     Training average positive_sample_loss at step 903700: 0.137981\n",
      "2022-11-09 02:40:49,343 INFO     Training average negative_sample_loss at step 903700: 0.137597\n",
      "2022-11-09 02:40:49,343 INFO     Training average loss at step 903700: 0.137789\n",
      "2022-11-09 02:40:52,453 INFO     Training average positive_sample_loss at step 903800: 0.138983\n",
      "2022-11-09 02:40:52,453 INFO     Training average negative_sample_loss at step 903800: 0.141537\n",
      "2022-11-09 02:40:52,453 INFO     Training average loss at step 903800: 0.140260\n",
      "2022-11-09 02:40:55,560 INFO     Training average positive_sample_loss at step 903900: 0.138995\n",
      "2022-11-09 02:40:55,560 INFO     Training average negative_sample_loss at step 903900: 0.142238\n",
      "2022-11-09 02:40:55,560 INFO     Training average loss at step 903900: 0.140617\n",
      "2022-11-09 02:40:58,672 INFO     Training average positive_sample_loss at step 904000: 0.138908\n",
      "2022-11-09 02:40:58,672 INFO     Training average negative_sample_loss at step 904000: 0.137422\n",
      "2022-11-09 02:40:58,672 INFO     Training average loss at step 904000: 0.138165\n",
      "2022-11-09 02:41:02,638 INFO     Training average positive_sample_loss at step 904100: 0.146291\n",
      "2022-11-09 02:41:02,639 INFO     Training average negative_sample_loss at step 904100: 0.136213\n",
      "2022-11-09 02:41:02,639 INFO     Training average loss at step 904100: 0.141252\n",
      "2022-11-09 02:41:06,957 INFO     Training average positive_sample_loss at step 904200: 0.134106\n",
      "2022-11-09 02:41:06,957 INFO     Training average negative_sample_loss at step 904200: 0.138590\n",
      "2022-11-09 02:41:06,958 INFO     Training average loss at step 904200: 0.136348\n",
      "2022-11-09 02:41:10,062 INFO     Training average positive_sample_loss at step 904300: 0.140914\n",
      "2022-11-09 02:41:10,062 INFO     Training average negative_sample_loss at step 904300: 0.140844\n",
      "2022-11-09 02:41:10,062 INFO     Training average loss at step 904300: 0.140879\n",
      "2022-11-09 02:41:14,707 INFO     Training average positive_sample_loss at step 904400: 0.141466\n",
      "2022-11-09 02:41:14,707 INFO     Training average negative_sample_loss at step 904400: 0.132706\n",
      "2022-11-09 02:41:14,707 INFO     Training average loss at step 904400: 0.137086\n",
      "2022-11-09 02:41:17,820 INFO     Training average positive_sample_loss at step 904500: 0.134767\n",
      "2022-11-09 02:41:17,820 INFO     Training average negative_sample_loss at step 904500: 0.135997\n",
      "2022-11-09 02:41:17,820 INFO     Training average loss at step 904500: 0.135382\n",
      "2022-11-09 02:41:20,929 INFO     Training average positive_sample_loss at step 904600: 0.140145\n",
      "2022-11-09 02:41:20,929 INFO     Training average negative_sample_loss at step 904600: 0.137957\n",
      "2022-11-09 02:41:20,929 INFO     Training average loss at step 904600: 0.139051\n",
      "2022-11-09 02:41:24,046 INFO     Training average positive_sample_loss at step 904700: 0.139605\n",
      "2022-11-09 02:41:24,046 INFO     Training average negative_sample_loss at step 904700: 0.139064\n",
      "2022-11-09 02:41:24,047 INFO     Training average loss at step 904700: 0.139335\n",
      "2022-11-09 02:41:27,167 INFO     Training average positive_sample_loss at step 904800: 0.140510\n",
      "2022-11-09 02:41:27,167 INFO     Training average negative_sample_loss at step 904800: 0.132239\n",
      "2022-11-09 02:41:27,167 INFO     Training average loss at step 904800: 0.136375\n",
      "2022-11-09 02:41:30,294 INFO     Training average positive_sample_loss at step 904900: 0.143299\n",
      "2022-11-09 02:41:30,294 INFO     Training average negative_sample_loss at step 904900: 0.141400\n",
      "2022-11-09 02:41:30,294 INFO     Training average loss at step 904900: 0.142349\n",
      "2022-11-09 02:41:33,421 INFO     Training average positive_sample_loss at step 905000: 0.138909\n",
      "2022-11-09 02:41:33,421 INFO     Training average negative_sample_loss at step 905000: 0.132772\n",
      "2022-11-09 02:41:33,421 INFO     Training average loss at step 905000: 0.135840\n",
      "2022-11-09 02:41:36,527 INFO     Training average positive_sample_loss at step 905100: 0.140509\n",
      "2022-11-09 02:41:36,528 INFO     Training average negative_sample_loss at step 905100: 0.132192\n",
      "2022-11-09 02:41:36,528 INFO     Training average loss at step 905100: 0.136351\n",
      "2022-11-09 02:41:39,633 INFO     Training average positive_sample_loss at step 905200: 0.137768\n",
      "2022-11-09 02:41:39,634 INFO     Training average negative_sample_loss at step 905200: 0.133025\n",
      "2022-11-09 02:41:39,634 INFO     Training average loss at step 905200: 0.135397\n",
      "2022-11-09 02:41:42,749 INFO     Training average positive_sample_loss at step 905300: 0.144283\n",
      "2022-11-09 02:41:42,749 INFO     Training average negative_sample_loss at step 905300: 0.132038\n",
      "2022-11-09 02:41:42,749 INFO     Training average loss at step 905300: 0.138161\n",
      "2022-11-09 02:41:45,859 INFO     Training average positive_sample_loss at step 905400: 0.139059\n",
      "2022-11-09 02:41:45,859 INFO     Training average negative_sample_loss at step 905400: 0.138619\n",
      "2022-11-09 02:41:45,859 INFO     Training average loss at step 905400: 0.138839\n",
      "2022-11-09 02:41:48,964 INFO     Training average positive_sample_loss at step 905500: 0.136934\n",
      "2022-11-09 02:41:48,964 INFO     Training average negative_sample_loss at step 905500: 0.139616\n",
      "2022-11-09 02:41:48,964 INFO     Training average loss at step 905500: 0.138275\n",
      "2022-11-09 02:41:52,069 INFO     Training average positive_sample_loss at step 905600: 0.143797\n",
      "2022-11-09 02:41:52,069 INFO     Training average negative_sample_loss at step 905600: 0.136398\n",
      "2022-11-09 02:41:52,069 INFO     Training average loss at step 905600: 0.140097\n",
      "2022-11-09 02:41:55,179 INFO     Training average positive_sample_loss at step 905700: 0.140417\n",
      "2022-11-09 02:41:55,179 INFO     Training average negative_sample_loss at step 905700: 0.133742\n",
      "2022-11-09 02:41:55,180 INFO     Training average loss at step 905700: 0.137079\n",
      "2022-11-09 02:41:58,286 INFO     Training average positive_sample_loss at step 905800: 0.141280\n",
      "2022-11-09 02:41:58,286 INFO     Training average negative_sample_loss at step 905800: 0.137115\n",
      "2022-11-09 02:41:58,286 INFO     Training average loss at step 905800: 0.139197\n",
      "2022-11-09 02:42:01,392 INFO     Training average positive_sample_loss at step 905900: 0.138778\n",
      "2022-11-09 02:42:01,392 INFO     Training average negative_sample_loss at step 905900: 0.135016\n",
      "2022-11-09 02:42:01,392 INFO     Training average loss at step 905900: 0.136897\n",
      "2022-11-09 02:42:04,509 INFO     Training average positive_sample_loss at step 906000: 0.145549\n",
      "2022-11-09 02:42:04,510 INFO     Training average negative_sample_loss at step 906000: 0.136258\n",
      "2022-11-09 02:42:04,510 INFO     Training average loss at step 906000: 0.140904\n",
      "2022-11-09 02:42:07,620 INFO     Training average positive_sample_loss at step 906100: 0.140228\n",
      "2022-11-09 02:42:07,620 INFO     Training average negative_sample_loss at step 906100: 0.137083\n",
      "2022-11-09 02:42:07,620 INFO     Training average loss at step 906100: 0.138655\n",
      "2022-11-09 02:42:10,720 INFO     Training average positive_sample_loss at step 906200: 0.141626\n",
      "2022-11-09 02:42:10,720 INFO     Training average negative_sample_loss at step 906200: 0.133479\n",
      "2022-11-09 02:42:10,720 INFO     Training average loss at step 906200: 0.137553\n",
      "2022-11-09 02:42:13,814 INFO     Training average positive_sample_loss at step 906300: 0.138815\n",
      "2022-11-09 02:42:13,814 INFO     Training average negative_sample_loss at step 906300: 0.136065\n",
      "2022-11-09 02:42:13,814 INFO     Training average loss at step 906300: 0.137440\n",
      "2022-11-09 02:42:16,920 INFO     Training average positive_sample_loss at step 906400: 0.138603\n",
      "2022-11-09 02:42:16,920 INFO     Training average negative_sample_loss at step 906400: 0.135915\n",
      "2022-11-09 02:42:16,920 INFO     Training average loss at step 906400: 0.137259\n",
      "2022-11-09 02:42:20,031 INFO     Training average positive_sample_loss at step 906500: 0.136809\n",
      "2022-11-09 02:42:20,031 INFO     Training average negative_sample_loss at step 906500: 0.136452\n",
      "2022-11-09 02:42:20,031 INFO     Training average loss at step 906500: 0.136630\n",
      "2022-11-09 02:42:23,145 INFO     Training average positive_sample_loss at step 906600: 0.145222\n",
      "2022-11-09 02:42:23,145 INFO     Training average negative_sample_loss at step 906600: 0.135227\n",
      "2022-11-09 02:42:23,145 INFO     Training average loss at step 906600: 0.140225\n",
      "2022-11-09 02:42:26,256 INFO     Training average positive_sample_loss at step 906700: 0.138717\n",
      "2022-11-09 02:42:26,256 INFO     Training average negative_sample_loss at step 906700: 0.135168\n",
      "2022-11-09 02:42:26,256 INFO     Training average loss at step 906700: 0.136942\n",
      "2022-11-09 02:42:29,359 INFO     Training average positive_sample_loss at step 906800: 0.141913\n",
      "2022-11-09 02:42:29,359 INFO     Training average negative_sample_loss at step 906800: 0.137418\n",
      "2022-11-09 02:42:29,359 INFO     Training average loss at step 906800: 0.139666\n",
      "2022-11-09 02:42:32,462 INFO     Training average positive_sample_loss at step 906900: 0.141884\n",
      "2022-11-09 02:42:32,462 INFO     Training average negative_sample_loss at step 906900: 0.134226\n",
      "2022-11-09 02:42:32,462 INFO     Training average loss at step 906900: 0.138055\n",
      "2022-11-09 02:42:35,560 INFO     Training average positive_sample_loss at step 907000: 0.145320\n",
      "2022-11-09 02:42:35,560 INFO     Training average negative_sample_loss at step 907000: 0.131637\n",
      "2022-11-09 02:42:35,560 INFO     Training average loss at step 907000: 0.138479\n",
      "2022-11-09 02:42:38,666 INFO     Training average positive_sample_loss at step 907100: 0.146290\n",
      "2022-11-09 02:42:38,666 INFO     Training average negative_sample_loss at step 907100: 0.135389\n",
      "2022-11-09 02:42:38,666 INFO     Training average loss at step 907100: 0.140839\n",
      "2022-11-09 02:42:41,763 INFO     Training average positive_sample_loss at step 907200: 0.140600\n",
      "2022-11-09 02:42:41,764 INFO     Training average negative_sample_loss at step 907200: 0.134995\n",
      "2022-11-09 02:42:41,764 INFO     Training average loss at step 907200: 0.137798\n",
      "2022-11-09 02:42:44,874 INFO     Training average positive_sample_loss at step 907300: 0.139416\n",
      "2022-11-09 02:42:44,874 INFO     Training average negative_sample_loss at step 907300: 0.135257\n",
      "2022-11-09 02:42:44,874 INFO     Training average loss at step 907300: 0.137336\n",
      "2022-11-09 02:42:47,971 INFO     Training average positive_sample_loss at step 907400: 0.139355\n",
      "2022-11-09 02:42:47,971 INFO     Training average negative_sample_loss at step 907400: 0.140560\n",
      "2022-11-09 02:42:47,971 INFO     Training average loss at step 907400: 0.139958\n",
      "2022-11-09 02:42:51,071 INFO     Training average positive_sample_loss at step 907500: 0.141174\n",
      "2022-11-09 02:42:51,072 INFO     Training average negative_sample_loss at step 907500: 0.140369\n",
      "2022-11-09 02:42:51,072 INFO     Training average loss at step 907500: 0.140771\n",
      "2022-11-09 02:42:54,174 INFO     Training average positive_sample_loss at step 907600: 0.142134\n",
      "2022-11-09 02:42:54,174 INFO     Training average negative_sample_loss at step 907600: 0.136892\n",
      "2022-11-09 02:42:54,174 INFO     Training average loss at step 907600: 0.139513\n",
      "2022-11-09 02:42:57,273 INFO     Training average positive_sample_loss at step 907700: 0.142260\n",
      "2022-11-09 02:42:57,273 INFO     Training average negative_sample_loss at step 907700: 0.133912\n",
      "2022-11-09 02:42:57,273 INFO     Training average loss at step 907700: 0.138086\n",
      "2022-11-09 02:43:00,375 INFO     Training average positive_sample_loss at step 907800: 0.143569\n",
      "2022-11-09 02:43:00,375 INFO     Training average negative_sample_loss at step 907800: 0.139035\n",
      "2022-11-09 02:43:00,375 INFO     Training average loss at step 907800: 0.141302\n",
      "2022-11-09 02:43:03,482 INFO     Training average positive_sample_loss at step 907900: 0.139901\n",
      "2022-11-09 02:43:03,483 INFO     Training average negative_sample_loss at step 907900: 0.138342\n",
      "2022-11-09 02:43:03,483 INFO     Training average loss at step 907900: 0.139121\n",
      "2022-11-09 02:43:06,586 INFO     Training average positive_sample_loss at step 908000: 0.138641\n",
      "2022-11-09 02:43:06,586 INFO     Training average negative_sample_loss at step 908000: 0.136384\n",
      "2022-11-09 02:43:06,586 INFO     Training average loss at step 908000: 0.137513\n",
      "2022-11-09 02:43:09,694 INFO     Training average positive_sample_loss at step 908100: 0.143904\n",
      "2022-11-09 02:43:09,694 INFO     Training average negative_sample_loss at step 908100: 0.133900\n",
      "2022-11-09 02:43:09,694 INFO     Training average loss at step 908100: 0.138902\n",
      "2022-11-09 02:43:12,796 INFO     Training average positive_sample_loss at step 908200: 0.138937\n",
      "2022-11-09 02:43:12,796 INFO     Training average negative_sample_loss at step 908200: 0.136451\n",
      "2022-11-09 02:43:12,796 INFO     Training average loss at step 908200: 0.137694\n",
      "2022-11-09 02:43:15,890 INFO     Training average positive_sample_loss at step 908300: 0.143048\n",
      "2022-11-09 02:43:15,890 INFO     Training average negative_sample_loss at step 908300: 0.138112\n",
      "2022-11-09 02:43:15,890 INFO     Training average loss at step 908300: 0.140580\n",
      "2022-11-09 02:43:18,989 INFO     Training average positive_sample_loss at step 908400: 0.140098\n",
      "2022-11-09 02:43:18,989 INFO     Training average negative_sample_loss at step 908400: 0.131456\n",
      "2022-11-09 02:43:18,989 INFO     Training average loss at step 908400: 0.135777\n",
      "2022-11-09 02:43:22,090 INFO     Training average positive_sample_loss at step 908500: 0.139527\n",
      "2022-11-09 02:43:22,090 INFO     Training average negative_sample_loss at step 908500: 0.137949\n",
      "2022-11-09 02:43:22,090 INFO     Training average loss at step 908500: 0.138738\n",
      "2022-11-09 02:43:25,197 INFO     Training average positive_sample_loss at step 908600: 0.139891\n",
      "2022-11-09 02:43:25,197 INFO     Training average negative_sample_loss at step 908600: 0.131068\n",
      "2022-11-09 02:43:25,197 INFO     Training average loss at step 908600: 0.135479\n",
      "2022-11-09 02:43:28,310 INFO     Training average positive_sample_loss at step 908700: 0.139750\n",
      "2022-11-09 02:43:28,310 INFO     Training average negative_sample_loss at step 908700: 0.135547\n",
      "2022-11-09 02:43:28,310 INFO     Training average loss at step 908700: 0.137649\n",
      "2022-11-09 02:43:32,255 INFO     Training average positive_sample_loss at step 908800: 0.140227\n",
      "2022-11-09 02:43:32,255 INFO     Training average negative_sample_loss at step 908800: 0.137150\n",
      "2022-11-09 02:43:32,255 INFO     Training average loss at step 908800: 0.138688\n",
      "2022-11-09 02:43:36,586 INFO     Training average positive_sample_loss at step 908900: 0.141909\n",
      "2022-11-09 02:43:36,586 INFO     Training average negative_sample_loss at step 908900: 0.130559\n",
      "2022-11-09 02:43:36,586 INFO     Training average loss at step 908900: 0.136234\n",
      "2022-11-09 02:43:39,697 INFO     Training average positive_sample_loss at step 909000: 0.140883\n",
      "2022-11-09 02:43:39,697 INFO     Training average negative_sample_loss at step 909000: 0.137558\n",
      "2022-11-09 02:43:39,697 INFO     Training average loss at step 909000: 0.139221\n",
      "2022-11-09 02:43:44,377 INFO     Training average positive_sample_loss at step 909100: 0.137648\n",
      "2022-11-09 02:43:44,377 INFO     Training average negative_sample_loss at step 909100: 0.136758\n",
      "2022-11-09 02:43:44,377 INFO     Training average loss at step 909100: 0.137203\n",
      "2022-11-09 02:43:47,490 INFO     Training average positive_sample_loss at step 909200: 0.137904\n",
      "2022-11-09 02:43:47,490 INFO     Training average negative_sample_loss at step 909200: 0.135674\n",
      "2022-11-09 02:43:47,490 INFO     Training average loss at step 909200: 0.136789\n",
      "2022-11-09 02:43:50,589 INFO     Training average positive_sample_loss at step 909300: 0.142062\n",
      "2022-11-09 02:43:50,589 INFO     Training average negative_sample_loss at step 909300: 0.137254\n",
      "2022-11-09 02:43:50,589 INFO     Training average loss at step 909300: 0.139658\n",
      "2022-11-09 02:43:53,691 INFO     Training average positive_sample_loss at step 909400: 0.138547\n",
      "2022-11-09 02:43:53,691 INFO     Training average negative_sample_loss at step 909400: 0.137637\n",
      "2022-11-09 02:43:53,691 INFO     Training average loss at step 909400: 0.138092\n",
      "2022-11-09 02:43:56,809 INFO     Training average positive_sample_loss at step 909500: 0.144401\n",
      "2022-11-09 02:43:56,809 INFO     Training average negative_sample_loss at step 909500: 0.133446\n",
      "2022-11-09 02:43:56,809 INFO     Training average loss at step 909500: 0.138924\n",
      "2022-11-09 02:43:59,924 INFO     Training average positive_sample_loss at step 909600: 0.142755\n",
      "2022-11-09 02:43:59,924 INFO     Training average negative_sample_loss at step 909600: 0.138521\n",
      "2022-11-09 02:43:59,924 INFO     Training average loss at step 909600: 0.140638\n",
      "2022-11-09 02:44:03,035 INFO     Training average positive_sample_loss at step 909700: 0.134309\n",
      "2022-11-09 02:44:03,035 INFO     Training average negative_sample_loss at step 909700: 0.133436\n",
      "2022-11-09 02:44:03,035 INFO     Training average loss at step 909700: 0.133873\n",
      "2022-11-09 02:44:06,135 INFO     Training average positive_sample_loss at step 909800: 0.139449\n",
      "2022-11-09 02:44:06,135 INFO     Training average negative_sample_loss at step 909800: 0.138271\n",
      "2022-11-09 02:44:06,135 INFO     Training average loss at step 909800: 0.138860\n",
      "2022-11-09 02:44:09,243 INFO     Training average positive_sample_loss at step 909900: 0.137414\n",
      "2022-11-09 02:44:09,243 INFO     Training average negative_sample_loss at step 909900: 0.131007\n",
      "2022-11-09 02:44:09,243 INFO     Training average loss at step 909900: 0.134210\n",
      "2022-11-09 02:44:15,152 INFO     Training average positive_sample_loss at step 910000: 0.142561\n",
      "2022-11-09 02:44:15,152 INFO     Training average negative_sample_loss at step 910000: 0.135927\n",
      "2022-11-09 02:44:15,152 INFO     Training average loss at step 910000: 0.139244\n",
      "2022-11-09 02:44:18,265 INFO     Training average positive_sample_loss at step 910100: 0.139841\n",
      "2022-11-09 02:44:18,265 INFO     Training average negative_sample_loss at step 910100: 0.136998\n",
      "2022-11-09 02:44:18,265 INFO     Training average loss at step 910100: 0.138419\n",
      "2022-11-09 02:44:21,371 INFO     Training average positive_sample_loss at step 910200: 0.144069\n",
      "2022-11-09 02:44:21,371 INFO     Training average negative_sample_loss at step 910200: 0.136907\n",
      "2022-11-09 02:44:21,371 INFO     Training average loss at step 910200: 0.140488\n",
      "2022-11-09 02:44:24,484 INFO     Training average positive_sample_loss at step 910300: 0.140989\n",
      "2022-11-09 02:44:24,484 INFO     Training average negative_sample_loss at step 910300: 0.131194\n",
      "2022-11-09 02:44:24,484 INFO     Training average loss at step 910300: 0.136091\n",
      "2022-11-09 02:44:27,594 INFO     Training average positive_sample_loss at step 910400: 0.133914\n",
      "2022-11-09 02:44:27,594 INFO     Training average negative_sample_loss at step 910400: 0.134638\n",
      "2022-11-09 02:44:27,594 INFO     Training average loss at step 910400: 0.134276\n",
      "2022-11-09 02:44:30,702 INFO     Training average positive_sample_loss at step 910500: 0.139330\n",
      "2022-11-09 02:44:30,702 INFO     Training average negative_sample_loss at step 910500: 0.139408\n",
      "2022-11-09 02:44:30,702 INFO     Training average loss at step 910500: 0.139369\n",
      "2022-11-09 02:44:33,812 INFO     Training average positive_sample_loss at step 910600: 0.140400\n",
      "2022-11-09 02:44:33,812 INFO     Training average negative_sample_loss at step 910600: 0.134396\n",
      "2022-11-09 02:44:33,812 INFO     Training average loss at step 910600: 0.137398\n",
      "2022-11-09 02:44:36,929 INFO     Training average positive_sample_loss at step 910700: 0.139226\n",
      "2022-11-09 02:44:36,929 INFO     Training average negative_sample_loss at step 910700: 0.134486\n",
      "2022-11-09 02:44:36,930 INFO     Training average loss at step 910700: 0.136856\n",
      "2022-11-09 02:44:40,036 INFO     Training average positive_sample_loss at step 910800: 0.142168\n",
      "2022-11-09 02:44:40,036 INFO     Training average negative_sample_loss at step 910800: 0.136370\n",
      "2022-11-09 02:44:40,036 INFO     Training average loss at step 910800: 0.139269\n",
      "2022-11-09 02:44:43,146 INFO     Training average positive_sample_loss at step 910900: 0.146116\n",
      "2022-11-09 02:44:43,146 INFO     Training average negative_sample_loss at step 910900: 0.138291\n",
      "2022-11-09 02:44:43,146 INFO     Training average loss at step 910900: 0.142203\n",
      "2022-11-09 02:44:46,253 INFO     Training average positive_sample_loss at step 911000: 0.139650\n",
      "2022-11-09 02:44:46,254 INFO     Training average negative_sample_loss at step 911000: 0.138368\n",
      "2022-11-09 02:44:46,254 INFO     Training average loss at step 911000: 0.139009\n",
      "2022-11-09 02:44:49,363 INFO     Training average positive_sample_loss at step 911100: 0.142217\n",
      "2022-11-09 02:44:49,363 INFO     Training average negative_sample_loss at step 911100: 0.136749\n",
      "2022-11-09 02:44:49,363 INFO     Training average loss at step 911100: 0.139483\n",
      "2022-11-09 02:44:52,473 INFO     Training average positive_sample_loss at step 911200: 0.135458\n",
      "2022-11-09 02:44:52,473 INFO     Training average negative_sample_loss at step 911200: 0.140048\n",
      "2022-11-09 02:44:52,473 INFO     Training average loss at step 911200: 0.137753\n",
      "2022-11-09 02:44:55,596 INFO     Training average positive_sample_loss at step 911300: 0.140347\n",
      "2022-11-09 02:44:55,596 INFO     Training average negative_sample_loss at step 911300: 0.132393\n",
      "2022-11-09 02:44:55,596 INFO     Training average loss at step 911300: 0.136370\n",
      "2022-11-09 02:44:58,713 INFO     Training average positive_sample_loss at step 911400: 0.141912\n",
      "2022-11-09 02:44:58,713 INFO     Training average negative_sample_loss at step 911400: 0.136130\n",
      "2022-11-09 02:44:58,713 INFO     Training average loss at step 911400: 0.139021\n",
      "2022-11-09 02:45:01,828 INFO     Training average positive_sample_loss at step 911500: 0.143242\n",
      "2022-11-09 02:45:01,828 INFO     Training average negative_sample_loss at step 911500: 0.137675\n",
      "2022-11-09 02:45:01,828 INFO     Training average loss at step 911500: 0.140458\n",
      "2022-11-09 02:45:04,940 INFO     Training average positive_sample_loss at step 911600: 0.140864\n",
      "2022-11-09 02:45:04,940 INFO     Training average negative_sample_loss at step 911600: 0.135475\n",
      "2022-11-09 02:45:04,940 INFO     Training average loss at step 911600: 0.138169\n",
      "2022-11-09 02:45:08,061 INFO     Training average positive_sample_loss at step 911700: 0.140708\n",
      "2022-11-09 02:45:08,061 INFO     Training average negative_sample_loss at step 911700: 0.133530\n",
      "2022-11-09 02:45:08,061 INFO     Training average loss at step 911700: 0.137119\n",
      "2022-11-09 02:45:11,178 INFO     Training average positive_sample_loss at step 911800: 0.137301\n",
      "2022-11-09 02:45:11,178 INFO     Training average negative_sample_loss at step 911800: 0.134038\n",
      "2022-11-09 02:45:11,178 INFO     Training average loss at step 911800: 0.135670\n",
      "2022-11-09 02:45:14,293 INFO     Training average positive_sample_loss at step 911900: 0.143517\n",
      "2022-11-09 02:45:14,293 INFO     Training average negative_sample_loss at step 911900: 0.135178\n",
      "2022-11-09 02:45:14,293 INFO     Training average loss at step 911900: 0.139347\n",
      "2022-11-09 02:45:17,391 INFO     Training average positive_sample_loss at step 912000: 0.142775\n",
      "2022-11-09 02:45:17,392 INFO     Training average negative_sample_loss at step 912000: 0.135252\n",
      "2022-11-09 02:45:17,392 INFO     Training average loss at step 912000: 0.139014\n",
      "2022-11-09 02:45:20,498 INFO     Training average positive_sample_loss at step 912100: 0.140957\n",
      "2022-11-09 02:45:20,498 INFO     Training average negative_sample_loss at step 912100: 0.141884\n",
      "2022-11-09 02:45:20,498 INFO     Training average loss at step 912100: 0.141420\n",
      "2022-11-09 02:45:23,600 INFO     Training average positive_sample_loss at step 912200: 0.145870\n",
      "2022-11-09 02:45:23,600 INFO     Training average negative_sample_loss at step 912200: 0.134738\n",
      "2022-11-09 02:45:23,600 INFO     Training average loss at step 912200: 0.140304\n",
      "2022-11-09 02:45:26,707 INFO     Training average positive_sample_loss at step 912300: 0.142047\n",
      "2022-11-09 02:45:26,707 INFO     Training average negative_sample_loss at step 912300: 0.132461\n",
      "2022-11-09 02:45:26,707 INFO     Training average loss at step 912300: 0.137254\n",
      "2022-11-09 02:45:29,809 INFO     Training average positive_sample_loss at step 912400: 0.137965\n",
      "2022-11-09 02:45:29,810 INFO     Training average negative_sample_loss at step 912400: 0.134743\n",
      "2022-11-09 02:45:29,810 INFO     Training average loss at step 912400: 0.136354\n",
      "2022-11-09 02:45:32,907 INFO     Training average positive_sample_loss at step 912500: 0.138347\n",
      "2022-11-09 02:45:32,907 INFO     Training average negative_sample_loss at step 912500: 0.136860\n",
      "2022-11-09 02:45:32,907 INFO     Training average loss at step 912500: 0.137604\n",
      "2022-11-09 02:45:36,010 INFO     Training average positive_sample_loss at step 912600: 0.137777\n",
      "2022-11-09 02:45:36,010 INFO     Training average negative_sample_loss at step 912600: 0.137818\n",
      "2022-11-09 02:45:36,010 INFO     Training average loss at step 912600: 0.137797\n",
      "2022-11-09 02:45:39,119 INFO     Training average positive_sample_loss at step 912700: 0.143196\n",
      "2022-11-09 02:45:39,119 INFO     Training average negative_sample_loss at step 912700: 0.133969\n",
      "2022-11-09 02:45:39,119 INFO     Training average loss at step 912700: 0.138582\n",
      "2022-11-09 02:45:42,210 INFO     Training average positive_sample_loss at step 912800: 0.141198\n",
      "2022-11-09 02:45:42,210 INFO     Training average negative_sample_loss at step 912800: 0.138206\n",
      "2022-11-09 02:45:42,210 INFO     Training average loss at step 912800: 0.139702\n",
      "2022-11-09 02:45:45,316 INFO     Training average positive_sample_loss at step 912900: 0.138498\n",
      "2022-11-09 02:45:45,316 INFO     Training average negative_sample_loss at step 912900: 0.136805\n",
      "2022-11-09 02:45:45,316 INFO     Training average loss at step 912900: 0.137652\n",
      "2022-11-09 02:45:48,417 INFO     Training average positive_sample_loss at step 913000: 0.139797\n",
      "2022-11-09 02:45:48,417 INFO     Training average negative_sample_loss at step 913000: 0.136324\n",
      "2022-11-09 02:45:48,417 INFO     Training average loss at step 913000: 0.138061\n",
      "2022-11-09 02:45:51,514 INFO     Training average positive_sample_loss at step 913100: 0.138269\n",
      "2022-11-09 02:45:51,514 INFO     Training average negative_sample_loss at step 913100: 0.133989\n",
      "2022-11-09 02:45:51,514 INFO     Training average loss at step 913100: 0.136129\n",
      "2022-11-09 02:45:54,619 INFO     Training average positive_sample_loss at step 913200: 0.142765\n",
      "2022-11-09 02:45:54,619 INFO     Training average negative_sample_loss at step 913200: 0.136136\n",
      "2022-11-09 02:45:54,619 INFO     Training average loss at step 913200: 0.139450\n",
      "2022-11-09 02:45:57,719 INFO     Training average positive_sample_loss at step 913300: 0.140743\n",
      "2022-11-09 02:45:57,719 INFO     Training average negative_sample_loss at step 913300: 0.139157\n",
      "2022-11-09 02:45:57,719 INFO     Training average loss at step 913300: 0.139950\n",
      "2022-11-09 02:46:00,820 INFO     Training average positive_sample_loss at step 913400: 0.144511\n",
      "2022-11-09 02:46:00,820 INFO     Training average negative_sample_loss at step 913400: 0.136660\n",
      "2022-11-09 02:46:00,820 INFO     Training average loss at step 913400: 0.140585\n",
      "2022-11-09 02:46:05,430 INFO     Training average positive_sample_loss at step 913500: 0.142861\n",
      "2022-11-09 02:46:05,430 INFO     Training average negative_sample_loss at step 913500: 0.136471\n",
      "2022-11-09 02:46:05,430 INFO     Training average loss at step 913500: 0.139666\n",
      "2022-11-09 02:46:08,541 INFO     Training average positive_sample_loss at step 913600: 0.141877\n",
      "2022-11-09 02:46:08,541 INFO     Training average negative_sample_loss at step 913600: 0.136567\n",
      "2022-11-09 02:46:08,541 INFO     Training average loss at step 913600: 0.139222\n",
      "2022-11-09 02:46:13,206 INFO     Training average positive_sample_loss at step 913700: 0.141981\n",
      "2022-11-09 02:46:13,207 INFO     Training average negative_sample_loss at step 913700: 0.133509\n",
      "2022-11-09 02:46:13,207 INFO     Training average loss at step 913700: 0.137745\n",
      "2022-11-09 02:46:16,320 INFO     Training average positive_sample_loss at step 913800: 0.141244\n",
      "2022-11-09 02:46:16,320 INFO     Training average negative_sample_loss at step 913800: 0.136622\n",
      "2022-11-09 02:46:16,320 INFO     Training average loss at step 913800: 0.138933\n",
      "2022-11-09 02:46:19,423 INFO     Training average positive_sample_loss at step 913900: 0.140500\n",
      "2022-11-09 02:46:19,423 INFO     Training average negative_sample_loss at step 913900: 0.136016\n",
      "2022-11-09 02:46:19,423 INFO     Training average loss at step 913900: 0.138258\n",
      "2022-11-09 02:46:22,530 INFO     Training average positive_sample_loss at step 914000: 0.143005\n",
      "2022-11-09 02:46:22,530 INFO     Training average negative_sample_loss at step 914000: 0.131368\n",
      "2022-11-09 02:46:22,530 INFO     Training average loss at step 914000: 0.137187\n",
      "2022-11-09 02:46:25,639 INFO     Training average positive_sample_loss at step 914100: 0.140218\n",
      "2022-11-09 02:46:25,639 INFO     Training average negative_sample_loss at step 914100: 0.135321\n",
      "2022-11-09 02:46:25,639 INFO     Training average loss at step 914100: 0.137769\n",
      "2022-11-09 02:46:28,748 INFO     Training average positive_sample_loss at step 914200: 0.136791\n",
      "2022-11-09 02:46:28,749 INFO     Training average negative_sample_loss at step 914200: 0.134716\n",
      "2022-11-09 02:46:28,749 INFO     Training average loss at step 914200: 0.135754\n",
      "2022-11-09 02:46:31,865 INFO     Training average positive_sample_loss at step 914300: 0.141099\n",
      "2022-11-09 02:46:31,865 INFO     Training average negative_sample_loss at step 914300: 0.133531\n",
      "2022-11-09 02:46:31,865 INFO     Training average loss at step 914300: 0.137315\n",
      "2022-11-09 02:46:34,975 INFO     Training average positive_sample_loss at step 914400: 0.141520\n",
      "2022-11-09 02:46:34,975 INFO     Training average negative_sample_loss at step 914400: 0.139780\n",
      "2022-11-09 02:46:34,975 INFO     Training average loss at step 914400: 0.140650\n",
      "2022-11-09 02:46:38,098 INFO     Training average positive_sample_loss at step 914500: 0.141619\n",
      "2022-11-09 02:46:38,099 INFO     Training average negative_sample_loss at step 914500: 0.134197\n",
      "2022-11-09 02:46:38,099 INFO     Training average loss at step 914500: 0.137908\n",
      "2022-11-09 02:46:41,214 INFO     Training average positive_sample_loss at step 914600: 0.140696\n",
      "2022-11-09 02:46:41,214 INFO     Training average negative_sample_loss at step 914600: 0.130533\n",
      "2022-11-09 02:46:41,214 INFO     Training average loss at step 914600: 0.135615\n",
      "2022-11-09 02:46:44,321 INFO     Training average positive_sample_loss at step 914700: 0.138526\n",
      "2022-11-09 02:46:44,321 INFO     Training average negative_sample_loss at step 914700: 0.134980\n",
      "2022-11-09 02:46:44,321 INFO     Training average loss at step 914700: 0.136753\n",
      "2022-11-09 02:46:47,409 INFO     Training average positive_sample_loss at step 914800: 0.138540\n",
      "2022-11-09 02:46:47,409 INFO     Training average negative_sample_loss at step 914800: 0.133456\n",
      "2022-11-09 02:46:47,410 INFO     Training average loss at step 914800: 0.135998\n",
      "2022-11-09 02:46:50,513 INFO     Training average positive_sample_loss at step 914900: 0.136775\n",
      "2022-11-09 02:46:50,513 INFO     Training average negative_sample_loss at step 914900: 0.135087\n",
      "2022-11-09 02:46:50,513 INFO     Training average loss at step 914900: 0.135931\n",
      "2022-11-09 02:46:53,626 INFO     Training average positive_sample_loss at step 915000: 0.144585\n",
      "2022-11-09 02:46:53,626 INFO     Training average negative_sample_loss at step 915000: 0.136215\n",
      "2022-11-09 02:46:53,626 INFO     Training average loss at step 915000: 0.140400\n",
      "2022-11-09 02:46:56,736 INFO     Training average positive_sample_loss at step 915100: 0.141923\n",
      "2022-11-09 02:46:56,736 INFO     Training average negative_sample_loss at step 915100: 0.137573\n",
      "2022-11-09 02:46:56,737 INFO     Training average loss at step 915100: 0.139748\n",
      "2022-11-09 02:46:59,831 INFO     Training average positive_sample_loss at step 915200: 0.146969\n",
      "2022-11-09 02:46:59,831 INFO     Training average negative_sample_loss at step 915200: 0.136863\n",
      "2022-11-09 02:46:59,831 INFO     Training average loss at step 915200: 0.141916\n",
      "2022-11-09 02:47:02,923 INFO     Training average positive_sample_loss at step 915300: 0.142309\n",
      "2022-11-09 02:47:02,923 INFO     Training average negative_sample_loss at step 915300: 0.134814\n",
      "2022-11-09 02:47:02,923 INFO     Training average loss at step 915300: 0.138562\n",
      "2022-11-09 02:47:06,041 INFO     Training average positive_sample_loss at step 915400: 0.139333\n",
      "2022-11-09 02:47:06,041 INFO     Training average negative_sample_loss at step 915400: 0.140585\n",
      "2022-11-09 02:47:06,041 INFO     Training average loss at step 915400: 0.139959\n",
      "2022-11-09 02:47:09,158 INFO     Training average positive_sample_loss at step 915500: 0.139977\n",
      "2022-11-09 02:47:09,158 INFO     Training average negative_sample_loss at step 915500: 0.135049\n",
      "2022-11-09 02:47:09,158 INFO     Training average loss at step 915500: 0.137513\n",
      "2022-11-09 02:47:12,269 INFO     Training average positive_sample_loss at step 915600: 0.141510\n",
      "2022-11-09 02:47:12,269 INFO     Training average negative_sample_loss at step 915600: 0.137148\n",
      "2022-11-09 02:47:12,269 INFO     Training average loss at step 915600: 0.139329\n",
      "2022-11-09 02:47:15,373 INFO     Training average positive_sample_loss at step 915700: 0.140641\n",
      "2022-11-09 02:47:15,373 INFO     Training average negative_sample_loss at step 915700: 0.137214\n",
      "2022-11-09 02:47:15,373 INFO     Training average loss at step 915700: 0.138928\n",
      "2022-11-09 02:47:18,472 INFO     Training average positive_sample_loss at step 915800: 0.141302\n",
      "2022-11-09 02:47:18,472 INFO     Training average negative_sample_loss at step 915800: 0.133970\n",
      "2022-11-09 02:47:18,472 INFO     Training average loss at step 915800: 0.137636\n",
      "2022-11-09 02:47:21,573 INFO     Training average positive_sample_loss at step 915900: 0.143355\n",
      "2022-11-09 02:47:21,573 INFO     Training average negative_sample_loss at step 915900: 0.138133\n",
      "2022-11-09 02:47:21,573 INFO     Training average loss at step 915900: 0.140744\n",
      "2022-11-09 02:47:24,683 INFO     Training average positive_sample_loss at step 916000: 0.138723\n",
      "2022-11-09 02:47:24,683 INFO     Training average negative_sample_loss at step 916000: 0.134324\n",
      "2022-11-09 02:47:24,683 INFO     Training average loss at step 916000: 0.136523\n",
      "2022-11-09 02:47:27,785 INFO     Training average positive_sample_loss at step 916100: 0.135200\n",
      "2022-11-09 02:47:27,785 INFO     Training average negative_sample_loss at step 916100: 0.133450\n",
      "2022-11-09 02:47:27,785 INFO     Training average loss at step 916100: 0.134325\n",
      "2022-11-09 02:47:30,898 INFO     Training average positive_sample_loss at step 916200: 0.140412\n",
      "2022-11-09 02:47:30,898 INFO     Training average negative_sample_loss at step 916200: 0.140045\n",
      "2022-11-09 02:47:30,898 INFO     Training average loss at step 916200: 0.140229\n",
      "2022-11-09 02:47:34,005 INFO     Training average positive_sample_loss at step 916300: 0.142477\n",
      "2022-11-09 02:47:34,005 INFO     Training average negative_sample_loss at step 916300: 0.139474\n",
      "2022-11-09 02:47:34,005 INFO     Training average loss at step 916300: 0.140975\n",
      "2022-11-09 02:47:37,108 INFO     Training average positive_sample_loss at step 916400: 0.141848\n",
      "2022-11-09 02:47:37,109 INFO     Training average negative_sample_loss at step 916400: 0.137986\n",
      "2022-11-09 02:47:37,109 INFO     Training average loss at step 916400: 0.139917\n",
      "2022-11-09 02:47:40,222 INFO     Training average positive_sample_loss at step 916500: 0.136909\n",
      "2022-11-09 02:47:40,222 INFO     Training average negative_sample_loss at step 916500: 0.142312\n",
      "2022-11-09 02:47:40,222 INFO     Training average loss at step 916500: 0.139610\n",
      "2022-11-09 02:47:43,325 INFO     Training average positive_sample_loss at step 916600: 0.138413\n",
      "2022-11-09 02:47:43,325 INFO     Training average negative_sample_loss at step 916600: 0.131953\n",
      "2022-11-09 02:47:43,325 INFO     Training average loss at step 916600: 0.135183\n",
      "2022-11-09 02:47:46,426 INFO     Training average positive_sample_loss at step 916700: 0.140253\n",
      "2022-11-09 02:47:46,426 INFO     Training average negative_sample_loss at step 916700: 0.137715\n",
      "2022-11-09 02:47:46,426 INFO     Training average loss at step 916700: 0.138984\n",
      "2022-11-09 02:47:49,523 INFO     Training average positive_sample_loss at step 916800: 0.138958\n",
      "2022-11-09 02:47:49,523 INFO     Training average negative_sample_loss at step 916800: 0.136089\n",
      "2022-11-09 02:47:49,523 INFO     Training average loss at step 916800: 0.137524\n",
      "2022-11-09 02:47:52,629 INFO     Training average positive_sample_loss at step 916900: 0.138181\n",
      "2022-11-09 02:47:52,629 INFO     Training average negative_sample_loss at step 916900: 0.139843\n",
      "2022-11-09 02:47:52,629 INFO     Training average loss at step 916900: 0.139012\n",
      "2022-11-09 02:47:55,751 INFO     Training average positive_sample_loss at step 917000: 0.147023\n",
      "2022-11-09 02:47:55,751 INFO     Training average negative_sample_loss at step 917000: 0.140281\n",
      "2022-11-09 02:47:55,751 INFO     Training average loss at step 917000: 0.143652\n",
      "2022-11-09 02:47:58,854 INFO     Training average positive_sample_loss at step 917100: 0.139171\n",
      "2022-11-09 02:47:58,855 INFO     Training average negative_sample_loss at step 917100: 0.137104\n",
      "2022-11-09 02:47:58,855 INFO     Training average loss at step 917100: 0.138138\n",
      "2022-11-09 02:48:01,958 INFO     Training average positive_sample_loss at step 917200: 0.144321\n",
      "2022-11-09 02:48:01,958 INFO     Training average negative_sample_loss at step 917200: 0.137749\n",
      "2022-11-09 02:48:01,958 INFO     Training average loss at step 917200: 0.141035\n",
      "2022-11-09 02:48:05,055 INFO     Training average positive_sample_loss at step 917300: 0.142573\n",
      "2022-11-09 02:48:05,055 INFO     Training average negative_sample_loss at step 917300: 0.136427\n",
      "2022-11-09 02:48:05,055 INFO     Training average loss at step 917300: 0.139500\n",
      "2022-11-09 02:48:08,160 INFO     Training average positive_sample_loss at step 917400: 0.141227\n",
      "2022-11-09 02:48:08,160 INFO     Training average negative_sample_loss at step 917400: 0.133731\n",
      "2022-11-09 02:48:08,160 INFO     Training average loss at step 917400: 0.137479\n",
      "2022-11-09 02:48:11,275 INFO     Training average positive_sample_loss at step 917500: 0.140968\n",
      "2022-11-09 02:48:11,275 INFO     Training average negative_sample_loss at step 917500: 0.139729\n",
      "2022-11-09 02:48:11,275 INFO     Training average loss at step 917500: 0.140348\n",
      "2022-11-09 02:48:14,404 INFO     Training average positive_sample_loss at step 917600: 0.143527\n",
      "2022-11-09 02:48:14,404 INFO     Training average negative_sample_loss at step 917600: 0.139211\n",
      "2022-11-09 02:48:14,404 INFO     Training average loss at step 917600: 0.141369\n",
      "2022-11-09 02:48:17,502 INFO     Training average positive_sample_loss at step 917700: 0.140712\n",
      "2022-11-09 02:48:17,502 INFO     Training average negative_sample_loss at step 917700: 0.136507\n",
      "2022-11-09 02:48:17,502 INFO     Training average loss at step 917700: 0.138610\n",
      "2022-11-09 02:48:20,611 INFO     Training average positive_sample_loss at step 917800: 0.147012\n",
      "2022-11-09 02:48:20,611 INFO     Training average negative_sample_loss at step 917800: 0.137621\n",
      "2022-11-09 02:48:20,611 INFO     Training average loss at step 917800: 0.142317\n",
      "2022-11-09 02:48:23,719 INFO     Training average positive_sample_loss at step 917900: 0.143363\n",
      "2022-11-09 02:48:23,719 INFO     Training average negative_sample_loss at step 917900: 0.139363\n",
      "2022-11-09 02:48:23,719 INFO     Training average loss at step 917900: 0.141363\n",
      "2022-11-09 02:48:26,832 INFO     Training average positive_sample_loss at step 918000: 0.141890\n",
      "2022-11-09 02:48:26,833 INFO     Training average negative_sample_loss at step 918000: 0.135705\n",
      "2022-11-09 02:48:26,833 INFO     Training average loss at step 918000: 0.138798\n",
      "2022-11-09 02:48:31,381 INFO     Training average positive_sample_loss at step 918100: 0.138935\n",
      "2022-11-09 02:48:31,382 INFO     Training average negative_sample_loss at step 918100: 0.131246\n",
      "2022-11-09 02:48:31,382 INFO     Training average loss at step 918100: 0.135090\n",
      "2022-11-09 02:48:34,502 INFO     Training average positive_sample_loss at step 918200: 0.144411\n",
      "2022-11-09 02:48:34,502 INFO     Training average negative_sample_loss at step 918200: 0.133576\n",
      "2022-11-09 02:48:34,502 INFO     Training average loss at step 918200: 0.138994\n",
      "2022-11-09 02:48:37,627 INFO     Training average positive_sample_loss at step 918300: 0.136681\n",
      "2022-11-09 02:48:37,627 INFO     Training average negative_sample_loss at step 918300: 0.136134\n",
      "2022-11-09 02:48:37,627 INFO     Training average loss at step 918300: 0.136407\n",
      "2022-11-09 02:48:42,259 INFO     Training average positive_sample_loss at step 918400: 0.146637\n",
      "2022-11-09 02:48:42,260 INFO     Training average negative_sample_loss at step 918400: 0.135221\n",
      "2022-11-09 02:48:42,260 INFO     Training average loss at step 918400: 0.140929\n",
      "2022-11-09 02:48:45,377 INFO     Training average positive_sample_loss at step 918500: 0.138185\n",
      "2022-11-09 02:48:45,377 INFO     Training average negative_sample_loss at step 918500: 0.135095\n",
      "2022-11-09 02:48:45,378 INFO     Training average loss at step 918500: 0.136640\n",
      "2022-11-09 02:48:48,491 INFO     Training average positive_sample_loss at step 918600: 0.136916\n",
      "2022-11-09 02:48:48,491 INFO     Training average negative_sample_loss at step 918600: 0.132643\n",
      "2022-11-09 02:48:48,491 INFO     Training average loss at step 918600: 0.134779\n",
      "2022-11-09 02:48:51,626 INFO     Training average positive_sample_loss at step 918700: 0.137346\n",
      "2022-11-09 02:48:51,626 INFO     Training average negative_sample_loss at step 918700: 0.136847\n",
      "2022-11-09 02:48:51,626 INFO     Training average loss at step 918700: 0.137097\n",
      "2022-11-09 02:48:54,757 INFO     Training average positive_sample_loss at step 918800: 0.142477\n",
      "2022-11-09 02:48:54,757 INFO     Training average negative_sample_loss at step 918800: 0.134256\n",
      "2022-11-09 02:48:54,757 INFO     Training average loss at step 918800: 0.138367\n",
      "2022-11-09 02:48:57,881 INFO     Training average positive_sample_loss at step 918900: 0.141852\n",
      "2022-11-09 02:48:57,881 INFO     Training average negative_sample_loss at step 918900: 0.135775\n",
      "2022-11-09 02:48:57,881 INFO     Training average loss at step 918900: 0.138814\n",
      "2022-11-09 02:49:00,984 INFO     Training average positive_sample_loss at step 919000: 0.136736\n",
      "2022-11-09 02:49:00,984 INFO     Training average negative_sample_loss at step 919000: 0.138545\n",
      "2022-11-09 02:49:00,984 INFO     Training average loss at step 919000: 0.137641\n",
      "2022-11-09 02:49:04,086 INFO     Training average positive_sample_loss at step 919100: 0.140467\n",
      "2022-11-09 02:49:04,086 INFO     Training average negative_sample_loss at step 919100: 0.132108\n",
      "2022-11-09 02:49:04,086 INFO     Training average loss at step 919100: 0.136288\n",
      "2022-11-09 02:49:07,197 INFO     Training average positive_sample_loss at step 919200: 0.141815\n",
      "2022-11-09 02:49:07,197 INFO     Training average negative_sample_loss at step 919200: 0.134250\n",
      "2022-11-09 02:49:07,197 INFO     Training average loss at step 919200: 0.138033\n",
      "2022-11-09 02:49:10,312 INFO     Training average positive_sample_loss at step 919300: 0.139788\n",
      "2022-11-09 02:49:10,312 INFO     Training average negative_sample_loss at step 919300: 0.135720\n",
      "2022-11-09 02:49:10,312 INFO     Training average loss at step 919300: 0.137754\n",
      "2022-11-09 02:49:13,417 INFO     Training average positive_sample_loss at step 919400: 0.141192\n",
      "2022-11-09 02:49:13,417 INFO     Training average negative_sample_loss at step 919400: 0.137406\n",
      "2022-11-09 02:49:13,418 INFO     Training average loss at step 919400: 0.139299\n",
      "2022-11-09 02:49:16,519 INFO     Training average positive_sample_loss at step 919500: 0.139787\n",
      "2022-11-09 02:49:16,519 INFO     Training average negative_sample_loss at step 919500: 0.136061\n",
      "2022-11-09 02:49:16,519 INFO     Training average loss at step 919500: 0.137924\n",
      "2022-11-09 02:49:19,630 INFO     Training average positive_sample_loss at step 919600: 0.149550\n",
      "2022-11-09 02:49:19,631 INFO     Training average negative_sample_loss at step 919600: 0.137079\n",
      "2022-11-09 02:49:19,631 INFO     Training average loss at step 919600: 0.143315\n",
      "2022-11-09 02:49:22,740 INFO     Training average positive_sample_loss at step 919700: 0.140153\n",
      "2022-11-09 02:49:22,740 INFO     Training average negative_sample_loss at step 919700: 0.138089\n",
      "2022-11-09 02:49:22,740 INFO     Training average loss at step 919700: 0.139121\n",
      "2022-11-09 02:49:25,859 INFO     Training average positive_sample_loss at step 919800: 0.139656\n",
      "2022-11-09 02:49:25,859 INFO     Training average negative_sample_loss at step 919800: 0.133759\n",
      "2022-11-09 02:49:25,859 INFO     Training average loss at step 919800: 0.136707\n",
      "2022-11-09 02:49:28,976 INFO     Training average positive_sample_loss at step 919900: 0.145731\n",
      "2022-11-09 02:49:28,976 INFO     Training average negative_sample_loss at step 919900: 0.135566\n",
      "2022-11-09 02:49:28,977 INFO     Training average loss at step 919900: 0.140649\n",
      "2022-11-09 02:49:34,948 INFO     Training average positive_sample_loss at step 920000: 0.142302\n",
      "2022-11-09 02:49:34,948 INFO     Training average negative_sample_loss at step 920000: 0.138490\n",
      "2022-11-09 02:49:34,948 INFO     Training average loss at step 920000: 0.140396\n",
      "2022-11-09 02:49:38,062 INFO     Training average positive_sample_loss at step 920100: 0.138749\n",
      "2022-11-09 02:49:38,062 INFO     Training average negative_sample_loss at step 920100: 0.138852\n",
      "2022-11-09 02:49:38,062 INFO     Training average loss at step 920100: 0.138800\n",
      "2022-11-09 02:49:41,177 INFO     Training average positive_sample_loss at step 920200: 0.139525\n",
      "2022-11-09 02:49:41,177 INFO     Training average negative_sample_loss at step 920200: 0.137599\n",
      "2022-11-09 02:49:41,177 INFO     Training average loss at step 920200: 0.138562\n",
      "2022-11-09 02:49:44,276 INFO     Training average positive_sample_loss at step 920300: 0.139556\n",
      "2022-11-09 02:49:44,276 INFO     Training average negative_sample_loss at step 920300: 0.133930\n",
      "2022-11-09 02:49:44,276 INFO     Training average loss at step 920300: 0.136743\n",
      "2022-11-09 02:49:47,377 INFO     Training average positive_sample_loss at step 920400: 0.139075\n",
      "2022-11-09 02:49:47,377 INFO     Training average negative_sample_loss at step 920400: 0.132119\n",
      "2022-11-09 02:49:47,377 INFO     Training average loss at step 920400: 0.135597\n",
      "2022-11-09 02:49:50,487 INFO     Training average positive_sample_loss at step 920500: 0.139857\n",
      "2022-11-09 02:49:50,487 INFO     Training average negative_sample_loss at step 920500: 0.134662\n",
      "2022-11-09 02:49:50,487 INFO     Training average loss at step 920500: 0.137260\n",
      "2022-11-09 02:49:53,591 INFO     Training average positive_sample_loss at step 920600: 0.139084\n",
      "2022-11-09 02:49:53,591 INFO     Training average negative_sample_loss at step 920600: 0.134629\n",
      "2022-11-09 02:49:53,591 INFO     Training average loss at step 920600: 0.136856\n",
      "2022-11-09 02:49:56,695 INFO     Training average positive_sample_loss at step 920700: 0.141578\n",
      "2022-11-09 02:49:56,695 INFO     Training average negative_sample_loss at step 920700: 0.136812\n",
      "2022-11-09 02:49:56,695 INFO     Training average loss at step 920700: 0.139195\n",
      "2022-11-09 02:49:59,796 INFO     Training average positive_sample_loss at step 920800: 0.136558\n",
      "2022-11-09 02:49:59,796 INFO     Training average negative_sample_loss at step 920800: 0.136019\n",
      "2022-11-09 02:49:59,796 INFO     Training average loss at step 920800: 0.136289\n",
      "2022-11-09 02:50:02,899 INFO     Training average positive_sample_loss at step 920900: 0.141080\n",
      "2022-11-09 02:50:02,899 INFO     Training average negative_sample_loss at step 920900: 0.135071\n",
      "2022-11-09 02:50:02,899 INFO     Training average loss at step 920900: 0.138076\n",
      "2022-11-09 02:50:06,012 INFO     Training average positive_sample_loss at step 921000: 0.143122\n",
      "2022-11-09 02:50:06,012 INFO     Training average negative_sample_loss at step 921000: 0.140198\n",
      "2022-11-09 02:50:06,012 INFO     Training average loss at step 921000: 0.141660\n",
      "2022-11-09 02:50:09,131 INFO     Training average positive_sample_loss at step 921100: 0.141244\n",
      "2022-11-09 02:50:09,131 INFO     Training average negative_sample_loss at step 921100: 0.137957\n",
      "2022-11-09 02:50:09,131 INFO     Training average loss at step 921100: 0.139600\n",
      "2022-11-09 02:50:12,254 INFO     Training average positive_sample_loss at step 921200: 0.145946\n",
      "2022-11-09 02:50:12,254 INFO     Training average negative_sample_loss at step 921200: 0.138077\n",
      "2022-11-09 02:50:12,254 INFO     Training average loss at step 921200: 0.142012\n",
      "2022-11-09 02:50:15,369 INFO     Training average positive_sample_loss at step 921300: 0.144091\n",
      "2022-11-09 02:50:15,370 INFO     Training average negative_sample_loss at step 921300: 0.134461\n",
      "2022-11-09 02:50:15,370 INFO     Training average loss at step 921300: 0.139276\n",
      "2022-11-09 02:50:18,469 INFO     Training average positive_sample_loss at step 921400: 0.144732\n",
      "2022-11-09 02:50:18,469 INFO     Training average negative_sample_loss at step 921400: 0.136995\n",
      "2022-11-09 02:50:18,469 INFO     Training average loss at step 921400: 0.140863\n",
      "2022-11-09 02:50:21,573 INFO     Training average positive_sample_loss at step 921500: 0.144706\n",
      "2022-11-09 02:50:21,573 INFO     Training average negative_sample_loss at step 921500: 0.137883\n",
      "2022-11-09 02:50:21,574 INFO     Training average loss at step 921500: 0.141294\n",
      "2022-11-09 02:50:24,686 INFO     Training average positive_sample_loss at step 921600: 0.138899\n",
      "2022-11-09 02:50:24,686 INFO     Training average negative_sample_loss at step 921600: 0.136819\n",
      "2022-11-09 02:50:24,686 INFO     Training average loss at step 921600: 0.137859\n",
      "2022-11-09 02:50:27,796 INFO     Training average positive_sample_loss at step 921700: 0.141033\n",
      "2022-11-09 02:50:27,796 INFO     Training average negative_sample_loss at step 921700: 0.132551\n",
      "2022-11-09 02:50:27,796 INFO     Training average loss at step 921700: 0.136792\n",
      "2022-11-09 02:50:30,906 INFO     Training average positive_sample_loss at step 921800: 0.138782\n",
      "2022-11-09 02:50:30,906 INFO     Training average negative_sample_loss at step 921800: 0.135105\n",
      "2022-11-09 02:50:30,906 INFO     Training average loss at step 921800: 0.136943\n",
      "2022-11-09 02:50:34,008 INFO     Training average positive_sample_loss at step 921900: 0.140615\n",
      "2022-11-09 02:50:34,008 INFO     Training average negative_sample_loss at step 921900: 0.138436\n",
      "2022-11-09 02:50:34,008 INFO     Training average loss at step 921900: 0.139525\n",
      "2022-11-09 02:50:37,120 INFO     Training average positive_sample_loss at step 922000: 0.143345\n",
      "2022-11-09 02:50:37,120 INFO     Training average negative_sample_loss at step 922000: 0.137636\n",
      "2022-11-09 02:50:37,120 INFO     Training average loss at step 922000: 0.140491\n",
      "2022-11-09 02:50:40,236 INFO     Training average positive_sample_loss at step 922100: 0.138278\n",
      "2022-11-09 02:50:40,236 INFO     Training average negative_sample_loss at step 922100: 0.136696\n",
      "2022-11-09 02:50:40,236 INFO     Training average loss at step 922100: 0.137487\n",
      "2022-11-09 02:50:43,342 INFO     Training average positive_sample_loss at step 922200: 0.139035\n",
      "2022-11-09 02:50:43,342 INFO     Training average negative_sample_loss at step 922200: 0.137503\n",
      "2022-11-09 02:50:43,342 INFO     Training average loss at step 922200: 0.138269\n",
      "2022-11-09 02:50:46,445 INFO     Training average positive_sample_loss at step 922300: 0.139967\n",
      "2022-11-09 02:50:46,445 INFO     Training average negative_sample_loss at step 922300: 0.137823\n",
      "2022-11-09 02:50:46,445 INFO     Training average loss at step 922300: 0.138895\n",
      "2022-11-09 02:50:49,549 INFO     Training average positive_sample_loss at step 922400: 0.142881\n",
      "2022-11-09 02:50:49,549 INFO     Training average negative_sample_loss at step 922400: 0.133007\n",
      "2022-11-09 02:50:49,549 INFO     Training average loss at step 922400: 0.137944\n",
      "2022-11-09 02:50:52,659 INFO     Training average positive_sample_loss at step 922500: 0.142143\n",
      "2022-11-09 02:50:52,659 INFO     Training average negative_sample_loss at step 922500: 0.133556\n",
      "2022-11-09 02:50:52,659 INFO     Training average loss at step 922500: 0.137850\n",
      "2022-11-09 02:50:55,766 INFO     Training average positive_sample_loss at step 922600: 0.138456\n",
      "2022-11-09 02:50:55,766 INFO     Training average negative_sample_loss at step 922600: 0.132017\n",
      "2022-11-09 02:50:55,766 INFO     Training average loss at step 922600: 0.135236\n",
      "2022-11-09 02:50:58,872 INFO     Training average positive_sample_loss at step 922700: 0.137937\n",
      "2022-11-09 02:50:58,872 INFO     Training average negative_sample_loss at step 922700: 0.139207\n",
      "2022-11-09 02:50:58,872 INFO     Training average loss at step 922700: 0.138572\n",
      "2022-11-09 02:51:03,405 INFO     Training average positive_sample_loss at step 922800: 0.145975\n",
      "2022-11-09 02:51:03,405 INFO     Training average negative_sample_loss at step 922800: 0.136824\n",
      "2022-11-09 02:51:03,405 INFO     Training average loss at step 922800: 0.141399\n",
      "2022-11-09 02:51:06,505 INFO     Training average positive_sample_loss at step 922900: 0.144250\n",
      "2022-11-09 02:51:06,505 INFO     Training average negative_sample_loss at step 922900: 0.137560\n",
      "2022-11-09 02:51:06,505 INFO     Training average loss at step 922900: 0.140905\n",
      "2022-11-09 02:51:09,615 INFO     Training average positive_sample_loss at step 923000: 0.138253\n",
      "2022-11-09 02:51:09,615 INFO     Training average negative_sample_loss at step 923000: 0.140063\n",
      "2022-11-09 02:51:09,615 INFO     Training average loss at step 923000: 0.139158\n",
      "2022-11-09 02:51:14,261 INFO     Training average positive_sample_loss at step 923100: 0.140184\n",
      "2022-11-09 02:51:14,261 INFO     Training average negative_sample_loss at step 923100: 0.134997\n",
      "2022-11-09 02:51:14,261 INFO     Training average loss at step 923100: 0.137590\n",
      "2022-11-09 02:51:17,388 INFO     Training average positive_sample_loss at step 923200: 0.146050\n",
      "2022-11-09 02:51:17,388 INFO     Training average negative_sample_loss at step 923200: 0.139522\n",
      "2022-11-09 02:51:17,388 INFO     Training average loss at step 923200: 0.142786\n",
      "2022-11-09 02:51:20,508 INFO     Training average positive_sample_loss at step 923300: 0.137865\n",
      "2022-11-09 02:51:20,508 INFO     Training average negative_sample_loss at step 923300: 0.136537\n",
      "2022-11-09 02:51:20,508 INFO     Training average loss at step 923300: 0.137201\n",
      "2022-11-09 02:51:23,634 INFO     Training average positive_sample_loss at step 923400: 0.137164\n",
      "2022-11-09 02:51:23,634 INFO     Training average negative_sample_loss at step 923400: 0.134892\n",
      "2022-11-09 02:51:23,634 INFO     Training average loss at step 923400: 0.136028\n",
      "2022-11-09 02:51:26,739 INFO     Training average positive_sample_loss at step 923500: 0.139410\n",
      "2022-11-09 02:51:26,739 INFO     Training average negative_sample_loss at step 923500: 0.140792\n",
      "2022-11-09 02:51:26,739 INFO     Training average loss at step 923500: 0.140101\n",
      "2022-11-09 02:51:29,846 INFO     Training average positive_sample_loss at step 923600: 0.142066\n",
      "2022-11-09 02:51:29,846 INFO     Training average negative_sample_loss at step 923600: 0.134772\n",
      "2022-11-09 02:51:29,846 INFO     Training average loss at step 923600: 0.138419\n",
      "2022-11-09 02:51:32,964 INFO     Training average positive_sample_loss at step 923700: 0.138939\n",
      "2022-11-09 02:51:32,964 INFO     Training average negative_sample_loss at step 923700: 0.135388\n",
      "2022-11-09 02:51:32,964 INFO     Training average loss at step 923700: 0.137164\n",
      "2022-11-09 02:51:36,090 INFO     Training average positive_sample_loss at step 923800: 0.141497\n",
      "2022-11-09 02:51:36,090 INFO     Training average negative_sample_loss at step 923800: 0.135279\n",
      "2022-11-09 02:51:36,090 INFO     Training average loss at step 923800: 0.138388\n",
      "2022-11-09 02:51:39,211 INFO     Training average positive_sample_loss at step 923900: 0.138227\n",
      "2022-11-09 02:51:39,211 INFO     Training average negative_sample_loss at step 923900: 0.134699\n",
      "2022-11-09 02:51:39,211 INFO     Training average loss at step 923900: 0.136463\n",
      "2022-11-09 02:51:42,339 INFO     Training average positive_sample_loss at step 924000: 0.142040\n",
      "2022-11-09 02:51:42,339 INFO     Training average negative_sample_loss at step 924000: 0.133972\n",
      "2022-11-09 02:51:42,339 INFO     Training average loss at step 924000: 0.138006\n",
      "2022-11-09 02:51:45,461 INFO     Training average positive_sample_loss at step 924100: 0.140660\n",
      "2022-11-09 02:51:45,461 INFO     Training average negative_sample_loss at step 924100: 0.132907\n",
      "2022-11-09 02:51:45,461 INFO     Training average loss at step 924100: 0.136784\n",
      "2022-11-09 02:51:48,575 INFO     Training average positive_sample_loss at step 924200: 0.140504\n",
      "2022-11-09 02:51:48,576 INFO     Training average negative_sample_loss at step 924200: 0.137951\n",
      "2022-11-09 02:51:48,576 INFO     Training average loss at step 924200: 0.139227\n",
      "2022-11-09 02:51:51,692 INFO     Training average positive_sample_loss at step 924300: 0.137135\n",
      "2022-11-09 02:51:51,692 INFO     Training average negative_sample_loss at step 924300: 0.132093\n",
      "2022-11-09 02:51:51,692 INFO     Training average loss at step 924300: 0.134614\n",
      "2022-11-09 02:51:54,820 INFO     Training average positive_sample_loss at step 924400: 0.146454\n",
      "2022-11-09 02:51:54,820 INFO     Training average negative_sample_loss at step 924400: 0.135303\n",
      "2022-11-09 02:51:54,820 INFO     Training average loss at step 924400: 0.140879\n",
      "2022-11-09 02:51:57,924 INFO     Training average positive_sample_loss at step 924500: 0.139517\n",
      "2022-11-09 02:51:57,924 INFO     Training average negative_sample_loss at step 924500: 0.133555\n",
      "2022-11-09 02:51:57,924 INFO     Training average loss at step 924500: 0.136536\n",
      "2022-11-09 02:52:01,017 INFO     Training average positive_sample_loss at step 924600: 0.141555\n",
      "2022-11-09 02:52:01,017 INFO     Training average negative_sample_loss at step 924600: 0.138246\n",
      "2022-11-09 02:52:01,017 INFO     Training average loss at step 924600: 0.139901\n",
      "2022-11-09 02:52:04,135 INFO     Training average positive_sample_loss at step 924700: 0.137902\n",
      "2022-11-09 02:52:04,135 INFO     Training average negative_sample_loss at step 924700: 0.132759\n",
      "2022-11-09 02:52:04,135 INFO     Training average loss at step 924700: 0.135330\n",
      "2022-11-09 02:52:07,253 INFO     Training average positive_sample_loss at step 924800: 0.137457\n",
      "2022-11-09 02:52:07,253 INFO     Training average negative_sample_loss at step 924800: 0.138482\n",
      "2022-11-09 02:52:07,253 INFO     Training average loss at step 924800: 0.137969\n",
      "2022-11-09 02:52:10,384 INFO     Training average positive_sample_loss at step 924900: 0.139380\n",
      "2022-11-09 02:52:10,384 INFO     Training average negative_sample_loss at step 924900: 0.136627\n",
      "2022-11-09 02:52:10,384 INFO     Training average loss at step 924900: 0.138004\n",
      "2022-11-09 02:52:13,512 INFO     Training average positive_sample_loss at step 925000: 0.141311\n",
      "2022-11-09 02:52:13,512 INFO     Training average negative_sample_loss at step 925000: 0.135377\n",
      "2022-11-09 02:52:13,512 INFO     Training average loss at step 925000: 0.138344\n",
      "2022-11-09 02:52:16,638 INFO     Training average positive_sample_loss at step 925100: 0.140493\n",
      "2022-11-09 02:52:16,638 INFO     Training average negative_sample_loss at step 925100: 0.134609\n",
      "2022-11-09 02:52:16,638 INFO     Training average loss at step 925100: 0.137551\n",
      "2022-11-09 02:52:19,747 INFO     Training average positive_sample_loss at step 925200: 0.143300\n",
      "2022-11-09 02:52:19,747 INFO     Training average negative_sample_loss at step 925200: 0.133214\n",
      "2022-11-09 02:52:19,747 INFO     Training average loss at step 925200: 0.138257\n",
      "2022-11-09 02:52:22,858 INFO     Training average positive_sample_loss at step 925300: 0.138424\n",
      "2022-11-09 02:52:22,858 INFO     Training average negative_sample_loss at step 925300: 0.137618\n",
      "2022-11-09 02:52:22,858 INFO     Training average loss at step 925300: 0.138021\n",
      "2022-11-09 02:52:25,968 INFO     Training average positive_sample_loss at step 925400: 0.140568\n",
      "2022-11-09 02:52:25,968 INFO     Training average negative_sample_loss at step 925400: 0.137080\n",
      "2022-11-09 02:52:25,968 INFO     Training average loss at step 925400: 0.138824\n",
      "2022-11-09 02:52:29,074 INFO     Training average positive_sample_loss at step 925500: 0.139050\n",
      "2022-11-09 02:52:29,074 INFO     Training average negative_sample_loss at step 925500: 0.135479\n",
      "2022-11-09 02:52:29,074 INFO     Training average loss at step 925500: 0.137264\n",
      "2022-11-09 02:52:32,190 INFO     Training average positive_sample_loss at step 925600: 0.142486\n",
      "2022-11-09 02:52:32,190 INFO     Training average negative_sample_loss at step 925600: 0.138097\n",
      "2022-11-09 02:52:32,190 INFO     Training average loss at step 925600: 0.140292\n",
      "2022-11-09 02:52:35,308 INFO     Training average positive_sample_loss at step 925700: 0.139356\n",
      "2022-11-09 02:52:35,308 INFO     Training average negative_sample_loss at step 925700: 0.132196\n",
      "2022-11-09 02:52:35,308 INFO     Training average loss at step 925700: 0.135776\n",
      "2022-11-09 02:52:38,418 INFO     Training average positive_sample_loss at step 925800: 0.140976\n",
      "2022-11-09 02:52:38,419 INFO     Training average negative_sample_loss at step 925800: 0.134316\n",
      "2022-11-09 02:52:38,419 INFO     Training average loss at step 925800: 0.137646\n",
      "2022-11-09 02:52:41,535 INFO     Training average positive_sample_loss at step 925900: 0.147586\n",
      "2022-11-09 02:52:41,535 INFO     Training average negative_sample_loss at step 925900: 0.136092\n",
      "2022-11-09 02:52:41,535 INFO     Training average loss at step 925900: 0.141839\n",
      "2022-11-09 02:52:44,629 INFO     Training average positive_sample_loss at step 926000: 0.140758\n",
      "2022-11-09 02:52:44,629 INFO     Training average negative_sample_loss at step 926000: 0.138170\n",
      "2022-11-09 02:52:44,629 INFO     Training average loss at step 926000: 0.139464\n",
      "2022-11-09 02:52:47,720 INFO     Training average positive_sample_loss at step 926100: 0.139458\n",
      "2022-11-09 02:52:47,720 INFO     Training average negative_sample_loss at step 926100: 0.139705\n",
      "2022-11-09 02:52:47,720 INFO     Training average loss at step 926100: 0.139581\n",
      "2022-11-09 02:52:50,838 INFO     Training average positive_sample_loss at step 926200: 0.142502\n",
      "2022-11-09 02:52:50,839 INFO     Training average negative_sample_loss at step 926200: 0.138575\n",
      "2022-11-09 02:52:50,839 INFO     Training average loss at step 926200: 0.140538\n",
      "2022-11-09 02:52:53,957 INFO     Training average positive_sample_loss at step 926300: 0.138364\n",
      "2022-11-09 02:52:53,957 INFO     Training average negative_sample_loss at step 926300: 0.132325\n",
      "2022-11-09 02:52:53,957 INFO     Training average loss at step 926300: 0.135344\n",
      "2022-11-09 02:52:57,080 INFO     Training average positive_sample_loss at step 926400: 0.141574\n",
      "2022-11-09 02:52:57,080 INFO     Training average negative_sample_loss at step 926400: 0.135625\n",
      "2022-11-09 02:52:57,080 INFO     Training average loss at step 926400: 0.138600\n",
      "2022-11-09 02:53:00,206 INFO     Training average positive_sample_loss at step 926500: 0.138218\n",
      "2022-11-09 02:53:00,206 INFO     Training average negative_sample_loss at step 926500: 0.135868\n",
      "2022-11-09 02:53:00,206 INFO     Training average loss at step 926500: 0.137043\n",
      "2022-11-09 02:53:03,314 INFO     Training average positive_sample_loss at step 926600: 0.140902\n",
      "2022-11-09 02:53:03,315 INFO     Training average negative_sample_loss at step 926600: 0.136466\n",
      "2022-11-09 02:53:03,315 INFO     Training average loss at step 926600: 0.138684\n",
      "2022-11-09 02:53:06,425 INFO     Training average positive_sample_loss at step 926700: 0.145047\n",
      "2022-11-09 02:53:06,425 INFO     Training average negative_sample_loss at step 926700: 0.133205\n",
      "2022-11-09 02:53:06,425 INFO     Training average loss at step 926700: 0.139126\n",
      "2022-11-09 02:53:09,538 INFO     Training average positive_sample_loss at step 926800: 0.139562\n",
      "2022-11-09 02:53:09,538 INFO     Training average negative_sample_loss at step 926800: 0.133200\n",
      "2022-11-09 02:53:09,538 INFO     Training average loss at step 926800: 0.136381\n",
      "2022-11-09 02:53:12,653 INFO     Training average positive_sample_loss at step 926900: 0.139776\n",
      "2022-11-09 02:53:12,653 INFO     Training average negative_sample_loss at step 926900: 0.137006\n",
      "2022-11-09 02:53:12,654 INFO     Training average loss at step 926900: 0.138391\n",
      "2022-11-09 02:53:15,759 INFO     Training average positive_sample_loss at step 927000: 0.146729\n",
      "2022-11-09 02:53:15,760 INFO     Training average negative_sample_loss at step 927000: 0.135521\n",
      "2022-11-09 02:53:15,760 INFO     Training average loss at step 927000: 0.141125\n",
      "2022-11-09 02:53:18,875 INFO     Training average positive_sample_loss at step 927100: 0.139770\n",
      "2022-11-09 02:53:18,875 INFO     Training average negative_sample_loss at step 927100: 0.138053\n",
      "2022-11-09 02:53:18,875 INFO     Training average loss at step 927100: 0.138911\n",
      "2022-11-09 02:53:22,003 INFO     Training average positive_sample_loss at step 927200: 0.140054\n",
      "2022-11-09 02:53:22,003 INFO     Training average negative_sample_loss at step 927200: 0.136602\n",
      "2022-11-09 02:53:22,003 INFO     Training average loss at step 927200: 0.138328\n",
      "2022-11-09 02:53:25,114 INFO     Training average positive_sample_loss at step 927300: 0.137029\n",
      "2022-11-09 02:53:25,114 INFO     Training average negative_sample_loss at step 927300: 0.138626\n",
      "2022-11-09 02:53:25,114 INFO     Training average loss at step 927300: 0.137827\n",
      "2022-11-09 02:53:28,239 INFO     Training average positive_sample_loss at step 927400: 0.140714\n",
      "2022-11-09 02:53:28,239 INFO     Training average negative_sample_loss at step 927400: 0.131255\n",
      "2022-11-09 02:53:28,239 INFO     Training average loss at step 927400: 0.135985\n",
      "2022-11-09 02:53:32,803 INFO     Training average positive_sample_loss at step 927500: 0.143048\n",
      "2022-11-09 02:53:32,803 INFO     Training average negative_sample_loss at step 927500: 0.128863\n",
      "2022-11-09 02:53:32,803 INFO     Training average loss at step 927500: 0.135955\n",
      "2022-11-09 02:53:35,909 INFO     Training average positive_sample_loss at step 927600: 0.139172\n",
      "2022-11-09 02:53:35,909 INFO     Training average negative_sample_loss at step 927600: 0.135789\n",
      "2022-11-09 02:53:35,909 INFO     Training average loss at step 927600: 0.137480\n",
      "2022-11-09 02:53:39,015 INFO     Training average positive_sample_loss at step 927700: 0.144833\n",
      "2022-11-09 02:53:39,015 INFO     Training average negative_sample_loss at step 927700: 0.130499\n",
      "2022-11-09 02:53:39,015 INFO     Training average loss at step 927700: 0.137666\n",
      "2022-11-09 02:53:43,639 INFO     Training average positive_sample_loss at step 927800: 0.140307\n",
      "2022-11-09 02:53:43,639 INFO     Training average negative_sample_loss at step 927800: 0.137404\n",
      "2022-11-09 02:53:43,639 INFO     Training average loss at step 927800: 0.138856\n",
      "2022-11-09 02:53:46,746 INFO     Training average positive_sample_loss at step 927900: 0.138142\n",
      "2022-11-09 02:53:46,746 INFO     Training average negative_sample_loss at step 927900: 0.133557\n",
      "2022-11-09 02:53:46,746 INFO     Training average loss at step 927900: 0.135849\n",
      "2022-11-09 02:53:49,865 INFO     Training average positive_sample_loss at step 928000: 0.135815\n",
      "2022-11-09 02:53:49,865 INFO     Training average negative_sample_loss at step 928000: 0.131790\n",
      "2022-11-09 02:53:49,865 INFO     Training average loss at step 928000: 0.133803\n",
      "2022-11-09 02:53:52,975 INFO     Training average positive_sample_loss at step 928100: 0.140820\n",
      "2022-11-09 02:53:52,975 INFO     Training average negative_sample_loss at step 928100: 0.137772\n",
      "2022-11-09 02:53:52,976 INFO     Training average loss at step 928100: 0.139296\n",
      "2022-11-09 02:53:56,096 INFO     Training average positive_sample_loss at step 928200: 0.146421\n",
      "2022-11-09 02:53:56,096 INFO     Training average negative_sample_loss at step 928200: 0.131592\n",
      "2022-11-09 02:53:56,096 INFO     Training average loss at step 928200: 0.139006\n",
      "2022-11-09 02:53:59,195 INFO     Training average positive_sample_loss at step 928300: 0.144868\n",
      "2022-11-09 02:53:59,195 INFO     Training average negative_sample_loss at step 928300: 0.134506\n",
      "2022-11-09 02:53:59,195 INFO     Training average loss at step 928300: 0.139687\n",
      "2022-11-09 02:54:02,306 INFO     Training average positive_sample_loss at step 928400: 0.141498\n",
      "2022-11-09 02:54:02,306 INFO     Training average negative_sample_loss at step 928400: 0.134475\n",
      "2022-11-09 02:54:02,306 INFO     Training average loss at step 928400: 0.137987\n",
      "2022-11-09 02:54:05,433 INFO     Training average positive_sample_loss at step 928500: 0.143118\n",
      "2022-11-09 02:54:05,433 INFO     Training average negative_sample_loss at step 928500: 0.133055\n",
      "2022-11-09 02:54:05,433 INFO     Training average loss at step 928500: 0.138086\n",
      "2022-11-09 02:54:08,550 INFO     Training average positive_sample_loss at step 928600: 0.142818\n",
      "2022-11-09 02:54:08,550 INFO     Training average negative_sample_loss at step 928600: 0.135631\n",
      "2022-11-09 02:54:08,550 INFO     Training average loss at step 928600: 0.139225\n",
      "2022-11-09 02:54:11,654 INFO     Training average positive_sample_loss at step 928700: 0.137571\n",
      "2022-11-09 02:54:11,654 INFO     Training average negative_sample_loss at step 928700: 0.129769\n",
      "2022-11-09 02:54:11,654 INFO     Training average loss at step 928700: 0.133670\n",
      "2022-11-09 02:54:14,755 INFO     Training average positive_sample_loss at step 928800: 0.144085\n",
      "2022-11-09 02:54:14,755 INFO     Training average negative_sample_loss at step 928800: 0.136867\n",
      "2022-11-09 02:54:14,755 INFO     Training average loss at step 928800: 0.140476\n",
      "2022-11-09 02:54:17,857 INFO     Training average positive_sample_loss at step 928900: 0.142668\n",
      "2022-11-09 02:54:17,857 INFO     Training average negative_sample_loss at step 928900: 0.138316\n",
      "2022-11-09 02:54:17,857 INFO     Training average loss at step 928900: 0.140492\n",
      "2022-11-09 02:54:20,957 INFO     Training average positive_sample_loss at step 929000: 0.140328\n",
      "2022-11-09 02:54:20,957 INFO     Training average negative_sample_loss at step 929000: 0.133635\n",
      "2022-11-09 02:54:20,957 INFO     Training average loss at step 929000: 0.136982\n",
      "2022-11-09 02:54:24,066 INFO     Training average positive_sample_loss at step 929100: 0.142364\n",
      "2022-11-09 02:54:24,066 INFO     Training average negative_sample_loss at step 929100: 0.136624\n",
      "2022-11-09 02:54:24,066 INFO     Training average loss at step 929100: 0.139494\n",
      "2022-11-09 02:54:27,167 INFO     Training average positive_sample_loss at step 929200: 0.141674\n",
      "2022-11-09 02:54:27,167 INFO     Training average negative_sample_loss at step 929200: 0.133742\n",
      "2022-11-09 02:54:27,167 INFO     Training average loss at step 929200: 0.137708\n",
      "2022-11-09 02:54:30,289 INFO     Training average positive_sample_loss at step 929300: 0.140208\n",
      "2022-11-09 02:54:30,289 INFO     Training average negative_sample_loss at step 929300: 0.134373\n",
      "2022-11-09 02:54:30,289 INFO     Training average loss at step 929300: 0.137291\n",
      "2022-11-09 02:54:33,398 INFO     Training average positive_sample_loss at step 929400: 0.138235\n",
      "2022-11-09 02:54:33,399 INFO     Training average negative_sample_loss at step 929400: 0.135464\n",
      "2022-11-09 02:54:33,399 INFO     Training average loss at step 929400: 0.136849\n",
      "2022-11-09 02:54:36,498 INFO     Training average positive_sample_loss at step 929500: 0.142634\n",
      "2022-11-09 02:54:36,498 INFO     Training average negative_sample_loss at step 929500: 0.137825\n",
      "2022-11-09 02:54:36,498 INFO     Training average loss at step 929500: 0.140230\n",
      "2022-11-09 02:54:39,622 INFO     Training average positive_sample_loss at step 929600: 0.148734\n",
      "2022-11-09 02:54:39,622 INFO     Training average negative_sample_loss at step 929600: 0.137397\n",
      "2022-11-09 02:54:39,622 INFO     Training average loss at step 929600: 0.143065\n",
      "2022-11-09 02:54:42,745 INFO     Training average positive_sample_loss at step 929700: 0.142644\n",
      "2022-11-09 02:54:42,745 INFO     Training average negative_sample_loss at step 929700: 0.134837\n",
      "2022-11-09 02:54:42,745 INFO     Training average loss at step 929700: 0.138740\n",
      "2022-11-09 02:54:45,860 INFO     Training average positive_sample_loss at step 929800: 0.137715\n",
      "2022-11-09 02:54:45,860 INFO     Training average negative_sample_loss at step 929800: 0.135664\n",
      "2022-11-09 02:54:45,860 INFO     Training average loss at step 929800: 0.136689\n",
      "2022-11-09 02:54:48,986 INFO     Training average positive_sample_loss at step 929900: 0.145855\n",
      "2022-11-09 02:54:48,986 INFO     Training average negative_sample_loss at step 929900: 0.134342\n",
      "2022-11-09 02:54:48,986 INFO     Training average loss at step 929900: 0.140099\n",
      "2022-11-09 02:54:54,970 INFO     Training average positive_sample_loss at step 930000: 0.140979\n",
      "2022-11-09 02:54:54,970 INFO     Training average negative_sample_loss at step 930000: 0.136716\n",
      "2022-11-09 02:54:54,970 INFO     Training average loss at step 930000: 0.138847\n",
      "2022-11-09 02:54:58,095 INFO     Training average positive_sample_loss at step 930100: 0.135401\n",
      "2022-11-09 02:54:58,095 INFO     Training average negative_sample_loss at step 930100: 0.135537\n",
      "2022-11-09 02:54:58,095 INFO     Training average loss at step 930100: 0.135469\n",
      "2022-11-09 02:55:01,214 INFO     Training average positive_sample_loss at step 930200: 0.140330\n",
      "2022-11-09 02:55:01,214 INFO     Training average negative_sample_loss at step 930200: 0.141195\n",
      "2022-11-09 02:55:01,214 INFO     Training average loss at step 930200: 0.140762\n",
      "2022-11-09 02:55:04,298 INFO     Training average positive_sample_loss at step 930300: 0.141242\n",
      "2022-11-09 02:55:04,298 INFO     Training average negative_sample_loss at step 930300: 0.133181\n",
      "2022-11-09 02:55:04,298 INFO     Training average loss at step 930300: 0.137212\n",
      "2022-11-09 02:55:07,381 INFO     Training average positive_sample_loss at step 930400: 0.137615\n",
      "2022-11-09 02:55:07,381 INFO     Training average negative_sample_loss at step 930400: 0.139104\n",
      "2022-11-09 02:55:07,381 INFO     Training average loss at step 930400: 0.138360\n",
      "2022-11-09 02:55:10,467 INFO     Training average positive_sample_loss at step 930500: 0.139834\n",
      "2022-11-09 02:55:10,468 INFO     Training average negative_sample_loss at step 930500: 0.137030\n",
      "2022-11-09 02:55:10,468 INFO     Training average loss at step 930500: 0.138432\n",
      "2022-11-09 02:55:13,565 INFO     Training average positive_sample_loss at step 930600: 0.141934\n",
      "2022-11-09 02:55:13,565 INFO     Training average negative_sample_loss at step 930600: 0.136514\n",
      "2022-11-09 02:55:13,565 INFO     Training average loss at step 930600: 0.139224\n",
      "2022-11-09 02:55:16,682 INFO     Training average positive_sample_loss at step 930700: 0.140894\n",
      "2022-11-09 02:55:16,682 INFO     Training average negative_sample_loss at step 930700: 0.135240\n",
      "2022-11-09 02:55:16,682 INFO     Training average loss at step 930700: 0.138067\n",
      "2022-11-09 02:55:19,792 INFO     Training average positive_sample_loss at step 930800: 0.142714\n",
      "2022-11-09 02:55:19,792 INFO     Training average negative_sample_loss at step 930800: 0.138201\n",
      "2022-11-09 02:55:19,792 INFO     Training average loss at step 930800: 0.140457\n",
      "2022-11-09 02:55:22,900 INFO     Training average positive_sample_loss at step 930900: 0.142219\n",
      "2022-11-09 02:55:22,900 INFO     Training average negative_sample_loss at step 930900: 0.135022\n",
      "2022-11-09 02:55:22,900 INFO     Training average loss at step 930900: 0.138621\n",
      "2022-11-09 02:55:26,008 INFO     Training average positive_sample_loss at step 931000: 0.140385\n",
      "2022-11-09 02:55:26,008 INFO     Training average negative_sample_loss at step 931000: 0.134218\n",
      "2022-11-09 02:55:26,008 INFO     Training average loss at step 931000: 0.137301\n",
      "2022-11-09 02:55:29,131 INFO     Training average positive_sample_loss at step 931100: 0.145729\n",
      "2022-11-09 02:55:29,131 INFO     Training average negative_sample_loss at step 931100: 0.134264\n",
      "2022-11-09 02:55:29,131 INFO     Training average loss at step 931100: 0.139996\n",
      "2022-11-09 02:55:32,237 INFO     Training average positive_sample_loss at step 931200: 0.145426\n",
      "2022-11-09 02:55:32,238 INFO     Training average negative_sample_loss at step 931200: 0.136748\n",
      "2022-11-09 02:55:32,238 INFO     Training average loss at step 931200: 0.141087\n",
      "2022-11-09 02:55:35,347 INFO     Training average positive_sample_loss at step 931300: 0.141611\n",
      "2022-11-09 02:55:35,347 INFO     Training average negative_sample_loss at step 931300: 0.134418\n",
      "2022-11-09 02:55:35,347 INFO     Training average loss at step 931300: 0.138015\n",
      "2022-11-09 02:55:38,466 INFO     Training average positive_sample_loss at step 931400: 0.142192\n",
      "2022-11-09 02:55:38,466 INFO     Training average negative_sample_loss at step 931400: 0.135578\n",
      "2022-11-09 02:55:38,466 INFO     Training average loss at step 931400: 0.138885\n",
      "2022-11-09 02:55:41,573 INFO     Training average positive_sample_loss at step 931500: 0.141126\n",
      "2022-11-09 02:55:41,573 INFO     Training average negative_sample_loss at step 931500: 0.134464\n",
      "2022-11-09 02:55:41,573 INFO     Training average loss at step 931500: 0.137795\n",
      "2022-11-09 02:55:44,665 INFO     Training average positive_sample_loss at step 931600: 0.137316\n",
      "2022-11-09 02:55:44,665 INFO     Training average negative_sample_loss at step 931600: 0.141225\n",
      "2022-11-09 02:55:44,665 INFO     Training average loss at step 931600: 0.139271\n",
      "2022-11-09 02:55:47,748 INFO     Training average positive_sample_loss at step 931700: 0.138377\n",
      "2022-11-09 02:55:47,748 INFO     Training average negative_sample_loss at step 931700: 0.129474\n",
      "2022-11-09 02:55:47,748 INFO     Training average loss at step 931700: 0.133925\n",
      "2022-11-09 02:55:50,836 INFO     Training average positive_sample_loss at step 931800: 0.143382\n",
      "2022-11-09 02:55:50,836 INFO     Training average negative_sample_loss at step 931800: 0.136730\n",
      "2022-11-09 02:55:50,836 INFO     Training average loss at step 931800: 0.140056\n",
      "2022-11-09 02:55:53,916 INFO     Training average positive_sample_loss at step 931900: 0.141124\n",
      "2022-11-09 02:55:53,916 INFO     Training average negative_sample_loss at step 931900: 0.135792\n",
      "2022-11-09 02:55:53,916 INFO     Training average loss at step 931900: 0.138458\n",
      "2022-11-09 02:55:58,137 INFO     Training average positive_sample_loss at step 932000: 0.137711\n",
      "2022-11-09 02:55:58,137 INFO     Training average negative_sample_loss at step 932000: 0.138759\n",
      "2022-11-09 02:55:58,137 INFO     Training average loss at step 932000: 0.138235\n",
      "2022-11-09 02:56:01,246 INFO     Training average positive_sample_loss at step 932100: 0.139155\n",
      "2022-11-09 02:56:01,246 INFO     Training average negative_sample_loss at step 932100: 0.134091\n",
      "2022-11-09 02:56:01,246 INFO     Training average loss at step 932100: 0.136623\n",
      "2022-11-09 02:56:05,319 INFO     Training average positive_sample_loss at step 932200: 0.142273\n",
      "2022-11-09 02:56:05,319 INFO     Training average negative_sample_loss at step 932200: 0.133505\n",
      "2022-11-09 02:56:05,319 INFO     Training average loss at step 932200: 0.137889\n",
      "2022-11-09 02:56:08,395 INFO     Training average positive_sample_loss at step 932300: 0.142976\n",
      "2022-11-09 02:56:08,395 INFO     Training average negative_sample_loss at step 932300: 0.133169\n",
      "2022-11-09 02:56:08,395 INFO     Training average loss at step 932300: 0.138073\n",
      "2022-11-09 02:56:11,472 INFO     Training average positive_sample_loss at step 932400: 0.142551\n",
      "2022-11-09 02:56:11,472 INFO     Training average negative_sample_loss at step 932400: 0.137054\n",
      "2022-11-09 02:56:11,472 INFO     Training average loss at step 932400: 0.139802\n",
      "2022-11-09 02:56:16,130 INFO     Training average positive_sample_loss at step 932500: 0.135347\n",
      "2022-11-09 02:56:16,130 INFO     Training average negative_sample_loss at step 932500: 0.138621\n",
      "2022-11-09 02:56:16,130 INFO     Training average loss at step 932500: 0.136984\n",
      "2022-11-09 02:56:19,216 INFO     Training average positive_sample_loss at step 932600: 0.141473\n",
      "2022-11-09 02:56:19,216 INFO     Training average negative_sample_loss at step 932600: 0.140584\n",
      "2022-11-09 02:56:19,216 INFO     Training average loss at step 932600: 0.141029\n",
      "2022-11-09 02:56:22,302 INFO     Training average positive_sample_loss at step 932700: 0.145292\n",
      "2022-11-09 02:56:22,302 INFO     Training average negative_sample_loss at step 932700: 0.137277\n",
      "2022-11-09 02:56:22,302 INFO     Training average loss at step 932700: 0.141284\n",
      "2022-11-09 02:56:25,390 INFO     Training average positive_sample_loss at step 932800: 0.139543\n",
      "2022-11-09 02:56:25,390 INFO     Training average negative_sample_loss at step 932800: 0.135065\n",
      "2022-11-09 02:56:25,390 INFO     Training average loss at step 932800: 0.137304\n",
      "2022-11-09 02:56:28,473 INFO     Training average positive_sample_loss at step 932900: 0.142527\n",
      "2022-11-09 02:56:28,473 INFO     Training average negative_sample_loss at step 932900: 0.136196\n",
      "2022-11-09 02:56:28,473 INFO     Training average loss at step 932900: 0.139362\n",
      "2022-11-09 02:56:31,556 INFO     Training average positive_sample_loss at step 933000: 0.140727\n",
      "2022-11-09 02:56:31,557 INFO     Training average negative_sample_loss at step 933000: 0.131262\n",
      "2022-11-09 02:56:31,557 INFO     Training average loss at step 933000: 0.135994\n",
      "2022-11-09 02:56:34,663 INFO     Training average positive_sample_loss at step 933100: 0.141797\n",
      "2022-11-09 02:56:34,663 INFO     Training average negative_sample_loss at step 933100: 0.131388\n",
      "2022-11-09 02:56:34,664 INFO     Training average loss at step 933100: 0.136593\n",
      "2022-11-09 02:56:37,765 INFO     Training average positive_sample_loss at step 933200: 0.138838\n",
      "2022-11-09 02:56:37,765 INFO     Training average negative_sample_loss at step 933200: 0.134264\n",
      "2022-11-09 02:56:37,765 INFO     Training average loss at step 933200: 0.136551\n",
      "2022-11-09 02:56:40,863 INFO     Training average positive_sample_loss at step 933300: 0.141931\n",
      "2022-11-09 02:56:40,863 INFO     Training average negative_sample_loss at step 933300: 0.134809\n",
      "2022-11-09 02:56:40,863 INFO     Training average loss at step 933300: 0.138370\n",
      "2022-11-09 02:56:43,951 INFO     Training average positive_sample_loss at step 933400: 0.143585\n",
      "2022-11-09 02:56:43,951 INFO     Training average negative_sample_loss at step 933400: 0.138379\n",
      "2022-11-09 02:56:43,951 INFO     Training average loss at step 933400: 0.140982\n",
      "2022-11-09 02:56:47,035 INFO     Training average positive_sample_loss at step 933500: 0.141335\n",
      "2022-11-09 02:56:47,035 INFO     Training average negative_sample_loss at step 933500: 0.135553\n",
      "2022-11-09 02:56:47,035 INFO     Training average loss at step 933500: 0.138444\n",
      "2022-11-09 02:56:50,130 INFO     Training average positive_sample_loss at step 933600: 0.139794\n",
      "2022-11-09 02:56:50,130 INFO     Training average negative_sample_loss at step 933600: 0.137928\n",
      "2022-11-09 02:56:50,130 INFO     Training average loss at step 933600: 0.138861\n",
      "2022-11-09 02:56:53,214 INFO     Training average positive_sample_loss at step 933700: 0.141540\n",
      "2022-11-09 02:56:53,215 INFO     Training average negative_sample_loss at step 933700: 0.136182\n",
      "2022-11-09 02:56:53,215 INFO     Training average loss at step 933700: 0.138861\n",
      "2022-11-09 02:56:56,317 INFO     Training average positive_sample_loss at step 933800: 0.146083\n",
      "2022-11-09 02:56:56,317 INFO     Training average negative_sample_loss at step 933800: 0.135969\n",
      "2022-11-09 02:56:56,317 INFO     Training average loss at step 933800: 0.141026\n",
      "2022-11-09 02:56:59,414 INFO     Training average positive_sample_loss at step 933900: 0.143739\n",
      "2022-11-09 02:56:59,414 INFO     Training average negative_sample_loss at step 933900: 0.135441\n",
      "2022-11-09 02:56:59,414 INFO     Training average loss at step 933900: 0.139590\n",
      "2022-11-09 02:57:02,508 INFO     Training average positive_sample_loss at step 934000: 0.140813\n",
      "2022-11-09 02:57:02,508 INFO     Training average negative_sample_loss at step 934000: 0.137464\n",
      "2022-11-09 02:57:02,508 INFO     Training average loss at step 934000: 0.139139\n",
      "2022-11-09 02:57:05,598 INFO     Training average positive_sample_loss at step 934100: 0.137489\n",
      "2022-11-09 02:57:05,598 INFO     Training average negative_sample_loss at step 934100: 0.135021\n",
      "2022-11-09 02:57:05,598 INFO     Training average loss at step 934100: 0.136255\n",
      "2022-11-09 02:57:08,682 INFO     Training average positive_sample_loss at step 934200: 0.142257\n",
      "2022-11-09 02:57:08,683 INFO     Training average negative_sample_loss at step 934200: 0.133465\n",
      "2022-11-09 02:57:08,683 INFO     Training average loss at step 934200: 0.137861\n",
      "2022-11-09 02:57:11,757 INFO     Training average positive_sample_loss at step 934300: 0.144205\n",
      "2022-11-09 02:57:11,757 INFO     Training average negative_sample_loss at step 934300: 0.136218\n",
      "2022-11-09 02:57:11,757 INFO     Training average loss at step 934300: 0.140212\n",
      "2022-11-09 02:57:14,838 INFO     Training average positive_sample_loss at step 934400: 0.136114\n",
      "2022-11-09 02:57:14,839 INFO     Training average negative_sample_loss at step 934400: 0.136173\n",
      "2022-11-09 02:57:14,839 INFO     Training average loss at step 934400: 0.136143\n",
      "2022-11-09 02:57:17,929 INFO     Training average positive_sample_loss at step 934500: 0.145863\n",
      "2022-11-09 02:57:17,929 INFO     Training average negative_sample_loss at step 934500: 0.133941\n",
      "2022-11-09 02:57:17,929 INFO     Training average loss at step 934500: 0.139902\n",
      "2022-11-09 02:57:21,035 INFO     Training average positive_sample_loss at step 934600: 0.143925\n",
      "2022-11-09 02:57:21,035 INFO     Training average negative_sample_loss at step 934600: 0.135395\n",
      "2022-11-09 02:57:21,035 INFO     Training average loss at step 934600: 0.139660\n",
      "2022-11-09 02:57:24,123 INFO     Training average positive_sample_loss at step 934700: 0.143518\n",
      "2022-11-09 02:57:24,124 INFO     Training average negative_sample_loss at step 934700: 0.137279\n",
      "2022-11-09 02:57:24,124 INFO     Training average loss at step 934700: 0.140398\n",
      "2022-11-09 02:57:27,227 INFO     Training average positive_sample_loss at step 934800: 0.137244\n",
      "2022-11-09 02:57:27,227 INFO     Training average negative_sample_loss at step 934800: 0.134710\n",
      "2022-11-09 02:57:27,227 INFO     Training average loss at step 934800: 0.135977\n",
      "2022-11-09 02:57:30,329 INFO     Training average positive_sample_loss at step 934900: 0.142752\n",
      "2022-11-09 02:57:30,329 INFO     Training average negative_sample_loss at step 934900: 0.141362\n",
      "2022-11-09 02:57:30,329 INFO     Training average loss at step 934900: 0.142057\n",
      "2022-11-09 02:57:33,430 INFO     Training average positive_sample_loss at step 935000: 0.142169\n",
      "2022-11-09 02:57:33,430 INFO     Training average negative_sample_loss at step 935000: 0.137002\n",
      "2022-11-09 02:57:33,430 INFO     Training average loss at step 935000: 0.139585\n",
      "2022-11-09 02:57:36,509 INFO     Training average positive_sample_loss at step 935100: 0.135480\n",
      "2022-11-09 02:57:36,509 INFO     Training average negative_sample_loss at step 935100: 0.135171\n",
      "2022-11-09 02:57:36,509 INFO     Training average loss at step 935100: 0.135325\n",
      "2022-11-09 02:57:39,598 INFO     Training average positive_sample_loss at step 935200: 0.140040\n",
      "2022-11-09 02:57:39,598 INFO     Training average negative_sample_loss at step 935200: 0.137033\n",
      "2022-11-09 02:57:39,598 INFO     Training average loss at step 935200: 0.138536\n",
      "2022-11-09 02:57:42,693 INFO     Training average positive_sample_loss at step 935300: 0.140960\n",
      "2022-11-09 02:57:42,693 INFO     Training average negative_sample_loss at step 935300: 0.137246\n",
      "2022-11-09 02:57:42,693 INFO     Training average loss at step 935300: 0.139103\n",
      "2022-11-09 02:57:45,782 INFO     Training average positive_sample_loss at step 935400: 0.144955\n",
      "2022-11-09 02:57:45,782 INFO     Training average negative_sample_loss at step 935400: 0.135620\n",
      "2022-11-09 02:57:45,782 INFO     Training average loss at step 935400: 0.140288\n",
      "2022-11-09 02:57:48,868 INFO     Training average positive_sample_loss at step 935500: 0.144141\n",
      "2022-11-09 02:57:48,869 INFO     Training average negative_sample_loss at step 935500: 0.135373\n",
      "2022-11-09 02:57:48,869 INFO     Training average loss at step 935500: 0.139757\n",
      "2022-11-09 02:57:51,957 INFO     Training average positive_sample_loss at step 935600: 0.144609\n",
      "2022-11-09 02:57:51,957 INFO     Training average negative_sample_loss at step 935600: 0.131701\n",
      "2022-11-09 02:57:51,957 INFO     Training average loss at step 935600: 0.138155\n",
      "2022-11-09 02:57:55,053 INFO     Training average positive_sample_loss at step 935700: 0.141221\n",
      "2022-11-09 02:57:55,053 INFO     Training average negative_sample_loss at step 935700: 0.130126\n",
      "2022-11-09 02:57:55,053 INFO     Training average loss at step 935700: 0.135674\n",
      "2022-11-09 02:57:58,140 INFO     Training average positive_sample_loss at step 935800: 0.140213\n",
      "2022-11-09 02:57:58,140 INFO     Training average negative_sample_loss at step 935800: 0.135179\n",
      "2022-11-09 02:57:58,140 INFO     Training average loss at step 935800: 0.137696\n",
      "2022-11-09 02:58:01,244 INFO     Training average positive_sample_loss at step 935900: 0.144167\n",
      "2022-11-09 02:58:01,244 INFO     Training average negative_sample_loss at step 935900: 0.138856\n",
      "2022-11-09 02:58:01,244 INFO     Training average loss at step 935900: 0.141512\n",
      "2022-11-09 02:58:04,333 INFO     Training average positive_sample_loss at step 936000: 0.142082\n",
      "2022-11-09 02:58:04,333 INFO     Training average negative_sample_loss at step 936000: 0.140192\n",
      "2022-11-09 02:58:04,333 INFO     Training average loss at step 936000: 0.141137\n",
      "2022-11-09 02:58:07,426 INFO     Training average positive_sample_loss at step 936100: 0.139085\n",
      "2022-11-09 02:58:07,426 INFO     Training average negative_sample_loss at step 936100: 0.139265\n",
      "2022-11-09 02:58:07,426 INFO     Training average loss at step 936100: 0.139175\n",
      "2022-11-09 02:58:10,505 INFO     Training average positive_sample_loss at step 936200: 0.138038\n",
      "2022-11-09 02:58:10,506 INFO     Training average negative_sample_loss at step 936200: 0.135439\n",
      "2022-11-09 02:58:10,506 INFO     Training average loss at step 936200: 0.136739\n",
      "2022-11-09 02:58:13,595 INFO     Training average positive_sample_loss at step 936300: 0.144255\n",
      "2022-11-09 02:58:13,595 INFO     Training average negative_sample_loss at step 936300: 0.137890\n",
      "2022-11-09 02:58:13,595 INFO     Training average loss at step 936300: 0.141072\n",
      "2022-11-09 02:58:16,685 INFO     Training average positive_sample_loss at step 936400: 0.144524\n",
      "2022-11-09 02:58:16,685 INFO     Training average negative_sample_loss at step 936400: 0.134224\n",
      "2022-11-09 02:58:16,685 INFO     Training average loss at step 936400: 0.139374\n",
      "2022-11-09 02:58:19,774 INFO     Training average positive_sample_loss at step 936500: 0.134642\n",
      "2022-11-09 02:58:19,774 INFO     Training average negative_sample_loss at step 936500: 0.136086\n",
      "2022-11-09 02:58:19,774 INFO     Training average loss at step 936500: 0.135364\n",
      "2022-11-09 02:58:24,017 INFO     Training average positive_sample_loss at step 936600: 0.139494\n",
      "2022-11-09 02:58:24,017 INFO     Training average negative_sample_loss at step 936600: 0.140230\n",
      "2022-11-09 02:58:24,017 INFO     Training average loss at step 936600: 0.139862\n",
      "2022-11-09 02:58:28,072 INFO     Training average positive_sample_loss at step 936700: 0.138939\n",
      "2022-11-09 02:58:28,072 INFO     Training average negative_sample_loss at step 936700: 0.137392\n",
      "2022-11-09 02:58:28,072 INFO     Training average loss at step 936700: 0.138166\n",
      "2022-11-09 02:58:31,158 INFO     Training average positive_sample_loss at step 936800: 0.142930\n",
      "2022-11-09 02:58:31,158 INFO     Training average negative_sample_loss at step 936800: 0.135072\n",
      "2022-11-09 02:58:31,158 INFO     Training average loss at step 936800: 0.139001\n",
      "2022-11-09 02:58:34,247 INFO     Training average positive_sample_loss at step 936900: 0.141428\n",
      "2022-11-09 02:58:34,247 INFO     Training average negative_sample_loss at step 936900: 0.137475\n",
      "2022-11-09 02:58:34,247 INFO     Training average loss at step 936900: 0.139451\n",
      "2022-11-09 02:58:37,327 INFO     Training average positive_sample_loss at step 937000: 0.143806\n",
      "2022-11-09 02:58:37,327 INFO     Training average negative_sample_loss at step 937000: 0.138754\n",
      "2022-11-09 02:58:37,327 INFO     Training average loss at step 937000: 0.141280\n",
      "2022-11-09 02:58:40,407 INFO     Training average positive_sample_loss at step 937100: 0.135232\n",
      "2022-11-09 02:58:40,407 INFO     Training average negative_sample_loss at step 937100: 0.133588\n",
      "2022-11-09 02:58:40,407 INFO     Training average loss at step 937100: 0.134410\n",
      "2022-11-09 02:58:45,038 INFO     Training average positive_sample_loss at step 937200: 0.138129\n",
      "2022-11-09 02:58:45,038 INFO     Training average negative_sample_loss at step 937200: 0.135848\n",
      "2022-11-09 02:58:45,038 INFO     Training average loss at step 937200: 0.136988\n",
      "2022-11-09 02:58:48,123 INFO     Training average positive_sample_loss at step 937300: 0.143446\n",
      "2022-11-09 02:58:48,123 INFO     Training average negative_sample_loss at step 937300: 0.136463\n",
      "2022-11-09 02:58:48,123 INFO     Training average loss at step 937300: 0.139954\n",
      "2022-11-09 02:58:51,210 INFO     Training average positive_sample_loss at step 937400: 0.137935\n",
      "2022-11-09 02:58:51,210 INFO     Training average negative_sample_loss at step 937400: 0.133261\n",
      "2022-11-09 02:58:51,210 INFO     Training average loss at step 937400: 0.135598\n",
      "2022-11-09 02:58:54,292 INFO     Training average positive_sample_loss at step 937500: 0.143187\n",
      "2022-11-09 02:58:54,293 INFO     Training average negative_sample_loss at step 937500: 0.134894\n",
      "2022-11-09 02:58:54,293 INFO     Training average loss at step 937500: 0.139041\n",
      "2022-11-09 02:58:57,377 INFO     Training average positive_sample_loss at step 937600: 0.142923\n",
      "2022-11-09 02:58:57,377 INFO     Training average negative_sample_loss at step 937600: 0.136516\n",
      "2022-11-09 02:58:57,377 INFO     Training average loss at step 937600: 0.139720\n",
      "2022-11-09 02:59:00,487 INFO     Training average positive_sample_loss at step 937700: 0.142595\n",
      "2022-11-09 02:59:00,487 INFO     Training average negative_sample_loss at step 937700: 0.132392\n",
      "2022-11-09 02:59:00,487 INFO     Training average loss at step 937700: 0.137493\n",
      "2022-11-09 02:59:03,567 INFO     Training average positive_sample_loss at step 937800: 0.140863\n",
      "2022-11-09 02:59:03,567 INFO     Training average negative_sample_loss at step 937800: 0.134465\n",
      "2022-11-09 02:59:03,567 INFO     Training average loss at step 937800: 0.137664\n",
      "2022-11-09 02:59:06,654 INFO     Training average positive_sample_loss at step 937900: 0.144651\n",
      "2022-11-09 02:59:06,654 INFO     Training average negative_sample_loss at step 937900: 0.133922\n",
      "2022-11-09 02:59:06,654 INFO     Training average loss at step 937900: 0.139286\n",
      "2022-11-09 02:59:09,739 INFO     Training average positive_sample_loss at step 938000: 0.137837\n",
      "2022-11-09 02:59:09,739 INFO     Training average negative_sample_loss at step 938000: 0.137577\n",
      "2022-11-09 02:59:09,739 INFO     Training average loss at step 938000: 0.137707\n",
      "2022-11-09 02:59:12,818 INFO     Training average positive_sample_loss at step 938100: 0.142040\n",
      "2022-11-09 02:59:12,818 INFO     Training average negative_sample_loss at step 938100: 0.140697\n",
      "2022-11-09 02:59:12,818 INFO     Training average loss at step 938100: 0.141369\n",
      "2022-11-09 02:59:15,908 INFO     Training average positive_sample_loss at step 938200: 0.141357\n",
      "2022-11-09 02:59:15,908 INFO     Training average negative_sample_loss at step 938200: 0.136882\n",
      "2022-11-09 02:59:15,909 INFO     Training average loss at step 938200: 0.139120\n",
      "2022-11-09 02:59:18,993 INFO     Training average positive_sample_loss at step 938300: 0.141927\n",
      "2022-11-09 02:59:18,993 INFO     Training average negative_sample_loss at step 938300: 0.136932\n",
      "2022-11-09 02:59:18,994 INFO     Training average loss at step 938300: 0.139430\n",
      "2022-11-09 02:59:22,080 INFO     Training average positive_sample_loss at step 938400: 0.138165\n",
      "2022-11-09 02:59:22,080 INFO     Training average negative_sample_loss at step 938400: 0.134043\n",
      "2022-11-09 02:59:22,080 INFO     Training average loss at step 938400: 0.136104\n",
      "2022-11-09 02:59:25,152 INFO     Training average positive_sample_loss at step 938500: 0.143966\n",
      "2022-11-09 02:59:25,152 INFO     Training average negative_sample_loss at step 938500: 0.139100\n",
      "2022-11-09 02:59:25,152 INFO     Training average loss at step 938500: 0.141533\n",
      "2022-11-09 02:59:28,235 INFO     Training average positive_sample_loss at step 938600: 0.139800\n",
      "2022-11-09 02:59:28,235 INFO     Training average negative_sample_loss at step 938600: 0.137892\n",
      "2022-11-09 02:59:28,235 INFO     Training average loss at step 938600: 0.138846\n",
      "2022-11-09 02:59:31,327 INFO     Training average positive_sample_loss at step 938700: 0.142841\n",
      "2022-11-09 02:59:31,327 INFO     Training average negative_sample_loss at step 938700: 0.133587\n",
      "2022-11-09 02:59:31,327 INFO     Training average loss at step 938700: 0.138214\n",
      "2022-11-09 02:59:34,412 INFO     Training average positive_sample_loss at step 938800: 0.141554\n",
      "2022-11-09 02:59:34,413 INFO     Training average negative_sample_loss at step 938800: 0.138394\n",
      "2022-11-09 02:59:34,413 INFO     Training average loss at step 938800: 0.139974\n",
      "2022-11-09 02:59:37,500 INFO     Training average positive_sample_loss at step 938900: 0.137690\n",
      "2022-11-09 02:59:37,500 INFO     Training average negative_sample_loss at step 938900: 0.134822\n",
      "2022-11-09 02:59:37,500 INFO     Training average loss at step 938900: 0.136256\n",
      "2022-11-09 02:59:40,594 INFO     Training average positive_sample_loss at step 939000: 0.139658\n",
      "2022-11-09 02:59:40,594 INFO     Training average negative_sample_loss at step 939000: 0.133345\n",
      "2022-11-09 02:59:40,594 INFO     Training average loss at step 939000: 0.136501\n",
      "2022-11-09 02:59:43,694 INFO     Training average positive_sample_loss at step 939100: 0.143174\n",
      "2022-11-09 02:59:43,694 INFO     Training average negative_sample_loss at step 939100: 0.137635\n",
      "2022-11-09 02:59:43,694 INFO     Training average loss at step 939100: 0.140404\n",
      "2022-11-09 02:59:46,797 INFO     Training average positive_sample_loss at step 939200: 0.138520\n",
      "2022-11-09 02:59:46,797 INFO     Training average negative_sample_loss at step 939200: 0.136912\n",
      "2022-11-09 02:59:46,797 INFO     Training average loss at step 939200: 0.137716\n",
      "2022-11-09 02:59:49,890 INFO     Training average positive_sample_loss at step 939300: 0.144262\n",
      "2022-11-09 02:59:49,891 INFO     Training average negative_sample_loss at step 939300: 0.134279\n",
      "2022-11-09 02:59:49,891 INFO     Training average loss at step 939300: 0.139271\n",
      "2022-11-09 02:59:53,000 INFO     Training average positive_sample_loss at step 939400: 0.138991\n",
      "2022-11-09 02:59:53,000 INFO     Training average negative_sample_loss at step 939400: 0.138158\n",
      "2022-11-09 02:59:53,001 INFO     Training average loss at step 939400: 0.138575\n",
      "2022-11-09 02:59:56,110 INFO     Training average positive_sample_loss at step 939500: 0.143497\n",
      "2022-11-09 02:59:56,110 INFO     Training average negative_sample_loss at step 939500: 0.136525\n",
      "2022-11-09 02:59:56,110 INFO     Training average loss at step 939500: 0.140011\n",
      "2022-11-09 02:59:59,201 INFO     Training average positive_sample_loss at step 939600: 0.140421\n",
      "2022-11-09 02:59:59,201 INFO     Training average negative_sample_loss at step 939600: 0.133463\n",
      "2022-11-09 02:59:59,201 INFO     Training average loss at step 939600: 0.136942\n",
      "2022-11-09 03:00:02,293 INFO     Training average positive_sample_loss at step 939700: 0.147718\n",
      "2022-11-09 03:00:02,293 INFO     Training average negative_sample_loss at step 939700: 0.137429\n",
      "2022-11-09 03:00:02,293 INFO     Training average loss at step 939700: 0.142573\n",
      "2022-11-09 03:00:05,381 INFO     Training average positive_sample_loss at step 939800: 0.135374\n",
      "2022-11-09 03:00:05,381 INFO     Training average negative_sample_loss at step 939800: 0.134591\n",
      "2022-11-09 03:00:05,381 INFO     Training average loss at step 939800: 0.134983\n",
      "2022-11-09 03:00:08,465 INFO     Training average positive_sample_loss at step 939900: 0.136992\n",
      "2022-11-09 03:00:08,465 INFO     Training average negative_sample_loss at step 939900: 0.133468\n",
      "2022-11-09 03:00:08,465 INFO     Training average loss at step 939900: 0.135230\n",
      "2022-11-09 03:00:14,425 INFO     Training average positive_sample_loss at step 940000: 0.142182\n",
      "2022-11-09 03:00:14,425 INFO     Training average negative_sample_loss at step 940000: 0.137397\n",
      "2022-11-09 03:00:14,425 INFO     Training average loss at step 940000: 0.139790\n",
      "2022-11-09 03:00:17,526 INFO     Training average positive_sample_loss at step 940100: 0.140490\n",
      "2022-11-09 03:00:17,526 INFO     Training average negative_sample_loss at step 940100: 0.132918\n",
      "2022-11-09 03:00:17,526 INFO     Training average loss at step 940100: 0.136704\n",
      "2022-11-09 03:00:20,631 INFO     Training average positive_sample_loss at step 940200: 0.141742\n",
      "2022-11-09 03:00:20,632 INFO     Training average negative_sample_loss at step 940200: 0.137670\n",
      "2022-11-09 03:00:20,632 INFO     Training average loss at step 940200: 0.139706\n",
      "2022-11-09 03:00:23,721 INFO     Training average positive_sample_loss at step 940300: 0.142238\n",
      "2022-11-09 03:00:23,721 INFO     Training average negative_sample_loss at step 940300: 0.136667\n",
      "2022-11-09 03:00:23,721 INFO     Training average loss at step 940300: 0.139452\n",
      "2022-11-09 03:00:26,825 INFO     Training average positive_sample_loss at step 940400: 0.140139\n",
      "2022-11-09 03:00:26,826 INFO     Training average negative_sample_loss at step 940400: 0.137132\n",
      "2022-11-09 03:00:26,826 INFO     Training average loss at step 940400: 0.138636\n",
      "2022-11-09 03:00:29,932 INFO     Training average positive_sample_loss at step 940500: 0.142829\n",
      "2022-11-09 03:00:29,932 INFO     Training average negative_sample_loss at step 940500: 0.141960\n",
      "2022-11-09 03:00:29,932 INFO     Training average loss at step 940500: 0.142394\n",
      "2022-11-09 03:00:33,046 INFO     Training average positive_sample_loss at step 940600: 0.141000\n",
      "2022-11-09 03:00:33,046 INFO     Training average negative_sample_loss at step 940600: 0.132696\n",
      "2022-11-09 03:00:33,046 INFO     Training average loss at step 940600: 0.136848\n",
      "2022-11-09 03:00:36,140 INFO     Training average positive_sample_loss at step 940700: 0.142326\n",
      "2022-11-09 03:00:36,140 INFO     Training average negative_sample_loss at step 940700: 0.134770\n",
      "2022-11-09 03:00:36,140 INFO     Training average loss at step 940700: 0.138548\n",
      "2022-11-09 03:00:39,236 INFO     Training average positive_sample_loss at step 940800: 0.141787\n",
      "2022-11-09 03:00:39,236 INFO     Training average negative_sample_loss at step 940800: 0.133908\n",
      "2022-11-09 03:00:39,236 INFO     Training average loss at step 940800: 0.137847\n",
      "2022-11-09 03:00:42,343 INFO     Training average positive_sample_loss at step 940900: 0.141515\n",
      "2022-11-09 03:00:42,343 INFO     Training average negative_sample_loss at step 940900: 0.136235\n",
      "2022-11-09 03:00:42,343 INFO     Training average loss at step 940900: 0.138875\n",
      "2022-11-09 03:00:45,432 INFO     Training average positive_sample_loss at step 941000: 0.141168\n",
      "2022-11-09 03:00:45,432 INFO     Training average negative_sample_loss at step 941000: 0.137969\n",
      "2022-11-09 03:00:45,432 INFO     Training average loss at step 941000: 0.139569\n",
      "2022-11-09 03:00:48,536 INFO     Training average positive_sample_loss at step 941100: 0.139050\n",
      "2022-11-09 03:00:48,536 INFO     Training average negative_sample_loss at step 941100: 0.138261\n",
      "2022-11-09 03:00:48,536 INFO     Training average loss at step 941100: 0.138656\n",
      "2022-11-09 03:00:51,633 INFO     Training average positive_sample_loss at step 941200: 0.138334\n",
      "2022-11-09 03:00:51,633 INFO     Training average negative_sample_loss at step 941200: 0.133902\n",
      "2022-11-09 03:00:51,634 INFO     Training average loss at step 941200: 0.136118\n",
      "2022-11-09 03:00:55,807 INFO     Training average positive_sample_loss at step 941300: 0.137167\n",
      "2022-11-09 03:00:55,808 INFO     Training average negative_sample_loss at step 941300: 0.133230\n",
      "2022-11-09 03:00:55,808 INFO     Training average loss at step 941300: 0.135199\n",
      "2022-11-09 03:00:59,872 INFO     Training average positive_sample_loss at step 941400: 0.139898\n",
      "2022-11-09 03:00:59,872 INFO     Training average negative_sample_loss at step 941400: 0.139833\n",
      "2022-11-09 03:00:59,872 INFO     Training average loss at step 941400: 0.139865\n",
      "2022-11-09 03:01:02,962 INFO     Training average positive_sample_loss at step 941500: 0.137897\n",
      "2022-11-09 03:01:02,962 INFO     Training average negative_sample_loss at step 941500: 0.131350\n",
      "2022-11-09 03:01:02,962 INFO     Training average loss at step 941500: 0.134623\n",
      "2022-11-09 03:01:06,041 INFO     Training average positive_sample_loss at step 941600: 0.141131\n",
      "2022-11-09 03:01:06,041 INFO     Training average negative_sample_loss at step 941600: 0.135737\n",
      "2022-11-09 03:01:06,041 INFO     Training average loss at step 941600: 0.138434\n",
      "2022-11-09 03:01:09,123 INFO     Training average positive_sample_loss at step 941700: 0.146368\n",
      "2022-11-09 03:01:09,123 INFO     Training average negative_sample_loss at step 941700: 0.137920\n",
      "2022-11-09 03:01:09,123 INFO     Training average loss at step 941700: 0.142144\n",
      "2022-11-09 03:01:12,221 INFO     Training average positive_sample_loss at step 941800: 0.140430\n",
      "2022-11-09 03:01:12,221 INFO     Training average negative_sample_loss at step 941800: 0.131047\n",
      "2022-11-09 03:01:12,221 INFO     Training average loss at step 941800: 0.135738\n",
      "2022-11-09 03:01:16,835 INFO     Training average positive_sample_loss at step 941900: 0.141827\n",
      "2022-11-09 03:01:16,836 INFO     Training average negative_sample_loss at step 941900: 0.142688\n",
      "2022-11-09 03:01:16,836 INFO     Training average loss at step 941900: 0.142257\n",
      "2022-11-09 03:01:19,943 INFO     Training average positive_sample_loss at step 942000: 0.142375\n",
      "2022-11-09 03:01:19,943 INFO     Training average negative_sample_loss at step 942000: 0.137515\n",
      "2022-11-09 03:01:19,943 INFO     Training average loss at step 942000: 0.139945\n",
      "2022-11-09 03:01:23,043 INFO     Training average positive_sample_loss at step 942100: 0.146780\n",
      "2022-11-09 03:01:23,043 INFO     Training average negative_sample_loss at step 942100: 0.134494\n",
      "2022-11-09 03:01:23,043 INFO     Training average loss at step 942100: 0.140637\n",
      "2022-11-09 03:01:26,130 INFO     Training average positive_sample_loss at step 942200: 0.139247\n",
      "2022-11-09 03:01:26,130 INFO     Training average negative_sample_loss at step 942200: 0.139534\n",
      "2022-11-09 03:01:26,130 INFO     Training average loss at step 942200: 0.139391\n",
      "2022-11-09 03:01:29,224 INFO     Training average positive_sample_loss at step 942300: 0.144206\n",
      "2022-11-09 03:01:29,224 INFO     Training average negative_sample_loss at step 942300: 0.135466\n",
      "2022-11-09 03:01:29,224 INFO     Training average loss at step 942300: 0.139836\n",
      "2022-11-09 03:01:32,331 INFO     Training average positive_sample_loss at step 942400: 0.141223\n",
      "2022-11-09 03:01:32,331 INFO     Training average negative_sample_loss at step 942400: 0.131061\n",
      "2022-11-09 03:01:32,331 INFO     Training average loss at step 942400: 0.136142\n",
      "2022-11-09 03:01:35,439 INFO     Training average positive_sample_loss at step 942500: 0.143317\n",
      "2022-11-09 03:01:35,439 INFO     Training average negative_sample_loss at step 942500: 0.136716\n",
      "2022-11-09 03:01:35,439 INFO     Training average loss at step 942500: 0.140017\n",
      "2022-11-09 03:01:38,548 INFO     Training average positive_sample_loss at step 942600: 0.141709\n",
      "2022-11-09 03:01:38,548 INFO     Training average negative_sample_loss at step 942600: 0.140948\n",
      "2022-11-09 03:01:38,548 INFO     Training average loss at step 942600: 0.141328\n",
      "2022-11-09 03:01:41,644 INFO     Training average positive_sample_loss at step 942700: 0.138533\n",
      "2022-11-09 03:01:41,644 INFO     Training average negative_sample_loss at step 942700: 0.133467\n",
      "2022-11-09 03:01:41,644 INFO     Training average loss at step 942700: 0.136000\n",
      "2022-11-09 03:01:44,735 INFO     Training average positive_sample_loss at step 942800: 0.139586\n",
      "2022-11-09 03:01:44,735 INFO     Training average negative_sample_loss at step 942800: 0.133310\n",
      "2022-11-09 03:01:44,735 INFO     Training average loss at step 942800: 0.136448\n",
      "2022-11-09 03:01:47,834 INFO     Training average positive_sample_loss at step 942900: 0.140017\n",
      "2022-11-09 03:01:47,834 INFO     Training average negative_sample_loss at step 942900: 0.137107\n",
      "2022-11-09 03:01:47,834 INFO     Training average loss at step 942900: 0.138562\n",
      "2022-11-09 03:01:50,941 INFO     Training average positive_sample_loss at step 943000: 0.141210\n",
      "2022-11-09 03:01:50,941 INFO     Training average negative_sample_loss at step 943000: 0.138156\n",
      "2022-11-09 03:01:50,941 INFO     Training average loss at step 943000: 0.139683\n",
      "2022-11-09 03:01:54,051 INFO     Training average positive_sample_loss at step 943100: 0.147962\n",
      "2022-11-09 03:01:54,051 INFO     Training average negative_sample_loss at step 943100: 0.135709\n",
      "2022-11-09 03:01:54,051 INFO     Training average loss at step 943100: 0.141835\n",
      "2022-11-09 03:01:57,149 INFO     Training average positive_sample_loss at step 943200: 0.140762\n",
      "2022-11-09 03:01:57,149 INFO     Training average negative_sample_loss at step 943200: 0.136562\n",
      "2022-11-09 03:01:57,149 INFO     Training average loss at step 943200: 0.138662\n",
      "2022-11-09 03:02:00,238 INFO     Training average positive_sample_loss at step 943300: 0.141552\n",
      "2022-11-09 03:02:00,238 INFO     Training average negative_sample_loss at step 943300: 0.134546\n",
      "2022-11-09 03:02:00,238 INFO     Training average loss at step 943300: 0.138049\n",
      "2022-11-09 03:02:03,332 INFO     Training average positive_sample_loss at step 943400: 0.139494\n",
      "2022-11-09 03:02:03,332 INFO     Training average negative_sample_loss at step 943400: 0.134402\n",
      "2022-11-09 03:02:03,332 INFO     Training average loss at step 943400: 0.136948\n",
      "2022-11-09 03:02:06,421 INFO     Training average positive_sample_loss at step 943500: 0.139492\n",
      "2022-11-09 03:02:06,421 INFO     Training average negative_sample_loss at step 943500: 0.139333\n",
      "2022-11-09 03:02:06,421 INFO     Training average loss at step 943500: 0.139413\n",
      "2022-11-09 03:02:09,521 INFO     Training average positive_sample_loss at step 943600: 0.139060\n",
      "2022-11-09 03:02:09,522 INFO     Training average negative_sample_loss at step 943600: 0.137179\n",
      "2022-11-09 03:02:09,522 INFO     Training average loss at step 943600: 0.138120\n",
      "2022-11-09 03:02:12,625 INFO     Training average positive_sample_loss at step 943700: 0.138773\n",
      "2022-11-09 03:02:12,625 INFO     Training average negative_sample_loss at step 943700: 0.135621\n",
      "2022-11-09 03:02:12,625 INFO     Training average loss at step 943700: 0.137197\n",
      "2022-11-09 03:02:15,718 INFO     Training average positive_sample_loss at step 943800: 0.137133\n",
      "2022-11-09 03:02:15,718 INFO     Training average negative_sample_loss at step 943800: 0.134334\n",
      "2022-11-09 03:02:15,718 INFO     Training average loss at step 943800: 0.135733\n",
      "2022-11-09 03:02:18,815 INFO     Training average positive_sample_loss at step 943900: 0.138295\n",
      "2022-11-09 03:02:18,815 INFO     Training average negative_sample_loss at step 943900: 0.132533\n",
      "2022-11-09 03:02:18,815 INFO     Training average loss at step 943900: 0.135414\n",
      "2022-11-09 03:02:21,925 INFO     Training average positive_sample_loss at step 944000: 0.137192\n",
      "2022-11-09 03:02:21,925 INFO     Training average negative_sample_loss at step 944000: 0.138498\n",
      "2022-11-09 03:02:21,925 INFO     Training average loss at step 944000: 0.137845\n",
      "2022-11-09 03:02:25,028 INFO     Training average positive_sample_loss at step 944100: 0.135723\n",
      "2022-11-09 03:02:25,028 INFO     Training average negative_sample_loss at step 944100: 0.135048\n",
      "2022-11-09 03:02:25,028 INFO     Training average loss at step 944100: 0.135386\n",
      "2022-11-09 03:02:28,118 INFO     Training average positive_sample_loss at step 944200: 0.143090\n",
      "2022-11-09 03:02:28,118 INFO     Training average negative_sample_loss at step 944200: 0.136275\n",
      "2022-11-09 03:02:28,118 INFO     Training average loss at step 944200: 0.139682\n",
      "2022-11-09 03:02:31,212 INFO     Training average positive_sample_loss at step 944300: 0.141062\n",
      "2022-11-09 03:02:31,213 INFO     Training average negative_sample_loss at step 944300: 0.134008\n",
      "2022-11-09 03:02:31,213 INFO     Training average loss at step 944300: 0.137535\n",
      "2022-11-09 03:02:34,302 INFO     Training average positive_sample_loss at step 944400: 0.139225\n",
      "2022-11-09 03:02:34,302 INFO     Training average negative_sample_loss at step 944400: 0.137644\n",
      "2022-11-09 03:02:34,302 INFO     Training average loss at step 944400: 0.138435\n",
      "2022-11-09 03:02:37,397 INFO     Training average positive_sample_loss at step 944500: 0.147868\n",
      "2022-11-09 03:02:37,398 INFO     Training average negative_sample_loss at step 944500: 0.133695\n",
      "2022-11-09 03:02:37,398 INFO     Training average loss at step 944500: 0.140781\n",
      "2022-11-09 03:02:40,514 INFO     Training average positive_sample_loss at step 944600: 0.140039\n",
      "2022-11-09 03:02:40,514 INFO     Training average negative_sample_loss at step 944600: 0.138259\n",
      "2022-11-09 03:02:40,514 INFO     Training average loss at step 944600: 0.139149\n",
      "2022-11-09 03:02:43,631 INFO     Training average positive_sample_loss at step 944700: 0.137636\n",
      "2022-11-09 03:02:43,631 INFO     Training average negative_sample_loss at step 944700: 0.134815\n",
      "2022-11-09 03:02:43,631 INFO     Training average loss at step 944700: 0.136225\n",
      "2022-11-09 03:02:46,730 INFO     Training average positive_sample_loss at step 944800: 0.140859\n",
      "2022-11-09 03:02:46,730 INFO     Training average negative_sample_loss at step 944800: 0.130162\n",
      "2022-11-09 03:02:46,730 INFO     Training average loss at step 944800: 0.135510\n",
      "2022-11-09 03:02:49,840 INFO     Training average positive_sample_loss at step 944900: 0.144423\n",
      "2022-11-09 03:02:49,840 INFO     Training average negative_sample_loss at step 944900: 0.135343\n",
      "2022-11-09 03:02:49,840 INFO     Training average loss at step 944900: 0.139883\n",
      "2022-11-09 03:02:52,943 INFO     Training average positive_sample_loss at step 945000: 0.143974\n",
      "2022-11-09 03:02:52,944 INFO     Training average negative_sample_loss at step 945000: 0.134469\n",
      "2022-11-09 03:02:52,944 INFO     Training average loss at step 945000: 0.139222\n",
      "2022-11-09 03:02:56,041 INFO     Training average positive_sample_loss at step 945100: 0.142388\n",
      "2022-11-09 03:02:56,041 INFO     Training average negative_sample_loss at step 945100: 0.138368\n",
      "2022-11-09 03:02:56,041 INFO     Training average loss at step 945100: 0.140378\n",
      "2022-11-09 03:02:59,147 INFO     Training average positive_sample_loss at step 945200: 0.146736\n",
      "2022-11-09 03:02:59,147 INFO     Training average negative_sample_loss at step 945200: 0.133013\n",
      "2022-11-09 03:02:59,147 INFO     Training average loss at step 945200: 0.139874\n",
      "2022-11-09 03:03:02,244 INFO     Training average positive_sample_loss at step 945300: 0.145558\n",
      "2022-11-09 03:03:02,244 INFO     Training average negative_sample_loss at step 945300: 0.133808\n",
      "2022-11-09 03:03:02,244 INFO     Training average loss at step 945300: 0.139683\n",
      "2022-11-09 03:03:05,343 INFO     Training average positive_sample_loss at step 945400: 0.145120\n",
      "2022-11-09 03:03:05,343 INFO     Training average negative_sample_loss at step 945400: 0.140254\n",
      "2022-11-09 03:03:05,343 INFO     Training average loss at step 945400: 0.142687\n",
      "2022-11-09 03:03:08,444 INFO     Training average positive_sample_loss at step 945500: 0.143357\n",
      "2022-11-09 03:03:08,444 INFO     Training average negative_sample_loss at step 945500: 0.134071\n",
      "2022-11-09 03:03:08,444 INFO     Training average loss at step 945500: 0.138714\n",
      "2022-11-09 03:03:11,531 INFO     Training average positive_sample_loss at step 945600: 0.142750\n",
      "2022-11-09 03:03:11,532 INFO     Training average negative_sample_loss at step 945600: 0.136899\n",
      "2022-11-09 03:03:11,532 INFO     Training average loss at step 945600: 0.139824\n",
      "2022-11-09 03:03:14,626 INFO     Training average positive_sample_loss at step 945700: 0.140090\n",
      "2022-11-09 03:03:14,626 INFO     Training average negative_sample_loss at step 945700: 0.132504\n",
      "2022-11-09 03:03:14,626 INFO     Training average loss at step 945700: 0.136297\n",
      "2022-11-09 03:03:17,731 INFO     Training average positive_sample_loss at step 945800: 0.143257\n",
      "2022-11-09 03:03:17,731 INFO     Training average negative_sample_loss at step 945800: 0.136145\n",
      "2022-11-09 03:03:17,731 INFO     Training average loss at step 945800: 0.139701\n",
      "2022-11-09 03:03:20,809 INFO     Training average positive_sample_loss at step 945900: 0.146273\n",
      "2022-11-09 03:03:20,809 INFO     Training average negative_sample_loss at step 945900: 0.137070\n",
      "2022-11-09 03:03:20,809 INFO     Training average loss at step 945900: 0.141671\n",
      "2022-11-09 03:03:25,005 INFO     Training average positive_sample_loss at step 946000: 0.138912\n",
      "2022-11-09 03:03:25,005 INFO     Training average negative_sample_loss at step 946000: 0.135794\n",
      "2022-11-09 03:03:25,005 INFO     Training average loss at step 946000: 0.137353\n",
      "2022-11-09 03:03:29,070 INFO     Training average positive_sample_loss at step 946100: 0.145022\n",
      "2022-11-09 03:03:29,070 INFO     Training average negative_sample_loss at step 946100: 0.138726\n",
      "2022-11-09 03:03:29,070 INFO     Training average loss at step 946100: 0.141874\n",
      "2022-11-09 03:03:32,176 INFO     Training average positive_sample_loss at step 946200: 0.139732\n",
      "2022-11-09 03:03:32,176 INFO     Training average negative_sample_loss at step 946200: 0.135974\n",
      "2022-11-09 03:03:32,176 INFO     Training average loss at step 946200: 0.137853\n",
      "2022-11-09 03:03:35,280 INFO     Training average positive_sample_loss at step 946300: 0.141693\n",
      "2022-11-09 03:03:35,281 INFO     Training average negative_sample_loss at step 946300: 0.137892\n",
      "2022-11-09 03:03:35,281 INFO     Training average loss at step 946300: 0.139793\n",
      "2022-11-09 03:03:38,406 INFO     Training average positive_sample_loss at step 946400: 0.136616\n",
      "2022-11-09 03:03:38,406 INFO     Training average negative_sample_loss at step 946400: 0.132787\n",
      "2022-11-09 03:03:38,407 INFO     Training average loss at step 946400: 0.134702\n",
      "2022-11-09 03:03:41,516 INFO     Training average positive_sample_loss at step 946500: 0.142467\n",
      "2022-11-09 03:03:41,517 INFO     Training average negative_sample_loss at step 946500: 0.133094\n",
      "2022-11-09 03:03:41,517 INFO     Training average loss at step 946500: 0.137780\n",
      "2022-11-09 03:03:46,148 INFO     Training average positive_sample_loss at step 946600: 0.141402\n",
      "2022-11-09 03:03:46,148 INFO     Training average negative_sample_loss at step 946600: 0.133921\n",
      "2022-11-09 03:03:46,148 INFO     Training average loss at step 946600: 0.137661\n",
      "2022-11-09 03:03:49,248 INFO     Training average positive_sample_loss at step 946700: 0.146962\n",
      "2022-11-09 03:03:49,248 INFO     Training average negative_sample_loss at step 946700: 0.136173\n",
      "2022-11-09 03:03:49,248 INFO     Training average loss at step 946700: 0.141567\n",
      "2022-11-09 03:03:52,350 INFO     Training average positive_sample_loss at step 946800: 0.138003\n",
      "2022-11-09 03:03:52,350 INFO     Training average negative_sample_loss at step 946800: 0.135633\n",
      "2022-11-09 03:03:52,350 INFO     Training average loss at step 946800: 0.136818\n",
      "2022-11-09 03:03:55,452 INFO     Training average positive_sample_loss at step 946900: 0.141934\n",
      "2022-11-09 03:03:55,452 INFO     Training average negative_sample_loss at step 946900: 0.134887\n",
      "2022-11-09 03:03:55,452 INFO     Training average loss at step 946900: 0.138411\n",
      "2022-11-09 03:03:58,548 INFO     Training average positive_sample_loss at step 947000: 0.142532\n",
      "2022-11-09 03:03:58,549 INFO     Training average negative_sample_loss at step 947000: 0.135412\n",
      "2022-11-09 03:03:58,549 INFO     Training average loss at step 947000: 0.138972\n",
      "2022-11-09 03:04:01,638 INFO     Training average positive_sample_loss at step 947100: 0.144659\n",
      "2022-11-09 03:04:01,638 INFO     Training average negative_sample_loss at step 947100: 0.134047\n",
      "2022-11-09 03:04:01,638 INFO     Training average loss at step 947100: 0.139353\n",
      "2022-11-09 03:04:04,737 INFO     Training average positive_sample_loss at step 947200: 0.143402\n",
      "2022-11-09 03:04:04,737 INFO     Training average negative_sample_loss at step 947200: 0.137045\n",
      "2022-11-09 03:04:04,737 INFO     Training average loss at step 947200: 0.140224\n",
      "2022-11-09 03:04:07,836 INFO     Training average positive_sample_loss at step 947300: 0.139418\n",
      "2022-11-09 03:04:07,836 INFO     Training average negative_sample_loss at step 947300: 0.135625\n",
      "2022-11-09 03:04:07,836 INFO     Training average loss at step 947300: 0.137521\n",
      "2022-11-09 03:04:10,947 INFO     Training average positive_sample_loss at step 947400: 0.140136\n",
      "2022-11-09 03:04:10,947 INFO     Training average negative_sample_loss at step 947400: 0.133463\n",
      "2022-11-09 03:04:10,947 INFO     Training average loss at step 947400: 0.136799\n",
      "2022-11-09 03:04:14,043 INFO     Training average positive_sample_loss at step 947500: 0.140686\n",
      "2022-11-09 03:04:14,043 INFO     Training average negative_sample_loss at step 947500: 0.134685\n",
      "2022-11-09 03:04:14,043 INFO     Training average loss at step 947500: 0.137685\n",
      "2022-11-09 03:04:17,135 INFO     Training average positive_sample_loss at step 947600: 0.144167\n",
      "2022-11-09 03:04:17,135 INFO     Training average negative_sample_loss at step 947600: 0.133910\n",
      "2022-11-09 03:04:17,135 INFO     Training average loss at step 947600: 0.139039\n",
      "2022-11-09 03:04:20,232 INFO     Training average positive_sample_loss at step 947700: 0.142727\n",
      "2022-11-09 03:04:20,232 INFO     Training average negative_sample_loss at step 947700: 0.138373\n",
      "2022-11-09 03:04:20,232 INFO     Training average loss at step 947700: 0.140550\n",
      "2022-11-09 03:04:23,335 INFO     Training average positive_sample_loss at step 947800: 0.139366\n",
      "2022-11-09 03:04:23,335 INFO     Training average negative_sample_loss at step 947800: 0.132009\n",
      "2022-11-09 03:04:23,335 INFO     Training average loss at step 947800: 0.135688\n",
      "2022-11-09 03:04:26,435 INFO     Training average positive_sample_loss at step 947900: 0.145692\n",
      "2022-11-09 03:04:26,435 INFO     Training average negative_sample_loss at step 947900: 0.135593\n",
      "2022-11-09 03:04:26,435 INFO     Training average loss at step 947900: 0.140642\n",
      "2022-11-09 03:04:29,551 INFO     Training average positive_sample_loss at step 948000: 0.144002\n",
      "2022-11-09 03:04:29,551 INFO     Training average negative_sample_loss at step 948000: 0.140283\n",
      "2022-11-09 03:04:29,551 INFO     Training average loss at step 948000: 0.142142\n",
      "2022-11-09 03:04:32,682 INFO     Training average positive_sample_loss at step 948100: 0.143514\n",
      "2022-11-09 03:04:32,682 INFO     Training average negative_sample_loss at step 948100: 0.135908\n",
      "2022-11-09 03:04:32,682 INFO     Training average loss at step 948100: 0.139711\n",
      "2022-11-09 03:04:35,808 INFO     Training average positive_sample_loss at step 948200: 0.141325\n",
      "2022-11-09 03:04:35,808 INFO     Training average negative_sample_loss at step 948200: 0.133320\n",
      "2022-11-09 03:04:35,808 INFO     Training average loss at step 948200: 0.137323\n",
      "2022-11-09 03:04:38,937 INFO     Training average positive_sample_loss at step 948300: 0.141977\n",
      "2022-11-09 03:04:38,937 INFO     Training average negative_sample_loss at step 948300: 0.134241\n",
      "2022-11-09 03:04:38,937 INFO     Training average loss at step 948300: 0.138109\n",
      "2022-11-09 03:04:42,063 INFO     Training average positive_sample_loss at step 948400: 0.141510\n",
      "2022-11-09 03:04:42,063 INFO     Training average negative_sample_loss at step 948400: 0.135369\n",
      "2022-11-09 03:04:42,064 INFO     Training average loss at step 948400: 0.138440\n",
      "2022-11-09 03:04:45,178 INFO     Training average positive_sample_loss at step 948500: 0.137931\n",
      "2022-11-09 03:04:45,178 INFO     Training average negative_sample_loss at step 948500: 0.131525\n",
      "2022-11-09 03:04:45,178 INFO     Training average loss at step 948500: 0.134728\n",
      "2022-11-09 03:04:48,288 INFO     Training average positive_sample_loss at step 948600: 0.138837\n",
      "2022-11-09 03:04:48,288 INFO     Training average negative_sample_loss at step 948600: 0.137131\n",
      "2022-11-09 03:04:48,288 INFO     Training average loss at step 948600: 0.137984\n",
      "2022-11-09 03:04:51,413 INFO     Training average positive_sample_loss at step 948700: 0.143595\n",
      "2022-11-09 03:04:51,413 INFO     Training average negative_sample_loss at step 948700: 0.137009\n",
      "2022-11-09 03:04:51,413 INFO     Training average loss at step 948700: 0.140302\n",
      "2022-11-09 03:04:54,525 INFO     Training average positive_sample_loss at step 948800: 0.140869\n",
      "2022-11-09 03:04:54,526 INFO     Training average negative_sample_loss at step 948800: 0.137193\n",
      "2022-11-09 03:04:54,526 INFO     Training average loss at step 948800: 0.139031\n",
      "2022-11-09 03:04:57,639 INFO     Training average positive_sample_loss at step 948900: 0.140331\n",
      "2022-11-09 03:04:57,639 INFO     Training average negative_sample_loss at step 948900: 0.137472\n",
      "2022-11-09 03:04:57,639 INFO     Training average loss at step 948900: 0.138902\n",
      "2022-11-09 03:05:00,755 INFO     Training average positive_sample_loss at step 949000: 0.138525\n",
      "2022-11-09 03:05:00,755 INFO     Training average negative_sample_loss at step 949000: 0.133729\n",
      "2022-11-09 03:05:00,755 INFO     Training average loss at step 949000: 0.136127\n",
      "2022-11-09 03:05:03,859 INFO     Training average positive_sample_loss at step 949100: 0.142132\n",
      "2022-11-09 03:05:03,859 INFO     Training average negative_sample_loss at step 949100: 0.133931\n",
      "2022-11-09 03:05:03,859 INFO     Training average loss at step 949100: 0.138032\n",
      "2022-11-09 03:05:06,973 INFO     Training average positive_sample_loss at step 949200: 0.140047\n",
      "2022-11-09 03:05:06,973 INFO     Training average negative_sample_loss at step 949200: 0.133666\n",
      "2022-11-09 03:05:06,973 INFO     Training average loss at step 949200: 0.136856\n",
      "2022-11-09 03:05:10,098 INFO     Training average positive_sample_loss at step 949300: 0.139175\n",
      "2022-11-09 03:05:10,098 INFO     Training average negative_sample_loss at step 949300: 0.139264\n",
      "2022-11-09 03:05:10,098 INFO     Training average loss at step 949300: 0.139219\n",
      "2022-11-09 03:05:13,229 INFO     Training average positive_sample_loss at step 949400: 0.139732\n",
      "2022-11-09 03:05:13,229 INFO     Training average negative_sample_loss at step 949400: 0.138561\n",
      "2022-11-09 03:05:13,229 INFO     Training average loss at step 949400: 0.139147\n",
      "2022-11-09 03:05:16,342 INFO     Training average positive_sample_loss at step 949500: 0.138026\n",
      "2022-11-09 03:05:16,342 INFO     Training average negative_sample_loss at step 949500: 0.135525\n",
      "2022-11-09 03:05:16,342 INFO     Training average loss at step 949500: 0.136775\n",
      "2022-11-09 03:05:19,454 INFO     Training average positive_sample_loss at step 949600: 0.140877\n",
      "2022-11-09 03:05:19,454 INFO     Training average negative_sample_loss at step 949600: 0.136176\n",
      "2022-11-09 03:05:19,454 INFO     Training average loss at step 949600: 0.138526\n",
      "2022-11-09 03:05:22,560 INFO     Training average positive_sample_loss at step 949700: 0.141725\n",
      "2022-11-09 03:05:22,560 INFO     Training average negative_sample_loss at step 949700: 0.136444\n",
      "2022-11-09 03:05:22,560 INFO     Training average loss at step 949700: 0.139084\n",
      "2022-11-09 03:05:25,661 INFO     Training average positive_sample_loss at step 949800: 0.138128\n",
      "2022-11-09 03:05:25,661 INFO     Training average negative_sample_loss at step 949800: 0.140068\n",
      "2022-11-09 03:05:25,661 INFO     Training average loss at step 949800: 0.139098\n",
      "2022-11-09 03:05:31,731 INFO     Training average positive_sample_loss at step 949900: 0.141372\n",
      "2022-11-09 03:05:31,731 INFO     Training average negative_sample_loss at step 949900: 0.139105\n",
      "2022-11-09 03:05:31,731 INFO     Training average loss at step 949900: 0.140238\n",
      "2022-11-09 03:05:37,824 INFO     Training average positive_sample_loss at step 950000: 0.134444\n",
      "2022-11-09 03:05:37,824 INFO     Training average negative_sample_loss at step 950000: 0.140563\n",
      "2022-11-09 03:05:37,824 INFO     Training average loss at step 950000: 0.137504\n",
      "2022-11-09 03:05:40,956 INFO     Training average positive_sample_loss at step 950100: 0.133500\n",
      "2022-11-09 03:05:40,957 INFO     Training average negative_sample_loss at step 950100: 0.131426\n",
      "2022-11-09 03:05:40,957 INFO     Training average loss at step 950100: 0.132463\n",
      "2022-11-09 03:05:44,055 INFO     Training average positive_sample_loss at step 950200: 0.132707\n",
      "2022-11-09 03:05:44,055 INFO     Training average negative_sample_loss at step 950200: 0.136481\n",
      "2022-11-09 03:05:44,055 INFO     Training average loss at step 950200: 0.134594\n",
      "2022-11-09 03:05:47,168 INFO     Training average positive_sample_loss at step 950300: 0.129487\n",
      "2022-11-09 03:05:47,168 INFO     Training average negative_sample_loss at step 950300: 0.134961\n",
      "2022-11-09 03:05:47,168 INFO     Training average loss at step 950300: 0.132224\n",
      "2022-11-09 03:05:50,281 INFO     Training average positive_sample_loss at step 950400: 0.131111\n",
      "2022-11-09 03:05:50,281 INFO     Training average negative_sample_loss at step 950400: 0.134850\n",
      "2022-11-09 03:05:50,281 INFO     Training average loss at step 950400: 0.132980\n",
      "2022-11-09 03:05:53,394 INFO     Training average positive_sample_loss at step 950500: 0.131277\n",
      "2022-11-09 03:05:53,394 INFO     Training average negative_sample_loss at step 950500: 0.132825\n",
      "2022-11-09 03:05:53,394 INFO     Training average loss at step 950500: 0.132051\n",
      "2022-11-09 03:05:56,509 INFO     Training average positive_sample_loss at step 950600: 0.132465\n",
      "2022-11-09 03:05:56,509 INFO     Training average negative_sample_loss at step 950600: 0.137330\n",
      "2022-11-09 03:05:56,509 INFO     Training average loss at step 950600: 0.134897\n",
      "2022-11-09 03:05:59,625 INFO     Training average positive_sample_loss at step 950700: 0.140615\n",
      "2022-11-09 03:05:59,625 INFO     Training average negative_sample_loss at step 950700: 0.138085\n",
      "2022-11-09 03:05:59,625 INFO     Training average loss at step 950700: 0.139350\n",
      "2022-11-09 03:06:02,736 INFO     Training average positive_sample_loss at step 950800: 0.133253\n",
      "2022-11-09 03:06:02,736 INFO     Training average negative_sample_loss at step 950800: 0.136690\n",
      "2022-11-09 03:06:02,736 INFO     Training average loss at step 950800: 0.134972\n",
      "2022-11-09 03:06:05,848 INFO     Training average positive_sample_loss at step 950900: 0.134193\n",
      "2022-11-09 03:06:05,849 INFO     Training average negative_sample_loss at step 950900: 0.137799\n",
      "2022-11-09 03:06:05,849 INFO     Training average loss at step 950900: 0.135996\n",
      "2022-11-09 03:06:08,964 INFO     Training average positive_sample_loss at step 951000: 0.136543\n",
      "2022-11-09 03:06:08,964 INFO     Training average negative_sample_loss at step 951000: 0.135739\n",
      "2022-11-09 03:06:08,965 INFO     Training average loss at step 951000: 0.136141\n",
      "2022-11-09 03:06:12,075 INFO     Training average positive_sample_loss at step 951100: 0.139431\n",
      "2022-11-09 03:06:12,075 INFO     Training average negative_sample_loss at step 951100: 0.138360\n",
      "2022-11-09 03:06:12,075 INFO     Training average loss at step 951100: 0.138896\n",
      "2022-11-09 03:06:15,200 INFO     Training average positive_sample_loss at step 951200: 0.130986\n",
      "2022-11-09 03:06:15,200 INFO     Training average negative_sample_loss at step 951200: 0.130261\n",
      "2022-11-09 03:06:15,200 INFO     Training average loss at step 951200: 0.130624\n",
      "2022-11-09 03:06:18,297 INFO     Training average positive_sample_loss at step 951300: 0.134075\n",
      "2022-11-09 03:06:18,297 INFO     Training average negative_sample_loss at step 951300: 0.135212\n",
      "2022-11-09 03:06:18,297 INFO     Training average loss at step 951300: 0.134643\n",
      "2022-11-09 03:06:21,411 INFO     Training average positive_sample_loss at step 951400: 0.133881\n",
      "2022-11-09 03:06:21,411 INFO     Training average negative_sample_loss at step 951400: 0.135823\n",
      "2022-11-09 03:06:21,411 INFO     Training average loss at step 951400: 0.134852\n",
      "2022-11-09 03:06:24,534 INFO     Training average positive_sample_loss at step 951500: 0.130057\n",
      "2022-11-09 03:06:24,534 INFO     Training average negative_sample_loss at step 951500: 0.134675\n",
      "2022-11-09 03:06:24,534 INFO     Training average loss at step 951500: 0.132366\n",
      "2022-11-09 03:06:27,641 INFO     Training average positive_sample_loss at step 951600: 0.133877\n",
      "2022-11-09 03:06:27,641 INFO     Training average negative_sample_loss at step 951600: 0.134792\n",
      "2022-11-09 03:06:27,641 INFO     Training average loss at step 951600: 0.134334\n",
      "2022-11-09 03:06:30,736 INFO     Training average positive_sample_loss at step 951700: 0.136060\n",
      "2022-11-09 03:06:30,736 INFO     Training average negative_sample_loss at step 951700: 0.135860\n",
      "2022-11-09 03:06:30,737 INFO     Training average loss at step 951700: 0.135960\n",
      "2022-11-09 03:06:33,842 INFO     Training average positive_sample_loss at step 951800: 0.134669\n",
      "2022-11-09 03:06:33,842 INFO     Training average negative_sample_loss at step 951800: 0.134413\n",
      "2022-11-09 03:06:33,842 INFO     Training average loss at step 951800: 0.134541\n",
      "2022-11-09 03:06:36,955 INFO     Training average positive_sample_loss at step 951900: 0.136487\n",
      "2022-11-09 03:06:36,956 INFO     Training average negative_sample_loss at step 951900: 0.133598\n",
      "2022-11-09 03:06:36,956 INFO     Training average loss at step 951900: 0.135042\n",
      "2022-11-09 03:06:40,084 INFO     Training average positive_sample_loss at step 952000: 0.137911\n",
      "2022-11-09 03:06:40,084 INFO     Training average negative_sample_loss at step 952000: 0.135043\n",
      "2022-11-09 03:06:40,084 INFO     Training average loss at step 952000: 0.136477\n",
      "2022-11-09 03:06:43,198 INFO     Training average positive_sample_loss at step 952100: 0.136956\n",
      "2022-11-09 03:06:43,198 INFO     Training average negative_sample_loss at step 952100: 0.131230\n",
      "2022-11-09 03:06:43,198 INFO     Training average loss at step 952100: 0.134093\n",
      "2022-11-09 03:06:46,315 INFO     Training average positive_sample_loss at step 952200: 0.133980\n",
      "2022-11-09 03:06:46,315 INFO     Training average negative_sample_loss at step 952200: 0.138439\n",
      "2022-11-09 03:06:46,315 INFO     Training average loss at step 952200: 0.136209\n",
      "2022-11-09 03:06:49,408 INFO     Training average positive_sample_loss at step 952300: 0.135317\n",
      "2022-11-09 03:06:49,409 INFO     Training average negative_sample_loss at step 952300: 0.136514\n",
      "2022-11-09 03:06:49,409 INFO     Training average loss at step 952300: 0.135915\n",
      "2022-11-09 03:06:52,518 INFO     Training average positive_sample_loss at step 952400: 0.137006\n",
      "2022-11-09 03:06:52,518 INFO     Training average negative_sample_loss at step 952400: 0.136301\n",
      "2022-11-09 03:06:52,518 INFO     Training average loss at step 952400: 0.136654\n",
      "2022-11-09 03:06:55,624 INFO     Training average positive_sample_loss at step 952500: 0.135042\n",
      "2022-11-09 03:06:55,625 INFO     Training average negative_sample_loss at step 952500: 0.137403\n",
      "2022-11-09 03:06:55,625 INFO     Training average loss at step 952500: 0.136222\n",
      "2022-11-09 03:06:58,730 INFO     Training average positive_sample_loss at step 952600: 0.137357\n",
      "2022-11-09 03:06:58,730 INFO     Training average negative_sample_loss at step 952600: 0.132637\n",
      "2022-11-09 03:06:58,730 INFO     Training average loss at step 952600: 0.134997\n",
      "2022-11-09 03:07:01,835 INFO     Training average positive_sample_loss at step 952700: 0.135061\n",
      "2022-11-09 03:07:01,835 INFO     Training average negative_sample_loss at step 952700: 0.136034\n",
      "2022-11-09 03:07:01,835 INFO     Training average loss at step 952700: 0.135548\n",
      "2022-11-09 03:07:04,929 INFO     Training average positive_sample_loss at step 952800: 0.137186\n",
      "2022-11-09 03:07:04,929 INFO     Training average negative_sample_loss at step 952800: 0.135582\n",
      "2022-11-09 03:07:04,929 INFO     Training average loss at step 952800: 0.136384\n",
      "2022-11-09 03:07:08,032 INFO     Training average positive_sample_loss at step 952900: 0.137809\n",
      "2022-11-09 03:07:08,032 INFO     Training average negative_sample_loss at step 952900: 0.135690\n",
      "2022-11-09 03:07:08,032 INFO     Training average loss at step 952900: 0.136750\n",
      "2022-11-09 03:07:11,147 INFO     Training average positive_sample_loss at step 953000: 0.134119\n",
      "2022-11-09 03:07:11,147 INFO     Training average negative_sample_loss at step 953000: 0.136050\n",
      "2022-11-09 03:07:11,147 INFO     Training average loss at step 953000: 0.135084\n",
      "2022-11-09 03:07:14,264 INFO     Training average positive_sample_loss at step 953100: 0.134875\n",
      "2022-11-09 03:07:14,264 INFO     Training average negative_sample_loss at step 953100: 0.132290\n",
      "2022-11-09 03:07:14,264 INFO     Training average loss at step 953100: 0.133583\n",
      "2022-11-09 03:07:17,385 INFO     Training average positive_sample_loss at step 953200: 0.134896\n",
      "2022-11-09 03:07:17,385 INFO     Training average negative_sample_loss at step 953200: 0.136222\n",
      "2022-11-09 03:07:17,385 INFO     Training average loss at step 953200: 0.135559\n",
      "2022-11-09 03:07:20,511 INFO     Training average positive_sample_loss at step 953300: 0.136366\n",
      "2022-11-09 03:07:20,511 INFO     Training average negative_sample_loss at step 953300: 0.132365\n",
      "2022-11-09 03:07:20,511 INFO     Training average loss at step 953300: 0.134366\n",
      "2022-11-09 03:07:23,612 INFO     Training average positive_sample_loss at step 953400: 0.134418\n",
      "2022-11-09 03:07:23,612 INFO     Training average negative_sample_loss at step 953400: 0.134956\n",
      "2022-11-09 03:07:23,612 INFO     Training average loss at step 953400: 0.134687\n",
      "2022-11-09 03:07:26,714 INFO     Training average positive_sample_loss at step 953500: 0.140538\n",
      "2022-11-09 03:07:26,714 INFO     Training average negative_sample_loss at step 953500: 0.136354\n",
      "2022-11-09 03:07:26,715 INFO     Training average loss at step 953500: 0.138446\n",
      "2022-11-09 03:07:29,824 INFO     Training average positive_sample_loss at step 953600: 0.136138\n",
      "2022-11-09 03:07:29,824 INFO     Training average negative_sample_loss at step 953600: 0.139557\n",
      "2022-11-09 03:07:29,824 INFO     Training average loss at step 953600: 0.137848\n",
      "2022-11-09 03:07:32,939 INFO     Training average positive_sample_loss at step 953700: 0.137676\n",
      "2022-11-09 03:07:32,939 INFO     Training average negative_sample_loss at step 953700: 0.136067\n",
      "2022-11-09 03:07:32,939 INFO     Training average loss at step 953700: 0.136872\n",
      "2022-11-09 03:07:36,046 INFO     Training average positive_sample_loss at step 953800: 0.139197\n",
      "2022-11-09 03:07:36,046 INFO     Training average negative_sample_loss at step 953800: 0.135625\n",
      "2022-11-09 03:07:36,046 INFO     Training average loss at step 953800: 0.137411\n",
      "2022-11-09 03:07:39,160 INFO     Training average positive_sample_loss at step 953900: 0.138448\n",
      "2022-11-09 03:07:39,160 INFO     Training average negative_sample_loss at step 953900: 0.136689\n",
      "2022-11-09 03:07:39,160 INFO     Training average loss at step 953900: 0.137568\n",
      "2022-11-09 03:07:42,270 INFO     Training average positive_sample_loss at step 954000: 0.138257\n",
      "2022-11-09 03:07:42,270 INFO     Training average negative_sample_loss at step 954000: 0.135737\n",
      "2022-11-09 03:07:42,270 INFO     Training average loss at step 954000: 0.136997\n",
      "2022-11-09 03:07:45,374 INFO     Training average positive_sample_loss at step 954100: 0.133705\n",
      "2022-11-09 03:07:45,374 INFO     Training average negative_sample_loss at step 954100: 0.136705\n",
      "2022-11-09 03:07:45,374 INFO     Training average loss at step 954100: 0.135205\n",
      "2022-11-09 03:07:48,493 INFO     Training average positive_sample_loss at step 954200: 0.135202\n",
      "2022-11-09 03:07:48,494 INFO     Training average negative_sample_loss at step 954200: 0.134001\n",
      "2022-11-09 03:07:48,494 INFO     Training average loss at step 954200: 0.134602\n",
      "2022-11-09 03:07:51,611 INFO     Training average positive_sample_loss at step 954300: 0.137730\n",
      "2022-11-09 03:07:51,611 INFO     Training average negative_sample_loss at step 954300: 0.131788\n",
      "2022-11-09 03:07:51,611 INFO     Training average loss at step 954300: 0.134759\n",
      "2022-11-09 03:07:54,722 INFO     Training average positive_sample_loss at step 954400: 0.133837\n",
      "2022-11-09 03:07:54,722 INFO     Training average negative_sample_loss at step 954400: 0.134189\n",
      "2022-11-09 03:07:54,722 INFO     Training average loss at step 954400: 0.134013\n",
      "2022-11-09 03:07:57,835 INFO     Training average positive_sample_loss at step 954500: 0.140651\n",
      "2022-11-09 03:07:57,835 INFO     Training average negative_sample_loss at step 954500: 0.136775\n",
      "2022-11-09 03:07:57,835 INFO     Training average loss at step 954500: 0.138713\n",
      "2022-11-09 03:08:00,951 INFO     Training average positive_sample_loss at step 954600: 0.144302\n",
      "2022-11-09 03:08:00,951 INFO     Training average negative_sample_loss at step 954600: 0.135063\n",
      "2022-11-09 03:08:00,951 INFO     Training average loss at step 954600: 0.139683\n",
      "2022-11-09 03:08:04,063 INFO     Training average positive_sample_loss at step 954700: 0.136618\n",
      "2022-11-09 03:08:04,063 INFO     Training average negative_sample_loss at step 954700: 0.133885\n",
      "2022-11-09 03:08:04,063 INFO     Training average loss at step 954700: 0.135251\n",
      "2022-11-09 03:08:07,161 INFO     Training average positive_sample_loss at step 954800: 0.136212\n",
      "2022-11-09 03:08:07,161 INFO     Training average negative_sample_loss at step 954800: 0.135336\n",
      "2022-11-09 03:08:07,161 INFO     Training average loss at step 954800: 0.135774\n",
      "2022-11-09 03:08:10,258 INFO     Training average positive_sample_loss at step 954900: 0.129361\n",
      "2022-11-09 03:08:10,258 INFO     Training average negative_sample_loss at step 954900: 0.134184\n",
      "2022-11-09 03:08:10,258 INFO     Training average loss at step 954900: 0.131772\n",
      "2022-11-09 03:08:13,355 INFO     Training average positive_sample_loss at step 955000: 0.139179\n",
      "2022-11-09 03:08:13,355 INFO     Training average negative_sample_loss at step 955000: 0.135716\n",
      "2022-11-09 03:08:13,355 INFO     Training average loss at step 955000: 0.137448\n",
      "2022-11-09 03:08:16,460 INFO     Training average positive_sample_loss at step 955100: 0.139374\n",
      "2022-11-09 03:08:16,460 INFO     Training average negative_sample_loss at step 955100: 0.128153\n",
      "2022-11-09 03:08:16,460 INFO     Training average loss at step 955100: 0.133763\n",
      "2022-11-09 03:08:19,569 INFO     Training average positive_sample_loss at step 955200: 0.138812\n",
      "2022-11-09 03:08:19,569 INFO     Training average negative_sample_loss at step 955200: 0.132641\n",
      "2022-11-09 03:08:19,569 INFO     Training average loss at step 955200: 0.135727\n",
      "2022-11-09 03:08:22,673 INFO     Training average positive_sample_loss at step 955300: 0.135740\n",
      "2022-11-09 03:08:22,673 INFO     Training average negative_sample_loss at step 955300: 0.135072\n",
      "2022-11-09 03:08:22,673 INFO     Training average loss at step 955300: 0.135406\n",
      "2022-11-09 03:08:25,770 INFO     Training average positive_sample_loss at step 955400: 0.135483\n",
      "2022-11-09 03:08:25,770 INFO     Training average negative_sample_loss at step 955400: 0.130783\n",
      "2022-11-09 03:08:25,770 INFO     Training average loss at step 955400: 0.133133\n",
      "2022-11-09 03:08:28,889 INFO     Training average positive_sample_loss at step 955500: 0.137081\n",
      "2022-11-09 03:08:28,889 INFO     Training average negative_sample_loss at step 955500: 0.138642\n",
      "2022-11-09 03:08:28,889 INFO     Training average loss at step 955500: 0.137861\n",
      "2022-11-09 03:08:32,007 INFO     Training average positive_sample_loss at step 955600: 0.135744\n",
      "2022-11-09 03:08:32,007 INFO     Training average negative_sample_loss at step 955600: 0.133204\n",
      "2022-11-09 03:08:32,007 INFO     Training average loss at step 955600: 0.134474\n",
      "2022-11-09 03:08:35,119 INFO     Training average positive_sample_loss at step 955700: 0.142657\n",
      "2022-11-09 03:08:35,119 INFO     Training average negative_sample_loss at step 955700: 0.135740\n",
      "2022-11-09 03:08:35,119 INFO     Training average loss at step 955700: 0.139199\n",
      "2022-11-09 03:08:38,223 INFO     Training average positive_sample_loss at step 955800: 0.136244\n",
      "2022-11-09 03:08:38,223 INFO     Training average negative_sample_loss at step 955800: 0.127179\n",
      "2022-11-09 03:08:38,223 INFO     Training average loss at step 955800: 0.131711\n",
      "2022-11-09 03:08:41,331 INFO     Training average positive_sample_loss at step 955900: 0.139770\n",
      "2022-11-09 03:08:41,331 INFO     Training average negative_sample_loss at step 955900: 0.136247\n",
      "2022-11-09 03:08:41,331 INFO     Training average loss at step 955900: 0.138008\n",
      "2022-11-09 03:08:44,432 INFO     Training average positive_sample_loss at step 956000: 0.135176\n",
      "2022-11-09 03:08:44,432 INFO     Training average negative_sample_loss at step 956000: 0.137090\n",
      "2022-11-09 03:08:44,432 INFO     Training average loss at step 956000: 0.136133\n",
      "2022-11-09 03:08:47,550 INFO     Training average positive_sample_loss at step 956100: 0.136931\n",
      "2022-11-09 03:08:47,551 INFO     Training average negative_sample_loss at step 956100: 0.138503\n",
      "2022-11-09 03:08:47,551 INFO     Training average loss at step 956100: 0.137717\n",
      "2022-11-09 03:08:50,646 INFO     Training average positive_sample_loss at step 956200: 0.137953\n",
      "2022-11-09 03:08:50,646 INFO     Training average negative_sample_loss at step 956200: 0.135896\n",
      "2022-11-09 03:08:50,646 INFO     Training average loss at step 956200: 0.136925\n",
      "2022-11-09 03:08:53,753 INFO     Training average positive_sample_loss at step 956300: 0.134190\n",
      "2022-11-09 03:08:53,753 INFO     Training average negative_sample_loss at step 956300: 0.138064\n",
      "2022-11-09 03:08:53,753 INFO     Training average loss at step 956300: 0.136127\n",
      "2022-11-09 03:08:56,848 INFO     Training average positive_sample_loss at step 956400: 0.133119\n",
      "2022-11-09 03:08:56,848 INFO     Training average negative_sample_loss at step 956400: 0.138056\n",
      "2022-11-09 03:08:56,848 INFO     Training average loss at step 956400: 0.135587\n",
      "2022-11-09 03:08:59,946 INFO     Training average positive_sample_loss at step 956500: 0.134918\n",
      "2022-11-09 03:08:59,946 INFO     Training average negative_sample_loss at step 956500: 0.134239\n",
      "2022-11-09 03:08:59,946 INFO     Training average loss at step 956500: 0.134579\n",
      "2022-11-09 03:09:03,058 INFO     Training average positive_sample_loss at step 956600: 0.134144\n",
      "2022-11-09 03:09:03,058 INFO     Training average negative_sample_loss at step 956600: 0.138046\n",
      "2022-11-09 03:09:03,058 INFO     Training average loss at step 956600: 0.136095\n",
      "2022-11-09 03:09:06,165 INFO     Training average positive_sample_loss at step 956700: 0.131040\n",
      "2022-11-09 03:09:06,165 INFO     Training average negative_sample_loss at step 956700: 0.134497\n",
      "2022-11-09 03:09:06,165 INFO     Training average loss at step 956700: 0.132768\n",
      "2022-11-09 03:09:09,272 INFO     Training average positive_sample_loss at step 956800: 0.139028\n",
      "2022-11-09 03:09:09,272 INFO     Training average negative_sample_loss at step 956800: 0.132582\n",
      "2022-11-09 03:09:09,272 INFO     Training average loss at step 956800: 0.135805\n",
      "2022-11-09 03:09:12,376 INFO     Training average positive_sample_loss at step 956900: 0.137499\n",
      "2022-11-09 03:09:12,376 INFO     Training average negative_sample_loss at step 956900: 0.136518\n",
      "2022-11-09 03:09:12,376 INFO     Training average loss at step 956900: 0.137009\n",
      "2022-11-09 03:09:15,488 INFO     Training average positive_sample_loss at step 957000: 0.134231\n",
      "2022-11-09 03:09:15,488 INFO     Training average negative_sample_loss at step 957000: 0.134484\n",
      "2022-11-09 03:09:15,488 INFO     Training average loss at step 957000: 0.134357\n",
      "2022-11-09 03:09:18,594 INFO     Training average positive_sample_loss at step 957100: 0.138307\n",
      "2022-11-09 03:09:18,594 INFO     Training average negative_sample_loss at step 957100: 0.133805\n",
      "2022-11-09 03:09:18,594 INFO     Training average loss at step 957100: 0.136056\n",
      "2022-11-09 03:09:21,695 INFO     Training average positive_sample_loss at step 957200: 0.135706\n",
      "2022-11-09 03:09:21,695 INFO     Training average negative_sample_loss at step 957200: 0.138108\n",
      "2022-11-09 03:09:21,695 INFO     Training average loss at step 957200: 0.136907\n",
      "2022-11-09 03:09:24,796 INFO     Training average positive_sample_loss at step 957300: 0.137779\n",
      "2022-11-09 03:09:24,796 INFO     Training average negative_sample_loss at step 957300: 0.134409\n",
      "2022-11-09 03:09:24,796 INFO     Training average loss at step 957300: 0.136094\n",
      "2022-11-09 03:09:27,895 INFO     Training average positive_sample_loss at step 957400: 0.137019\n",
      "2022-11-09 03:09:27,895 INFO     Training average negative_sample_loss at step 957400: 0.136608\n",
      "2022-11-09 03:09:27,895 INFO     Training average loss at step 957400: 0.136814\n",
      "2022-11-09 03:09:30,996 INFO     Training average positive_sample_loss at step 957500: 0.136460\n",
      "2022-11-09 03:09:30,996 INFO     Training average negative_sample_loss at step 957500: 0.138185\n",
      "2022-11-09 03:09:30,996 INFO     Training average loss at step 957500: 0.137322\n",
      "2022-11-09 03:09:34,100 INFO     Training average positive_sample_loss at step 957600: 0.136268\n",
      "2022-11-09 03:09:34,100 INFO     Training average negative_sample_loss at step 957600: 0.135908\n",
      "2022-11-09 03:09:34,100 INFO     Training average loss at step 957600: 0.136088\n",
      "2022-11-09 03:09:37,203 INFO     Training average positive_sample_loss at step 957700: 0.135326\n",
      "2022-11-09 03:09:37,203 INFO     Training average negative_sample_loss at step 957700: 0.134069\n",
      "2022-11-09 03:09:37,203 INFO     Training average loss at step 957700: 0.134698\n",
      "2022-11-09 03:09:40,305 INFO     Training average positive_sample_loss at step 957800: 0.136393\n",
      "2022-11-09 03:09:40,305 INFO     Training average negative_sample_loss at step 957800: 0.131161\n",
      "2022-11-09 03:09:40,305 INFO     Training average loss at step 957800: 0.133777\n",
      "2022-11-09 03:09:43,404 INFO     Training average positive_sample_loss at step 957900: 0.138609\n",
      "2022-11-09 03:09:43,404 INFO     Training average negative_sample_loss at step 957900: 0.134483\n",
      "2022-11-09 03:09:43,404 INFO     Training average loss at step 957900: 0.136546\n",
      "2022-11-09 03:09:46,505 INFO     Training average positive_sample_loss at step 958000: 0.135291\n",
      "2022-11-09 03:09:46,505 INFO     Training average negative_sample_loss at step 958000: 0.135441\n",
      "2022-11-09 03:09:46,505 INFO     Training average loss at step 958000: 0.135366\n",
      "2022-11-09 03:09:49,602 INFO     Training average positive_sample_loss at step 958100: 0.137187\n",
      "2022-11-09 03:09:49,602 INFO     Training average negative_sample_loss at step 958100: 0.133590\n",
      "2022-11-09 03:09:49,602 INFO     Training average loss at step 958100: 0.135388\n",
      "2022-11-09 03:09:52,713 INFO     Training average positive_sample_loss at step 958200: 0.135879\n",
      "2022-11-09 03:09:52,713 INFO     Training average negative_sample_loss at step 958200: 0.133200\n",
      "2022-11-09 03:09:52,713 INFO     Training average loss at step 958200: 0.134539\n",
      "2022-11-09 03:09:55,813 INFO     Training average positive_sample_loss at step 958300: 0.134291\n",
      "2022-11-09 03:09:55,813 INFO     Training average negative_sample_loss at step 958300: 0.136006\n",
      "2022-11-09 03:09:55,813 INFO     Training average loss at step 958300: 0.135148\n",
      "2022-11-09 03:09:58,916 INFO     Training average positive_sample_loss at step 958400: 0.135748\n",
      "2022-11-09 03:09:58,916 INFO     Training average negative_sample_loss at step 958400: 0.133488\n",
      "2022-11-09 03:09:58,916 INFO     Training average loss at step 958400: 0.134618\n",
      "2022-11-09 03:10:02,023 INFO     Training average positive_sample_loss at step 958500: 0.133789\n",
      "2022-11-09 03:10:02,023 INFO     Training average negative_sample_loss at step 958500: 0.145215\n",
      "2022-11-09 03:10:02,023 INFO     Training average loss at step 958500: 0.139502\n",
      "2022-11-09 03:10:05,141 INFO     Training average positive_sample_loss at step 958600: 0.138074\n",
      "2022-11-09 03:10:05,141 INFO     Training average negative_sample_loss at step 958600: 0.134999\n",
      "2022-11-09 03:10:05,141 INFO     Training average loss at step 958600: 0.136537\n",
      "2022-11-09 03:10:08,240 INFO     Training average positive_sample_loss at step 958700: 0.138924\n",
      "2022-11-09 03:10:08,240 INFO     Training average negative_sample_loss at step 958700: 0.132440\n",
      "2022-11-09 03:10:08,240 INFO     Training average loss at step 958700: 0.135682\n",
      "2022-11-09 03:10:11,350 INFO     Training average positive_sample_loss at step 958800: 0.136753\n",
      "2022-11-09 03:10:11,350 INFO     Training average negative_sample_loss at step 958800: 0.132991\n",
      "2022-11-09 03:10:11,350 INFO     Training average loss at step 958800: 0.134872\n",
      "2022-11-09 03:10:14,449 INFO     Training average positive_sample_loss at step 958900: 0.138059\n",
      "2022-11-09 03:10:14,449 INFO     Training average negative_sample_loss at step 958900: 0.137093\n",
      "2022-11-09 03:10:14,449 INFO     Training average loss at step 958900: 0.137576\n",
      "2022-11-09 03:10:17,558 INFO     Training average positive_sample_loss at step 959000: 0.135171\n",
      "2022-11-09 03:10:17,558 INFO     Training average negative_sample_loss at step 959000: 0.136106\n",
      "2022-11-09 03:10:17,558 INFO     Training average loss at step 959000: 0.135638\n",
      "2022-11-09 03:10:20,658 INFO     Training average positive_sample_loss at step 959100: 0.135918\n",
      "2022-11-09 03:10:20,658 INFO     Training average negative_sample_loss at step 959100: 0.133355\n",
      "2022-11-09 03:10:20,658 INFO     Training average loss at step 959100: 0.134636\n",
      "2022-11-09 03:10:23,759 INFO     Training average positive_sample_loss at step 959200: 0.137330\n",
      "2022-11-09 03:10:23,759 INFO     Training average negative_sample_loss at step 959200: 0.131810\n",
      "2022-11-09 03:10:23,759 INFO     Training average loss at step 959200: 0.134570\n",
      "2022-11-09 03:10:26,866 INFO     Training average positive_sample_loss at step 959300: 0.134066\n",
      "2022-11-09 03:10:26,866 INFO     Training average negative_sample_loss at step 959300: 0.136960\n",
      "2022-11-09 03:10:26,866 INFO     Training average loss at step 959300: 0.135513\n",
      "2022-11-09 03:10:29,975 INFO     Training average positive_sample_loss at step 959400: 0.133921\n",
      "2022-11-09 03:10:29,975 INFO     Training average negative_sample_loss at step 959400: 0.136504\n",
      "2022-11-09 03:10:29,975 INFO     Training average loss at step 959400: 0.135212\n",
      "2022-11-09 03:10:33,080 INFO     Training average positive_sample_loss at step 959500: 0.133248\n",
      "2022-11-09 03:10:33,080 INFO     Training average negative_sample_loss at step 959500: 0.135115\n",
      "2022-11-09 03:10:33,080 INFO     Training average loss at step 959500: 0.134182\n",
      "2022-11-09 03:10:36,178 INFO     Training average positive_sample_loss at step 959600: 0.139670\n",
      "2022-11-09 03:10:36,178 INFO     Training average negative_sample_loss at step 959600: 0.133801\n",
      "2022-11-09 03:10:36,179 INFO     Training average loss at step 959600: 0.136735\n",
      "2022-11-09 03:10:39,278 INFO     Training average positive_sample_loss at step 959700: 0.136722\n",
      "2022-11-09 03:10:39,278 INFO     Training average negative_sample_loss at step 959700: 0.133914\n",
      "2022-11-09 03:10:39,278 INFO     Training average loss at step 959700: 0.135318\n",
      "2022-11-09 03:10:42,391 INFO     Training average positive_sample_loss at step 959800: 0.137772\n",
      "2022-11-09 03:10:42,391 INFO     Training average negative_sample_loss at step 959800: 0.128999\n",
      "2022-11-09 03:10:42,391 INFO     Training average loss at step 959800: 0.133385\n",
      "2022-11-09 03:10:45,492 INFO     Training average positive_sample_loss at step 959900: 0.137106\n",
      "2022-11-09 03:10:45,493 INFO     Training average negative_sample_loss at step 959900: 0.137229\n",
      "2022-11-09 03:10:45,493 INFO     Training average loss at step 959900: 0.137167\n",
      "2022-11-09 03:10:51,469 INFO     Training average positive_sample_loss at step 960000: 0.135201\n",
      "2022-11-09 03:10:51,469 INFO     Training average negative_sample_loss at step 960000: 0.129921\n",
      "2022-11-09 03:10:51,469 INFO     Training average loss at step 960000: 0.132561\n",
      "2022-11-09 03:10:57,868 INFO     Training average positive_sample_loss at step 960100: 0.138713\n",
      "2022-11-09 03:10:57,869 INFO     Training average negative_sample_loss at step 960100: 0.133307\n",
      "2022-11-09 03:10:57,869 INFO     Training average loss at step 960100: 0.136010\n",
      "2022-11-09 03:11:00,979 INFO     Training average positive_sample_loss at step 960200: 0.136549\n",
      "2022-11-09 03:11:00,979 INFO     Training average negative_sample_loss at step 960200: 0.132551\n",
      "2022-11-09 03:11:00,979 INFO     Training average loss at step 960200: 0.134550\n",
      "2022-11-09 03:11:04,096 INFO     Training average positive_sample_loss at step 960300: 0.139261\n",
      "2022-11-09 03:11:04,096 INFO     Training average negative_sample_loss at step 960300: 0.131930\n",
      "2022-11-09 03:11:04,096 INFO     Training average loss at step 960300: 0.135596\n",
      "2022-11-09 03:11:07,209 INFO     Training average positive_sample_loss at step 960400: 0.134714\n",
      "2022-11-09 03:11:07,209 INFO     Training average negative_sample_loss at step 960400: 0.134645\n",
      "2022-11-09 03:11:07,210 INFO     Training average loss at step 960400: 0.134679\n",
      "2022-11-09 03:11:10,332 INFO     Training average positive_sample_loss at step 960500: 0.133673\n",
      "2022-11-09 03:11:10,332 INFO     Training average negative_sample_loss at step 960500: 0.136270\n",
      "2022-11-09 03:11:10,332 INFO     Training average loss at step 960500: 0.134972\n",
      "2022-11-09 03:11:13,443 INFO     Training average positive_sample_loss at step 960600: 0.134824\n",
      "2022-11-09 03:11:13,443 INFO     Training average negative_sample_loss at step 960600: 0.133447\n",
      "2022-11-09 03:11:13,444 INFO     Training average loss at step 960600: 0.134135\n",
      "2022-11-09 03:11:16,558 INFO     Training average positive_sample_loss at step 960700: 0.132930\n",
      "2022-11-09 03:11:16,559 INFO     Training average negative_sample_loss at step 960700: 0.129195\n",
      "2022-11-09 03:11:16,559 INFO     Training average loss at step 960700: 0.131063\n",
      "2022-11-09 03:11:19,671 INFO     Training average positive_sample_loss at step 960800: 0.138180\n",
      "2022-11-09 03:11:19,671 INFO     Training average negative_sample_loss at step 960800: 0.137502\n",
      "2022-11-09 03:11:19,671 INFO     Training average loss at step 960800: 0.137841\n",
      "2022-11-09 03:11:22,781 INFO     Training average positive_sample_loss at step 960900: 0.136305\n",
      "2022-11-09 03:11:22,781 INFO     Training average negative_sample_loss at step 960900: 0.139535\n",
      "2022-11-09 03:11:22,781 INFO     Training average loss at step 960900: 0.137920\n",
      "2022-11-09 03:11:25,895 INFO     Training average positive_sample_loss at step 961000: 0.136395\n",
      "2022-11-09 03:11:25,895 INFO     Training average negative_sample_loss at step 961000: 0.134578\n",
      "2022-11-09 03:11:25,895 INFO     Training average loss at step 961000: 0.135486\n",
      "2022-11-09 03:11:29,003 INFO     Training average positive_sample_loss at step 961100: 0.138756\n",
      "2022-11-09 03:11:29,003 INFO     Training average negative_sample_loss at step 961100: 0.133594\n",
      "2022-11-09 03:11:29,003 INFO     Training average loss at step 961100: 0.136175\n",
      "2022-11-09 03:11:32,116 INFO     Training average positive_sample_loss at step 961200: 0.131722\n",
      "2022-11-09 03:11:32,116 INFO     Training average negative_sample_loss at step 961200: 0.131754\n",
      "2022-11-09 03:11:32,116 INFO     Training average loss at step 961200: 0.131738\n",
      "2022-11-09 03:11:35,229 INFO     Training average positive_sample_loss at step 961300: 0.141870\n",
      "2022-11-09 03:11:35,229 INFO     Training average negative_sample_loss at step 961300: 0.135593\n",
      "2022-11-09 03:11:35,229 INFO     Training average loss at step 961300: 0.138731\n",
      "2022-11-09 03:11:38,334 INFO     Training average positive_sample_loss at step 961400: 0.137948\n",
      "2022-11-09 03:11:38,334 INFO     Training average negative_sample_loss at step 961400: 0.132488\n",
      "2022-11-09 03:11:38,334 INFO     Training average loss at step 961400: 0.135218\n",
      "2022-11-09 03:11:41,441 INFO     Training average positive_sample_loss at step 961500: 0.137784\n",
      "2022-11-09 03:11:41,441 INFO     Training average negative_sample_loss at step 961500: 0.133245\n",
      "2022-11-09 03:11:41,441 INFO     Training average loss at step 961500: 0.135514\n",
      "2022-11-09 03:11:44,539 INFO     Training average positive_sample_loss at step 961600: 0.134705\n",
      "2022-11-09 03:11:44,539 INFO     Training average negative_sample_loss at step 961600: 0.134584\n",
      "2022-11-09 03:11:44,539 INFO     Training average loss at step 961600: 0.134645\n",
      "2022-11-09 03:11:47,642 INFO     Training average positive_sample_loss at step 961700: 0.136954\n",
      "2022-11-09 03:11:47,643 INFO     Training average negative_sample_loss at step 961700: 0.136153\n",
      "2022-11-09 03:11:47,643 INFO     Training average loss at step 961700: 0.136554\n",
      "2022-11-09 03:11:50,751 INFO     Training average positive_sample_loss at step 961800: 0.133363\n",
      "2022-11-09 03:11:50,751 INFO     Training average negative_sample_loss at step 961800: 0.137924\n",
      "2022-11-09 03:11:50,751 INFO     Training average loss at step 961800: 0.135644\n",
      "2022-11-09 03:11:53,835 INFO     Training average positive_sample_loss at step 961900: 0.136353\n",
      "2022-11-09 03:11:53,836 INFO     Training average negative_sample_loss at step 961900: 0.138652\n",
      "2022-11-09 03:11:53,836 INFO     Training average loss at step 961900: 0.137502\n",
      "2022-11-09 03:11:56,951 INFO     Training average positive_sample_loss at step 962000: 0.141080\n",
      "2022-11-09 03:11:56,951 INFO     Training average negative_sample_loss at step 962000: 0.136021\n",
      "2022-11-09 03:11:56,951 INFO     Training average loss at step 962000: 0.138551\n",
      "2022-11-09 03:12:00,058 INFO     Training average positive_sample_loss at step 962100: 0.133257\n",
      "2022-11-09 03:12:00,058 INFO     Training average negative_sample_loss at step 962100: 0.134378\n",
      "2022-11-09 03:12:00,058 INFO     Training average loss at step 962100: 0.133817\n",
      "2022-11-09 03:12:03,172 INFO     Training average positive_sample_loss at step 962200: 0.135239\n",
      "2022-11-09 03:12:03,172 INFO     Training average negative_sample_loss at step 962200: 0.134387\n",
      "2022-11-09 03:12:03,173 INFO     Training average loss at step 962200: 0.134813\n",
      "2022-11-09 03:12:06,270 INFO     Training average positive_sample_loss at step 962300: 0.134209\n",
      "2022-11-09 03:12:06,270 INFO     Training average negative_sample_loss at step 962300: 0.132006\n",
      "2022-11-09 03:12:06,270 INFO     Training average loss at step 962300: 0.133108\n",
      "2022-11-09 03:12:09,375 INFO     Training average positive_sample_loss at step 962400: 0.139332\n",
      "2022-11-09 03:12:09,375 INFO     Training average negative_sample_loss at step 962400: 0.135242\n",
      "2022-11-09 03:12:09,375 INFO     Training average loss at step 962400: 0.137287\n",
      "2022-11-09 03:12:12,483 INFO     Training average positive_sample_loss at step 962500: 0.139080\n",
      "2022-11-09 03:12:12,483 INFO     Training average negative_sample_loss at step 962500: 0.133744\n",
      "2022-11-09 03:12:12,483 INFO     Training average loss at step 962500: 0.136412\n",
      "2022-11-09 03:12:15,571 INFO     Training average positive_sample_loss at step 962600: 0.137514\n",
      "2022-11-09 03:12:15,571 INFO     Training average negative_sample_loss at step 962600: 0.128157\n",
      "2022-11-09 03:12:15,571 INFO     Training average loss at step 962600: 0.132835\n",
      "2022-11-09 03:12:18,678 INFO     Training average positive_sample_loss at step 962700: 0.140118\n",
      "2022-11-09 03:12:18,678 INFO     Training average negative_sample_loss at step 962700: 0.133307\n",
      "2022-11-09 03:12:18,678 INFO     Training average loss at step 962700: 0.136713\n",
      "2022-11-09 03:12:21,785 INFO     Training average positive_sample_loss at step 962800: 0.132873\n",
      "2022-11-09 03:12:21,786 INFO     Training average negative_sample_loss at step 962800: 0.136789\n",
      "2022-11-09 03:12:21,786 INFO     Training average loss at step 962800: 0.134831\n",
      "2022-11-09 03:12:24,893 INFO     Training average positive_sample_loss at step 962900: 0.134596\n",
      "2022-11-09 03:12:24,893 INFO     Training average negative_sample_loss at step 962900: 0.137694\n",
      "2022-11-09 03:12:24,893 INFO     Training average loss at step 962900: 0.136145\n",
      "2022-11-09 03:12:28,007 INFO     Training average positive_sample_loss at step 963000: 0.139458\n",
      "2022-11-09 03:12:28,007 INFO     Training average negative_sample_loss at step 963000: 0.133999\n",
      "2022-11-09 03:12:28,007 INFO     Training average loss at step 963000: 0.136728\n",
      "2022-11-09 03:12:31,117 INFO     Training average positive_sample_loss at step 963100: 0.138473\n",
      "2022-11-09 03:12:31,117 INFO     Training average negative_sample_loss at step 963100: 0.135593\n",
      "2022-11-09 03:12:31,118 INFO     Training average loss at step 963100: 0.137033\n",
      "2022-11-09 03:12:34,231 INFO     Training average positive_sample_loss at step 963200: 0.132393\n",
      "2022-11-09 03:12:34,231 INFO     Training average negative_sample_loss at step 963200: 0.134996\n",
      "2022-11-09 03:12:34,231 INFO     Training average loss at step 963200: 0.133694\n",
      "2022-11-09 03:12:37,351 INFO     Training average positive_sample_loss at step 963300: 0.143486\n",
      "2022-11-09 03:12:37,351 INFO     Training average negative_sample_loss at step 963300: 0.134115\n",
      "2022-11-09 03:12:37,351 INFO     Training average loss at step 963300: 0.138800\n",
      "2022-11-09 03:12:40,464 INFO     Training average positive_sample_loss at step 963400: 0.139433\n",
      "2022-11-09 03:12:40,464 INFO     Training average negative_sample_loss at step 963400: 0.134197\n",
      "2022-11-09 03:12:40,464 INFO     Training average loss at step 963400: 0.136815\n",
      "2022-11-09 03:12:43,572 INFO     Training average positive_sample_loss at step 963500: 0.140846\n",
      "2022-11-09 03:12:43,572 INFO     Training average negative_sample_loss at step 963500: 0.133078\n",
      "2022-11-09 03:12:43,572 INFO     Training average loss at step 963500: 0.136962\n",
      "2022-11-09 03:12:46,692 INFO     Training average positive_sample_loss at step 963600: 0.133645\n",
      "2022-11-09 03:12:46,692 INFO     Training average negative_sample_loss at step 963600: 0.133948\n",
      "2022-11-09 03:12:46,692 INFO     Training average loss at step 963600: 0.133796\n",
      "2022-11-09 03:12:49,809 INFO     Training average positive_sample_loss at step 963700: 0.137299\n",
      "2022-11-09 03:12:49,809 INFO     Training average negative_sample_loss at step 963700: 0.132991\n",
      "2022-11-09 03:12:49,809 INFO     Training average loss at step 963700: 0.135145\n",
      "2022-11-09 03:12:52,925 INFO     Training average positive_sample_loss at step 963800: 0.134116\n",
      "2022-11-09 03:12:52,925 INFO     Training average negative_sample_loss at step 963800: 0.137620\n",
      "2022-11-09 03:12:52,925 INFO     Training average loss at step 963800: 0.135868\n",
      "2022-11-09 03:12:56,036 INFO     Training average positive_sample_loss at step 963900: 0.136581\n",
      "2022-11-09 03:12:56,036 INFO     Training average negative_sample_loss at step 963900: 0.131019\n",
      "2022-11-09 03:12:56,036 INFO     Training average loss at step 963900: 0.133800\n",
      "2022-11-09 03:12:59,140 INFO     Training average positive_sample_loss at step 964000: 0.136087\n",
      "2022-11-09 03:12:59,140 INFO     Training average negative_sample_loss at step 964000: 0.137950\n",
      "2022-11-09 03:12:59,140 INFO     Training average loss at step 964000: 0.137018\n",
      "2022-11-09 03:13:02,233 INFO     Training average positive_sample_loss at step 964100: 0.130931\n",
      "2022-11-09 03:13:02,233 INFO     Training average negative_sample_loss at step 964100: 0.132006\n",
      "2022-11-09 03:13:02,233 INFO     Training average loss at step 964100: 0.131468\n",
      "2022-11-09 03:13:05,333 INFO     Training average positive_sample_loss at step 964200: 0.141263\n",
      "2022-11-09 03:13:05,333 INFO     Training average negative_sample_loss at step 964200: 0.135115\n",
      "2022-11-09 03:13:05,333 INFO     Training average loss at step 964200: 0.138189\n",
      "2022-11-09 03:13:08,442 INFO     Training average positive_sample_loss at step 964300: 0.138215\n",
      "2022-11-09 03:13:08,442 INFO     Training average negative_sample_loss at step 964300: 0.137931\n",
      "2022-11-09 03:13:08,442 INFO     Training average loss at step 964300: 0.138073\n",
      "2022-11-09 03:13:11,548 INFO     Training average positive_sample_loss at step 964400: 0.137941\n",
      "2022-11-09 03:13:11,548 INFO     Training average negative_sample_loss at step 964400: 0.136536\n",
      "2022-11-09 03:13:11,548 INFO     Training average loss at step 964400: 0.137239\n",
      "2022-11-09 03:13:14,648 INFO     Training average positive_sample_loss at step 964500: 0.137515\n",
      "2022-11-09 03:13:14,648 INFO     Training average negative_sample_loss at step 964500: 0.131522\n",
      "2022-11-09 03:13:14,648 INFO     Training average loss at step 964500: 0.134518\n",
      "2022-11-09 03:13:17,755 INFO     Training average positive_sample_loss at step 964600: 0.136798\n",
      "2022-11-09 03:13:17,755 INFO     Training average negative_sample_loss at step 964600: 0.130786\n",
      "2022-11-09 03:13:17,755 INFO     Training average loss at step 964600: 0.133792\n",
      "2022-11-09 03:13:20,860 INFO     Training average positive_sample_loss at step 964700: 0.133785\n",
      "2022-11-09 03:13:20,860 INFO     Training average negative_sample_loss at step 964700: 0.133790\n",
      "2022-11-09 03:13:20,860 INFO     Training average loss at step 964700: 0.133787\n",
      "2022-11-09 03:13:27,029 INFO     Training average positive_sample_loss at step 964800: 0.134559\n",
      "2022-11-09 03:13:27,029 INFO     Training average negative_sample_loss at step 964800: 0.132446\n",
      "2022-11-09 03:13:27,029 INFO     Training average loss at step 964800: 0.133503\n",
      "2022-11-09 03:13:30,141 INFO     Training average positive_sample_loss at step 964900: 0.142245\n",
      "2022-11-09 03:13:30,141 INFO     Training average negative_sample_loss at step 964900: 0.136904\n",
      "2022-11-09 03:13:30,141 INFO     Training average loss at step 964900: 0.139574\n",
      "2022-11-09 03:13:33,251 INFO     Training average positive_sample_loss at step 965000: 0.132606\n",
      "2022-11-09 03:13:33,251 INFO     Training average negative_sample_loss at step 965000: 0.135704\n",
      "2022-11-09 03:13:33,251 INFO     Training average loss at step 965000: 0.134155\n",
      "2022-11-09 03:13:36,358 INFO     Training average positive_sample_loss at step 965100: 0.133108\n",
      "2022-11-09 03:13:36,358 INFO     Training average negative_sample_loss at step 965100: 0.132155\n",
      "2022-11-09 03:13:36,358 INFO     Training average loss at step 965100: 0.132631\n",
      "2022-11-09 03:13:39,480 INFO     Training average positive_sample_loss at step 965200: 0.132213\n",
      "2022-11-09 03:13:39,480 INFO     Training average negative_sample_loss at step 965200: 0.132587\n",
      "2022-11-09 03:13:39,480 INFO     Training average loss at step 965200: 0.132400\n",
      "2022-11-09 03:13:42,599 INFO     Training average positive_sample_loss at step 965300: 0.137900\n",
      "2022-11-09 03:13:42,599 INFO     Training average negative_sample_loss at step 965300: 0.132645\n",
      "2022-11-09 03:13:42,599 INFO     Training average loss at step 965300: 0.135272\n",
      "2022-11-09 03:13:45,719 INFO     Training average positive_sample_loss at step 965400: 0.141003\n",
      "2022-11-09 03:13:45,719 INFO     Training average negative_sample_loss at step 965400: 0.132797\n",
      "2022-11-09 03:13:45,720 INFO     Training average loss at step 965400: 0.136900\n",
      "2022-11-09 03:13:48,833 INFO     Training average positive_sample_loss at step 965500: 0.136401\n",
      "2022-11-09 03:13:48,833 INFO     Training average negative_sample_loss at step 965500: 0.134611\n",
      "2022-11-09 03:13:48,833 INFO     Training average loss at step 965500: 0.135506\n",
      "2022-11-09 03:13:51,951 INFO     Training average positive_sample_loss at step 965600: 0.138926\n",
      "2022-11-09 03:13:51,951 INFO     Training average negative_sample_loss at step 965600: 0.128588\n",
      "2022-11-09 03:13:51,951 INFO     Training average loss at step 965600: 0.133757\n",
      "2022-11-09 03:13:55,070 INFO     Training average positive_sample_loss at step 965700: 0.139148\n",
      "2022-11-09 03:13:55,071 INFO     Training average negative_sample_loss at step 965700: 0.133619\n",
      "2022-11-09 03:13:55,071 INFO     Training average loss at step 965700: 0.136383\n",
      "2022-11-09 03:13:58,188 INFO     Training average positive_sample_loss at step 965800: 0.140942\n",
      "2022-11-09 03:13:58,188 INFO     Training average negative_sample_loss at step 965800: 0.135973\n",
      "2022-11-09 03:13:58,188 INFO     Training average loss at step 965800: 0.138458\n",
      "2022-11-09 03:14:01,305 INFO     Training average positive_sample_loss at step 965900: 0.139413\n",
      "2022-11-09 03:14:01,305 INFO     Training average negative_sample_loss at step 965900: 0.137895\n",
      "2022-11-09 03:14:01,305 INFO     Training average loss at step 965900: 0.138654\n",
      "2022-11-09 03:14:04,412 INFO     Training average positive_sample_loss at step 966000: 0.133039\n",
      "2022-11-09 03:14:04,412 INFO     Training average negative_sample_loss at step 966000: 0.132153\n",
      "2022-11-09 03:14:04,412 INFO     Training average loss at step 966000: 0.132596\n",
      "2022-11-09 03:14:07,530 INFO     Training average positive_sample_loss at step 966100: 0.135009\n",
      "2022-11-09 03:14:07,530 INFO     Training average negative_sample_loss at step 966100: 0.130026\n",
      "2022-11-09 03:14:07,530 INFO     Training average loss at step 966100: 0.132517\n",
      "2022-11-09 03:14:10,655 INFO     Training average positive_sample_loss at step 966200: 0.140495\n",
      "2022-11-09 03:14:10,655 INFO     Training average negative_sample_loss at step 966200: 0.132182\n",
      "2022-11-09 03:14:10,656 INFO     Training average loss at step 966200: 0.136339\n",
      "2022-11-09 03:14:13,766 INFO     Training average positive_sample_loss at step 966300: 0.138454\n",
      "2022-11-09 03:14:13,766 INFO     Training average negative_sample_loss at step 966300: 0.134660\n",
      "2022-11-09 03:14:13,766 INFO     Training average loss at step 966300: 0.136557\n",
      "2022-11-09 03:14:16,872 INFO     Training average positive_sample_loss at step 966400: 0.134066\n",
      "2022-11-09 03:14:16,872 INFO     Training average negative_sample_loss at step 966400: 0.135632\n",
      "2022-11-09 03:14:16,872 INFO     Training average loss at step 966400: 0.134849\n",
      "2022-11-09 03:14:19,992 INFO     Training average positive_sample_loss at step 966500: 0.138786\n",
      "2022-11-09 03:14:19,992 INFO     Training average negative_sample_loss at step 966500: 0.137245\n",
      "2022-11-09 03:14:19,992 INFO     Training average loss at step 966500: 0.138015\n",
      "2022-11-09 03:14:23,098 INFO     Training average positive_sample_loss at step 966600: 0.136466\n",
      "2022-11-09 03:14:23,098 INFO     Training average negative_sample_loss at step 966600: 0.135976\n",
      "2022-11-09 03:14:23,098 INFO     Training average loss at step 966600: 0.136221\n",
      "2022-11-09 03:14:26,218 INFO     Training average positive_sample_loss at step 966700: 0.137864\n",
      "2022-11-09 03:14:26,218 INFO     Training average negative_sample_loss at step 966700: 0.135856\n",
      "2022-11-09 03:14:26,218 INFO     Training average loss at step 966700: 0.136860\n",
      "2022-11-09 03:14:29,325 INFO     Training average positive_sample_loss at step 966800: 0.136378\n",
      "2022-11-09 03:14:29,325 INFO     Training average negative_sample_loss at step 966800: 0.131724\n",
      "2022-11-09 03:14:29,325 INFO     Training average loss at step 966800: 0.134051\n",
      "2022-11-09 03:14:32,430 INFO     Training average positive_sample_loss at step 966900: 0.138131\n",
      "2022-11-09 03:14:32,430 INFO     Training average negative_sample_loss at step 966900: 0.137992\n",
      "2022-11-09 03:14:32,430 INFO     Training average loss at step 966900: 0.138061\n",
      "2022-11-09 03:14:35,540 INFO     Training average positive_sample_loss at step 967000: 0.140760\n",
      "2022-11-09 03:14:35,540 INFO     Training average negative_sample_loss at step 967000: 0.132866\n",
      "2022-11-09 03:14:35,540 INFO     Training average loss at step 967000: 0.136813\n",
      "2022-11-09 03:14:38,668 INFO     Training average positive_sample_loss at step 967100: 0.136492\n",
      "2022-11-09 03:14:38,669 INFO     Training average negative_sample_loss at step 967100: 0.132074\n",
      "2022-11-09 03:14:38,669 INFO     Training average loss at step 967100: 0.134283\n",
      "2022-11-09 03:14:41,784 INFO     Training average positive_sample_loss at step 967200: 0.137746\n",
      "2022-11-09 03:14:41,784 INFO     Training average negative_sample_loss at step 967200: 0.134837\n",
      "2022-11-09 03:14:41,784 INFO     Training average loss at step 967200: 0.136291\n",
      "2022-11-09 03:14:44,903 INFO     Training average positive_sample_loss at step 967300: 0.138360\n",
      "2022-11-09 03:14:44,903 INFO     Training average negative_sample_loss at step 967300: 0.133749\n",
      "2022-11-09 03:14:44,903 INFO     Training average loss at step 967300: 0.136055\n",
      "2022-11-09 03:14:48,028 INFO     Training average positive_sample_loss at step 967400: 0.135389\n",
      "2022-11-09 03:14:48,028 INFO     Training average negative_sample_loss at step 967400: 0.130446\n",
      "2022-11-09 03:14:48,028 INFO     Training average loss at step 967400: 0.132918\n",
      "2022-11-09 03:14:51,135 INFO     Training average positive_sample_loss at step 967500: 0.139430\n",
      "2022-11-09 03:14:51,135 INFO     Training average negative_sample_loss at step 967500: 0.133434\n",
      "2022-11-09 03:14:51,135 INFO     Training average loss at step 967500: 0.136432\n",
      "2022-11-09 03:14:54,241 INFO     Training average positive_sample_loss at step 967600: 0.134070\n",
      "2022-11-09 03:14:54,241 INFO     Training average negative_sample_loss at step 967600: 0.137706\n",
      "2022-11-09 03:14:54,241 INFO     Training average loss at step 967600: 0.135888\n",
      "2022-11-09 03:14:57,359 INFO     Training average positive_sample_loss at step 967700: 0.141403\n",
      "2022-11-09 03:14:57,359 INFO     Training average negative_sample_loss at step 967700: 0.132820\n",
      "2022-11-09 03:14:57,359 INFO     Training average loss at step 967700: 0.137112\n",
      "2022-11-09 03:15:00,478 INFO     Training average positive_sample_loss at step 967800: 0.140038\n",
      "2022-11-09 03:15:00,478 INFO     Training average negative_sample_loss at step 967800: 0.134377\n",
      "2022-11-09 03:15:00,478 INFO     Training average loss at step 967800: 0.137207\n",
      "2022-11-09 03:15:03,607 INFO     Training average positive_sample_loss at step 967900: 0.136147\n",
      "2022-11-09 03:15:03,607 INFO     Training average negative_sample_loss at step 967900: 0.134057\n",
      "2022-11-09 03:15:03,607 INFO     Training average loss at step 967900: 0.135102\n",
      "2022-11-09 03:15:06,741 INFO     Training average positive_sample_loss at step 968000: 0.136013\n",
      "2022-11-09 03:15:06,741 INFO     Training average negative_sample_loss at step 968000: 0.128077\n",
      "2022-11-09 03:15:06,741 INFO     Training average loss at step 968000: 0.132045\n",
      "2022-11-09 03:15:09,860 INFO     Training average positive_sample_loss at step 968100: 0.133669\n",
      "2022-11-09 03:15:09,860 INFO     Training average negative_sample_loss at step 968100: 0.135327\n",
      "2022-11-09 03:15:09,860 INFO     Training average loss at step 968100: 0.134498\n",
      "2022-11-09 03:15:12,976 INFO     Training average positive_sample_loss at step 968200: 0.136065\n",
      "2022-11-09 03:15:12,977 INFO     Training average negative_sample_loss at step 968200: 0.137271\n",
      "2022-11-09 03:15:12,977 INFO     Training average loss at step 968200: 0.136668\n",
      "2022-11-09 03:15:16,084 INFO     Training average positive_sample_loss at step 968300: 0.135928\n",
      "2022-11-09 03:15:16,084 INFO     Training average negative_sample_loss at step 968300: 0.133364\n",
      "2022-11-09 03:15:16,084 INFO     Training average loss at step 968300: 0.134646\n",
      "2022-11-09 03:15:19,202 INFO     Training average positive_sample_loss at step 968400: 0.136893\n",
      "2022-11-09 03:15:19,202 INFO     Training average negative_sample_loss at step 968400: 0.136519\n",
      "2022-11-09 03:15:19,202 INFO     Training average loss at step 968400: 0.136706\n",
      "2022-11-09 03:15:22,308 INFO     Training average positive_sample_loss at step 968500: 0.136738\n",
      "2022-11-09 03:15:22,309 INFO     Training average negative_sample_loss at step 968500: 0.136466\n",
      "2022-11-09 03:15:22,309 INFO     Training average loss at step 968500: 0.136602\n",
      "2022-11-09 03:15:25,420 INFO     Training average positive_sample_loss at step 968600: 0.141068\n",
      "2022-11-09 03:15:25,420 INFO     Training average negative_sample_loss at step 968600: 0.134546\n",
      "2022-11-09 03:15:25,420 INFO     Training average loss at step 968600: 0.137807\n",
      "2022-11-09 03:15:28,525 INFO     Training average positive_sample_loss at step 968700: 0.135333\n",
      "2022-11-09 03:15:28,525 INFO     Training average negative_sample_loss at step 968700: 0.132069\n",
      "2022-11-09 03:15:28,525 INFO     Training average loss at step 968700: 0.133701\n",
      "2022-11-09 03:15:31,626 INFO     Training average positive_sample_loss at step 968800: 0.137712\n",
      "2022-11-09 03:15:31,626 INFO     Training average negative_sample_loss at step 968800: 0.133982\n",
      "2022-11-09 03:15:31,626 INFO     Training average loss at step 968800: 0.135847\n",
      "2022-11-09 03:15:34,733 INFO     Training average positive_sample_loss at step 968900: 0.134788\n",
      "2022-11-09 03:15:34,733 INFO     Training average negative_sample_loss at step 968900: 0.136859\n",
      "2022-11-09 03:15:34,733 INFO     Training average loss at step 968900: 0.135823\n",
      "2022-11-09 03:15:37,840 INFO     Training average positive_sample_loss at step 969000: 0.136818\n",
      "2022-11-09 03:15:37,840 INFO     Training average negative_sample_loss at step 969000: 0.134653\n",
      "2022-11-09 03:15:37,840 INFO     Training average loss at step 969000: 0.135736\n",
      "2022-11-09 03:15:40,958 INFO     Training average positive_sample_loss at step 969100: 0.142191\n",
      "2022-11-09 03:15:40,958 INFO     Training average negative_sample_loss at step 969100: 0.133333\n",
      "2022-11-09 03:15:40,958 INFO     Training average loss at step 969100: 0.137762\n",
      "2022-11-09 03:15:44,068 INFO     Training average positive_sample_loss at step 969200: 0.132902\n",
      "2022-11-09 03:15:44,068 INFO     Training average negative_sample_loss at step 969200: 0.131926\n",
      "2022-11-09 03:15:44,068 INFO     Training average loss at step 969200: 0.132414\n",
      "2022-11-09 03:15:48,630 INFO     Training average positive_sample_loss at step 969300: 0.142985\n",
      "2022-11-09 03:15:48,630 INFO     Training average negative_sample_loss at step 969300: 0.133282\n",
      "2022-11-09 03:15:48,630 INFO     Training average loss at step 969300: 0.138133\n",
      "2022-11-09 03:15:53,151 INFO     Training average positive_sample_loss at step 969400: 0.136085\n",
      "2022-11-09 03:15:53,151 INFO     Training average negative_sample_loss at step 969400: 0.134151\n",
      "2022-11-09 03:15:53,151 INFO     Training average loss at step 969400: 0.135118\n",
      "2022-11-09 03:15:56,399 INFO     Training average positive_sample_loss at step 969500: 0.135093\n",
      "2022-11-09 03:15:56,399 INFO     Training average negative_sample_loss at step 969500: 0.136145\n",
      "2022-11-09 03:15:56,399 INFO     Training average loss at step 969500: 0.135619\n",
      "2022-11-09 03:15:59,509 INFO     Training average positive_sample_loss at step 969600: 0.135278\n",
      "2022-11-09 03:15:59,509 INFO     Training average negative_sample_loss at step 969600: 0.134061\n",
      "2022-11-09 03:15:59,509 INFO     Training average loss at step 969600: 0.134670\n",
      "2022-11-09 03:16:02,613 INFO     Training average positive_sample_loss at step 969700: 0.134636\n",
      "2022-11-09 03:16:02,613 INFO     Training average negative_sample_loss at step 969700: 0.133630\n",
      "2022-11-09 03:16:02,613 INFO     Training average loss at step 969700: 0.134133\n",
      "2022-11-09 03:16:05,718 INFO     Training average positive_sample_loss at step 969800: 0.138694\n",
      "2022-11-09 03:16:05,718 INFO     Training average negative_sample_loss at step 969800: 0.136162\n",
      "2022-11-09 03:16:05,718 INFO     Training average loss at step 969800: 0.137428\n",
      "2022-11-09 03:16:08,825 INFO     Training average positive_sample_loss at step 969900: 0.137256\n",
      "2022-11-09 03:16:08,825 INFO     Training average negative_sample_loss at step 969900: 0.131850\n",
      "2022-11-09 03:16:08,825 INFO     Training average loss at step 969900: 0.134553\n",
      "2022-11-09 03:16:14,846 INFO     Training average positive_sample_loss at step 970000: 0.136824\n",
      "2022-11-09 03:16:14,846 INFO     Training average negative_sample_loss at step 970000: 0.134534\n",
      "2022-11-09 03:16:14,846 INFO     Training average loss at step 970000: 0.135679\n",
      "2022-11-09 03:16:17,949 INFO     Training average positive_sample_loss at step 970100: 0.141704\n",
      "2022-11-09 03:16:17,949 INFO     Training average negative_sample_loss at step 970100: 0.133149\n",
      "2022-11-09 03:16:17,949 INFO     Training average loss at step 970100: 0.137427\n",
      "2022-11-09 03:16:21,052 INFO     Training average positive_sample_loss at step 970200: 0.138709\n",
      "2022-11-09 03:16:21,053 INFO     Training average negative_sample_loss at step 970200: 0.134040\n",
      "2022-11-09 03:16:21,053 INFO     Training average loss at step 970200: 0.136375\n",
      "2022-11-09 03:16:24,176 INFO     Training average positive_sample_loss at step 970300: 0.137504\n",
      "2022-11-09 03:16:24,176 INFO     Training average negative_sample_loss at step 970300: 0.136680\n",
      "2022-11-09 03:16:24,176 INFO     Training average loss at step 970300: 0.137092\n",
      "2022-11-09 03:16:27,300 INFO     Training average positive_sample_loss at step 970400: 0.133579\n",
      "2022-11-09 03:16:27,300 INFO     Training average negative_sample_loss at step 970400: 0.131308\n",
      "2022-11-09 03:16:27,300 INFO     Training average loss at step 970400: 0.132444\n",
      "2022-11-09 03:16:30,425 INFO     Training average positive_sample_loss at step 970500: 0.136257\n",
      "2022-11-09 03:16:30,425 INFO     Training average negative_sample_loss at step 970500: 0.132590\n",
      "2022-11-09 03:16:30,425 INFO     Training average loss at step 970500: 0.134424\n",
      "2022-11-09 03:16:33,542 INFO     Training average positive_sample_loss at step 970600: 0.136590\n",
      "2022-11-09 03:16:33,542 INFO     Training average negative_sample_loss at step 970600: 0.135596\n",
      "2022-11-09 03:16:33,542 INFO     Training average loss at step 970600: 0.136093\n",
      "2022-11-09 03:16:36,652 INFO     Training average positive_sample_loss at step 970700: 0.135280\n",
      "2022-11-09 03:16:36,652 INFO     Training average negative_sample_loss at step 970700: 0.137914\n",
      "2022-11-09 03:16:36,652 INFO     Training average loss at step 970700: 0.136597\n",
      "2022-11-09 03:16:39,751 INFO     Training average positive_sample_loss at step 970800: 0.136250\n",
      "2022-11-09 03:16:39,751 INFO     Training average negative_sample_loss at step 970800: 0.136659\n",
      "2022-11-09 03:16:39,751 INFO     Training average loss at step 970800: 0.136454\n",
      "2022-11-09 03:16:42,874 INFO     Training average positive_sample_loss at step 970900: 0.137940\n",
      "2022-11-09 03:16:42,874 INFO     Training average negative_sample_loss at step 970900: 0.137359\n",
      "2022-11-09 03:16:42,874 INFO     Training average loss at step 970900: 0.137650\n",
      "2022-11-09 03:16:45,985 INFO     Training average positive_sample_loss at step 971000: 0.137580\n",
      "2022-11-09 03:16:45,985 INFO     Training average negative_sample_loss at step 971000: 0.133680\n",
      "2022-11-09 03:16:45,986 INFO     Training average loss at step 971000: 0.135630\n",
      "2022-11-09 03:16:49,085 INFO     Training average positive_sample_loss at step 971100: 0.135505\n",
      "2022-11-09 03:16:49,085 INFO     Training average negative_sample_loss at step 971100: 0.131422\n",
      "2022-11-09 03:16:49,085 INFO     Training average loss at step 971100: 0.133464\n",
      "2022-11-09 03:16:52,197 INFO     Training average positive_sample_loss at step 971200: 0.139387\n",
      "2022-11-09 03:16:52,198 INFO     Training average negative_sample_loss at step 971200: 0.131677\n",
      "2022-11-09 03:16:52,198 INFO     Training average loss at step 971200: 0.135532\n",
      "2022-11-09 03:16:55,301 INFO     Training average positive_sample_loss at step 971300: 0.129625\n",
      "2022-11-09 03:16:55,301 INFO     Training average negative_sample_loss at step 971300: 0.135150\n",
      "2022-11-09 03:16:55,301 INFO     Training average loss at step 971300: 0.132388\n",
      "2022-11-09 03:16:58,419 INFO     Training average positive_sample_loss at step 971400: 0.141149\n",
      "2022-11-09 03:16:58,419 INFO     Training average negative_sample_loss at step 971400: 0.138261\n",
      "2022-11-09 03:16:58,419 INFO     Training average loss at step 971400: 0.139705\n",
      "2022-11-09 03:17:01,549 INFO     Training average positive_sample_loss at step 971500: 0.134738\n",
      "2022-11-09 03:17:01,549 INFO     Training average negative_sample_loss at step 971500: 0.129979\n",
      "2022-11-09 03:17:01,549 INFO     Training average loss at step 971500: 0.132359\n",
      "2022-11-09 03:17:04,654 INFO     Training average positive_sample_loss at step 971600: 0.134810\n",
      "2022-11-09 03:17:04,654 INFO     Training average negative_sample_loss at step 971600: 0.132839\n",
      "2022-11-09 03:17:04,654 INFO     Training average loss at step 971600: 0.133825\n",
      "2022-11-09 03:17:07,759 INFO     Training average positive_sample_loss at step 971700: 0.138953\n",
      "2022-11-09 03:17:07,759 INFO     Training average negative_sample_loss at step 971700: 0.130212\n",
      "2022-11-09 03:17:07,759 INFO     Training average loss at step 971700: 0.134582\n",
      "2022-11-09 03:17:10,863 INFO     Training average positive_sample_loss at step 971800: 0.134390\n",
      "2022-11-09 03:17:10,863 INFO     Training average negative_sample_loss at step 971800: 0.136392\n",
      "2022-11-09 03:17:10,863 INFO     Training average loss at step 971800: 0.135391\n",
      "2022-11-09 03:17:13,964 INFO     Training average positive_sample_loss at step 971900: 0.140327\n",
      "2022-11-09 03:17:13,964 INFO     Training average negative_sample_loss at step 971900: 0.132388\n",
      "2022-11-09 03:17:13,964 INFO     Training average loss at step 971900: 0.136358\n",
      "2022-11-09 03:17:17,075 INFO     Training average positive_sample_loss at step 972000: 0.133240\n",
      "2022-11-09 03:17:17,075 INFO     Training average negative_sample_loss at step 972000: 0.132614\n",
      "2022-11-09 03:17:17,075 INFO     Training average loss at step 972000: 0.132927\n",
      "2022-11-09 03:17:20,176 INFO     Training average positive_sample_loss at step 972100: 0.136909\n",
      "2022-11-09 03:17:20,177 INFO     Training average negative_sample_loss at step 972100: 0.132973\n",
      "2022-11-09 03:17:20,177 INFO     Training average loss at step 972100: 0.134941\n",
      "2022-11-09 03:17:23,294 INFO     Training average positive_sample_loss at step 972200: 0.135155\n",
      "2022-11-09 03:17:23,294 INFO     Training average negative_sample_loss at step 972200: 0.135574\n",
      "2022-11-09 03:17:23,294 INFO     Training average loss at step 972200: 0.135365\n",
      "2022-11-09 03:17:26,391 INFO     Training average positive_sample_loss at step 972300: 0.137475\n",
      "2022-11-09 03:17:26,391 INFO     Training average negative_sample_loss at step 972300: 0.133672\n",
      "2022-11-09 03:17:26,391 INFO     Training average loss at step 972300: 0.135574\n",
      "2022-11-09 03:17:29,514 INFO     Training average positive_sample_loss at step 972400: 0.137782\n",
      "2022-11-09 03:17:29,514 INFO     Training average negative_sample_loss at step 972400: 0.134522\n",
      "2022-11-09 03:17:29,514 INFO     Training average loss at step 972400: 0.136152\n",
      "2022-11-09 03:17:32,643 INFO     Training average positive_sample_loss at step 972500: 0.141027\n",
      "2022-11-09 03:17:32,643 INFO     Training average negative_sample_loss at step 972500: 0.132701\n",
      "2022-11-09 03:17:32,643 INFO     Training average loss at step 972500: 0.136864\n",
      "2022-11-09 03:17:35,739 INFO     Training average positive_sample_loss at step 972600: 0.137326\n",
      "2022-11-09 03:17:35,739 INFO     Training average negative_sample_loss at step 972600: 0.133865\n",
      "2022-11-09 03:17:35,739 INFO     Training average loss at step 972600: 0.135596\n",
      "2022-11-09 03:17:38,851 INFO     Training average positive_sample_loss at step 972700: 0.136348\n",
      "2022-11-09 03:17:38,852 INFO     Training average negative_sample_loss at step 972700: 0.137322\n",
      "2022-11-09 03:17:38,852 INFO     Training average loss at step 972700: 0.136835\n",
      "2022-11-09 03:17:41,980 INFO     Training average positive_sample_loss at step 972800: 0.140280\n",
      "2022-11-09 03:17:41,980 INFO     Training average negative_sample_loss at step 972800: 0.134783\n",
      "2022-11-09 03:17:41,980 INFO     Training average loss at step 972800: 0.137532\n",
      "2022-11-09 03:17:45,103 INFO     Training average positive_sample_loss at step 972900: 0.137338\n",
      "2022-11-09 03:17:45,103 INFO     Training average negative_sample_loss at step 972900: 0.135856\n",
      "2022-11-09 03:17:45,103 INFO     Training average loss at step 972900: 0.136597\n",
      "2022-11-09 03:17:48,229 INFO     Training average positive_sample_loss at step 973000: 0.135288\n",
      "2022-11-09 03:17:48,229 INFO     Training average negative_sample_loss at step 973000: 0.133585\n",
      "2022-11-09 03:17:48,229 INFO     Training average loss at step 973000: 0.134437\n",
      "2022-11-09 03:17:51,357 INFO     Training average positive_sample_loss at step 973100: 0.137048\n",
      "2022-11-09 03:17:51,357 INFO     Training average negative_sample_loss at step 973100: 0.134061\n",
      "2022-11-09 03:17:51,357 INFO     Training average loss at step 973100: 0.135554\n",
      "2022-11-09 03:17:54,468 INFO     Training average positive_sample_loss at step 973200: 0.137087\n",
      "2022-11-09 03:17:54,468 INFO     Training average negative_sample_loss at step 973200: 0.137172\n",
      "2022-11-09 03:17:54,468 INFO     Training average loss at step 973200: 0.137129\n",
      "2022-11-09 03:17:57,572 INFO     Training average positive_sample_loss at step 973300: 0.138298\n",
      "2022-11-09 03:17:57,572 INFO     Training average negative_sample_loss at step 973300: 0.135339\n",
      "2022-11-09 03:17:57,572 INFO     Training average loss at step 973300: 0.136819\n",
      "2022-11-09 03:18:00,688 INFO     Training average positive_sample_loss at step 973400: 0.139046\n",
      "2022-11-09 03:18:00,688 INFO     Training average negative_sample_loss at step 973400: 0.135773\n",
      "2022-11-09 03:18:00,688 INFO     Training average loss at step 973400: 0.137409\n",
      "2022-11-09 03:18:03,807 INFO     Training average positive_sample_loss at step 973500: 0.136952\n",
      "2022-11-09 03:18:03,807 INFO     Training average negative_sample_loss at step 973500: 0.132579\n",
      "2022-11-09 03:18:03,807 INFO     Training average loss at step 973500: 0.134765\n",
      "2022-11-09 03:18:06,913 INFO     Training average positive_sample_loss at step 973600: 0.133626\n",
      "2022-11-09 03:18:06,913 INFO     Training average negative_sample_loss at step 973600: 0.134759\n",
      "2022-11-09 03:18:06,913 INFO     Training average loss at step 973600: 0.134192\n",
      "2022-11-09 03:18:10,020 INFO     Training average positive_sample_loss at step 973700: 0.137951\n",
      "2022-11-09 03:18:10,020 INFO     Training average negative_sample_loss at step 973700: 0.134857\n",
      "2022-11-09 03:18:10,020 INFO     Training average loss at step 973700: 0.136404\n",
      "2022-11-09 03:18:13,126 INFO     Training average positive_sample_loss at step 973800: 0.138240\n",
      "2022-11-09 03:18:13,126 INFO     Training average negative_sample_loss at step 973800: 0.133070\n",
      "2022-11-09 03:18:13,126 INFO     Training average loss at step 973800: 0.135655\n",
      "2022-11-09 03:18:16,240 INFO     Training average positive_sample_loss at step 973900: 0.139855\n",
      "2022-11-09 03:18:16,240 INFO     Training average negative_sample_loss at step 973900: 0.133682\n",
      "2022-11-09 03:18:16,240 INFO     Training average loss at step 973900: 0.136768\n",
      "2022-11-09 03:18:20,818 INFO     Training average positive_sample_loss at step 974000: 0.134481\n",
      "2022-11-09 03:18:20,819 INFO     Training average negative_sample_loss at step 974000: 0.128192\n",
      "2022-11-09 03:18:20,819 INFO     Training average loss at step 974000: 0.131337\n",
      "2022-11-09 03:18:25,484 INFO     Training average positive_sample_loss at step 974100: 0.138647\n",
      "2022-11-09 03:18:25,485 INFO     Training average negative_sample_loss at step 974100: 0.135087\n",
      "2022-11-09 03:18:25,485 INFO     Training average loss at step 974100: 0.136867\n",
      "2022-11-09 03:18:28,581 INFO     Training average positive_sample_loss at step 974200: 0.135601\n",
      "2022-11-09 03:18:28,581 INFO     Training average negative_sample_loss at step 974200: 0.138244\n",
      "2022-11-09 03:18:28,581 INFO     Training average loss at step 974200: 0.136923\n",
      "2022-11-09 03:18:31,688 INFO     Training average positive_sample_loss at step 974300: 0.135418\n",
      "2022-11-09 03:18:31,688 INFO     Training average negative_sample_loss at step 974300: 0.134578\n",
      "2022-11-09 03:18:31,688 INFO     Training average loss at step 974300: 0.134998\n",
      "2022-11-09 03:18:34,817 INFO     Training average positive_sample_loss at step 974400: 0.136344\n",
      "2022-11-09 03:18:34,817 INFO     Training average negative_sample_loss at step 974400: 0.133628\n",
      "2022-11-09 03:18:34,817 INFO     Training average loss at step 974400: 0.134986\n",
      "2022-11-09 03:18:37,917 INFO     Training average positive_sample_loss at step 974500: 0.139674\n",
      "2022-11-09 03:18:37,917 INFO     Training average negative_sample_loss at step 974500: 0.131403\n",
      "2022-11-09 03:18:37,917 INFO     Training average loss at step 974500: 0.135539\n",
      "2022-11-09 03:18:41,022 INFO     Training average positive_sample_loss at step 974600: 0.138046\n",
      "2022-11-09 03:18:41,022 INFO     Training average negative_sample_loss at step 974600: 0.133248\n",
      "2022-11-09 03:18:41,022 INFO     Training average loss at step 974600: 0.135647\n",
      "2022-11-09 03:18:44,129 INFO     Training average positive_sample_loss at step 974700: 0.138811\n",
      "2022-11-09 03:18:44,129 INFO     Training average negative_sample_loss at step 974700: 0.134581\n",
      "2022-11-09 03:18:44,129 INFO     Training average loss at step 974700: 0.136696\n",
      "2022-11-09 03:18:47,230 INFO     Training average positive_sample_loss at step 974800: 0.137716\n",
      "2022-11-09 03:18:47,230 INFO     Training average negative_sample_loss at step 974800: 0.135450\n",
      "2022-11-09 03:18:47,230 INFO     Training average loss at step 974800: 0.136583\n",
      "2022-11-09 03:18:50,328 INFO     Training average positive_sample_loss at step 974900: 0.137126\n",
      "2022-11-09 03:18:50,328 INFO     Training average negative_sample_loss at step 974900: 0.135575\n",
      "2022-11-09 03:18:50,328 INFO     Training average loss at step 974900: 0.136350\n",
      "2022-11-09 03:18:53,432 INFO     Training average positive_sample_loss at step 975000: 0.141539\n",
      "2022-11-09 03:18:53,433 INFO     Training average negative_sample_loss at step 975000: 0.133349\n",
      "2022-11-09 03:18:53,433 INFO     Training average loss at step 975000: 0.137444\n",
      "2022-11-09 03:18:56,531 INFO     Training average positive_sample_loss at step 975100: 0.135178\n",
      "2022-11-09 03:18:56,531 INFO     Training average negative_sample_loss at step 975100: 0.132393\n",
      "2022-11-09 03:18:56,531 INFO     Training average loss at step 975100: 0.133786\n",
      "2022-11-09 03:18:59,633 INFO     Training average positive_sample_loss at step 975200: 0.134836\n",
      "2022-11-09 03:18:59,633 INFO     Training average negative_sample_loss at step 975200: 0.134556\n",
      "2022-11-09 03:18:59,633 INFO     Training average loss at step 975200: 0.134696\n",
      "2022-11-09 03:19:02,736 INFO     Training average positive_sample_loss at step 975300: 0.136720\n",
      "2022-11-09 03:19:02,736 INFO     Training average negative_sample_loss at step 975300: 0.135260\n",
      "2022-11-09 03:19:02,736 INFO     Training average loss at step 975300: 0.135990\n",
      "2022-11-09 03:19:05,840 INFO     Training average positive_sample_loss at step 975400: 0.137554\n",
      "2022-11-09 03:19:05,841 INFO     Training average negative_sample_loss at step 975400: 0.132808\n",
      "2022-11-09 03:19:05,841 INFO     Training average loss at step 975400: 0.135181\n",
      "2022-11-09 03:19:08,944 INFO     Training average positive_sample_loss at step 975500: 0.137722\n",
      "2022-11-09 03:19:08,944 INFO     Training average negative_sample_loss at step 975500: 0.135289\n",
      "2022-11-09 03:19:08,944 INFO     Training average loss at step 975500: 0.136505\n",
      "2022-11-09 03:19:12,048 INFO     Training average positive_sample_loss at step 975600: 0.135470\n",
      "2022-11-09 03:19:12,049 INFO     Training average negative_sample_loss at step 975600: 0.133671\n",
      "2022-11-09 03:19:12,049 INFO     Training average loss at step 975600: 0.134571\n",
      "2022-11-09 03:19:15,156 INFO     Training average positive_sample_loss at step 975700: 0.134946\n",
      "2022-11-09 03:19:15,156 INFO     Training average negative_sample_loss at step 975700: 0.133819\n",
      "2022-11-09 03:19:15,156 INFO     Training average loss at step 975700: 0.134382\n",
      "2022-11-09 03:19:18,280 INFO     Training average positive_sample_loss at step 975800: 0.140923\n",
      "2022-11-09 03:19:18,280 INFO     Training average negative_sample_loss at step 975800: 0.132449\n",
      "2022-11-09 03:19:18,280 INFO     Training average loss at step 975800: 0.136686\n",
      "2022-11-09 03:19:21,396 INFO     Training average positive_sample_loss at step 975900: 0.138174\n",
      "2022-11-09 03:19:21,396 INFO     Training average negative_sample_loss at step 975900: 0.137552\n",
      "2022-11-09 03:19:21,396 INFO     Training average loss at step 975900: 0.137863\n",
      "2022-11-09 03:19:24,517 INFO     Training average positive_sample_loss at step 976000: 0.137588\n",
      "2022-11-09 03:19:24,517 INFO     Training average negative_sample_loss at step 976000: 0.133066\n",
      "2022-11-09 03:19:24,517 INFO     Training average loss at step 976000: 0.135327\n",
      "2022-11-09 03:19:27,635 INFO     Training average positive_sample_loss at step 976100: 0.134042\n",
      "2022-11-09 03:19:27,635 INFO     Training average negative_sample_loss at step 976100: 0.134102\n",
      "2022-11-09 03:19:27,635 INFO     Training average loss at step 976100: 0.134072\n",
      "2022-11-09 03:19:30,742 INFO     Training average positive_sample_loss at step 976200: 0.138155\n",
      "2022-11-09 03:19:30,742 INFO     Training average negative_sample_loss at step 976200: 0.133413\n",
      "2022-11-09 03:19:30,742 INFO     Training average loss at step 976200: 0.135784\n",
      "2022-11-09 03:19:33,854 INFO     Training average positive_sample_loss at step 976300: 0.134834\n",
      "2022-11-09 03:19:33,854 INFO     Training average negative_sample_loss at step 976300: 0.137305\n",
      "2022-11-09 03:19:33,854 INFO     Training average loss at step 976300: 0.136069\n",
      "2022-11-09 03:19:36,966 INFO     Training average positive_sample_loss at step 976400: 0.137926\n",
      "2022-11-09 03:19:36,966 INFO     Training average negative_sample_loss at step 976400: 0.134101\n",
      "2022-11-09 03:19:36,966 INFO     Training average loss at step 976400: 0.136014\n",
      "2022-11-09 03:19:40,079 INFO     Training average positive_sample_loss at step 976500: 0.135513\n",
      "2022-11-09 03:19:40,079 INFO     Training average negative_sample_loss at step 976500: 0.132859\n",
      "2022-11-09 03:19:40,079 INFO     Training average loss at step 976500: 0.134186\n",
      "2022-11-09 03:19:43,200 INFO     Training average positive_sample_loss at step 976600: 0.136267\n",
      "2022-11-09 03:19:43,200 INFO     Training average negative_sample_loss at step 976600: 0.132211\n",
      "2022-11-09 03:19:43,200 INFO     Training average loss at step 976600: 0.134239\n",
      "2022-11-09 03:19:46,318 INFO     Training average positive_sample_loss at step 976700: 0.137165\n",
      "2022-11-09 03:19:46,319 INFO     Training average negative_sample_loss at step 976700: 0.131648\n",
      "2022-11-09 03:19:46,319 INFO     Training average loss at step 976700: 0.134406\n",
      "2022-11-09 03:19:49,435 INFO     Training average positive_sample_loss at step 976800: 0.138078\n",
      "2022-11-09 03:19:49,435 INFO     Training average negative_sample_loss at step 976800: 0.135879\n",
      "2022-11-09 03:19:49,435 INFO     Training average loss at step 976800: 0.136978\n",
      "2022-11-09 03:19:52,548 INFO     Training average positive_sample_loss at step 976900: 0.135854\n",
      "2022-11-09 03:19:52,548 INFO     Training average negative_sample_loss at step 976900: 0.133072\n",
      "2022-11-09 03:19:52,548 INFO     Training average loss at step 976900: 0.134463\n",
      "2022-11-09 03:19:55,665 INFO     Training average positive_sample_loss at step 977000: 0.136473\n",
      "2022-11-09 03:19:55,665 INFO     Training average negative_sample_loss at step 977000: 0.136013\n",
      "2022-11-09 03:19:55,665 INFO     Training average loss at step 977000: 0.136243\n",
      "2022-11-09 03:19:58,786 INFO     Training average positive_sample_loss at step 977100: 0.134237\n",
      "2022-11-09 03:19:58,786 INFO     Training average negative_sample_loss at step 977100: 0.133669\n",
      "2022-11-09 03:19:58,786 INFO     Training average loss at step 977100: 0.133953\n",
      "2022-11-09 03:20:01,892 INFO     Training average positive_sample_loss at step 977200: 0.138494\n",
      "2022-11-09 03:20:01,892 INFO     Training average negative_sample_loss at step 977200: 0.132646\n",
      "2022-11-09 03:20:01,892 INFO     Training average loss at step 977200: 0.135570\n",
      "2022-11-09 03:20:04,987 INFO     Training average positive_sample_loss at step 977300: 0.138628\n",
      "2022-11-09 03:20:04,987 INFO     Training average negative_sample_loss at step 977300: 0.133278\n",
      "2022-11-09 03:20:04,987 INFO     Training average loss at step 977300: 0.135953\n",
      "2022-11-09 03:20:08,093 INFO     Training average positive_sample_loss at step 977400: 0.133976\n",
      "2022-11-09 03:20:08,093 INFO     Training average negative_sample_loss at step 977400: 0.134370\n",
      "2022-11-09 03:20:08,093 INFO     Training average loss at step 977400: 0.134173\n",
      "2022-11-09 03:20:11,195 INFO     Training average positive_sample_loss at step 977500: 0.137967\n",
      "2022-11-09 03:20:11,195 INFO     Training average negative_sample_loss at step 977500: 0.131289\n",
      "2022-11-09 03:20:11,195 INFO     Training average loss at step 977500: 0.134628\n",
      "2022-11-09 03:20:14,300 INFO     Training average positive_sample_loss at step 977600: 0.141745\n",
      "2022-11-09 03:20:14,300 INFO     Training average negative_sample_loss at step 977600: 0.131106\n",
      "2022-11-09 03:20:14,300 INFO     Training average loss at step 977600: 0.136425\n",
      "2022-11-09 03:20:17,426 INFO     Training average positive_sample_loss at step 977700: 0.139187\n",
      "2022-11-09 03:20:17,426 INFO     Training average negative_sample_loss at step 977700: 0.137403\n",
      "2022-11-09 03:20:17,426 INFO     Training average loss at step 977700: 0.138295\n",
      "2022-11-09 03:20:20,537 INFO     Training average positive_sample_loss at step 977800: 0.136466\n",
      "2022-11-09 03:20:20,537 INFO     Training average negative_sample_loss at step 977800: 0.134878\n",
      "2022-11-09 03:20:20,537 INFO     Training average loss at step 977800: 0.135672\n",
      "2022-11-09 03:20:23,649 INFO     Training average positive_sample_loss at step 977900: 0.137599\n",
      "2022-11-09 03:20:23,649 INFO     Training average negative_sample_loss at step 977900: 0.137804\n",
      "2022-11-09 03:20:23,649 INFO     Training average loss at step 977900: 0.137701\n",
      "2022-11-09 03:20:26,755 INFO     Training average positive_sample_loss at step 978000: 0.140626\n",
      "2022-11-09 03:20:26,755 INFO     Training average negative_sample_loss at step 978000: 0.137292\n",
      "2022-11-09 03:20:26,755 INFO     Training average loss at step 978000: 0.138959\n",
      "2022-11-09 03:20:29,869 INFO     Training average positive_sample_loss at step 978100: 0.143103\n",
      "2022-11-09 03:20:29,869 INFO     Training average negative_sample_loss at step 978100: 0.136473\n",
      "2022-11-09 03:20:29,869 INFO     Training average loss at step 978100: 0.139788\n",
      "2022-11-09 03:20:32,988 INFO     Training average positive_sample_loss at step 978200: 0.137723\n",
      "2022-11-09 03:20:32,988 INFO     Training average negative_sample_loss at step 978200: 0.129658\n",
      "2022-11-09 03:20:32,988 INFO     Training average loss at step 978200: 0.133691\n",
      "2022-11-09 03:20:36,102 INFO     Training average positive_sample_loss at step 978300: 0.138190\n",
      "2022-11-09 03:20:36,102 INFO     Training average negative_sample_loss at step 978300: 0.138186\n",
      "2022-11-09 03:20:36,102 INFO     Training average loss at step 978300: 0.138188\n",
      "2022-11-09 03:20:39,216 INFO     Training average positive_sample_loss at step 978400: 0.133709\n",
      "2022-11-09 03:20:39,216 INFO     Training average negative_sample_loss at step 978400: 0.136746\n",
      "2022-11-09 03:20:39,216 INFO     Training average loss at step 978400: 0.135227\n",
      "2022-11-09 03:20:42,338 INFO     Training average positive_sample_loss at step 978500: 0.135984\n",
      "2022-11-09 03:20:42,338 INFO     Training average negative_sample_loss at step 978500: 0.132853\n",
      "2022-11-09 03:20:42,338 INFO     Training average loss at step 978500: 0.134418\n",
      "2022-11-09 03:20:45,464 INFO     Training average positive_sample_loss at step 978600: 0.138373\n",
      "2022-11-09 03:20:45,464 INFO     Training average negative_sample_loss at step 978600: 0.135552\n",
      "2022-11-09 03:20:45,464 INFO     Training average loss at step 978600: 0.136963\n",
      "2022-11-09 03:20:50,121 INFO     Training average positive_sample_loss at step 978700: 0.135024\n",
      "2022-11-09 03:20:50,121 INFO     Training average negative_sample_loss at step 978700: 0.135170\n",
      "2022-11-09 03:20:50,121 INFO     Training average loss at step 978700: 0.135097\n",
      "2022-11-09 03:20:54,797 INFO     Training average positive_sample_loss at step 978800: 0.136960\n",
      "2022-11-09 03:20:54,797 INFO     Training average negative_sample_loss at step 978800: 0.133617\n",
      "2022-11-09 03:20:54,797 INFO     Training average loss at step 978800: 0.135289\n",
      "2022-11-09 03:20:57,902 INFO     Training average positive_sample_loss at step 978900: 0.137878\n",
      "2022-11-09 03:20:57,902 INFO     Training average negative_sample_loss at step 978900: 0.133301\n",
      "2022-11-09 03:20:57,902 INFO     Training average loss at step 978900: 0.135589\n",
      "2022-11-09 03:21:01,000 INFO     Training average positive_sample_loss at step 979000: 0.140706\n",
      "2022-11-09 03:21:01,000 INFO     Training average negative_sample_loss at step 979000: 0.131946\n",
      "2022-11-09 03:21:01,000 INFO     Training average loss at step 979000: 0.136326\n",
      "2022-11-09 03:21:04,090 INFO     Training average positive_sample_loss at step 979100: 0.139846\n",
      "2022-11-09 03:21:04,091 INFO     Training average negative_sample_loss at step 979100: 0.136714\n",
      "2022-11-09 03:21:04,091 INFO     Training average loss at step 979100: 0.138280\n",
      "2022-11-09 03:21:07,198 INFO     Training average positive_sample_loss at step 979200: 0.139502\n",
      "2022-11-09 03:21:07,198 INFO     Training average negative_sample_loss at step 979200: 0.132431\n",
      "2022-11-09 03:21:07,198 INFO     Training average loss at step 979200: 0.135967\n",
      "2022-11-09 03:21:10,299 INFO     Training average positive_sample_loss at step 979300: 0.136560\n",
      "2022-11-09 03:21:10,299 INFO     Training average negative_sample_loss at step 979300: 0.132172\n",
      "2022-11-09 03:21:10,299 INFO     Training average loss at step 979300: 0.134366\n",
      "2022-11-09 03:21:13,401 INFO     Training average positive_sample_loss at step 979400: 0.137734\n",
      "2022-11-09 03:21:13,401 INFO     Training average negative_sample_loss at step 979400: 0.135496\n",
      "2022-11-09 03:21:13,401 INFO     Training average loss at step 979400: 0.136615\n",
      "2022-11-09 03:21:16,500 INFO     Training average positive_sample_loss at step 979500: 0.137849\n",
      "2022-11-09 03:21:16,500 INFO     Training average negative_sample_loss at step 979500: 0.133945\n",
      "2022-11-09 03:21:16,501 INFO     Training average loss at step 979500: 0.135897\n",
      "2022-11-09 03:21:19,596 INFO     Training average positive_sample_loss at step 979600: 0.136376\n",
      "2022-11-09 03:21:19,596 INFO     Training average negative_sample_loss at step 979600: 0.133650\n",
      "2022-11-09 03:21:19,596 INFO     Training average loss at step 979600: 0.135013\n",
      "2022-11-09 03:21:22,712 INFO     Training average positive_sample_loss at step 979700: 0.134974\n",
      "2022-11-09 03:21:22,712 INFO     Training average negative_sample_loss at step 979700: 0.138557\n",
      "2022-11-09 03:21:22,712 INFO     Training average loss at step 979700: 0.136765\n",
      "2022-11-09 03:21:25,821 INFO     Training average positive_sample_loss at step 979800: 0.135361\n",
      "2022-11-09 03:21:25,821 INFO     Training average negative_sample_loss at step 979800: 0.133165\n",
      "2022-11-09 03:21:25,821 INFO     Training average loss at step 979800: 0.134263\n",
      "2022-11-09 03:21:28,946 INFO     Training average positive_sample_loss at step 979900: 0.138745\n",
      "2022-11-09 03:21:28,946 INFO     Training average negative_sample_loss at step 979900: 0.136488\n",
      "2022-11-09 03:21:28,946 INFO     Training average loss at step 979900: 0.137617\n",
      "2022-11-09 03:21:34,958 INFO     Training average positive_sample_loss at step 980000: 0.135442\n",
      "2022-11-09 03:21:34,958 INFO     Training average negative_sample_loss at step 980000: 0.135591\n",
      "2022-11-09 03:21:34,958 INFO     Training average loss at step 980000: 0.135517\n",
      "2022-11-09 03:21:38,055 INFO     Training average positive_sample_loss at step 980100: 0.136412\n",
      "2022-11-09 03:21:38,055 INFO     Training average negative_sample_loss at step 980100: 0.136596\n",
      "2022-11-09 03:21:38,055 INFO     Training average loss at step 980100: 0.136504\n",
      "2022-11-09 03:21:41,151 INFO     Training average positive_sample_loss at step 980200: 0.138188\n",
      "2022-11-09 03:21:41,151 INFO     Training average negative_sample_loss at step 980200: 0.134276\n",
      "2022-11-09 03:21:41,151 INFO     Training average loss at step 980200: 0.136232\n",
      "2022-11-09 03:21:44,254 INFO     Training average positive_sample_loss at step 980300: 0.135374\n",
      "2022-11-09 03:21:44,254 INFO     Training average negative_sample_loss at step 980300: 0.135464\n",
      "2022-11-09 03:21:44,254 INFO     Training average loss at step 980300: 0.135419\n",
      "2022-11-09 03:21:47,356 INFO     Training average positive_sample_loss at step 980400: 0.138792\n",
      "2022-11-09 03:21:47,356 INFO     Training average negative_sample_loss at step 980400: 0.134506\n",
      "2022-11-09 03:21:47,356 INFO     Training average loss at step 980400: 0.136649\n",
      "2022-11-09 03:21:50,467 INFO     Training average positive_sample_loss at step 980500: 0.139956\n",
      "2022-11-09 03:21:50,467 INFO     Training average negative_sample_loss at step 980500: 0.136355\n",
      "2022-11-09 03:21:50,467 INFO     Training average loss at step 980500: 0.138156\n",
      "2022-11-09 03:21:53,579 INFO     Training average positive_sample_loss at step 980600: 0.134997\n",
      "2022-11-09 03:21:53,579 INFO     Training average negative_sample_loss at step 980600: 0.133656\n",
      "2022-11-09 03:21:53,579 INFO     Training average loss at step 980600: 0.134327\n",
      "2022-11-09 03:21:56,689 INFO     Training average positive_sample_loss at step 980700: 0.137978\n",
      "2022-11-09 03:21:56,689 INFO     Training average negative_sample_loss at step 980700: 0.137634\n",
      "2022-11-09 03:21:56,689 INFO     Training average loss at step 980700: 0.137806\n",
      "2022-11-09 03:21:59,793 INFO     Training average positive_sample_loss at step 980800: 0.137164\n",
      "2022-11-09 03:21:59,793 INFO     Training average negative_sample_loss at step 980800: 0.135527\n",
      "2022-11-09 03:21:59,793 INFO     Training average loss at step 980800: 0.136346\n",
      "2022-11-09 03:22:02,889 INFO     Training average positive_sample_loss at step 980900: 0.137493\n",
      "2022-11-09 03:22:02,889 INFO     Training average negative_sample_loss at step 980900: 0.132329\n",
      "2022-11-09 03:22:02,889 INFO     Training average loss at step 980900: 0.134911\n",
      "2022-11-09 03:22:05,989 INFO     Training average positive_sample_loss at step 981000: 0.138942\n",
      "2022-11-09 03:22:05,989 INFO     Training average negative_sample_loss at step 981000: 0.134696\n",
      "2022-11-09 03:22:05,989 INFO     Training average loss at step 981000: 0.136819\n",
      "2022-11-09 03:22:09,102 INFO     Training average positive_sample_loss at step 981100: 0.135904\n",
      "2022-11-09 03:22:09,102 INFO     Training average negative_sample_loss at step 981100: 0.131198\n",
      "2022-11-09 03:22:09,102 INFO     Training average loss at step 981100: 0.133551\n",
      "2022-11-09 03:22:12,213 INFO     Training average positive_sample_loss at step 981200: 0.135696\n",
      "2022-11-09 03:22:12,213 INFO     Training average negative_sample_loss at step 981200: 0.134679\n",
      "2022-11-09 03:22:12,213 INFO     Training average loss at step 981200: 0.135188\n",
      "2022-11-09 03:22:15,326 INFO     Training average positive_sample_loss at step 981300: 0.137768\n",
      "2022-11-09 03:22:15,326 INFO     Training average negative_sample_loss at step 981300: 0.133909\n",
      "2022-11-09 03:22:15,326 INFO     Training average loss at step 981300: 0.135839\n",
      "2022-11-09 03:22:18,426 INFO     Training average positive_sample_loss at step 981400: 0.136972\n",
      "2022-11-09 03:22:18,426 INFO     Training average negative_sample_loss at step 981400: 0.133434\n",
      "2022-11-09 03:22:18,426 INFO     Training average loss at step 981400: 0.135203\n",
      "2022-11-09 03:22:21,535 INFO     Training average positive_sample_loss at step 981500: 0.135749\n",
      "2022-11-09 03:22:21,535 INFO     Training average negative_sample_loss at step 981500: 0.134526\n",
      "2022-11-09 03:22:21,535 INFO     Training average loss at step 981500: 0.135138\n",
      "2022-11-09 03:22:24,642 INFO     Training average positive_sample_loss at step 981600: 0.139707\n",
      "2022-11-09 03:22:24,642 INFO     Training average negative_sample_loss at step 981600: 0.136626\n",
      "2022-11-09 03:22:24,642 INFO     Training average loss at step 981600: 0.138167\n",
      "2022-11-09 03:22:27,745 INFO     Training average positive_sample_loss at step 981700: 0.137337\n",
      "2022-11-09 03:22:27,745 INFO     Training average negative_sample_loss at step 981700: 0.139446\n",
      "2022-11-09 03:22:27,745 INFO     Training average loss at step 981700: 0.138392\n",
      "2022-11-09 03:22:30,856 INFO     Training average positive_sample_loss at step 981800: 0.136985\n",
      "2022-11-09 03:22:30,856 INFO     Training average negative_sample_loss at step 981800: 0.135413\n",
      "2022-11-09 03:22:30,856 INFO     Training average loss at step 981800: 0.136199\n",
      "2022-11-09 03:22:33,976 INFO     Training average positive_sample_loss at step 981900: 0.139684\n",
      "2022-11-09 03:22:33,977 INFO     Training average negative_sample_loss at step 981900: 0.133206\n",
      "2022-11-09 03:22:33,977 INFO     Training average loss at step 981900: 0.136445\n",
      "2022-11-09 03:22:37,077 INFO     Training average positive_sample_loss at step 982000: 0.137649\n",
      "2022-11-09 03:22:37,077 INFO     Training average negative_sample_loss at step 982000: 0.134664\n",
      "2022-11-09 03:22:37,077 INFO     Training average loss at step 982000: 0.136156\n",
      "2022-11-09 03:22:40,196 INFO     Training average positive_sample_loss at step 982100: 0.139632\n",
      "2022-11-09 03:22:40,196 INFO     Training average negative_sample_loss at step 982100: 0.137883\n",
      "2022-11-09 03:22:40,196 INFO     Training average loss at step 982100: 0.138758\n",
      "2022-11-09 03:22:43,316 INFO     Training average positive_sample_loss at step 982200: 0.139924\n",
      "2022-11-09 03:22:43,316 INFO     Training average negative_sample_loss at step 982200: 0.138479\n",
      "2022-11-09 03:22:43,316 INFO     Training average loss at step 982200: 0.139201\n",
      "2022-11-09 03:22:46,431 INFO     Training average positive_sample_loss at step 982300: 0.134484\n",
      "2022-11-09 03:22:46,431 INFO     Training average negative_sample_loss at step 982300: 0.135996\n",
      "2022-11-09 03:22:46,431 INFO     Training average loss at step 982300: 0.135240\n",
      "2022-11-09 03:22:49,534 INFO     Training average positive_sample_loss at step 982400: 0.130887\n",
      "2022-11-09 03:22:49,534 INFO     Training average negative_sample_loss at step 982400: 0.136927\n",
      "2022-11-09 03:22:49,534 INFO     Training average loss at step 982400: 0.133907\n",
      "2022-11-09 03:22:52,651 INFO     Training average positive_sample_loss at step 982500: 0.131434\n",
      "2022-11-09 03:22:52,651 INFO     Training average negative_sample_loss at step 982500: 0.133528\n",
      "2022-11-09 03:22:52,651 INFO     Training average loss at step 982500: 0.132481\n",
      "2022-11-09 03:22:55,755 INFO     Training average positive_sample_loss at step 982600: 0.135842\n",
      "2022-11-09 03:22:55,755 INFO     Training average negative_sample_loss at step 982600: 0.134078\n",
      "2022-11-09 03:22:55,755 INFO     Training average loss at step 982600: 0.134960\n",
      "2022-11-09 03:22:58,872 INFO     Training average positive_sample_loss at step 982700: 0.136127\n",
      "2022-11-09 03:22:58,872 INFO     Training average negative_sample_loss at step 982700: 0.137038\n",
      "2022-11-09 03:22:58,872 INFO     Training average loss at step 982700: 0.136582\n",
      "2022-11-09 03:23:01,995 INFO     Training average positive_sample_loss at step 982800: 0.139086\n",
      "2022-11-09 03:23:01,995 INFO     Training average negative_sample_loss at step 982800: 0.134254\n",
      "2022-11-09 03:23:01,995 INFO     Training average loss at step 982800: 0.136670\n",
      "2022-11-09 03:23:05,105 INFO     Training average positive_sample_loss at step 982900: 0.141300\n",
      "2022-11-09 03:23:05,105 INFO     Training average negative_sample_loss at step 982900: 0.136490\n",
      "2022-11-09 03:23:05,105 INFO     Training average loss at step 982900: 0.138895\n",
      "2022-11-09 03:23:08,215 INFO     Training average positive_sample_loss at step 983000: 0.135914\n",
      "2022-11-09 03:23:08,215 INFO     Training average negative_sample_loss at step 983000: 0.129667\n",
      "2022-11-09 03:23:08,215 INFO     Training average loss at step 983000: 0.132791\n",
      "2022-11-09 03:23:11,332 INFO     Training average positive_sample_loss at step 983100: 0.138489\n",
      "2022-11-09 03:23:11,333 INFO     Training average negative_sample_loss at step 983100: 0.132216\n",
      "2022-11-09 03:23:11,333 INFO     Training average loss at step 983100: 0.135352\n",
      "2022-11-09 03:23:14,433 INFO     Training average positive_sample_loss at step 983200: 0.137755\n",
      "2022-11-09 03:23:14,433 INFO     Training average negative_sample_loss at step 983200: 0.133561\n",
      "2022-11-09 03:23:14,433 INFO     Training average loss at step 983200: 0.135658\n",
      "2022-11-09 03:23:19,000 INFO     Training average positive_sample_loss at step 983300: 0.137030\n",
      "2022-11-09 03:23:19,000 INFO     Training average negative_sample_loss at step 983300: 0.135315\n",
      "2022-11-09 03:23:19,000 INFO     Training average loss at step 983300: 0.136172\n",
      "2022-11-09 03:23:22,122 INFO     Training average positive_sample_loss at step 983400: 0.138871\n",
      "2022-11-09 03:23:22,122 INFO     Training average negative_sample_loss at step 983400: 0.135220\n",
      "2022-11-09 03:23:22,122 INFO     Training average loss at step 983400: 0.137046\n",
      "2022-11-09 03:23:26,762 INFO     Training average positive_sample_loss at step 983500: 0.136537\n",
      "2022-11-09 03:23:26,762 INFO     Training average negative_sample_loss at step 983500: 0.134445\n",
      "2022-11-09 03:23:26,762 INFO     Training average loss at step 983500: 0.135491\n",
      "2022-11-09 03:23:29,879 INFO     Training average positive_sample_loss at step 983600: 0.140775\n",
      "2022-11-09 03:23:29,879 INFO     Training average negative_sample_loss at step 983600: 0.132032\n",
      "2022-11-09 03:23:29,879 INFO     Training average loss at step 983600: 0.136404\n",
      "2022-11-09 03:23:33,003 INFO     Training average positive_sample_loss at step 983700: 0.142850\n",
      "2022-11-09 03:23:33,003 INFO     Training average negative_sample_loss at step 983700: 0.132479\n",
      "2022-11-09 03:23:33,003 INFO     Training average loss at step 983700: 0.137664\n",
      "2022-11-09 03:23:36,110 INFO     Training average positive_sample_loss at step 983800: 0.134857\n",
      "2022-11-09 03:23:36,110 INFO     Training average negative_sample_loss at step 983800: 0.135515\n",
      "2022-11-09 03:23:36,111 INFO     Training average loss at step 983800: 0.135186\n",
      "2022-11-09 03:23:39,222 INFO     Training average positive_sample_loss at step 983900: 0.136803\n",
      "2022-11-09 03:23:39,222 INFO     Training average negative_sample_loss at step 983900: 0.136384\n",
      "2022-11-09 03:23:39,222 INFO     Training average loss at step 983900: 0.136593\n",
      "2022-11-09 03:23:42,355 INFO     Training average positive_sample_loss at step 984000: 0.138237\n",
      "2022-11-09 03:23:42,356 INFO     Training average negative_sample_loss at step 984000: 0.133657\n",
      "2022-11-09 03:23:42,356 INFO     Training average loss at step 984000: 0.135947\n",
      "2022-11-09 03:23:45,480 INFO     Training average positive_sample_loss at step 984100: 0.134624\n",
      "2022-11-09 03:23:45,480 INFO     Training average negative_sample_loss at step 984100: 0.135532\n",
      "2022-11-09 03:23:45,480 INFO     Training average loss at step 984100: 0.135078\n",
      "2022-11-09 03:23:48,591 INFO     Training average positive_sample_loss at step 984200: 0.134784\n",
      "2022-11-09 03:23:48,591 INFO     Training average negative_sample_loss at step 984200: 0.133217\n",
      "2022-11-09 03:23:48,591 INFO     Training average loss at step 984200: 0.134000\n",
      "2022-11-09 03:23:51,708 INFO     Training average positive_sample_loss at step 984300: 0.136962\n",
      "2022-11-09 03:23:51,708 INFO     Training average negative_sample_loss at step 984300: 0.131095\n",
      "2022-11-09 03:23:51,708 INFO     Training average loss at step 984300: 0.134029\n",
      "2022-11-09 03:23:54,815 INFO     Training average positive_sample_loss at step 984400: 0.135585\n",
      "2022-11-09 03:23:54,815 INFO     Training average negative_sample_loss at step 984400: 0.129745\n",
      "2022-11-09 03:23:54,815 INFO     Training average loss at step 984400: 0.132665\n",
      "2022-11-09 03:23:57,920 INFO     Training average positive_sample_loss at step 984500: 0.141481\n",
      "2022-11-09 03:23:57,920 INFO     Training average negative_sample_loss at step 984500: 0.132550\n",
      "2022-11-09 03:23:57,920 INFO     Training average loss at step 984500: 0.137015\n",
      "2022-11-09 03:24:01,029 INFO     Training average positive_sample_loss at step 984600: 0.136060\n",
      "2022-11-09 03:24:01,029 INFO     Training average negative_sample_loss at step 984600: 0.133497\n",
      "2022-11-09 03:24:01,029 INFO     Training average loss at step 984600: 0.134778\n",
      "2022-11-09 03:24:04,133 INFO     Training average positive_sample_loss at step 984700: 0.138621\n",
      "2022-11-09 03:24:04,133 INFO     Training average negative_sample_loss at step 984700: 0.136609\n",
      "2022-11-09 03:24:04,133 INFO     Training average loss at step 984700: 0.137615\n",
      "2022-11-09 03:24:07,235 INFO     Training average positive_sample_loss at step 984800: 0.137723\n",
      "2022-11-09 03:24:07,235 INFO     Training average negative_sample_loss at step 984800: 0.132318\n",
      "2022-11-09 03:24:07,236 INFO     Training average loss at step 984800: 0.135020\n",
      "2022-11-09 03:24:10,351 INFO     Training average positive_sample_loss at step 984900: 0.139783\n",
      "2022-11-09 03:24:10,351 INFO     Training average negative_sample_loss at step 984900: 0.136759\n",
      "2022-11-09 03:24:10,351 INFO     Training average loss at step 984900: 0.138271\n",
      "2022-11-09 03:24:13,464 INFO     Training average positive_sample_loss at step 985000: 0.137815\n",
      "2022-11-09 03:24:13,464 INFO     Training average negative_sample_loss at step 985000: 0.129876\n",
      "2022-11-09 03:24:13,464 INFO     Training average loss at step 985000: 0.133846\n",
      "2022-11-09 03:24:16,571 INFO     Training average positive_sample_loss at step 985100: 0.134350\n",
      "2022-11-09 03:24:16,572 INFO     Training average negative_sample_loss at step 985100: 0.136911\n",
      "2022-11-09 03:24:16,572 INFO     Training average loss at step 985100: 0.135631\n",
      "2022-11-09 03:24:19,675 INFO     Training average positive_sample_loss at step 985200: 0.139969\n",
      "2022-11-09 03:24:19,675 INFO     Training average negative_sample_loss at step 985200: 0.128413\n",
      "2022-11-09 03:24:19,675 INFO     Training average loss at step 985200: 0.134191\n",
      "2022-11-09 03:24:22,788 INFO     Training average positive_sample_loss at step 985300: 0.137097\n",
      "2022-11-09 03:24:22,788 INFO     Training average negative_sample_loss at step 985300: 0.132143\n",
      "2022-11-09 03:24:22,788 INFO     Training average loss at step 985300: 0.134620\n",
      "2022-11-09 03:24:25,910 INFO     Training average positive_sample_loss at step 985400: 0.140699\n",
      "2022-11-09 03:24:25,911 INFO     Training average negative_sample_loss at step 985400: 0.135619\n",
      "2022-11-09 03:24:25,911 INFO     Training average loss at step 985400: 0.138159\n",
      "2022-11-09 03:24:29,028 INFO     Training average positive_sample_loss at step 985500: 0.139211\n",
      "2022-11-09 03:24:29,028 INFO     Training average negative_sample_loss at step 985500: 0.134673\n",
      "2022-11-09 03:24:29,028 INFO     Training average loss at step 985500: 0.136942\n",
      "2022-11-09 03:24:32,126 INFO     Training average positive_sample_loss at step 985600: 0.141056\n",
      "2022-11-09 03:24:32,126 INFO     Training average negative_sample_loss at step 985600: 0.133937\n",
      "2022-11-09 03:24:32,126 INFO     Training average loss at step 985600: 0.137497\n",
      "2022-11-09 03:24:35,238 INFO     Training average positive_sample_loss at step 985700: 0.134678\n",
      "2022-11-09 03:24:35,238 INFO     Training average negative_sample_loss at step 985700: 0.134150\n",
      "2022-11-09 03:24:35,239 INFO     Training average loss at step 985700: 0.134414\n",
      "2022-11-09 03:24:38,355 INFO     Training average positive_sample_loss at step 985800: 0.136027\n",
      "2022-11-09 03:24:38,355 INFO     Training average negative_sample_loss at step 985800: 0.132960\n",
      "2022-11-09 03:24:38,355 INFO     Training average loss at step 985800: 0.134494\n",
      "2022-11-09 03:24:41,462 INFO     Training average positive_sample_loss at step 985900: 0.136113\n",
      "2022-11-09 03:24:41,462 INFO     Training average negative_sample_loss at step 985900: 0.131397\n",
      "2022-11-09 03:24:41,462 INFO     Training average loss at step 985900: 0.133755\n",
      "2022-11-09 03:24:44,584 INFO     Training average positive_sample_loss at step 986000: 0.142103\n",
      "2022-11-09 03:24:44,584 INFO     Training average negative_sample_loss at step 986000: 0.134176\n",
      "2022-11-09 03:24:44,584 INFO     Training average loss at step 986000: 0.138140\n",
      "2022-11-09 03:24:47,696 INFO     Training average positive_sample_loss at step 986100: 0.140264\n",
      "2022-11-09 03:24:47,697 INFO     Training average negative_sample_loss at step 986100: 0.131086\n",
      "2022-11-09 03:24:47,697 INFO     Training average loss at step 986100: 0.135675\n",
      "2022-11-09 03:24:50,802 INFO     Training average positive_sample_loss at step 986200: 0.137545\n",
      "2022-11-09 03:24:50,802 INFO     Training average negative_sample_loss at step 986200: 0.133587\n",
      "2022-11-09 03:24:50,802 INFO     Training average loss at step 986200: 0.135566\n",
      "2022-11-09 03:24:53,911 INFO     Training average positive_sample_loss at step 986300: 0.137883\n",
      "2022-11-09 03:24:53,911 INFO     Training average negative_sample_loss at step 986300: 0.133038\n",
      "2022-11-09 03:24:53,911 INFO     Training average loss at step 986300: 0.135461\n",
      "2022-11-09 03:24:57,015 INFO     Training average positive_sample_loss at step 986400: 0.139624\n",
      "2022-11-09 03:24:57,015 INFO     Training average negative_sample_loss at step 986400: 0.134571\n",
      "2022-11-09 03:24:57,015 INFO     Training average loss at step 986400: 0.137098\n",
      "2022-11-09 03:25:00,135 INFO     Training average positive_sample_loss at step 986500: 0.137168\n",
      "2022-11-09 03:25:00,135 INFO     Training average negative_sample_loss at step 986500: 0.131251\n",
      "2022-11-09 03:25:00,135 INFO     Training average loss at step 986500: 0.134210\n",
      "2022-11-09 03:25:03,246 INFO     Training average positive_sample_loss at step 986600: 0.144303\n",
      "2022-11-09 03:25:03,246 INFO     Training average negative_sample_loss at step 986600: 0.133354\n",
      "2022-11-09 03:25:03,246 INFO     Training average loss at step 986600: 0.138828\n",
      "2022-11-09 03:25:06,370 INFO     Training average positive_sample_loss at step 986700: 0.130354\n",
      "2022-11-09 03:25:06,370 INFO     Training average negative_sample_loss at step 986700: 0.136626\n",
      "2022-11-09 03:25:06,370 INFO     Training average loss at step 986700: 0.133490\n",
      "2022-11-09 03:25:09,495 INFO     Training average positive_sample_loss at step 986800: 0.134251\n",
      "2022-11-09 03:25:09,495 INFO     Training average negative_sample_loss at step 986800: 0.136023\n",
      "2022-11-09 03:25:09,495 INFO     Training average loss at step 986800: 0.135137\n",
      "2022-11-09 03:25:12,604 INFO     Training average positive_sample_loss at step 986900: 0.137154\n",
      "2022-11-09 03:25:12,604 INFO     Training average negative_sample_loss at step 986900: 0.138335\n",
      "2022-11-09 03:25:12,604 INFO     Training average loss at step 986900: 0.137745\n",
      "2022-11-09 03:25:15,720 INFO     Training average positive_sample_loss at step 987000: 0.137168\n",
      "2022-11-09 03:25:15,720 INFO     Training average negative_sample_loss at step 987000: 0.130866\n",
      "2022-11-09 03:25:15,720 INFO     Training average loss at step 987000: 0.134017\n",
      "2022-11-09 03:25:18,845 INFO     Training average positive_sample_loss at step 987100: 0.136850\n",
      "2022-11-09 03:25:18,846 INFO     Training average negative_sample_loss at step 987100: 0.134605\n",
      "2022-11-09 03:25:18,846 INFO     Training average loss at step 987100: 0.135728\n",
      "2022-11-09 03:25:21,974 INFO     Training average positive_sample_loss at step 987200: 0.136738\n",
      "2022-11-09 03:25:21,974 INFO     Training average negative_sample_loss at step 987200: 0.131699\n",
      "2022-11-09 03:25:21,974 INFO     Training average loss at step 987200: 0.134219\n",
      "2022-11-09 03:25:25,093 INFO     Training average positive_sample_loss at step 987300: 0.137685\n",
      "2022-11-09 03:25:25,094 INFO     Training average negative_sample_loss at step 987300: 0.133727\n",
      "2022-11-09 03:25:25,094 INFO     Training average loss at step 987300: 0.135706\n",
      "2022-11-09 03:25:28,211 INFO     Training average positive_sample_loss at step 987400: 0.133571\n",
      "2022-11-09 03:25:28,211 INFO     Training average negative_sample_loss at step 987400: 0.133654\n",
      "2022-11-09 03:25:28,211 INFO     Training average loss at step 987400: 0.133612\n",
      "2022-11-09 03:25:31,316 INFO     Training average positive_sample_loss at step 987500: 0.136437\n",
      "2022-11-09 03:25:31,316 INFO     Training average negative_sample_loss at step 987500: 0.134578\n",
      "2022-11-09 03:25:31,316 INFO     Training average loss at step 987500: 0.135508\n",
      "2022-11-09 03:25:34,415 INFO     Training average positive_sample_loss at step 987600: 0.139635\n",
      "2022-11-09 03:25:34,415 INFO     Training average negative_sample_loss at step 987600: 0.137942\n",
      "2022-11-09 03:25:34,415 INFO     Training average loss at step 987600: 0.138789\n",
      "2022-11-09 03:25:37,548 INFO     Training average positive_sample_loss at step 987700: 0.136773\n",
      "2022-11-09 03:25:37,548 INFO     Training average negative_sample_loss at step 987700: 0.134044\n",
      "2022-11-09 03:25:37,548 INFO     Training average loss at step 987700: 0.135409\n",
      "2022-11-09 03:25:42,089 INFO     Training average positive_sample_loss at step 987800: 0.137910\n",
      "2022-11-09 03:25:42,089 INFO     Training average negative_sample_loss at step 987800: 0.138170\n",
      "2022-11-09 03:25:42,089 INFO     Training average loss at step 987800: 0.138040\n",
      "2022-11-09 03:25:45,207 INFO     Training average positive_sample_loss at step 987900: 0.137886\n",
      "2022-11-09 03:25:45,207 INFO     Training average negative_sample_loss at step 987900: 0.135133\n",
      "2022-11-09 03:25:45,208 INFO     Training average loss at step 987900: 0.136510\n",
      "2022-11-09 03:25:48,325 INFO     Training average positive_sample_loss at step 988000: 0.148733\n",
      "2022-11-09 03:25:48,325 INFO     Training average negative_sample_loss at step 988000: 0.134592\n",
      "2022-11-09 03:25:48,325 INFO     Training average loss at step 988000: 0.141663\n",
      "2022-11-09 03:25:51,456 INFO     Training average positive_sample_loss at step 988100: 0.136613\n",
      "2022-11-09 03:25:51,456 INFO     Training average negative_sample_loss at step 988100: 0.131867\n",
      "2022-11-09 03:25:51,456 INFO     Training average loss at step 988100: 0.134240\n",
      "2022-11-09 03:25:56,082 INFO     Training average positive_sample_loss at step 988200: 0.138896\n",
      "2022-11-09 03:25:56,082 INFO     Training average negative_sample_loss at step 988200: 0.132496\n",
      "2022-11-09 03:25:56,082 INFO     Training average loss at step 988200: 0.135696\n",
      "2022-11-09 03:25:59,198 INFO     Training average positive_sample_loss at step 988300: 0.137027\n",
      "2022-11-09 03:25:59,198 INFO     Training average negative_sample_loss at step 988300: 0.132422\n",
      "2022-11-09 03:25:59,198 INFO     Training average loss at step 988300: 0.134725\n",
      "2022-11-09 03:26:02,308 INFO     Training average positive_sample_loss at step 988400: 0.139160\n",
      "2022-11-09 03:26:02,308 INFO     Training average negative_sample_loss at step 988400: 0.134068\n",
      "2022-11-09 03:26:02,308 INFO     Training average loss at step 988400: 0.136614\n",
      "2022-11-09 03:26:05,406 INFO     Training average positive_sample_loss at step 988500: 0.137304\n",
      "2022-11-09 03:26:05,406 INFO     Training average negative_sample_loss at step 988500: 0.133590\n",
      "2022-11-09 03:26:05,406 INFO     Training average loss at step 988500: 0.135447\n",
      "2022-11-09 03:26:08,510 INFO     Training average positive_sample_loss at step 988600: 0.135154\n",
      "2022-11-09 03:26:08,511 INFO     Training average negative_sample_loss at step 988600: 0.135760\n",
      "2022-11-09 03:26:08,511 INFO     Training average loss at step 988600: 0.135457\n",
      "2022-11-09 03:26:11,616 INFO     Training average positive_sample_loss at step 988700: 0.142902\n",
      "2022-11-09 03:26:11,616 INFO     Training average negative_sample_loss at step 988700: 0.134448\n",
      "2022-11-09 03:26:11,616 INFO     Training average loss at step 988700: 0.138675\n",
      "2022-11-09 03:26:14,728 INFO     Training average positive_sample_loss at step 988800: 0.137666\n",
      "2022-11-09 03:26:14,728 INFO     Training average negative_sample_loss at step 988800: 0.136287\n",
      "2022-11-09 03:26:14,728 INFO     Training average loss at step 988800: 0.136976\n",
      "2022-11-09 03:26:17,842 INFO     Training average positive_sample_loss at step 988900: 0.138146\n",
      "2022-11-09 03:26:17,842 INFO     Training average negative_sample_loss at step 988900: 0.133493\n",
      "2022-11-09 03:26:17,842 INFO     Training average loss at step 988900: 0.135819\n",
      "2022-11-09 03:26:20,952 INFO     Training average positive_sample_loss at step 989000: 0.137085\n",
      "2022-11-09 03:26:20,952 INFO     Training average negative_sample_loss at step 989000: 0.138073\n",
      "2022-11-09 03:26:20,952 INFO     Training average loss at step 989000: 0.137579\n",
      "2022-11-09 03:26:24,059 INFO     Training average positive_sample_loss at step 989100: 0.134472\n",
      "2022-11-09 03:26:24,059 INFO     Training average negative_sample_loss at step 989100: 0.135102\n",
      "2022-11-09 03:26:24,059 INFO     Training average loss at step 989100: 0.134787\n",
      "2022-11-09 03:26:27,169 INFO     Training average positive_sample_loss at step 989200: 0.136877\n",
      "2022-11-09 03:26:27,169 INFO     Training average negative_sample_loss at step 989200: 0.133372\n",
      "2022-11-09 03:26:27,169 INFO     Training average loss at step 989200: 0.135125\n",
      "2022-11-09 03:26:30,288 INFO     Training average positive_sample_loss at step 989300: 0.137987\n",
      "2022-11-09 03:26:30,288 INFO     Training average negative_sample_loss at step 989300: 0.129022\n",
      "2022-11-09 03:26:30,289 INFO     Training average loss at step 989300: 0.133505\n",
      "2022-11-09 03:26:33,393 INFO     Training average positive_sample_loss at step 989400: 0.135120\n",
      "2022-11-09 03:26:33,393 INFO     Training average negative_sample_loss at step 989400: 0.135593\n",
      "2022-11-09 03:26:33,393 INFO     Training average loss at step 989400: 0.135356\n",
      "2022-11-09 03:26:36,497 INFO     Training average positive_sample_loss at step 989500: 0.141609\n",
      "2022-11-09 03:26:36,497 INFO     Training average negative_sample_loss at step 989500: 0.134312\n",
      "2022-11-09 03:26:36,497 INFO     Training average loss at step 989500: 0.137960\n",
      "2022-11-09 03:26:39,600 INFO     Training average positive_sample_loss at step 989600: 0.137154\n",
      "2022-11-09 03:26:39,600 INFO     Training average negative_sample_loss at step 989600: 0.132419\n",
      "2022-11-09 03:26:39,600 INFO     Training average loss at step 989600: 0.134787\n",
      "2022-11-09 03:26:42,699 INFO     Training average positive_sample_loss at step 989700: 0.134056\n",
      "2022-11-09 03:26:42,699 INFO     Training average negative_sample_loss at step 989700: 0.134645\n",
      "2022-11-09 03:26:42,699 INFO     Training average loss at step 989700: 0.134351\n",
      "2022-11-09 03:26:45,802 INFO     Training average positive_sample_loss at step 989800: 0.139041\n",
      "2022-11-09 03:26:45,802 INFO     Training average negative_sample_loss at step 989800: 0.134638\n",
      "2022-11-09 03:26:45,802 INFO     Training average loss at step 989800: 0.136839\n",
      "2022-11-09 03:26:48,906 INFO     Training average positive_sample_loss at step 989900: 0.134685\n",
      "2022-11-09 03:26:48,906 INFO     Training average negative_sample_loss at step 989900: 0.135025\n",
      "2022-11-09 03:26:48,906 INFO     Training average loss at step 989900: 0.134855\n",
      "2022-11-09 03:26:54,911 INFO     Training average positive_sample_loss at step 990000: 0.135721\n",
      "2022-11-09 03:26:54,911 INFO     Training average negative_sample_loss at step 990000: 0.133675\n",
      "2022-11-09 03:26:54,911 INFO     Training average loss at step 990000: 0.134698\n",
      "2022-11-09 03:26:58,029 INFO     Training average positive_sample_loss at step 990100: 0.141239\n",
      "2022-11-09 03:26:58,029 INFO     Training average negative_sample_loss at step 990100: 0.135568\n",
      "2022-11-09 03:26:58,029 INFO     Training average loss at step 990100: 0.138403\n",
      "2022-11-09 03:27:01,134 INFO     Training average positive_sample_loss at step 990200: 0.136424\n",
      "2022-11-09 03:27:01,135 INFO     Training average negative_sample_loss at step 990200: 0.133305\n",
      "2022-11-09 03:27:01,135 INFO     Training average loss at step 990200: 0.134864\n",
      "2022-11-09 03:27:04,244 INFO     Training average positive_sample_loss at step 990300: 0.140136\n",
      "2022-11-09 03:27:04,244 INFO     Training average negative_sample_loss at step 990300: 0.134839\n",
      "2022-11-09 03:27:04,244 INFO     Training average loss at step 990300: 0.137488\n",
      "2022-11-09 03:27:07,348 INFO     Training average positive_sample_loss at step 990400: 0.138511\n",
      "2022-11-09 03:27:07,349 INFO     Training average negative_sample_loss at step 990400: 0.131624\n",
      "2022-11-09 03:27:07,349 INFO     Training average loss at step 990400: 0.135067\n",
      "2022-11-09 03:27:10,466 INFO     Training average positive_sample_loss at step 990500: 0.139109\n",
      "2022-11-09 03:27:10,466 INFO     Training average negative_sample_loss at step 990500: 0.138915\n",
      "2022-11-09 03:27:10,466 INFO     Training average loss at step 990500: 0.139012\n",
      "2022-11-09 03:27:13,571 INFO     Training average positive_sample_loss at step 990600: 0.137139\n",
      "2022-11-09 03:27:13,571 INFO     Training average negative_sample_loss at step 990600: 0.137558\n",
      "2022-11-09 03:27:13,571 INFO     Training average loss at step 990600: 0.137348\n",
      "2022-11-09 03:27:16,678 INFO     Training average positive_sample_loss at step 990700: 0.137009\n",
      "2022-11-09 03:27:16,678 INFO     Training average negative_sample_loss at step 990700: 0.132763\n",
      "2022-11-09 03:27:16,678 INFO     Training average loss at step 990700: 0.134886\n",
      "2022-11-09 03:27:19,784 INFO     Training average positive_sample_loss at step 990800: 0.136584\n",
      "2022-11-09 03:27:19,784 INFO     Training average negative_sample_loss at step 990800: 0.138958\n",
      "2022-11-09 03:27:19,784 INFO     Training average loss at step 990800: 0.137771\n",
      "2022-11-09 03:27:22,897 INFO     Training average positive_sample_loss at step 990900: 0.137987\n",
      "2022-11-09 03:27:22,897 INFO     Training average negative_sample_loss at step 990900: 0.134697\n",
      "2022-11-09 03:27:22,897 INFO     Training average loss at step 990900: 0.136342\n",
      "2022-11-09 03:27:26,000 INFO     Training average positive_sample_loss at step 991000: 0.135877\n",
      "2022-11-09 03:27:26,001 INFO     Training average negative_sample_loss at step 991000: 0.134717\n",
      "2022-11-09 03:27:26,001 INFO     Training average loss at step 991000: 0.135297\n",
      "2022-11-09 03:27:29,108 INFO     Training average positive_sample_loss at step 991100: 0.139561\n",
      "2022-11-09 03:27:29,108 INFO     Training average negative_sample_loss at step 991100: 0.142419\n",
      "2022-11-09 03:27:29,108 INFO     Training average loss at step 991100: 0.140990\n",
      "2022-11-09 03:27:32,215 INFO     Training average positive_sample_loss at step 991200: 0.140053\n",
      "2022-11-09 03:27:32,215 INFO     Training average negative_sample_loss at step 991200: 0.133344\n",
      "2022-11-09 03:27:32,216 INFO     Training average loss at step 991200: 0.136698\n",
      "2022-11-09 03:27:35,320 INFO     Training average positive_sample_loss at step 991300: 0.136496\n",
      "2022-11-09 03:27:35,320 INFO     Training average negative_sample_loss at step 991300: 0.134868\n",
      "2022-11-09 03:27:35,320 INFO     Training average loss at step 991300: 0.135682\n",
      "2022-11-09 03:27:38,428 INFO     Training average positive_sample_loss at step 991400: 0.136976\n",
      "2022-11-09 03:27:38,429 INFO     Training average negative_sample_loss at step 991400: 0.133931\n",
      "2022-11-09 03:27:38,429 INFO     Training average loss at step 991400: 0.135453\n",
      "2022-11-09 03:27:41,542 INFO     Training average positive_sample_loss at step 991500: 0.136670\n",
      "2022-11-09 03:27:41,542 INFO     Training average negative_sample_loss at step 991500: 0.134115\n",
      "2022-11-09 03:27:41,542 INFO     Training average loss at step 991500: 0.135393\n",
      "2022-11-09 03:27:44,647 INFO     Training average positive_sample_loss at step 991600: 0.136176\n",
      "2022-11-09 03:27:44,647 INFO     Training average negative_sample_loss at step 991600: 0.133003\n",
      "2022-11-09 03:27:44,647 INFO     Training average loss at step 991600: 0.134589\n",
      "2022-11-09 03:27:47,756 INFO     Training average positive_sample_loss at step 991700: 0.141132\n",
      "2022-11-09 03:27:47,756 INFO     Training average negative_sample_loss at step 991700: 0.134245\n",
      "2022-11-09 03:27:47,756 INFO     Training average loss at step 991700: 0.137688\n",
      "2022-11-09 03:27:50,856 INFO     Training average positive_sample_loss at step 991800: 0.139539\n",
      "2022-11-09 03:27:50,856 INFO     Training average negative_sample_loss at step 991800: 0.134681\n",
      "2022-11-09 03:27:50,856 INFO     Training average loss at step 991800: 0.137110\n",
      "2022-11-09 03:27:53,967 INFO     Training average positive_sample_loss at step 991900: 0.137652\n",
      "2022-11-09 03:27:53,967 INFO     Training average negative_sample_loss at step 991900: 0.133237\n",
      "2022-11-09 03:27:53,967 INFO     Training average loss at step 991900: 0.135444\n",
      "2022-11-09 03:27:57,070 INFO     Training average positive_sample_loss at step 992000: 0.137920\n",
      "2022-11-09 03:27:57,070 INFO     Training average negative_sample_loss at step 992000: 0.134334\n",
      "2022-11-09 03:27:57,070 INFO     Training average loss at step 992000: 0.136127\n",
      "2022-11-09 03:28:00,187 INFO     Training average positive_sample_loss at step 992100: 0.135948\n",
      "2022-11-09 03:28:00,187 INFO     Training average negative_sample_loss at step 992100: 0.136338\n",
      "2022-11-09 03:28:00,187 INFO     Training average loss at step 992100: 0.136143\n",
      "2022-11-09 03:28:03,293 INFO     Training average positive_sample_loss at step 992200: 0.137462\n",
      "2022-11-09 03:28:03,293 INFO     Training average negative_sample_loss at step 992200: 0.134242\n",
      "2022-11-09 03:28:03,293 INFO     Training average loss at step 992200: 0.135852\n",
      "2022-11-09 03:28:06,396 INFO     Training average positive_sample_loss at step 992300: 0.138413\n",
      "2022-11-09 03:28:06,397 INFO     Training average negative_sample_loss at step 992300: 0.132483\n",
      "2022-11-09 03:28:06,397 INFO     Training average loss at step 992300: 0.135448\n",
      "2022-11-09 03:28:09,498 INFO     Training average positive_sample_loss at step 992400: 0.139475\n",
      "2022-11-09 03:28:09,498 INFO     Training average negative_sample_loss at step 992400: 0.135733\n",
      "2022-11-09 03:28:09,498 INFO     Training average loss at step 992400: 0.137604\n",
      "2022-11-09 03:28:14,049 INFO     Training average positive_sample_loss at step 992500: 0.139682\n",
      "2022-11-09 03:28:14,050 INFO     Training average negative_sample_loss at step 992500: 0.133758\n",
      "2022-11-09 03:28:14,050 INFO     Training average loss at step 992500: 0.136720\n",
      "2022-11-09 03:28:17,148 INFO     Training average positive_sample_loss at step 992600: 0.137785\n",
      "2022-11-09 03:28:17,149 INFO     Training average negative_sample_loss at step 992600: 0.130017\n",
      "2022-11-09 03:28:17,149 INFO     Training average loss at step 992600: 0.133901\n",
      "2022-11-09 03:28:20,258 INFO     Training average positive_sample_loss at step 992700: 0.136975\n",
      "2022-11-09 03:28:20,259 INFO     Training average negative_sample_loss at step 992700: 0.134480\n",
      "2022-11-09 03:28:20,259 INFO     Training average loss at step 992700: 0.135727\n",
      "2022-11-09 03:28:23,360 INFO     Training average positive_sample_loss at step 992800: 0.136008\n",
      "2022-11-09 03:28:23,360 INFO     Training average negative_sample_loss at step 992800: 0.134023\n",
      "2022-11-09 03:28:23,360 INFO     Training average loss at step 992800: 0.135015\n",
      "2022-11-09 03:28:28,006 INFO     Training average positive_sample_loss at step 992900: 0.141918\n",
      "2022-11-09 03:28:28,006 INFO     Training average negative_sample_loss at step 992900: 0.136868\n",
      "2022-11-09 03:28:28,006 INFO     Training average loss at step 992900: 0.139393\n",
      "2022-11-09 03:28:31,108 INFO     Training average positive_sample_loss at step 993000: 0.134706\n",
      "2022-11-09 03:28:31,108 INFO     Training average negative_sample_loss at step 993000: 0.135518\n",
      "2022-11-09 03:28:31,108 INFO     Training average loss at step 993000: 0.135112\n",
      "2022-11-09 03:28:34,221 INFO     Training average positive_sample_loss at step 993100: 0.138345\n",
      "2022-11-09 03:28:34,221 INFO     Training average negative_sample_loss at step 993100: 0.131916\n",
      "2022-11-09 03:28:34,221 INFO     Training average loss at step 993100: 0.135130\n",
      "2022-11-09 03:28:37,328 INFO     Training average positive_sample_loss at step 993200: 0.139618\n",
      "2022-11-09 03:28:37,328 INFO     Training average negative_sample_loss at step 993200: 0.129249\n",
      "2022-11-09 03:28:37,328 INFO     Training average loss at step 993200: 0.134434\n",
      "2022-11-09 03:28:40,448 INFO     Training average positive_sample_loss at step 993300: 0.136792\n",
      "2022-11-09 03:28:40,448 INFO     Training average negative_sample_loss at step 993300: 0.129603\n",
      "2022-11-09 03:28:40,448 INFO     Training average loss at step 993300: 0.133197\n",
      "2022-11-09 03:28:43,537 INFO     Training average positive_sample_loss at step 993400: 0.137471\n",
      "2022-11-09 03:28:43,537 INFO     Training average negative_sample_loss at step 993400: 0.136807\n",
      "2022-11-09 03:28:43,537 INFO     Training average loss at step 993400: 0.137139\n",
      "2022-11-09 03:28:46,635 INFO     Training average positive_sample_loss at step 993500: 0.143860\n",
      "2022-11-09 03:28:46,636 INFO     Training average negative_sample_loss at step 993500: 0.136940\n",
      "2022-11-09 03:28:46,636 INFO     Training average loss at step 993500: 0.140400\n",
      "2022-11-09 03:28:49,746 INFO     Training average positive_sample_loss at step 993600: 0.135312\n",
      "2022-11-09 03:28:49,746 INFO     Training average negative_sample_loss at step 993600: 0.138534\n",
      "2022-11-09 03:28:49,746 INFO     Training average loss at step 993600: 0.136923\n",
      "2022-11-09 03:28:52,840 INFO     Training average positive_sample_loss at step 993700: 0.137090\n",
      "2022-11-09 03:28:52,840 INFO     Training average negative_sample_loss at step 993700: 0.133428\n",
      "2022-11-09 03:28:52,840 INFO     Training average loss at step 993700: 0.135259\n",
      "2022-11-09 03:28:55,941 INFO     Training average positive_sample_loss at step 993800: 0.139944\n",
      "2022-11-09 03:28:55,942 INFO     Training average negative_sample_loss at step 993800: 0.136560\n",
      "2022-11-09 03:28:55,942 INFO     Training average loss at step 993800: 0.138252\n",
      "2022-11-09 03:28:59,039 INFO     Training average positive_sample_loss at step 993900: 0.137158\n",
      "2022-11-09 03:28:59,039 INFO     Training average negative_sample_loss at step 993900: 0.135699\n",
      "2022-11-09 03:28:59,039 INFO     Training average loss at step 993900: 0.136429\n",
      "2022-11-09 03:29:02,155 INFO     Training average positive_sample_loss at step 994000: 0.133800\n",
      "2022-11-09 03:29:02,156 INFO     Training average negative_sample_loss at step 994000: 0.130058\n",
      "2022-11-09 03:29:02,156 INFO     Training average loss at step 994000: 0.131929\n",
      "2022-11-09 03:29:05,269 INFO     Training average positive_sample_loss at step 994100: 0.141876\n",
      "2022-11-09 03:29:05,269 INFO     Training average negative_sample_loss at step 994100: 0.128255\n",
      "2022-11-09 03:29:05,269 INFO     Training average loss at step 994100: 0.135065\n",
      "2022-11-09 03:29:08,388 INFO     Training average positive_sample_loss at step 994200: 0.137192\n",
      "2022-11-09 03:29:08,389 INFO     Training average negative_sample_loss at step 994200: 0.135141\n",
      "2022-11-09 03:29:08,389 INFO     Training average loss at step 994200: 0.136167\n",
      "2022-11-09 03:29:11,513 INFO     Training average positive_sample_loss at step 994300: 0.133754\n",
      "2022-11-09 03:29:11,514 INFO     Training average negative_sample_loss at step 994300: 0.137604\n",
      "2022-11-09 03:29:11,514 INFO     Training average loss at step 994300: 0.135679\n",
      "2022-11-09 03:29:14,637 INFO     Training average positive_sample_loss at step 994400: 0.133492\n",
      "2022-11-09 03:29:14,637 INFO     Training average negative_sample_loss at step 994400: 0.133821\n",
      "2022-11-09 03:29:14,637 INFO     Training average loss at step 994400: 0.133656\n",
      "2022-11-09 03:29:17,756 INFO     Training average positive_sample_loss at step 994500: 0.137227\n",
      "2022-11-09 03:29:17,756 INFO     Training average negative_sample_loss at step 994500: 0.133067\n",
      "2022-11-09 03:29:17,756 INFO     Training average loss at step 994500: 0.135147\n",
      "2022-11-09 03:29:20,877 INFO     Training average positive_sample_loss at step 994600: 0.140379\n",
      "2022-11-09 03:29:20,877 INFO     Training average negative_sample_loss at step 994600: 0.137127\n",
      "2022-11-09 03:29:20,877 INFO     Training average loss at step 994600: 0.138753\n",
      "2022-11-09 03:29:23,988 INFO     Training average positive_sample_loss at step 994700: 0.133104\n",
      "2022-11-09 03:29:23,988 INFO     Training average negative_sample_loss at step 994700: 0.135306\n",
      "2022-11-09 03:29:23,988 INFO     Training average loss at step 994700: 0.134205\n",
      "2022-11-09 03:29:27,103 INFO     Training average positive_sample_loss at step 994800: 0.136996\n",
      "2022-11-09 03:29:27,103 INFO     Training average negative_sample_loss at step 994800: 0.136332\n",
      "2022-11-09 03:29:27,103 INFO     Training average loss at step 994800: 0.136664\n",
      "2022-11-09 03:29:30,219 INFO     Training average positive_sample_loss at step 994900: 0.135396\n",
      "2022-11-09 03:29:30,219 INFO     Training average negative_sample_loss at step 994900: 0.134744\n",
      "2022-11-09 03:29:30,219 INFO     Training average loss at step 994900: 0.135070\n",
      "2022-11-09 03:29:33,331 INFO     Training average positive_sample_loss at step 995000: 0.134296\n",
      "2022-11-09 03:29:33,331 INFO     Training average negative_sample_loss at step 995000: 0.131402\n",
      "2022-11-09 03:29:33,331 INFO     Training average loss at step 995000: 0.132849\n",
      "2022-11-09 03:29:36,464 INFO     Training average positive_sample_loss at step 995100: 0.137621\n",
      "2022-11-09 03:29:36,465 INFO     Training average negative_sample_loss at step 995100: 0.136335\n",
      "2022-11-09 03:29:36,465 INFO     Training average loss at step 995100: 0.136978\n",
      "2022-11-09 03:29:39,598 INFO     Training average positive_sample_loss at step 995200: 0.135814\n",
      "2022-11-09 03:29:39,598 INFO     Training average negative_sample_loss at step 995200: 0.131595\n",
      "2022-11-09 03:29:39,598 INFO     Training average loss at step 995200: 0.133704\n",
      "2022-11-09 03:29:42,713 INFO     Training average positive_sample_loss at step 995300: 0.135066\n",
      "2022-11-09 03:29:42,713 INFO     Training average negative_sample_loss at step 995300: 0.136313\n",
      "2022-11-09 03:29:42,713 INFO     Training average loss at step 995300: 0.135690\n",
      "2022-11-09 03:29:45,817 INFO     Training average positive_sample_loss at step 995400: 0.139394\n",
      "2022-11-09 03:29:45,817 INFO     Training average negative_sample_loss at step 995400: 0.137411\n",
      "2022-11-09 03:29:45,817 INFO     Training average loss at step 995400: 0.138403\n",
      "2022-11-09 03:29:48,933 INFO     Training average positive_sample_loss at step 995500: 0.137996\n",
      "2022-11-09 03:29:48,934 INFO     Training average negative_sample_loss at step 995500: 0.134643\n",
      "2022-11-09 03:29:48,934 INFO     Training average loss at step 995500: 0.136320\n",
      "2022-11-09 03:29:52,057 INFO     Training average positive_sample_loss at step 995600: 0.137657\n",
      "2022-11-09 03:29:52,057 INFO     Training average negative_sample_loss at step 995600: 0.134888\n",
      "2022-11-09 03:29:52,057 INFO     Training average loss at step 995600: 0.136272\n",
      "2022-11-09 03:29:55,183 INFO     Training average positive_sample_loss at step 995700: 0.136070\n",
      "2022-11-09 03:29:55,184 INFO     Training average negative_sample_loss at step 995700: 0.137006\n",
      "2022-11-09 03:29:55,184 INFO     Training average loss at step 995700: 0.136538\n",
      "2022-11-09 03:29:58,303 INFO     Training average positive_sample_loss at step 995800: 0.138406\n",
      "2022-11-09 03:29:58,303 INFO     Training average negative_sample_loss at step 995800: 0.134033\n",
      "2022-11-09 03:29:58,303 INFO     Training average loss at step 995800: 0.136220\n",
      "2022-11-09 03:30:01,435 INFO     Training average positive_sample_loss at step 995900: 0.139660\n",
      "2022-11-09 03:30:01,435 INFO     Training average negative_sample_loss at step 995900: 0.131717\n",
      "2022-11-09 03:30:01,435 INFO     Training average loss at step 995900: 0.135689\n",
      "2022-11-09 03:30:04,540 INFO     Training average positive_sample_loss at step 996000: 0.138910\n",
      "2022-11-09 03:30:04,540 INFO     Training average negative_sample_loss at step 996000: 0.131489\n",
      "2022-11-09 03:30:04,541 INFO     Training average loss at step 996000: 0.135200\n",
      "2022-11-09 03:30:07,655 INFO     Training average positive_sample_loss at step 996100: 0.147336\n",
      "2022-11-09 03:30:07,655 INFO     Training average negative_sample_loss at step 996100: 0.135827\n",
      "2022-11-09 03:30:07,655 INFO     Training average loss at step 996100: 0.141582\n",
      "2022-11-09 03:30:10,774 INFO     Training average positive_sample_loss at step 996200: 0.137132\n",
      "2022-11-09 03:30:10,775 INFO     Training average negative_sample_loss at step 996200: 0.132848\n",
      "2022-11-09 03:30:10,775 INFO     Training average loss at step 996200: 0.134990\n",
      "2022-11-09 03:30:13,882 INFO     Training average positive_sample_loss at step 996300: 0.137504\n",
      "2022-11-09 03:30:13,882 INFO     Training average negative_sample_loss at step 996300: 0.130092\n",
      "2022-11-09 03:30:13,882 INFO     Training average loss at step 996300: 0.133798\n",
      "2022-11-09 03:30:16,978 INFO     Training average positive_sample_loss at step 996400: 0.131918\n",
      "2022-11-09 03:30:16,978 INFO     Training average negative_sample_loss at step 996400: 0.136254\n",
      "2022-11-09 03:30:16,978 INFO     Training average loss at step 996400: 0.134086\n",
      "2022-11-09 03:30:20,084 INFO     Training average positive_sample_loss at step 996500: 0.137703\n",
      "2022-11-09 03:30:20,084 INFO     Training average negative_sample_loss at step 996500: 0.137372\n",
      "2022-11-09 03:30:20,084 INFO     Training average loss at step 996500: 0.137537\n",
      "2022-11-09 03:30:23,170 INFO     Training average positive_sample_loss at step 996600: 0.137652\n",
      "2022-11-09 03:30:23,170 INFO     Training average negative_sample_loss at step 996600: 0.137539\n",
      "2022-11-09 03:30:23,170 INFO     Training average loss at step 996600: 0.137596\n",
      "2022-11-09 03:30:26,258 INFO     Training average positive_sample_loss at step 996700: 0.142451\n",
      "2022-11-09 03:30:26,259 INFO     Training average negative_sample_loss at step 996700: 0.131868\n",
      "2022-11-09 03:30:26,259 INFO     Training average loss at step 996700: 0.137159\n",
      "2022-11-09 03:30:29,387 INFO     Training average positive_sample_loss at step 996800: 0.137334\n",
      "2022-11-09 03:30:29,388 INFO     Training average negative_sample_loss at step 996800: 0.130813\n",
      "2022-11-09 03:30:29,388 INFO     Training average loss at step 996800: 0.134073\n",
      "2022-11-09 03:30:32,484 INFO     Training average positive_sample_loss at step 996900: 0.137443\n",
      "2022-11-09 03:30:32,484 INFO     Training average negative_sample_loss at step 996900: 0.129433\n",
      "2022-11-09 03:30:32,484 INFO     Training average loss at step 996900: 0.133438\n",
      "2022-11-09 03:30:35,599 INFO     Training average positive_sample_loss at step 997000: 0.144076\n",
      "2022-11-09 03:30:35,599 INFO     Training average negative_sample_loss at step 997000: 0.134422\n",
      "2022-11-09 03:30:35,599 INFO     Training average loss at step 997000: 0.139249\n",
      "2022-11-09 03:30:38,721 INFO     Training average positive_sample_loss at step 997100: 0.138799\n",
      "2022-11-09 03:30:38,721 INFO     Training average negative_sample_loss at step 997100: 0.134028\n",
      "2022-11-09 03:30:38,721 INFO     Training average loss at step 997100: 0.136414\n",
      "2022-11-09 03:30:43,268 INFO     Training average positive_sample_loss at step 997200: 0.136531\n",
      "2022-11-09 03:30:43,268 INFO     Training average negative_sample_loss at step 997200: 0.134665\n",
      "2022-11-09 03:30:43,269 INFO     Training average loss at step 997200: 0.135598\n",
      "2022-11-09 03:30:46,366 INFO     Training average positive_sample_loss at step 997300: 0.132668\n",
      "2022-11-09 03:30:46,366 INFO     Training average negative_sample_loss at step 997300: 0.129138\n",
      "2022-11-09 03:30:46,366 INFO     Training average loss at step 997300: 0.130903\n",
      "2022-11-09 03:30:49,473 INFO     Training average positive_sample_loss at step 997400: 0.143005\n",
      "2022-11-09 03:30:49,473 INFO     Training average negative_sample_loss at step 997400: 0.134300\n",
      "2022-11-09 03:30:49,473 INFO     Training average loss at step 997400: 0.138652\n",
      "2022-11-09 03:30:52,575 INFO     Training average positive_sample_loss at step 997500: 0.137249\n",
      "2022-11-09 03:30:52,575 INFO     Training average negative_sample_loss at step 997500: 0.136225\n",
      "2022-11-09 03:30:52,575 INFO     Training average loss at step 997500: 0.136737\n",
      "2022-11-09 03:30:57,218 INFO     Training average positive_sample_loss at step 997600: 0.135116\n",
      "2022-11-09 03:30:57,218 INFO     Training average negative_sample_loss at step 997600: 0.129845\n",
      "2022-11-09 03:30:57,218 INFO     Training average loss at step 997600: 0.132481\n",
      "2022-11-09 03:31:00,333 INFO     Training average positive_sample_loss at step 997700: 0.138081\n",
      "2022-11-09 03:31:00,333 INFO     Training average negative_sample_loss at step 997700: 0.131738\n",
      "2022-11-09 03:31:00,333 INFO     Training average loss at step 997700: 0.134909\n",
      "2022-11-09 03:31:03,438 INFO     Training average positive_sample_loss at step 997800: 0.135315\n",
      "2022-11-09 03:31:03,438 INFO     Training average negative_sample_loss at step 997800: 0.136102\n",
      "2022-11-09 03:31:03,438 INFO     Training average loss at step 997800: 0.135709\n",
      "2022-11-09 03:31:06,540 INFO     Training average positive_sample_loss at step 997900: 0.137591\n",
      "2022-11-09 03:31:06,540 INFO     Training average negative_sample_loss at step 997900: 0.135120\n",
      "2022-11-09 03:31:06,540 INFO     Training average loss at step 997900: 0.136355\n",
      "2022-11-09 03:31:09,642 INFO     Training average positive_sample_loss at step 998000: 0.133591\n",
      "2022-11-09 03:31:09,642 INFO     Training average negative_sample_loss at step 998000: 0.133261\n",
      "2022-11-09 03:31:09,642 INFO     Training average loss at step 998000: 0.133426\n",
      "2022-11-09 03:31:12,742 INFO     Training average positive_sample_loss at step 998100: 0.138416\n",
      "2022-11-09 03:31:12,742 INFO     Training average negative_sample_loss at step 998100: 0.137201\n",
      "2022-11-09 03:31:12,742 INFO     Training average loss at step 998100: 0.137808\n",
      "2022-11-09 03:31:15,834 INFO     Training average positive_sample_loss at step 998200: 0.137555\n",
      "2022-11-09 03:31:15,834 INFO     Training average negative_sample_loss at step 998200: 0.134668\n",
      "2022-11-09 03:31:15,834 INFO     Training average loss at step 998200: 0.136111\n",
      "2022-11-09 03:31:18,926 INFO     Training average positive_sample_loss at step 998300: 0.133650\n",
      "2022-11-09 03:31:18,926 INFO     Training average negative_sample_loss at step 998300: 0.131997\n",
      "2022-11-09 03:31:18,926 INFO     Training average loss at step 998300: 0.132824\n",
      "2022-11-09 03:31:22,018 INFO     Training average positive_sample_loss at step 998400: 0.138066\n",
      "2022-11-09 03:31:22,018 INFO     Training average negative_sample_loss at step 998400: 0.133700\n",
      "2022-11-09 03:31:22,018 INFO     Training average loss at step 998400: 0.135883\n",
      "2022-11-09 03:31:25,113 INFO     Training average positive_sample_loss at step 998500: 0.137190\n",
      "2022-11-09 03:31:25,113 INFO     Training average negative_sample_loss at step 998500: 0.132975\n",
      "2022-11-09 03:31:25,113 INFO     Training average loss at step 998500: 0.135083\n",
      "2022-11-09 03:31:28,217 INFO     Training average positive_sample_loss at step 998600: 0.136191\n",
      "2022-11-09 03:31:28,217 INFO     Training average negative_sample_loss at step 998600: 0.130333\n",
      "2022-11-09 03:31:28,217 INFO     Training average loss at step 998600: 0.133262\n",
      "2022-11-09 03:31:31,335 INFO     Training average positive_sample_loss at step 998700: 0.138720\n",
      "2022-11-09 03:31:31,335 INFO     Training average negative_sample_loss at step 998700: 0.136240\n",
      "2022-11-09 03:31:31,335 INFO     Training average loss at step 998700: 0.137480\n",
      "2022-11-09 03:31:34,435 INFO     Training average positive_sample_loss at step 998800: 0.136341\n",
      "2022-11-09 03:31:34,435 INFO     Training average negative_sample_loss at step 998800: 0.135422\n",
      "2022-11-09 03:31:34,435 INFO     Training average loss at step 998800: 0.135882\n",
      "2022-11-09 03:31:37,545 INFO     Training average positive_sample_loss at step 998900: 0.135274\n",
      "2022-11-09 03:31:37,545 INFO     Training average negative_sample_loss at step 998900: 0.132100\n",
      "2022-11-09 03:31:37,545 INFO     Training average loss at step 998900: 0.133687\n",
      "2022-11-09 03:31:40,669 INFO     Training average positive_sample_loss at step 999000: 0.134092\n",
      "2022-11-09 03:31:40,669 INFO     Training average negative_sample_loss at step 999000: 0.135280\n",
      "2022-11-09 03:31:40,669 INFO     Training average loss at step 999000: 0.134686\n",
      "2022-11-09 03:31:43,771 INFO     Training average positive_sample_loss at step 999100: 0.140613\n",
      "2022-11-09 03:31:43,772 INFO     Training average negative_sample_loss at step 999100: 0.135049\n",
      "2022-11-09 03:31:43,772 INFO     Training average loss at step 999100: 0.137831\n",
      "2022-11-09 03:31:46,880 INFO     Training average positive_sample_loss at step 999200: 0.135131\n",
      "2022-11-09 03:31:46,880 INFO     Training average negative_sample_loss at step 999200: 0.133171\n",
      "2022-11-09 03:31:46,880 INFO     Training average loss at step 999200: 0.134151\n",
      "2022-11-09 03:31:49,990 INFO     Training average positive_sample_loss at step 999300: 0.137659\n",
      "2022-11-09 03:31:49,990 INFO     Training average negative_sample_loss at step 999300: 0.136784\n",
      "2022-11-09 03:31:49,990 INFO     Training average loss at step 999300: 0.137221\n",
      "2022-11-09 03:31:53,112 INFO     Training average positive_sample_loss at step 999400: 0.140646\n",
      "2022-11-09 03:31:53,112 INFO     Training average negative_sample_loss at step 999400: 0.135667\n",
      "2022-11-09 03:31:53,112 INFO     Training average loss at step 999400: 0.138157\n",
      "2022-11-09 03:31:56,243 INFO     Training average positive_sample_loss at step 999500: 0.133944\n",
      "2022-11-09 03:31:56,243 INFO     Training average negative_sample_loss at step 999500: 0.131824\n",
      "2022-11-09 03:31:56,243 INFO     Training average loss at step 999500: 0.132884\n",
      "2022-11-09 03:31:59,358 INFO     Training average positive_sample_loss at step 999600: 0.139069\n",
      "2022-11-09 03:31:59,358 INFO     Training average negative_sample_loss at step 999600: 0.138923\n",
      "2022-11-09 03:31:59,358 INFO     Training average loss at step 999600: 0.138996\n",
      "2022-11-09 03:32:02,471 INFO     Training average positive_sample_loss at step 999700: 0.138662\n",
      "2022-11-09 03:32:02,471 INFO     Training average negative_sample_loss at step 999700: 0.141341\n",
      "2022-11-09 03:32:02,471 INFO     Training average loss at step 999700: 0.140002\n",
      "2022-11-09 03:32:05,569 INFO     Training average positive_sample_loss at step 999800: 0.138471\n",
      "2022-11-09 03:32:05,569 INFO     Training average negative_sample_loss at step 999800: 0.133414\n",
      "2022-11-09 03:32:05,569 INFO     Training average loss at step 999800: 0.135942\n",
      "2022-11-09 03:32:08,684 INFO     Training average positive_sample_loss at step 999900: 0.136466\n",
      "2022-11-09 03:32:08,684 INFO     Training average negative_sample_loss at step 999900: 0.132373\n",
      "2022-11-09 03:32:08,684 INFO     Training average loss at step 999900: 0.134420\n",
      "2022-11-09 03:32:14,616 INFO     Evaluating on Valid Dataset...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/roger/Desktop/projects/KnowledgeGraphEmbedding/codes/run.py\", line 364, in <module>\n",
      "    main(parse_args())\n",
      "  File \"/home/roger/Desktop/projects/KnowledgeGraphEmbedding/codes/run.py\", line 350, in main\n",
      "    metrics = kge_model.test_step(kge_model, valid_triples, all_true_triples, args)\n",
      "  File \"/home/roger/Desktop/projects/KnowledgeGraphEmbedding/codes/model.py\", line 401, in test_step\n",
      "    score = model((positive_sample, negative_sample), mode)\n",
      "  File \"/home/roger/Desktop/projects/virtual_Environments/rotate_venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/roger/Desktop/projects/KnowledgeGraphEmbedding/codes/model.py\", line 110, in forward\n",
      "    head = torch.index_select(\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.44 GiB (GPU 0; 9.78 GiB total capacity; 1.90 GiB already allocated; 6.94 GiB free; 1.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "# Batch Sz/ Neg_samp_Sz/ Dims/ gamma/ alpha/ lr/ steps/ test batch size/ double ent/ double rel/ regularization\n",
    "!bash run.sh train RotatE MIND_CtD 0 optimized 244 108 250 48.0 1.0 0.0001 1000000 16 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b111e5-f3ad-4826-9f0f-5a86d748b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-13 21:15:02,962 INFO     Model: RotatE\n",
      "2022-11-13 21:15:02,962 INFO     Data Path: data/MIND_CtD\n",
      "2022-11-13 21:15:02,963 INFO     #entity: 249605\n",
      "2022-11-13 21:15:02,963 INFO     #relation: 83\n",
      "2022-11-13 21:15:10,912 INFO     #train: 9657134\n",
      "2022-11-13 21:15:10,913 INFO     #valid: 473\n",
      "2022-11-13 21:15:10,916 INFO     #test: 511\n",
      "2022-11-13 21:15:12,587 INFO     Model Parameter Configuration:\n",
      "2022-11-13 21:15:12,587 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2022-11-13 21:15:12,587 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2022-11-13 21:15:12,587 INFO     Parameter entity_embedding: torch.Size([249605, 500]), require_grad = True\n",
      "2022-11-13 21:15:12,587 INFO     Parameter relation_embedding: torch.Size([83, 250]), require_grad = True\n",
      "2022-11-13 21:15:12,587 INFO     Loading checkpoint models/RotatE_MIND_CtD_optimized...\n",
      "2022-11-13 21:15:19,611 INFO     Start Training...\n",
      "2022-11-13 21:15:19,612 INFO     init_step = 999999\n",
      "2022-11-13 21:15:19,612 INFO     batch_size = 1024\n",
      "2022-11-13 21:15:19,612 INFO     negative_adversarial_sampling = 0\n",
      "2022-11-13 21:15:19,612 INFO     hidden_dim = 250\n",
      "2022-11-13 21:15:19,612 INFO     gamma = 12.000000\n",
      "2022-11-13 21:15:19,612 INFO     negative_adversarial_sampling = False\n",
      "2022-11-13 21:15:19,612 INFO     Evaluating on Test Dataset...\n",
      "2022-11-13 21:18:00,177 INFO     Evaluating the model... (0/64)\n",
      "2022-11-13 21:28:36,103 INFO     Evaluating the model... (5/64)\n",
      "2022-11-13 21:35:26,327 INFO     Evaluating the model... (10/64)\n",
      "2022-11-13 21:42:11,651 INFO     Evaluating the model... (15/64)\n",
      "2022-11-13 21:48:12,336 INFO     Evaluating the model... (20/64)\n",
      "2022-11-13 21:54:58,241 INFO     Evaluating the model... (25/64)\n",
      "2022-11-13 22:00:55,224 INFO     Evaluating the model... (30/64)\n",
      "2022-11-13 22:06:50,161 INFO     Evaluating the model... (35/64)\n",
      "2022-11-13 22:13:08,588 INFO     Evaluating the model... (40/64)\n",
      "2022-11-13 22:19:20,949 INFO     Evaluating the model... (45/64)\n",
      "2022-11-13 22:25:53,396 INFO     Evaluating the model... (50/64)\n",
      "2022-11-13 22:33:51,913 INFO     Evaluating the model... (55/64)\n",
      "2022-11-13 22:48:04,345 INFO     Evaluating the model... (60/64)\n",
      "2022-11-13 22:56:28,282 INFO     Test MRR at step 999999: 0.123203\n",
      "2022-11-13 22:56:28,282 INFO     Test MR at step 999999: 3605.146771\n",
      "2022-11-13 22:56:28,282 INFO     Test HITS@1 at step 999999: 0.063601\n",
      "2022-11-13 22:56:28,282 INFO     Test HITS@3 at step 999999: 0.138943\n",
      "2022-11-13 22:56:28,282 INFO     Test HITS@10 at step 999999: 0.239726\n",
      "2022-11-13 22:56:28,282 INFO     Test head-batch MRR at step 999999: 0.078197\n",
      "2022-11-13 22:56:28,282 INFO     Test head-batch MR at step 999999: 6025.457926\n",
      "2022-11-13 22:56:28,282 INFO     Test head-batch HITS@1 at step 999999: 0.035225\n",
      "2022-11-13 22:56:28,282 INFO     Test head-batch HITS@3 at step 999999: 0.088063\n",
      "2022-11-13 22:56:28,282 INFO     Test head-batch HITS@10 at step 999999: 0.156556\n",
      "2022-11-13 22:56:28,282 INFO     Test tail-batch MRR at step 999999: 0.168209\n",
      "2022-11-13 22:56:28,282 INFO     Test tail-batch MR at step 999999: 1184.835616\n",
      "2022-11-13 22:56:28,282 INFO     Test tail-batch HITS@1 at step 999999: 0.091977\n",
      "2022-11-13 22:56:28,282 INFO     Test tail-batch HITS@3 at step 999999: 0.189824\n",
      "2022-11-13 22:56:28,282 INFO     Test tail-batch HITS@10 at step 999999: 0.322896\n"
     ]
    }
   ],
   "source": [
    "!python -u codes/run.py --do_test -init models/RotatE_MIND_CtD_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c21833d-5b14-47ab-a40c-cc7c0a1655ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-03 14:22:54,830 INFO     Model: RotatE\n",
      "2023-01-03 14:22:54,831 INFO     Data Path: data/MIND_CtD\n",
      "2023-01-03 14:22:54,831 INFO     #entity: 249605\n",
      "2023-01-03 14:22:54,831 INFO     #relation: 83\n",
      "2023-01-03 14:22:59,841 INFO     #train: 9657134\n",
      "2023-01-03 14:22:59,842 INFO     #valid: 473\n",
      "2023-01-03 14:22:59,842 INFO     #test: 511\n",
      "2023-01-03 14:23:00,746 INFO     Model Parameter Configuration:\n",
      "2023-01-03 14:23:00,746 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-01-03 14:23:00,746 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-01-03 14:23:00,746 INFO     Parameter entity_embedding: torch.Size([249605, 500]), require_grad = True\n",
      "2023-01-03 14:23:00,746 INFO     Parameter relation_embedding: torch.Size([83, 250]), require_grad = True\n",
      "2023-01-03 14:23:00,746 INFO     Loading checkpoint models/RotatE_MIND_CtD_optimized...\n",
      "2023-01-03 14:23:04,504 INFO     Start Training...\n",
      "2023-01-03 14:23:04,504 INFO     init_step = 999999\n",
      "2023-01-03 14:23:04,504 INFO     batch_size = 1024\n",
      "2023-01-03 14:23:04,504 INFO     negative_adversarial_sampling = 0\n",
      "2023-01-03 14:23:04,505 INFO     hidden_dim = 250\n",
      "2023-01-03 14:23:04,505 INFO     gamma = 12.000000\n",
      "2023-01-03 14:23:04,505 INFO     negative_adversarial_sampling = False\n",
      "2023-01-03 14:23:04,505 INFO     Evaluating on Valid Dataset...\n",
      "2023-01-03 14:25:56,139 INFO     Evaluating the model... (0/60)\n",
      "2023-01-03 14:40:06,012 INFO     Evaluating the model... (5/60)\n",
      "2023-01-03 14:52:56,712 INFO     Evaluating the model... (10/60)\n",
      "2023-01-03 15:05:22,773 INFO     Evaluating the model... (15/60)\n",
      "2023-01-03 15:19:14,467 INFO     Evaluating the model... (20/60)\n",
      "2023-01-03 15:33:17,983 INFO     Evaluating the model... (25/60)\n",
      "2023-01-03 15:45:46,331 INFO     Evaluating the model... (30/60)\n",
      "2023-01-03 15:59:31,172 INFO     Evaluating the model... (35/60)\n",
      "2023-01-03 16:13:22,907 INFO     Evaluating the model... (40/60)\n",
      "2023-01-03 16:27:08,909 INFO     Evaluating the model... (45/60)\n",
      "2023-01-03 16:41:07,466 INFO     Evaluating the model... (50/60)\n",
      "2023-01-03 16:55:02,843 INFO     Evaluating the model... (55/60)\n",
      "2023-01-03 17:04:57,485 INFO     Valid MRR at step 999999: 0.063014\n",
      "2023-01-03 17:04:57,485 INFO     Valid MR at step 999999: 4232.003171\n",
      "2023-01-03 17:04:57,485 INFO     Valid HITS@1 at step 999999: 0.024313\n",
      "2023-01-03 17:04:57,485 INFO     Valid HITS@3 at step 999999: 0.053911\n",
      "2023-01-03 17:04:57,485 INFO     Valid HITS@10 at step 999999: 0.149049\n",
      "2023-01-03 17:04:57,485 INFO     Valid head-batch MRR at step 999999: 0.063998\n",
      "2023-01-03 17:04:57,485 INFO     Valid head-batch MR at step 999999: 6402.391121\n",
      "2023-01-03 17:04:57,485 INFO     Valid head-batch HITS@1 at step 999999: 0.029598\n",
      "2023-01-03 17:04:57,485 INFO     Valid head-batch HITS@3 at step 999999: 0.057082\n",
      "2023-01-03 17:04:57,485 INFO     Valid head-batch HITS@10 at step 999999: 0.139535\n",
      "2023-01-03 17:04:57,485 INFO     Valid tail-batch MRR at step 999999: 0.062030\n",
      "2023-01-03 17:04:57,485 INFO     Valid tail-batch MR at step 999999: 2061.615222\n",
      "2023-01-03 17:04:57,485 INFO     Valid tail-batch HITS@1 at step 999999: 0.019027\n",
      "2023-01-03 17:04:57,485 INFO     Valid tail-batch HITS@3 at step 999999: 0.050740\n",
      "2023-01-03 17:04:57,485 INFO     Valid tail-batch HITS@10 at step 999999: 0.158562\n"
     ]
    }
   ],
   "source": [
    "!python -u codes/run.py --do_valid -init models/RotatE_MIND_CtD_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8d417-9356-4e52-a4cb-830bd8846580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
